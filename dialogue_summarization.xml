<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivdialogue summarization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 08 Oct 2025 13:00:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems</title><link>http://arxiv.org/abs/2402.18013v2</link><description>This survey provides a comprehensive review of research on multi-turndialogue systems, with a particular focus on multi-turn dialogue systems basedon large language models (LLMs). This paper aims to (a) give a summary ofexisting LLMs and approaches for adapting LLMs to downstream tasks; (b)elaborate recent advances in multi-turn dialogue systems, covering bothLLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems,along with datasets and evaluation metrics; (c) discuss some future emphasisand recent research problems arising from the development of LLMs and theincreasing demands on multi-turn dialogue systems.</description><author>Zihao Yi, Jiarui Ouyang, Zhe Xu, Yuwen Liu, Tianhao Liao, Haohao Luo, Ying Shen</author><pubDate>Fri, 15 Aug 2025 03:28:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18013v2</guid></item><item><title>Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking</title><link>http://arxiv.org/abs/2403.09717v2</link><description>Depression-diagnosis-oriented chat aims to guide patients in self-expressionto collect key symptoms for depression detection. Recent work focuses oncombining task-oriented dialogue and chitchat to simulate the interview-baseddepression diagnosis. Whereas, these methods can not well capture the changinginformation, feelings, or symptoms of the patient during dialogues. Moreover,no explicit framework has been explored to guide the dialogue, which results insome useless communications that affect the experience. In this paper, wepropose to integrate Psychological State Tracking (POST) within the largelanguage model (LLM) to explicitly guide depression-diagnosis-oriented chat.Specifically, the state is adapted from a psychological theoretical model,which consists of four components, namely Stage, Information, Summary and Next.We fine-tune an LLM model to generate the dynamic psychological state, which isfurther used to assist response generation at each turn to simulate thepsychiatrist. Experimental results on the existing benchmark show that ourproposed method boosts the performance of all subtasks indepression-diagnosis-oriented chat.</description><author>Yiyang Gu, Yougen Zhou, Qin Chen, Ningning Zhou, Jie Zhou, Aimin Zhou, Liang He</author><pubDate>Wed, 20 Aug 2025 02:28:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09717v2</guid></item><item><title>Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</title><link>http://arxiv.org/abs/2308.15022v4</link><description>Recently, large language models (LLMs), such as GPT-4, stand out remarkableconversational abilities, enabling them to engage in dynamic and contextuallyrelevant dialogues across a wide range of topics. However, given a longconversation, these chatbots fail to recall past information and tend togenerate inconsistent responses. To address this, we propose to recursivelygenerate summaries/ memory using large language models (LLMs) to enhancelong-term memory ability. Specifically, our method first stimulates LLMs tomemorize small dialogue contexts and then recursively produce new memory usingprevious memory and following contexts. Finally, the chatbot can easilygenerate a highly consistent response with the help of the latest memory. Weevaluate our method on both open and closed LLMs, and the experiments on thewidely-used public dataset show that our method can generate more consistentresponses in a long-context conversation. Also, we show that our strategy couldnicely complement both long-context (e.g., 8K and 16K) and retrieval-enhancedLLMs, bringing further long-term dialogue performance. Notably, our method is apotential solution to enable the LLM to model the extremely long context. Thecode and scripts are released.</description><author>Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, Liang Ding</author><pubDate>Mon, 25 Aug 2025 14:43:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15022v4</guid></item><item><title>"Where does it hurt?" -- Dataset and Study on Physician Intent Trajectories in Doctor Patient Dialogues</title><link>http://arxiv.org/abs/2508.19077v1</link><description>In a doctor-patient dialogue, the primary objective of physicians is todiagnose patients and propose a treatment plan. Medical doctors guide theseconversations through targeted questioning to efficiently gather theinformation required to provide the best possible outcomes for patients. To thebest of our knowledge, this is the first work that studies physician intenttrajectories in doctor-patient dialogues. We use the `Ambient ClinicalIntelligence Benchmark' (Aci-bench) dataset for our study. We collaborate withmedical professionals to develop a fine-grained taxonomy of physician intentsbased on the SOAP framework (Subjective, Objective, Assessment, and Plan). Wethen conduct a large-scale annotation effort to label over 5000 doctor-patientturns with the help of a large number of medical experts recruited usingProlific, a popular crowd-sourcing platform. This large labeled dataset is animportant resource contribution that we use for benchmarking thestate-of-the-art generative and encoder models for medical intentclassification tasks. Our findings show that our models understand the generalstructure of medical dialogues with high accuracy, but often fail to identifytransitions between SOAP categories. We also report for the first time commontrajectories in medical dialogue structures that provide valuable insights fordesigning `differential diagnosis' systems. Finally, we extensively study theimpact of intent filtering for medical dialogue summarization and observe asignificant boost in performance. We make the codes and data, includingannotation guidelines, publicly available athttps://github.com/DATEXIS/medical-intent-classification.</description><author>Tom Röhr, Soumyadeep Roy, Fares Al Mohamad, Jens-Michalis Papaioannou, Wolfgang Nejdl, Felix Gers, Alexander Löser</author><pubDate>Tue, 26 Aug 2025 14:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.19077v1</guid></item><item><title>SGMem: Sentence Graph Memory for Long-Term Conversational Agents</title><link>http://arxiv.org/abs/2509.21212v1</link><description>Long-term conversational agents require effective memory management to handledialogue histories that exceed the context window of large language models(LLMs). Existing methods based on fact extraction or summarization reduceredundancy but struggle to organize and retrieve relevant information acrossdifferent granularities of dialogue and generated memory. We introduce SGMem(Sentence Graph Memory), which represents dialogue as sentence-level graphswithin chunked units, capturing associations across turn-, round-, andsession-level contexts. By combining retrieved raw dialogue with generatedmemory such as summaries, facts and insights, SGMem supplies LLMs with coherentand relevant context for response generation. Experiments on LongMemEval andLoCoMo show that SGMem consistently improves accuracy and outperforms strongbaselines in long-term conversational question answering.</description><author>Yaxiong Wu, Yongyue Zhang, Sheng Liang, Yong Liu</author><pubDate>Thu, 25 Sep 2025 14:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21212v1</guid></item><item><title>HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention</title><link>http://arxiv.org/abs/2509.07475v1</link><description>Detecting content that contradicts or is unsupported by a given source textis a critical challenge for the safe deployment of generative language models.We introduce HALT-RAG, a post-hoc verification system designed to identifyhallucinations in the outputs of Retrieval-Augmented Generation (RAG)pipelines. Our flexible and task-adaptable framework uses a universal featureset derived from an ensemble of two frozen, off-the-shelf Natural LanguageInference (NLI) models and lightweight lexical signals. These features are usedto train a simple, calibrated, and task-adapted meta-classifier. Using arigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage andproduce unbiased estimates, we evaluate our system on the HaluEval benchmark.By pairing our universal feature set with a lightweight, task-adaptedclassifier and a precision-constrained decision policy, HALT-RAG achievesstrong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,and dialogue tasks, respectively. The system's well-calibrated probabilitiesenable a practical abstention mechanism, providing a reliable tool forbalancing model performance with safety requirements.</description><author>Saumya Goswami, Siddharth Kurra</author><pubDate>Tue, 09 Sep 2025 07:58:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.07475v1</guid></item><item><title>Efficient Fine-Tuning of Large Language Models for Automated Medical Documentation</title><link>http://arxiv.org/abs/2409.09324v3</link><description>Scientific research indicates that for every hour spent in direct patientcare, physicians spend nearly two additional hours on administrative tasks,particularly on electronic health records (EHRs) and desk work. This excessiveadministrative burden not only reduces the time available for patient care butalso contributes to physician burnout and inefficiencies in healthcaredelivery. To address these challenges, this study introduces MediGen, afine-tuned large language model (LLM) designed to automate the generation ofmedical reports from medical dialogues. By leveraging state-of-the-artmethodologies for fine-tuning open-source pretrained models, includingLLaMA3-8B, MediGen achieves high accuracy in transcribing and summarizingclinical interactions. The fine-tuned LLaMA3-8B model demonstrated promisingresults, achieving a ROUGE score of 58% and a BERTScore-F1 of 72%, indicatingits effectiveness in generating accurate and clinically relevant medicalreports. These findings suggest that MediGen has the potential to significantlyreduce the administrative workload on physicians, improving both healthcareefficiency and physician well-being.</description><author>Hui Yi Leong, Yi Fan Gao, Ji Shuai, Yang Zhang, Uktu Pamuksuz</author><pubDate>Wed, 24 Sep 2025 16:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09324v3</guid></item><item><title>Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation</title><link>http://arxiv.org/abs/2509.25144v1</link><description>We present Paired by the Teacher (PbT), a two-stage teacher-student pipelinethat synthesizes accurate input-output pairs without human labels or paralleldata. In many low-resource natural language generation (NLG) scenarios,practitioners may have only raw outputs, like highlights, recaps, or questions,or only raw inputs, such as articles, dialogues, or paragraphs, but seldomboth. This mismatch forces small models to learn from very few examples or relyon costly, broad-scope synthetic examples produced by large LLMs. PbT addressesthis by asking a teacher LLM to compress each unpaired example into a conciseintermediate representation (IR), and training a student to reconstruct inputsfrom IRs. This enables outputs to be paired with student-generated inputs,yielding high-quality synthetic data. We evaluate PbT on fivebenchmarks-document summarization (XSum, CNNDM), dialogue summarization(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpairedsetting on SwitchBoard (paired with DialogSum summaries). An 8B student trainedonly on PbT data outperforms models trained on 70 B teacher-generated corporaand other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotatedpairs and closing 82% of the oracle gap at one-third the annotation cost ofdirect synthesis. Human evaluation on SwitchBoard further confirms that onlyPbT produces concise, faithful summaries aligned with the target style,highlighting its advantage of generating in-domain sources that avoid themismatch, limiting direct synthesis.</description><author>Yen-Ju Lu, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba</author><pubDate>Mon, 29 Sep 2025 17:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25144v1</guid></item><item><title>Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations</title><link>http://arxiv.org/abs/2507.14688v2</link><description>Post-training has emerged as a crucial technique for aligning pre-trainedLarge Language Models (LLMs) with human instructions, significantly enhancingtheir performance across a wide range of tasks. Central to this process is thequality and diversity of post-training datasets. This paper presents a reviewof publicly available Arabic post-training datasets on the Hugging Face Hub,organized along four key dimensions: (1) LLM Capabilities (e.g., QuestionAnswering, Translation, Reasoning, Summarization, Dialogue, Code Generation,and Function Calling); (2) Steerability (e.g., Persona and System Prompts); (3)Alignment (e.g., Cultural, Safety, Ethics, and Fairness); and (4) Robustness.Each dataset is rigorously evaluated based on popularity, practical adoption,recency and maintenance, documentation and annotation quality, licensingtransparency, and scientific contribution. Our review revealed critical gaps inthe development of Arabic post-training datasets, including limited taskdiversity, inconsistent or missing documentation and annotation, and lowadoption across the community. Finally, the paper discusses the implications ofthese gaps on the progress of Arabic-centric LLMs and applications whileproviding concrete recommendations for future efforts in Arabic post-trainingdataset development.</description><author>Mohammed Alkhowaiter, Norah Alshahrani, Saied Alshahrani, Reem I. Masoud, Alaa Alzahrani, Deema Alnuhait, Emad A. Alghamdi, Khalid Almubarak</author><pubDate>Tue, 30 Sep 2025 16:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.14688v2</guid></item><item><title>Stream RAG: Instant and Accurate Spoken Dialogue Systems with Streaming Tool Usage</title><link>http://arxiv.org/abs/2510.02044v1</link><description>End-to-end speech-in speech-out dialogue systems are emerging as a powerfulalternative to traditional ASR-LLM-TTS pipelines, generating more natural,expressive responses with significantly lower latency. However, these systemsremain prone to hallucinations due to limited factual grounding. Whiletext-based dialogue systems address this challenge by integrating tools such asweb search and knowledge graph APIs, we introduce the first approach to extendtool use directly into speech-in speech-out systems. A key challenge is thattool integration substantially increases response latency, disruptingconversational flow. To mitigate this, we propose Streaming Retrieval-AugmentedGeneration (Streaming RAG), a novel framework that reduces user-perceivedlatency by predicting tool queries in parallel with user speech, even beforethe user finishes speaking. Specifically, we develop a post-training pipelinethat teaches the model when to issue tool calls during ongoing speech and howto generate spoken summaries that fuse audio queries with retrieved textresults, thereby improving both accuracy and responsiveness. To evaluate ourapproach, we construct AudioCRAG, a benchmark created by converting queriesfrom the publicly available CRAG dataset into speech form. Experimental resultsdemonstrate that our streaming RAG approach increases QA accuracy by up to 200%relative (from 11.1% to 34.2% absolute) and further enhances user experience byreducing tool use latency by 20%. Importantly, our streaming RAG approach ismodality-agnostic and can be applied equally to typed input, paving the way formore agentic, real-time AI assistants.</description><author>Siddhant Arora, Haidar Khan, Kai Sun, Xin Luna Dong, Sajal Choudhary, Seungwhan Moon, Xinyuan Zhang, Adithya Sagar, Surya Teja Appini, Kaushik Patnaik, Sanat Sharma, Shinji Watanabe, Anuj Kumar, Ahmed Aly, Yue Liu, Florian Metze, Zhaojiang Lin</author><pubDate>Thu, 02 Oct 2025 14:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02044v1</guid></item></channel></rss>