<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 01 Oct 2025 13:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>TTT3R: 3D Reconstruction as Test-Time Training</title><link>http://arxiv.org/abs/2509.26645v1</link><description>Modern Recurrent Neural Networks have become a competitive architecture for3D reconstruction due to their linear-time complexity. However, theirperformance degrades significantly when applied beyond the training contextlength, revealing limited length generalization. In this work, we revisit the3D reconstruction foundation models from a Test-Time Training perspective,framing their designs as an online learning problem. Building on thisperspective, we leverage the alignment confidence between the memory state andincoming observations to derive a closed-form learning rate for memory updates,to balance between retaining historical information and adapting to newobservations. This training-free intervention, termed TTT3R, substantiallyimproves length generalization, achieving a $2\times$ improvement in globalpose estimation over baselines, while operating at 20 FPS with just 6 GB of GPUmemory to process thousands of images. Code available inhttps://rover-xingyu.github.io/TTT3R</description><author>Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen</author><pubDate>Tue, 30 Sep 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26645v1</guid></item><item><title>Stitch: Training-Free Position Control in Multimodal Diffusion Transformers</title><link>http://arxiv.org/abs/2509.26644v1</link><description>Text-to-Image (T2I) generation models have advanced rapidly in recent years,but accurately capturing spatial relationships like "above" or "to the rightof" poses a persistent challenge. Earlier methods improved spatial relationshipfollowing with external position control. However, as architectures evolved toenhance image quality, these techniques became incompatible with modern models.We propose Stitch, a training-free method for incorporating external positioncontrol into Multi-Modal Diffusion Transformers (MMDiT) viaautomatically-generated bounding boxes. Stitch produces images that are bothspatially accurate and visually appealing by generating individual objectswithin designated bounding boxes and seamlessly stitching them together. Wefind that targeted attention heads capture the information necessary to isolateand cut out individual objects mid-generation, without needing to fullycomplete the image. We evaluate Stitch on PosEval, our benchmark forposition-based T2I generation. Featuring five new tasks that extend the conceptof Position beyond the basic GenEval task, PosEval demonstrates that even topmodels still have significant room for improvement in position-basedgeneration. Tested on Qwen-Image, FLUX, and SD3.5, Stitch consistently enhancesbase models, even improving FLUX by 218% on GenEval's Position task and by 206%on PosEval. Stitch achieves state-of-the-art results with Qwen-Image onPosEval, improving over previous models by 54%, all accomplished whileintegrating position control into leading models training-free. Code isavailable at https://github.com/ExplainableML/Stitch.</description><author>Jessica Bader, Mateusz Pach, Maria A. Bravo, Serge Belongie, Zeynep Akata</author><pubDate>Tue, 30 Sep 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26644v1</guid></item><item><title>Convergence and Divergence of Language Models under Different Random Seeds</title><link>http://arxiv.org/abs/2509.26643v1</link><description>In this paper, we investigate the convergence of language models (LMs)trained under different random seeds, measuring convergence as the expectedper-token Kullback--Leibler (KL) divergence across seeds. By comparing LMconvergence as a function of model size and training checkpoint, we identify afour-phase convergence pattern: (i) an initial uniform phase, (ii) asharp-convergence phase, (iii) a sharp-divergence phase, and (iv) aslow-reconvergence phase. Further, we observe that larger models reconvergefaster in later training stages, while smaller models never actuallyreconverge; these results suggest that a certain model size may be necessary tolearn stable distributions. Restricting our analysis to specific tokenfrequencies or part-of-speech (PoS) tags further reveals that convergence isuneven across linguistic categories: frequent tokens and function wordsconverge faster and more reliably than their counterparts (infrequent tokensand content words). Overall, our findings highlight factors that influence thestability of the learned distributions in model training.</description><author>Finlay Fehlauer, Kyle Mahowald, Tiago Pimentel</author><pubDate>Tue, 30 Sep 2025 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26643v1</guid></item><item><title>Query-Kontext: An Unified Multimodal Model for Image Generation and Editing</title><link>http://arxiv.org/abs/2509.26641v1</link><description>Unified Multimodal Models (UMMs) have demonstrated remarkable performance intext-to-image generation (T2I) and editing (TI2I), whether instantiated asassembled unified frameworks which couple powerful vision-language model (VLM)with diffusion-based generator, or as naive Unified Multimodal Models with anearly fusion of understanding and generation modalities. We contend that incurrent unified frameworks, the crucial capability of multimodal generativereasoning which encompasses instruction understanding, grounding, and imagereferring for identity preservation and faithful reconstruction, isintrinsically entangled with high-fidelity synthesis. In this work, weintroduce Query-Kontext, a novel approach that bridges the VLM and diffusionmodel via a multimodal ``kontext'' composed of semantic cues and coarse-grainedimage conditions encoded from multimodal inputs. This design delegates thecomplex ability of multimodal generative reasoning to powerful VLM whilereserving diffusion model's role for high-quality visual synthesis. To achievethis, we propose a three-stage progressive training strategy. First, we connectthe VLM to a lightweight diffusion head via multimodal kontext tokens tounleash the VLM's generative reasoning ability. Second, we scale this head to alarge, pre-trained diffusion model to enhance visual detail and realism.Finally, we introduce a low-level image encoder to improve image fidelity andperform instruction tuning on downstream tasks. Furthermore, we build acomprehensive data pipeline integrating real, synthetic, and open-sourcedatasets, covering diverse multimodal reference-to-image scenarios, includingimage generation, instruction-driven editing, customized generation, andmulti-subject composition. Experiments show that our approach matches strongunified baselines and even outperforms task-specific state-of-the-art methodsin several cases.</description><author>Yuxin Song, Wenkai Dong, Shizun Wang, Qi Zhang, Song Xue, Tao Yuan, Hu Yang, Haocheng Feng, Hang Zhou, Xinyan Xiao, Jingdong Wang</author><pubDate>Tue, 30 Sep 2025 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26641v1</guid></item><item><title>SPATA: Systematic Pattern Analysis for Detailed and Transparent Data Cards</title><link>http://arxiv.org/abs/2509.26640v1</link><description>Due to the susceptibility of Artificial Intelligence (AI) to dataperturbations and adversarial examples, it is crucial to perform a thoroughrobustness evaluation before any Machine Learning (ML) model is deployed.However, examining a model's decision boundaries and identifying potentialvulnerabilities typically requires access to the training and testing datasets,which may pose risks to data privacy and confidentiality. To improvetransparency in organizations that handle confidential data or manage criticalinfrastructure, it is essential to allow external verification and validationof AI without the disclosure of private datasets. This paper presentsSystematic Pattern Analysis (SPATA), a deterministic method that converts anytabular dataset to a domain-independent representation of its statisticalpatterns, to provide more detailed and transparent data cards. SPATA computesthe projection of each data instance into a discrete space where they can beanalyzed and compared, without risking data leakage. These projected datasetscan be reliably used for the evaluation of how different features affect MLmodel robustness and for the generation of interpretable explanations of theirbehavior, contributing to more trustworthy AI.</description><author>João Vitorino, Eva Maia, Isabel Praça, Carlos Soares</author><pubDate>Tue, 30 Sep 2025 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26640v1</guid></item><item><title>Benchmarking Egocentric Visual-Inertial SLAM at City Scale</title><link>http://arxiv.org/abs/2509.26639v1</link><description>Precise 6-DoF simultaneous localization and mapping (SLAM) from onboardsensors is critical for wearable devices capturing egocentric data, whichexhibits specific challenges, such as a wider diversity of motions andviewpoints, prevalent dynamic visual content, or long sessions affected bytime-varying sensor calibration. While recent progress on SLAM has been swift,academic research is still driven by benchmarks that do not reflect thesechallenges or do not offer sufficiently accurate ground truth poses. In thispaper, we introduce a new dataset and benchmark for visual-inertial SLAM withegocentric, multi-modal data. We record hours and kilometers of trajectoriesthrough a city center with glasses-like devices equipped with various sensors.We leverage surveying tools to obtain control points as indirect poseannotations that are metric, centimeter-accurate, and available at city scale.This makes it possible to evaluate extreme trajectories that involve walking atnight or traveling in a vehicle. We show that state-of-the-art systemsdeveloped by academia are not robust to these challenges and we identifycomponents that are responsible for this. In addition, we design tracks withdifferent levels of difficulty to ease in-depth analysis and evaluation of lessmature approaches. The dataset and benchmark are available athttps://www.lamaria.ethz.ch.</description><author>Anusha Krishnan, Shaohui Liu, Paul-Edouard Sarlin, Oscar Gentilhomme, David Caruso, Maurizio Monge, Richard Newcombe, Jakob Engel, Marc Pollefeys</author><pubDate>Tue, 30 Sep 2025 17:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26639v1</guid></item><item><title>AccidentBench: Benchmarking Multimodal Understanding and Reasoning in Vehicle Accidents and Beyond</title><link>http://arxiv.org/abs/2509.26636v1</link><description>Rapid advances in multimodal models demand benchmarks that rigorouslyevaluate understanding and reasoning in safety-critical, dynamic real-worldsettings. We present AccidentBench, a large-scale benchmark that combinesvehicle accident scenarios with Beyond domains, safety-critical settings in airand water that emphasize spatial and temporal reasoning (e.g., navigation,orientation, multi-vehicle motion). The benchmark contains approximately 2000videos and over 19000 human-annotated question--answer pairs spanning multiplevideo lengths (short/medium/long) and difficulty levels (easy/medium/hard).Tasks systematically probe core capabilities: temporal, spatial, and intentunderstanding and reasoning. By unifying accident-centric traffic scenes withbroader safety-critical scenarios in air and water, AccidentBench offers acomprehensive, physically grounded testbed for evaluating models underreal-world variability. Evaluations of state-of-the-art models (e.g.,Gemini-2.5 Pro and GPT-5) show that even the strongest models achieve onlyabout 18% accuracy on the hardest tasks and longest videos, revealingsubstantial gaps in real-world temporal, spatial, and intent reasoning.AccidentBench is designed to expose these critical gaps and drive thedevelopment of multimodal models that are safer, more robust, and betteraligned with real-world safety-critical challenges. The code and dataset areavailable at: https://github.com/SafeRL-Lab/AccidentBench</description><author>Shangding Gu, Xiaohan Wang, Donghao Ying, Haoyu Zhao, Runing Yang, Ming Jin, Boyi Li, Marco Pavone, Serena Yeung-Levy, Jun Wang, Dawn Song, Costas Spanos</author><pubDate>Tue, 30 Sep 2025 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26636v1</guid></item><item><title>Scaling Spoken Language Models with Syllabic Speech Tokenization</title><link>http://arxiv.org/abs/2509.26634v1</link><description>Spoken language models (SLMs) typically discretize speech intohigh-frame-rate tokens extracted from SSL speech models. As the most successfulLMs are based on the Transformer architecture, processing these long tokenstreams with self-attention is expensive, as attention scales quadraticallywith sequence length. A recent SSL work introduces acoustic tokenization ofspeech at the syllable level, which is more interpretable and potentially morescalable with significant compression in token lengths (4-5 Hz). Yet, theirvalue for spoken language modeling is not yet fully explored. We present thefirst systematic study of syllabic tokenization for spoken language modeling,evaluating models on a suite of SLU benchmarks while varying training datascale. Syllabic tokens can match or surpass the previous high-frame rate tokenswhile significantly cutting training and inference costs, achieving more than a2x reduction in training time and a 5x reduction in FLOPs. Our findingshighlight syllable-level language modeling as a promising path to efficientlong-context spoken language models.</description><author>Nicholas Lee, Cheol Jun Cho, Alan W Black, Gopala K. Anumanchipalli</author><pubDate>Tue, 30 Sep 2025 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26634v1</guid></item><item><title>OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction</title><link>http://arxiv.org/abs/2509.26633v1</link><description>A dominant paradigm for teaching humanoid robots complex skills is toretarget human motions as kinematic references to train reinforcement learning(RL) policies. However, existing retargeting pipelines often struggle with thesignificant embodiment gap between humans and robots, producing physicallyimplausible artifacts like foot-skating and penetration. More importantly,common retargeting methods neglect the rich human-object and human-environmentinteractions essential for expressive locomotion and loco-manipulation. Toaddress this, we introduce OmniRetarget, an interaction-preserving datageneration engine based on an interaction mesh that explicitly models andpreserves the crucial spatial and contact relationships between an agent, theterrain, and manipulated objects. By minimizing the Laplacian deformationbetween the human and robot meshes while enforcing kinematic constraints,OmniRetarget generates kinematically feasible trajectories. Moreover,preserving task-relevant interactions enables efficient data augmentation, froma single demonstration to different robot embodiments, terrains, and objectconfigurations. We comprehensively evaluate OmniRetarget by retargeting motionsfrom OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hourtrajectories that achieve better kinematic constraint satisfaction and contactpreservation than widely used baselines. Such high-quality data enablesproprioceptive RL policies to successfully execute long-horizon (up to 30seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trainedwith only 5 reward terms and simple domain randomization shared by all tasks,without any learning curriculum.</description><author>Lujie Yang, Xiaoyu Huang, Zhen Wu, Angjoo Kanazawa, Pieter Abbeel, Carmelo Sferrazza, C. Karen Liu, Rocky Duan, Guanya Shi</author><pubDate>Tue, 30 Sep 2025 17:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26633v1</guid></item><item><title>Branching Out: Broadening AI Measurement and Evaluation with Measurement Trees</title><link>http://arxiv.org/abs/2509.26632v1</link><description>This paper introduces \textit{measurement trees}, a novel class of metricsdesigned to combine various constructs into an interpretable multi-levelrepresentation of a measurand. Unlike conventional metrics that yield singlevalues, vectors, surfaces, or categories, measurement trees produce ahierarchical directed graph in which each node summarizes its children throughuser-defined aggregation methods. In response to recent calls to expand thescope of AI system evaluation, measurement trees enhance metric transparencyand facilitate the integration of heterogeneous evidence, including, e.g.,agentic, business, energy-efficiency, sociotechnical, or security signals. Wepresent definitions and examples, demonstrate practical utility through alarge-scale measurement exercise, and provide accompanying open-source Pythoncode. By operationalizing a transparent approach to measurement of complexconstructs, this work offers a principled foundation for broader and moreinterpretable AI evaluation.</description><author>Craig Greenberg, Patrick Hall, Theodore Jensen, Kristen Greene, Razvan Amironesei</author><pubDate>Tue, 30 Sep 2025 17:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26632v1</guid></item><item><title>Learning Generalizable Shape Completion with SIM(3) Equivariance</title><link>http://arxiv.org/abs/2509.26631v1</link><description>3D shape completion methods typically assume scans are pre-aligned to acanonical frame. This leaks pose and scale cues that networks may exploit tomemorize absolute positions rather than inferring intrinsic geometry. When suchalignment is absent in real data, performance collapses. We argue that robustgeneralization demands architectural equivariance to the similarity group,SIM(3), so the model remains agnostic to pose and scale. Following thisprinciple, we introduce the first SIM(3)-equivariant shape completion network,whose modular layers successively canonicalize features, reason oversimilarity-invariant geometry, and restore the original frame. Under ade-biased evaluation protocol that removes the hidden cues, our modeloutperforms both equivariant and augmentation baselines on the PCN benchmark.It also sets new cross-domain records on real driving and indoor scans,lowering minimal matching distance on KITTI by 17% and Chamfer distance $\ell1$on OmniObject3D by 14%. Perhaps surprisingly, ours under the stricter protocolstill outperforms competitors under their biased settings. These resultsestablish full SIM(3) equivariance as an effective route to truly generalizableshape completion. Project page: https://sime-completion.github.io.</description><author>Yuqing Wang, Zhaiyu Chen, Xiao Xiang Zhu</author><pubDate>Tue, 30 Sep 2025 17:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26631v1</guid></item><item><title>Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models</title><link>http://arxiv.org/abs/2509.26628v1</link><description>Reinforcement Learning (RL) has shown remarkable success in enhancing thereasoning capabilities of Large Language Models (LLMs). Process-Supervised RL(PSRL) has emerged as a more effective paradigm compared to outcome-based RL.However, existing PSRL approaches suffer from limited exploration efficiency,both in terms of branching positions and sampling. In this paper, we introducea novel PSRL framework (AttnRL), which enables efficient exploration forreasoning models. Motivated by preliminary observations that steps exhibitinghigh attention scores correlate with reasoning behaviors, we propose to branchfrom positions with high values. Furthermore, we develop an adaptive samplingstrategy that accounts for problem difficulty and historical batch size,ensuring that the whole training batch maintains non-zero advantage values. Tofurther improve sampling efficiency, we design a one-step off-policy trainingpipeline for PSRL. Extensive experiments on multiple challenging mathematicalreasoning benchmarks demonstrate that our method consistently outperforms priorapproaches in terms of performance and sampling and training efficiency.</description><author>Runze Liu, Jiakang Wang, Yuling Shi, Zhihui Xie, Chenxin An, Kaiyan Zhang, Jian Zhao, Xiaodong Gu, Lei Lin, Wenping Hu, Xiu Li, Fuzheng Zhang, Guorui Zhou, Kun Gai</author><pubDate>Tue, 30 Sep 2025 17:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26628v1</guid></item><item><title>TimeRewarder: Learning Dense Reward from Passive Videos via Frame-wise Temporal Distance</title><link>http://arxiv.org/abs/2509.26627v1</link><description>Designing dense rewards is crucial for reinforcement learning (RL), yet inrobotics it often demands extensive manual effort and lacks scalability. Onepromising solution is to view task progress as a dense reward signal, as itquantifies the degree to which actions advance the system toward taskcompletion over time. We present TimeRewarder, a simple yet effective rewardlearning method that derives progress estimation signals from passive videos,including robot demonstrations and human videos, by modeling temporal distancesbetween frame pairs. We then demonstrate how TimeRewarder can supply step-wiseproxy rewards to guide reinforcement learning. In our comprehensive experimentson ten challenging Meta-World tasks, we show that TimeRewarder dramaticallyimproves RL for sparse-reward tasks, achieving nearly perfect success in 9/10tasks with only 200,000 interactions per task with the environment. Thisapproach outperformed previous methods and even the manually designedenvironment dense reward on both the final success rate and sample efficiency.Moreover, we show that TimeRewarder pretraining can exploit real-world humanvideos, highlighting its potential as a scalable approach path to rich rewardsignals from diverse video sources.</description><author>Yuyang Liu, Chuan Wen, Yihang Hu, Dinesh Jayaraman, Yang Gao</author><pubDate>Tue, 30 Sep 2025 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26627v1</guid></item><item><title>The Impact of Language Mixing on Bilingual LLM Reasoning</title><link>http://arxiv.org/abs/2507.15849v2</link><description>Proficient multilingual speakers often intentionally switch languages in themiddle of a conversation. Similarly, recent reasoning-focused bilingual largelanguage models (LLMs) with strong capabilities in both languages exhibitlanguage mixing-alternating languages within their chain of thought.Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy,suggesting that language mixing may benefit reasoning. In this work, we studylanguage switching in Chinese-English bilingual reasoning models. We identifyreinforcement learning with verifiable rewards (RLVR) as the critical trainingstage that leads to language mixing. We show that language mixing can enhancereasoning: enforcing monolingual decoding reduces accuracy by 5.6 percentagepoints on MATH500. Additionally, a lightweight probe can be trained to predictwhether a potential language switch would benefit or harm reasoning, and whenused to guide decoding, increases accuracy by 2.92 percentage points. Ourfindings suggest that language mixing is not merely a byproduct of multilingualtraining, but is a strategic reasoning behavior.</description><author>Yihao Li, Jiayi Xin, Miranda Muqing Miao, Qi Long, Lyle Ungar</author><pubDate>Tue, 30 Sep 2025 17:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15849v2</guid></item><item><title>Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models</title><link>http://arxiv.org/abs/2509.26626v1</link><description>Test-time scaling methods improve the capabilities of large language models(LLMs) by increasing the amount of compute used during inference to make aprediction. Inference-time compute can be scaled in parallel by choosing amongmultiple independent solutions or sequentially through self-refinement. Wepropose Recursive Self-Aggregation (RSA), a test-time scaling method inspiredby evolutionary methods that combines the benefits of both parallel andsequential scaling. Each step of RSA refines a population of candidatereasoning chains through aggregation of subsets to yield a population ofimproved solutions, which are then used as the candidate pool for the nextiteration. RSA exploits the rich information embedded in the reasoning chains-- not just the final answers -- and enables bootstrapping from partiallycorrect intermediate steps within different chains of thought. Empirically, RSAdelivers substantial performance gains with increasing compute budgets acrossdiverse tasks, model families and sizes. Notably, RSA enablesQwen3-4B-Instruct-2507 to achieve competitive performance with larger reasoningmodels, including DeepSeek-R1 and o3-mini (high), while outperforming purelyparallel and sequential scaling strategies across AIME-25, HMMT-25, ReasoningGym, LiveCodeBench-v6, and SuperGPQA. We further demonstrate that training themodel to combine solutions via a novel aggregation-aware reinforcement learningapproach yields significant performance gains. Code available athttps://github.com/HyperPotatoNeo/RSA.</description><author>Siddarth Venkatraman, Vineet Jain, Sarthak Mittal, Vedant Shah, Johan Obando-Ceron, Yoshua Bengio, Brian R. Bartoldson, Bhavya Kailkhura, Guillaume Lajoie, Glen Berseth, Nikolay Malkin, Moksh Jain</author><pubDate>Tue, 30 Sep 2025 17:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26626v1</guid></item><item><title>Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training</title><link>http://arxiv.org/abs/2509.26625v1</link><description>Large Language Models (LLMs), despite being trained on text alone,surprisingly develop rich visual priors. These priors allow latent visualcapabilities to be unlocked for vision tasks with a relatively small amount ofmultimodal data, and in some cases, to perform visual tasks without ever havingseen an image. Through systematic analysis, we reveal that visual priors-theimplicit, emergent knowledge about the visual world acquired during languagepre-training-are composed of separable perception and reasoning priors withunique scaling trends and origins. We show that an LLM's latent visualreasoning ability is predominantly developed by pre-training onreasoning-centric data (e.g., code, math, academia) and scales progressively.This reasoning prior acquired from language pre-training is transferable anduniversally applicable to visual reasoning. In contrast, a perception prioremerges more diffusely from broad corpora, and perception ability is moresensitive to the vision encoder and visual instruction tuning data. Inparallel, text describing the visual world proves crucial, though itsperformance impact saturates rapidly. Leveraging these insights, we propose adata-centric recipe for pre-training vision-aware LLMs and verify it in 1Ttoken scale pre-training. Our findings are grounded in over 100 controlledexperiments consuming 500,000 GPU-hours, spanning the full MLLM constructionpipeline-from LLM pre-training to visual alignment and supervised multimodalfine-tuning-across five model scales, a wide range of data categories andmixtures, and multiple adaptation setups. Along with our main findings, wepropose and investigate several hypotheses, and introduce the Multi-LevelExistence Bench (MLE-Bench). Together, this work provides a new way ofdeliberately cultivating visual priors from language pre-training, paving theway for the next generation of multimodal LLMs.</description><author>Junlin Han, Shengbang Tong, David Fan, Yufan Ren, Koustuv Sinha, Philip Torr, Filippos Kokkinos</author><pubDate>Tue, 30 Sep 2025 17:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26625v1</guid></item><item><title>On Fitting Flow Models with Large Sinkhorn Couplings</title><link>http://arxiv.org/abs/2506.05526v3</link><description>Flow models transform data gradually from one modality (e.g. noise) ontoanother (e.g. images). Such models are parameterized by a time-dependentvelocity field, trained to fit segments connecting pairs of source and targetpoints. When the pairing between source and target points is given, trainingflow models boils down to a supervised regression problem. When no such pairingexists, as is the case when generating data from noise, training flows is muchharder. A popular approach lies in picking source and target pointsindependently. This can, however, lead to velocity fields that are slow totrain, but also costly to integrate at inference time. In theory, one wouldgreatly benefit from training flow models by sampling pairs from an optimaltransport (OT) measure coupling source and target, since this would lead to ahighly efficient flow solving the Benamou and Brenier dynamical OT problem. Inpractice, recent works have proposed to sample mini-batches of $n$ source and$n$ target points and reorder them using an OT solver to form better pairs.These works have advocated using batches of size $n\approx 256$, and consideredOT solvers that return couplings that are either sharp (using e.g. theHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.Sinkhorn). We follow in the footsteps of these works by exploring the benefitsof increasing $n$ by three to four orders of magnitude, and look more carefullyon the effect of the entropic regularization $\varepsilon$ used in the Sinkhornalgorithm. Our analysis is facilitated by new scale invariant quantities toreport the sharpness of a coupling, while our sharded computations acrossmultiple GPU or GPU nodes allow scaling up $n$. We show that in both syntheticand image generation tasks, flow models greatly benefit when fitted with largeSinkhorn couplings, with a low entropic regularization $\varepsilon$.</description><author>Stephen Zhang, Alireza Mousavi-Hosseini, Michal Klein, Marco Cuturi</author><pubDate>Tue, 30 Sep 2025 17:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05526v3</guid></item><item><title>HART: Human Aligned Reconstruction Transformer</title><link>http://arxiv.org/abs/2509.26621v1</link><description>We introduce HART, a unified framework for sparse-view human reconstruction.Given a small set of uncalibrated RGB images of a person as input, it outputs awatertight clothed mesh, the aligned SMPL-X body mesh, and a Gaussian-splatrepresentation for photorealistic novel-view rendering. Prior methods forclothed human reconstruction either optimize parametric templates, whichoverlook loose garments and human-object interactions, or train implicitfunctions under simplified camera assumptions, limiting applicability in realscenes. In contrast, HART predicts per-pixel 3D point maps, normals, and bodycorrespondences, and employs an occlusion-aware Poisson reconstruction torecover complete geometry, even in self-occluded regions. These predictionsalso align with a parametric SMPL-X body model, ensuring that reconstructedgeometry remains consistent with human structure while capturing loose clothingand interactions. These human-aligned meshes initialize Gaussian splats tofurther enable sparse-view rendering. While trained on only 2.3K syntheticscans, HART achieves state-of-the-art results: Chamfer Distance improves by18-23 percent for clothed-mesh reconstruction, PA-V2V drops by 6-27 percent forSMPL-X estimation, LPIPS decreases by 15-27 percent for novel-view synthesis ona wide range of datasets. These results suggest that feed-forward transformerscan serve as a scalable model for robust human reconstruction in real-worldsettings. Code and models will be released.</description><author>Xiyi Chen, Shaofei Wang, Marko Mihajlovic, Taewon Kang, Sergey Prokudin, Ming Lin</author><pubDate>Tue, 30 Sep 2025 17:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26621v1</guid></item><item><title>Searching for Difficult-to-Translate Test Examples at Scale</title><link>http://arxiv.org/abs/2509.26619v1</link><description>NLP models require test data that are sufficiently challenging. Thedifficulty of an example is linked to the topic it originates from (''seedtopic''). The relationship between the topic and the difficulty of itsinstances is stochastic in nature: an example about a difficult topic canhappen to be easy, and vice versa. At the scale of the Internet, there are tensof thousands of potential topics, and finding the most difficult one by drawingand evaluating a large number of examples across all topics is computationallyinfeasible. We formalize this task and treat it as a multi-armed banditproblem. In this framework, each topic is an ''arm,'' and pulling an arm (at acost) involves drawing a single example, evaluating it, and measuring itsdifficulty. The goal is to efficiently identify the most difficult topicswithin a fixed computational budget. We illustrate the bandit problem setup offinding difficult examples for the task of machine translation. We find thatvarious bandit strategies vastly outperform baseline methods like brute-forcesearching the most challenging topics.</description><author>Wenda Xu, Vilém Zouhar, Parker Riley, Mara Finkelstein, Markus Freitag, Daniel Deutsch</author><pubDate>Tue, 30 Sep 2025 17:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26619v1</guid></item><item><title>DA$^2$: Depth Anything in Any Direction</title><link>http://arxiv.org/abs/2509.26618v1</link><description>Panorama has a full FoV (360$^\circ\times$180$^\circ$), offering a morecomplete visual description than perspective images. Thanks to thischaracteristic, panoramic depth estimation is gaining increasing traction in 3Dvision. However, due to the scarcity of panoramic data, previous methods areoften restricted to in-domain settings, leading to poor zero-shotgeneralization. Furthermore, due to the spherical distortions inherent inpanoramas, many approaches rely on perspective splitting (e.g., cubemaps),which leads to suboptimal efficiency. To address these challenges, we propose$\textbf{DA}$$^{\textbf{2}}$: $\textbf{D}$epth $\textbf{A}$nything in$\textbf{A}$ny $\textbf{D}$irection, an accurate, zero-shot generalizable, andfully end-to-end panoramic depth estimator. Specifically, for scaling uppanoramic data, we introduce a data curation engine for generating high-qualitypanoramic depth data from perspective, and create $\sim$543K panoramicRGB-depth pairs, bringing the total to $\sim$607K. To further mitigate thespherical distortions, we present SphereViT, which explicitly leveragesspherical coordinates to enforce the spherical geometric consistency inpanoramic image features, yielding improved performance. A comprehensivebenchmark on multiple datasets clearly demonstrates DA$^{2}$'s SoTAperformance, with an average 38% improvement on AbsRel over the strongestzero-shot baseline. Surprisingly, DA$^{2}$ even outperforms prior in-domainmethods, highlighting its superior zero-shot generalization. Moreover, as anend-to-end solution, DA$^{2}$ exhibits much higher efficiency over fusion-basedapproaches. Both the code and the curated panoramic data will be released.Project page: https://depth-any-in-any-dir.github.io/.</description><author>Haodong Li, Wangguangdong Zheng, Jing He, Yuhao Liu, Xin Lin, Xin Yang, Ying-Cong Chen, Chunchao Guo</author><pubDate>Tue, 30 Sep 2025 17:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26618v1</guid></item><item><title>Hy-Facial: Hybrid Feature Extraction by Dimensionality Reduction Methods for Enhanced Facial Expression Classification</title><link>http://arxiv.org/abs/2509.26614v1</link><description>Facial expression classification remains a challenging task due to the highdimensionality and inherent complexity of facial image data. This paperpresents Hy-Facial, a hybrid feature extraction framework that integrates bothdeep learning and traditional image processing techniques, complemented by asystematic investigation of dimensionality reduction strategies. The proposedmethod fuses deep features extracted from the Visual Geometry Group 19-layernetwork (VGG19) with handcrafted local descriptors and the scale-invariantfeature transform (SIFT) and Oriented FAST and Rotated BRIEF (ORB) algorithms,to obtain rich and diverse image representations. To mitigate featureredundancy and reduce computational complexity, we conduct a comprehensiveevaluation of dimensionality reduction techniques and feature extraction. Amongthese, UMAP is identified as the most effective, preserving both local andglobal structures of the high-dimensional feature space. The Hy-Facial pipelineintegrated VGG19, SIFT, and ORB for feature extraction, followed by K-meansclustering and UMAP for dimensionality reduction, resulting in a classificationaccuracy of 83. 3\% in the facial expression recognition (FER) dataset. Thesefindings underscore the pivotal role of dimensionality reduction not only as apre-processing step but as an essential component in improving feature qualityand overall classification performance.</description><author>Xinjin Li, Yu Ma, Kaisen Ye, Jinghan Cao, Minghao Zhou, Yeyang Zhou</author><pubDate>Tue, 30 Sep 2025 17:53:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26614v1</guid></item><item><title>Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models</title><link>http://arxiv.org/abs/2505.15489v3</link><description>The impact of misinformation arises not only from factual inaccuracies butalso from the misleading narratives that creators deliberately embed.Interpreting such creator intent is therefore essential for multimodalmisinformation detection (MMD) and effective information governance. To thisend, we introduce DeceptionDecoded, a large-scale benchmark of 12,000image-caption pairs grounded in trustworthy reference articles, created usingan intent-guided simulation framework that models both the desired influenceand the execution plan of news creators. The dataset captures both misleadingand non-misleading cases, spanning manipulations across visual and textualmodalities, and supports three intent-centric tasks: (1) misleading intentdetection, (2) misleading source attribution, and (3) creator desire inference.We evaluate 14 state-of-the-art vision-language models (VLMs) and find thatthey struggle with intent reasoning, often relying on shallow cues such assurface-level alignment, stylistic polish, or heuristic authenticity signals.These results highlight the limitations of current VLMs and positionDeceptionDecoded as a foundation for developing intent-aware models that gobeyond shallow cues in MMD.</description><author>Jiaying Wu, Fanxiao Li, Zihang Fu, Min-Yen Kan, Bryan Hooi</author><pubDate>Tue, 30 Sep 2025 17:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15489v3</guid></item><item><title>Winning Gold at IMO 2025 with a Model-Agnostic Verification-and-Refinement Pipeline</title><link>http://arxiv.org/abs/2507.15855v4</link><description>The International Mathematical Olympiad (IMO) is widely regarded as the worldchampionship of high-school mathematics. IMO problems are renowned for theirdifficulty and novelty, demanding deep insight, creativity, and rigor. Althoughlarge language models perform well on many mathematical benchmarks, they oftenstruggle with Olympiad-level problems. Using carefully designed prompts, weconstruct a model-agnostic, verification-and-refinement pipeline. Wedemonstrate its effectiveness on the recent IMO 2025, avoiding datacontamination for models released before the competition. Equipped with any ofthe three leading models -- Gemini 2.5 Pro, Grok-4, or GPT-5 -- our pipelinecorrectly solved 5 out of the 6 problems ($\approx$85.7% accuracy). This is insharp contrast to their baseline accuracies: 31.6% (Gemini 2.5 Pro), 21.4%(Grok-4), and 38.1% (GPT-5), obtained by selecting the best of 32 candidatesolutions. The substantial improvement underscores that the path to advanced AIreasoning requires not only developing more powerful base models but alsodesigning effective methodologies to harness their full potential for complextasks.</description><author>Yichen Huang, Lin F. Yang</author><pubDate>Tue, 30 Sep 2025 17:53:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15855v4</guid></item><item><title>Uncertainty Quantification for Regression using Proper Scoring Rules</title><link>http://arxiv.org/abs/2509.26610v1</link><description>Quantifying uncertainty of machine learning model predictions is essentialfor reliable decision-making, especially in safety-critical applications.Recently, uncertainty quantification (UQ) theory has advanced significantly,building on a firm basis of learning with proper scoring rules. However, theseadvances were focused on classification, while extending these ideas toregression remains challenging. In this work, we introduce a unified UQframework for regression based on proper scoring rules, such as CRPS,logarithmic, squared error, and quadratic scores. We derive closed-formexpressions for the resulting uncertainty measures under practical parametricassumptions and show how to estimate them using ensembles of models. Inparticular, the derived uncertainty measures naturally decompose into aleatoricand epistemic components. The framework recovers popular regression UQ measuresbased on predictive variance and differential entropy. Our broad evaluation onsynthetic and real-world regression datasets provides guidance for selectingreliable UQ measures.</description><author>Alexander Fishkov, Kajetan Schweighofer, Mykyta Ielanskyi, Nikita Kotelevskii, Mohsen Guizani, Maxim Panov</author><pubDate>Tue, 30 Sep 2025 17:52:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26610v1</guid></item><item><title>Fine-tuning Behavioral Cloning Policies with Preference-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2509.26605v1</link><description>Deploying reinforcement learning (RL) in robotics, industry, and health careis blocked by two obstacles: the difficulty of specifying accurate rewards andthe risk of unsafe, data-hungry exploration. We address this by proposing atwo-stage framework that first learns a safe initial policy from a reward-freedataset of expert demonstrations, then fine-tunes it online usingpreference-based human feedback. We provide the first principled analysis ofthis offline-to-online approach and introduce BRIDGE, a unified algorithm thatintegrates both signals via an uncertainty-weighted objective. We derive regretbounds that shrink with the number of offline demonstrations, explicitlyconnecting the quantity of offline data to online sample efficiency. Wevalidate BRIDGE in discrete and continuous control MuJoCo environments, showingit achieves lower regret than both standalone behavioral cloning and onlinepreference-based RL. Our work establishes a theoretical foundation fordesigning more sample-efficient interactive agents.</description><author>Maël Macuglia, Paul Friedrich, Giorgia Ramponi</author><pubDate>Tue, 30 Sep 2025 17:50:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26605v1</guid></item><item><title>Video Object Segmentation-Aware Audio Generation</title><link>http://arxiv.org/abs/2509.26604v1</link><description>Existing multimodal audio generation models often lack precise user control,which limits their applicability in professional Foley workflows. Inparticular, these models focus on the entire video and do not provide precisemethods for prioritizing a specific object within a scene, generatingunnecessary background sounds, or focusing on the wrong objects. To addressthis gap, we introduce the novel task of video object segmentation-aware audiogeneration, which explicitly conditions sound synthesis on object-levelsegmentation maps. We present SAGANet, a new multimodal generative model thatenables controllable audio generation by leveraging visual segmentation masksalong with video and textual cues. Our model provides users with fine-grainedand visually localized control over audio generation. To support this task andfurther research on segmentation-aware Foley, we propose Segmented Music Solos,a benchmark dataset of musical instrument performance videos with segmentationinformation. Our method demonstrates substantial improvements over currentstate-of-the-art methods and sets a new standard for controllable,high-fidelity Foley synthesis. Code, samples, and Segmented Music Solos areavailable at https://saganet.notion.site</description><author>Ilpo Viertola, Vladimir Iashin, Esa Rahtu</author><pubDate>Tue, 30 Sep 2025 17:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26604v1</guid></item><item><title>DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively</title><link>http://arxiv.org/abs/2509.26603v1</link><description>While previous AI Scientist systems can generate novel findings, they oftenlack the focus to produce scientifically valuable contributions that addresspressing human-defined challenges. We introduce DeepScientist, a systemdesigned to overcome this by conducting goal-oriented, fully autonomousscientific discovery over month-long timelines. It formalizes discovery as aBayesian Optimization problem, operationalized through a hierarchicalevaluation process consisting of "hypothesize, verify, and analyze". Leveraginga cumulative Findings Memory, this loop intelligently balances the explorationof novel hypotheses with exploitation, selectively promoting the most promisingfindings to higher-fidelity levels of validation. Consuming over 20,000 GPUhours, the system generated about 5,000 unique scientific ideas andexperimentally validated approximately 1100 of them, ultimately surpassinghuman-designed state-of-the-art (SOTA) methods on three frontier AI tasks by183.7\%, 1.9\%, and 7.9\%. This work provides the first large-scale evidence ofan AI achieving discoveries that progressively surpass human SOTA on scientifictasks, producing valuable findings that genuinely push the frontier ofscientific discovery. To facilitate further research into this process, we willopen-source all experimental logs and system code athttps://github.com/ResearAI/DeepScientist/.</description><author>Yixuan Weng, Minjun Zhu, Qiujie Xie, Qiyao Sun, Zhen Lin, Sifan Liu, Yue Zhang</author><pubDate>Tue, 30 Sep 2025 17:49:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26603v1</guid></item><item><title>MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages</title><link>http://arxiv.org/abs/2509.26601v1</link><description>Ensuring native-like quality of large language model (LLM) responses acrossmany languages is challenging. To address this, we introduce MENLO, a frameworkthat operationalizes the evaluation of native-like response quality based onaudience design-inspired mechanisms. Using MENLO, we create a dataset of 6,423human-annotated prompt-response preference pairs covering four qualitydimensions with high inter-annotator agreement in 47 language varieties. Ourevaluation reveals that zero-shot LLM judges benefit significantly frompairwise evaluation and our structured annotation rubrics, yet they stillunderperform human annotators on our dataset. We demonstrate substantialimprovements through fine-tuning with reinforcement learning, reward shaping,and multi-task learning approaches. Additionally, we show that RL-trainedjudges can serve as generative reward models to enhance LLMs' multilingualproficiency, though discrepancies with human judgment remain. Our findingssuggest promising directions for scalable multilingual evaluation andpreference alignment. We release our dataset and evaluation framework tosupport further research in multilingual LLM evaluation.</description><author>Chenxi Whitehouse, Sebastian Ruder, Tony Lin, Oksana Kurylo, Haruka Takagi, Janice Lam, Nicolò Busetto, Denise Diaz</author><pubDate>Tue, 30 Sep 2025 17:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26601v1</guid></item><item><title>Deconstructing Self-Bias in LLM-generated Translation Benchmarks</title><link>http://arxiv.org/abs/2509.26600v1</link><description>As large language models (LLMs) begin to saturate existing benchmarks,automated benchmark creation using LLMs (LLM as a benchmark) has emerged as ascalable alternative to slow and costly human curation. While these generatedtest sets have to potential to cheaply rank models, we demonstrate a criticalflaw. LLM generated benchmarks systematically favor the model that created thebenchmark, they exhibit self bias on low resource languages to Englishtranslation tasks. We show three key findings on automatic benchmarking of LLMsfor translation: First, this bias originates from two sources: the generatedtest data (LLM as a testset) and the evaluation method (LLM as an evaluator),with their combination amplifying the effect. Second, self bias in LLM as abenchmark is heavily influenced by the model's generation capabilities in thesource language. For instance, we observe more pronounced bias in into Englishtranslation, where the model's generation system is developed, than in out ofEnglish translation tasks. Third, we observe that low diversity in source textis one attribution to self bias. Our results suggest that improving thediversity of these generated source texts can mitigate some of the observedself bias.</description><author>Wenda Xu, Sweta Agrawal, Vilém Zouhar, Markus Freitag, Daniel Deutsch</author><pubDate>Tue, 30 Sep 2025 17:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26600v1</guid></item><item><title>DiffCamera: Arbitrary Refocusing on Images</title><link>http://arxiv.org/abs/2509.26599v1</link><description>The depth-of-field (DoF) effect, which introduces aesthetically pleasingblur, enhances photographic quality but is fixed and difficult to modify oncethe image has been created. This becomes problematic when the applied blur isundesirable~(e.g., the subject is out of focus). To address this, we proposeDiffCamera, a model that enables flexible refocusing of a created imageconditioned on an arbitrary new focus point and a blur level. Specifically, wedesign a diffusion transformer framework for refocusing learning. However, thetraining requires pairs of data with different focus planes and bokeh levels inthe same scene, which are hard to acquire. To overcome this limitation, wedevelop a simulation-based pipeline to generate large-scale image pairs withvarying focus planes and bokeh levels. With the simulated data, we find thattraining with only a vanilla diffusion objective often leads to incorrect DoFbehaviors due to the complexity of the task. This requires a strongerconstraint during training. Inspired by the photographic principle that photosof different focus planes can be linearly blended into a multi-focus image, wepropose a stacking constraint during training to enforce precise DoFmanipulation. This constraint enhances model training by imposing physicallygrounded refocusing behavior that the focusing results should be faithfullyaligned with the scene structure and the camera conditions so that they can becombined into the correct multi-focus image. We also construct a benchmark toevaluate the effectiveness of our refocusing model. Extensive experimentsdemonstrate that DiffCamera supports stable refocusing across a wide range ofscenes, providing unprecedented control over DoF adjustments for photographyand generative AI applications.</description><author>Yiyang Wang, Xi Chen, Xiaogang Xu, Yu Liu, Hengshuang Zhao</author><pubDate>Tue, 30 Sep 2025 17:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26599v1</guid></item><item><title>Are Robust LLM Fingerprints Adversarially Robust?</title><link>http://arxiv.org/abs/2509.26598v1</link><description>Model fingerprinting has emerged as a promising paradigm for claiming modelownership. However, robustness evaluations of these schemes have mostly focusedon benign perturbations such as incremental fine-tuning, model merging, andprompting. Lack of systematic investigations into {\em adversarial robustness}against a malicious model host leaves current systems vulnerable. To bridgethis gap, we first define a concrete, practical threat model against modelfingerprinting. We then take a critical look at existing model fingerprintingschemes to identify their fundamental vulnerabilities. Based on these, wedevelop adaptive adversarial attacks tailored for each vulnerability, anddemonstrate that these can bypass model authentication completely for tenrecently proposed fingerprinting schemes while maintaining high utility of themodel for the end users. Our work encourages fingerprint designers to adoptadversarial robustness by design. We end with recommendations for futurefingerprinting methods.</description><author>Anshul Nasery, Edoardo Contente, Alkin Kaz, Pramod Viswanath, Sewoong Oh</author><pubDate>Tue, 30 Sep 2025 17:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26598v1</guid></item><item><title>Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces</title><link>http://arxiv.org/abs/2509.26594v1</link><description>Recent text-only models demonstrate remarkable mathematical reasoningcapabilities. Extending these to visual domains requires vision-language modelsto translate images into text descriptions. However, current models, trained toproduce captions for human readers, often omit the precise details thatreasoning systems require. This creates an interface mismatch: reasoners oftenfail not due to reasoning limitations but because they lack access to criticalvisual information. We propose Adaptive-Clarification Reinforcement Learning(AC-RL), which teaches vision models what information reasoners need throughinteraction. Our key insight is that clarification requests during trainingreveal information gaps; by penalizing success that requires clarification, wecreate pressure for comprehensive initial captions that enable the reasoner tosolve the problem in a single pass. AC-RL improves average accuracy by 4.4points over pretrained baselines across seven visual mathematical reasoningbenchmarks, and analysis shows it would cut clarification requests by up to 39%if those were allowed. By treating clarification as a form of implicitsupervision, AC-RL demonstrates that vision-language interfaces can beeffectively learned through interaction alone, without requiring explicitannotations.</description><author>John Gkountouras, Ivan Titov</author><pubDate>Tue, 30 Sep 2025 17:46:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26594v1</guid></item><item><title>Generating Difficult-to-Translate Texts</title><link>http://arxiv.org/abs/2509.26592v1</link><description>Machine translation benchmarks sourced from the real world are quicklyobsoleted, due to most examples being easy for state-of-the-art translationmodels. This limits the benchmark's ability to distinguish which model isbetter or to reveal models' weaknesses. Current methods for creating difficulttest cases, such as subsampling or from-scratch synthesis, either fall short ofidentifying difficult examples or suffer from a lack of diversity andnaturalness. Inspired by the iterative process of human experts probing formodel failures, we propose MT-breaker, a method where a large language modeliteratively refines a source text to increase its translation difficulty. TheLLM iteratively queries a target machine translation model to guide itsgeneration of difficult examples. Our approach generates examples that are morechallenging for the target MT model while preserving the diversity of naturaltexts. While the examples are tailored to a particular machine translationmodel during the generation, the difficulty also transfers to other models andlanguages.</description><author>Vilém Zouhar, Wenda Xu, Parker Riley, Juraj Juraska, Mara Finkelstein, Markus Freitag, Dan Deutsch</author><pubDate>Tue, 30 Sep 2025 17:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26592v1</guid></item><item><title>Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset</title><link>http://arxiv.org/abs/2509.20715v2</link><description>Intention recognition has traditionally focused on individual intentions,overlooking the complexities of collective intentions in group settings. Toaddress this limitation, we introduce the concept of group intention, whichrepresents shared goals emerging through the actions of multiple individuals,and Group Intention Forecasting (GIF), a novel task that forecasts when groupintentions will occur by analyzing individual actions and interactions beforethe collective goal becomes apparent. To investigate GIF in a specificscenario, we propose SHOT, the first large-scale dataset for GIF, consisting of1,979 basketball video clips captured from 5 camera views and annotated with 6types of individual attributes. SHOT is designed with 3 key characteristics:multi-individual information, multi-view adaptability, and multi-levelintention, making it well-suited for studying emerging group intentions.Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework thatextracts fine-grained individual features and models evolving group dynamics toforecast intention emergence. Experimental results confirm the effectiveness ofSHOT and GIFT, establishing a strong foundation for future research in groupintention forecasting. The dataset is available athttps://xinyi-hu.github.io/SHOT_DATASET.</description><author>Ruixu Zhang, Yuran Wang, Xinyi Hu, Chaoyu Mai, Wenxuan Liu, Danni Xu, Xian Zhong, Zheng Wang</author><pubDate>Tue, 30 Sep 2025 17:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20715v2</guid></item><item><title>MaskSQL: Safeguarding Privacy for LLM-Based Text-to-SQL via Abstraction</title><link>http://arxiv.org/abs/2509.23459v2</link><description>Large language models (LLMs) have shown promising performance on tasks thatrequire reasoning, such as text-to-SQL, code generation, and debugging.However, regulatory frameworks with strict privacy requirements constrain theirintegration into sensitive systems. State-of-the-art LLMs are also proprietary,costly, and resource-intensive, making local deployment impractical.Consequently, utilizing such LLMs often requires sharing data with third-partyproviders, raising privacy concerns and risking noncompliance with regulations.Although fine-tuned small language models (SLMs) can outperform LLMs on certaintasks and be deployed locally to mitigate privacy concerns, they underperformon more complex tasks such as text-to-SQL translation. In this work, weintroduce MaskSQL, a text-to-SQL framework that utilizes abstraction as aprivacy protection mechanism to mask sensitive information in LLM prompts.Unlike redaction, which removes content entirely, or generalization, whichbroadens tokens, abstraction retains essential information while discardingunnecessary details, striking an effective privacy-utility balance for thetext-to-SQL task. Moreover, by providing mechanisms to control theprivacy-utility tradeoff, MaskSQL facilitates adoption across a broader rangeof use cases. Our experimental results show that MaskSQL outperforms leadingSLM-based text-to-SQL models and achieves performance approachingstate-of-the-art LLM-based models, while preserving privacy.</description><author>Sepideh Abedini, Shubhankar Mohapatra, D. B. Emerson, Masoumeh Shafieinejad, Jesse C. Cresswell, Xi He</author><pubDate>Tue, 30 Sep 2025 17:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23459v2</guid></item><item><title>Autoproof: Automated Segmentation Proofreading for Connectomics</title><link>http://arxiv.org/abs/2509.26585v1</link><description>Producing connectomes from electron microscopy (EM) images has historicallyrequired a great deal of human proofreading effort. This manual annotation costis the current bottleneck in scaling EM connectomics, for example, in makinglarger connectome reconstructions feasible, or in enabling comparativeconnectomics where multiple related reconstructions are produced. In this work,we propose using the available ground-truth data generated by this manualannotation effort to learn a machine learning model to automate or optimizeparts of the required proofreading workflows. We validate our approach on arecent complete reconstruction of the \emph{Drosophila} male central nervoussystem. We first show our method would allow for obtaining 90\% of the value ofa guided proofreading workflow while reducing required cost by 80\%. We thendemonstrate a second application for automatically merging many segmentationfragments to proofread neurons. Our system is able to automatically attach 200thousand fragments, equivalent to four proofreader years of manual work, andincreasing the connectivity completion rate of the connectome by 1.3\% points.</description><author>Gary B Huang, William M Katz, Stuart Berg, Louis Scheffer</author><pubDate>Tue, 30 Sep 2025 17:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26585v1</guid></item><item><title>Provable Scaling Laws of Feature Emergence from Learning Dynamics of Grokking</title><link>http://arxiv.org/abs/2509.21519v3</link><description>While the phenomenon of grokking, i.e., delayed generalization, has beenstudied extensively, it remains an open problem whether there is a mathematicalframework that characterizes what kind of features will emerge, how and inwhich conditions it happens, and is closely related to the gradient dynamics ofthe training, for complex structured inputs. We propose a novel framework,named $\mathbf{Li_2}$, that captures three key stages for the grokking behaviorof 2-layer nonlinear networks: (I) \underline{\textbf{L}}azy learning, (II)\underline{\textbf{i}}ndependent feature learning and (III)\underline{\textbf{i}}nteractive feature learning. At the lazy learning stage,top layer overfits to random hidden representation and the model appears tomemorize. Thanks to lazy learning and weight decay, the \emph{backpropagatedgradient} $G_F$ from the top layer now carries information about the targetlabel, with a specific structure that enables each hidden node to learn theirrepresentation \emph{independently}. Interestingly, the independent dynamicsfollows exactly the \emph{gradient ascent} of an energy function $E$, and itslocal maxima are precisely the emerging features. We study whether theselocal-optima induced features are generalizable, their representation power,and how they change on sample size, in group arithmetic tasks. When hiddennodes start to interact in the later stage of learning, we provably show how$G_F$ changes to focus on missing features that need to be learned. Our studysheds lights on roles played by key hyperparameters such as weight decay,learning rate and sample sizes in grokking, leads to provable scaling laws offeature emergence, memorization and generalization, and reveals the underlyingcause why recent optimizers such as Muon can be effective, from the firstprinciples of gradient dynamics. Our analysis can be extended to multi-layerarchitectures.</description><author>Yuandong Tian</author><pubDate>Tue, 30 Sep 2025 17:43:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21519v3</guid></item><item><title>Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models</title><link>http://arxiv.org/abs/2509.26584v1</link><description>Large Language Models (LLMs) are widely used across multiple domains butcontinue to raise concerns regarding security and fairness. Beyond known attackvectors such as data poisoning and prompt injection, LLMs are also vulnerableto fairness bugs. These refer to unintended behaviors influenced by sensitivedemographic cues (e.g., race or sexual orientation) that should not affectoutcomes. Another key issue is hallucination, where models generate plausibleyet false information. Retrieval-Augmented Generation (RAG) has emerged as astrategy to mitigate hallucinations by combining external retrieval with textgeneration. However, its adoption raises new fairness concerns, as theretrieved content itself may surface or amplify bias. This study conductsfairness testing through metamorphic testing (MT), introducing controlleddemographic perturbations in prompts to assess fairness in sentiment analysisperformed by three Small Language Models (SLMs) hosted on HuggingFace(Llama-3.2-3B-Instruct, Mistral-7B-Instruct-v0.3, and Llama-3.1-Nemotron-8B),each integrated into a RAG pipeline. Results show that minor demographicvariations can break up to one third of metamorphic relations (MRs). A detailedanalysis of these failures reveals a consistent bias hierarchy, withperturbations involving racial cues being the predominant cause of theviolations. In addition to offering a comparative evaluation, this workreinforces that the retrieval component in RAG must be carefully curated toprevent bias amplification. The findings serve as a practical alert fordevelopers, testers and small organizations aiming to adopt accessible SLMswithout compromising fairness or reliability.</description><author>Matheus Vinicius da Silva de Oliveira, Jonathan de Andrade Silva, Awdren de Lima Fontao</author><pubDate>Tue, 30 Sep 2025 17:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26584v1</guid></item><item><title>EVO-LRP: Evolutionary Optimization of LRP for Interpretable Model Explanations</title><link>http://arxiv.org/abs/2509.23585v2</link><description>Explainable AI (XAI) methods help identify which image regions influence amodel's prediction, but often face a trade-off between detail andinterpretability. Layer-wise Relevance Propagation (LRP) offers a model-awarealternative. However, LRP implementations commonly rely on heuristic rule setsthat are not optimized for clarity or alignment with model behavior. Weintroduce EVO-LRP, a method that applies Covariance Matrix Adaptation EvolutionStrategy (CMA-ES) to tune LRP hyperparameters based on quantitativeinterpretability metrics, such as faithfulness or sparseness. EVO-LRPoutperforms traditional XAI approaches in both interpretability metricperformance and visual coherence, with strong sensitivity to class-specificfeatures. These findings demonstrate that attribution quality can besystematically improved through principled, task-specific optimization.</description><author>Emerald Zhang, Julian Weaver, Samantha R Santacruz, Edward Castillo</author><pubDate>Tue, 30 Sep 2025 17:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23585v2</guid></item><item><title>Source Separation for A Cappella Music</title><link>http://arxiv.org/abs/2509.26580v1</link><description>In this work, we study the task of multi-singer separation in a cappellamusic, where the number of active singers varies across mixtures. To addressthis, we use a power set-based data augmentation strategy that expands limitedmulti-singer datasets into exponentially more training samples. To separatesingers, we introduce SepACap, an adaptation of SepReformer, a state-of-the-artspeaker separation model architecture. We adapt the model with periodicactivations and a composite loss function that remains effective when stems aresilent, enabling robust detection and separation. Experiments on the JaCappelladataset demonstrate that our approach achieves state-of-the-art performance inboth full-ensemble and subset singer separation scenarios, outperformingspectrogram-based baselines while generalizing to realistic mixtures withvarying numbers of singers.</description><author>Luca A. Lanzendörfer, Constantin Pinkl, Florian Grötschla</author><pubDate>Tue, 30 Sep 2025 17:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26580v1</guid></item><item><title>ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2506.05480v3</link><description>We introduce ODE-GS, a novel approach that integrates 3D Gaussian Splattingwith latent neural ordinary differential equations (ODEs) to enable futureextrapolation of dynamic 3D scenes. Unlike existing dynamic scenereconstruction methods, which rely on time-conditioned deformation networks andare limited to interpolation within a fixed time window, ODE-GS eliminatestimestamp dependency by modeling Gaussian parameter trajectories ascontinuous-time latent dynamics. Our approach first learns an interpolationmodel to generate accurate Gaussian trajectories within the observed window,then trains a Transformer encoder to aggregate past trajectories into a latentstate evolved via a neural ODE. Finally, numerical integration produces smooth,physically plausible future Gaussian trajectories, enabling rendering atarbitrary future timestamps. On the D-NeRF, NVFi, and HyperNeRF benchmarks,ODE-GS achieves state-of-the-art extrapolation performance, improving metricsby 19.8% compared to leading baselines, demonstrating its ability to accuratelyrepresent and predict 3D scene dynamics.</description><author>Daniel Wang, Patrick Rim, Tian Tian, Dong Lao, Alex Wong, Ganesh Sundaramoorthi</author><pubDate>Tue, 30 Sep 2025 17:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05480v3</guid></item><item><title>Linking Process to Outcome: Conditional Reward Modeling for LLM Reasoning</title><link>http://arxiv.org/abs/2509.26578v1</link><description>Process Reward Models (PRMs) have emerged as a promising approach to enhancethe reasoning capabilities of large language models (LLMs) by guiding theirstep-by-step reasoning toward a final answer. However, existing PRMs eithertreat each reasoning step in isolation, failing to capture inter-stepdependencies, or struggle to align process rewards with the final outcome.Consequently, the reward signal fails to respect temporal causality insequential reasoning and faces ambiguous credit assignment. These limitationsmake downstream models vulnerable to reward hacking and lead to suboptimalperformance. In this work, we propose Conditional Reward Modeling (CRM) thatframes LLM reasoning as a temporal process leading to a correct answer. Thereward of each reasoning step is not only conditioned on the preceding stepsbut also explicitly linked to the final outcome of the reasoning trajectory. Byenforcing conditional probability rules, our design captures the causalrelationships among reasoning steps, with the link to the outcome allowingprecise attribution of each intermediate step, thereby resolving creditassignment ambiguity. Further, through this consistent probabilistic modeling,the rewards produced by CRM enable more reliable cross-sample comparison.Experiments across Best-of-N sampling, beam search and reinforcement learningdemonstrate that CRM consistently outperforms existing reward models, offeringa principled framework for enhancing LLM reasoning. In particular, CRM is morerobust to reward hacking and delivers stable downstream improvements withoutrelying on verifiable rewards derived from ground truth.</description><author>Zheng Zhang, Ziwei Shan, Kaitao Song, Yexin Li, Kan Ren</author><pubDate>Tue, 30 Sep 2025 17:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26578v1</guid></item><item><title>Importance of localized dilatation and distensibility in identifying determinants of thoracic aortic aneurysm with neural operators</title><link>http://arxiv.org/abs/2509.26576v1</link><description>Thoracic aortic aneurysms (TAAs) arise from diverse mechanical andmechanobiological disruptions to the aortic wall that increase the risk ofdissection or rupture. Evidence links TAA development to dysfunctions in theaortic mechanotransduction axis, including loss of elastic fiber integrity andcell-matrix connections. Because distinct insults create different mechanicalvulnerabilities, there is a critical need to identify interacting factors thatdrive progression. Here, we use a finite element framework to generatesynthetic TAAs from hundreds of heterogeneous insults spanning varying degreesof elastic fiber damage and impaired mechanosensing. From these simulations, weconstruct spatial maps of localized dilatation and distensibility to trainneural networks that predict the initiating combined insult. We compare severalarchitectures (Deep Operator Networks, UNets, and Laplace Neural Operators) andmultiple input data formats to define a standard for future subject-specificmodeling. We also quantify predictive performance when networks are trainedusing only geometric data (dilatation) versus both geometric and mechanicaldata (dilatation plus distensibility). Across all networks, prediction errorsare significantly higher when trained on dilatation alone, underscoring theadded value of distensibility information. Among the tested models, UNetconsistently provides the highest accuracy across all data formats. Thesefindings highlight the importance of acquiring full-field measurements of bothdilatation and distensibility in TAA assessment to reveal the mechanobiologicaldrivers of disease and support the development of personalized treatmentstrategies.</description><author>David S. Li, Somdatta Goswami, Qianying Cao, Vivek Oommen, Roland Assi, Jay D. Humphrey, George E. Karniadakis</author><pubDate>Tue, 30 Sep 2025 17:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26576v1</guid></item><item><title>Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark</title><link>http://arxiv.org/abs/2509.26574v1</link><description>While large language models (LLMs) with reasoning capabilities areprogressing rapidly on high-school math competitions and coding, can theyreason effectively through complex, open-ended challenges found in frontierphysics research? And crucially, what kinds of reasoning tasks do physicistswant LLMs to assist with? To address these questions, we present the CritPt(Complex Research using Integrated Thinking - Physics Test, pronounced"critical point"), the first benchmark designed to test LLMs on unpublished,research-level reasoning tasks that broadly covers modern physics researchareas, including condensed matter, quantum physics, atomic, molecular &amp; opticalphysics, astrophysics, high energy physics, mathematical physics, statisticalphysics, nuclear physics, nonlinear dynamics, fluid dynamics and biophysics.CritPt consists of 71 composite research challenges designed to simulatefull-scale research projects at the entry level, which are also decomposed to190 simpler checkpoint tasks for more fine-grained insights. All problems arenewly created by 50+ active physics researchers based on their own research.Every problem is hand-curated to admit a guess-resistant and machine-verifiableanswer and is evaluated by an automated grading pipeline heavily customized foradvanced physics-specific output formats. We find that while currentstate-of-the-art LLMs show early promise on isolated checkpoints, they remainfar from being able to reliably solve full research-scale challenges: the bestaverage accuracy among base models is only 4.0% , achieved by GPT-5 (high),moderately rising to around 10% when equipped with coding tools. Through therealistic yet standardized evaluation offered by CritPt, we highlight a largedisconnect between current model capabilities and realistic physics researchdemands, offering a foundation to guide the development of scientificallygrounded AI tools.</description><author>Minhui Zhu, Minyang Tian, Xiaocheng Yang, Tianci Zhou, Penghao Zhu, Eli Chertkov, Shengyan Liu, Yufeng Du, Lifan Yuan, Ziming Ji, Indranil Das, Junyi Cao, Yufeng Du, Jinchen He, Yifan Su, Jiabin Yu, Yikun Jiang, Yujie Zhang, Chang Liu, Ze-Min Huang, Weizhen Jia, Xinan Chen, Peixue Wu, Yunkai Wang, Juntai Zhou, Yong Zhao, Farshid Jafarpour, Jessie Shelton, Aaron Young, John Bartolotta, Wenchao Xu, Yue Sun, Anjun Chu, Victor Colussi, Chris Akers, Nathan Brooks, Wenbo Fu, Christopher Wilson, Jinchao Zhao, Marvin Qi, Anqi Mu, Yubo Yang, Allen Zang, Yang Lyu, Peizhi Mai, Xuefei Guo, Luyu Gao, Ze Yang, Chi Xue, Dmytro Bandak, Yaïr Hein, Yonatan Kahn, Kevin Zhou, John Drew Wilson Jarrod T. Reilly, Di Luo, Daniel Inafuku, Hao Tong, Liang Yang, Ruixing Zhang, Xueying Wang, Ofir Press, Nicolas Chia,</author><pubDate>Tue, 30 Sep 2025 17:34:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26574v1</guid></item><item><title>AI-assisted Advanced Propellant Development for Electric Propulsion</title><link>http://arxiv.org/abs/2509.26567v1</link><description>Artificial Intelligence algorithms are introduced in this work as a tool topredict the performance of new chemical compounds as alternative propellantsfor electric propulsion, focusing on predicting their ionisationcharacteristics and fragmentation patterns. The chemical properties andstructure of the compounds are encoded using a chemical fingerprint, and thetraining datasets are extracted from the NIST WebBook. The AI-predictedionisation energy and minimum appearance energy have a mean relative error of6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relativeerror. In the cases of full mass spectra due to electron ionisation, thepredictions have a cosine similarity of 0.6395 and align with the top 10 mostsimilar mass spectra in 78% of instances within a 30 Da range.</description><author>Angel Pan Du, Miguel Arana-Catania, Enric Grustan Gutiérrez</author><pubDate>Tue, 30 Sep 2025 17:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26567v1</guid></item><item><title>Parametric Neural Amp Modeling with Active Learning</title><link>http://arxiv.org/abs/2509.26564v1</link><description>We introduce Panama, an active learning framework to train parametric guitaramp models end-to-end using a combination of an LSTM model and a WaveNet-likearchitecture. With \model, one can create a virtual amp by recording samplesthat are determined through an ensemble-based active learning strategy tominimize the amount of datapoints needed (i.e., amp knob settings). Ourstrategy uses gradient-based optimization to maximize the disagreement amongensemble models, in order to identify the most informative datapoints. MUSHRAlistening tests reveal that, with 75 datapoints, our models are able to matchthe perceptual quality of NAM, the leading open-source non-parametric ampmodeler.</description><author>Florian Grötschla, Longxiang Jiao, Luca A. Lanzendörfer, Roger Wattenhofer</author><pubDate>Tue, 30 Sep 2025 17:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26564v1</guid></item><item><title>DeepProv: Behavioral Characterization and Repair of Neural Networks via Inference Provenance Graph Analysis</title><link>http://arxiv.org/abs/2509.26562v1</link><description>Deep neural networks (DNNs) are increasingly being deployed in high-stakesapplications, from self-driving cars to biometric authentication. However,their unpredictable and unreliable behaviors in real-world settings require newapproaches to characterize and ensure their reliability. This paper introduces DeepProv, a novel and customizable system designed tocapture and characterize the runtime behavior of DNNs during inference by usingtheir underlying graph structure. Inspired by system audit provenance graphs,DeepProv models the computational information flow of a DNN's inference processthrough Inference Provenance Graphs (IPGs). These graphs provide a detailedstructural representation of the behavior of DNN, allowing both empirical andstructural analysis. DeepProv uses these insights to systematically repair DNNsfor specific objectives, such as improving robustness, privacy, or fairness. We instantiate DeepProv with adversarial robustness as the goal of modelrepair and conduct extensive case studies to evaluate its effectiveness. Ourresults demonstrate its effectiveness and scalability across diverseclassification tasks, attack scenarios, and model complexities. DeepProvautomatically identifies repair actions at the node and edge-level within IPGs,significantly enhancing the robustness of the model. In particular, applyingDeepProv repair strategies to just a single layer of a DNN yields an average55% improvement in adversarial accuracy. Moreover, DeepProv complementsexisting defenses, achieving substantial gains in adversarial robustness.Beyond robustness, we demonstrate the broader potential of DeepProv as anadaptable system to characterize DNN behavior in other critical areas, such asprivacy auditing and fairness analysis.</description><author>Firas Ben Hmida, Abderrahmen Amich, Ata Kaboudi, Birhanu Eshete</author><pubDate>Tue, 30 Sep 2025 17:29:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26562v1</guid></item><item><title>Estimating Dimensionality of Neural Representations from Finite Samples</title><link>http://arxiv.org/abs/2509.26560v1</link><description>The global dimensionality of a neural representation manifold provides richinsight into the computational process underlying both artificial andbiological neural networks. However, all existing measures of globaldimensionality are sensitive to the number of samples, i.e., the number of rowsand columns of the sample matrix. We show that, in particular, theparticipation ratio of eigenvalues, a popular measure of global dimensionality,is highly biased with small sample sizes, and propose a bias-correctedestimator that is more accurate with finite samples and with noise. Onsynthetic data examples, we demonstrate that our estimator can recover the trueknown dimensionality. We apply our estimator to neural brain recordings,including calcium imaging, electrophysiological recordings, and fMRI data, andto the neural activations in a large language model and show our estimator isinvariant to the sample size. Finally, our estimators can additionally be usedto measure the local dimensionalities of curved neural manifolds by weightingthe finite samples appropriately.</description><author>Chanwoo Chun, Abdulkadir Canatar, SueYeon Chung, Daniel Lee</author><pubDate>Tue, 30 Sep 2025 17:26:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26560v1</guid></item><item><title>VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use</title><link>http://arxiv.org/abs/2509.01055v2</link><description>Reinforcement Learning with Verifiable Rewards (RLVR) has demonstratedsuccess in enhancing LLM reasoning capabilities, but remains limited tosingle-turn interactions without tool integration. While recent AgenticReinforcement Learning with Tool use (ARLT) approaches have emerged to addressmulti-turn tool interactions, existing works develop task-specific codebasesthat suffer from fragmentation, synchronous execution bottlenecks, and limitedextensibility across domains. These inefficiencies hinder broader communityadoption and algorithmic innovation. We introduce VerlTool, a unified andmodular framework that addresses these limitations through systematic designprinciples. VerlTool provides four key contributions: (1) upstream alignmentwith VeRL ensuring compatibility and simplified maintenance, (2) unified toolmanagement via standardized APIs supporting diverse modalities including codeexecution, search, SQL databases, and vision processing, (3) asynchronousrollout execution achieving near 2$\times$ speedup by eliminatingsynchronization bottlenecks, and (4) comprehensive evaluation demonstratingcompetitive performance across 6 ARLT domains. Our framework formalizes ARLT asmulti-turn trajectories with multi-modal observation tokens (text/image/video),extending beyond single-turn RLVR paradigms. We train and evaluate models onmathematical reasoning, knowledge QA, SQL generation, visual reasoning, websearch, and software engineering tasks, achieving results comparable tospecialized systems while providing unified training infrastructure. Themodular plugin architecture enables rapid tool integration requiring onlylightweight Python definitions, significantly reducing development overhead andproviding a scalable foundation for tool-augmented RL research. Our code isopen-sourced at https://github.com/TIGER-AI-Lab/verl-tool.</description><author>Dongfu Jiang, Yi Lu, Zhuofeng Li, Zhiheng Lyu, Ping Nie, Haozhe Wang, Alex Su, Hui Chen, Kai Zou, Chao Du, Tianyu Pang, Wenhu Chen</author><pubDate>Tue, 30 Sep 2025 17:22:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.01055v2</guid></item><item><title>Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation</title><link>http://arxiv.org/abs/2509.26555v1</link><description>Recent advances in video generation have enabled high-fidelity videosynthesis from user provided prompts. However, existing models and benchmarksfail to capture the complexity and requirements of professional videogeneration. Towards that goal, we introduce Stable Cinemetrics, a structuredevaluation framework that formalizes filmmaking controls into fourdisentangled, hierarchical taxonomies: Setup, Event, Lighting, and Camera.Together, these taxonomies define 76 fine-grained control nodes grounded inindustry practices. Using these taxonomies, we construct a benchmark of promptsaligned with professional use cases and develop an automated pipeline forprompt categorization and question generation, enabling independent evaluationof each control dimension. We conduct a large-scale human study spanning 10+models and 20K videos, annotated by a pool of 80+ film professionals. Ouranalysis, both coarse and fine-grained reveal that even the strongest currentmodels exhibit significant gaps, particularly in Events and Camera-relatedcontrols. To enable scalable evaluation, we train an automatic evaluator, avision-language model aligned with expert annotations that outperforms existingzero-shot baselines. SCINE is the first approach to situate professional videogeneration within the landscape of video generative models, introducingtaxonomies centered around cinematic controls and supporting them withstructured evaluation pipelines and detailed analyses to guide future research.</description><author>Agneet Chatterjee, Rahim Entezari, Maksym Zhuravinskyi, Maksim Lapin, Reshinth Adithyan, Amit Raj, Chitta Baral, Yezhou Yang, Varun Jampani</author><pubDate>Tue, 30 Sep 2025 17:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26555v1</guid></item><item><title>AutoJudge: Judge Decoding Without Manual Annotation</title><link>http://arxiv.org/abs/2504.20039v2</link><description>We introduce AutoJudge, a method that accelerates large language model (LLM)inference with task-specific lossy speculative decoding. Instead of matchingthe original model output distribution token-by-token, we identify which of thegenerated tokens affect the downstream quality of the response, relaxing thedistribution match guarantee so that the "unimportant" tokens can be generatedfaster. Our approach relies on a semi-greedy search algorithm to test which ofthe mismatches between target and draft models should be corrected to preservequality and which ones may be skipped. We then train a lightweight classifierbased on existing LLM embeddings to predict, at inference time, whichmismatching tokens can be safely accepted without compromising the final answerquality. We evaluate the effectiveness of AutoJudge with multiple draft/targetmodel pairs on mathematical reasoning and programming benchmarks, achievingsignificant speedups at the cost of a minor accuracy reduction. Notably, onGSM8k with the Llama 3.1 70B target model, our approach achieves up to$\approx2\times$ speedup over speculative decoding at the cost of $\le 1\%$drop in accuracy. When applied to the LiveCodeBench benchmark, AutoJudgeautomatically detects programming-specific important tokens, accepting $\ge 25$tokens per speculation cycle at $2\%$ drop in Pass@1. Our approach requires nohuman annotation and is easy to integrate with modern LLM inference frameworks.</description><author>Roman Garipov, Fedor Velikonivtsev, Ivan Ermakov, Ruslan Svirschevski, Vage Egiazarian, Max Ryabinin</author><pubDate>Tue, 30 Sep 2025 17:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.20039v2</guid></item><item><title>Towards Reliable Benchmarking: A Contamination Free, Controllable Evaluation Framework for Multi-step LLM Function Calling</title><link>http://arxiv.org/abs/2509.26553v1</link><description>As language models gain access to external tools via structured functioncalls, they become increasingly more capable of solving complex, multi-steptasks. However, existing benchmarks for tool-augmented language models (TaLMs)provide insufficient control over factors such as the number of functionsaccessible, task complexity, and input size, and remain vulnerable to datacontamination. We present FuncBenchGen, a unified, contamination-free frameworkthat evaluates TaLMs by generating synthetic multi-step tool-use tasks. The keyidea is to cast tool use as traversal over a hidden function-dependency DAGwhere nodes are function calls and an edge between nodes represents onefunction consuming the output of another. Given a set of external functionschemas, initial variable values, and a target variable, models must composethe correct call sequence to compute the target variable. FuncBenchGen allowsusers to precisely control task difficulty (e.g., graph size, dependency depth,and distractor functions) while avoiding data leakage. We apply ourFuncBenchGen framework to evaluate seven LLMs on tool use tasks of varyingdifficulty. Reasoning-optimized models consistently outperform general-purposemodels with GPT-5 significantly outperforming other models. Performancedeclines sharply as dependency depth increases. Furthermore, connectedirrelevant functions prove especially difficult to handle. We find that strongmodels often make syntactically valid function calls but propagate incorrect orstale argument values across steps, revealing brittle state tracking by LLMs inmulti-turn tool use. Motivated by this observation, we introduce a simplemitigation strategy that explicitly restates prior variable values to the agentat each step. Surprisingly, this lightweight change yields substantial gainsacross models. e.g., yielding a success rate improvement from 62.5% to 81.3%for GPT-5.</description><author>Seiji Maekawa, Jackson Hassell, Pouya Pezeshkpour, Tom Mitchell, Estevam Hruschka</author><pubDate>Tue, 30 Sep 2025 17:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26553v1</guid></item><item><title>Pretrain-Test Task Alignment Governs Generalization in In-Context Learning</title><link>http://arxiv.org/abs/2509.26551v1</link><description>In-context learning (ICL) is a central capability of Transformer models, butthe structures in data that enable its emergence and govern its robustnessremain poorly understood. In this work, we study how the structure ofpretraining tasks governs generalization in ICL. Using a solvable model for ICLof linear regression by linear attention, we derive an exact expression for ICLgeneralization error in high dimensions under arbitrary pretraining-testingtask covariance mismatch. This leads to a new alignment measure that quantifieshow much information about the pretraining task distribution is useful forinference at test time. We show that this measure directly predicts ICLperformance not only in the solvable model but also in nonlinear Transformers.Our analysis further reveals a tradeoff between specialization andgeneralization in ICL: depending on task distribution alignment, increasingpretraining task diversity can either improve or harm test performance.Together, these results identify train-test task alignment as a key determinantof generalization in ICL.</description><author>Mary I. Letey, Jacob A. Zavatone-Veth, Yue M. Lu, Cengiz Pehlevan</author><pubDate>Tue, 30 Sep 2025 17:19:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26551v1</guid></item><item><title>Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework</title><link>http://arxiv.org/abs/2509.26548v1</link><description>Scanning Electron Microscopy (SEM) is indispensable for characterizing themicrostructure of thin films during perovskite solar cell fabrication. Accurateidentification and quantification of lead iodide and perovskite phases arecritical because residual lead iodide strongly influences crystallizationpathways and defect formation, while the morphology of perovskite grainsgoverns carrier transport and device stability. Yet current SEM image analysisis still largely manual, limiting throughput and consistency. Here, we presentan automated deep learning-based framework for SEM image segmentation thatenables precise and efficient identification of lead iodide, perovskite anddefect domains across diverse morphologies. Built upon an improved YOLOv8xarchitecture, our model named PerovSegNet incorporates two novel modules: (i)Adaptive Shuffle Dilated Convolution Block, which enhances multi-scale andfine-grained feature extraction through group convolutions and channel mixing;and (ii) Separable Adaptive Downsampling module, which jointly preservesfine-scale textures and large-scale structures for more robust boundaryrecognition. Trained on an augmented dataset of 10,994 SEM images, PerovSegNetachieves a mean Average Precision of 87.25% with 265.4 Giga Floating PointOperations, outperforming the baseline YOLOv8x-seg by 4.08%, while reducingmodel size and computational load by 24.43% and 25.22%, respectively. Beyondsegmentation, the framework provides quantitative grain-level metrics, such aslead iodide/perovskite area and count, which can serve as reliable indicatorsof crystallization efficiency and microstructural quality. These capabilitiesestablish PerovSegNet as a scalable tool for real-time process monitoring anddata-driven optimization of perovskite thin-film fabrication.The source code isavailable at:https://github.com/wlyyj/PerovSegNet/tree/master.</description><author>Jian Guo Pan, Lin Wang, Xia Cai</author><pubDate>Tue, 30 Sep 2025 17:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26548v1</guid></item><item><title>Scalable Fingerprinting of Large Language Models</title><link>http://arxiv.org/abs/2502.07760v2</link><description>Model fingerprinting has emerged as a powerful tool for model owners toidentify their shared model given API access. However, to lower false discoveryrate, fight fingerprint leakage, and defend against coalitions of model usersattempting to bypass detection, we argue that {\em scalability} is critical,i.e., scaling up the number of fingerprints one can embed into a model. Hence,we pose scalability as a crucial requirement for fingerprinting schemes. Weexperiment with fingerprint design at a scale significantly larger thanpreviously considered, and introduce a new method, dubbed Perinucleus sampling,to generate scalable, persistent, and harmless fingerprints. We demonstratethat this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- twoorders of magnitude more than existing schemes -- without degrading the model'sutility. Our inserted fingerprints persist even after supervised fine-tuning onstandard post-training data. We further address security risks forfingerprinting, and theoretically and empirically show how a scalablefingerprinting scheme like ours can mitigate these risks. Our code is availableat https://github.com/SewoongLab/scalable-fingerprinting-of-llms</description><author>Anshul Nasery, Jonathan Hayase, Creston Brooks, Peiyao Sheng, Himanshu Tyagi, Pramod Viswanath, Sewoong Oh</author><pubDate>Tue, 30 Sep 2025 17:18:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07760v2</guid></item><item><title>Towards Verified Code Reasoning by LLMs</title><link>http://arxiv.org/abs/2509.26546v1</link><description>While LLM-based agents are able to tackle a wide variety of code reasoningquestions, the answers are not always correct. This prevents the agent frombeing useful in situations where high precision is desired: (1) helping asoftware engineer understand a new code base, (2) helping a software engineerduring code review sessions, and (3) ensuring that the code generated by anautomated code generation system meets certain requirements (e.g. fixes a bug,improves readability, implements a feature). As a result of this lack of trustworthiness, the agent's answers need to bemanually verified before they can be trusted. Manually confirming responsesfrom a code reasoning agent requires human effort and can result in slowerdeveloper productivity, which weakens the assistance benefits of the agent. Inthis paper, we describe a method to automatically validate the answers providedby a code reasoning agent by verifying its reasoning steps. At a very highlevel, the method consists of extracting a formal representation of the agent'sresponse and, subsequently, using formal verification and program analysistools to verify the agent's reasoning steps. We applied this approach to a benchmark set of 20 uninitialized variableerrors detected by sanitizers and 20 program equivalence queries. For theuninitialized variable errors, the formal verification step was able tovalidate the agent's reasoning on 13/20 examples, and for the programequivalence queries, the formal verification step successfully caught 6/8incorrect judgments made by the agent.</description><author>Meghana Sistla, Gogul Balakrishnan, Pat Rondon, José Cambronero, Michele Tufano, Satish Chandra</author><pubDate>Tue, 30 Sep 2025 17:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26546v1</guid></item><item><title>Bayesian Influence Functions for Hessian-Free Data Attribution</title><link>http://arxiv.org/abs/2509.26544v1</link><description>Classical influence functions face significant challenges when applied todeep neural networks, primarily due to non-invertible Hessians andhigh-dimensional parameter spaces. We propose the local Bayesian influencefunction (BIF), an extension of classical influence functions that replacesHessian inversion with loss landscape statistics that can be estimated viastochastic-gradient MCMC sampling. This Hessian-free approach captureshigher-order interactions among parameters and scales efficiently to neuralnetworks with billions of parameters. We demonstrate state-of-the-art resultson predicting retraining experiments.</description><author>Philipp Alexander Kreer, Wilson Wu, Maxwell Adam, Zach Furman, Jesse Hoogland</author><pubDate>Tue, 30 Sep 2025 17:17:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26544v1</guid></item><item><title>BoxDreamer: Dreaming Box Corners for Generalizable Object Pose Estimation</title><link>http://arxiv.org/abs/2504.07955v2</link><description>This paper presents a generalizable RGB-based approach for object poseestimation, specifically designed to address challenges in sparse-viewsettings. While existing methods can estimate the poses of unseen objects,their generalization ability remains limited in scenarios involving occlusionsand sparse reference views, restricting their real-world applicability. Toovercome these limitations, we introduce corner points of the object boundingbox as an intermediate representation of the object pose. The 3D object cornerscan be reliably recovered from sparse input views, while the 2D corner pointsin the target view are estimated through a novel reference-based pointsynthesizer, which works well even in scenarios involving occlusions. As objectsemantic points, object corners naturally establish 2D-3D correspondences forobject pose estimation with a PnP algorithm. Extensive experiments on theYCB-Video and Occluded-LINEMOD datasets show that our approach outperformsstate-of-the-art methods, highlighting the effectiveness of the proposedrepresentation and significantly enhancing the generalization capabilities ofobject pose estimation, which is crucial for real-world applications.</description><author>Yuanhong Yu, Xingyi He, Chen Zhao, Junhao Yu, Jiaqi Yang, Ruizhen Hu, Yujun Shen, Xing Zhu, Xiaowei Zhou, Sida Peng</author><pubDate>Tue, 30 Sep 2025 17:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.07955v2</guid></item><item><title>The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models</title><link>http://arxiv.org/abs/2509.26543v1</link><description>Contrastive explanations, which indicate why an AI system produced one output(the target) instead of another (the foil), are widely regarded in explainableAI as more informative and interpretable than standard explanations. However,obtaining such explanations for speech-to-text (S2T) generative models remainsan open challenge. Drawing from feature attribution techniques, we propose thefirst method to obtain contrastive explanations in S2T by analyzing how partsof the input spectrogram influence the choice between alternative outputs.Through a case study on gender assignment in speech translation, we show thatour method accurately identifies the audio features that drive the selection ofone gender over another. By extending the scope of contrastive explanations toS2T, our work provides a foundation for better understanding S2T models.</description><author>Lina Conti, Dennis Fucci, Marco Gaido, Matteo Negri, Guillaume Wisniewski, Luisa Bentivogli</author><pubDate>Tue, 30 Sep 2025 17:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26543v1</guid></item><item><title>TASP: Topology-aware Sequence Parallelism</title><link>http://arxiv.org/abs/2509.26541v1</link><description>Long-context large language models (LLMs) face constraints due to thequadratic complexity of the self-attention mechanism. The mainstream sequenceparallelism (SP) method, Ring Attention, attempts to solve this by distributingthe query into multiple query chunks across accelerators and enable each Qtensor to access all KV tensors from other accelerators via the Ring AllGathercommunication primitive. However, it exhibits low communication efficiency,restricting its practical applicability. This inefficiency stems from themismatch between the Ring AllGather communication primitive it adopts and theAlltoAll topology of modern accelerators. A Ring AllGather primitive iscomposed of iterations of ring-styled data transfer, which can only utilize avery limited fraction of an AlltoAll topology. Inspired by the Hamiltonian decomposition of complete directed graphs, weidentify that modern accelerator topology can be decomposed into multipleorthogonal ring datapaths which can concurrently transfer data withoutinterference. Based on this, we further observe that the Ring AllGatherprimitive can also be decomposed into the same number of concurrent ring-styleddata transfer at every iteration. Based on these insights, we propose TASP, atopology-aware SP method for long-context LLMs that fully utilizes thecommunication capacity of modern accelerators via topology decomposition andprimitive decomposition. Experimental results on both single-node andmulti-node NVIDIA H100 systems and a single-node AMD MI300X system demonstratethat TASP achieves higher communication efficiency than Ring Attention on thesemodern accelerator topologies and achieves up to 3.58 speedup than RingAttention and its variant Zigzag-Ring Attention. The code is available athttps://github.com/infinigence/HamiltonAttention.</description><author>Yida Wang, Ke Hong, Xiuhong Li, Yuanchao Xu, Wenxun Wang, Guohao Dai, Yu Wang</author><pubDate>Tue, 30 Sep 2025 17:15:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26541v1</guid></item><item><title>FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation</title><link>http://arxiv.org/abs/2506.21095v3</link><description>Federated Learning (FL) enables collaborative model training across multipleclients without sharing clients' private data. However, the diverse and oftenconflicting biases present across clients pose significant challenges to modelfairness. Current fairness-enhancing FL solutions often fall short, as theytypically mitigate biases for a single, usually binary, sensitive attribute,while ignoring the heterogeneous fairness needs that exist in real-worldsettings. Moreover, these solutions often evaluate unfairness reduction only onthe server side, hiding persistent unfairness at the individual client level.To support more robust and reproducible fairness research in FL, we introduce acomprehensive benchmarking framework for fairness-aware FL at both the globaland client levels. Our contributions are three-fold: (1) We introduce\fairdataset, a library to create tabular datasets tailored to evaluating fairFL methods under heterogeneous client bias; (2) we release fourbias-heterogeneous datasets and corresponding benchmarks to compare fairnessmitigation methods in a controlled environment; (3) we provide ready-to-usefunctions for evaluating fairness outcomes for these datasets.</description><author>Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale</author><pubDate>Tue, 30 Sep 2025 17:14:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.21095v3</guid></item><item><title>Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents</title><link>http://arxiv.org/abs/2509.26539v1</link><description>Developing autonomous agents that effectively interact with Graphic UserInterfaces (GUIs) remains a challenging open problem, especially for smallon-device models. In this paper, we present Ferret-UI Lite, a compact,end-to-end GUI agent that operates across diverse platforms, including mobile,web, and desktop. Utilizing techniques optimized for developing small models,we build our 3B Ferret-UI Lite agent through curating a diverse GUI datamixture from real and synthetic sources, strengthening inference-timeperformance through chain-of-thought reasoning and visual tool-use, andreinforcement learning with designed rewards. Ferret-UI Lite achievescompetitive performance with other small-scale GUI agents. In GUI grounding,Ferret-UI Lite attains scores of $91.6\%$, $53.3\%$, and $61.2\%$ on theScreenSpot-V2, ScreenSpot-Pro, and OSWorld-G benchmarks, respectively. For GUInavigation, Ferret-UI Lite achieves success rates of $28.0\%$ on AndroidWorldand $19.8\%$ on OSWorld. We share our methods and lessons learned fromdeveloping compact, on-device GUI agents.</description><author>Zhen Yang, Zi-Yi Dou, Di Feng, Forrest Huang, Anh Nguyen, Keen You, Omar Attia, Yuhao Yang, Michael Feng, Haotian Zhang, Ram Ramrakhya, Chao Jia, Jeffrey Nichols, Alexander Toshev, Yinfei Yang, Zhe Gan</author><pubDate>Tue, 30 Sep 2025 17:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26539v1</guid></item><item><title>FM-SIREN &amp; FM-FINER: Nyquist-Informed Frequency Multiplier for Implicit Neural Representation with Periodic Activation</title><link>http://arxiv.org/abs/2509.23438v2</link><description>Existing periodic activation-based implicit neural representation (INR)networks, such as SIREN and FINER, suffer from hidden feature redundancy, whereneurons within a layer capture overlapping frequency components due to the useof a fixed frequency multiplier. This redundancy limits the expressive capacityof multilayer perceptrons (MLPs). Drawing inspiration from classical signalprocessing methods such as the Discrete Sine Transform (DST), we proposeFM-SIREN and FM-FINER, which assign Nyquist-informed, neuron-specific frequencymultipliers to periodic activations. Unlike existing approaches, our designintroduces frequency diversity without requiring hyperparameter tuning oradditional network depth. This simple yet principled modification reduces theredundancy of features by nearly 50% and consistently improves signalreconstruction across diverse INR tasks, including fitting 1D audio, 2D imageand 3D shape, and synthesis of neural radiance fields (NeRF), outperformingtheir baseline counterparts while maintaining efficiency.</description><author>Mohammed Alsakabi, Wael Mobeirek, John M. Dolan, Ozan K. Tonguz</author><pubDate>Tue, 30 Sep 2025 17:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23438v2</guid></item><item><title>HilbertA: Hilbert Attention for Image Generation with Diffusion Models</title><link>http://arxiv.org/abs/2509.26538v1</link><description>Designing sparse attention for diffusion transformers requires reconcilingtwo-dimensional spatial locality with GPU efficiency, a trade-off that currentmethods struggle to achieve. Existing approaches enforce two-dimensionalspatial locality but often incur uncoalesced memory access. We presentHilbertA, a 2D-aware and GPU-efficient sparse attention mechanism. HilbertAreorders image tokens along Hilbert curves to achieve a contiguous memorylayout while preserving spatial neighborhoods, and employs a sliding scheduleacross layers to enable long-range information propagation without repeated oruncoalesced memory access. To further enhance cross-tile communication andpositional awareness, HilbertA introduces a small central shared region.Implemented in Triton, HilbertA delivers comparable image quality withsignificant acceleration over prior methods on Flux.1-dev, demonstrating thefeasibility of hardware-aligned two-dimensional sparse attention forhigh-resolution image generation. HilbertA delivers attention speedups of$2.3\times$ when generating $1024\times 1024$ images, and up to $4.17\times$ at$2048\times 2048$, while achieving image quality comparable to or surpassingbaselines.</description><author>Shaoyi Zheng, Wenbo Lu, Yuxuan Xia, Haomin Liu, Shengjie Wang</author><pubDate>Tue, 30 Sep 2025 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26538v1</guid></item><item><title>The Loss Kernel: A Geometric Probe for Deep Learning Interpretability</title><link>http://arxiv.org/abs/2509.26537v1</link><description>We introduce the loss kernel, an interpretability method for measuringsimilarity between data points according to a trained neural network. Thekernel is the covariance matrix of per-sample losses computed under adistribution of low-loss-preserving parameter perturbations. We first validateour method on a synthetic multitask problem, showing it separates inputs bytask as predicted by theory. We then apply this kernel to Inception-v1 tovisualize the structure of ImageNet, and we show that the kernel's structurealigns with the WordNet semantic hierarchy. This establishes the loss kernel asa practical tool for interpretability and data attribution.</description><author>Maxwell Adam, Zach Furman, Jesse Hoogland</author><pubDate>Tue, 30 Sep 2025 17:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26537v1</guid></item><item><title>OceanGym: A Benchmark Environment for Underwater Embodied Agents</title><link>http://arxiv.org/abs/2509.26536v1</link><description>We introduce OceanGym, the first comprehensive benchmark for ocean underwaterembodied agents, designed to advance AI in one of the most demanding real-worldenvironments. Unlike terrestrial or aerial domains, underwater settings presentextreme perceptual and decision-making challenges, including low visibility,dynamic ocean currents, making effective agent deployment exceptionallydifficult. OceanGym encompasses eight realistic task domains and a unifiedagent framework driven by Multi-modal Large Language Models (MLLMs), whichintegrates perception, memory, and sequential decision-making. Agents arerequired to comprehend optical and sonar data, autonomously explore complexenvironments, and accomplish long-horizon objectives under these harshconditions. Extensive experiments reveal substantial gaps betweenstate-of-the-art MLLM-driven agents and human experts, highlighting thepersistent difficulty of perception, planning, and adaptability in oceanunderwater environments. By providing a high-fidelity, rigorously designedplatform, OceanGym establishes a testbed for developing robust embodied AI andtransferring these capabilities to real-world autonomous ocean underwatervehicles, marking a decisive step toward intelligent agents capable ofoperating in one of Earth's last unexplored frontiers. The code and data areavailable at https://github.com/OceanGPT/OceanGym.</description><author>Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng, Xinyu An, Ningyu Zhang, Ying Chen, Huajun Chen</author><pubDate>Tue, 30 Sep 2025 17:09:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26536v1</guid></item><item><title>MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal Reasoning</title><link>http://arxiv.org/abs/2509.24922v2</link><description>Multi-agent systems (MAS), leveraging the remarkable capabilities of LargeLanguage Models (LLMs), show great potential in addressing complex tasks. Inthis context, integrating MAS with legal tasks is a crucial step. Whileprevious studies have developed legal benchmarks for LLM agents, none arespecifically designed to consider the unique advantages of MAS, such as taskdecomposition, agent specialization, and flexible training. In fact, the lackof evaluation methods limits the potential of MAS in the legal domain. Toaddress this gap, we propose MASLegalBench, a legal benchmark tailored for MASand designed with a deductive reasoning approach. Our benchmark uses GDPR asthe application scenario, encompassing extensive background knowledge andcovering complex reasoning processes that effectively reflect the intricaciesof real-world legal situations. Furthermore, we manually design variousrole-based MAS and conduct extensive experiments using differentstate-of-the-art LLMs. Our results highlight the strengths, limitations, andpotential areas for improvement of existing models and MAS architectures.</description><author>Huihao Jing, Wenbin Hu, Hongyu Luo, Jianhui Yang, Wei Fan, Haoran Li, Yangqiu Song</author><pubDate>Tue, 30 Sep 2025 17:09:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24922v2</guid></item><item><title>Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework</title><link>http://arxiv.org/abs/2509.26534v1</link><description>The rapid rise of large language models (LLMs) has been driving an enormousdemand for AI inference infrastructure, mainly powered by high-end GPUs. Whilethese accelerators offer immense computational power, they incur high capitaland operational costs due to frequent upgrades, dense power consumption, andcooling demands, making total cost of ownership (TCO) for AI datacenters acritical concern for cloud providers. Unfortunately, traditional datacenterlifecycle management (designed for general-purpose workloads) struggles to keeppace with AI's fast-evolving models, rising resource needs, and diversehardware profiles. In this paper, we rethink the AI datacenter lifecycle schemeacross three stages: building, hardware refresh, and operation. We show howdesign choices in power, cooling, and networking provisioning impact long-termTCO. We also explore refresh strategies aligned with hardware trends. Finally,we use operation software optimizations to reduce cost. While theseoptimizations at each stage yield benefits, unlocking the full potentialrequires rethinking the entire lifecycle. Thus, we present a holistic lifecyclemanagement framework that coordinates and co-optimizes decisions across allthree stages, accounting for workload dynamics, hardware evolution, and systemaging. Our system reduces the TCO by up to 40\% over traditional approaches.Using our framework we provide guidelines on how to manage AI datacenterlifecycle for the future.</description><author>Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Ricardo Bianchini</author><pubDate>Tue, 30 Sep 2025 17:08:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26534v1</guid></item><item><title>Machine-Learning Driven Load Shedding to Mitigate Instability Attacks in Power Grids</title><link>http://arxiv.org/abs/2509.26532v1</link><description>Every year critical infrastructure becomes more complex and we grow to relyon it more and more. With this reliance, it becomes an attractive target forcyberattacks from sophisticated actors, with one of the most attractive targetsbeing the power grid. One class of attacks, instability attacks, is a newertype of attack that has relatively few protections developed. We present a costeffective, data-driven approach to training a supervised machine learning modelto retrofit load shedding decision systems in power grids with the capacity todefend against instability attacks. We show a proof of concept on the IEEE 14Bus System using the Achilles Heel Technologies Power Grid Analyzer, and showthrough an implementation of modified Prony analysis (MPA) that MPA is a viablemethod for detecting instability attacks and triggering defense mechanisms.</description><author>Justin Tackett, Benjamin Francis, Luis Garcia, David Grimsman, Sean Warnick</author><pubDate>Tue, 30 Sep 2025 17:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26532v1</guid></item><item><title>DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization</title><link>http://arxiv.org/abs/2505.12366v3</link><description>The recent success and openness of DeepSeek-R1 have brought widespreadattention to Group Relative Policy Optimization (GRPO) as a reinforcementlearning method for large reasoning models (LRMs). In this work, we analyze theGRPO objective under a binary reward setting and reveal an inherent limitationof question-level difficulty bias. We also identify a connection between GRPOand traditional discriminative methods in supervised learning. Motivated bythese insights, we introduce a new Discriminative Constrained Optimization(DisCO) framework for reinforcing LRMs, grounded in the principle ofdiscriminative learning. The main differences between DisCO and GRPO and itsrecent variants are: (1) it replaces the group relative objective with adiscriminative objective defined by a scoring function; (2) it abandonsclipping-based surrogates in favor of non-clipping RL surrogate objectives usedas scoring functions; (3) it employs a simple yet effective constrainedoptimization approach to enforce the KL divergence constraint. As a result,DisCO offers notable advantages over GRPO and its variants: (i) it completelyeliminates difficulty bias by adopting discriminative objectives; (ii) itaddresses the entropy instability in GRPO and its variants through the use ofnon-clipping scoring functions and a constrained optimization approach,yielding long and stable training dynamics; (iii) it allows the incorporationof advanced discriminative learning techniques to address data imbalance, wherea significant number of questions have more negative than positive generatedanswers during training. Our experiments on enhancing the mathematicalreasoning capabilities of SFT-finetuned models show that DisCO significantlyoutperforms GRPO and its improved variants such as DAPO, achieving averagegains of 7\% over GRPO and 6\% over DAPO across six benchmark tasks for an 1.5Bmodel.</description><author>Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang</author><pubDate>Tue, 30 Sep 2025 17:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12366v3</guid></item><item><title>Unlocking Transfer Learning for Open-World Few-Shot Recognition</title><link>http://arxiv.org/abs/2411.09986v3</link><description>Few-Shot Open-Set Recognition (FSOSR) targets a critical real-worldchallenge, aiming to categorize inputs into known categories, termed closed-setclasses, while identifying open-set inputs that fall outside these classes.Although transfer learning where a model is tuned to a given few-shot task hasbecome a prominent paradigm in closed-world, we observe that it fails to expandto open-world. To unlock this challenge, we propose a two-stage method whichconsists of open-set aware meta-learning with open-set free transfer learning.In the open-set aware meta-learning stage, a model is trained to establish ametric space that serves as a beneficial starting point for the subsequentstage. During the open-set free transfer learning stage, the model is furtheradapted to a specific target task through transfer learning. Additionally, weintroduce a strategy to simulate open-set examples by modifying the trainingdataset or generating pseudo open-set examples. The proposed method achievesstate-of-the-art performance on two widely recognized benchmarks, miniImageNetand tieredImageNet, with only a 1.5\% increase in training effort. Our workdemonstrates the effectiveness of transfer learning in FSOSR.</description><author>Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang</author><pubDate>Tue, 30 Sep 2025 17:02:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09986v3</guid></item><item><title>TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning</title><link>http://arxiv.org/abs/2509.26524v1</link><description>Federated Learning (FL), despite demonstrating impressive capabilities in thetraining of multiple models in a decentralized manner, has been shown toproduce a final model not necessarily well-suited to the needs of each client.While extensive work has been conducted on how to create tailored personalizedmodels, called Personalized Federated Learning (PFL), less attention has beengiven to personalization via fine-tuning of foundation models with multi-taskand multi-modal properties. Moreover, there exists a lack of understanding inthe literature on how to fine-tune and personalize such models in a settingthat is heterogeneous across clients not only in data, but also in tasks andmodalities. To address this gap in the literature, we propose TAP (Two-StageAdaptive Personalization), which (i) leverages mismatched model architecturesbetween the clients and server to selectively conduct replacement operationswhen it benefits a client's local tasks and (ii) engages in post-FL knowledgedistillation for capturing beneficial general knowledge without compromisingpersonalization. We also introduce the first convergence analysis of the servermodel under its modality-task pair architecture, and demonstrate that as thenumber of modality-task pairs increases, its ability to cater to all taskssuffers. Through extensive experiments, we demonstrate the effectiveness of ourproposed algorithm across a variety of datasets and tasks in comparison to amultitude of baselines. Implementation code is publicly available athttps://github.com/lee3296/TAP.</description><author>Seohyun Lee, Wenzhi Fang, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton</author><pubDate>Tue, 30 Sep 2025 17:01:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26524v1</guid></item><item><title>Entropy After $\langle \texttt{/Think} \rangle$ for reasoning model early exiting</title><link>http://arxiv.org/abs/2509.26522v1</link><description>Large reasoning models show improved performance with longer chains ofthought. However, recent work has highlighted (qualitatively) their tendency tooverthink, continuing to revise answers even after reaching the correctsolution. We quantitatively confirm this inefficiency by tracking Pass@1 foranswers averaged over a large number of rollouts and find that the model oftenbegins to always produce the correct answer early in the reasoning, makingextra reasoning a waste of tokens. To detect and prevent overthinking, wepropose a simple and inexpensive novel signal -- Entropy After &lt;/Think&gt; (EAT)-- for monitoring and deciding whether to exit reasoning early. By appending astop thinking token (&lt;/think&gt;) and monitoring the entropy of the followingtoken as the model reasons, we obtain a trajectory that decreases andstabilizes when Pass@1 plateaus; thresholding its variance under an exponentialmoving average yields a practical stopping rule. Importantly, our approachenables adaptively allocating compute based on the EAT trajectory, allowing usto spend compute in a more efficient way compared with fixing the token budgetfor all questions. Empirically, on MATH500 and AIME2025, EAT reduces tokenusage by 13 - 21% without harming accuracy, and it remains effective in blackbox settings where logits from the reasoning model are not accessible, and EATis computed with proxy models.</description><author>Xi Wang, James McInerney, Lequn Wang, Nathan Kallus</author><pubDate>Tue, 30 Sep 2025 16:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26522v1</guid></item><item><title>MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models</title><link>http://arxiv.org/abs/2509.26521v1</link><description>Interpretability is essential for deploying deep learning models in symbolicmusic analysis, yet most research emphasizes model performance overexplanation. To address this, we introduce MUSE-Explainer, a new method thathelps reveal how music Graph Neural Network models make decisions by providingclear, human-friendly explanations. Our approach generates counterfactualexplanations by making small, meaningful changes to musical score graphs thatalter a model's prediction while ensuring the results remain musicallycoherent. Unlike existing methods, MUSE-Explainer tailors its explanations tothe structure of musical data and avoids unrealistic or confusing outputs. Weevaluate our method on a music analysis task and show it offers intuitiveinsights that can be visualized with standard music tools such as Verovio.</description><author>Baptiste Hilaire, Emmanouil Karystinaios, Gerhard Widmer</author><pubDate>Tue, 30 Sep 2025 16:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26521v1</guid></item><item><title>Training Matryoshka Mixture-of-Experts for Elastic Inference-Time Expert Utilization</title><link>http://arxiv.org/abs/2509.26520v1</link><description>Mixture-of-Experts (MoE) has emerged as a promising paradigm for efficientlyscaling large language models without a proportional increase in computationalcost. However, the standard training strategy of Top-K router prevents MoEmodels from realizing their full potential for elastic inference. When thenumber of activated experts is altered at inference time, these models exhibitprecipitous performance degradation. In this work, we introduce Matryoshka MoE(M-MoE), a training framework that instills a coarse-to-fine structure directlyinto the expert ensemble. By systematically varying the number of activatedexperts during training, M-MoE compels the model to learn a meaningful ranking:top-ranked experts collaborate to provide essential, coarse-grainedcapabilities, while subsequent experts add progressively finer-grained detail.We explore this principle at multiple granularities, identifying a layer-wiserandomization strategy as the most effective. Our experiments demonstrate thata single M-MoE model achieves remarkable elasticity, with its performance atvarious expert counts closely matching that of an entire suite of specialistmodels, but at only a fraction of the total training cost. This flexibility notonly unlocks elastic inference but also enables optimizing performance byallocating different computational budgets to different model layers. Our workpaves the way for more practical and adaptable deployments of large-scale MoEmodels.</description><author>Yaoxiang Wang, Qingguo Hu, Yucheng Ding, Ruizhe Wang, Yeyun Gong, Jian Jiao, Yelong Shen, Peng Cheng, Jinsong Su</author><pubDate>Tue, 30 Sep 2025 16:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26520v1</guid></item><item><title>Deep Taxonomic Networks for Unsupervised Hierarchical Prototype Discovery</title><link>http://arxiv.org/abs/2509.23602v2</link><description>Inspired by the human ability to learn and organize knowledge intohierarchical taxonomies with prototypes, this paper addresses key limitationsin current deep hierarchical clustering methods. Existing methods often tie thestructure to the number of classes and underutilize the rich prototypeinformation available at intermediate hierarchical levels. We introduce deeptaxonomic networks, a novel deep latent variable approach designed to bridgethese gaps. Our method optimizes a large latent taxonomic hierarchy,specifically a complete binary tree structured mixture-of-Gaussian prior withina variational inference framework, to automatically discover taxonomicstructures and associated prototype clusters directly from unlabeled datawithout assuming true label sizes. We analytically show that optimizing theELBO of our method encourages the discovery of hierarchical relationships amongprototypes. Empirically, our learned models demonstrate strong hierarchicalclustering performance, outperforming baselines across diverse imageclassification datasets using our novel evaluation mechanism that leveragesprototype clusters discovered at all hierarchical levels. Qualitative resultsfurther reveal that deep taxonomic networks discover rich and interpretablehierarchical taxonomies, capturing both coarse-grained semantic categories andfine-grained visual distinctions.</description><author>Zekun Wang, Ethan Haarer, Tianyi Zhu, Zhiyi Dai, Christopher J. MacLellan</author><pubDate>Tue, 30 Sep 2025 16:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23602v2</guid></item><item><title>BatonVoice: An Operationalist Framework for Enhancing Controllable Speech Synthesis with Linguistic Intelligence from LLMs</title><link>http://arxiv.org/abs/2509.26514v1</link><description>The rise of Large Language Models (LLMs) is reshaping multimodel models, withspeech synthesis being a prominent application. However, existing approachesoften underutilize the linguistic intelligence of these models, typicallyfailing to leverage their powerful instruction-following capabilities. Thislimitation hinders the model's ability to follow text instructions forcontrollable Text-to-Speech~(TTS). To address this, we propose a new paradigminspired by ``operationalism'' that decouples instruction understanding fromspeech generation. We introduce BatonVoice, a framework where an LLM acts as a``conductor'', understanding user instructions and generating a textual``plan'' -- explicit vocal features (e.g., pitch, energy). A separate TTSmodel, the ``orchestra'', then generates the speech from these features. Torealize this component, we develop BatonTTS, a TTS model trained specificallyfor this task. Our experiments demonstrate that BatonVoice achieves strongperformance in controllable and emotional speech synthesis, outperformingstrong open- and closed-source baselines. Notably, our approach enablesremarkable zero-shot cross-lingual generalization, accurately applying featurecontrol abilities to languages unseen during post-training. This demonstratesthat objectifying speech into textual vocal features can more effectivelyunlock the linguistic intelligence of LLMs.</description><author>Yue Wang, Ruotian Ma, Xingyu Chen, Zhengliang Shi, Wanshun Chen, Huang Liu, Jiadi Yao, Qu Yang, Qingxuan Jiang, Fanghua Ye, Juntao Li, Min Zhang, Zhaopeng Tu, Xiaolong Li, Linus</author><pubDate>Tue, 30 Sep 2025 16:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26514v1</guid></item><item><title>Signal-Aware Workload Shifting Algorithms with Uncertainty-Quantified Predictors</title><link>http://arxiv.org/abs/2509.26511v1</link><description>A wide range of sustainability and grid-integration strategies depend onworkload shifting, which aligns the timing of energy consumption with externalsignals such as grid curtailment events, carbon intensity, or time-of-useelectricity prices. The main challenge lies in the online nature of theproblem: operators must make real-time decisions (e.g., whether to consumeenergy now) without knowledge of the future. While forecasts of signal valuesare typically available, prior work on learning-augmented online algorithms hasrelied almost exclusively on simple point forecasts. In parallel, theforecasting research has made significant progress in uncertaintyquantification (UQ), which provides richer and more fine-grained predictiveinformation. In this paper, we study how online workload shifting can leverageUQ predictors to improve decision-making. We introduce $\texttt{UQ-Advice}$, alearning-augmented algorithm that systematically integrates UQ forecaststhrough a $\textit{decision uncertainty score}$ that measures how forecastuncertainty affects optimal future decisions. By introducing$\textit{UQ-robustness}$, a new metric that characterizes how performancedegrades with forecast uncertainty, we establish theoretical performanceguarantees for $\texttt{UQ-Advice}$. Finally, using trace-driven experiments oncarbon intensity and electricity price data, we demonstrate that$\texttt{UQ-Advice}$ consistently outperforms robust baselines and existinglearning-augmented methods that ignore uncertainty.</description><author>Ezra Johnson, Adam Lechowicz, Mohammad Hajiesmaili</author><pubDate>Tue, 30 Sep 2025 16:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26511v1</guid></item><item><title>CE-SDWV: Effective and Efficient Concept Erasure for Text-to-Image Diffusion Models via a Semantic-Driven Word Vocabulary</title><link>http://arxiv.org/abs/2501.15562v2</link><description>Large-scale text-to-image (T2I) diffusion models have achieved remarkablegenerative performance about various concepts. With the limitation of privacyand safety in practice, the generative capability concerning NSFW (Not Safe ForWork) concepts is undesirable, e.g., producing sexually explicit photos, andlicensed images. The concept erasure task for T2I diffusion models hasattracted considerable attention and requires an effective and efficientmethod. To achieve this goal, we propose a CE-SDWV framework, which removes thetarget concepts (e.g., NSFW concepts) of T2I diffusion models in the textsemantic space by only adjusting the text condition tokens and does not need tore-train the original T2I diffusion model's weights. Specifically, ourframework first builds a target concept-related word vocabulary to enhance therepresentation of the target concepts within the text semantic space, and thenutilizes an adaptive semantic component suppression strategy to ablate thetarget concept-related semantic information in the text condition tokens. Tofurther adapt the above text condition tokens to the original image semanticspace, we propose an end-to-end gradient-orthogonal token optimizationstrategy. Extensive experiments on I2P and UnlearnCanvas benchmarks demonstratethe effectiveness and efficiency of our method. Code is available athttps://github.com/TtuHamg/CE-SDWV.</description><author>Jiahang Tu, Qian Feng, Jiahua Dong, Hanbin Zhao, Chao Zhang, Nicu Sebe, Hui Qian</author><pubDate>Tue, 30 Sep 2025 16:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15562v2</guid></item><item><title>The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain</title><link>http://arxiv.org/abs/2509.26507v1</link><description>The relationship between computing systems and the brain has served asmotivation for pioneering theoreticians since John von Neumann and Alan Turing.Uniform, scale-free biological networks, such as the brain, have powerfulproperties, including generalizing over time, which is the main barrier forMachine Learning on the path to Universal Reasoning Models. We introduce `Dragon Hatchling' (BDH), a new Large Language Modelarchitecture based on a scale-free biologically inspired network of \$n\$locally-interacting neuron particles. BDH couples strong theoreticalfoundations and inherent interpretability without sacrificing Transformer-likeperformance. BDH is a practical, performant state-of-the-art attention-based state spacesequence learning architecture. In addition to being a graph model, BDH admitsa GPU-friendly formulation. It exhibits Transformer-like scaling laws:empirically BDH rivals GPT2 performance on language and translation tasks, atthe same number of parameters (10M to 1B), for the same training data. BDH can be represented as a brain model. The working memory of BDH duringinference entirely relies on synaptic plasticity with Hebbian learning usingspiking neurons. We confirm empirically that specific, individual synapsesstrengthen connection whenever BDH hears or reasons about a specific conceptwhile processing language inputs. The neuron interaction network of BDH is agraph of high modularity with heavy-tailed degree distribution. The BDH modelis biologically plausible, explaining one possible mechanism which humanneurons could use to achieve speech. BDH is designed for interpretability. Activation vectors of BDH are sparseand positive. We demonstrate monosemanticity in BDH on language tasks.Interpretability of state, which goes beyond interpretability of neurons andmodel parameters, is an inherent feature of the BDH architecture.</description><author>Adrian Kosowski, Przemysław Uznański, Jan Chorowski, Zuzanna Stamirowska, Michał Bartoszkiewicz</author><pubDate>Tue, 30 Sep 2025 16:49:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26507v1</guid></item><item><title>SCUBA: Salesforce Computer Use Benchmark</title><link>http://arxiv.org/abs/2509.26506v1</link><description>We introduce SCUBA, a benchmark designed to evaluate computer-use agents oncustomer relationship management (CRM) workflows within the Salesforceplatform. SCUBA contains 300 task instances derived from real user interviews,spanning three primary personas, platform administrators, salesrepresentatives, and service agents. The tasks test a range ofenterprise-critical abilities, including Enterprise Software UI navigation,data manipulation, workflow automation, information retrieval, andtroubleshooting. To ensure realism, SCUBA operates in Salesforce sandboxenvironments with support for parallel execution and fine-grained evaluationmetrics to capture milestone progress. We benchmark a diverse set of agentsunder both zero-shot and demonstration-augmented settings. We observed hugeperformance gaps in different agent design paradigms and gaps between theopen-source model and the closed-source model. In the zero-shot setting,open-source model powered computer-use agents that have strong performance onrelated benchmarks like OSWorld only have less than 5\% success rate on SCUBA,while methods built on closed-source models can still have up to 39% tasksuccess rate. In the demonstration-augmented settings, task success rates canbe improved to 50\% while simultaneously reducing time and costs by 13% and16%, respectively. These findings highlight both the challenges of enterprisetasks automation and the promise of agentic solutions. By offering a realisticbenchmark with interpretable evaluation, SCUBA aims to accelerate progress inbuilding reliable computer-use agents for complex business software ecosystems.</description><author>Yutong Dai, Krithika Ramakrishnan, Jing Gu, Matthew Fernandez, Yanqi Luo, Viraj Prabhu, Zhenyu Hu, Silvio Savarese, Caiming Xiong, Zeyuan Chen, Ran Xu</author><pubDate>Tue, 30 Sep 2025 16:48:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26506v1</guid></item><item><title>Photography Perspective Composition: Towards Aesthetic Perspective Recommendation</title><link>http://arxiv.org/abs/2505.20655v3</link><description>Traditional photography composition approaches are dominated by 2Dcropping-based methods. However, these methods fall short when scenes containpoorly arranged subjects. Professional photographers often employ perspectiveadjustment as a form of 3D recomposition, modifying the projected 2Drelationships between subjects while maintaining their actual spatial positionsto achieve better compositional balance. Inspired by this artistic practice, wepropose photography perspective composition (PPC), extending beyond traditionalcropping-based methods. However, implementing the PPC faces significantchallenges: the scarcity of perspective transformation datasets and undefinedassessment criteria for perspective quality. To address these challenges, wepresent three key contributions: (1) An automated framework for building PPCdatasets through expert photographs. (2) A video generation approach thatdemonstrates the transformation process from less favorable to aestheticallyenhanced perspectives. (3) A perspective quality assessment (PQA) modelconstructed based on human performance. Our approach is concise and requires noadditional prompt instructions or camera trajectories, helping and guidingordinary users to enhance their composition skills.</description><author>Lujian Yao, Siming Zheng, Xinbin Yuan, Zhuoxuan Cai, Pu Wu, Jinwei Chen, Bo Li, Peng-Tao Jiang</author><pubDate>Tue, 30 Sep 2025 16:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.20655v3</guid></item><item><title>GastroViT: A Vision Transformer Based Ensemble Learning Approach for Gastrointestinal Disease Classification with Grad CAM &amp; SHAP Visualization</title><link>http://arxiv.org/abs/2509.26502v1</link><description>The gastrointestinal (GI) tract of humans can have a wide variety of aberrantmucosal abnormality findings, ranging from mild irritations to extremely fatalillnesses. Prompt identification of gastrointestinal disorders greatlycontributes to arresting the progression of the illness and improvingtherapeutic outcomes. This paper presents an ensemble of pre-trained visiontransformers (ViTs) for accurately classifying endoscopic images of the GItract to categorize gastrointestinal problems and illnesses. ViTs,attention-based neural networks, have revolutionized image recognition byleveraging the transformative power of the transformer architecture, achievingstate-of-the-art (SOTA) performance across various visual tasks. The proposedmodel was evaluated on the publicly available HyperKvasir dataset with 10,662images of 23 different GI diseases for the purpose of identifying GI tractdiseases. An ensemble method is proposed utilizing the predictions of twopre-trained models, MobileViT_XS and MobileViT_V2_200, which achievedaccuracies of 90.57% and 90.48%, respectively. All the individual models areoutperformed by the ensemble model, GastroViT, with an average precision,recall, F1 score, and accuracy of 69%, 63%, 64%, and 91.98%, respectively, inthe first testing that involves 23 classes. The model comprises only 20 million(M) parameters, even without data augmentation and despite the highlyimbalanced dataset. For the second testing with 16 classes, the scores are evenhigher, with average precision, recall, F1 score, and accuracy of 87%, 86%,87%, and 92.70%, respectively. Additionally, the incorporation of explainableAI (XAI) methods such as Grad-CAM (Gradient Weighted Class Activation Mapping)and SHAP (Shapley Additive Explanations) enhances model interpretability,providing valuable insights for reliable GI diagnosis in real-world settings.</description><author>Sumaiya Tabassum, Md. Faysal Ahamed, Hafsa Binte Kibria, Md. Nahiduzzaman, Julfikar Haider, Muhammad E. H. Chowdhury, Mohammad Tariqul Islam</author><pubDate>Tue, 30 Sep 2025 16:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26502v1</guid></item><item><title>Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers</title><link>http://arxiv.org/abs/2509.26500v1</link><description>The desirability of the mid-band frequency range (1 - 10 GHz) for federal andcommercial applications, combined with the growing applications for commercialindoor use-cases, such as factory automation, opens up a new approach tospectrum sharing: the same frequency bands used outdoors by federal incumbentscan be reused by commercial indoor users. A recent example of such sharing,between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) whereunlicensed, low-power-indoor (LPI) users share the band with outdoorincumbents, primarily fixed microwave links. However, to date, there exist noreliable, automatic means of determining whether a device is indoors oroutdoors, necessitating the use of other mechanisms such as mandating indooraccess points (APs) to have integrated antennas and not be battery powered, andreducing transmit power of client devices which may be outdoors. An accurateindoor/outdoor (I/O) classification addresses these challenges, enablingautomatic transmit power adjustments without interfering with incumbents. Tothis end, we leverage the Global Navigation Satellite System (GNSS) signals forI/O classification. GNSS signals, designed inherently for outdoor reception andhighly susceptible to indoor attenuation and blocking, provide a robust anddistinguishing feature for environmental sensing. We develop variousmethodologies, including threshold-based techniques and machine learningapproaches and evaluate them using an expanded dataset gathered from diversegeographical locations. Our results demonstrate that GNSS-based methods alonecan achieve greater accuracy than approaches relying solely on wireless (Wi-Fi)data, particularly in unfamiliar locations. Furthermore, the integration ofGNSS data with Wi-Fi information leads to improved classification accuracy,showcasing the significant benefits of multi-modal data fusion.</description><author>Hossein Nasiri, Muhammad Iqbal Rochman, Monisha Ghosh</author><pubDate>Tue, 30 Sep 2025 16:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26500v1</guid></item><item><title>Information-Geometric Barycenters for Bayesian Federated Learning</title><link>http://arxiv.org/abs/2412.11646v3</link><description>Federated learning (FL) is a widely used and impactful distributedoptimization framework that achieves consensus through averaging locallytrained models. While effective, this approach may not align well with Bayesianinference, where the model space has the structure of a distribution space.Taking an information-geometric perspective, we reinterpret FL aggregation asthe problem of finding the barycenter of local posteriors using a prespecifieddivergence metric, minimizing the average discrepancy across clients. Thisperspective provides a unifying framework that generalizes many existingmethods and offers crisp insights into their theoretical underpinnings. We thenpropose BA-BFL, an algorithm that retains the convergence properties ofFederated Averaging in non-convex settings. In non-independent and identicallydistributed scenarios, we conduct extensive comparisons with statisticalaggregation techniques, showing that BA-BFL achieves performance comparable tostate-of-the-art methods while offering a geometric interpretation of theaggregation phase. Additionally, we extend our analysis to Hybrid Bayesian DeepLearning, exploring the impact of Bayesian layers on uncertainty quantificationand model calibration.</description><author>Nour Jamoussi, Giuseppe Serra, Photios A. Stavrou, Marios Kountouris</author><pubDate>Tue, 30 Sep 2025 16:43:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.11646v3</guid></item><item><title>LoLA: Low-Rank Linear Attention With Sparse Caching</title><link>http://arxiv.org/abs/2505.23666v2</link><description>The per-token cost of transformer inference scales with context length,preventing its application to lifelong in-context learning. Linear attention isan efficient alternative that maintains a constant memory footprint, even oninfinite context lengths. While this is a potential candidate for lifelonglearning, it falls short in memory capacity. In this paper, we propose LoLA, atraining-free augmentation to linear attention that boosts associative recall.LoLA distributes past key-value pairs from context into three memory systems:(i) recent pairs in a local sliding window cache; (ii) difficult-to-memorizepairs in a sparse, global cache; and (iii) generic pairs in the recurrenthidden state of linear attention. We show through ablations that ourself-recall error metric is crucial to efficiently manage long-term associativememories. On pass-key retrieval tasks, LoLA improves the base model'sperformance from 0.6% to 97.4% accuracy. This is achieved with a 4.6x smallercache than Llama-3.1 8B on 4K context length. LoLA also outperforms other 1Band 8B parameter subquadratic models on zero-shot commonsense reasoning tasks.</description><author>Luke McDermott, Robert W. Heath Jr., Rahul Parhi</author><pubDate>Tue, 30 Sep 2025 16:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.23666v2</guid></item><item><title>Equivariance by Local Canonicalization: A Matter of Representation</title><link>http://arxiv.org/abs/2509.26499v1</link><description>Equivariant neural networks offer strong inductive biases for learning frommolecular and geometric data but often rely on specialized, computationallyexpensive tensor operations. We present a framework to transfers existingtensor field networks into the more efficient local canonicalization paradigm,preserving equivariance while significantly improving the runtime. Within thisframework, we systematically compare different equivariant representations interms of theoretical complexity, empirical runtime, and predictive accuracy. Wepublish the tensor_frames package, a PyTorchGeometric based implementation forlocal canonicalization, that enables straightforward integration ofequivariance into any standard message passing neural network.</description><author>Gerrit Gerhartz, Peter Lippmann, Fred A. Hamprecht</author><pubDate>Tue, 30 Sep 2025 16:41:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26499v1</guid></item><item><title>DEPTHOR++: Robust Depth Enhancement from a Real-World Lightweight dToF and RGB Guidance</title><link>http://arxiv.org/abs/2509.26498v1</link><description>Depth enhancement, which converts raw dToF signals into dense depth mapsusing RGB guidance, is crucial for improving depth perception in high-precisiontasks such as 3D reconstruction and SLAM. However, existing methods oftenassume ideal dToF inputs and perfect dToF-RGB alignment, overlookingcalibration errors and anomalies, thus limiting real-world applicability. Thiswork systematically analyzes the noise characteristics of real-worldlightweight dToF sensors and proposes a practical and novel depth completionframework, DEPTHOR++, which enhances robustness to noisy dToF inputs from threekey aspects. First, we introduce a simulation method based on syntheticdatasets to generate realistic training samples for robust model training.Second, we propose a learnable-parameter-free anomaly detection mechanism toidentify and remove erroneous dToF measurements, preventing misleadingpropagation during completion. Third, we design a depth completion networktailored to noisy dToF inputs, which integrates RGB images and pre-trainedmonocular depth estimation priors to improve depth recovery in challengingregions. On the ZJU-L5 dataset and real-world samples, our training strategysignificantly boosts existing depth completion models, with our model achievingstate-of-the-art performance, improving RMSE and Rel by 22% and 11% on average.On the Mirror3D-NYU dataset, by incorporating the anomaly detection method, ourmodel improves upon the previous SOTA by 37% in mirror regions. On the Hammerdataset, using simulated low-cost dToF data from RealSense L515, our methodsurpasses the L515 measurements with an average gain of 22%, demonstrating itspotential to enable low-cost sensors to outperform higher-end devices.Qualitative results across diverse real-world datasets further validate theeffectiveness and generalizability of our approach.</description><author>Jijun Xiang, Longliang Liu, Xuan Zhu, Xianqi Wang, Min Lin, Xin Yang</author><pubDate>Tue, 30 Sep 2025 16:41:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26498v1</guid></item><item><title>Revealing the Power of Post-Training for Small Language Models via Knowledge Distillation</title><link>http://arxiv.org/abs/2509.26497v1</link><description>The rapid advancement of large language models (LLMs) has significantlyadvanced the capabilities of artificial intelligence across various domains.However, their massive scale and high computational costs render themunsuitable for direct deployment in resource-constrained edge environments.This creates a critical need for high-performance small models that can operateefficiently at the edge. Yet, after pre-training alone, these smaller modelsoften fail to meet the performance requirements of complex tasks. To bridgethis gap, we introduce a systematic post-training pipeline that efficientlyenhances small model accuracy. Our post training pipeline consists ofcurriculum-based supervised fine-tuning (SFT) and offline on-policy knowledgedistillation. The resulting instruction-tuned model achieves state-of-the-artperformance among billion-parameter models, demonstrating strong generalizationunder strict hardware constraints while maintaining competitive accuracy acrossa variety of tasks. This work provides a practical and efficient solution fordeveloping high-performance language models on Ascend edge devices.</description><author>Miao Rang, Zhenni Bi, Hang Zhou, Hanting Chen, An Xiao, Tianyu Guo, Kai Han, Xinghao Chen, Yunhe Wang</author><pubDate>Tue, 30 Sep 2025 16:40:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26497v1</guid></item><item><title>GIM: Improved Interpretability for Large Language Models</title><link>http://arxiv.org/abs/2505.17630v2</link><description>Ensuring faithful interpretability in large language models is imperative fortrustworthy and reliable AI. A key obstacle is self-repair, a phenomenon wherenetworks compensate for reduced signal in one component by amplifying others,masking the true importance of the ablated component. While prior workattributes self-repair to layer normalization and back-up components thatcompensate for ablated components, we identify a novel form occurring withinthe attention mechanism, where softmax redistribution conceals the influence ofimportant attention scores. This leads traditional ablation and gradient-basedmethods to underestimate the significance of all components contributing tothese attention scores. We introduce Gradient Interaction Modifications (GIM),a technique that accounts for self-repair during backpropagation. Extensiveexperiments across multiple large language models (Gemma 2B/9B, LLAMA 1B/3B/8B,Qwen 1.5B/3B) and diverse tasks demonstrate that GIM significantly improvesfaithfulness over existing circuit identification and feature attributionmethods. Our work is a significant step toward better understanding the innermechanisms of LLMs, which is crucial for improving them and ensuring theirsafety. Our code is available at https://github.com/JoakimEdin/gim.</description><author>Joakim Edin, Róbert Csordás, Tuukka Ruotsalo, Zhengxuan Wu, Maria Maistro, Jing Huang, Lars Maaløe</author><pubDate>Tue, 30 Sep 2025 16:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17630v2</guid></item><item><title>UniAPL: A Unified Adversarial Preference Learning Framework for Instruct-Following</title><link>http://arxiv.org/abs/2509.25148v1</link><description>Shaping powerful LLMs to be beneficial and safe is central to AI alignment.We argue that post-training alignment is fundamentally a unified PreferenceLearning problem, involving two modalities: demonstrated preferences (e.g.,Supervised Fine-Tuning, SFT) and comparative preferences (e.g., ReinforcementLearning, RL).The standard sequential pipeline-SFT followed by RL-is flawed dueto a critical distributional mismatch: SFT uses static expert data, but as thepolicy evolves, its generation distribution drifts, making SFT knowledgebrittle. Subsequent RL then explores without direct access to the rich,ground-truth knowledge in expert demonstrations, leading to inefficient,ungrounded updates. This separation prevents mutual regularization between datasources. To address this, we reframe alignment as a constrained optimizationproblem and propose Unified Adversarial Preference Learning (UniAPL),a novelframework that dynamically aligns the policy's distribution with the expert's.UniAPL implements a single-stage unified training objective, jointly learningfrom mixed batches of SFT and preference data. In every gradient step, denseexpert demonstrations directly ground and regularize online exploration,inherently resolving distributional mismatch and maximizing data synergy.Weevaluate UniAPL on instruction-following tasks using Qwen3-235B-Instruct-2507as the teacher. Our models match or exceed strong GRPO baselines: +5.77% onQwen3-0.6B (matching a 32B model) and +3.75% on Qwen3-4B,even outperforming theteacher. Analyses of response length and log-probability distributions confirmthat UniAPL outputs closely mimic expert demonstrations, achieving bothstronger performance and better behavioral alignment.</description><author>FaQiang Qian, WeiKun Zhang, Ziliang Wang, Kang An, Xuhui Zheng, Liangjian Wen, Mengya Gao, Yong Dai, Yichao Wu</author><pubDate>Mon, 29 Sep 2025 17:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25148v1</guid></item><item><title>Fast Feature Field ($\text{F}^3$): A Predictive Representation of Events</title><link>http://arxiv.org/abs/2509.25146v1</link><description>This paper develops a mathematical argument and algorithms for buildingrepresentations of data from event-based cameras, that we call Fast FeatureField ($\text{F}^3$). We learn this representation by predicting future eventsfrom past events and show that it preserves scene structure and motioninformation. $\text{F}^3$ exploits the sparsity of event data and is robust tonoise and variations in event rates. It can be computed efficiently using ideasfrom multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and440 Hz at VGA resolutions. $\text{F}^3$ represents events within a contiguousspatiotemporal volume as a multi-channel image, enabling a range of downstreamtasks. We obtain state-of-the-art performance on optical flow estimation,semantic segmentation, and monocular metric depth estimation, on data fromthree robotic platforms (a car, a quadruped robot and a flying platform),across different lighting conditions (daytime, nighttime), environments(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors(resolutions and event rates). Our implementations can predict these tasks at25-75 Hz at HD resolution.</description><author>Richeek Das, Kostas Daniilidis, Pratik Chaudhari</author><pubDate>Mon, 29 Sep 2025 17:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25146v1</guid></item><item><title>Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation</title><link>http://arxiv.org/abs/2509.25144v1</link><description>We present Paired by the Teacher (PbT), a two-stage teacher-student pipelinethat synthesizes accurate input-output pairs without human labels or paralleldata. In many low-resource natural language generation (NLG) scenarios,practitioners may have only raw outputs, like highlights, recaps, or questions,or only raw inputs, such as articles, dialogues, or paragraphs, but seldomboth. This mismatch forces small models to learn from very few examples or relyon costly, broad-scope synthetic examples produced by large LLMs. PbT addressesthis by asking a teacher LLM to compress each unpaired example into a conciseintermediate representation (IR), and training a student to reconstruct inputsfrom IRs. This enables outputs to be paired with student-generated inputs,yielding high-quality synthetic data. We evaluate PbT on fivebenchmarks-document summarization (XSum, CNNDM), dialogue summarization(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpairedsetting on SwitchBoard (paired with DialogSum summaries). An 8B student trainedonly on PbT data outperforms models trained on 70 B teacher-generated corporaand other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotatedpairs and closing 82% of the oracle gap at one-third the annotation cost ofdirect synthesis. Human evaluation on SwitchBoard further confirms that onlyPbT produces concise, faithful summaries aligned with the target style,highlighting its advantage of generating in-domain sources that avoid themismatch, limiting direct synthesis.</description><author>Yen-Ju Lu, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba</author><pubDate>Mon, 29 Sep 2025 17:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25144v1</guid></item><item><title>TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models</title><link>http://arxiv.org/abs/2509.25143v1</link><description>Existing medical reasoning benchmarks for vision-language models primarilyfocus on analyzing a patient's condition based on an image from a single visit.However, this setting deviates significantly from real-world clinical practice,where doctors typically refer to a patient's historical conditions to provide acomprehensive assessment by tracking their changes over time. In this paper, weintroduce TemMed-Bench, the first benchmark designed for analyzing changes inpatients' conditions between different clinical visits, which challenges largevision-language models (LVLMs) to reason over temporal medical images.TemMed-Bench consists of a test set comprising three tasks - visualquestion-answering (VQA), report generation, and image-pair selection - and asupplementary knowledge corpus of over 17,000 instances. With TemMed-Bench, weconduct an evaluation of six proprietary and six open-source LVLMs. Our resultsshow that most LVLMs lack the ability to analyze patients' condition changesover temporal medical images, and a large proportion perform only at arandom-guessing level in the closed-book setting. In contrast, GPT o3, o4-miniand Claude 3.5 Sonnet demonstrate comparatively decent performance, though theyhave yet to reach the desired level. Furthermore, we explore augmenting theinput with both retrieved visual and textual modalities in the medical domain.We also show that multi-modal retrieval augmentation yields notably higherperformance gains than no retrieval and textual retrieval alone across mostmodels on our benchmark, with the VQA task showing an average improvement of2.59%. Overall, we compose a benchmark grounded on real-world clinicalpractice, and it reveals LVLMs' limitations in temporal medical imagereasoning, as well as highlighting the use of multi-modal retrievalaugmentation as a potentially promising direction worth exploring to addressthis challenge.</description><author>Junyi Zhang, Jia-Chen Gu, Wenbo Hu, Yu Zhou, Robinson Piramuthu, Nanyun Peng</author><pubDate>Mon, 29 Sep 2025 17:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25143v1</guid></item><item><title>Visual serial processing deficits explain divergences in human and VLM reasoning</title><link>http://arxiv.org/abs/2509.25142v1</link><description>Why do Vision Language Models (VLMs), despite success on standard benchmarks,often fail to match human performance on surprisingly simple visual reasoningtasks? While the underlying computational principles are still debated, wehypothesize that a crucial factor is a deficit in visually-grounded serialprocessing. To test this hypothesis, we compared human and VLM performanceacross tasks designed to vary serial processing demands in three distinctdomains: geometric reasoning, perceptual enumeration, and mental rotation.Tasks within each domain varied serial processing load by manipulating factorssuch as geometric concept complexity, perceptual individuation load, andtransformation difficulty. Across all domains, our results revealed aconsistent pattern: decreased VLM accuracy was strongly correlated withincreased human reaction time (used as a proxy for serial processing load). Astasks require more demanding serial processing -- whether composing concepts,enumerating items, or performing mental transformations -- the VLM-humanperformance gap widens reliably. These findings support our hypothesis,indicating that limitations in serial, visually grounded reasoning represent afundamental bottleneck that distinguishes current VLMs from humans.</description><author>Nicholas Budny, Kia Ghods, Declan Campbell, Raja Marjieh, Amogh Joshi, Sreejan Kumar, Jonathan D. Cohen, Taylor W. Webb, Thomas L. Griffiths</author><pubDate>Mon, 29 Sep 2025 17:51:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25142v1</guid></item><item><title>ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory</title><link>http://arxiv.org/abs/2509.25140v1</link><description>With the growing adoption of large language model agents in persistentreal-world roles, they naturally encounter continuous streams of tasks. A keylimitation, however, is their failure to learn from the accumulated interactionhistory, forcing them to discard valuable insights and repeat past errors. Wepropose ReasoningBank, a novel memory framework that distills generalizablereasoning strategies from an agent's self-judged successful and failedexperiences. At test time, an agent retrieves relevant memories fromReasoningBank to inform its interaction and then integrates new learnings back,enabling it to become more capable over time. Building on this powerfulexperience learner, we further introduce memory-aware test-time scaling(MaTTS), which accelerates and diversifies this learning process by scaling upthe agent's interaction experience. By allocating more compute to each task,the agent generates abundant, diverse experiences that provide rich contrastivesignals for synthesizing higher-quality memory. The better memory in turnguides more effective scaling, establishing a powerful synergy between memoryand test-time scaling. Across web browsing and software engineering benchmarks,ReasoningBank consistently outperforms existing memory mechanisms that storeraw trajectories or only successful task routines, improving both effectivenessand efficiency; MaTTS further amplifies these gains. These findings establishmemory-driven experience scaling as a new scaling dimension, enabling agents toself-evolve with emergent behaviors naturally arise.</description><author>Siru Ouyang, Jun Yan, I-Hung Hsu, Yanfei Chen, Ke Jiang, Zifeng Wang, Rujun Han, Long T. Le, Samira Daruki, Xiangru Tang, Vishy Tirumalashetty, George Lee, Mahsan Rofouei, Hangfei Lin, Jiawei Han, Chen-Yu Lee, Tomas Pfister</author><pubDate>Mon, 29 Sep 2025 17:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25140v1</guid></item><item><title>Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs</title><link>http://arxiv.org/abs/2509.25139v1</link><description>Integrating large language models (LLMs) into embodied AI models is becomingincreasingly prevalent. However, existing zero-shot LLM-basedVision-and-Language Navigation (VLN) agents either encode images as textualscene descriptions, potentially oversimplifying visual details, or process rawimage inputs, which can fail to capture abstract semantics required forhigh-level reasoning. In this paper, we improve the navigation agent'scontextual understanding by incorporating textual descriptions from multipleperspectives that facilitate analogical reasoning across images. By leveragingtext-based analogical reasoning, the agent enhances its global sceneunderstanding and spatial reasoning, leading to more accurate action decisions.We evaluate our approach on the R2R dataset, where our experiments demonstratesignificant improvements in navigation performance.</description><author>Yue Zhang, Tianyi Ma, Zun Wang, Yanyuan Qiao, Parisa Kordjamshidi</author><pubDate>Mon, 29 Sep 2025 17:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25139v1</guid></item><item><title>Investigating Language and Retrieval Bias in Multilingual Previously Fact-Checked Claim Detection</title><link>http://arxiv.org/abs/2509.25138v1</link><description>Multilingual Large Language Models (LLMs) offer powerful capabilities forcross-lingual fact-checking. However, these models often exhibit language bias,performing disproportionately better on high-resource languages such as Englishthan on low-resource counterparts. We also present and inspect a novel concept- retrieval bias, when information retrieval systems tend to favor certaininformation over others, leaving the retrieval process skewed. In this paper,we study language and retrieval bias in the context of Previously Fact-CheckedClaim Detection (PFCD). We evaluate six open-source multilingual LLMs across 20languages using a fully multilingual prompting strategy, leveraging the AMC-16Kdataset. By translating task prompts into each language, we uncover disparitiesin monolingual and cross-lingual performance and identify key trends based onmodel family, size, and prompting strategy. Our findings highlight persistentbias in LLM behavior and offer recommendations for improving equity inmultilingual fact-checking. To investigate retrieval bias, we employedmultilingual embedding models and look into the frequency of retrieved claims.Our analysis reveals that certain claims are retrieved disproportionatelyacross different posts, leading to inflated retrieval performance for popularclaims while under-representing less common ones.</description><author>Ivan Vykopal, Antonia Karamolegkou, Jaroslav Kopčan, Qiwei Peng, Tomáš Javůrek, Michal Gregor, Marián Šimko</author><pubDate>Mon, 29 Sep 2025 17:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25138v1</guid></item><item><title>The Era of Real-World Human Interaction: RL from User Conversations</title><link>http://arxiv.org/abs/2509.25137v1</link><description>We posit that to achieve continual model improvement and multifacetedalignment, future models must learn from natural human interaction. Currentconversational models are aligned using pre-annotated, expert-generated humanfeedback. In this work, we introduce Reinforcement Learning from HumanInteraction (RLHI), a paradigm that learns directly from in-the-wild userconversations. We develop two complementary methods: (1) RLHI with User-GuidedRewrites, which revises unsatisfactory model outputs based on users'natural-language follow-up responses, (2) RLHI with User-Based Rewards, whichlearns via a reward model conditioned on knowledge of the user's long-terminteraction history (termed persona). Together, these methods link long-termuser personas to turn-level preferences via persona-conditioned preferenceoptimization. Trained on conversations derived from WildChat, both RLHIvariants outperform strong baselines in personalization andinstruction-following, and similar feedback enhances performance on reasoningbenchmarks. These results suggest organic human interaction offers scalable,effective supervision for personalized alignment.</description><author>Chuanyang Jin, Jing Xu, Bo Liu, Leitian Tao, Olga Golovneva, Tianmin Shu, Wenting Zhao, Xian Li, Jason Weston</author><pubDate>Mon, 29 Sep 2025 17:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25137v1</guid></item><item><title>BALF: Budgeted Activation-Aware Low-Rank Factorization for Fine-Tuning-Free Model Compression</title><link>http://arxiv.org/abs/2509.25136v1</link><description>Neural network compression techniques typically require expensive fine-tuningor search procedures, rendering them impractical on commodity hardware.Inspired by recent LLM compression research, we present a generalactivation-aware factorization framework that can be applied to a broad rangeof layers. Moreover, we introduce a scalable budgeted rank allocator thatallows flexible control over compression targets (e.g., retaining 50% ofparameters) with no overhead. Together, these components form BALF, anefficient pipeline for compressing models without fine-tuning. We demonstrateits effectiveness across multiple scales and architectures, from ResNet-20 onCIFAR-10 to ResNeXt-101 and vision transformers on ImageNet, and show that itachieves excellent results in the fine-tuning-free regime. For instance, BALFreduces FLOPs on ResNeXt-101 by 45% with only a 1-percentage-point top-1accuracy drop.</description><author>David González Martínez</author><pubDate>Mon, 29 Sep 2025 17:50:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25136v1</guid></item></channel></rss>