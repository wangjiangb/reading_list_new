<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 14 Feb 2024 06:00:18 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation</title><link>http://arxiv.org/abs/2402.08682v1</link><description>Most text-to-3D generators build upon off-the-shelf text-to-image modelstrained on billions of images. They use variants of Score Distillation Sampling(SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigationis to fine-tune the 2D generator to be multi-view aware, which can helpdistillation or can be combined with reconstruction networks to output 3Dobjects directly. In this paper, we further explore the design space oftext-to-3D models. We significantly improve multi-view generation byconsidering video instead of image generators. Combined with a 3Dreconstruction algorithm which, by using Gaussian splatting, can optimize arobust image-based loss, we directly produce high-quality 3D outputs from thegenerated views. Our new method, IM-3D, reduces the number of evaluations ofthe 2D generator network 10-100x, resulting in a much more efficient pipeline,better quality, fewer geometric inconsistencies, and higher yield of usable 3Dassets.</description><author>Luke Melas-Kyriazi, Iro Laina, Christian Rupprecht, Natalia Neverova, Andrea Vedaldi, Oran Gafni, Filippos Kokkinos</author><pubDate>Tue, 13 Feb 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08682v1</guid></item><item><title>Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance</title><link>http://arxiv.org/abs/2402.08680v1</link><description>The advancement of Large Vision-Language Models (LVLMs) has increasinglyhighlighted the critical issue of their tendency to hallucinate non-existingobjects in the images. To address this issue, previous works focused on usingspecially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify theoutputs of LVLMs. However, these approaches require either expensivetraining/fine-tuning or API access to advanced LLMs to correct the model'soutput post-generation. In this paper, we tackle this challenge by introducinga framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE(MARINE), which is both training-free and API-free, and can effectively andefficiently reduce object hallucinations during the generation process.Specifically, MARINE enriches the visual context of LVLMs by integratingexisting open-source vision models, and employs classifier-free guidance toincorporate the additional object grounding features to improve the precisionof LVLMs' generations. Through comprehensive evaluations across $6$ popularLVLMs with diverse evaluation metrics, we demonstrate the effectiveness ofMARINE, which even outperforms existing fine-tuning-based methods. Remarkably,it not only reduces hallucinations but also improves the detailedness of LVLMs'generations, as assessed by GPT-4V.</description><author>Linxi Zhao, Yihe Deng, Weitong Zhang, Quanquan Gu</author><pubDate>Tue, 13 Feb 2024 18:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08680v1</guid></item><item><title>COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability</title><link>http://arxiv.org/abs/2402.08679v1</link><description>Jailbreaks on Large language models (LLMs) have recently received increasingattention. For a comprehensive assessment of LLM safety, it is essential toconsider jailbreaks with diverse attributes, such as contextual coherence andsentiment/stylistic variations, and hence it is beneficial to studycontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In thispaper, we formally formulate the controllable attack generation problem, andbuild a novel connection between this problem and controllable text generation,a well-explored topic of natural language processing. Based on this connection,we adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), astate-of-the-art, highly efficient algorithm in controllable text generation,and introduce the COLD-Attack framework which unifies and automates the searchof adversarial LLM attacks under a variety of control requirements such asfluency, stealthiness, sentiment, and left-right-coherence. The controllabilityenabled by COLD-Attack leads to diverse new jailbreak scenarios which not onlycover the standard setting of generating fluent suffix attacks, but also allowus to address new controllable attack settings such as revising a user queryadversarially with minimal paraphrasing, and inserting stealthy attacks incontext with left-right-coherence. Our extensive experiments on various LLMs(Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) show COLD-Attack's broadapplicability, strong controllability, high success rate, and attacktransferability. Our code is available athttps://github.com/Yu-Fangxu/COLD-Attack.</description><author>Xingang Guo, Fangxu Yu, Huan Zhang, Lianhui Qin, Bin Hu</author><pubDate>Tue, 13 Feb 2024 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08679v1</guid></item><item><title>Graph Mamba: Towards Learning on Graphs with State Space Models</title><link>http://arxiv.org/abs/2402.08678v1</link><description>Graph Neural Networks (GNNs) have shown promising potential in graphrepresentation learning. The majority of GNNs define a local message-passingmechanism, propagating information over the graph by stacking multiple layers.These methods, however, are known to suffer from two major limitations:over-squashing and poor capturing of long-range dependencies. Recently, GraphTransformers (GTs) emerged as a powerful alternative to Message-Passing NeuralNetworks (MPNNs). GTs, however, have quadratic computational cost, lackinductive biases on graph structures, and rely on complex Positional/StructuralEncodings (SE/PE). In this paper, we show that while Transformers, complexmessage-passing, and SE/PE are sufficient for good performance in practice,neither is necessary. Motivated by the recent success of State Space Models(SSMs), such as Mamba, we present Graph Mamba Networks (GMNs), a generalframework for a new class of GNNs based on selective SSMs. We discuss andcategorize the new challenges when adopting SSMs to graph-structured data, andpresent four required and one optional steps to design GMNs, where we choose(1) Neighborhood Tokenization, (2) Token Ordering, (3) Architecture ofBidirectional Selective SSM Encoder, (4) Local Encoding, and dispensable (5) PEand SE. We further provide theoretical justification for the power of GMNs.Experiments demonstrate that despite much less computational cost, GMNs attainan outstanding performance in long-range, small-scale, large-scale, andheterophilic benchmark datasets.</description><author>Ali Behrouz, Farnoosh Hashemi</author><pubDate>Tue, 13 Feb 2024 18:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08678v1</guid></item><item><title>A Convergence Analysis of Approximate Message Passing with Non-Separable Functions and Applications to Multi-Class Classification</title><link>http://arxiv.org/abs/2402.08676v1</link><description>Motivated by the recent application of approximate message passing (AMP) tothe analysis of convex optimizations in multi-class classifications [Loureiro,et. al., 2021], we present a convergence analysis of AMP dynamics withnon-separable multivariate nonlinearities. As an application, we present acomplete (and independent) analysis of the motivated convex optimizationproblem.</description><author>Burak Çakmak, Yue M. Lu, Manfred Opper</author><pubDate>Tue, 13 Feb 2024 18:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08676v1</guid></item><item><title>Human Curriculum Effects Emerge with In-Context Learning in Neural Networks</title><link>http://arxiv.org/abs/2402.08674v1</link><description>Human learning is sensitive to rule-like structure and the curriculum ofexamples used for training. In tasks governed by succinct rules, learning ismore robust when related examples are blocked across trials, but in the absenceof such rules, interleaving is more effective. To date, no neural model hassimultaneously captured these seemingly contradictory effects. Here we showthat this same tradeoff spontaneously emerges with "in-context learning" (ICL)both in neural networks trained with metalearning and in large language models(LLMs). ICL is the ability to learn new tasks "in context" - without weightchanges - via an inner-loop algorithm implemented in activation dynamics.Experiments with pretrained LLMs and metalearning transformers show that ICLexhibits the blocking advantage demonstrated in humans on a task involvingrule-like structure, and conversely, that concurrent in-weight learningreproduces the interleaving advantage observed in humans on tasks lacking suchstructure.</description><author>Jacob Russin, Ellie Pavlick, Michael J. Frank</author><pubDate>Tue, 13 Feb 2024 18:55:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08674v1</guid></item><item><title>Model Assessment and Selection under Temporal Distribution Shift</title><link>http://arxiv.org/abs/2402.08672v1</link><description>We investigate model assessment and selection in a changing environment, bysynthesizing datasets from both the current time period and historical epochs.To tackle unknown and potentially arbitrary temporal distribution shift, wedevelop an adaptive rolling window approach to estimate the generalizationerror of a given model. This strategy also facilitates the comparison betweenany two candidate models by estimating the difference of their generalizationerrors. We further integrate pairwise comparisons into a single-eliminationtournament, achieving near-optimal model selection from a collection ofcandidates. Theoretical analyses and numerical experiments demonstrate theadaptivity of our proposed methods to the non-stationarity in data.</description><author>Elise Han, Chengpiao Huang, Kaizheng Wang</author><pubDate>Tue, 13 Feb 2024 18:54:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08672v1</guid></item><item><title>Omitted Labels in Causality: A Study of Paradoxes</title><link>http://arxiv.org/abs/2311.06840v2</link><description>We explore what we call ``omitted label contexts,'' in which training data islimited to a subset of the possible labels. This setting is common amongspecialized human experts or specific focused studies. We lean on well-studiedparadoxes (Simpson's and Condorcet) to illustrate the more general difficultiesof causal inference in omitted label contexts. Contrary to the fundamentalprinciples on which much of causal inference is built, we show that ``correct''adjustments sometimes require non-exchangeable treatment and control groups.These pitfalls lead us to the study networks of conclusions drawn fromdifferent contexts and the structures the form, proving an interestingconnection between these networks and social choice theory.</description><author>Bijan Mazaheri, Siddharth Jain, Matthew Cook, Jehoshua Bruck</author><pubDate>Tue, 13 Feb 2024 18:53:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06840v2</guid></item><item><title>Are Semi-Dense Detector-Free Methods Good at Matching Local Features?</title><link>http://arxiv.org/abs/2402.08671v1</link><description>Semi-dense detector-free approaches (SDF), such as LoFTR, are currently amongthe most popular image matching methods. While SDF methods are trained toestablish correspondences between two images, their performances are almostexclusively evaluated using relative pose estimation metrics. Thus, the linkbetween their ability to establish correspondences and the quality of theresulting estimated pose has thus far received little attention. This paper isa first attempt to study this link. We start with proposing a novel structuredattention-based image matching architecture (SAM). It allows us to show acounter-intuitive result on two datasets (MegaDepth and HPatches): on the onehand SAM either outperforms or is on par with SDF methods in terms ofpose/homography estimation metrics, but on the other hand SDF approaches aresignificantly better than SAM in terms of matching accuracy. We then propose tolimit the computation of the matching accuracy to textured regions, and showthat in this case SAM often surpasses SDF methods. Our findings highlight astrong correlation between the ability to establish accurate correspondences intextured regions and the accuracy of the resulting estimated pose/homography.Our code will be made available.</description><author>Matthieu Vilain, Rémi Giraud, Hugo Germain, Guillaume Bourmaud</author><pubDate>Tue, 13 Feb 2024 18:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08671v1</guid></item><item><title>Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models</title><link>http://arxiv.org/abs/2402.08670v1</link><description>The development of large vision-language models (LVLMs) offers the potentialto address challenges faced by traditional multimodal recommendations thanks totheir proficient understanding of static images and textual dynamics. However,the application of LVLMs in this field is still limited due to the followingcomplexities: First, LVLMs lack user preference knowledge as they are trainedfrom vast general datasets. Second, LVLMs suffer setbacks in addressingmultiple image dynamics in scenarios involving discrete, noisy, and redundantimage sequences. To overcome these issues, we propose the novel reasoningscheme named Rec-GPT4V: Visual-Summary Thought (VST) of leveraging largevision-language models for multimodal recommendation. We utilize user historyas in-context user preferences to address the first challenge. Next, we promptLVLMs to generate item image summaries and utilize image comprehension innatural language space combined with item titles to query the user preferencesover candidate items. We conduct comprehensive experiments across four datasetswith three LVLMs: GPT4-V, LLaVa-7b, and LLaVa-13b. The numerical resultsindicate the efficacy of VST.</description><author>Yuqing Liu, Yu Wang, Lichao Sun, Philip S. Yu</author><pubDate>Tue, 13 Feb 2024 18:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08670v1</guid></item><item><title>Target Score Matching</title><link>http://arxiv.org/abs/2402.08667v1</link><description>Denoising Score Matching estimates the score of a noised version of a targetdistribution by minimizing a regression loss and is widely used to train thepopular class of Denoising Diffusion Models. A well known limitation ofDenoising Score Matching, however, is that it yields poor estimates of thescore at low noise levels. This issue is particularly unfavourable for problemsin the physical sciences and for Monte Carlo sampling tasks for which the scoreof the clean original target is known. Intuitively, estimating the score of aslightly noised version of the target should be a simple task in such cases. Inthis paper, we address this shortcoming and show that it is indeed possible toleverage knowledge of the target score. We present a Target Score Identity andcorresponding Target Score Matching regression loss which allows us to obtainscore estimates admitting favourable properties at low noise levels.</description><author>Valentin De Bortoli, Michael Hutchinson, Peter Wirnsberger, Arnaud Doucet</author><pubDate>Tue, 13 Feb 2024 18:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08667v1</guid></item><item><title>Improving Generalization in Semantic Parsing by Increasing Natural Language Variation</title><link>http://arxiv.org/abs/2402.08666v1</link><description>Text-to-SQL semantic parsing has made significant progress in recent years,with various models demonstrating impressive performance on the challengingSpider benchmark. However, it has also been shown that these models oftenstruggle to generalize even when faced with small perturbations of previously(accurately) parsed expressions. This is mainly due to the linguistic form ofquestions in Spider which are overly specific, unnatural, and display limitedvariation. In this work, we use data augmentation to enhance the robustness oftext-to-SQL parsers against natural language variations. Existing approachesgenerate question reformulations either via models trained on Spider or onlyintroduce local changes. In contrast, we leverage the capabilities of largelanguage models to generate more realistic and diverse questions. Using only afew prompts, we achieve a two-fold increase in the number of questions inSpider. Training on this augmented dataset yields substantial improvements on arange of evaluation sets, including robustness benchmarks and out-of-domaindata.</description><author>Irina Saparina, Mirella Lapata</author><pubDate>Tue, 13 Feb 2024 18:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08666v1</guid></item><item><title>Learning Emergent Gaits with Decentralized Phase Oscillators: on the role of Observations, Rewards, and Feedback</title><link>http://arxiv.org/abs/2402.08662v1</link><description>We present a minimal phase oscillator model for learning quadrupedallocomotion. Each of the four oscillators is coupled only to itself and itscorresponding leg through local feedback of the ground reaction force, whichcan be interpreted as an observer feedback gain. We interpret the oscillatoritself as a latent contact state-estimator. Through a systematic ablationstudy, we show that the combination of phase observations, simple phase-basedrewards, and the local feedback dynamics induces policies that exhibit emergentgait preferences, while using a reduced set of simple rewards, and withoutprescribing a specific gait. The code is open-source, and a video synopsisavailable at https://youtu.be/1NKQ0rSV3jU.</description><author>Jenny Zhang, Steve Heim, Se Hwan Jeon, Sangbae Kim</author><pubDate>Tue, 13 Feb 2024 18:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08662v1</guid></item><item><title>Suppressing Pink Elephants with Direct Principle Feedback</title><link>http://arxiv.org/abs/2402.07896v2</link><description>Existing methods for controlling language models, such as RLHF andConstitutional AI, involve determining which LLM behaviors are desirable andtraining them into a language model. However, in many cases, it is desirablefor LLMs to be controllable at inference time, so that they can be used inmultiple contexts with diverse needs. We illustrate this with the Pink ElephantProblem: instructing an LLM to avoid discussing a certain entity (a ``PinkElephant''), and instead discuss a preferred entity (``Grey Elephant''). Weapply a novel simplification of Constitutional AI, Direct Principle Feedback,which skips the ranking of responses and uses DPO directly on critiques andrevisions. Our results show that after DPF fine-tuning on our synthetic PinkElephants dataset, our 13B fine-tuned LLaMA 2 model significantly outperformsLlama-2-13B-Chat and a prompted baseline, and performs as well as GPT-4 in onour curated test set assessing the Pink Elephant Problem.</description><author>Louis Castricato, Nathan Lile, Suraj Anand, Hailey Schoelkopf, Siddharth Verma, Stella Biderman</author><pubDate>Tue, 13 Feb 2024 18:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07896v2</guid></item><item><title>Instruction Tuning with Human Curriculum</title><link>http://arxiv.org/abs/2310.09518v2</link><description>In building instruction-tuned large language models (LLMs), the importance ofa deep understanding of human knowledge can be often overlooked by theimportance of instruction diversification. This research proposes a novelapproach to instruction tuning by integrating a structured cognitive learningmethodology that takes inspiration from the systematic progression andcognitively stimulating nature of human education through two key steps. First,our synthetic instruction data generation pipeline, designed with somereferences to human educational frameworks, is enriched with meta-datadetailing topics and cognitive rigor for each instruction. Specifically, ourgeneration framework is infused with questions of varying levels ofrigorousness, inspired by Bloom's Taxonomy, a classic educational model forstructured curriculum learning. Second, during instruction tuning, we curateinstructions such that questions are presented in an increasingly complexmanner utilizing the information on question complexity and cognitiverigorousness produced by our data generation pipeline. Our human-inspiredcurriculum learning yields significant performance enhancements compared touniform sampling or round-robin, improving MMLU by 3.06 on LLaMA 2. We conductextensive experiments and find that the benefits of our approach areconsistently observed in eight other benchmarks. We hope that our work willshed light on the post-training learning process of LLMs and its similaritywith their human counterpart.</description><author>Bruce W. Lee, Hyunsoo Cho, Kang Min Yoo</author><pubDate>Tue, 13 Feb 2024 18:40:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09518v2</guid></item><item><title>The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting</title><link>http://arxiv.org/abs/2402.08658v1</link><description>We explored the viability of Large Language Models (LLMs) for triggering andpersonalizing content for Just-in-Time Adaptive Interventions (JITAIs) indigital health. JITAIs are being explored as a key mechanism for sustainablebehavior change, adapting interventions to an individual's current context andneeds. However, traditional rule-based and machine learning models for JITAIimplementation face scalability and reliability limitations, such as lack ofpersonalization, difficulty in managing multi-parametric systems, and issueswith data sparsity. To investigate JITAI implementation via LLMs, we tested thecontemporary overall performance-leading model 'GPT-4' with examples groundedin the use case of fostering heart-healthy physical activity in outpatientcardiac rehabilitation. Three personas and five sets of context information perpersona were used as a basis of triggering and personalizing JITAIs.Subsequently, we generated a total of 450 proposed JITAI decisions and messagecontent, divided equally into JITAIs generated by 10 iterations with GPT-4, abaseline provided by 10 laypersons (LayPs), and a gold standard set by 10healthcare professionals (HCPs). Ratings from 27 LayPs indicated that JITAIsgenerated by GPT-4 were superior to those by HCPs and LayPs over all assessedscales: i.e., appropriateness, engagement, effectiveness, and professionality.This study indicates that LLMs have significant potential for implementingJITAIs as a building block of personalized or "precision" health, offeringscalability, effective personalization based on opportunistically sampledinformation, and good acceptability.</description><author>David Haag, Devender Kumar, Sebastian Gruber, Mahdi Sareban, Gunnar Treff, Josef Niebauer, Christopher Bull, Jan David Smeddinck</author><pubDate>Tue, 13 Feb 2024 18:39:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08658v1</guid></item><item><title>PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs</title><link>http://arxiv.org/abs/2402.08657v1</link><description>Vision-Language Models (VLMs), such as Flamingo and GPT-4V, have shownimmense potential by integrating large language models with vision systems.Nevertheless, these models face challenges in the fundamental computer visiontask of object localisation, due to their training on multimodal datacontaining mostly captions without explicit spatial grounding. While it ispossible to construct custom, supervised training pipelines with bounding boxannotations that integrate with VLMs, these result in specialized andhard-to-scale models. In this paper, we aim to explore the limits ofcaption-based VLMs and instead propose to tackle the challenge in a simplermanner by i) keeping the weights of a caption-based VLM frozen and ii) notusing any supervised detection data. To this end, we introduce aninput-agnostic Positional Insert (PIN), a learnable spatial prompt, containinga minimal set of parameters that are slid inside the frozen VLM, unlockingobject localisation capabilities. Our PIN module is trained with a simplenext-token prediction task on synthetic data without requiring the introductionof new output heads. Our experiments demonstrate strong zero-shot localisationperformances on a variety of images, including Pascal VOC, COCO, LVIS, anddiverse images like paintings or cartoons.</description><author>Michael Dorkenwald, Nimrod Barazani, Cees G. M. Snoek, Yuki M. Asano</author><pubDate>Tue, 13 Feb 2024 18:39:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08657v1</guid></item><item><title>AlpaGasus: Training A Better Alpaca with Fewer Data</title><link>http://arxiv.org/abs/2307.08701v5</link><description>Large language models (LLMs) strengthen instruction-following capabilitythrough instruction-finetuning (IFT) on supervised instruction/response data.However, widely used IFT datasets (e.g., Alpaca's 52k data) surprisinglycontain many low-quality instances with incorrect or irrelevant responses,which are misleading and detrimental to IFT. In this paper, we propose a simpleand effective data selection strategy that automatically identifies and filtersout low-quality data using a strong LLM (e.g., ChatGPT). To this end, weintroduce AlpaGasus, which is finetuned on only 9k high-quality data filteredfrom the 52k Alpaca data. AlpaGasus significantly outperforms the originalAlpaca as evaluated by GPT-4 on multiple test sets and the controlled humanevaluation. Its 13B variant matches $&gt;90\%$ performance of its teacher LLM(i.e., Text-Davinci-003 generating the 52k data) on test tasks. It alsoprovides 5.7x faster training, reducing the training time for a 7B variant from80 minutes (for Alpaca) to 14 minutes. Moreover, the experiments prove theefficacy of our method across diverse datasets, base models, and LLM filters.Overall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can begenerally applied to instruction-tuning data, leading to faster training andbetter instruction-following models. Our project page is available at:https://lichang-chen.github.io/AlpaGasus/</description><author>Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, Hongxia Jin</author><pubDate>Tue, 13 Feb 2024 18:37:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08701v5</guid></item><item><title>Learning Continuous 3D Words for Text-to-Image Generation</title><link>http://arxiv.org/abs/2402.08654v1</link><description>Current controls over diffusion models (e.g., through text or ControlNet) forimage generation fall short in recognizing abstract, continuous attributes likeillumination direction or non-rigid shape change. In this paper, we present anapproach for allowing users of text-to-image models to have fine-grainedcontrol of several attributes in an image. We do this by engineering specialsets of input tokens that can be transformed in a continuous manner -- we callthem Continuous 3D Words. These attributes can, for example, be represented assliders and applied jointly with text prompts for fine-grained control overimage generation. Given only a single mesh and a rendering engine, we show thatour approach can be adopted to provide continuous user control over several3D-aware attributes, including time-of-day illumination, bird wing orientation,dollyzoom effect, and object poses. Our method is capable of conditioning imagecreation with multiple Continuous 3D Words and text descriptions simultaneouslywhile adding no overhead to the generative process. Project Page:https://ttchengab.github.io/continuous_3d_words</description><author>Ta-Ying Cheng, Matheus Gadelha, Thibault Groueix, Matthew Fisher, Radomir Mech, Andrew Markham, Niki Trigoni</author><pubDate>Tue, 13 Feb 2024 18:34:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08654v1</guid></item><item><title>What can we know about that which we cannot even imagine?</title><link>http://arxiv.org/abs/2208.03886v4</link><description>In this essay I will consider a sequence of questions. The first questionsconcern the biological function of intelligence in general, and cognitiveprostheses of human intelligence in particular. These will lead into questionsconcerning human language, perhaps the most important cognitive prosthesishumanity has ever developed. While it is traditional to rhapsodize about thecognitive power encapsulated in human language, I will emphasize how horriblylimited human language is - and therefore how limited our cognitive abilitiesare, despite their being augmented with language. This will lead to questionsof whether human mathematics, being ultimately formulated in terms of humanlanguage, is also deeply limited. I will then combine these questions to pose apartial, sort-of, sideways answer to the guiding concern of this essay: what wecan ever discern about that we cannot even conceive?</description><author>David H. Wolpert</author><pubDate>Tue, 13 Feb 2024 18:33:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.03886v4</guid></item><item><title>SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds</title><link>http://arxiv.org/abs/2402.08653v1</link><description>Modern graph neural networks (GNNs) can be sensitive to changes in the inputgraph structure and node features, potentially resulting in unpredictablebehavior and degraded performance. In this work, we introduce a spectralframework known as SAGMAN for examining the stability of GNNs. This frameworkassesses the distance distortions that arise from the nonlinear mappings ofGNNs between the input and output manifolds: when two nearby nodes on the inputmanifold are mapped (through a GNN model) to two distant ones on the outputmanifold, it implies a large distance distortion and thus a poor GNN stability.We propose a distance-preserving graph dimension reduction (GDR) approach thatutilizes spectral graph embedding and probabilistic graphical models (PGMs) tocreate low-dimensional input/output graph-based manifolds for meaningfulstability analysis. Our empirical evaluations show that SAGMAN effectivelyassesses the stability of each node when subjected to various edge or featureperturbations, offering a scalable approach for evaluating the stability ofGNNs, extending to applications within recommendation systems. Furthermore, weillustrate its utility in downstream tasks, notably in enhancing GNN stabilityand facilitating adversarial targeted attacks.</description><author>Wuxinlin Cheng, Chenhui Deng, Ali Aghdaei, Zhiru Zhang, Zhuo Feng</author><pubDate>Tue, 13 Feb 2024 18:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08653v1</guid></item><item><title>Generating Universal Adversarial Perturbations for Quantum Classifiers</title><link>http://arxiv.org/abs/2402.08648v1</link><description>Quantum Machine Learning (QML) has emerged as a promising field of research,aiming to leverage the capabilities of quantum computing to enhance existingmachine learning methodologies. Recent studies have revealed that, like theirclassical counterparts, QML models based on Parametrized Quantum Circuits(PQCs) are also vulnerable to adversarial attacks. Moreover, the existence ofUniversal Adversarial Perturbations (UAPs) in the quantum domain has beendemonstrated theoretically in the context of quantum classifiers. In this work,we introduce QuGAP: a novel framework for generating UAPs for quantumclassifiers. We conceptualize the notion of additive UAPs for PQC-basedclassifiers and theoretically demonstrate their existence. We then utilizegenerative models (QuGAP-A) to craft additive UAPs and experimentally show thatquantum classifiers are susceptible to such attacks. Moreover, we formulate anew method for generating unitary UAPs (QuGAP-U) using quantum generativemodels and a novel loss function based on fidelity constraints. We evaluate theperformance of the proposed framework and show that our method achievesstate-of-the-art misclassification rates, while maintaining high fidelitybetween legitimate and adversarial samples.</description><author>Gautham Anil, Vishnu Vinod, Apurva Narayan</author><pubDate>Tue, 13 Feb 2024 18:27:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08648v1</guid></item><item><title>Inference of Abstraction for a Unified Account of Symbolic Reasoning from Data</title><link>http://arxiv.org/abs/2402.08646v1</link><description>Inspired by empirical work in neuroscience for Bayesian approaches to brainfunction, we give a unified probabilistic account of various types of symbolicreasoning from data. We characterise them in terms of formal logic using theclassical consequence relation, an empirical consequence relation, maximalconsistent sets, maximal possible sets and maximum likelihood estimation. Thetheory gives new insights into reasoning towards human-like machineintelligence.</description><author>Hiroyuki Kido</author><pubDate>Tue, 13 Feb 2024 18:24:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08646v1</guid></item><item><title>Peeking Behind the Curtains of Residual Learning</title><link>http://arxiv.org/abs/2402.08645v1</link><description>The utilization of residual learning has become widespread in deep andscalable neural nets. However, the fundamental principles that contribute tothe success of residual learning remain elusive, thus hindering effectivetraining of plain nets with depth scalability. In this paper, we peek behindthe curtains of residual learning by uncovering the "dissipating inputs"phenomenon that leads to convergence failure in plain neural nets: the input isgradually compromised through plain layers due to non-linearities, resulting inchallenges of learning feature representations. We theoretically demonstratehow plain neural nets degenerate the input to random noise and emphasize thesignificance of a residual connection that maintains a better lower bound ofsurviving neurons as a solution. With our theoretical discoveries, we propose"The Plain Neural Net Hypothesis" (PNNH) that identifies the internal pathacross non-linear layers as the most critical part in residual learning, andestablishes a paradigm to support the training of deep plain neural nets devoidof residual connections. We thoroughly evaluate PNNH-enabled CNN architecturesand Transformers on popular vision benchmarks, showing on-par accuracy, up to0.3% higher training throughput, and 2x better parameter efficiency compared toResNets and vision Transformers.</description><author>Tunhou Zhang, Feng Yan, Hai Li, Yiran Chen</author><pubDate>Tue, 13 Feb 2024 18:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08645v1</guid></item><item><title>Tandem Transformers for Inference Efficient LLMs</title><link>http://arxiv.org/abs/2402.08644v1</link><description>The autoregressive nature of conventional large language models (LLMs)inherently limits inference speed, as tokens are generated sequentially. Whilespeculative and parallel decoding techniques attempt to mitigate this, theyface limitations: either relying on less accurate smaller models for generationor failing to fully leverage the base LLM's representations. We introduce a novel architecture, Tandem transformers, to address theseissues. This architecture uniquely combines (1) a small autoregressive modeland (2) a large model operating in block mode (processing multiple tokenssimultaneously). The small model's predictive accuracy is substantiallyenhanced by granting it attention to the large model's richer representations.On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Geckodemonstrates a 3.3% improvement in next-token prediction accuracy over astandalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Ottermodel with comparable downstream performance. We further incorporate the tandemmodel within the speculative decoding (SPEED) framework where the large modelvalidates tokens from the small model. This ensures that the Tandem ofPaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x fasterthan using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstreamtask accuracy.</description><author>Aishwarya P S, Pranav Ajit Nair, Yashas Samaga, Toby Boyd, Sanjiv Kumar, Prateek Jain, Praneeth Netrapalli</author><pubDate>Tue, 13 Feb 2024 18:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08644v1</guid></item><item><title>SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning</title><link>http://arxiv.org/abs/2310.04918v3</link><description>This study tackles the issue of neural network pruning that inaccurategradients exist when computing the empirical Fisher Information Matrix (FIM).We introduce SWAP, an Entropic Wasserstein regression (EWR) network pruningformulation, capitalizing on the geometric attributes of the optimal transport(OT) problem. The "swap" of a commonly used standard linear regression (LR)with the EWR in optimization is analytically showcased to excel in noisemitigation by adopting neighborhood interpolation across data points, yetincurs marginal extra computational cost. The unique strength of SWAP is itsintrinsic ability to strike a balance between noise reduction and covarianceinformation preservation. Extensive experiments performed on various networksshow comparable performance of SWAP with state-of-the-art (SoTA) networkpruning algorithms. Our proposed method outperforms the SoTA when the networksize or the target sparsity is large, the gain is even larger with theexistence of noisy gradients, possibly from noisy data, analog memory, oradversarial attacks. Notably, our proposed method achieves a gain of 6%improvement in accuracy and 8% improvement in testing loss for MobileNetV1 withless than one-fourth of the network parameters remaining.</description><author>Lei You, Hei Victor Cheng</author><pubDate>Tue, 13 Feb 2024 18:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04918v3</guid></item><item><title>Learned Image Compression with Text Quality Enhancement</title><link>http://arxiv.org/abs/2402.08643v1</link><description>Learned image compression has gained widespread popularity for theirefficiency in achieving ultra-low bit-rates. Yet, images containing substantialtextual content, particularly screen-content images (SCI), often suffers fromtext distortion at such compressed levels. To address this, we propose tominimize a novel text logit loss designed to quantify the disparity in textbetween the original and reconstructed images, thereby improving the perceptualquality of the reconstructed text. Through rigorous experimentation acrossdiverse datasets and employing state-of-the-art algorithms, our findings revealsignificant enhancements in the quality of reconstructed text upon integrationof the proposed loss function with appropriate weighting. Notably, we achieve aBjontegaard delta (BD) rate of -32.64% for Character Error Rate (CER) and-28.03% for Word Error Rate (WER) on average by applying the text logit lossfor two screenshot datasets. Additionally, we present quantitative metricstailored for evaluating text quality in image compression tasks. Our findingsunderscore the efficacy and potential applicability of our proposed text logitloss function across various text-aware image compression contexts.</description><author>Chih-Yu Lai, Dung Tran, Kazuhito Koishida</author><pubDate>Tue, 13 Feb 2024 18:20:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08643v1</guid></item><item><title>Compositional Deep Probabilistic Models of DNA Encoded Libraries</title><link>http://arxiv.org/abs/2310.13769v2</link><description>DNA-Encoded Library (DEL) has proven to be a powerful tool that utilizescombinatorially constructed small molecules to facilitate highly-efficientscreening assays. These selection experiments, involving multiple stages ofwashing, elution, and identification of potent binders via unique DNA barcodes,often generate complex data. This complexity can potentially mask theunderlying signals, necessitating the application of computational tools suchas machine learning to uncover valuable insights. We introduce a compositionaldeep probabilistic model of DEL data, DEL-Compose, which decomposes molecularrepresentations into their mono-synthon, di-synthon, and tri-synthon buildingblocks and capitalizes on the inherent hierarchical structure of thesemolecules by modeling latent reactions between embedded synthons. Additionally,we investigate methods to improve the observation models for DEL count datasuch as integrating covariate factors to more effectively account for datanoise. Across two popular public benchmark datasets (CA-IX and HRP), our modeldemonstrates strong performance compared to count baselines, enriches thecorrect pharmacophores, and offers valuable insights via its intrinsicinterpretable structure, thereby providing a robust tool for the analysis ofDEL data.</description><author>Benson Chen, Mohammad M. Sultan, Theofanis Karaletsos</author><pubDate>Tue, 13 Feb 2024 18:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13769v2</guid></item><item><title>Controlled Decoding from Language Models</title><link>http://arxiv.org/abs/2310.17022v2</link><description>KL-regularized reinforcement learning (RL) is a popular alignment frameworkto control the language model responses towards high reward outcomes. Wepropose a modular solver for this RL objective, called controlled decoding(CD), which exerts control through a separate prefix scorer module. At trainingtime, the prefix scorer learns a value function for the reward, and it is usedat inference time to control the generation from a frozen base model, provablysampling from a solution to the RL objective. We empirically demonstrate thatCD is effective as a control mechanism on popular benchmarks. We also show thata single prefix scorer can learn multiple rewards and different rewardcombinations can be configurable at inference time, effectively solving amulti-objective RL problem with no additional training. We show that thebenefits of applying CD transfer to an unseen base model with no furthertuning. Finally, we show that CD can be applied in a blockwise decoding fashionat inference-time, essentially bridging the gap between the popular best-of-$n$strategy and token-level control through reinforcement learning. This makes CDa promising approach for alignment of language models.</description><author>Sidharth Mudgal, Jong Lee, Harish Ganapathy, YaGuang Li, Tao Wang, Yanping Huang, Zhifeng Chen, Heng-Tze Cheng, Michael Collins, Trevor Strohman, Jilin Chen, Alex Beutel, Ahmad Beirami</author><pubDate>Tue, 13 Feb 2024 18:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17022v2</guid></item><item><title>Forecasting high-impact research topics via machine learning on evolving knowledge graphs</title><link>http://arxiv.org/abs/2402.08640v1</link><description>The exponential growth in scientific publications poses a severe challengefor human researchers. It forces attention to more narrow sub-fields, whichmakes it challenging to discover new impactful research ideas andcollaborations outside one's own field. While there are ways to predict ascientific paper's future citation counts, they need the research to befinished and the paper written, usually assessing impact long after the ideawas conceived. Here we show how to predict the impact of onsets of ideas thathave never been published by researchers. For that, we developed a largeevolving knowledge graph built from more than 21 million scientific papers. Itcombines a semantic network created from the content of the papers and animpact network created from the historic citations of papers. Using machinelearning, we can predict the dynamic of the evolving network into the futurewith high accuracy, and thereby the impact of new research directions. Weenvision that the ability to predict the impact of new ideas will be a crucialcomponent of future artificial muses that can inspire new impactful andinteresting scientific ideas.</description><author>Xuemei Gu, Mario Krenn</author><pubDate>Tue, 13 Feb 2024 18:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08640v1</guid></item><item><title>Treatment of Epistemic Uncertainty in Conjunction Analysis with Dempster-Shafer Theory</title><link>http://arxiv.org/abs/2402.00060v2</link><description>The paper presents an approach to the modelling of epistemic uncertainty inConjunction Data Messages (CDM) and the classification of conjunction eventsaccording to the confidence in the probability of collision. The approachproposed in this paper is based on the Dempster-Shafer Theory (DSt) of evidenceand starts from the assumption that the observed CDMs are drawn from a familyof unknown distributions. The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality isused to construct robust bounds on such a family of unknown distributionsstarting from a time series of CDMs. A DSt structure is then derived from theprobability boxes constructed with DKW inequality. The DSt structureencapsulates the uncertainty in the CDMs at every point along the time seriesand allows the computation of the belief and plausibility in the realisation ofa given probability of collision. The methodology proposed in this paper istested on a number of real events and compared against existing practices inthe European and French Space Agencies. We will show that the classificationsystem proposed in this paper is more conservative than the approach taken bythe European Space Agency but provides an added quantification of uncertaintyin the probability of collision.</description><author>Luis Sanchez, Massimiliano Vasile, Silvia Sanvido, Klaus Mertz, Christophe Taillan</author><pubDate>Tue, 13 Feb 2024 18:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00060v2</guid></item><item><title>SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages</title><link>http://arxiv.org/abs/2402.08638v1</link><description>Exploring and quantifying semantic relatedness is central to representinglanguage. It holds significant implications across various NLP tasks, includingoffering insights into the capabilities and performance of Large LanguageModels (LLMs). While earlier NLP research primarily focused on semanticsimilarity, often within the English language context, we instead investigatethe broader phenomenon of semantic relatedness. In this paper, we presentSemRel, a new semantic relatedness dataset collection annotated by nativespeakers across 14 languages:Afrikaans, Algerian Arabic, Amharic, English,Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, ModernStandard Arabic, Punjabi, Spanish, and Telugu. These languages originate fromfive distinct language families and are predominantly spoken in Africa and Asia-- regions characterised by a relatively limited availability of NLP resources.Each instance in the SemRel datasets is a sentence pair associated with a scorethat represents the degree of semantic textual relatedness between the twosentences. The scores are obtained using a comparative annotation framework. Wedescribe the data collection and annotation processes, related challenges whenbuilding the datasets, and their impact and utility in NLP. We further reportexperiments for each language and across the different languages.</description><author>Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine De Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Winata, Seid Muhie Yimam, Saif M. Mohammad</author><pubDate>Tue, 13 Feb 2024 18:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08638v1</guid></item><item><title>Strategizing against No-Regret Learners in First-Price Auctions</title><link>http://arxiv.org/abs/2402.08637v1</link><description>We study repeated first-price auctions and general repeated Bayesian gamesbetween two players, where one player, the learner, employs a no-regretlearning algorithm, and the other player, the optimizer, knowing the learner'salgorithm, strategizes to maximize its own utility. For a commonly used classof no-regret learning algorithms called mean-based algorithms, we show that (i)in standard (i.e., full-information) first-price auctions, the optimizer cannotget more than the Stackelberg utility -- a standard benchmark in theliterature, but (ii) in Bayesian first-price auctions, there are instanceswhere the optimizer can achieve much higher than the Stackelberg utility. On the other hand, Mansour et al. (2022) showed that a more sophisticatedclass of algorithms called no-polytope-swap-regret algorithms are sufficient tocap the optimizer's utility at the Stackelberg utility in any repeated Bayesiangame (including Bayesian first-price auctions), and they pose the open questionwhether no-polytope-swap-regret algorithms are necessary to cap the optimizer'sutility. For general Bayesian games, under a reasonable and necessarycondition, we prove that no-polytope-swap-regret algorithms are indeednecessary to cap the optimizer's utility and thus answer their open question.For Bayesian first-price auctions, we give a simple improvement of the standardalgorithm for minimizing the polytope swap regret by exploiting the structureof Bayesian first-price auctions.</description><author>Aviad Rubinstein, Junyao Zhao</author><pubDate>Tue, 13 Feb 2024 18:03:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08637v1</guid></item><item><title>BdSLW60: A Word-Level Bangla Sign Language Dataset</title><link>http://arxiv.org/abs/2402.08635v1</link><description>Sign language discourse is an essential mode of daily communication for thedeaf and hard-of-hearing people. However, research on Bangla Sign Language(BdSL) faces notable limitations, primarily due to the lack of datasets.Recognizing wordlevel signs in BdSL (WL-BdSL) presents a multitude ofchallenges, including the need for well-annotated datasets, capturing thedynamic nature of sign gestures from facial or hand landmarks, developingsuitable machine learning or deep learning-based models with substantial videosamples, and so on. In this paper, we address these challenges by creating acomprehensive BdSL word-level dataset named BdSLW60 in an unconstrained andnatural setting, allowing positional and temporal variations and allowing signusers to change hand dominance freely. The dataset encompasses 60 Bangla signwords, with a significant scale of 9307 video trials provided by 18 signersunder the supervision of a sign language professional. The dataset wasrigorously annotated and cross-checked by 60 annotators. We also introduced aunique approach of a relative quantization-based key frame encoding techniquefor landmark based sign gesture recognition. We report the benchmarking of ourBdSLW60 dataset using the Support Vector Machine (SVM) with testing accuracy upto 67.6% and an attention-based bi-LSTM with testing accuracy up to 75.1%. Thedataset is available at https://www.kaggle.com/datasets/hasaniut/bdslw60 andthe code base is accessible from https://github.com/hasanssl/BdSLW60_Code.</description><author>Husne Ara Rubaiyeat, Hasan Mahmud, Ahsan Habib, Md. Kamrul Hasan</author><pubDate>Tue, 13 Feb 2024 18:02:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08635v1</guid></item><item><title>Knowledge Editing on Black-box Large Language Models</title><link>http://arxiv.org/abs/2402.08631v1</link><description>Knowledge editing (KE) aims to efficiently and precisely modify the behaviorof large language models (LLMs) to update specific knowledge without negativelyinfluencing other knowledge. Current research primarily focuses on white-boxLLMs editing, overlooking an important scenario: black-box LLMs editing, whereLLMs are accessed through interfaces and only textual output is available. Toaddress the limitations of existing evaluations that are not inapplicable toblack-box LLM editing and lack comprehensiveness, we propose amulti-perspective evaluation framework, incorporating the assessment of styleretention for the first time. To tackle privacy leaks of editing data and styleover-editing in current methods, we introduce a novel postEdit framework,resolving privacy concerns through downstream post-processing and maintainingtextual style consistency via fine-grained editing to original responses.Experiments and analysis on two benchmarks demonstrate that postEditoutperforms all baselines and achieves strong generalization, especially withhuge improvements on style retention (average $+20.82\%\uparrow$).</description><author>Xiaoshuai Song, Zhengyang Wang, Keqing He, Guanting Dong, Jinxu Zhao, Weiran Xu</author><pubDate>Tue, 13 Feb 2024 17:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08631v1</guid></item><item><title>LLbezpeky: Leveraging Large Language Models for Vulnerability Detection</title><link>http://arxiv.org/abs/2401.01269v2</link><description>Despite the continued research and progress in building secure systems,Android applications continue to be ridden with vulnerabilities, necessitatingeffective detection methods. Current strategies involving static and dynamicanalysis tools come with limitations like overwhelming number of falsepositives and limited scope of analysis which make either difficult to adopt.Over the past years, machine learning based approaches have been extensivelyexplored for vulnerability detection, but its real-world applicability isconstrained by data requirements and feature engineering challenges. LargeLanguage Models (LLMs), with their vast parameters, have shown tremendouspotential in understanding semnatics in human as well as programming languages.We dive into the efficacy of LLMs for detecting vulnerabilities in the contextof Android security. We focus on building an AI-driven workflow to assistdevelopers in identifying and rectifying vulnerabilities. Our experiments showthat LLMs outperform our expectations in finding issues within applicationscorrectly flagging insecure apps in 91.67% of cases in the Ghera benchmark. Weuse inferences from our experiments towards building a robust and actionablevulnerability detection system and demonstrate its effectiveness. Ourexperiments also shed light on how different various simple configurations canaffect the True Positive (TP) and False Positive (FP) rates.</description><author>Noble Saji Mathews, Yelizaveta Brus, Yousra Aafer, Meiyappan Nagappan, Shane McIntosh</author><pubDate>Tue, 13 Feb 2024 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01269v2</guid></item><item><title>Vision-Language Models Provide Promptable Representations for Reinforcement Learning</title><link>http://arxiv.org/abs/2402.02651v2</link><description>Humans can quickly learn new behaviors by leveraging background worldknowledge. In contrast, agents trained with reinforcement learning (RL)typically learn behaviors from scratch. We thus propose a novel approach thatuses the vast amounts of general and indexable world knowledge encoded invision-language models (VLMs) pre-trained on Internet-scale data for embodiedRL. We initialize policies with VLMs by using them as promptablerepresentations: embeddings that are grounded in visual observations and encodesemantic features based on the VLM's internal knowledge, as elicited throughprompts that provide task context and auxiliary information. We evaluate ourapproach on visually-complex, long horizon RL tasks in Minecraft and robotnavigation in Habitat. We find that our policies trained on embeddingsextracted from general-purpose VLMs outperform equivalent policies trained ongeneric, non-promptable image embeddings. We also find our approach outperformsinstruction-following methods and performs comparably to domain-specificembeddings.</description><author>William Chen, Oier Mees, Aviral Kumar, Sergey Levine</author><pubDate>Tue, 13 Feb 2024 17:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02651v2</guid></item><item><title>NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs</title><link>http://arxiv.org/abs/2402.08622v1</link><description>A Neural Radiance Field (NeRF) encodes the specific relation of 3D geometryand appearance of a scene. We here ask the question whether we can transfer theappearance from a source NeRF onto a target 3D geometry in a semanticallymeaningful way, such that the resulting new NeRF retains the target geometrybut has an appearance that is an analogy to the source NeRF. To this end, wegeneralize classic image analogies from 2D images to NeRFs. We leveragecorrespondence transfer along semantic affinity that is driven by semanticfeatures from large, pre-trained 2D image models to achieve multi-viewconsistent appearance transfer. Our method allows exploring the mix-and-matchproduct space of 3D geometry and appearance. We show that our methodoutperforms traditional stylization-based methods and that a large majority ofusers prefer our method over several typical baselines.</description><author>Michael Fischer, Zhengqin Li, Thu Nguyen-Phuoc, Aljaz Bozic, Zhao Dong, Carl Marshall, Tobias Ritschel</author><pubDate>Tue, 13 Feb 2024 17:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08622v1</guid></item><item><title>A Generalized Approach to Online Convex Optimization</title><link>http://arxiv.org/abs/2402.08621v1</link><description>In this paper, we analyze the problem of online convex optimization indifferent settings. We show that any algorithm for online linear optimizationwith fully adaptive adversaries is an algorithm for online convex optimization.We also show that any such algorithm that requires full-information feedbackmay be transformed to an algorithm with semi-bandit feedback with comparableregret bound. We further show that algorithms that are designed for fullyadaptive adversaries using deterministic semi-bandit feedback can obtainsimilar bounds using only stochastic semi-bandit feedback when facing obliviousadversaries. We use this to describe general meta-algorithms to convert firstorder algorithms to zeroth order algorithms with comparable regret bounds. Ourframework allows us to analyze online optimization in various settings, suchfull-information feedback, bandit feedback, stochastic regret, adversarialregret and various forms of non-stationary regret. Using our analysis, weprovide the first efficient projection-free online convex optimizationalgorithm using linear optimization oracles.</description><author>Mohammad Pedramfar, Vaneet Aggarwal</author><pubDate>Tue, 13 Feb 2024 17:42:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08621v1</guid></item><item><title>Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms</title><link>http://arxiv.org/abs/2309.00851v3</link><description>The fitness level method is a popular tool for analyzing the hitting time ofelitist evolutionary algorithms. Its idea is to divide the search space intomultiple fitness levels and estimate lower and upper bounds on the hitting timeusing transition probabilities between fitness levels. However, the lower boundgenerated by this method is often loose. An open question regarding the fitnesslevel method is what are the tightest lower and upper time bounds that can beconstructed based on transition probabilities between fitness levels. To answerthis question, {\color{red} we combine drift analysis with fitness levels anddefine the tightest bound problem as a constrained multi-objective optimizationproblem subject to fitness levels.} The tightest metric bounds from fitnesslevels are constructed and proven for the first time. Then linear bounds arederived from metric bounds and a framework is established that can be used todevelop different fitness level methods for different types of linear bounds.The framework is generic and promising, as it can be used to draw tight timebounds on both fitness landscapes without and with shortcuts. This isdemonstrated in the example of the (1+1) EA maximizing the TwoMax1 function</description><author>Jun He, Yuren Zhou</author><pubDate>Tue, 13 Feb 2024 17:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00851v3</guid></item><item><title>Adjustment Identification Distance: A gadjid for Causal Structure Learning</title><link>http://arxiv.org/abs/2402.08616v1</link><description>Evaluating graphs learned by causal discovery algorithms is difficult: Thenumber of edges that differ between two graphs does not reflect how the graphsdiffer with respect to the identifying formulas they suggest for causaleffects. We introduce a framework for developing causal distances betweengraphs which includes the structural intervention distance for directed acyclicgraphs as a special case. We use this framework to develop improvedadjustment-based distances as well as extensions to completed partiallydirected acyclic graphs and causal orders. We develop polynomial-timereachability algorithms to compute the distances efficiently. In our packagegadjid (open source at https://github.com/CausalDisco/gadjid), we provideimplementations of our distances; they are orders of magnitude faster than thestructural intervention distance and thereby provide a success metric forcausal discovery that scales to graph sizes that were previously prohibitive.</description><author>Leonard Henckel, Theo Würtzen, Sebastian Weichwald</author><pubDate>Tue, 13 Feb 2024 17:32:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08616v1</guid></item><item><title>Learning to Stabilize Online Reinforcement Learning in Unbounded State Spaces</title><link>http://arxiv.org/abs/2306.01896v2</link><description>In many reinforcement learning (RL) applications, we want policies that reachdesired states and then keep the controlled system within an acceptable regionaround the desired states over an indefinite period of time. This latterobjective is called stability and is especially important when the state spaceis unbounded, such that the states can be arbitrarily far from each other andthe agent can drift far away from the desired states. For example, instochastic queuing networks, where queues of waiting jobs can grow withoutbound, the desired state is all-zero queue lengths. Here, a stable policyensures queue lengths are finite while an optimal policy minimizes queuelengths. Since an optimal policy is also stable, one would expect that RLalgorithms would implicitly give us stable policies. However, in this work, wefind that deep RL algorithms that directly minimize the distance to the desiredstate during online training often result in unstable policies, i.e., policiesthat drift far away from the desired state. We attribute this instability topoor credit-assignment for destabilizing actions. We then introduce an approachbased on two ideas: 1) a Lyapunov-based cost-shaping technique and 2) statetransformations to the unbounded state space. We conduct an empirical study onvarious queueing networks and traffic signal control problems and find that ourapproach performs competitively against strong baselines with knowledge of thetransition dynamics.</description><author>Brahma S. Pavse, Matthew Zurek, Yudong Chen, Qiaomin Xie, Josiah P. Hanna</author><pubDate>Tue, 13 Feb 2024 17:32:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01896v2</guid></item><item><title>Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type</title><link>http://arxiv.org/abs/2402.01632v2</link><description>Bayesian optimisation requires fitting a Gaussian process model, which inturn requires specifying hyperparameters - most of the theoretical literatureassumes those hyperparameters are known. The commonly used maximum likelihoodestimator for hyperparameters of the Gaussian process is consistent only if thedata fills the space uniformly, which does not have to be the case in Bayesianoptimisation. Since no guarantees exist regarding the correctness ofhyperparameter estimation, and those hyperparameters can significantly affectthe Gaussian process fit, theoretical analysis of Bayesian optimisation withunknown hyperparameters is very challenging. Previously proposed algorithmswith the no-regret property were only able to handle the special case ofunknown lengthscales, reproducing kernel Hilbert space norm and applied only tothe frequentist case. We propose a novel algorithm, HE-GP-UCB, which is thefirst algorithm enjoying the no-regret property in the case of unknownhyperparameters of arbitrary form, and which supports both Bayesian andfrequentist settings. Our proof idea is novel and can easily be extended toother variants of Bayesian optimisation. We show this by extending ouralgorithm to the adversarially robust optimisation setting under unknownhyperparameters. Finally, we empirically evaluate our algorithm on a set of toyproblems and show that it can outperform the maximum likelihood estimator.</description><author>Juliusz Ziomek, Masaki Adachi, Michael A. Osborne</author><pubDate>Tue, 13 Feb 2024 17:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01632v2</guid></item><item><title>Computational Copyright: Towards A Royalty Model for Music Generative AI</title><link>http://arxiv.org/abs/2312.06646v2</link><description>The advancement of generative AI has given rise to pressing copyrightchallenges, particularly in music industry. This paper focuses on the economicaspects of these challenges, emphasizing that the economic impact constitutes acentral issue in the copyright arena. The complexity of the black-boxgenerative AI technologies not only suggests but necessitates algorithmicsolutions. However, such solutions have been largely missing, leading toregulatory challenges in this landscape. We aim to bridge the gap in currentapproaches by proposing potential royalty models for revenue sharing on AImusic generation platforms. Our methodology involves a detailed analysis ofexisting royalty models in platforms like Spotify and YouTube, and adaptingthese to the unique context of AI-generated music. A significant challenge weaddress is the attribution of AI-generated music to influential copyrightedcontent in the training data. To this end, we present algorithmic solutionsemploying data attribution techniques. Our experimental results verify theeffectiveness of these solutions. This research represents a pioneering effortin integrating technical advancements with economic and legal considerations inthe field of generative AI, offering a computational copyright solution for thechallenges posed by the opaque nature of AI technologies.</description><author>Junwei Deng, Jiaqi Ma</author><pubDate>Tue, 13 Feb 2024 17:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06646v2</guid></item><item><title>HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs</title><link>http://arxiv.org/abs/2402.07309v2</link><description>Hypergraphs are marked by complex topology, expressing higher-orderinteractions among multiple entities with hyperedges. Lately, hypergraph-baseddeep learning methods to learn informative data representations for the problemof node classification on text-attributed hypergraphs have garnered increasingresearch attention. However, existing methods struggle to simultaneouslycapture the full extent of hypergraph structural information and the richlinguistic attributes inherent in the nodes attributes, which largely hamperstheir effectiveness and generalizability. To overcome these challenges, weexplore ways to further augment a pretrained BERT model with specializedhypergraph-aware layers for the task of node classification. Such layersintroduce higher-order structural inductive bias into the language model, thusimproving the model's capacity to harness both higher-order context informationfrom the hypergraph structure and semantic information present in text. In thispaper, we propose a new architecture, HyperBERT, a mixed text-hypergraph modelwhich simultaneously models hypergraph relational structure while maintainingthe high-quality text encoding capabilities of a pre-trained BERT. Notably,HyperBERT presents results that achieve a new state-of-the-art on fivechallenging text-attributed hypergraph node classification benchmarks.</description><author>Adrián Bazaga, Pietro Liò, Gos Micklem</author><pubDate>Tue, 13 Feb 2024 17:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07309v2</guid></item><item><title>Mixtures of Experts Unlock Parameter Scaling for Deep RL</title><link>http://arxiv.org/abs/2402.08609v1</link><description>The recent rapid progress in (self) supervised learning models is in largepart predicted by empirical scaling laws: a model's performance scalesproportionally to its size. Analogous scaling laws remain elusive forreinforcement learning domains, however, where increasing the parameter countof a model often hurts its final performance. In this paper, we demonstratethat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs(Puigcerver et al., 2023), into value-based networks results in moreparameter-scalable models, evidenced by substantial performance increasesacross a variety of training regimes and model sizes. This work thus providesstrong empirical evidence towards developing scaling laws for reinforcementlearning.</description><author>Johan Obando-Ceron, Ghada Sokar, Timon Willi, Clare Lyle, Jesse Farebrother, Jakob Foerster, Gintare Karolina Dziugaite, Doina Precup, Pablo Samuel Castro</author><pubDate>Tue, 13 Feb 2024 17:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08609v1</guid></item><item><title>A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence</title><link>http://arxiv.org/abs/2301.13139v4</link><description>Modern policy optimization methods in reinforcement learning, such as TRPOand PPO, owe their success to the use of parameterized policies. However, whiletheoretical guarantees have been established for this class of algorithms,especially in the tabular setting, the use of general parameterization schemesremains mostly unjustified. In this work, we introduce a novel framework forpolicy optimization based on mirror descent that naturally accommodates generalparameterizations. The policy class induced by our scheme recovers knownclasses, e.g., softmax, and generates new ones depending on the choice ofmirror map. Using our framework, we obtain the first result that guaranteeslinear convergence for a policy-gradient-based method involving generalparameterization. To demonstrate the ability of our framework to accommodategeneral parameterization schemes, we provide its sample complexity when usingshallow neural networks, show that it represents an improvement upon theprevious best results, and empirically validate the effectiveness of ourtheoretical claims on classic control tasks.</description><author>Carlo Alfano, Rui Yuan, Patrick Rebeschini</author><pubDate>Tue, 13 Feb 2024 17:18:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13139v4</guid></item><item><title>Neural Algorithmic Reasoning for Combinatorial Optimisation</title><link>http://arxiv.org/abs/2306.06064v5</link><description>Solving NP-hard/complete combinatorial problems with neural networks is achallenging research area that aims to surpass classical approximatealgorithms. The long-term objective is to outperform hand-designed heuristicsfor NP-hard/complete problems by learning to generate superior solutions solelyfrom training data. Current neural-based methods for solving CO problems oftenoverlook the inherent "algorithmic" nature of the problems. In contrast,heuristics designed for CO problems, e.g. TSP, frequently leveragewell-established algorithms, such as those for finding the minimum spanningtree. In this paper, we propose leveraging recent advancements in neuralalgorithmic reasoning to improve the learning of CO problems. Specifically, wesuggest pre-training our neural model on relevant algorithms before training iton CO instances. Our results demonstrate that by using this learning setup, weachieve superior performance compared to non-algorithmically informed deeplearning models.</description><author>Dobrik Georgiev, Danilo Numeroso, Davide Bacciu, Pietro Liò</author><pubDate>Tue, 13 Feb 2024 17:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06064v5</guid></item><item><title>CroissantLLM: A Truly Bilingual French-English Language Model</title><link>http://arxiv.org/abs/2402.00786v3</link><description>We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3TEnglish and French tokens, to bring to the research and industrial community ahigh-performance, fully open-sourced bilingual model that runs swiftly onconsumer-grade local hardware. To that end, we pioneer the approach of trainingan intrinsically bilingual model with a 1:1 English-to-French pretraining dataratio, a custom tokenizer, and bilingual finetuning datasets. We release thetraining dataset, notably containing a French split with manually curated,high-quality, and varied data sources. To assess performance outside ofEnglish, we craft a novel benchmark, FrenchBench, consisting of an array ofclassification and generation tasks, covering various orthogonal aspects ofmodel performance in the French Language. Additionally, rooted in transparencyand to foster further Large Language Model research, we release codebases, anddozens of checkpoints across various model sizes, training data distributions,and training steps, as well as fine-tuned Chat models, and strong translationmodels. We evaluate our model through the FMTI framework, and validate 81 % ofthe transparency criteria, far beyond the scores of even most open initiatives.This work enriches the NLP landscape, breaking away from previousEnglish-centric work in order to strengthen our understanding ofmultilinguality in language models.</description><author>Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, António Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, François Yvon, André F. T. Martins, Gautier Viaud, Céline Hudelot, Pierre Colombo</author><pubDate>Tue, 13 Feb 2024 17:12:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00786v3</guid></item><item><title>Arbitrary Polynomial Separations in Trainable Quantum Machine Learning</title><link>http://arxiv.org/abs/2402.08606v1</link><description>Recent theoretical results in quantum machine learning have demonstrated ageneral trade-off between the expressive power of quantum neural networks(QNNs) and their trainability; as a corollary of these results, practicalexponential separations in expressive power over classical machine learningmodels are believed to be infeasible as such QNNs take a time to train that isexponential in the model size. We here circumvent these negative results byconstructing a hierarchy of efficiently trainable QNNs that exhibitunconditionally provable, polynomial memory separations of arbitrary constantdegree over classical neural networks in performing a classical sequencemodeling task. Furthermore, each unit cell of the introduced class of QNNs iscomputationally efficient, implementable in constant time on a quantum device.The classical networks we prove a separation over include well-known examplessuch as recurrent neural networks and Transformers. We show that quantumcontextuality is the source of the expressivity separation, suggesting thatother classical sequence learning problems with long-time correlations may be aregime where practical advantages in quantum machine learning may exist.</description><author>Eric R. Anschuetz, Xun Gao</author><pubDate>Tue, 13 Feb 2024 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08606v1</guid></item><item><title>Globally-Optimal Greedy Experiment Selection for Active Sequential Estimation</title><link>http://arxiv.org/abs/2402.08602v1</link><description>Motivated by modern applications such as computerized adaptive testing,sequential rank aggregation, and heterogeneous data source selection, we studythe problem of active sequential estimation, which involves adaptivelyselecting experiments for sequentially collected data. The goal is to designexperiment selection rules for more accurate model estimation. Greedyinformation-based experiment selection methods, optimizing the information gainfor one-step ahead, have been employed in practice thanks to theircomputational convenience, flexibility to context or task changes, and broadapplicability. However, statistical analysis is restricted to one-dimensionalcases due to the problem's combinatorial nature and the seemingly limitedcapacity of greedy algorithms, leaving the multidimensional problem open. In this study, we close the gap for multidimensional problems. In particular,we propose adopting a class of greedy experiment selection methods and providestatistical analysis for the maximum likelihood estimator following theseselection rules. This class encompasses both existing methods and introducesnew methods with improved numerical efficiency. We prove that these methodsproduce consistent and asymptotically normal estimators. Additionally, within adecision theory framework, we establish that the proposed methods achieveasymptotic optimality when the risk measure aligns with the selection rule. Wealso conduct extensive numerical studies on both simulated and real data toillustrate the efficacy of the proposed methods. From a technical perspective, we devise new analytical tools to addresstheoretical challenges. These analytical tools are of independent theoreticalinterest and may be reused in related problems involving stochasticapproximation and sequential designs.</description><author>Xiaoou Li, Hongru Zhao</author><pubDate>Tue, 13 Feb 2024 17:09:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08602v1</guid></item><item><title>Latent Inversion with Timestep-aware Sampling for Training-free Non-rigid Editing</title><link>http://arxiv.org/abs/2402.08601v1</link><description>Text-guided non-rigid editing involves complex edits for input images, suchas changing motion or compositions within their surroundings. Since it requiresmanipulating the input structure, existing methods often struggle withpreserving object identity and background, particularly when combined withStable Diffusion. In this work, we propose a training-free approach fornon-rigid editing with Stable Diffusion, aimed at improving the identitypreservation quality without compromising editability. Our approach comprisesthree stages: text optimization, latent inversion, and timestep-aware textinjection sampling. Inspired by the recent success of Imagic, we employ theirtext optimization for smooth editing. Then, we introduce latent inversion topreserve the input image's identity without additional model fine-tuning. Tofully utilize the input reconstruction ability of latent inversion, we suggesttimestep-aware text inject sampling. This effectively retains the structure ofthe input image by injecting the source text prompt in early sampling steps andthen transitioning to the target prompt in subsequent sampling steps. Thisstrategic approach seamlessly harmonizes with text optimization, facilitatingcomplex non-rigid edits to the input without losing the original identity. Wedemonstrate the effectiveness of our method in terms of identity preservation,editability, and aesthetic quality through extensive experiments.</description><author>Yunji Jung, Seokju Lee, Tair Djanibekov, Hyunjung Shim, Jongchul Ye</author><pubDate>Tue, 13 Feb 2024 17:08:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08601v1</guid></item><item><title>Homomorphism Counts for Graph Neural Networks: All About That Basis</title><link>http://arxiv.org/abs/2402.08595v1</link><description>Graph neural networks are architectures for learning invariant functions overgraphs. A large body of work has investigated the properties of graph neuralnetworks and identified several limitations, particularly pertaining to theirexpressive power. Their inability to count certain patterns (e.g., cycles) in agraph lies at the heart of such limitations, since many functions to be learnedrely on the ability of counting such patterns. Two prominent paradigms aim toaddress this limitation by enriching the graph features with subgraph orhomomorphism pattern counts. In this work, we show that both of theseapproaches are sub-optimal in a certain sense and argue for a more fine-grainedapproach, which incorporates the homomorphism counts of all structures in the"basis" of the target pattern. This yields strictly more expressivearchitectures without incurring any additional overhead in terms ofcomputational complexity compared to existing approaches. We prove a series oftheoretical results on node-level and graph-level motif parameters andempirically validate them on standard benchmark datasets.</description><author>Emily Jin, Michael Bronstein, Ismail Ilkan Ceylan, Matthias Lanzinger</author><pubDate>Tue, 13 Feb 2024 16:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08595v1</guid></item><item><title>Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning</title><link>http://arxiv.org/abs/2402.08594v1</link><description>Prompt tuning, in which prompts are optimized to adapt large-scalepre-trained language models to downstream tasks instead of fine-tuning the fullmodel parameters, has been shown to be particularly effective when the promptsare trained in a multi-task transfer learning setting. These methods generallyinvolve individually training prompts for each source task and then aggregatingthem to provide the initialization of the prompt for the target task. However,this approach critically ignores the fact that some of the source tasks couldbe negatively or positively interfering with each other. We argue that when weextract knowledge from source tasks via training source prompts, we need toconsider this correlation among source tasks for better transfer to targettasks. To this end, we propose a Bayesian approach where we work with theposterior distribution of prompts across source tasks. We obtain representativesource prompts corresponding to the samples from the posterior utilizing SteinVariational Gradient Descent, which are then aggregated to constitute theinitial target prompt. We show extensive experimental results on the standardbenchmark NLP tasks, where our Bayesian multi-task transfer learning approachoutperforms the state-of-the-art methods in many settings. Furthermore, ourapproach requires no auxiliary models other than the prompt itself, achieving ahigh degree of parameter efficiency.</description><author>Haeju Lee, Minchan Jeong, Se-Young Yun, Kee-Eung Kim</author><pubDate>Tue, 13 Feb 2024 16:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08594v1</guid></item><item><title>Graph Feature Preprocessor: Real-time Extraction of Subgraph-based Features from Transaction Graphs</title><link>http://arxiv.org/abs/2402.08593v1</link><description>In this paper, we present "Graph Feature Preprocessor", a software libraryfor detecting typical money laundering and fraud patterns in financialtransaction graphs in real time. These patterns are used to produce a rich setof transaction features for downstream machine learning training and inferencetasks such as money laundering detection. We show that our enriched transactionfeatures dramatically improve the prediction accuracy ofgradient-boosting-based machine learning models. Our library exploits multicoreparallelism, maintains a dynamic in-memory graph, and efficiently minessubgraph patterns in the incoming transaction stream, which enables it to beoperated in a streaming manner. We evaluate our library using highly-imbalancedsynthetic anti-money laundering (AML) and real-life Ethereum phishing datasets.In these datasets, the proportion of illicit transactions is very small, whichmakes the learning process challenging. Our solution, which combines our GraphFeature Preprocessor and gradient-boosting-based machine learning models, isable to detect these illicit transactions with higher minority-class F1 scoresthan standard graph neural networks. In addition, the end-to-end throughputrate of our solution executed on a multicore CPU outperforms the graph neuralnetwork baselines executed on a powerful V100 GPU. Overall, the combination ofhigh accuracy, a high throughput rate, and low latency of our solutiondemonstrates the practical value of our library in real-world applications.Graph Feature Preprocessor has been integrated into IBM mainframe softwareproducts, namely "IBM Cloud Pak for Data on Z" and "AI Toolkit for IBM Z andLinuxONE".</description><author>Jovan Blanuša, Maximo Cravero Baraja, Andreea Anghel, Luc von Niederhäusern, Erik Altman, Haris Pozidis, Kubilay Atasu</author><pubDate>Tue, 13 Feb 2024 16:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08593v1</guid></item><item><title>Convolutional Neural Networks Towards Facial Skin Lesions Detection</title><link>http://arxiv.org/abs/2402.08592v1</link><description>Facial analysis has emerged as a prominent area of research with diverseapplications, including cosmetic surgery programs, the beauty industry,photography, and entertainment. Manipulating patient images often necessitatesprofessional image processing software. This study contributes by providing amodel that facilitates the detection of blemishes and skin lesions on facialimages through a convolutional neural network and machine learning approach.The proposed method offers advantages such as simple architecture, speed andsuitability for image processing while avoiding the complexities associatedwith traditional methods. The model comprises four main steps: area selection,scanning the chosen region, lesion diagnosis, and marking the identifiedlesion. Raw data for this research were collected from a reputable clinic inTehran specializing in skincare and beauty services. The dataset includesadministrative information, clinical data, and facial and profile images. Atotal of 2300 patient images were extracted from this raw data. A software toolwas developed to crop and label lesions, with input from two treatment experts.In the lesion preparation phase, the selected area was standardized to 50 * 50pixels. Subsequently, a convolutional neural network model was employed forlesion labeling. The classification model demonstrated high accuracy, with ameasure of 0.98 for healthy skin and 0.97 for lesioned skin specificity.Internal validation involved performance indicators and cross-validation, whileexternal validation compared the model's performance indicators with those ofthe transfer learning method using the Vgg16 deep network model. Compared toexisting studies, the results of this research showcase the efficacy anddesirability of the proposed model and methodology.</description><author>Reza Sarshar, Mohammad Heydari, Elham Akhondzadeh Noughabi</author><pubDate>Tue, 13 Feb 2024 16:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08592v1</guid></item><item><title>Faster Repeated Evasion Attacks in Tree Ensembles</title><link>http://arxiv.org/abs/2402.08586v1</link><description>Tree ensembles are one of the most widely used model classes. However, thesemodels are susceptible to adversarial examples, i.e., slightly perturbedexamples that elicit a misprediction. There has been significant research ondesigning approaches to construct such examples for tree ensembles. But this isa computationally challenging problem that often must be solved a large numberof times (e.g., for all examples in a training set). This is compounded by thefact that current approaches attempt to find such examples from scratch. Incontrast, we exploit the fact that multiple similar problems are being solved.Specifically, our approach exploits the insight that adversarial examples fortree ensembles tend to perturb a consistent but relatively small set offeatures. We show that we can quickly identify this set of features and usethis knowledge to speedup constructing adversarial examples.</description><author>Lorenzo Cascioli, Laurens Devos, Ondřej Kuželka, Jesse Davis</author><pubDate>Tue, 13 Feb 2024 16:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08586v1</guid></item><item><title>A Survey on Domain Generalization for Medical Image Analysis</title><link>http://arxiv.org/abs/2402.05035v2</link><description>Medical Image Analysis (MedIA) has emerged as a crucial tool incomputer-aided diagnosis systems, particularly with the advancement of deeplearning (DL) in recent years. However, well-trained deep models oftenexperience significant performance degradation when deployed in differentmedical sites, modalities, and sequences, known as a domain shift issue. Inlight of this, Domain Generalization (DG) for MedIA aims to address the domainshift challenge by generalizing effectively and performing robustly acrossunknown data distributions. This paper presents the a comprehensive review ofsubstantial developments in this area. First, we provide a formal definition ofdomain shift and domain generalization in medical field, and discuss severalrelated settings. Subsequently, we summarize the recent methods from threeviewpoints: data manipulation level, feature representation level, and modeltraining level, and present some algorithms in detail for each viewpoints.Furthermore, we introduce the commonly used datasets. Finally, we summarizeexisting literature and present some potential research topics for the future.For this survey, we also created a GitHub project by collecting the supportingresources, at the link: https://github.com/Ziwei-Niu/DG_for_MedIA</description><author>Ziwei Niu, Shuyi Ouyang, Shiao Xie, Yen-wei Chen, Lanfen Lin</author><pubDate>Tue, 13 Feb 2024 16:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05035v2</guid></item><item><title>Learn To be Efficient: Build Structured Sparsity in Large Language Models</title><link>http://arxiv.org/abs/2402.06126v2</link><description>Large Language Models (LLMs) have achieved remarkable success with theirbillion-level parameters, yet they incur high inference overheads. Theemergence of activation sparsity in LLMs provides a natural approach to reducethis cost by involving only parts of the parameters for inference. Existingmethods only focus on utilizing this naturally formed activation sparsity,overlooking the potential for further amplifying this inherent sparsity. Inthis paper, we hypothesize that LLMs can learn to be efficient by achievingmore structured activation sparsity. To achieve this, we introduce a novelalgorithm, Learn-To-be-Efficient (LTE), designed to train efficiency-aware LLMsto learn to activate fewer neurons and achieve a better trade-off betweensparsity and performance. Furthermore, unlike SOTA MoEfication methods, whichmainly focus on ReLU-based models, LTE can also be applied to LLMs like GPT andLLaMA with soft activation functions. We evaluate LTE on four models and elevendatasets. The experiments show that LTE achieves a better trade-off betweensparsity and task performance. For instance, LTE with LLaMA provides a1.83x-2.59x FLOPs speed-up on language generation tasks, outperforming thestate-of-the-art methods.</description><author>Haizhong Zheng, Xiaoyan Bai, Beidi Chen, Fan Lai, Atul Prakash</author><pubDate>Tue, 13 Feb 2024 16:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06126v2</guid></item><item><title>Mixture of Link Predictors</title><link>http://arxiv.org/abs/2402.08583v1</link><description>Link prediction, which aims to forecast unseen connections in graphs, is afundamental task in graph machine learning. Heuristic methods, leveraging arange of different pairwise measures such as common neighbors and shortestpaths, often rival the performance of vanilla Graph Neural Networks (GNNs).Therefore, recent advancements in GNNs for link prediction (GNN4LP) haveprimarily focused on integrating one or a few types of pairwise information. Inthis work, we reveal that different node pairs within the same datasetnecessitate varied pairwise information for accurate prediction and models thatonly apply the same pairwise information uniformly could achieve suboptimalperformance. As a result, we propose a simple mixture of experts model Link-MoEfor link prediction. Link-MoE utilizes various GNNs as experts andstrategically selects the appropriate expert for each node pair based onvarious types of pairwise information. Experimental results across diversereal-world datasets demonstrate substantial performance improvement fromLink-MoE. Notably, Link-MoE achieves a relative improvement of 18.82\% on theMRR metric for the Pubmed dataset and 10.8\% on the Hits@100 metric for theogbl-ppa dataset, compared to the best baselines.</description><author>Li Ma, Haoyu Han, Juanhui Li, Harry Shomer, Hui Liu, Xiaofeng Gao, Jiliang Tang</author><pubDate>Tue, 13 Feb 2024 16:36:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08583v1</guid></item><item><title>FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis</title><link>http://arxiv.org/abs/2402.08582v1</link><description>Medical image segmentation is a critical process in the field of medicalimaging, playing a pivotal role in diagnosis, treatment, and research. Itinvolves partitioning of an image into multiple regions, representing distinctanatomical or pathological structures. Conventional methods often grapple withthe challenge of balancing spatial precision and comprehensive featurerepresentation due to their reliance on traditional loss functions. To overcomethis, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), thatintegrates the benefits of contrastive learning (which extracts intricatefeatures, particularly in the nuanced domain of medical imaging) with thespatial accuracy inherent in the Dice loss. The objective is to augment bothspatial precision and feature-based representation in the segmentation ofmedical images. FESS Loss signifies a notable advancement, offering a moreaccurate and refined segmentation process, ultimately contributing toheightened precision in the analysis of medical images. Further, FESS lossdemonstrates superior performance in limited annotated data availabilityscenarios often present in the medical domain.</description><author>Charulkumar Chodvadiya, Navyansh Mahla, Kinshuk Gaurav Singh, Kshitij Sharad Jadhav</author><pubDate>Tue, 13 Feb 2024 16:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08582v1</guid></item><item><title>Improving Factual Error Correction for Abstractive Summarization via Data Distillation and Conditional-generation Cloze</title><link>http://arxiv.org/abs/2402.08581v1</link><description>Improving factual consistency in abstractive summarization has been a focusof current research. One promising approach is the post-editing method.However, previous works have yet to make sufficient use of factual factors insummaries and suffers from the negative effect of the training datasets. Inthis paper, we first propose a novel factual error correction model FactClozebased on a conditional-generation cloze task. FactCloze can construct thecausality among factual factors while being able to determine whether the blankcan be answered or not. Then, we propose a data distillation method to generatea more faithful summarization dataset SummDSC via multiple-dimensionalevaluation. We experimentally validate the effectiveness of our approach, whichleads to an improvement in multiple factual consistency metrics compared tobaselines.</description><author>Yiyang Li, Lei Li, Dingxin Hu, Xueyi Hao, Marina Litvak, Natalia Vanetik, Yanquan Zhou</author><pubDate>Tue, 13 Feb 2024 16:35:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08581v1</guid></item><item><title>Amortized Variational Inference: When and Why?</title><link>http://arxiv.org/abs/2307.11018v3</link><description>In a probabilistic latent variable model, factorized (or mean-field)variational inference (F-VI) fits a separate parametric distribution for eachlatent variable. Amortized variational inference (A-VI) instead learns a commoninference function, which maps each observation to its corresponding latentvariable's approximate posterior. Typically, A-VI is used as a cog in thetraining of variational autoencoders, however it stands to reason that A-VIcould also be used as a general alternative to F-VI. In this paper we studywhen and why A-VI can be used for approximate Bayesian inference. We deriveconditions on a latent variable model which are necessary, sufficient, andverifiable under which A-VI can attain F-VI's optimal solution, thereby closingthe amortization gap. We prove these conditions are uniquely verified by simplehierarchical models, a broad class that encompasses many models in machinelearning. We then show, on a broader class of models, how to expand the domainof AVI's inference function to improve its solution, and we provide examples,e.g. hidden Markov models, where the amortization gap cannot be closed.</description><author>Charles C. Margossian, David M. Blei</author><pubDate>Tue, 13 Feb 2024 16:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11018v3</guid></item><item><title>On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling</title><link>http://arxiv.org/abs/2402.05098v2</link><description>We study the problem of training diffusion models to sample from adistribution with a given unnormalized density or energy function. We benchmarkseveral diffusion-structured inference methods, including simulation-basedvariational approaches and off-policy methods (continuous generative flownetworks). Our results shed light on the relative advantages of existingalgorithms while bringing into question some claims from past work. We alsopropose a novel exploration strategy for off-policy methods, based on localsearch in the target space with the use of a replay buffer, and show that itimproves the quality of samples on a variety of target distributions. Our codefor the sampling methods and benchmarks studied is made public athttps://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusionmodels for amortized inference.</description><author>Marcin Sendera, Minsu Kim, Sarthak Mittal, Pablo Lemos, Luca Scimeca, Jarrid Rector-Brooks, Alexandre Adam, Yoshua Bengio, Nikolay Malkin</author><pubDate>Tue, 13 Feb 2024 16:32:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05098v2</guid></item><item><title>MatSynth: A Modern PBR Materials Dataset</title><link>http://arxiv.org/abs/2401.06056v2</link><description>We introduce MatSynth, a dataset of 4,000+ CC0 ultra-high resolution PBRmaterials. Materials are crucial components of virtual relightable assets,defining the interaction of light at the surface of geometries. Given theirimportance, significant research effort was dedicated to their representation,creation and acquisition. However, in the past 6 years, most research inmaterial acquisiton or generation relied either on the same unique dataset, oron company-owned huge library of procedural materials. With this dataset wepropose a significantly larger, more diverse, and higher resolution set ofmaterials than previously publicly available. We carefully discuss the datacollection process and demonstrate the benefits of this dataset on materialacquisition and generation applications. The complete data further containsmetadata with each material's origin, license, category, tags, creation methodand, when available, descriptions and physical size, as well as 3M+ renderingsof the augmented materials, in 1K, under various environment lightings. TheMatSynth dataset is released through the project page at:https://www.gvecchio.com/matsynth.</description><author>Giuseppe Vecchio, Valentin Deschaintre</author><pubDate>Tue, 13 Feb 2024 16:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06056v2</guid></item><item><title>Training Coupled Phase Oscillators as a Neuromorphic Platform using Equilibrium Propagation</title><link>http://arxiv.org/abs/2402.08579v1</link><description>Given the rapidly growing scale and resource requirements of machine learningapplications, the idea of building more efficient learning machines much closerto the laws of physics is an attractive proposition. One central question foridentifying promising candidates for such neuromorphic platforms is whether notonly inference but also training can exploit the physical dynamics. In thiswork, we show that it is possible to successfully train a system of coupledphase oscillators - one of the most widely investigated nonlinear dynamicalsystems with a multitude of physical implementations, comprising laser arrays,coupled mechanical limit cycles, superfluids, and exciton-polaritons. To thisend, we apply the approach of equilibrium propagation, which permits to extracttraining gradients via a physical realization of backpropagation, based only onlocal interactions. The complex energy landscape of the XY/ Kuramoto modelleads to multistability, and we show how to address this challenge. Our studyidentifies coupled phase oscillators as a new general-purpose neuromorphicplatform and opens the door towards future experimental implementations.</description><author>Qingshan Wang, Clara C. Wanjura, Florian Marquardt</author><pubDate>Tue, 13 Feb 2024 16:31:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08579v1</guid></item><item><title>FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local Parameter Sharing</title><link>http://arxiv.org/abs/2402.08578v1</link><description>Federated Learning (FL) has emerged as a promising solution in Edge Computing(EC) environments to process the proliferation of data generated by edgedevices. By collaboratively optimizing the global machine learning models ondistributed edge devices, FL circumvents the need for transmitting raw data andenhances user privacy. Despite practical successes, FL still confrontssignificant challenges including constrained edge device resources, multipletasks deployment, and data heterogeneity. However, existing studies focus onmitigating the FL training costs of each single task whereas neglecting theresource consumption across multiple tasks in heterogeneous FL scenarios. Inthis paper, we propose Heterogeneous Federated Learning with Local ParameterSharing (FedLPS) to fill this gap. FedLPS leverages principles from transferlearning to facilitate the deployment of multiple tasks on a single device bydividing the local model into a shareable encoder and task-specific encoders.To further reduce resource consumption, a channel-wise model pruning algorithmthat shrinks the footprint of local models while accounting for both data andsystem heterogeneity is employed in FedLPS. Additionally, a novel heterogeneousmodel aggregation algorithm is proposed to aggregate the heterogeneouspredictors in FedLPS. We implemented the proposed FedLPS on a real FL platformand compared it with state-of-the-art (SOTA) FL frameworks. The experimentalresults on five popular datasets and two modern DNN models illustrate that theproposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88%and reduces the computational resource consumption by 21.3%. Our code isavailable at:https://github.com/jyzgh/FedLPS.</description><author>Yongzhe Jia, Xuyun Zhang, Amin Beheshti, Wanchun Dou</author><pubDate>Tue, 13 Feb 2024 16:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08578v1</guid></item><item><title>Test-Time Backdoor Attacks on Multimodal Large Language Models</title><link>http://arxiv.org/abs/2402.08577v1</link><description>Backdoor attacks are commonly executed by contaminating training data, suchthat a trigger can activate predetermined harmful effects during the testphase. In this work, we present AnyDoor, a test-time backdoor attack againstmultimodal large language models (MLLMs), which involves injecting the backdoorinto the textual modality using adversarial test images (sharing the sameuniversal perturbation), without requiring access to or modification of thetraining data. AnyDoor employs similar techniques used in universal adversarialattacks, but distinguishes itself by its ability to decouple the timing ofsetup and activation of harmful effects. In our experiments, we validate theeffectiveness of AnyDoor against popular MLLMs such as LLaVA-1.5, MiniGPT-4,InstructBLIP, and BLIP-2, as well as provide comprehensive ablation studies.Notably, because the backdoor is injected by a universal perturbation, AnyDoorcan dynamically change its backdoor trigger prompts/harmful effects, exposing anew challenge for defending against backdoor attacks. Our project page isavailable at https://sail-sg.github.io/AnyDoor/.</description><author>Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin</author><pubDate>Tue, 13 Feb 2024 16:28:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08577v1</guid></item><item><title>Deep Active Learning with Noise Stability</title><link>http://arxiv.org/abs/2205.13340v2</link><description>Uncertainty estimation for unlabeled data is crucial to active learning. Witha deep neural network employed as the backbone model, the data selectionprocess is highly challenging due to the potential over-confidence of the modelinference. Existing methods resort to special learning fashions (e.g.adversarial) or auxiliary models to address this challenge. This tends toresult in complex and inefficient pipelines, which would render the methodsimpractical. In this work, we propose a novel algorithm that leverages noisestability to estimate data uncertainty. The key idea is to measure the outputderivation from the original observation when the model parameters are randomlyperturbed by noise. We provide theoretical analyses by leveraging the smallGaussian noise theory and demonstrate that our method favors a subset withlarge and diverse gradients. Our method is generally applicable in varioustasks, including computer vision, natural language processing, and structuraldata analysis. It achieves competitive performance compared againststate-of-the-art active learning baselines.</description><author>Xingjian Li, Pengkun Yang, Yangcheng Gu, Xueying Zhan, Tianyang Wang, Min Xu, Chengzhong Xu</author><pubDate>Tue, 13 Feb 2024 16:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.13340v2</guid></item><item><title>Regret Minimization in Stackelberg Games with Side Information</title><link>http://arxiv.org/abs/2402.08576v1</link><description>In its most basic form, a Stackelberg game is a two-player game in which aleader commits to a (mixed) strategy, and a follower best-responds. Stackelberggames are perhaps one of the biggest success stories of algorithmic game theoryover the last decade, as algorithms for playing in Stackelberg games have beendeployed in many real-world domains including airport security, anti-poachingefforts, and cyber-crime prevention. However, these algorithms often fail totake into consideration the additional information available to each player(e.g. traffic patterns, weather conditions, network congestion), a salientfeature of reality which may significantly affect both players' optimalstrategies. We formalize such settings as Stackelberg games with sideinformation, in which both players observe an external context before playing.The leader then commits to a (possibly context-dependent) strategy, and thefollower best-responds to both the leader's strategy and the context. We focuson the online setting in which a sequence of followers arrive over time, andthe context may change from round-to-round. In sharp contrast to thenon-contextual version, we show that it is impossible for the leader to achievegood performance (measured by regret) in the full adversarial setting (i.e.,when both the context and the follower are chosen by an adversary). However, itturns out that a little bit of randomness goes a long way. Motivated by ourimpossibility result, we show that no-regret learning is possible in twonatural relaxations: the setting in which the sequence of followers is chosenstochastically and the sequence of contexts is adversarial, and the setting inwhich the sequence of contexts is stochastic and the sequence of followers ischosen by an adversary.</description><author>Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan</author><pubDate>Tue, 13 Feb 2024 16:24:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08576v1</guid></item><item><title>Two Tales of Single-Phase Contrastive Hebbian Learning</title><link>http://arxiv.org/abs/2402.08573v1</link><description>The search for "biologically plausible" learning algorithms has converged onthe idea of representing gradients as activity differences. However, mostapproaches require a high degree of synchronization (distinct phases duringlearning) and introduce substantial computational overhead, which raises doubtsregarding their biological plausibility as well as their potential utility forneuromorphic computing. Furthermore, they commonly rely on applyinginfinitesimal perturbations (nudges) to output units, which is impractical innoisy environments. Recently it has been shown that by modelling artificialneurons as dyads with two oppositely nudged compartments, it is possible for afully local learning algorithm named ``dual propagation'' to bridge theperformance gap to backpropagation, without requiring separate learning phasesor infinitesimal nudging. However, the algorithm has the drawback that itsnumerical stability relies on symmetric nudging, which may be restrictive inbiological and analog implementations. In this work we first provide a solidfoundation for the objective underlying the dual propagation method, which alsoreveals a surprising connection with adversarial robustness. Second, wedemonstrate how dual propagation is related to a particular adjoint statemethod, which is stable regardless of asymmetric nudging.</description><author>Rasmus Kjær Høier, Christopher Zach</author><pubDate>Tue, 13 Feb 2024 16:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08573v1</guid></item><item><title>This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models</title><link>http://arxiv.org/abs/2305.14610v3</link><description>Do the Spratly Islands belong to China, the Philippines, or Vietnam? Apretrained large language model (LLM) may answer differently if asked in thelanguages of each claimant country: Chinese, Tagalog, or Vietnamese. Thiscontrasts with a multilingual human, who would likely answer consistently. Inthis paper, we show that LLMs recall certain geographical knowledgeinconsistently when queried in different languages--a phenomenon we termgeopolitical bias. As a targeted case study, we consider territorial disputes,an inherently controversial and multilingual task. We introduce BorderLines, adataset of territorial disputes which covers 251 territories, each associatedwith a set of multiple-choice questions in the languages of each claimantcountry (49 languages in total). We also propose a suite of evaluation metricsto precisely quantify bias and consistency in responses across differentlanguages. We then evaluate various multilingual LLMs on our dataset andmetrics to probe their internal knowledge and use the proposed metrics todiscover numerous inconsistencies in how these models respond in differentlanguages. Finally, we explore several prompt modification strategies, aimingto either amplify or mitigate geopolitical bias, which highlights how brittleLLMs are and how they tailor their responses depending on cues from theinteraction context.</description><author>Bryan Li, Samar Haider, Chris Callison-Burch</author><pubDate>Tue, 13 Feb 2024 16:18:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14610v3</guid></item><item><title>Tree Search in DAG Space with Model-based Reinforcement Learning for Causal Discovery</title><link>http://arxiv.org/abs/2310.13576v2</link><description>Identifying causal structure is central to many fields ranging from strategicdecision-making to biology and economics. In this work, we propose CD-UCT, amodel-based reinforcement learning method for causal discovery based on treesearch that builds directed acyclic graphs incrementally. We also formalize andprove the correctness of an efficient algorithm for excluding edges that wouldintroduce cycles, which enables deeper discrete search and sampling in DAGspace. The proposed method can be applied broadly to causal Bayesian networkswith both discrete and continuous random variables. We conduct a comprehensiveevaluation on synthetic and real-world datasets, showing that CD-UCTsubstantially outperforms the state-of-the-art model-free reinforcementlearning technique and greedy search, constituting a promising advancement forcombinatorial methods.</description><author>Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi</author><pubDate>Tue, 13 Feb 2024 16:18:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13576v2</guid></item><item><title>Online Foundation Model Selection in Robotics</title><link>http://arxiv.org/abs/2402.08570v1</link><description>Foundation models have recently expanded into robotics after excelling incomputer vision and natural language processing. The models are accessible intwo ways: open-source or paid, closed-source options. Users with access to bothface a problem when deciding between effective yet costly closed-source modelsand free but less powerful open-source alternatives. We call it the modelselection problem. Existing supervised-learning methods are impractical due tothe high cost of collecting extensive training data from closed-source models.Hence, we focus on the online learning setting where algorithms learn whilecollecting data, eliminating the need for large pre-collected datasets. We thusformulate a user-centric online model selection problem and propose a novelsolution that combines an open-source encoder to output context and an onlinelearning algorithm that processes this context. The encoder distills vast datadistributions into low-dimensional features, i.e., the context, withoutadditional training. The online learning algorithm aims to maximize a compositereward that includes model performance, execution time, and costs based on thecontext extracted from the data. It results in an improved trade-off betweenselecting open-source and closed-source models compared to non-contextualmethods, as validated by our theoretical analysis. Experiments acrosslanguage-based robotic tasks such as Waymo Open Dataset, ALFRED, and OpenX-Embodiment demonstrate real-world applications of the solution. The resultsshow that the solution significantly improves the task success rate by up to14%.</description><author>Po-han Li, Oyku Selin Toprak, Aditya Narayanan, Ufuk Topcu, Sandeep Chinchali</author><pubDate>Tue, 13 Feb 2024 16:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08570v1</guid></item><item><title>Glass Segmentation with Multi Scales and Primary Prediction Guiding</title><link>http://arxiv.org/abs/2402.08571v1</link><description>Glass-like objects can be seen everywhere in our daily life which are veryhard for existing methods to segment them. The properties of transparenciespose great challenges of detecting them from the chaotic background and thevague separation boundaries further impede the acquisition of their exactcontours. Moving machines which ignore glasses have great risks of crashinginto transparent barriers or difficulties in analysing objects reflected in themirror, thus it is of substantial significance to accurately locate glass-likeobjects and completely figure out their contours. In this paper, inspired bythe scale integration strategy and the refinement method, we proposed abrand-new network, named as MGNet, which consists of a Fine-Rescaling andMerging module (FRM) to improve the ability to extract spatially relationshipand a Primary Prediction Guiding module (PPG) to better mine the leftoversemantics from the fused features. Moreover, we supervise the model with anovel loss function with the uncertainty-aware loss to produce high-confidencesegmentation maps. Unlike the existing glass segmentation models that must betrained on different settings with respect to varied datasets, our model aretrained under consistent settings and has achieved superior performance onthree popular public datasets. Code is available at</description><author>Zhiyu Xu, Qingliang Chen</author><pubDate>Tue, 13 Feb 2024 16:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08571v1</guid></item><item><title>Interpreting and Improving Diffusion Models Using the Euclidean Distance Function</title><link>http://arxiv.org/abs/2306.04848v3</link><description>Denoising is intuitively related to projection. Indeed, under the manifoldhypothesis, adding random noise is approximately equivalent to orthogonalperturbation. Hence, learning to denoise is approximately learning to project.In this paper, we use this observation to reinterpret denoising diffusionmodels as approximate gradient descent applied to the Euclidean distancefunction. We then provide straight-forward convergence analysis of the DDIMsampler under simple assumptions on the projection-error of the denoiser.Finally, we propose a new sampler based on two simple modifications to DDIMusing insights from our theoretical results. In as few as 5-10 functionevaluations, our sampler achieves state-of-the-art FID scores on pretrainedCIFAR-10 and CelebA models and can generate high quality samples on latentdiffusion models.</description><author>Frank Permenter, Chenyang Yuan</author><pubDate>Tue, 13 Feb 2024 16:08:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04848v3</guid></item><item><title>Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast</title><link>http://arxiv.org/abs/2402.08567v1</link><description>A multimodal large language model (MLLM) agent can receive instructions,capture images, retrieve histories from memory, and decide which tools to use.Nonetheless, red-teaming efforts have revealed that adversarial images/promptscan jailbreak an MLLM and cause unaligned behaviors. In this work, we report aneven more severe safety issue in multi-agent environments, referred to asinfectious jailbreak. It entails the adversary simply jailbreaking a singleagent, and without any further intervention from the adversary, (almost) allagents will become infected exponentially fast and exhibit harmful behaviors.To validate the feasibility of infectious jailbreak, we simulate multi-agentenvironments containing up to one million LLaVA-1.5 agents, and employrandomized pair-wise chat as a proof-of-concept instantiation for multi-agentinteraction. Our results show that feeding an (infectious) adversarial imageinto the memory of any randomly chosen agent is sufficient to achieveinfectious jailbreak. Finally, we derive a simple principle for determiningwhether a defense mechanism can provably restrain the spread of infectiousjailbreak, but how to design a practical defense that meets this principleremains an open question to investigate. Our project page is available athttps://sail-sg.github.io/Agent-Smith/.</description><author>Xiangming Gu, Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Ye Wang, Jing Jiang, Min Lin</author><pubDate>Tue, 13 Feb 2024 16:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08567v1</guid></item><item><title>Algebraic methods for solving recognition problems with non-crossing classes</title><link>http://arxiv.org/abs/2401.13666v2</link><description>In this paper, we propose to consider various models of pattern recognition.At the same time, it is proposed to consider models in the form of twooperators: a recognizing operator and a decision rule. Algebraic operations areintroduced on recognizing operators, and based on the application of theseoperators, a family of recognizing algorithms is created. An upper estimate isconstructed for the model, which guarantees the completeness of the extension.</description><author>Anvar Kabulov, Alimdzhan Babadzhanov, Islambek Saymanov</author><pubDate>Tue, 13 Feb 2024 16:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13666v2</guid></item><item><title>Artificial Intelligence for Literature Reviews: Opportunities and Challenges</title><link>http://arxiv.org/abs/2402.08565v1</link><description>This manuscript presents a comprehensive review of the use of ArtificialIntelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorousand organised methodology that assesses and integrates previous research on agiven topic. Numerous tools have been developed to assist and partiallyautomate the SLR process. The increasing role of AI in this field shows greatpotential in providing more effective support for researchers, moving towardsthe semi-automatic creation of literature reviews. Our study focuses on how AItechniques are applied in the semi-automation of SLRs, specifically in thescreening and extraction phases. We examine 21 leading SLR tools using aframework that combines 23 traditional features with 11 AI features. We alsoanalyse 11 recent tools that leverage large language models for searching theliterature and assisting academic writing. Finally, the paper discusses currenttrends in the field, outlines key research challenges, and suggests directionsfor future research.</description><author>Francisco Bolanos, Angelo Salatino, Francesco Osborne, Enrico Motta</author><pubDate>Tue, 13 Feb 2024 16:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08565v1</guid></item><item><title>Logical recognition method for solving the problem of identification in the Internet of Things</title><link>http://arxiv.org/abs/2402.04338v2</link><description>A new area of application of methods of algebra of logic and to valued logic,which has emerged recently, is the problem of recognizing a variety of objectsand phenomena, medical or technical diagnostics, constructing modern machines,checking test problems, etc., which can be reduced to constructing an optimalextension of the logical function to the entire feature space. For example, inlogical recognition systems, logical methods based on discrete analysis andpropositional calculus based on it are used to build their own recognitionalgorithms. In the general case, the use of a logical recognition methodprovides for the presence of logical connections expressed by the optimalcontinuation of a k-valued function over the entire feature space, in which thevariables are the logical features of the objects or phenomena beingrecognized. The goal of this work is to develop a logical method for objectrecognition consisting of a reference table with logical features and classesof non-intersecting objects, which are specified as vectors from a givenfeature space. The method consists of considering the reference table as alogical function that is not defined everywhere and constructing an optimalcontinuation of the logical function to the entire feature space, whichdetermines the extension of classes to the entire space.</description><author>Islambek Saymanov</author><pubDate>Tue, 13 Feb 2024 16:05:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04338v2</guid></item><item><title>Denoising Diffusion Restoration Tackles Forward and Inverse Problems for the Laplace Operator</title><link>http://arxiv.org/abs/2402.08563v1</link><description>Diffusion models have emerged as a promising class of generative models thatmap noisy inputs to realistic images. More recently, they have been employed togenerate solutions to partial differential equations (PDEs). However, theystill struggle with inverse problems in the Laplacian operator, for instance,the Poisson equation, because the eigenvalues that are large in magnitudeamplify the measurement noise. This paper presents a novel approach for theinverse and forward solution of PDEs through the use of denoising diffusionrestoration models (DDRM). DDRMs were used in linear inverse problems torestore original clean signals by exploiting the singular value decomposition(SVD) of the linear operator. Equivalently, we present an approach to restorethe solution and the parameters in the Poisson equation by exploiting theeigenvalues and the eigenfunctions of the Laplacian operator. Our results showthat using denoising diffusion restoration significantly improves theestimation of the solution and parameters. Our research, as a result, pioneersthe integration of diffusion models with the principles of underlying physicsto solve PDEs.</description><author>Amartya Mukherjee, Melissa M. Stadt, Lena Podina, Mohammad Kohandel, Jun Liu</author><pubDate>Tue, 13 Feb 2024 16:04:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08563v1</guid></item><item><title>Higher Layers Need More LoRA Experts</title><link>http://arxiv.org/abs/2402.08562v1</link><description>Parameter-efficient tuning (PEFT) techniques like low-rank adaptation (LoRA)offer training efficiency on Large Language Models, but their impact on modelperformance remains limited. Recent efforts integrate LoRA andMixture-of-Experts (MoE) to improve the performance of PEFT methods. Despitepromising results, research on improving the efficiency of LoRA with MoE isstill in its early stages. Recent studies have shown that experts in the MoEarchitecture have different strengths and also exhibit some redundancy. Doesthis statement also apply to parameter-efficient MoE? In this paper, weintroduce a novel parameter-efficient MoE method,\textit{\textbf{M}oE-L\textbf{o}RA with \textbf{L}ayer-wise Expert\textbf{A}llocation (MoLA)} for Transformer-based models, where each modellayer has the flexibility to employ a varying number of LoRA experts. Weinvestigate several architectures with varying layer-wise expertconfigurations. Experiments on six well-known NLP and commonsense QA benchmarksdemonstrate that MoLA achieves equal or superior performance compared to allbaselines. We find that allocating more LoRA experts to higher layers furtherenhances the effectiveness of models with a certain number of experts in total.With much fewer parameters, this allocation strategy outperforms the settingwith the same number of experts in every layer. This work can be widely used asa plug-and-play parameter-efficient tuning approach for various applications.The code is available at https://github.com/GCYZSL/MoLA.</description><author>Chongyang Gao, Kezhen Chen, Jinmeng Rao, Baochen Sun, Ruibo Liu, Daiyi Peng, Yawen Zhang, Xiaoyuan Guo, Jie Yang, VS Subrahmanian</author><pubDate>Tue, 13 Feb 2024 16:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08562v1</guid></item><item><title>Learning Weakly Supervised Audio-Visual Violence Detection in Hyperbolic Space</title><link>http://arxiv.org/abs/2305.18797v3</link><description>In recent years, the task of weakly supervised audio-visual violencedetection has gained considerable attention. The goal of this task is toidentify violent segments within multimodal data based on video-level labels.Despite advances in this field, traditional Euclidean neural networks, whichhave been used in prior research, encounter difficulties in capturing highlydiscriminative representations due to limitations of the feature space. Toovercome this, we propose HyperVD, a novel framework that learns snippetembeddings in hyperbolic space to improve model discrimination. Our frameworkcomprises a detour fusion module for multimodal fusion, effectively alleviatingmodality inconsistency between audio and visual signals. Additionally, wecontribute two branches of fully hyperbolic graph convolutional networks thatexcavate feature similarities and temporal relationships among snippets inhyperbolic space. By learning snippet representations in this space, theframework effectively learns semantic discrepancies between violent and normalevents. Extensive experiments on the XD-Violence benchmark demonstrate that ourmethod outperforms state-of-the-art methods by a sizable margin.</description><author>Xiaogang Peng, Hao Wen, Yikai Luo, Xiao Zhou, Keyang Yu, Ping Yang, Zizhao Wu</author><pubDate>Tue, 13 Feb 2024 16:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18797v3</guid></item><item><title>Efficient Resource Scheduling for Distributed Infrastructures Using Negotiation Capabilities</title><link>http://arxiv.org/abs/2402.06938v2</link><description>In the past few decades, the rapid development of information and internettechnologies has spawned massive amounts of data and information. Theinformation explosion drives many enterprises or individuals to seek to rentcloud computing infrastructure to put their applications in the cloud. However,the agreements reached between cloud computing providers and clients are oftennot efficient. Many factors affect the efficiency, such as the idleness of theproviders' cloud computing infrastructure, and the additional cost to theclients. One possible solution is to introduce a comprehensive, bargaining game(a type of negotiation), and schedule resources according to the negotiationresults. We propose an agent-based auto-negotiation system for resourcescheduling based on fuzzy logic. The proposed method can complete a one-to-oneauto-negotiation process and generate optimal offers for the provider andclient. We compare the impact of different member functions, fuzzy rule sets,and negotiation scenario cases on the offers to optimize the system. It can beconcluded that our proposed method can utilize resources more efficiently andis interpretable, highly flexible, and customizable. We successfully trainmachine learning models to replace the fuzzy negotiation system to improveprocessing speed. The article also highlights possible future improvements tothe proposed system and machine learning models. All the codes and data areavailable in the open-source repository.</description><author>Junjie Chu, Prashant Singh, Salman Toor</author><pubDate>Tue, 13 Feb 2024 15:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06938v2</guid></item><item><title>Confronting Reward Overoptimization for Diffusion Models: A Perspective of Inductive and Primacy Biases</title><link>http://arxiv.org/abs/2402.08552v1</link><description>Bridging the gap between diffusion models and human preferences is crucialfor their integration into practical generative workflows. While optimizingdownstream reward models has emerged as a promising alignment strategy,concerns arise regarding the risk of excessive optimization with learned rewardmodels, which potentially compromises ground-truth performance. In this work,we confront the reward overoptimization problem in diffusion model alignmentthrough the lenses of both inductive and primacy biases. We first identify thedivergence of current methods from the temporal inductive bias inherent in themulti-step denoising process of diffusion models as a potential source ofoveroptimization. Then, we surprisingly discover that dormant neurons in ourcritic model act as a regularization against overoptimization, while activeneurons reflect primacy bias in this setting. Motivated by these observations,we propose Temporal Diffusion Policy Optimization with critic active neuronReset (TDPO-R), a policy gradient algorithm that exploits the temporalinductive bias of intermediate timesteps, along with a novel reset strategythat targets active neurons to counteract the primacy bias. Empirical resultsdemonstrate the superior efficacy of our algorithms in mitigating rewardoveroptimization.</description><author>Ziyi Zhang, Sen Zhang, Yibing Zhan, Yong Luo, Yonggang Wen, Dacheng Tao</author><pubDate>Tue, 13 Feb 2024 15:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08552v1</guid></item><item><title>Dueling Over Dessert, Mastering the Art of Repeated Cake Cutting</title><link>http://arxiv.org/abs/2402.08547v1</link><description>We consider the setting of repeated fair division between two players,denoted Alice and Bob, with private valuations over a cake. In each round, anew cake arrives, which is identical to the ones in previous rounds. Alice cutsthe cake at a point of her choice, while Bob chooses the left piece or theright piece, leaving the remainder for Alice. We consider two versions:sequential, where Bob observes Alice's cut point before choosing left/right,and simultaneous, where he only observes her cut point after making his choice.The simultaneous version was first considered by Aumann and Maschler (1995). We observe that if Bob is almost myopic and chooses his favorite piece toooften, then he can be systematically exploited by Alice through a strategy akinto a binary search. This strategy allows Alice to approximate Bob's preferenceswith increasing precision, thereby securing a disproportionate share of theresource over time. We analyze the limits of how much a player can exploit the other one and showthat fair utility profiles are in fact achievable. Specifically, the playerscan enforce the equitable utility profile of $(1/2, 1/2)$ in the limit on everytrajectory of play, by keeping the other player's utility to approximately$1/2$ on average while guaranteeing they themselves get at least approximately$1/2$ on average. We show this theorem using a connection with Blackwellapproachability. Finally, we analyze a natural dynamic known as fictitious play, where playersbest respond to the empirical distribution of the other player. We show thatfictitious play converges to the equitable utility profile of $(1/2, 1/2)$ at arate of $O(1/\sqrt{T})$.</description><author>Simina Brânzei, MohammadTaghi Hajiaghayi, Reed Phillips, Suho Shin, Kun Wang</author><pubDate>Tue, 13 Feb 2024 15:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08547v1</guid></item><item><title>Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees</title><link>http://arxiv.org/abs/2402.00899v3</link><description>We present a new methodology for handling AI errors by introducing weaklysupervised AI error correctors with a priori performance guarantees. These AIcorrectors are auxiliary maps whose role is to moderate the decisions of somepreviously constructed underlying classifier by either approving or rejectingits decisions. The rejection of a decision can be used as a signal to suggestabstaining from making a decision. A key technical focus of the work is inproviding performance guarantees for these new AI correctors through bounds onthe probabilities of incorrect decisions. These bounds are distributionagnostic and do not rely on assumptions on the data dimension. Our empiricalexample illustrates how the framework can be applied to improve the performanceof an image classifier in a challenging real-world task where training data arescarce.</description><author>Ivan Y. Tyukin, Tatiana Tyukina, Daniel van Helden, Zedong Zheng, Evgeny M. Mirkes, Oliver J. Sutton, Qinghua Zhou, Alexander N. Gorban, Penelope Allison</author><pubDate>Tue, 13 Feb 2024 15:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00899v3</guid></item><item><title>Towards a Certified Proof Checker for Deep Neural Network Verification</title><link>http://arxiv.org/abs/2307.06299v2</link><description>Recent developments in deep neural networks (DNNs) have led to their adoptionin safety-critical systems, which in turn has heightened the need forguaranteeing their safety. These safety properties of DNNs can be proven usingtools developed by the verification community. However, these tools arethemselves prone to implementation bugs and numerical stability problems, whichmake their reliability questionable. To overcome this, some verifiers produceproofs of their results which can be checked by a trusted checker. In thiswork, we present a novel implementation of a proof checker for DNNverification. It improves on existing implementations by offering numericalstability and greater verifiability. To achieve this, we leverage two keycapabilities of Imandra, an industrial theorem prover: its support of infiniteprecision real arithmetic and its formal verification infrastructure. So far,we have implemented a proof checker in Imandra, specified its correctnessproperties and started to verify the checker's compliance with them. Ourongoing work focuses on completing the formal verification of the checker andfurther optimizing its performance.</description><author>Remi Desmartin, Omri Isac, Grant Passmore, Kathrin Stark, Guy Katz, Ekaterina Komendantskaya</author><pubDate>Tue, 13 Feb 2024 15:51:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06299v2</guid></item><item><title>Setting the Record Straight on Transformer Oversmoothing</title><link>http://arxiv.org/abs/2401.04301v2</link><description>Transformer-based models have recently become wildly successful across adiverse set of domains. At the same time, recent work has argued thatTransformers are inherently low-pass filters that gradually oversmooth theinputs. This is worrisome as it limits generalization, especially as modeldepth increases. A natural question is: How can Transformers achieve thesesuccesses given this shortcoming? In this work we show that in factTransformers are not inherently low-pass filters. Instead, whether Transformersoversmooth or not depends on the eigenspectrum of their update equations.Further, depending on the task, smoothing does not harm generalization as modeldepth increases. Our analysis extends prior work in oversmoothing and in theclosely-related phenomenon of rank collapse. Based on this analysis, we derivea simple way to parameterize the weights of the Transformer update equationsthat allows for control over its filtering behavior. For image classificationtasks we show that smoothing, instead of sharpening, can improvegeneralization. Whereas for text generation tasks Transformers that are forcedto either smooth or sharpen have worse generalization. We hope that this workgives ML researchers and practitioners additional insight and leverage whendeveloping future Transformer models.</description><author>Gbètondji J-S Dovonon, Michael M. Bronstein, Matt J. Kusner</author><pubDate>Tue, 13 Feb 2024 15:48:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04301v2</guid></item><item><title>Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings</title><link>http://arxiv.org/abs/2402.08543v1</link><description>Despite a large and significant body of recent work focused on estimating theout-of-sample risk of regularized models in the high dimensional regime, atheoretical understanding of this problem for non-differentiable penalties suchas generalized LASSO and nuclear norm is missing. In this paper we resolve thischallenge. We study this problem in the proportional high dimensional regimewhere both the sample size n and number of features p are large, and n/p andthe signal-to-noise ratio (per observation) remain finite. We provide finitesample upper bounds on the expected squared error of leave-one-outcross-validation (LO) in estimating the out-of-sample risk. The theoreticalframework presented here provides a solid foundation for elucidating empiricalfindings that show the accuracy of LO.</description><author>Haolin Zou, Arnab Auddy, Kamiar Rahnama Rad, Arian Maleki</author><pubDate>Tue, 13 Feb 2024 15:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08543v1</guid></item><item><title>Generative VS non-Generative Models in Engineering Shape Optimization</title><link>http://arxiv.org/abs/2402.08540v1</link><description>In this work, we perform a systematic comparison of the effectiveness andefficiency of generative and non-generative models in constructing designspaces for novel and efficient design exploration and shape optimization. Weapply these models in the case of airfoil/hydrofoil design and conduct thecomparison on the resulting design spaces. A conventional GenerativeAdversarial Network (GAN) and a state-of-the-art generative model, thePerformance-Augmented Diverse Generative Adversarial Network (PaDGAN), arejuxtaposed with a linear non-generative model based on the coupling of theKarhunen-Lo\`eve Expansion and a physics-informed Shape Signature Vector(SSV-KLE). The comparison demonstrates that, with an appropriate shape encodingand a physics-augmented design space, non-generative models have the potentialto cost-effectively generate high-performing valid designs with enhancedcoverage of the design space. In this work, both approaches are applied to twolarge foil profile datasets comprising real-world and artificial designsgenerated through either a profile-generating parametric model or deep-learningapproach. These datasets are further enriched with integral properties of theirmembers' shapes as well as physics-informed parameters. Our results illustratethat the design spaces constructed by the non-generative model outperform thegenerative model in terms of design validity, generating robust latent spaceswith none or significantly fewer invalid designs when compared to generativemodels. We aspire that these findings will aid the engineering design communityin making informed decisions when constructing designs spaces for shapeoptimization, as we have show that under certain conditions computationallyinexpensive approaches can closely match or even outperform state-of-the artgenerative models.</description><author>Muhammad Usama, Zahid Masood, Shahroz Khan, Konstantinos Kostas, Panagiotis Kaklis</author><pubDate>Tue, 13 Feb 2024 15:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08540v1</guid></item><item><title>Intelligent Diagnosis of Alzheimer's Disease Based on Machine Learning</title><link>http://arxiv.org/abs/2402.08539v1</link><description>This study is based on the Alzheimer's Disease Neuroimaging Initiative (ADNI)dataset and aims to explore early detection and disease progression inAlzheimer's disease (AD). We employ innovative data preprocessing strategies,including the use of the random forest algorithm to fill missing data and thehandling of outliers and invalid data, thereby fully mining and utilizing theselimited data resources. Through Spearman correlation coefficient analysis, weidentify some features strongly correlated with AD diagnosis. We build and testthree machine learning models using these features: random forest, XGBoost, andsupport vector machine (SVM). Among them, the XGBoost model performs the bestin terms of diagnostic performance, achieving an accuracy of 91%. Overall, thisstudy successfully overcomes the challenge of missing data and providesvaluable insights into early detection of Alzheimer's disease, demonstratingits unique research value and practical significance.</description><author>Mingyang Li, Hongyu Liu, Yixuan Li, Zejun Wang, Yuan Yuan, Honglin Dai</author><pubDate>Tue, 13 Feb 2024 15:43:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08539v1</guid></item><item><title>Hypercomplex neural network in time series forecasting of stock data</title><link>http://arxiv.org/abs/2401.04632v2</link><description>The goal of this paper is to test three classes of neural network (NN)architectures based on four-dimensional (4D) hypercomplex algebras for timeseries prediction. We evaluate different architectures, varying the inputlayers to include convolutional, Long Short-Term Memory (LSTM), or densehypercomplex layers for 4D algebras. Four related Stock Market time series areused as input data, with the prediction focused on one of them. Hyperparameteroptimization for each architecture class was conducted to compare thebest-performing neural networks within each class. The results indicate that,in most cases, architectures with hypercomplex dense layers achieve similarMean Absolute Error (MAE) accuracy compared to other architectures, but withsignificantly fewer trainable parameters. Consequently, hypercomplex neuralnetworks demonstrate the ability to learn and process time series data fasterthan the other tested architectures. Additionally, it was found that theordering of the input time series have a notable impact on effectiveness.</description><author>Radosław Kycia, Agnieszka Niemczynowicz</author><pubDate>Tue, 13 Feb 2024 15:43:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04632v2</guid></item><item><title>Nonlinear Processing with Linear Optics</title><link>http://arxiv.org/abs/2307.08533v3</link><description>Deep neural networks have achieved remarkable breakthroughs by leveragingmultiple layers of data processing to extract hidden representations, albeit atthe cost of large electronic computing power. To enhance energy efficiency andspeed, the optical implementation of neural networks aims to harness theadvantages of optical bandwidth and the energy efficiency of opticalinterconnections. In the absence of low-power optical nonlinearities, thechallenge in the implementation of multilayer optical networks lies inrealizing multiple optical layers without resorting to electronic components.In this study, we present a novel framework that uses multiple scattering thatis capable of synthesizing programmable linear and nonlinear transformationsconcurrently at low optical power by leveraging the nonlinear relationshipbetween the scattering potential, represented by data, and the scattered field.Theoretical and experimental investigations show that repeating the data bymultiple scattering enables non-linear optical computing at low powercontinuous wave light. Moreover, we empirically found that scaling of thisoptical framework follows the power law as in state-of-the-art deep digitalnetworks.</description><author>Mustafa Yildirim, Niyazi Ulas Dinc, Ilker Oguz, Demetri Psaltis, Christophe Moser</author><pubDate>Tue, 13 Feb 2024 15:42:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08533v3</guid></item><item><title>Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification</title><link>http://arxiv.org/abs/2402.07595v2</link><description>Medical image analysis frequently encounters data scarcity challenges.Transfer learning has been effective in addressing this issue while conservingcomputational resources. The recent advent of foundational models like theDINOv2, which uses the vision transformer architecture, has opened newopportunities in the field and gathered significant interest. However, DINOv2'sperformance on clinical data still needs to be verified. In this paper, weperformed a glioma grading task using three clinical modalities of brain MRIdata. We compared the performance of various pre-trained deep learning models,including those based on ImageNet and DINOv2, in a transfer learning context.Our focus was on understanding the impact of the freezing mechanism onperformance. We also validated our findings on three other types of publicdatasets: chest radiography, fundus radiography, and dermoscopy. Our findingsindicate that in our clinical dataset, DINOv2's performance was not as strongas ImageNet-based pre-trained models, whereas in public datasets, DINOv2generally outperformed other models, especially when using the frozenmechanism. Similar performance was observed with various sizes of DINOv2 modelsacross different tasks. In summary, DINOv2 is viable for medical imageclassification tasks, particularly with data resembling natural images.However, its effectiveness may vary with data that significantly differs fromnatural images such as MRI. In addition, employing smaller versions of themodel can be adequate for medical task, offering resource-saving benefits. Ourcodes are available at https://github.com/GuanghuiFU/medical_DINOv2_eval.</description><author>Yuning Huang, Jingchen Zou, Lanxi Meng, Xin Yue, Qing Zhao, Jianqiang Li, Changwei Song, Gabriel Jimenez, Shaowu Li, Guanghui Fu</author><pubDate>Tue, 13 Feb 2024 15:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07595v2</guid></item><item><title>Improving Token-Based World Models with Parallel Observation Prediction</title><link>http://arxiv.org/abs/2402.05643v2</link><description>Motivated by the success of Transformers when applied to sequences ofdiscrete symbols, token-based world models (TBWMs) were recently proposed assample-efficient methods. In TBWMs, the world model consumes agent experienceas a language-like sequence of tokens, where each observation constitutes asub-sequence. However, during imagination, the sequential token-by-tokengeneration of next observations results in a severe bottleneck, leading to longtraining times, poor GPU utilization, and limited representations. To resolvethis bottleneck, we devise a novel Parallel Observation Prediction (POP)mechanism. POP augments a Retentive Network (RetNet) with a novel forward modetailored to our reinforcement learning setting. We incorporate POP in a novelTBWM agent named REM (Retentive Environment Model), showcasing a 15.4x fasterimagination compared to prior TBWMs. REM attains superhuman performance on 12out of 26 games of the Atari 100K benchmark, while training in less than 12hours. Our code is available at \url{https://github.com/leor-c/REM}.</description><author>Lior Cohen, Kaixin Wang, Bingyi Kang, Shie Mannor</author><pubDate>Tue, 13 Feb 2024 15:38:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05643v2</guid></item><item><title>A Distributional Analogue to the Successor Representation</title><link>http://arxiv.org/abs/2402.08530v1</link><description>This paper contributes a new approach for distributional reinforcementlearning which elucidates a clean separation of transition structure and rewardin the learning process. Analogous to how the successor representation (SR)describes the expected consequences of behaving according to a given policy,our distributional successor measure (SM) describes the distributionalconsequences of this behaviour. We formulate the distributional SM as adistribution over distributions and provide theory connecting it withdistributional and model-based reinforcement learning. Moreover, we propose analgorithm that learns the distributional SM from data by minimizing a two-levelmaximum mean discrepancy. Key to our method are a number of algorithmictechniques that are independently valuable for learning generative models ofstate. As an illustration of the usefulness of the distributional SM, we showthat it enables zero-shot risk-sensitive policy evaluation in a way that wasnot previously possible.</description><author>Harley Wiltzer, Jesse Farebrother, Arthur Gretton, Yunhao Tang, André Barreto, Will Dabney, Marc G. Bellemare, Mark Rowland</author><pubDate>Tue, 13 Feb 2024 15:35:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08530v1</guid></item><item><title>Approximately Piecewise E(3) Equivariant Point Networks</title><link>http://arxiv.org/abs/2402.08529v1</link><description>Integrating a notion of symmetry into point cloud neural networks is aprovably effective way to improve their generalization capability. Ofparticular interest are $E(3)$ equivariant point cloud networks where Euclideantransformations applied to the inputs are preserved in the outputs. Recentefforts aim to extend networks that are $E(3)$ equivariant, to accommodateinputs made of multiple parts, each of which exhibits local $E(3)$ symmetry. Inpractical settings, however, the partitioning into individually transformingregions is unknown a priori. Errors in the partition prediction wouldunavoidably map to errors in respecting the true input symmetry. Past workshave proposed different ways to predict the partition, which may exhibituncontrolled errors in their ability to maintain equivariance to the actualpartition. To this end, we introduce APEN: a general framework for constructingapproximate piecewise-$E(3)$ equivariant point networks. Our primary insight isthat functions that are equivariant with respect to a finer partition will alsomaintain equivariance in relation to the true partition. Leveraging thisobservation, we propose a design where the equivariance approximation error ateach layers can be bounded solely in terms of (i) uncertainty quantification ofthe partition prediction, and (ii) bounds on the probability of failing tosuggest a proper subpartition of the ground truth one. We demonstrate theeffectiveness of APEN using two data types exemplifying part-based symmetry:(i) real-world scans of room scenes containing multiple furniture-type objects;and, (ii) human motions, characterized by articulated parts exhibiting rigidmovement. Our empirical results demonstrate the advantage of integratingpiecewise $E(3)$ symmetry into network design, showing a distinct improvementin generalization compared to prior works for both classification andsegmentation tasks.</description><author>Matan Atzmon, Jiahui Huang, Francis Williams, Or Litany</author><pubDate>Tue, 13 Feb 2024 15:34:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08529v1</guid></item><item><title>GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data</title><link>http://arxiv.org/abs/2402.06198v2</link><description>3D Shape represented as point cloud has achieve advancements in multimodalpre-training to align image and language descriptions, which is curial toobject identification, classification, and retrieval. However, the discreterepresentations of point cloud lost the object's surface shape information andcreates a gap between rendering results and 2D correspondences. To address thisproblem, we propose GS-CLIP for the first attempt to introduce 3DGS (3DGaussian Splatting) into multimodal pre-training to enhance 3D representation.GS-CLIP leverages a pre-trained vision-language model for a learned commonvisual and textual space on massive real world image-text pairs and then learnsa 3D Encoder for aligning 3DGS optimized per object. Additionally, a novelGaussian-Aware Fusion is proposed to extract and fuse global explicit feature.As a general framework for language-image-3D pre-training, GS-CLIP is agnosticto 3D backbone networks. Experiments on challenging shows that GS-CLIPsignificantly improves the state-of-the-art, outperforming the previously bestresults.</description><author>Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang</author><pubDate>Tue, 13 Feb 2024 15:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06198v2</guid></item><item><title>Concept-1K: A Novel Benchmark for Instance Incremental Learning</title><link>http://arxiv.org/abs/2402.08526v1</link><description>Incremental learning (IL) is essential to realize the human-levelintelligence in the neural network. However, existing IL scenarios and datasetsare unqualified for assessing forgetting in PLMs, giving an illusion that PLMsdo not suffer from catastrophic forgetting. To this end, we propose achallenging IL scenario called instance-incremental learning (IIL) and a noveldataset called Concept-1K, which supports an order of magnitude larger ILsteps. Based on the experiments on Concept-1K, we reveal that billion-parameterPLMs still suffer from catastrophic forgetting, and the forgetting is affectedby both model scale, pretraining, and buffer size. Furthermore, existing ILmethods and a popular finetuning technique, LoRA, fail to achieve satisfactoryperformance. Our study provides a novel scenario for future studies to explorethe catastrophic forgetting of PLMs and encourage more powerful techniques tobe designed for alleviating the forgetting in PLMs. The data, code and scriptsare publicly available athttps://github.com/zzz47zzz/pretrained-lm-for-incremental-learning.</description><author>Junhao Zheng, Shengjie Qiu, Qianli Ma</author><pubDate>Tue, 13 Feb 2024 15:29:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08526v1</guid></item></channel></rss>