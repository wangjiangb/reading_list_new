<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 21 Oct 2024 13:00:15 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts</title><link>http://arxiv.org/abs/2410.14677v1</link><description>The rapid development of autoregressive Large Language Models (LLMs) hassignificantly improved the quality of generated texts, necessitating reliablemachine-generated text detectors. A huge number of detectors and collectionswith AI fragments have emerged, and several detection methods even showedrecognition quality up to 99.9% according to the target metrics in suchcollections. However, the quality of such detectors tends to drop dramaticallyin the wild, posing a question: Are detectors actually highly trustworthy or dotheir high benchmark scores come from the poor quality of evaluation datasets?In this paper, we emphasise the need for robust and qualitative methods forevaluating generated data to be secure against bias and low generalisingability of future model. We present a systematic review of datasets fromcompetitions dedicated to AI-generated content detection and propose methodsfor evaluating the quality of datasets containing AI-generated fragments. Inaddition, we discuss the possibility of using high-quality generated data toachieve two goals: improving the training of detection models and improving thetraining datasets themselves. Our contribution aims to facilitate a betterunderstanding of the dynamics between human and machine text, which willultimately support the integrity of information in an increasingly automatedworld.</description><author>German Gritsai, Anastasia Voznyuk, Andrey Grabovoy, Yury Chekhovich</author><pubDate>Fri, 18 Oct 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14677v1</guid></item><item><title>SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment</title><link>http://arxiv.org/abs/2410.14676v1</link><description>Existing preference alignment is a one-size-fits-all alignment mechanism,where the part of the large language model (LLM) parametric knowledge withnon-preferred features is uniformly blocked to all the users. However, thispart of knowledge can be useful to advanced users whose expertise qualifiesthem to handle these information. The one-size-fits-all alignment mechanismundermines LLM's utility for these qualified users. To address this problem, wepropose SudoLM, a framework that lets LLMs learn access control over specificparametric knowledge for users with different credentials via authorizationalignment. SudoLM allows authorized users to unlock their access to all theparametric knowledge with an assigned SUDO key while blocking access tonon-qualified users. Experiments on two application scenarios demonstrate thatSudoLM effectively controls the user's access to the parametric knowledge andmaintains its general utility.</description><author>Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen</author><pubDate>Fri, 18 Oct 2024 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14676v1</guid></item><item><title>Enhancing Large Language Models' Situated Faithfulness to External Contexts</title><link>http://arxiv.org/abs/2410.14675v1</link><description>Large Language Models (LLMs) are often augmented with external information ascontexts, but this external information can sometimes be inaccurate or evenintentionally misleading. We argue that robust LLMs should demonstrate situatedfaithfulness, dynamically calibrating their trust in external information basedon their confidence in the internal knowledge and the external context. Tobenchmark this capability, we evaluate LLMs across several QA datasets,including a newly created dataset called RedditQA featuring in-the-wildincorrect contexts sourced from Reddit posts. We show that when provided withboth correct and incorrect contexts, both open-source and proprietary modelstend to overly rely on external information, regardless of its factualaccuracy. To enhance situated faithfulness, we propose two approaches:Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning(RCR). SCR enables models to self-access the confidence of external informationrelative to their own internal knowledge to produce the most accurate answer.RCR, in contrast, extracts explicit confidence signals from the LLM anddetermines the final answer using predefined rules. Our results show that forLLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCRoutperforms RCR, achieving improvements of up to 24.2% over a direct inputaugmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCRoutperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning DirectPreference Optimization (CR-DPO) method improves performance on both seen andunseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. Inaddition to quantitative results, we offer insights into the relative strengthsof SCR and RCR. Our findings highlight promising avenues for improving situatedfaithfulness in LLMs. The data and code are released.</description><author>Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra</author><pubDate>Fri, 18 Oct 2024 17:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14675v1</guid></item><item><title>Self-supervised contrastive learning performs non-linear system identification</title><link>http://arxiv.org/abs/2410.14673v1</link><description>Self-supervised learning (SSL) approaches have brought tremendous successacross many tasks and domains. It has been argued that these successes can beattributed to a link between SSL and identifiable representation learning:Temporal structure and auxiliary variables ensure that latent representationsare related to the true underlying generative factors of the data. Here, wedeepen this connection and show that SSL can perform system identification inlatent space. We propose DynCL, a framework to uncover linear, switching linearand non-linear dynamics under a non-linear observation model, give theoreticalguarantees and validate them empirically.</description><author>Rodrigo González Laiz, Tobias Schmidt, Steffen Schneider</author><pubDate>Fri, 18 Oct 2024 17:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14673v1</guid></item><item><title>BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities</title><link>http://arxiv.org/abs/2410.14672v1</link><description>We introduce BiGR, a novel conditional image generation model using compactbinary latent codes for generative training, focusing on enhancing bothgeneration and representation capabilities. BiGR is the first conditionalgenerative model that unifies generation and discrimination within the sameframework. BiGR features a binary tokenizer, a masked modeling mechanism, and abinary transcoder for binary code prediction. Additionally, we introduce anovel entropy-ordered sampling method to enable efficient image generation.Extensive experiments validate BiGR's superior performance in generationquality, as measured by FID-50k, and representation capabilities, as evidencedby linear-probe accuracy. Moreover, BiGR showcases zero-shot generalizationacross various vision tasks, enabling applications such as image inpainting,outpainting, editing, interpolation, and enrichment, without the need forstructural modifications. Our findings suggest that BiGR unifies generative anddiscriminative tasks effectively, paving the way for further advancements inthe field.</description><author>Shaozhe Hao, Xuantong Liu, Xianbiao Qi, Shihao Zhao, Bojia Zi, Rong Xiao, Kai Han, Kwan-Yee K. Wong</author><pubDate>Fri, 18 Oct 2024 17:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14672v1</guid></item><item><title>Decomposing The Dark Matter of Sparse Autoencoders</title><link>http://arxiv.org/abs/2410.14670v1</link><description>Sparse autoencoders (SAEs) are a promising technique for decomposing languagemodel activations into interpretable linear features. However, current SAEsfall short of completely explaining model performance, resulting in "darkmatter": unexplained variance in activations. This work investigates darkmatter as an object of study in its own right. Surprisingly, we find that muchof SAE dark matter--about half of the error vector itself and &gt;90% of itsnorm--can be linearly predicted from the initial activation vector.Additionally, we find that the scaling behavior of SAE error norms at a pertoken level is remarkably predictable: larger SAEs mostly struggle toreconstruct the same contexts as smaller SAEs. We build on the linearrepresentation hypothesis to propose models of activations that might lead tothese observations, including postulating a new type of "introduced error";these insights imply that the part of the SAE error vector that cannot belinearly predicted ("nonlinear" error) might be fundamentally different fromthe linearly predictable component. To validate this hypothesis, we empiricallyanalyze nonlinear SAE error and show that 1) it contains fewer not yet learnedfeatures, 2) SAEs trained on it are quantitatively worse, 3) it helps predictSAE per-token scaling behavior, and 4) it is responsible for a proportionalamount of the downstream increase in cross entropy loss when SAE activationsare inserted into the model. Finally, we examine two methods to reducenonlinear SAE error at a fixed sparsity: inference time gradient pursuit, whichleads to a very slight decrease in nonlinear error, and linear transformationsfrom earlier layer SAE outputs, which leads to a larger reduction.</description><author>Joshua Engels, Logan Riggs, Max Tegmark</author><pubDate>Fri, 18 Oct 2024 17:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14670v1</guid></item><item><title>NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples</title><link>http://arxiv.org/abs/2410.14669v1</link><description>Vision-language models (VLMs) have made significant progress in recentvisual-question-answering (VQA) benchmarks that evaluate complexvisio-linguistic reasoning. However, are these models truly effective? In thiswork, we show that VLMs still struggle with natural images and questions thathumans can easily answer, which we term natural adversarial samples. We alsofind it surprisingly easy to generate these VQA samples from natural image-textcorpora using off-the-shelf models like CLIP and ChatGPT. We propose asemi-automated approach to collect a new benchmark, NaturalBench, for reliablyevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a$\textbf{vision-centric}$ design by pairing each question with two images thatyield different answers, preventing blind solutions from answering withoutusing the images. This makes NaturalBench more challenging than previousbenchmarks that can be solved with commonsense priors. We evaluate 53state-of-the-art VLMs on NaturalBench, showing that models likeLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4olag 50%-70% behind human performance (over 90%). We analyze why NaturalBench ishard from two angles: (1) Compositionality: Solving NaturalBench requiresdiverse visio-linguistic skills, including understanding attribute bindings,object relationships, and advanced reasoning like logic and counting. To thisend, unlike prior work that uses a single tag per sample, we tag eachNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)Biases: NaturalBench exposes severe biases in VLMs, as models often choose thesame answer regardless of the image. Lastly, we apply our benchmark curationmethod to diverse data sources, including long captions (over 100 words) andnon-English languages like Chinese and Hindi, highlighting its potential fordynamic evaluations of VLMs.</description><author>Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan</author><pubDate>Fri, 18 Oct 2024 17:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14669v1</guid></item><item><title>MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps</title><link>http://arxiv.org/abs/2410.14668v1</link><description>Multimodal Chain of Thought (MCoT) is a popular prompting strategy forimproving the performance of multimodal large language models (MLLMs) across arange of complex reasoning tasks. Despite its popularity, there is a notableabsence of automated methods for evaluating the quality of reasoning steps inMCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation(MiCEval), a framework designed to assess the correctness of reasoning chainsby evaluating the quality of both the description and each reasoning step. Theevaluation of the description component focuses on the accuracy of the imagedescriptions, while the reasoning step evaluates the quality of each step as itis conditionally generated based on the preceding steps. MiCEval is built upona fine-grained dataset with annotations that rate each step according tocorrectness, relevance, and informativeness. Extensive experiments on fourstate-of-the-art MLLMs show that step-wise evaluations using MiCEval align moreclosely with human judgments compared to existing methods based on cosinesimilarity or fine-tuning approaches. MiCEval datasets and code can be found inhttps://github.com/alenai97/MiCEval.</description><author>Xiongtao Zhou, Jie He, Lanyu Chen, jingyu li, Haojing Chen, Victor Gutierrez Basulto, Jeff Z. Pan, Hanjie Chen</author><pubDate>Fri, 18 Oct 2024 17:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14668v1</guid></item><item><title>Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating the Accuracy-Robustness Tradeoff</title><link>http://arxiv.org/abs/2410.14667v1</link><description>Inverse problems aim to reconstruct unseen data from corrupted or perturbedmeasurements. While most work focuses on improving reconstruction quality,generalization accuracy and robustness are equally important, especially forsafety-critical applications. Model-based architectures (MBAs), such as loopunrolling methods, are considered more interpretable and achieve betterreconstructions. Empirical evidence suggests that MBAs are more robust toperturbations than black-box solvers, but the accuracy-robustness tradeoff inMBAs remains underexplored. In this work, we propose a simple yet effectivetraining scheme for MBAs, called SGD jittering, which injects noiseiteration-wise during reconstruction. We theoretically demonstrate that SGDjittering not only generalizes better than the standard mean squared errortraining but is also more robust to average-case attacks. We validate SGDjittering using denoising toy examples, seismic deconvolution, and single-coilMRI reconstruction. The proposed method achieves cleaner reconstructions forout-of-distribution data and demonstrates enhanced robustness to adversarialattacks.</description><author>Peimeng Guan, Mark A. Davenport</author><pubDate>Fri, 18 Oct 2024 17:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14667v1</guid></item><item><title>DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph</title><link>http://arxiv.org/abs/2410.14666v1</link><description>Summarizing movie screenplays presents a unique set of challenges compared tostandard document summarization. Screenplays are not only lengthy, but alsofeature a complex interplay of characters, dialogues, and scenes, with numerousdirect and subtle relationships and contextual nuances that are difficult formachine learning models to accurately capture and comprehend. Recent attemptsat screenplay summarization focus on fine-tuning transformer-based pre-trainedmodels, but these models often fall short in capturing long-term dependenciesand latent relationships, and frequently encounter the "lost in the middle"issue. To address these challenges, we introduce DiscoGraMS, a novel resourcethat represents movie scripts as a movie character-aware discourse graph (CaDGraph). This approach is well-suited for various downstream tasks, such assummarization, question-answering, and salience detection. The model aims topreserve all salient information, offering a more comprehensive and faithfulrepresentation of the screenplay's content. We further explore a baselinemethod that combines the CaD Graph with the corresponding movie script througha late fusion of graph and text modalities, and we present very initialpromising results.</description><author>Maitreya Prafulla Chitale, Uday Bindal, Rajakrishnan Rajkumar, Rahul Mishra</author><pubDate>Fri, 18 Oct 2024 17:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14666v1</guid></item><item><title>Online Reinforcement Learning with Passive Memory</title><link>http://arxiv.org/abs/2410.14665v1</link><description>This paper considers an online reinforcement learning algorithm thatleverages pre-collected data (passive memory) from the environment for onlineinteraction. We show that using passive memory improves performance and furtherprovide theoretical guarantees for regret that turns out to be near-minimaxoptimal. Results show that the quality of passive memory determinessub-optimality of the incurred regret. The proposed approach and results holdin both continuous and discrete state-action spaces.</description><author>Anay Pattanaik, Lav R. Varshney</author><pubDate>Fri, 18 Oct 2024 17:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14665v1</guid></item><item><title>Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing</title><link>http://arxiv.org/abs/2410.06331v2</link><description>The locate-then-edit paradigm has shown significant promise for knowledgeediting (KE) in Large Language Models (LLMs). While previous methods performwell on single-hop fact recall tasks, they consistently struggle with multi-hopfactual recall tasks involving newly edited knowledge. In this paper,leveraging tools in mechanistic interpretability, we first identify that inmulti-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeperMLP layers, unlike single-hop tasks, which rely on earlier layers. Thisdistinction explains the poor performance of current methods in multi-hopqueries, as they primarily focus on editing shallow layers, leaving deeperlayers unchanged. To address this, we propose IFMET, a novel locate-then-editKE approach designed to edit both shallow and deep MLP layers. IFMET employsmulti-hop editing prompts and supplementary sets to locate and modify knowledgeacross different reasoning stages. Experimental results demonstrate that IFMETsignificantly improves performance on multi-hop factual recall tasks,effectively overcoming the limitations of previous locate-then-edit methods.</description><author>Zhuoran Zhang, Yongxiang Li, Zijian Kan, Keyuan Cheng, Lijie Hu, Di Wang</author><pubDate>Fri, 18 Oct 2024 17:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06331v2</guid></item><item><title>A Large Language Model-Driven Reward Design Framework via Dynamic Feedback for Reinforcement Learning</title><link>http://arxiv.org/abs/2410.14660v1</link><description>Large Language Models (LLMs) have shown significant potential in designingreward functions for Reinforcement Learning (RL) tasks. However, obtaininghigh-quality reward code often involves human intervention, numerous LLMqueries, or repetitive RL training. To address these issues, we propose CARD, aLLM-driven Reward Design framework that iteratively generates and improvesreward function code. Specifically, CARD includes a Coder that generates andverifies the code, while a Evaluator provides dynamic feedback to guide theCoder in improving the code, eliminating the need for human feedback. Inaddition to process feedback and trajectory feedback, we introduce TrajectoryPreference Evaluation (TPE), which evaluates the current reward function basedon trajectory preferences. If the code fails the TPE, the Evaluator providespreference feedback, avoiding RL training at every iteration and making thereward function better aligned with the task objective. Empirical results onMeta-World and ManiSkill2 demonstrate that our method achieves an effectivebalance between task performance and token efficiency, outperforming ormatching the baselines across all tasks. On 10 out of 12 tasks, CARD showsbetter or comparable performance to policies trained with expert-designedrewards, and our method even surpasses the oracle on 3 tasks.</description><author>Shengjie Sun, Runze Liu, Jiafei Lyu, Jing-Wen Yang, Liangpeng Zhang, Xiu Li</author><pubDate>Fri, 18 Oct 2024 17:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14660v1</guid></item><item><title>Harnessing Causality in Reinforcement Learning With Bagged Decision Times</title><link>http://arxiv.org/abs/2410.14659v1</link><description>We consider reinforcement learning (RL) for a class of problems with baggeddecision times. A bag contains a finite sequence of consecutive decision times.The transition dynamics are non-Markovian and non-stationary within a bag.Further, all actions within a bag jointly impact a single reward, observed atthe end of the bag. Our goal is to construct an online RL algorithm to maximizethe discounted sum of the bag-specific rewards. To handle non-Markoviantransitions within a bag, we utilize an expert-provided causal directed acyclicgraph (DAG). Based on the DAG, we construct the states as a dynamical Bayesiansufficient statistic of the observed history, which results in Markovian statetransitions within and across bags. We then frame this problem as a periodicMarkov decision process (MDP) that allows non-stationarity within a period. Anonline RL algorithm based on Bellman-equations for stationary MDPs isgeneralized to handle periodic MDPs. To justify the proposed RL algorithm, weshow that our constructed state achieves the maximal optimal value functionamong all state constructions for a periodic MDP. Further we prove the Bellmanoptimality equations for periodic MDPs. We evaluate the proposed method ontestbed variants, constructed with real data from a mobile health clinicaltrial.</description><author>Daiqi Gao, Hsin-Yu Lai, Predrag Klasnja, Susan A. Murphy</author><pubDate>Fri, 18 Oct 2024 17:51:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14659v1</guid></item><item><title>EasyRec: Simple yet Effective Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.08821v3</link><description>Deep neural networks have become a powerful technique for learningrepresentations from user-item interaction data in collaborative filtering (CF)for recommender systems. However, many existing methods heavily rely on uniqueuser and item IDs, which limits their ability to perform well in practicalzero-shot learning scenarios where sufficient training data may be unavailable.Inspired by the success of language models (LMs) and their stronggeneralization capabilities, a crucial question arises: How can we harness thepotential of language models to empower recommender systems and elevate itsgeneralization capabilities to new heights? In this study, we propose EasyRec -an effective and easy-to-use approach that seamlessly integrates text-basedsemantic understanding with collaborative signals. EasyRec employs atext-behavior alignment framework, which combines contrastive learning withcollaborative language model tuning, to ensure a strong alignment between thetext-enhanced semantic space and the collaborative behavior information.Extensive empirical evaluations across diverse real-world datasets demonstratethe superior performance of EasyRec compared to state-of-the-art alternativemodels, particularly in the challenging text-based zero-shot recommendationscenarios. Furthermore, the study highlights the potential of seamlesslyintegrating EasyRec as a plug-and-play component into text-enhancedcollaborative filtering frameworks, thereby empowering existing recommendersystems to elevate their recommendation performance and adapt to the evolvinguser preferences in dynamic environments. For better result reproducibility ofour EasyRec framework, the model implementation details, source code, anddatasets are available at the link: https://github.com/HKUDS/EasyRec.</description><author>Xubin Ren, Chao Huang</author><pubDate>Fri, 18 Oct 2024 17:50:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08821v3</guid></item><item><title>Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens</title><link>http://arxiv.org/abs/2410.14655v1</link><description>Language models are often trained to maximize the likelihood of the nexttoken given past tokens in the training dataset. However, during inferencetime, they are utilized differently, generating text sequentially andauto-regressively by using previously generated tokens as input to predict thenext one. Marginal differences in predictions at each step can cascade oversuccessive steps, resulting in different distributions from what the modelswere trained for and potentially leading to unpredictable behavior. This paperproposes two simple approaches based on model own generation to address thisdiscrepancy between the training and inference time. Our first approach isBatch-Scheduled Sampling, where, during training, we stochastically choosebetween the ground-truth token from the dataset and the model's own generatedtoken as input to predict the next token. This is done in an offline manner,modifying the context window by interleaving ground-truth tokens with thosegenerated by the model. Our second approach is Reference-Answer-basedCorrection, where we explicitly incorporate a self-correction capability intothe model during training. This enables the model to effectively self-correctthe gaps between the generated sequences and the ground truth data withoutrelying on an external oracle model. By incorporating our proposed strategiesduring training, we have observed an overall improvement in performancecompared to baseline methods, as demonstrated by our extensive experimentsusing summarization, general question-answering, and math question-answeringtasks.</description><author>Zhepeng Cen, Yao Liu, Siliang Zeng, Pratik Chaudhar, Huzefa Rangwala, George Karypis, Rasool Fakoor</author><pubDate>Fri, 18 Oct 2024 17:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14655v1</guid></item><item><title>Real-time Fake News from Adversarial Feedback</title><link>http://arxiv.org/abs/2410.14651v1</link><description>We show that existing evaluations for fake news detection based onconventional sources, such as claims on fact-checking websites, result in anincreasing accuracy over time for LLM-based detectors -- even after theirknowledge cutoffs. This suggests that recent popular political claims, whichform the majority of fake news on such sources, are easily classified usingsurface-level shallow patterns. Instead, we argue that a proper fake newsdetection dataset should test a model's ability to reason factually about thecurrent world by retrieving and reading related evidence. To this end, wedevelop a novel pipeline that leverages natural language feedback from aRAG-based detector to iteratively modify real-time news into deceptive fakenews that challenges LLMs. Our iterative rewrite decreases the binaryclassification AUC by an absolute 17.5 percent for a strong RAG GPT-4odetector. Our experiments reveal the important role of RAG in both detectingand generating fake news, as retrieval-free LLM detectors are vulnerable tounseen events and adversarial attacks, while feedback from RAG detection helpsdiscover more deceitful patterns in fake news.</description><author>Sanxing Chen, Yukun Huang, Bhuwan Dhingra</author><pubDate>Fri, 18 Oct 2024 17:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14651v1</guid></item><item><title>EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search</title><link>http://arxiv.org/abs/2410.14649v1</link><description>The high computational costs of large language models (LLMs) have led to aflurry of research on LLM compression, via methods such as quantization,sparsification, or structured pruning. A new frontier in this area is given by\emph{dynamic, non-uniform} compression methods, which adjust the compressionlevels (e.g., sparsity) per-block or even per-layer in order to minimizeaccuracy loss, while guaranteeing a global compression threshold. Yet, currentmethods rely on heuristics for identifying the "importance" of a given layertowards the loss, based on assumptions such as \emph{error monotonicity}, i.e.that the end-to-end model compression error is proportional to the sum oflayer-wise errors. In this paper, we revisit this area, and propose a new andgeneral approach for dynamic compression that is provably optimal in a giveninput range. We begin from the motivating observation that, in general,\emph{error monotonicity does not hold for LLMs}: compressed models with lowersum of per-layer errors can perform \emph{worse} than models with higher errorsums. To address this, we propose a new general evolutionary framework fordynamic LLM compression called EvoPress, which has provable convergence, andlow sample and evaluation complexity. We show that these theoretical guaranteeslead to highly competitive practical performance for dynamic compression ofLlama, Mistral and Phi models. Via EvoPress, we set new state-of-the-artresults across all compression approaches: structural pruning (block/layerdropping), unstructured sparsity, as well as quantization with dynamicbitwidths. Our code is available at https://github.com/IST-DASLab/EvoPress.</description><author>Oliver Sieberling, Denis Kuznedelev, Eldar Kurtic, Dan Alistarh</author><pubDate>Fri, 18 Oct 2024 17:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14649v1</guid></item><item><title>HR-Bandit: Human-AI Collaborated Linear Recourse Bandit</title><link>http://arxiv.org/abs/2410.14640v1</link><description>Human doctors frequently recommend actionable recourses that allow patientsto modify their conditions to access more effective treatments. Inspired bysuch healthcare scenarios, we propose the Recourse Linear UCB($\textsf{RLinUCB}$) algorithm, which optimizes both action selection andfeature modifications by balancing exploration and exploitation. We furtherextend this to the Human-AI Linear Recourse Bandit ($\textsf{HR-Bandit}$),which integrates human expertise to enhance performance. $\textsf{HR-Bandit}$offers three key guarantees: (i) a warm-start guarantee for improved initialperformance, (ii) a human-effort guarantee to minimize required humaninteractions, and (iii) a robustness guarantee that ensures sublinear regreteven when human decisions are suboptimal. Empirical results, including ahealthcare case study, validate its superior performance against existingbenchmarks.</description><author>Junyu Cao, Ruijiang Gao, Esmaeil Keyvanshokooh</author><pubDate>Fri, 18 Oct 2024 17:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14640v1</guid></item><item><title>Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs</title><link>http://arxiv.org/abs/2410.14641v1</link><description>Positional bias in large language models (LLMs) hinders their ability toeffectively process long inputs. A prominent example is the "lost in themiddle" phenomenon, where LLMs struggle to utilize relevant informationsituated in the middle of the input. While prior research primarily focuses onsingle pieces of relevant information, real-world applications often involvemultiple relevant information pieces. To bridge this gap, we presentLongPiBench, a benchmark designed to assess positional bias involving multiplepieces of relevant information. Thorough experiments are conducted with fivecommercial and six open-source models. These experiments reveal that while mostcurrent models are robust against the "lost in the middle" issue, there existsignificant biases related to the spacing of relevant information pieces. Thesefindings highlight the importance of evaluating and reducing positional biasesto advance LLM's capabilities.</description><author>Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu</author><pubDate>Fri, 18 Oct 2024 17:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14641v1</guid></item><item><title>Convergence of Manifold Filter-Combine Networks</title><link>http://arxiv.org/abs/2410.14639v1</link><description>In order to better understand manifold neural networks (MNNs), we introduceManifold Filter-Combine Networks (MFCNs). The filter-combine frameworkparallels the popular aggregate-combine paradigm for graph neural networks(GNNs) and naturally suggests many interesting families of MNNs which can beinterpreted as the manifold analog of various popular GNNs. We then propose amethod for implementing MFCNs on high-dimensional point clouds that relies onapproximating the manifold by a sparse graph. We prove that our method isconsistent in the sense that it converges to a continuum limit as the number ofdata points tends to infinity.</description><author>David R. Johnson, Joyce Chew, Siddharth Viswanath, Edward De Brouwer, Deanna Needell, Smita Krishnaswamy, Michael Perlmutter</author><pubDate>Fri, 18 Oct 2024 17:40:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14639v1</guid></item><item><title>Learning Generative Interactive Environments By Trained Agent Exploration</title><link>http://arxiv.org/abs/2409.06445v2</link><description>World models are increasingly pivotal in interpreting and simulating therules and actions of complex environments. Genie, a recent model, excels atlearning from visually diverse environments but relies on costlyhuman-collected data. We observe that their alternative method of using randomagents is too limited to explore the environment. We propose to improve themodel by employing reinforcement learning based agents for data generation.This approach produces diverse datasets that enhance the model's ability toadapt and perform well across various scenarios and realistic actions withinthe environment. In this paper, we first release the model GenieRedux - animplementation based on Genie. Additionally, we introduce GenieRedux-G, avariant that uses the agent's readily available actions to factor out actionprediction uncertainty during validation. Our evaluation, including areplication of the Coinrun case study, shows that GenieRedux-G achievessuperior visual fidelity and controllability using the trained agentexploration. The proposed approach is reproducable, scalable and adaptable tonew types of environments. Our codebase is available athttps://github.com/insait-institute/GenieRedux .</description><author>Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool</author><pubDate>Fri, 18 Oct 2024 17:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06445v2</guid></item><item><title>GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings</title><link>http://arxiv.org/abs/2410.14635v1</link><description>Training-free embedding methods directly leverage pretrained large languagemodels (LLMs) to embed text, bypassing the costly and complex procedure ofcontrastive learning. Previous training-free embedding methods have mainlyfocused on optimizing embedding prompts and have overlooked the benefits ofutilizing the generative abilities of LLMs. We propose a novel method, GenEOL,which uses LLMs to generate diverse transformations of a sentence that preserveits meaning, and aggregates the resulting embeddings of these transformationsto enhance the overall sentence embedding. GenEOL significantly outperforms theexisting training-free embedding methods by an average of 2.85 points acrossseveral LLMs on the sentence semantic text similarity (STS) benchmark. Ouranalysis shows that GenEOL stabilizes representation quality across LLM layersand is robust to perturbations of embedding prompts. GenEOL also achievesnotable gains on multiple clustering, reranking and pair-classification tasksfrom the MTEB benchmark.</description><author>Raghuveer Thirukovalluru, Bhuwan Dhingra</author><pubDate>Fri, 18 Oct 2024 17:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14635v1</guid></item><item><title>Parallel Backpropagation for Inverse of a Convolution with Application to Normalizing Flows</title><link>http://arxiv.org/abs/2410.14634v1</link><description>Inverse of an invertible convolution is an important operation that comes upin Normalizing Flows, Image Deblurring, etc. The naive algorithm forbackpropagation of this operation using Gaussian elimination has running time$O(n^3)$ where $n$ is the number of pixels in the image. We give a fastparallel backpropagation algorithm with running time $O(\sqrt{n})$ for a squareimage and provide a GPU implementation of the same. Inverse Convolutions areusually used in Normalizing Flows in the sampling pass, making them slow. Wepropose to use Inverse Convolutions in the forward (image to latent vector)pass of the Normalizing flow. Since the sampling pass is the inverse of theforward pass, it will use convolutions only, resulting in efficient samplingtimes. We use our parallel backpropagation algorithm for optimizing the inverseconvolution layer resulting in fast training times also. We implement thisapproach in various Normalizing Flow backbones, resulting in our Inverse-Flowmodels. We benchmark Inverse-Flow on standard datasets and show significantlyimproved sampling times with similar bits per dimension compared to previousmodels.</description><author>Sandeep Nagar, Girish Varma</author><pubDate>Fri, 18 Oct 2024 17:35:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14634v1</guid></item><item><title>Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning</title><link>http://arxiv.org/abs/2410.14633v1</link><description>Vision Foundation Models (VFMs) have demonstrated outstanding performance onnumerous downstream tasks. However, due to their inherent representation biasesoriginating from different training paradigms, VFMs exhibit advantages anddisadvantages across distinct vision tasks. Although amalgamating the strengthsof multiple VFMs for downstream tasks is an intuitive strategy, effectivelyexploiting these biases remains a significant challenge. In this paper, wepropose a novel and versatile "Swiss Army Knife" (SAK) solution, whichadaptively distills knowledge from a committee of VFMs to enhance multi-tasklearning. Unlike existing methods that use a single backbone for knowledgetransfer, our approach preserves the unique representation bias of each teacherby collaborating the lightweight Teacher-Specific Adapter Path modules with theTeacher-Agnostic Stem. Through dynamic selection and combination ofrepresentations with Mixture-of-Representations Routers, our SAK is capable ofsynergizing the complementary strengths of multiple VFMs. Extensive experimentsshow that our SAK remarkably outperforms prior state of the arts in multi-tasklearning by 10% on the NYUD-v2 benchmark, while also providing a flexible androbust framework that can readily accommodate more advanced model designs.</description><author>Yuxiang Lu, Shengcao Cao, Yu-Xiong Wang</author><pubDate>Fri, 18 Oct 2024 17:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14633v1</guid></item><item><title>A Distance-based Anomaly Detection Framework for Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2109.09889v3</link><description>In deep reinforcement learning (RL) systems, abnormal states pose significantrisks by potentially triggering unpredictable behaviors and unsafe actions,thus impeding the deployment of RL systems in real-world scenarios. It iscrucial for reliable decision-making systems to have the capability to cast analert whenever they encounter unfamiliar observations that they are notequipped to handle. In this paper, we propose a novel Mahalanobisdistance-based (MD) anomaly detection framework, called \textit{MDX}, for deepRL algorithms. MDX simultaneously addresses random, adversarial, andout-of-distribution (OOD) state outliers in both offline and online settings.It utilizes Mahalanobis distance within class-conditional distributions foreach action and operates within a statistical hypothesis testing frameworkunder the Gaussian assumption. We further extend it to robust anddistribution-free versions by incorporating Robust MD and conformal inferencetechniques. Through extensive experiments on classical control environments,Atari games, and autonomous driving scenarios, we demonstrate the effectivenessof our MD-based detection framework. MDX offers a simple, unified, andpractical anomaly detection tool for enhancing the safety and reliability of RLsystems in real-world applications.</description><author>Hongming Zhang, Ke Sun, Bo Xu, Linglong Kong, Martin Müller</author><pubDate>Fri, 18 Oct 2024 17:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.09889v3</guid></item><item><title>Diverging Preferences: When do Annotators Disagree and do Models Know?</title><link>http://arxiv.org/abs/2410.14632v1</link><description>We examine diverging preferences in human-labeled preference datasets. Wedevelop a taxonomy of disagreement sources spanning 10 categories across fourhigh-level classes -- task underspecification, response style, refusals, andannotation errors. We find that the majority of disagreements are in oppositionwith standard reward modeling approaches, which are designed with theassumption that annotator disagreement is noise. We then explore how thesefindings impact two areas of LLM development: reward modeling and evaluation.In our experiments, we demonstrate how standard reward modeling methods, likethe Bradley-Terry model, fail to differentiate whether a given preferencejudgment is the result of unanimous agreement among annotators or the majorityopinion among diverging user preferences. We also find that these tendenciesare also echoed by popular LLM-as-Judge evaluation methods, which consistentlyidentify a winning response in cases of diverging preferences. These findingshighlight remaining challenges in LLM evaluations, which are greatly influencedby divisive features like response style, and in developing pluralisticallyaligned LLMs. To address these issues, we develop methods for identifyingdiverging preferences to mitigate their influence on evaluation and training.</description><author>Michael JQ Zhang, Zhilin Wang, Jena D. Hwang, Yi Dong, Olivier Delalleau, Yejin Choi, Eunsol Choi, Xiang Ren, Valentina Pyatkin</author><pubDate>Fri, 18 Oct 2024 17:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14632v1</guid></item><item><title>On the Regularization of Learnable Embeddings for Time Series Processing</title><link>http://arxiv.org/abs/2410.14630v1</link><description>In processing multiple time series, accounting for the individual features ofeach sequence can be challenging. To address this, modern deep learning methodsfor time series analysis combine a shared (global) model with local layers,specific to each time series, often implemented as learnable embeddings.Ideally, these local embeddings should encode meaningful representations of theunique dynamics of each sequence. However, when these are learned end-to-end asparameters of a forecasting model, they may end up acting as mere sequenceidentifiers. Shared processing blocks may then become reliant on suchidentifiers, limiting their transferability to new contexts. In this paper, weaddress this issue by investigating methods to regularize the learning of locallearnable embeddings for time series processing. Specifically, we perform thefirst extensive empirical study on the subject and show how suchregularizations consistently improve performance in widely adoptedarchitectures. Furthermore, we show that methods preventing the co-adaptationof local and global parameters are particularly effective in this context. Thishypothesis is validated by comparing several methods preventing the downstreammodels from relying on sequence identifiers, going as far as completelyresetting the embeddings during training. The obtained results provide animportant contribution to understanding the interplay between learnable localparameters and shared processing layers: a key challenge in modern time seriesprocessing models and a step toward developing effective foundation models fortime series.</description><author>Luca Butera, Giovanni De Felice, Andrea Cini, Cesare Alippi</author><pubDate>Fri, 18 Oct 2024 17:30:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14630v1</guid></item><item><title>SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space Trajectory Similarity</title><link>http://arxiv.org/abs/2410.14629v1</link><description>Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, andFrechet, often incur quadratic time complexity, thus learning-based methodshave been proposed to accelerate the computation. The core idea is to train anencoder to transform trajectories into representation vectors and then computevector similarity to approximate the ground truth. However, existing methodsface dual challenges of effectiveness and efficiency: 1) they all utilizeEuclidean distance to compute representation similarity, which leads to thesevere curse of dimensionality issue -- reducing the distinguishability amongrepresentations and significantly affecting the accuracy of subsequentsimilarity search tasks; 2) most of them are trained in triplets manner andoften necessitate additional information which downgrades the efficiency; 3)previous studies, while emphasizing the scalability in terms of efficiency,overlooked the deterioration of effectiveness when the dataset size grows. Tocope with these issues, we propose a simple, yet accurate, fast, scalable modelthat only uses a single-layer vanilla transformer encoder as the featureextractor and employs tailored representation similarity functions toapproximate various ground truth similarity measures. Extensive experimentsdemonstrate our model significantly mitigates the curse of dimensionality issueand outperforms the state-of-the-arts in effectiveness, efficiency, andscalability.</description><author>Chuang Yang, Renhe Jiang, Xiaohang Xu, Chuan Xiao, Kaoru Sezaki</author><pubDate>Fri, 18 Oct 2024 17:30:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14629v1</guid></item><item><title>System 2 thinking in OpenAI's o1-preview model: Near-perfect performance on a mathematics exam</title><link>http://arxiv.org/abs/2410.07114v2</link><description>The processes underlying human cognition are often divided into System 1,which involves fast, intuitive thinking, and System 2, which involves slow,deliberate reasoning. Previously, large language models were criticized forlacking the deeper, more analytical capabilities of System 2. In September2024, OpenAI introduced the o1 model series, designed to handle System 2-likereasoning. While OpenAI's benchmarks are promising, independent validation isstill needed. In this study, we tested the o1-preview model twice on the Dutch'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76points. For context, only 24 out of 16,414 students in the Netherlands achieveda perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,well above the Dutch average of 40.63 points. Neither model had access to theexam figures. Since there was a risk of model contamination (i.e., theknowledge cutoff of o1-preview and GPT-4o was after the exam was publishedonline), we repeated the procedure with a new Mathematics B exam that waspublished after the cutoff date. The results again indicated that o1-previewperformed strongly (97.8th percentile), which suggests that contamination wasnot a factor. We also show that there is some variability in the output ofo1-preview, which means that sometimes there is 'luck' (the answer is correct)or 'bad luck' (the output has diverged into something that is incorrect). Wedemonstrate that a self-consistency approach, where repeated prompts are givenand the most common answer is selected, is a useful strategy for identifyingthe correct answer. It is concluded that while OpenAI's new model series holdsgreat potential, certain risks must be considered.</description><author>Joost de Winter, Dimitra Dodou, Yke Bauke Eisma</author><pubDate>Fri, 18 Oct 2024 17:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07114v2</guid></item><item><title>CELI: Controller-Embedded Language Model Interactions</title><link>http://arxiv.org/abs/2410.14627v1</link><description>We introduce Controller-Embedded Language Model Interactions (CELI), aframework that integrates control logic directly within language model (LM)prompts, facilitating complex, multi-stage task execution. CELI addresseslimitations of existing prompt engineering and workflow optimization techniquesby embedding control logic directly within the operational context of languagemodels, enabling dynamic adaptation to evolving task requirements. Ourframework transfers control from the traditional programming executionenvironment to the LMs, allowing them to autonomously manage computationalworkflows while maintaining seamless interaction with external systems andfunctions. CELI supports arbitrary function calls with variable arguments,bridging the gap between LMs' adaptive reasoning capabilities and conventionalsoftware paradigms' structured control mechanisms. To evaluate CELI'sversatility and effectiveness, we conducted case studies in two distinctdomains: code generation (HumanEval benchmark) and multi-stage contentgeneration (Wikipedia-style articles). The results demonstrate notableperformance improvements across a range of domains. CELI achieved a 4.9percentage point improvement over the best reported score of the baseline GPT-4model on the HumanEval code generation benchmark. In multi-stage contentgeneration, 94.4% of CELI-produced Wikipedia-style articles met or exceededfirst draft quality when optimally configured, with 44.4% achieving highquality. These outcomes underscore CELI's potential for optimizing AI-drivenworkflows across diverse computational domains.</description><author>Jan-Samuel Wagner, Dave DeCaprio, Abishek Chiffon Muthu Raja, Jonathan M. Holman, Lauren K. Brady, Sky C. Cheung, Hosein Barzekar, Eric Yang, Mark Anthony Martinez II, David Soong, Sriram Sridhar, Han Si, Brandon W. Higgs, Hisham Hamadeh, Scott Ogden</author><pubDate>Fri, 18 Oct 2024 17:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14627v1</guid></item><item><title>You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools</title><link>http://arxiv.org/abs/2410.14626v1</link><description>If sentiment analysis tools were valid classifiers, one would expect them toprovide comparable results for sentiment classification on different kinds ofcorpora and for different languages. In line with results of previous studieswe show that sentiment analysis tools disagree on the same dataset. Goingbeyond previous studies we show that the sentiment tool used for sentimentannotation can even be predicted from its outcome, revealing an algorithmicbias of sentiment analysis. Based on Twitter, Wikipedia and different newscorpora from the English, German and French languages, our classifiers separatesentiment tools with an averaged F1-score of 0.89 (for the English corpora). Wetherefore warn against taking sentiment annotations as face value and argue forthe need of more and systematic NLP evaluation studies.</description><author>Daniel Baumartz, Mevlüt Bagci, Alexander Henlein, Maxim Konca, Andy Lücking, Alexander Mehler</author><pubDate>Fri, 18 Oct 2024 17:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14626v1</guid></item><item><title>Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers and Electronic Health Records</title><link>http://arxiv.org/abs/2410.14625v1</link><description>In the rapidly evolving landscape of veterinary healthcare, integratingmachine learning (ML) clinical decision-making tools with electronic healthrecords (EHRs) promises to improve diagnostic accuracy and patient care.However, the seamless integration of ML classifiers into existing EHRs inveterinary medicine is frequently hindered by the rigidity of EHR systems orthe limited availability of IT resources. To address this shortcoming, wepresent Anna, a freely-available software solution that provides ML classifierresults for EHR laboratory data in real-time.</description><author>Chun Yin Kong, Picasso Vasquez, Makan Farhoodimoghadam, Chris Brandt, Titus C. Brown, Krystle L. Reagan, Allison Zwingenberger, Stefan M. Keller</author><pubDate>Fri, 18 Oct 2024 17:27:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14625v1</guid></item><item><title>syren-new: Precise formulae for the linear and nonlinear matter power spectra with massive neutrinos and dynamical dark energy</title><link>http://arxiv.org/abs/2410.14623v1</link><description>Current and future large scale structure surveys aim to constrain theneutrino mass and the equation of state of dark energy. We aim to constructaccurate and interpretable symbolic approximations to the linear and nonlinearmatter power spectra as a function of cosmological parameters in extended$\Lambda$CDM models which contain massive neutrinos and non-constant equationsof state for dark energy. This constitutes an extension of the syren-halofitemulators to incorporate these two effects, which we call syren-new(SYmbolic-Regression-ENhanced power spectrum emulator with NEutrinos and$W_0-w_a$). We also obtain a simple approximation to the derived parameter$\sigma_8$ as a function of the cosmological parameters for these models. Ourresults for the linear power spectrum are designed to emulate CLASS, whereasfor the nonlinear case we aim to match the results of EuclidEmulator2. Wecompare our results to existing emulators and $N$-body simulations. Ouranalytic emulators for $\sigma_8$, the linear and nonlinear power spectraachieve root mean squared errors of 0.1%, 0.3% and 1.3%, respectively, across awide range of cosmological parameters, redshifts and wavenumbers. We verifythat emulator-related discrepancies are subdominant compared to observationalerrors and other modelling uncertainties when computing shear power spectra forLSST-like surveys. Our expressions have similar accuracy to existing(numerical) emulators, but are at least an order of magnitude faster, both on aCPU and GPU. Our work greatly improves the accuracy, speed and range ofapplicability of current symbolic approximations to the linear and nonlinearmatter power spectra. We provide publicly available code for all symbolicapproximations found.</description><author>Ce Sui, Deaglan J. Bartlett, Shivam Pandey, Harry Desmond, Pedro G. Ferreira, Benjamin D. Wandelt</author><pubDate>Fri, 18 Oct 2024 17:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14623v1</guid></item><item><title>JAMUN: Transferable Molecular Conformational Ensemble Generation with Walk-Jump Sampling</title><link>http://arxiv.org/abs/2410.14621v1</link><description>Conformational ensembles of protein structures are immensely important bothto understanding protein function, and for drug discovery in novel modalitiessuch as cryptic pockets. Current techniques for sampling ensembles arecomputationally inefficient, or do not transfer to systems outside theirtraining data. We present walk-Jump Accelerated Molecular ensembles withUniversal Noise (JAMUN), a step towards the goal of efficiently sampling theBoltzmann distribution of arbitrary proteins. By extending Walk-Jump Samplingto point clouds, JAMUN enables ensemble generation at orders of magnitudefaster rates than traditional molecular dynamics or state-of-the-art MLmethods. Further, JAMUN is able to predict the stable basins of small peptidesthat were not seen during training.</description><author>Ameya Daigavane, Bodhi P. Vani, Saeed Saremi, Joseph Kleinhenz, Joshua Rackers</author><pubDate>Fri, 18 Oct 2024 17:21:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14621v1</guid></item><item><title>Liger Kernel: Efficient Triton Kernels for LLM Training</title><link>http://arxiv.org/abs/2410.10989v2</link><description>Training Large Language Models (LLMs) efficiently at scale presents aformidable challenge, driven by their ever-increasing computational demands andthe need for enhanced performance. In this work, we introduce Liger-Kernel, anopen-sourced set of Triton kernels developed specifically for LLM training.With kernel optimization techniques like kernel operation fusing and inputchunking, our kernels achieve on average a 20% increase in training throughputand a 60% reduction in GPU memory usage for popular LLMs compared toHuggingFace implementations. In addition, Liger-Kernel is designed withmodularity, accessibility, and adaptability in mind, catering to both casualand expert users. Comprehensive benchmarks and integration tests are built into ensure compatibility, performance, correctness, and convergence acrossdiverse computing environments and model architectures. The source code is available under a permissive license at:github.com/linkedin/Liger-Kernel.</description><author>Pin-Lun Hsu, Yun Dai, Vignesh Kothapalli, Qingquan Song, Shao Tang, Siyu Zhu, Steven Shimizu, Shivam Sahni, Haowen Ning, Yanning Chen</author><pubDate>Fri, 18 Oct 2024 17:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10989v2</guid></item><item><title>EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis</title><link>http://arxiv.org/abs/2410.01804v4</link><description>We present Exact Volumetric Ellipsoid Rendering (EVER), a method forreal-time differentiable emission-only volume rendering. Unlike recentrasterization based approach by 3D Gaussian Splatting (3DGS), our primitivebased representation allows for exact volume rendering, rather than alphacompositing 3D Gaussian billboards. As such, unlike 3DGS our formulation doesnot suffer from popping artifacts and view dependent density, but stillachieves frame rates of $\sim\!30$ FPS at 720p on an NVIDIA RTX4090. Since ourapproach is built upon ray tracing it enables effects such as defocus blur andcamera distortion (e.g. such as from fisheye cameras), which are difficult toachieve by rasterization. We show that our method is more accurate with fewerblending issues than 3DGS and follow-up work on view-consistent rendering,especially on the challenging large-scale scenes from the Zip-NeRF datasetwhere it achieves sharpest results among real-time techniques.</description><author>Alexander Mai, Peter Hedman, George Kopanas, Dor Verbin, David Futschik, Qiangeng Xu, Falko Kuester, Jonathan T. Barron, Yinda Zhang</author><pubDate>Fri, 18 Oct 2024 17:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01804v4</guid></item><item><title>Contextual Document Embeddings</title><link>http://arxiv.org/abs/2410.02525v3</link><description>Dense document embeddings are central to neural retrieval. The dominantparadigm is to train and construct embeddings by running encoders directly onindividual documents. In this work, we argue that these embeddings, whileeffective, are implicitly out-of-context for targeted use cases of retrieval,and that a contextualized document embedding should take into account both thedocument and neighboring documents in context - analogous to contextualizedword embeddings. We propose two complementary methods for contextualizeddocument embeddings: first, an alternative contrastive learning objective thatexplicitly incorporates the document neighbors into the intra-batch contextualloss; second, a new contextual architecture that explicitly encodes neighbordocument information into the encoded representation. Results show that bothmethods achieve better performance than biencoders in several settings, withdifferences especially pronounced out-of-domain. We achieve state-of-the-artresults on the MTEB benchmark with no hard negative mining, score distillation,dataset-specific instructions, intra-GPU example-sharing, or extremely largebatch sizes. Our method can be applied to improve performance on anycontrastive learning dataset and any biencoder.</description><author>John X. Morris, Alexander M. Rush</author><pubDate>Fri, 18 Oct 2024 17:18:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02525v3</guid></item><item><title>Learning Linear Attention in Polynomial Time</title><link>http://arxiv.org/abs/2410.10101v2</link><description>Previous research has explored the computational expressivity of Transformermodels in simulating Boolean circuits or Turing machines. However, thelearnability of these simulators from observational data has remained an openquestion. Our study addresses this gap by providing the first polynomial-timelearnability results (specifically strong, agnostic PAC learning) forsingle-layer Transformers with linear attention. We show that linear attentionmay be viewed as a linear predictor in a suitably defined RKHS. As aconsequence, the problem of learning any linear transformer may be convertedinto the problem of learning an ordinary linear predictor in an expandedfeature space, and any such predictor may be converted back into a multiheadedlinear transformer. Moving to generalization, we show how to efficientlyidentify training datasets for which every empirical risk minimizer isequivalent (up to trivial symmetries) to the linear Transformer that generatedthe data, thereby guaranteeing the learned model will correctly generalizeacross all inputs. Finally, we provide examples of computations expressible vialinear attention and therefore polynomial-time learnable, including associativememories, finite automata, and a class of Universal Turing Machine (UTMs) withpolynomially bounded computation histories. We empirically validate ourtheoretical findings on three tasks: learning random linear attention networks,key--value associations, and learning to execute finite automata. Our findingsbridge a critical gap between theoretical expressivity and learnability ofTransformers, and show that flexible and general models of computation areefficiently learnable.</description><author>Morris Yau, Ekin Akyürek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas</author><pubDate>Fri, 18 Oct 2024 17:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10101v2</guid></item><item><title>Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor Environments</title><link>http://arxiv.org/abs/2410.14616v1</link><description>Deep Reinforcement learning (DRL) is used to enable autonomous navigation inunknown environments. Most research assume perfect sensor data, but real-worldenvironments may contain natural and artificial sensor noise and denial. Here,we present a benchmark of both well-used and emerging DRL algorithms in anavigation task with configurable sensor denial effects. In particular, we areinterested in comparing how different DRL methods (e.g. model-free PPO vs.model-based DreamerV3) are affected by sensor denial. We show that DreamerV3outperforms other methods in the visual end-to-end navigation task with adynamic goal - and other methods are not able to learn this. Furthermore,DreamerV3 generally outperforms other methods in sensor-denied environments. Inorder to improve robustness, we use adversarial training and demonstrate animproved performance in denied environments, although this generally comes witha performance cost on the vanilla environments. We anticipate this benchmark ofdifferent DRL methods and the usage of adversarial training to be a startingpoint for the development of more elaborate navigation strategies that arecapable of dealing with uncertain and denied sensor readings.</description><author>Mariusz Wisniewski, Paraskevas Chatzithanos, Weisi Guo, Antonios Tsourdos</author><pubDate>Fri, 18 Oct 2024 17:14:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14616v1</guid></item><item><title>Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions</title><link>http://arxiv.org/abs/2410.14615v1</link><description>This paper addresses the problem of detecting changes when only unnormalizedpre- and post-change distributions are accessible. This situation happens inmany scenarios in physics such as in ferromagnetism, crystallography,magneto-hydrodynamics, and thermodynamics, where the energy models aredifficult to normalize. Our approach is based on the estimation of the Cumulative Sum (CUSUM)statistics, which is known to produce optimal performance. We first present anintuitively appealing approximation method. Unfortunately, this produces abiased estimator of the CUSUM statistics and may cause performance degradation.We then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)algorithm based on thermodynamic integration (TI) in order to estimate thelog-ratio of normalizing constants of pre- and post-change distributions. It isproved that this approach gives an unbiased estimate of the log-partitionfunction and the CUSUM statistics, and leads to an asymptotically optimalperformance. Moreover, we derive a relationship between the required samplesize for thermodynamic integration and the desired detection delay performance,offering guidelines for practical parameter selection. Numerical studies areprovided demonstrating the efficacy of our approach.</description><author>Arman Adibi, Sanjeev Kulkarni, H. Vincent Poor, Taposh Banerjee, Vahid Tarokh</author><pubDate>Fri, 18 Oct 2024 17:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14615v1</guid></item><item><title>One size doesn't fit all: Predicting the Number of Examples for In-Context Learning</title><link>http://arxiv.org/abs/2403.06402v2</link><description>In-context learning (ICL) refers to the process of adding a small number oflocalized examples (ones that are semantically similar to the input) from atraining set of labelled data to an LLM's prompt with an objective toeffectively control the generative process seeking to improve the downstreamtask performance. Existing ICL approaches use an identical number of examples(a pre-configured hyper-parameter) for each data instance. Our work alleviatesthe limitations of this 'one fits all' approach by dynamically predicting thenumber of examples for each data instance to be used in few-shot inference withLLMs. In particular, we employ a multi-label classifier, the parameters ofwhich are fitted using a training set, where the label for each instance in thetraining set indicates if using a specific value of k (number of most similarexamples from 0 up to a maximum value) leads to correct k-shot downstreampredictions. Our experiments on a number of text classification benchmarks showthat AICL substantially outperforms standard ICL by up to 17%.</description><author>Manish Chandra, Debasis Ganguly, Iadh Ounis</author><pubDate>Fri, 18 Oct 2024 17:10:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06402v2</guid></item><item><title>Modular Boundaries in Recurrent Neural Networks</title><link>http://arxiv.org/abs/2310.20601v2</link><description>Recent theoretical and experimental work in neuroscience has focused on therepresentational and dynamical character of neural manifolds --subspaces inneural activity space wherein many neurons coactivate. Importantly, neuralpopulations studied under this "neural manifold hypothesis" are continuous andnot cleanly divided into separate neural populations. This perspective clasheswith the "modular hypothesis" of brain organization, wherein neural elementsmaintain an "all-or-nothing" affiliation with modules. In line with thismodular hypothesis, recent research on recurrent neural networks suggests thatmulti-task networks become modular across training, such that different modulesspecialize for task-general dynamical motifs. If the modular hypothesis istrue, then it would be important to use a dimensionality reduction techniquethat captures modular structure. Here, we investigate the features of such amethod. We leverage RNNs as a model system to study the character of modularneural populations, using a community detection method from network scienceknown as modularity maximization to partition neurons into distinct modules.These partitions allow us to ask the following question: do these modularboundaries matter to the system? ...</description><author>Jacob Tanner, Sina Mansour L., Ludovico Coletta, Alessandro Gozzi, Richard F. Betzel</author><pubDate>Fri, 18 Oct 2024 17:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20601v2</guid></item><item><title>MultiOrg: A Multi-rater Organoid-detection Dataset</title><link>http://arxiv.org/abs/2410.14612v1</link><description>High-throughput image analysis in the biomedical domain has gainedsignificant attention in recent years, driving advancements in drug discovery,disease prediction, and personalized medicine. Organoids, specifically, are anactive area of research, providing excellent models for human organs and theirfunctions. Automating the quantification of organoids in microscopy imageswould provide an effective solution to overcome substantial manualquantification bottlenecks, particularly in high-throughput image analysis.However, there is a notable lack of open biomedical datasets, in contrast toother domains, such as autonomous driving, and, notably, only few of them haveattempted to quantify annotation uncertainty. In this work, we present MultiOrga comprehensive organoid dataset tailored for object detection tasks withuncertainty quantification. This dataset comprises over 400 high-resolution 2dmicroscopy images and curated annotations of more than 60,000 organoids. Mostimportantly, it includes three label sets for the test data, independentlyannotated by two experts at distinct time points. We additionally provide abenchmark for organoid detection, and make the best model available through aneasily installable, interactive plugin for the popular image visualization toolNapari, to perform organoid quantification.</description><author>Christina Bukas, Harshavardhan Subramanian, Fenja See, Carina Steinchen, Ivan Ezhov, Gowtham Boosarpu, Sara Asgharpour, Gerald Burgstaller, Mareike Lehmann, Florian Kofler, Marie Piraud</author><pubDate>Fri, 18 Oct 2024 17:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14612v1</guid></item><item><title>DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual Distillation in Conversational Search</title><link>http://arxiv.org/abs/2410.14609v1</link><description>Conversational Search (CS) is the task of retrieving relevant documents froma corpus within a conversational context, combining retrieval withconversational context modeling. With the explosion of Large Language Models(LLMs), the CS field has seen major improvements with LLMs rewriting userqueries, accounting for conversational context. However, engaging LLMs atinference time harms efficiency. Current methods address this by distillingembeddings from human-rewritten queries to learn the context modeling task.Yet, these approaches predominantly focus on context modeling, and only treatthe contrastive component of the retrieval task within adistillation-independent loss term. To address these limitations, we propose anew distillation method, as a relaxation of the previous objective, unifyingretrieval and context modeling. We relax the existing training objectives bydistilling similarity scores between conversations and documents, rather thanrelying solely on representation learning. Our proposed distillation objectiveallows for more freedom in the representation space and leverages thecontrastive nature of document relevance. Through experiments on Learned SparseRetrieval (LSR) across 5 CS datasets, our approach demonstrates substantialimprovements in both in-domain and out-of-domain retrieval performance,outperforming state-of-the-art with gains of up to 6 points in recall forout-of-domain datasets. Additionally, through the relaxation of the objective,we propose a multi-teacher distillation, using multiple LLMs as teachers,yielding additional gains, and outperforming the teachers themselves inin-domain experiments. Finally, analysis of the sparsity of the models revealsthat our distillation allows for better control over the sparsity of thetrained models.</description><author>Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas</author><pubDate>Fri, 18 Oct 2024 17:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14609v1</guid></item><item><title>Streaming Deep Reinforcement Learning Finally Works</title><link>http://arxiv.org/abs/2410.14606v1</link><description>Natural intelligence processes experience as a continuous stream, sensing,acting, and learning moment-by-moment in real time. Streaming learning, themodus operandi of classic reinforcement learning (RL) algorithms likeQ-learning and TD, mimics natural learning by using the most recent samplewithout storing it. This approach is also ideal for resource-constrained,communication-limited, and privacy-sensitive applications. However, in deep RL,learners almost always use batch updates and replay buffers, making themcomputationally expensive and incompatible with streaming learning. Althoughthe prevalence of batch deep RL is often attributed to its sample efficiency, amore critical reason for the absence of streaming deep RL is its frequentinstability and failure to learn, which we refer to as stream barrier. Thispaper introduces the stream-x algorithms, the first class of deep RL algorithmsto overcome stream barrier for both prediction and control and match sampleefficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,and Atari Games, we demonstrate stream barrier in existing algorithms andsuccessful stable learning with our stream-x algorithms: stream Q, stream AC,and stream TD, achieving the best model-free performance in DM Control Dogenvironments. A set of common techniques underlies the stream-x algorithms,enabling their success with a single set of hyperparameters and allowing foreasy extension to other algorithms, thereby reviving streaming RL.</description><author>Mohamed Elsayed, Gautham Vasan, A. Rupam Mahmood</author><pubDate>Fri, 18 Oct 2024 17:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14606v1</guid></item><item><title>Learning to Control the Smoothness of Graph Convolutional Network Features</title><link>http://arxiv.org/abs/2410.14604v1</link><description>The pioneering work of Oono and Suzuki [ICLR, 2020] and Cai and Wang[arXiv:2006.13318] initializes the analysis of the smoothness of graphconvolutional network (GCN) features. Their results reveal an intricateempirical correlation between node classification accuracy and the ratio ofsmooth to non-smooth feature components. However, the optimal ratio that favorsnode classification is unknown, and the non-smooth features of deep GCN withReLU or leaky ReLU activation function diminish. In this paper, we propose anew strategy to let GCN learn node features with a desired smoothness --adapting to data and tasks -- to enhance node classification. Our approach hasthree key steps: (1) We establish a geometric relationship between the inputand output of ReLU or leaky ReLU. (2) Building on our geometric insights, weaugment the message-passing process of graph convolutional layers (GCLs) with alearnable term to modulate the smoothness of node features with computationalefficiency. (3) We investigate the achievable ratio between smooth andnon-smooth feature components for GCNs with the augmented message-passingscheme. Our extensive numerical results show that the augmented message-passingschemes significantly improve node classification for GCN and some relatedmodels.</description><author>Shih-Hsin Wang, Justin Baker, Cory Hauck, Bao Wang</author><pubDate>Fri, 18 Oct 2024 16:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14604v1</guid></item><item><title>How Does Data Diversity Shape the Weight Landscape of Neural Networks?</title><link>http://arxiv.org/abs/2410.14602v1</link><description>To enhance the generalization of machine learning models to unseen data,techniques such as dropout, weight decay ($L_2$ regularization), and noiseaugmentation are commonly employed. While regularization methods (i.e., dropoutand weight decay) are geared toward adjusting model parameters to preventoverfitting, data augmentation increases the diversity of the input trainingset, a method purported to improve accuracy and calibration error. In thispaper, we investigate the impact of each of these techniques on the parameterspace of neural networks, with the goal of understanding how they alter theweight landscape in transfer learning scenarios. To accomplish this, we employRandom Matrix Theory to analyze the eigenvalue distributions of pre-trainedmodels, fine-tuned using these techniques but using different levels of datadiversity, for the same downstream tasks. We observe that diverse datainfluences the weight landscape in a similar fashion as dropout. Additionally,we compare commonly used data augmentation methods with synthetic data createdby generative models. We conclude that synthetic data can bring more diversityinto real input data, resulting in a better performance on out-of-distributiontest instances.</description><author>Yang Ba, Michelle V. Mancenido, Rong Pan</author><pubDate>Fri, 18 Oct 2024 16:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14602v1</guid></item><item><title>TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs</title><link>http://arxiv.org/abs/2406.09639v2</link><description>Multi-relational temporal graphs are powerful tools for modeling real-worlddata, capturing the evolving and interconnected nature of entities over time.Recently, many novel models are proposed for ML on such graphs intensifying theneed for robust evaluation and standardized benchmark datasets. However, theavailability of such resources remains scarce and evaluation faces addedcomplexity due to reproducibility issues in experimental protocols. To addressthese challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novelbenchmarking framework tailored for evaluating methods for predicting futurelinks on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with afocus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0facilitates comprehensive evaluations by presenting eight novel datasetsspanning five domains with up to 53 million edges. TGB 2.0 datasets aresignificantly larger than existing datasets in terms of number of nodes, edges,or timestamps. In addition, TGB 2.0 provides a reproducible and realisticevaluation pipeline for multi-relational temporal graphs. Through extensiveexperimentation, we observe that 1) leveraging edge-type information is crucialto obtain high performance, 2) simple heuristic baselines are often competitivewith more complex methods, 3) most methods fail to run on our largest datasets,highlighting the need for research on more scalable methods.</description><author>Julia Gastinger, Shenyang Huang, Mikhail Galkin, Erfan Loghmani, Ali Parviz, Farimah Poursafaei, Jacob Danovitch, Emanuele Rossi, Ioannis Koutis, Heiner Stuckenschmidt, Reihaneh Rabbany, Guillaume Rabusseau</author><pubDate>Fri, 18 Oct 2024 16:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09639v2</guid></item><item><title>Teaching Models to Balance Resisting and Accepting Persuasion</title><link>http://arxiv.org/abs/2410.14596v1</link><description>Large language models (LLMs) are susceptible to persuasion, which can poserisks when models are faced with an adversarial interlocutor. We take a firststep towards defending models against persuasion while also arguing thatdefense against adversarial (i.e. negative) persuasion is only half of theequation: models should also be able to accept beneficial (i.e. positive)persuasion to improve their answers. We show that optimizing models for onlyone side results in poor performance on the other. In order to balance positiveand negative persuasion, we introduce Persuasion-Balanced Training (or PBT),which leverages multi-agent recursive dialogue trees to create data and trainsmodels via preference optimization to accept persuasion when appropriate. PBTconsistently improves resistance to misinformation and resilience to beingchallenged while also resulting in the best overall performance on holisticdata containing both positive and negative persuasion. Crucially, we show thatPBT models are better teammates in multi-agent debates. We find that withoutPBT, pairs of stronger and weaker models have unstable performance, with theorder in which the models present their answers determining whether the teamobtains the stronger or weaker model's performance. PBT leads to better andmore stable results and less order dependence, with the stronger modelconsistently pulling the weaker one up.</description><author>Elias Stengel-Eskin, Peter Hase, Mohit Bansal</author><pubDate>Fri, 18 Oct 2024 16:49:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14596v1</guid></item><item><title>DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail Recovery and a Novel Contrastive Learning Paradigm</title><link>http://arxiv.org/abs/2410.14595v1</link><description>Image dehazing is crucial for clarifying images obscured by haze or fog, butcurrent learning-based approaches is dependent on large volumes of trainingdata and hence consumed significant computational power. Additionally, theirperformance is often inadequate under non-uniform or heavy haze. To addressthese challenges, we developed the Detail Recovery And Contrastive DehazeNet,which facilitates efficient and effective dehazing via a dense dilated invertedresidual block and an attention-based detail recovery network that tailorsenhancements to specific dehazed scene contexts. A major innovation is itsability to train effectively with limited data, achieved through a novelquadruplet loss-based contrastive dehazing paradigm. This approach distinctlyseparates hazy and clear image features while also distinguish lower-qualityand higher-quality dehazed images obtained from each sub-modules of ournetwork, thereby refining the dehazing process to a larger extent. Extensivetests on a variety of benchmarked haze datasets demonstrated the superiority ofour approach. The code repository for this work will be available soon.</description><author>Gao Yu Lee, Tanmoy Dam, Md Meftahul Ferdaus, Daniel Puiu Poenar, Vu Duong</author><pubDate>Fri, 18 Oct 2024 16:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14595v1</guid></item><item><title>Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases</title><link>http://arxiv.org/abs/2410.14594v1</link><description>Recent advancements in tool-equipped Agents (LLMs) have enabled complex taskslike secure database interactions and multi-agent code development. However,scaling tool capacity beyond agent reasoning or model limits remains achallenge. In this paper, we address these challenges by introducing ToolshedKnowledge Bases, a tool knowledge base (vector database) designed to storeenhanced tool representations and optimize tool selection for large-scaletool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, anovel ensemble of tool-applied advanced retrieval-augmented generation (RAG)techniques across the pre-retrieval, intra-retrieval, and post-retrievalphases, without requiring model fine-tuning. During pre-retrieval, tooldocuments are enhanced with key information and stored in the ToolshedKnowledge Base. Intra-retrieval focuses on query planning and transformation toincrease retrieval accuracy. Post-retrieval refines the retrieved tooldocuments and enables self-reflection. Furthermore, by varying both the totalnumber of tools (tool-M) an Agent has access to and the tool selectionthreshold (top-k), we address trade-offs between retrieval accuracy, agentperformance, and token cost. Our approach achieves 46%, 56%, and 47% absoluteimprovements on the ToolE single-tool, ToolE multi-tool and Seal-Toolsbenchmark datasets, respectively (Recall@5).</description><author>Elias Lumer</author><pubDate>Fri, 18 Oct 2024 16:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14594v1</guid></item><item><title>Movie101v2: Improved Movie Narration Benchmark</title><link>http://arxiv.org/abs/2404.13370v2</link><description>Automatic movie narration aims to generate video-aligned plot descriptions toassist visually impaired audiences. Unlike standard video captioning, itinvolves not only describing key visual details but also inferring plots thatunfold across multiple movie shots, presenting distinct and complex challenges.To advance this field, we introduce Movie101v2, a large-scale, bilingualdataset with enhanced data quality specifically designed for movie narration.Revisiting the task, we propose breaking down the ultimate goal of automaticmovie narration into three progressive stages, offering a clear roadmap withcorresponding evaluation metrics. Based on our new benchmark, we baseline arange of large vision-language models, including GPT-4V, and conduct anin-depth analysis of the challenges in narration generation. Our findingshighlight that achieving applicable movie narration generation is a fascinatinggoal that requires significant research.</description><author>Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin</author><pubDate>Fri, 18 Oct 2024 16:44:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13370v2</guid></item><item><title>Temporal Fair Division of Indivisible Items</title><link>http://arxiv.org/abs/2410.14593v1</link><description>We study a fair division model where indivisible items arrive sequentially,and must be allocated immediately and irrevocably. Previous work on online fairdivision has shown impossibility results in achieving approximate envy-freenessunder these constraints. In contrast, we consider an informed setting where thealgorithm has complete knowledge of future items, and aim to ensure that thecumulative allocation at each round satisfies approximate envy-freeness --which we define as temporal envy-freeness up to one item (TEF1). We focus onsettings where items can be exclusively goods or exclusively chores. For goods,while TEF1 allocations may not always exist, we identify several special caseswhere they do -- two agents, two item types, generalized binary valuations,unimodal preferences -- and provide polynomial-time algorithms for these cases.We also prove that determining the existence of a TEF1 allocation is NP-hard.For chores, we establish analogous results for the special cases, but present aslightly weaker intractability result. We also establish the incompatibilitybetween TEF1 and Pareto-optimality, with the implication that it is intractableto find a TEF1 allocation that maximizes any $p$-mean welfare, even for twoagents.</description><author>Edith Elkind, Alexander Lam, Mohamad Latifian, Tzeh Yuan Neoh, Nicholas Teh</author><pubDate>Fri, 18 Oct 2024 16:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14593v1</guid></item><item><title>Contractivity and linear convergence in bilinear saddle-point problems: An operator-theoretic approach</title><link>http://arxiv.org/abs/2410.14592v1</link><description>We study the convex-concave bilinear saddle-point problem $\min_x \max_y f(x)+ y^\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$are strongly convex, and suitable rank conditions on the matrix $A$ hold. Thesolution of this problem is at the core of many machine learning tasks. Byemploying tools from operator theory, we systematically prove the contractivity(in turn, the linear convergence) of several first-order primal-dualalgorithms, including the Chambolle-Pock method. Our approach results inconcise and elegant proofs, and it yields new convergence guarantees andtighter bounds compared to known results.</description><author>Colin Dirren, Mattia Bianchi, Panagiotis D. Grontas, John Lygeros, Florian Dörfler</author><pubDate>Fri, 18 Oct 2024 16:43:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14592v1</guid></item><item><title>MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback</title><link>http://arxiv.org/abs/2410.13191v2</link><description>Automatic question generation (QG) is essential for AI and NLP, particularlyin intelligent tutoring, dialogue systems, and fact verification. Generatingmultiple-choice questions (MCQG) for professional exams, like the United StatesMedical Licensing Examination (USMLE), is particularly challenging, requiringdomain expertise and complex multi-hop reasoning for high-quality questions.However, current large language models (LLMs) like GPT-4 struggle withprofessional MCQG due to outdated knowledge, hallucination issues, and promptsensitivity, resulting in unsatisfactory quality and difficulty. To addressthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critiqueand Correction) framework for converting medical cases into high-qualityUSMLE-style questions. By integrating expert-driven prompt engineering withiterative self-critique and self-correction feedback, MCQG-SRefinesignificantly enhances human expert satisfaction regarding both the quality anddifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-basedautomatic metric to replace the complex and costly expert evaluation process,ensuring reliable and expert-aligned assessments.</description><author>Zonghai Yao, Aditya Parashar, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Zhichao Yang, Hong Yu</author><pubDate>Fri, 18 Oct 2024 16:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13191v2</guid></item><item><title>A Lipschitz spaces view of infinitely wide shallow neural networks</title><link>http://arxiv.org/abs/2410.14591v1</link><description>We revisit the mean field parametrization of shallow neural networks, usingsigned measures on unbounded parameter spaces and duality pairings that takeinto account the regularity and growth of activation functions. This settingdirectly leads to the use of unbalanced Kantorovich-Rubinstein norms defined byduality with Lipschitz functions, and of spaces of measures dual to those ofcontinuous functions with controlled growth. These allow to make transparentthe need for total variation and moment bounds or penalization to obtainexistence of minimizers of variational formulations, under which we prove acompactness result in strong Kantorovich-Rubinstein norm, and in the absence ofwhich we show several examples demonstrating undesirable behavior. Further, theKantorovich-Rubinstein setting enables us to combine the advantages of acompletely linear parametrization and ensuing reproducing kernel Banach spaceframework with optimal transport insights. We showcase this synergy withrepresenter theorems and uniform large data limits for empirical riskminimization, and in proposed formulations for distillation and fusionapplications.</description><author>Francesca Bartolucci, Marcello Carioni, José A. Iglesias, Yury Korolev, Emanuele Naldi, Stefano Vigogna</author><pubDate>Fri, 18 Oct 2024 16:41:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14591v1</guid></item><item><title>Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum</title><link>http://arxiv.org/abs/2410.14589v1</link><description>There is increasing interest in looking at dialects in NLP. However, mostwork to date still treats dialects as discrete categories. For instance,evaluative work in variation-oriented NLP for English often works with IndianEnglish or African-American Venacular English as homogeneous categories (Faisalet al., 2024; Ziems et al., 2023), yet even within one variety there issubstantial variation. We examine within-dialect variation and show thatperformance critically varies within categories. We measure speech-to-textperformance on Italian dialects, and empirically observe a geographicalperformance disparity. This disparity correlates substantially (-0.5) withlinguistic similarity to the highest performing dialect variety. Wecross-examine our results against dialectometry methods, and interpret theperformance disparity to be due to a bias towards dialects that are moresimilar to the standard variety in the speech-to-text model examined. Weadditionally leverage geostatistical methods to predict zero-shot performanceat unseen sites, and find the incorporation of geographical information tosubstantially improve prediction performance, indicating there to begeographical structure in the performance distribution.</description><author>Ryan Soh-Eun Shim, Barbara Plank</author><pubDate>Fri, 18 Oct 2024 16:39:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14589v1</guid></item><item><title>Learning With Multi-Group Guarantees For Clusterable Subpopulations</title><link>http://arxiv.org/abs/2410.14588v1</link><description>A canonical desideratum for prediction problems is that performanceguarantees should hold not just on average over the population, but also formeaningful subpopulations within the overall population. But what constitutes ameaningful subpopulation? In this work, we take the perspective that relevantsubpopulations should be defined with respect to the clusters that naturallyemerge from the distribution of individuals for which predictions are beingmade. In this view, a population refers to a mixture model whose componentsconstitute the relevant subpopulations. We suggest two formalisms for capturingper-subgroup guarantees: first, by attributing each individual to the componentfrom which they were most likely drawn, given their features; and second, byattributing each individual to all components in proportion to their relativelikelihood of having been drawn from each component. Using online calibrationas a case study, we study a \variational algorithm that provides guarantees foreach of these formalisms by handling all plausible underlying subpopulationstructures simultaneously, and achieve an $O(T^{1/2})$ rate even when thesubpopulations are not well-separated. In comparison, the more naturalcluster-then-predict approach that first recovers the structure of thesubpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate andrequires the subpopulations to be separable. Along the way, we prove thatproviding per-subgroup calibration guarantees for underlying clusters can beeasier than learning the clusters: separation between median subgroup featuresis required for the latter but not the former.</description><author>Jessica Dai, Nika Haghtalab, Eric Zhao</author><pubDate>Fri, 18 Oct 2024 16:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14588v1</guid></item><item><title>Neuro-Symbolic Traders: Assessing the Wisdom of AI Crowds in Markets</title><link>http://arxiv.org/abs/2410.14587v1</link><description>Deep generative models are becoming increasingly used as tools for financialanalysis. However, it is unclear how these models will influence financialmarkets, especially when they infer financial value in a semi-autonomous way.In this work, we explore the interplay between deep generative models andmarket dynamics. We develop a form of virtual traders that use deep generativemodels to make buy/sell decisions, which we term neuro-symbolic traders, andexpose them to a virtual market. Under our framework, neuro-symbolic tradersare agents that use vision-language models to discover a model of thefundamental value of an asset. Agents develop this model as a stochasticdifferential equation, calibrated to market data using gradient descent. Wetest our neuro-symbolic traders on both synthetic data and real financial timeseries, including an equity stock, commodity, and a foreign exchange pair. Wethen expose several groups of neuro-symbolic traders to a virtual marketenvironment. This market environment allows for feedback between the tradersbelief of the underlying value to the observed price dynamics. We find thatthis leads to price suppression compared to the historical data, highlighting afuture risk to market stability. Our work is a first step towards quantifyingthe effect of deep generative agents on markets dynamics and sets out some ofthe potential risks and benefits of this approach in the future.</description><author>Namid R. Stillman, Rory Baggott</author><pubDate>Fri, 18 Oct 2024 16:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14587v1</guid></item><item><title>Neural Combinatorial Clustered Bandits for Recommendation Systems</title><link>http://arxiv.org/abs/2410.14586v1</link><description>We consider the contextual combinatorial bandit setting where in each round,the learning agent, e.g., a recommender system, selects a subset of "arms,"e.g., products, and observes rewards for both the individual base arms, whichare a function of known features (called "context"), and the super arm (thesubset of arms), which is a function of the base arm rewards. The agent's goalis to simultaneously learn the unknown reward functions and choose thehighest-reward arms. For example, the "reward" may represent a user'sprobability of clicking on one of the recommended products. Conventional banditmodels, however, employ restrictive reward function models in order to obtainperformance guarantees. We make use of deep neural networks to estimate andlearn the unknown reward functions and propose Neural UCB Clustering(NeUClust), which adopts a clustering approach to select the super arm in everyround by exploiting underlying structure in the context space. Unlike priorneural bandit works, NeUClust uses a neural network to estimate the super armreward and select the super arm, thus eliminating the need for a knownoptimization oracle. We non-trivially extend prior neural combinatorial banditworks to prove that NeUClust achieves$\widetilde{O}\left(\widetilde{d}\sqrt{T}\right)$ regret, where $\widetilde{d}$is the effective dimension of a neural tangent kernel matrix, $T$ the number ofrounds. Experiments on real world recommendation datasets show that NeUClustachieves better regret and reward than other contextual combinatorial andneural bandit algorithms.</description><author>Baran Atalar, Carlee Joe-Wong</author><pubDate>Fri, 18 Oct 2024 16:37:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14586v1</guid></item><item><title>MCSFF: Multi-modal Consistency and Specificity Fusion Framework for Entity Alignment</title><link>http://arxiv.org/abs/2410.14584v1</link><description>Multi-modal entity alignment (MMEA) is essential for enhancing knowledgegraphs and improving information retrieval and question-answering systems.Existing methods often focus on integrating modalities through theircomplementarity but overlook the specificity of each modality, which canobscure crucial features and reduce alignment accuracy. To solve this, wepropose the Multi-modal Consistency and Specificity Fusion Framework (MCSFF),which innovatively integrates both complementary and specific aspects ofmodalities. We utilize Scale Computing's hyper-converged infrastructure tooptimize IT management and resource allocation in large-scale data processing.Our framework first computes similarity matrices for each modality usingmodality embeddings to preserve their unique characteristics. Then, aniterative update method denoises and enhances modality features to fullyexpress critical information. Finally, we integrate the updated informationfrom all modalities to create enriched and precise entity representations.Experiments show our method outperforms current state-of-the-art MMEA baselineson the MMKG dataset, demonstrating its effectiveness and practical potential.</description><author>Wei Ai, Wen Deng, Hongyi Chen, Jiayi Du, Tao Meng, Yuntao Shou</author><pubDate>Fri, 18 Oct 2024 16:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14584v1</guid></item><item><title>Privacy-Preserving Decentralized AI with Confidential Computing</title><link>http://arxiv.org/abs/2410.13752v2</link><description>This paper addresses privacy protection in decentralized ArtificialIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, adecentralized AI platform designed for the Web3 domain. Decentralized AIdistributes AI services among multiple entities without centralized oversight,fostering transparency and robustness. However, this structure introducessignificant privacy challenges, as sensitive assets such as proprietary modelsand personal data may be exposed to untrusted participants. Cryptography-basedprivacy protection techniques such as zero-knowledge machine learning (zkML)suffers prohibitive computational overhead. To address the limitation, wepropose leveraging Confidential Computing (CC). Confidential Computingleverages hardware-based Trusted Execution Environments (TEEs) to provideisolation for processing sensitive data, ensuring that both model parametersand user data remain secure, even in decentralized, potentially untrustedenvironments. While TEEs face a few limitations, we believe they can bridge theprivacy gap in decentralized AI. We explore how we can integrate TEEs intoAtoma's decentralized framework.</description><author>Dayeol Lee, Jorge António, Hisham Khan</author><pubDate>Fri, 18 Oct 2024 16:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13752v2</guid></item><item><title>Do LLMs estimate uncertainty well in instruction-following?</title><link>http://arxiv.org/abs/2410.14582v1</link><description>Large language models (LLMs) could be valuable personal AI agents acrossvarious domains, provided they can precisely follow user instructions. However,recent studies have shown significant limitations in LLMs'instruction-following capabilities, raising concerns about their reliability inhigh-stakes applications. Accurately estimating LLMs' uncertainty in adheringto instructions is critical to mitigating deployment risks. We present, to ourknowledge, the first systematic evaluation of the uncertainty estimationabilities of LLMs in the context of instruction-following. Our study identifieskey challenges with existing instruction-following benchmarks, where multiplefactors are entangled with uncertainty stems from instruction-following,complicating the isolation and comparison across methods and models. To addressthese issues, we introduce a controlled evaluation setup with two benchmarkversions of data, enabling a comprehensive comparison of uncertainty estimationmethods under various conditions. Our findings show that existing uncertaintymethods struggle, particularly when models make subtle errors in instructionfollowing. While internal model states provide some improvement, they remaininadequate in more complex scenarios. The insights from our controlledevaluation setups provide a crucial understanding of LLMs' limitations andpotential for uncertainty estimation in instruction-following tasks, paving theway for more trustworthy AI agents.</description><author>Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain</author><pubDate>Fri, 18 Oct 2024 16:32:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14582v1</guid></item><item><title>Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection</title><link>http://arxiv.org/abs/2410.14581v1</link><description>Attention mechanisms have revolutionized several domains of artificialintelligence, such as natural language processing and computer vision, byenabling models to selectively focus on relevant parts of the input data. Whilerecent work has characterized the optimization dynamics of gradient descent(GD) in attention-based models and the structural properties of its preferredsolutions, less is known about more general optimization algorithms such asmirror descent (MD). In this paper, we investigate the convergence propertiesand implicit biases of a family of MD algorithms tailored for softmax attentionmechanisms, with the potential function chosen as the $p$-th power of the$\ell_p$-norm. Specifically, we show that these algorithms converge indirection to a generalized hard-margin SVM with an $\ell_p$-norm objective whenapplied to a classification problem using a softmax attention model. Notably,our theoretical results reveal that the convergence rate is comparable to thatof traditional GD in simpler models, despite the highly nonlinear and nonconvexnature of the present problem. Additionally, we delve into the jointoptimization dynamics of the key-query matrix and the decoder, establishingconditions under which this complex joint optimization converges to theirrespective hard-margin SVM solutions. Lastly, our numerical experiments on realdata demonstrate that MD algorithms improve generalization over standard GD andexcel in optimal token selection.</description><author>Aaron Alvarado Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan</author><pubDate>Fri, 18 Oct 2024 16:32:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14581v1</guid></item><item><title>Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification</title><link>http://arxiv.org/abs/2409.17777v2</link><description>Deep multimodal learning has shown remarkable success by leveragingcontrastive learning to capture explicit one-to-one relations acrossmodalities. However, real-world data often exhibits shared relations beyondsimple pairwise associations. We propose M3CoL, a Multimodal Mixup ContrastiveLearning approach to capture nuanced shared relations inherent in multimodaldata. Our key contribution is a Mixup-based contrastive loss that learns robustrepresentations by aligning mixed samples from one modality with theircorresponding samples from other modalities thereby capturing shared relationsbetween them. For multimodal classification tasks, we introduce a frameworkthat integrates a fusion module with unimodal prediction modules for auxiliarysupervision during training, complemented by our proposed Mixup-basedcontrastive loss. Through extensive experiments on diverse datasets (N24News,ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively capturesshared multimodal relations and generalizes across domains. It outperformsstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achievingcomparable performance on Food-101. Our work highlights the significance oflearning shared relations for robust multimodal learning, opening up promisingavenues for future research.</description><author>Raja Kumar, Raghav Singhal, Pranamya Kulkarni, Deval Mehta, Kshitij Jadhav</author><pubDate>Fri, 18 Oct 2024 16:31:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17777v2</guid></item><item><title>Towards Unsupervised Validation of Anomaly-Detection Models</title><link>http://arxiv.org/abs/2410.14579v1</link><description>Unsupervised validation of anomaly-detection models is a highly challengingtask. While the common practices for model validation involve a labeledvalidation set, such validation sets cannot be constructed when the underlyingdatasets are unlabeled. The lack of robust and efficient unsupervisedmodel-validation techniques presents an acute challenge in the implementationof automated anomaly-detection pipelines, especially when there exists no priorknowledge of the model's performance on similar datasets. This work presents anew paradigm to automated validation of anomaly-detection models, inspired byreal-world, collaborative decision-making mechanisms. We focus on twocommonly-used, unsupervised model-validation tasks -- model selection and modelevaluation -- and provide extensive experimental results that demonstrate theaccuracy and robustness of our approach on both tasks.</description><author>Lihi Idan</author><pubDate>Fri, 18 Oct 2024 16:27:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14579v1</guid></item><item><title>Large Language Models Are Overparameterized Text Encoders</title><link>http://arxiv.org/abs/2410.14578v1</link><description>Large language models (LLMs) demonstrate strong performance as text embeddingmodels when finetuned with supervised contrastive training. However, theirlarge size balloons inference time and memory requirements. In this paper, weshow that by pruning the last $p\%$ layers of an LLM before supervised trainingfor only 1000 steps, we can achieve a proportional reduction in memory andinference time. We evaluate four different state-of-the-art LLMs on textembedding tasks and find that our method can prune up to 30\% of layers withnegligible impact on performance and up to 80\% with only a modest drop. Withonly three lines of code, our method is easily implemented in any pipeline fortransforming LLMs to text encoders. We also propose $\text{L}^3 \text{Prune}$,a novel layer-pruning strategy based on the model's initial loss that providestwo optimal pruning configurations: a large variant with negligible performanceloss and a small variant for resource-constrained settings. On average, thelarge variant prunes 21\% of the parameters with a $-0.3$ performance drop, andthe small variant only suffers from a $-5.1$ decrease while pruning 74\% of themodel. We consider these results strong evidence that LLMs areoverparameterized for text embedding tasks, and can be easily pruned.</description><author>Thennal D K, Tim Fischer, Chris Biemann</author><pubDate>Fri, 18 Oct 2024 16:26:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14578v1</guid></item><item><title>IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera</title><link>http://arxiv.org/abs/2410.08107v2</link><description>Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) fornovel view synthesis have achieved remarkable progress with frame-based camera(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a noveltype of bio-inspired visual sensor, i.e. event camera, has demonstratedadvantages in high temporal resolution, high dynamic range, low powerconsumption and low latency. Due to its unique asynchronous and irregular datacapturing process, limited work has been proposed to apply neuralrepresentation or 3D Gaussian splatting for an event camera. In this work, wepresent IncEventGS, an incremental 3D Gaussian Splatting reconstructionalgorithm with a single event camera. To recover the 3D scene representationincrementally, we exploit the tracking and mapping paradigm of conventionalSLAM pipelines for IncEventGS. Given the incoming event stream, the trackerfirstly estimates an initial camera motion based on prior reconstructed 3D-GSscene representation. The mapper then jointly refines both the 3D scenerepresentation and camera motion based on the previously estimated motiontrajectory from the tracker. The experimental results demonstrate thatIncEventGS delivers superior performance compared to prior NeRF-based methodsand other related baselines, even we do not have the ground-truth camera poses.Furthermore, our method can also deliver better performance compared tostate-of-the-art event visual odometry methods in terms of camera motionestimation. Code is publicly available at:https://github.com/wu-cvgl/IncEventGS.</description><author>Jian Huang, Chengrui Dong, Peidong Liu</author><pubDate>Fri, 18 Oct 2024 16:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08107v2</guid></item><item><title>Scalable Drift Monitoring in Medical Imaging AI</title><link>http://arxiv.org/abs/2410.13174v2</link><description>The integration of artificial intelligence (AI) into medical imaging hasadvanced clinical diagnostics but poses challenges in managing model drift andensuring long-term reliability. To address these challenges, we develop MMC+,an enhanced framework for scalable drift monitoring, building upon theCheXstray framework that introduced real-time drift detection for medicalimaging AI models using multi-modal data concordance. This work extends theoriginal framework's methodologies, providing a more scalable and adaptablesolution for real-world healthcare settings and offers a reliable andcost-effective alternative to continuous performance monitoring addressinglimitations of both continuous and periodic monitoring methods. MMC+ introducescritical improvements to the original framework, including more robust handlingof diverse data streams, improved scalability with the integration offoundation models like MedImageInsight for high-dimensional image embeddingswithout site-specific training, and the introduction of uncertainty bounds tobetter capture drift in dynamic clinical environments. Validated withreal-world data from Massachusetts General Hospital during the COVID-19pandemic, MMC+ effectively detects significant data shifts and correlates themwith model performance changes. While not directly predicting performancedegradation, MMC+ serves as an early warning system, indicating when AI systemsmay deviate from acceptable performance bounds and enabling timelyinterventions. By emphasizing the importance of monitoring diverse data streamsand evaluating data shifts alongside model performance, this work contributesto the broader adoption and integration of AI solutions in clinical settings.</description><author>Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov</author><pubDate>Fri, 18 Oct 2024 16:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13174v2</guid></item><item><title>MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts</title><link>http://arxiv.org/abs/2410.14574v1</link><description>Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleledscalability in deep learning. SMoE has the potential to exponentially increaseparameter count while maintaining the efficiency of the model by onlyactivating a small subset of these parameters for a given sample. However, ithas been observed that SMoE suffers from unstable training and has difficultyadapting to new distributions, leading to the model's lack of robustness todata contamination. To overcome these limitations, we first establish aconnection between the dynamics of the expert representations in SMoEs andgradient descent on a multi-objective optimization problem. Leveraging ourframework, we then integrate momentum into SMoE and propose a new family ofSMoEs named MomentumSMoE. We theoretically prove and numerically demonstratethat MomentumSMoE is more stable and robust than SMoE. In particular, we verifythe advantages of MomentumSMoE over SMoE on a variety of practical tasksincluding ImageNet-1K object recognition and WikiText-103 language modeling. Wedemonstrate the applicability of MomentumSMoE to many types of SMoE models,including those in the Sparse MoE model for vision (V-MoE) and the GeneralistLanguage Model (GLaM). We also show that other advanced momentum-basedoptimization methods, such as Adam, can be easily incorporated into theMomentumSMoE framework for designing new SMoE models with even betterperformance, almost negligible additional computation cost, and simpleimplementations.</description><author>Rachel S. Y. Teo, Tan M. Nguyen</author><pubDate>Fri, 18 Oct 2024 16:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14574v1</guid></item><item><title>Building Trust in Black-box Optimization: A Comprehensive Framework for Explainability</title><link>http://arxiv.org/abs/2410.14573v1</link><description>Optimizing costly black-box functions within a constrained evaluation budgetpresents significant challenges in many real-world applications. SurrogateOptimization (SO) is a common resolution, yet its proprietary nature introducedby the complexity of surrogate models and the sampling core (e.g., acquisitionfunctions) often leads to a lack of explainability and transparency. Whileexisting literature has primarily concentrated on enhancing convergence toglobal optima, the practical interpretation of newly proposed strategiesremains underexplored, especially in batch evaluation settings. In this paper,we propose \emph{Inclusive} Explainability Metrics for Surrogate Optimization(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance thetransparency, trustworthiness, and explainability of the SO approaches. Throughthese metrics, we provide both intermediate and post-hoc explanations topractitioners before and after performing expensive evaluations to gain trust.We consider four primary categories of metrics, each targeting a specificaspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,Optimization Process Metrics, and Feature Importance. Our experimentalevaluations demonstrate the significant potential of the proposed metricsacross different benchmarks.</description><author>Nazanin Nezami, Hadis Anahideh</author><pubDate>Fri, 18 Oct 2024 16:20:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14573v1</guid></item><item><title>TransBox: EL++-closed Ontology Embedding</title><link>http://arxiv.org/abs/2410.14571v1</link><description>OWL (Web Ontology Language) ontologies, which are able to represent bothrelational and type facts as standard knowledge graphs and complex domainknowledge in Description Logic (DL) axioms, are widely adopted in domains suchas healthcare and bioinformatics. Inspired by the success of knowledge graphembeddings, embedding OWL ontologies has gained significant attention in recentyears. Current methods primarily focus on learning embeddings for atomicconcepts and roles, enabling the evaluation based on normalized axioms throughspecially designed score functions. However, they often neglect the embeddingof complex concepts, making it difficult to infer with more intricate axioms.This limitation reduces their effectiveness in advanced reasoning tasks, suchas Ontology Learning and ontology-mediated Query Answering. In this paper, wepropose EL++-closed ontology embeddings which are able to represent any logicalexpressions in DL via composition. Furthermore, we develop TransBox, aneffective EL++-closed ontology embedding method that can handle many-to-one,one-to-many and many-to-many relations. Our extensive experiments demonstratethat TransBox often achieves state-of-the-art performance across variousreal-world datasets for predicting complex axioms.</description><author>Hui Yang, Jiaoyan Chen, Uli Sattler</author><pubDate>Fri, 18 Oct 2024 16:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14571v1</guid></item><item><title>Understanding the difficulty of low-precision post-training quantization of large language models</title><link>http://arxiv.org/abs/2410.14570v1</link><description>Large language models of high parameter counts are computationally expensive,yet can be made much more efficient by compressing their weights to very lownumerical precision. This can be achieved either through post-trainingquantization by minimizing local, layer-wise quantization errors, or throughquantization-aware fine-tuning by minimizing the global loss function. In thisstudy, we discovered that, under the same data constraint, the former approachnearly always fared worse than the latter, a phenomenon particularly prominentwhen the numerical precision is very low. We further showed that thisdifficulty of post-training quantization arose from stark misalignment betweenoptimization of the local and global objective functions. Our findings explainslimited utility in minimization of local quantization error and the importanceof direct quantization-aware fine-tuning, in the regime of large models at verylow precision.</description><author>Zifei Xu, Sayeh Sharify, Wanzin Yazar, Tristan Webb, Xin Wang</author><pubDate>Fri, 18 Oct 2024 16:16:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14570v1</guid></item><item><title>When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs</title><link>http://arxiv.org/abs/2410.14569v1</link><description>Recent advancements in Large Language Models (LLMs) have established them asagentic systems capable of planning and interacting with various tools. TheseLLM agents are often paired with web-based tools, enabling access to diversesources and real-time information. Although these advancements offersignificant benefits across various applications, they also increase the riskof malicious use, particularly in cyberattacks involving personal information.In this work, we investigate the risks associated with misuse of LLM agents incyberattacks involving personal data. Specifically, we aim to understand: 1)how potent LLM agents can be when directed to conduct cyberattacks, 2) howcyberattacks are enhanced by web-based tools, and 3) how affordable and easy itbecomes to launch cyberattacks using LLM agents. We examine three attackscenarios: the collection of Personally Identifiable Information (PII), thegeneration of impersonation posts, and the creation of spear-phishing emails.Our experiments reveal the effectiveness of LLM agents in these attacks: LLMagents achieved a precision of up to 95.9% in collecting PII, up to 93.9% ofimpersonation posts created by LLM agents were evaluated as authentic, and theclick rate for links in spear phishing emails created by LLM agents reached upto 46.67%. Additionally, our findings underscore the limitations of existingsafeguards in contemporary commercial LLMs, emphasizing the urgent need formore robust security measures to prevent the misuse of LLM agents.</description><author>Hanna Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin, Kimin Lee</author><pubDate>Fri, 18 Oct 2024 16:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14569v1</guid></item><item><title>RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions</title><link>http://arxiv.org/abs/2410.14567v1</link><description>Conversational AI agents use Retrieval Augmented Generation (RAG) to provideverifiable document-grounded responses to user inquiries. However, many naturalquestions do not have good answers: about 25\% contain falseassumptions~\cite{Yu2023:CREPE}, and over 50\% areambiguous~\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improvetheir responses to confusing questions. This paper presents a novel syntheticdata generation method to efficiently create a diverse set of context-groundedconfusing questions from a given document corpus. We conduct an empiricalcomparative evaluation of several large language models as RAG agents tomeasure the accuracy of confusion detection and appropriate responsegeneration. We contribute a benchmark dataset to the public domain.</description><author>Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang</author><pubDate>Fri, 18 Oct 2024 16:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14567v1</guid></item><item><title>Learning diffusion at lightspeed</title><link>http://arxiv.org/abs/2406.12616v2</link><description>Diffusion regulates numerous natural processes and the dynamics of manysuccessful generative models. Existing models to learn the diffusion terms fromobservational data rely on complex bilevel optimization problems and model onlythe drift of the system. We propose a new simple model, JKOnet*, which bypassesthe complexity of existing architectures while presenting significantlyenhanced representational capabilities: JKOnet* recovers the potential,interaction, and internal energy components of the underlying diffusionprocess. JKOnet* minimizes a simple quadratic loss and outperforms otherbaselines in terms of sample efficiency, computational complexity, andaccuracy. Additionally, JKOnet* provides a closed-form optimal solution forlinearly parametrized functionals, and, when applied to predict the evolutionof cellular processes from real-world data, it achieves state-of-the-artaccuracy at a fraction of the computational cost of all existing methods. Ourmethodology is based on the interpretation of diffusion processes asenergy-minimizing trajectories in the probability space via the so-called JKOscheme, which we study via its first-order optimality conditions.</description><author>Antonio Terpin, Nicolas Lanzetti, Martin Gadea, Florian Dörfler</author><pubDate>Fri, 18 Oct 2024 16:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12616v2</guid></item><item><title>Measuring Diversity: Axioms and Challenges</title><link>http://arxiv.org/abs/2410.14556v1</link><description>The concept of diversity is widely used in various applications: from imageor molecule generation to recommender systems. Thus, being able to properlymeasure diversity is important. This paper addresses the problem of quantifyingdiversity for a set of objects. First, we make a systematic review of existingdiversity measures and explore their undesirable behavior in some cases. Basedon this review, we formulate three desirable properties (axioms) of a reliablediversity measure: monotonicity, uniqueness, and continuity. We show that noneof the existing measures has all three properties and thus these measures arenot suitable for quantifying diversity. Then, we construct two examples ofmeasures that have all the desirable properties, thus proving that the list ofaxioms is not self-contradicting. Unfortunately, the constructed examples aretoo computationally complex for practical use, thus we pose an open problem ofconstructing a diversity measure that has all the listed properties and can becomputed in practice.</description><author>Mikhail Mironov, Liudmila Prokhorenkova</author><pubDate>Fri, 18 Oct 2024 15:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14556v1</guid></item><item><title>Advocating Character Error Rate for Multilingual ASR Evaluation</title><link>http://arxiv.org/abs/2410.07400v2</link><description>Automatic speech recognition (ASR) systems have traditionally been evaluatedusing English datasets, with the word error rate (WER) serving as thepredominant metric. WER's simplicity and ease of interpretation havecontributed to its widespread adoption, particularly for English. However, asASR systems expand to multilingual contexts, WER fails in various ways,particularly with morphologically complex languages or those without clear wordboundaries. Our work documents the limitations of WER as an evaluation metricand advocates for the character error rate (CER) as the primary metric inmultilingual ASR evaluation. We show that CER avoids many of the challenges WERfaces and exhibits greater consistency across writing systems. We support ourproposition by conducting human evaluations of ASR transcriptions in threelanguages: Malayalam, English, and Arabic, which exhibit distinct morphologicalcharacteristics. We show that CER correlates more closely with human judgmentsthan WER, even for English. To facilitate further research, we release ourhuman evaluation dataset for future benchmarking of ASR metrics. Our findingssuggest that CER should be prioritized, or at least supplemented, inmultilingual ASR evaluations to account for the varying linguisticcharacteristics of different languages.</description><author>Thennal D K, Jesin James, Deepa P Gopinath, Muhammed Ashraf K</author><pubDate>Fri, 18 Oct 2024 15:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07400v2</guid></item><item><title>English offensive text detection using CNN based Bi-GRU model</title><link>http://arxiv.org/abs/2409.15652v3</link><description>Over the years, the number of users of social media has increaseddrastically. People frequently share their thoughts through social platforms,and this leads to an increase in hate content. In this virtual community,individuals share their views, express their feelings, and post photos, videos,blogs, and more. Social networking sites like Facebook and Twitter provideplatforms to share vast amounts of content with a single click. However, theseplatforms do not impose restrictions on the uploaded content, which may includeabusive language and explicit images unsuitable for social media. To resolvethis issue, a new idea must be implemented to divide the inappropriate content.Numerous studies have been done to automate the process. In this paper, wepropose a new Bi-GRU-CNN model to classify whether the text is offensive ornot. The combination of the Bi-GRU and CNN models outperforms the existingmodel.</description><author>Tonmoy Roy, Md Robiul Islam, Asif Ahammad Miazee, Anika Antara, Al Amin, Sunjim Hossain</author><pubDate>Fri, 18 Oct 2024 15:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.15652v3</guid></item><item><title>Boosting K-means for Big Data by Fusing Data Streaming with Global Optimization</title><link>http://arxiv.org/abs/2410.14548v1</link><description>K-means clustering is a cornerstone of data mining, but its efficiencydeteriorates when confronted with massive datasets. To address this limitation,we propose a novel heuristic algorithm that leverages the Variable NeighborhoodSearch (VNS) metaheuristic to optimize K-means clustering for big data. Ourapproach is based on the sequential optimization of the partial objectivefunction landscapes obtained by restricting the Minimum Sum-of-SquaresClustering (MSSC) formulation to random samples from the original big dataset.Within each landscape, systematically expanding neighborhoods of the currentlybest (incumbent) solution are explored by reinitializing all degenerate and avarying number of additional centroids. Extensive and rigorous experimentationon a large number of real-world datasets reveals that by transforming thetraditional local search into a global one, our algorithm significantlyenhances the accuracy and efficiency of K-means clustering in big dataenvironments, becoming the new state of the art in the field.</description><author>Ravil Mussabayev, Rustam Mussabayev</author><pubDate>Fri, 18 Oct 2024 15:43:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14548v1</guid></item><item><title>Retraining with Predicted Hard Labels Provably Increases Model Accuracy</title><link>http://arxiv.org/abs/2406.11206v2</link><description>The performance of a model trained with \textit{noisy labels} is oftenimproved by simply \textit{retraining} the model with its own predicted\textit{hard} labels (i.e., $1$/$0$ labels). Yet, a detailed theoreticalcharacterization of this phenomenon is lacking. In this paper, we theoreticallyanalyze retraining in a linearly separable setting with randomly corruptedlabels given to us and prove that retraining can improve the populationaccuracy obtained by initially training with the given (noisy) labels. To thebest of our knowledge, this is the first such theoretical result. Retrainingfinds application in improving training with local label differential privacy(DP) which involves training with noisy labels. We empirically show thatretraining selectively on the samples for which the predicted label matches thegiven label significantly improves label DP training at \textit{no extraprivacy cost}; we call this \textit{consensus-based retraining}. As an example,when training ResNet-18 on CIFAR-100 with $\epsilon=3$ label DP, we obtain$6.4\%$ improvement in accuracy with consensus-based retraining.</description><author>Rudrajit Das, Inderjit S. Dhillon, Alessandro Epasto, Adel Javanmard, Jieming Mao, Vahab Mirrokni, Sujay Sanghavi, Peilin Zhong</author><pubDate>Fri, 18 Oct 2024 15:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11206v2</guid></item><item><title>Improving Reward Models with Synthetic Critiques</title><link>http://arxiv.org/abs/2405.20850v2</link><description>Reward models (RMs) play a critical role in aligning language models throughthe process of reinforcement learning from human feedback. RMs are trained topredict a score reflecting human preference, which requires significant timeand cost for human annotation. Additionally, RMs tend to quickly overfit onsuperficial features in the training set, hindering their generalizationperformance on unseen distributions. We propose a novel approach usingsynthetic natural language critiques generated by large language models toprovide additional feedback, evaluating aspects such as instruction following,correctness, and style. This offers richer signals and more robust features forRMs to assess and score on. We demonstrate that high-quality critiques improvethe performance and data efficiency of RMs initialized from differentpretrained models, reducing the reliance on costly human annotations.Furthermore, incorporating critiques improves both the interpretability androbustness of RM training.</description><author>Zihuiwen Ye, Fraser Greenlee-Scott, Max Bartolo, Phil Blunsom, Jon Ander Campos, Matthias Gallé</author><pubDate>Fri, 18 Oct 2024 15:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20850v2</guid></item><item><title>With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models</title><link>http://arxiv.org/abs/2409.14917v2</link><description>Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) havedemonstrated aptitude as potential substitutes for human participants inexperiments testing psycholinguistic phenomena. However, an understudiedquestion is to what extent models that only have access to vision and textmodalities are able to implicitly understand sound-based phenomena via abstractreasoning from orthography and imagery alone. To investigate this, we analysethe ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognisea non-arbitrary link between sounds and concepts) as well as their ability to"hear" via the interplay of the language and vision modules of open andclosed-source multimodal models. We perform multiple experiments, includingreplicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolismtasks, and comparing human judgements of linguistic iconicity with that ofLLMs. Our results show that VLMs demonstrate varying levels of agreement withhuman labels, and more task information may be required for VLMs versus theirhuman counterparts for in silico experimentation. We additionally see throughhigher maximum agreement levels that Magnitude Symbolism is an easier patternfor VLMs to identify than Shape Symbolism, and that an understanding oflinguistic iconicity is highly dependent on model size.</description><author>Tyler Loakman, Yucheng Li, Chenghua Lin</author><pubDate>Fri, 18 Oct 2024 15:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.14917v2</guid></item><item><title>Fundus to Fluorescein Angiography Video Generation as a Retinal Generative Foundation Model</title><link>http://arxiv.org/abs/2410.13242v2</link><description>Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoringretinal vascular issues but is limited by its invasive nature and restrictedaccessibility compared to color fundus (CF) imaging. Existing methods thatconvert CF images to FFA are confined to static image generation, missing thedynamic lesional changes. We introduce Fundus2Video, an autoregressivegenerative adversarial network (GAN) model that generates dynamic FFA videosfrom single CF images. Fundus2Video excels in video generation, achieving anFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated thefidelity of the generated videos. Additionally, the model's generatordemonstrates remarkable downstream transferability across ten external publicdatasets, including blood vessel segmentation, retinal disease diagnosis,systemic disease prediction, and multimodal retrieval, showcasing impressivezero-shot and few-shot capabilities. These findings position Fundus2Video as apowerful, non-invasive alternative to FFA exams and a versatile retinalgenerative foundation model that captures both static and temporal retinalfeatures, enabling the representation of complex inter-modality relationships.</description><author>Weiyi Zhang, Jiancheng Yang, Ruoyu Chen, Siyu Huang, Pusheng Xu, Xiaolan Chen, Shanfu Lu, Hongyu Cao, Mingguang He, Danli Shi</author><pubDate>Fri, 18 Oct 2024 15:41:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13242v2</guid></item><item><title>Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization</title><link>http://arxiv.org/abs/2410.14545v1</link><description>Meeting summarization is crucial in digital communication, but existingsolutions struggle with salience identification to generate personalized,workable summaries, and context understanding to fully comprehend the meetings'content. Previous attempts to address these issues by considering relatedsupplementary resources (e.g., presentation slides) alongside transcripts arehindered by models' limited context sizes and handling the additionalcomplexities of the multi-source tasks, such as identifying relevantinformation in additional files and seamlessly aligning it with the meetingcontent. This work explores multi-source meeting summarization consideringsupplementary materials through a three-stage large language model approach:identifying transcript passages needing additional context, inferring relevantdetails from supplementary materials and inserting them into the transcript,and generating a summary from this enriched transcript. Our multi-sourceapproach enhances model understanding, increasing summary relevance by ~9% andproducing more content-rich outputs. We introduce a personalization protocolthat extracts participant characteristics and tailors summaries accordingly,improving informativeness by ~10%. This work further provides insights onperformance-cost trade-offs across four leading model families, includingedge-device capable options. Our approach can be extended to similar complexgenerative tasks benefitting from additional resources and personalization,such as dialogue systems and action planning.</description><author>Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp</author><pubDate>Fri, 18 Oct 2024 15:40:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14545v1</guid></item><item><title>Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models</title><link>http://arxiv.org/abs/2407.02067v2</link><description>We present a comprehensive three-phase study to examine (1) the culturalunderstanding of Large Multimodal Models (LMMs) by introducing DalleStreet, alarge-scale dataset generated by DALL-E 3 and validated by humans, containing9,935 images of 67 countries and 10 concept classes; (2) the underlyingimplicit and potentially stereotypical cultural associations with a culturalartifact extraction task; and (3) an approach to adapt cultural representationin an image based on extracted associations using a modular pipeline,CultureAdapt. We find disparities in cultural understanding at geographicsub-region levels with both open-source (LLaVA) and closed-source (GPT-4V)models on DalleStreet and other existing benchmarks, which we try to understandusing over 18,000 artifacts that we identify in association to differentcountries. Our findings reveal a nuanced picture of the cultural competence ofLMMs, highlighting the need to develop culture-aware systems. Dataset and codeare available at https://github.com/iamshnoo/crossroads</description><author>Anjishnu Mukherjee, Ziwei Zhu, Antonios Anastasopoulos</author><pubDate>Fri, 18 Oct 2024 15:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02067v2</guid></item><item><title>Computational Grounding of Responsibility Attribution and Anticipation in LTLf</title><link>http://arxiv.org/abs/2410.14544v1</link><description>Responsibility is one of the key notions in machine ethics and in the area ofautonomous systems. It is a multi-faceted notion involving counterfactualreasoning about actions and strategies. In this paper, we study differentvariants of responsibility in a strategic setting based on LTLf. We show aconnection with notions in reactive synthesis, including synthesis of winning,dominant, and best-effort strategies. This connection provides the buildingblocks for a computational grounding of responsibility including complexitycharacterizations and sound, complete, and optimal algorithms for attributingand anticipating responsibility.</description><author>Giuseppe De Giacomo, Emiliano Lorini, Timothy Parker, Gianmarco Parretti</author><pubDate>Fri, 18 Oct 2024 15:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14544v1</guid></item><item><title>Clustering of timed sequences -- Application to the analysis of care pathways</title><link>http://arxiv.org/abs/2404.15379v2</link><description>Improving the future of healthcare starts by better understanding the currentactual practices in hospital settings. This motivates the objective ofdiscovering typical care pathways from patient data. Revealing typical carepathways can be achieved through clustering. The difficulty in clustering carepathways, represented by sequences of timestamped events, lies in defining asemantically appropriate metric and clustering algorithms. In this article, weadapt two methods developed for time series to the clustering of timedsequences: the drop-DTW metric and the DBA approach for the construction ofaveraged time sequences. These methods are then applied in clusteringalgorithms to propose original and sound clustering algorithms for timedsequences. This approach is experimented with and evaluated on synthetic andreal-world data.</description><author>Thomas Guyet, Pierre Pinson, Enoal Gesny</author><pubDate>Fri, 18 Oct 2024 15:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15379v2</guid></item><item><title>What's under the hood: Investigating Automatic Metrics on Meeting Summarization</title><link>http://arxiv.org/abs/2404.11124v2</link><description>Meeting summarization has become a critical task considering the increase inonline interactions. While new techniques are introduced regularly, theirevaluation uses metrics not designed to capture meeting-specific errors,undermining effective evaluation. This paper investigates what the frequentlyused automatic metrics capture and which errors they mask by correlatingautomatic metric scores with human evaluations across a broad error taxonomy.We commence with a comprehensive literature review on English meetingsummarization to define key challenges like speaker dynamics and contextualturn-taking and error types such as missing information and linguisticinaccuracy, concepts previously loosely defined in the field. We examine therelationship between characteristic challenges and errors by using annotatedtranscripts and summaries from Transformer-based sequence-to-sequence andautoregressive models from the general summary QMSum dataset. Throughexperimental validation, we find that different model architectures respondvariably to challenges in meeting transcripts, resulting in differentpronounced links between challenges and errors. Current default-used metricsstruggle to capture observable errors, showing weak to mid-correlations, whilea third of the correlations show trends of error masking. Only a subset reactsaccurately to specific errors, while most correlations show eitherunresponsiveness or failure to reflect the error's impact on summary quality.</description><author>Frederic Kirstein, Jan Philip Wahle, Terry Ruas, Bela Gipp</author><pubDate>Fri, 18 Oct 2024 15:34:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11124v2</guid></item><item><title>Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose Prior</title><link>http://arxiv.org/abs/2410.14540v1</link><description>The Skinned Multi-Person Linear (SMPL) model plays a crucial role in 3D humanpose estimation, providing a streamlined yet effective representation of thehuman body. However, ensuring the validity of SMPL configurations during taskssuch as human mesh regression remains a significant challenge , highlightingthe necessity for a robust human pose prior capable of discerning realistichuman poses. To address this, we introduce MOPED:\underline{M}ulti-m\underline{O}dal \underline{P}os\underline{E}\underline{D}iffuser. MOPED is the first method to leverage a novel multi-modalconditional diffusion model as a prior for SMPL pose parameters. Our methodoffers powerful unconditional pose generation with the ability to condition onmulti-modal inputs such as images and text. This capability enhances theapplicability of our approach by incorporating additional context oftenoverlooked in traditional pose priors. Extensive experiments across threedistinct tasks-pose estimation, pose denoising, and pose completion-demonstratethat our multi-modal diffusion model-based prior significantly outperformsexisting methods. These results indicate that our model captures a broaderspectrum of plausible human poses.</description><author>Calvin-Khang Ta, Arindam Dutta, Rohit Kundu, Rohit Lal, Hannah Dela Cruz, Dripta S. Raychaudhuri, Amit Roy-Chowdhury</author><pubDate>Fri, 18 Oct 2024 15:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14540v1</guid></item><item><title>Diffusion-based Semi-supervised Spectral Algorithm for Regression on Manifolds</title><link>http://arxiv.org/abs/2410.14539v1</link><description>We introduce a novel diffusion-based spectral algorithm to tackle regressionanalysis on high-dimensional data, particularly data embedded withinlower-dimensional manifolds. Traditional spectral algorithms often fall shortin such contexts, primarily due to the reliance on predetermined kernelfunctions, which inadequately address the complex structures inherent inmanifold-based data. By employing graph Laplacian approximation, our methoduses the local estimation property of heat kernel, offering an adaptive,data-driven approach to overcome this obstacle. Another distinct advantage ofour algorithm lies in its semi-supervised learning framework, enabling it tofully use the additional unlabeled data. This ability enhances the performanceby allowing the algorithm to dig the spectrum and curvature of the datamanifold, providing a more comprehensive understanding of the dataset.Moreover, our algorithm performs in an entirely data-driven manner, operatingdirectly within the intrinsic manifold structure of the data, without requiringany predefined manifold information. We provide a convergence analysis of ouralgorithm. Our findings reveal that the algorithm achieves a convergence ratethat depends solely on the intrinsic dimension of the underlying manifold,thereby avoiding the curse of dimensionality associated with the higher ambientdimension.</description><author>Weichun Xia, Jiaxin Jiang, Lei Shi</author><pubDate>Fri, 18 Oct 2024 15:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14539v1</guid></item><item><title>On Debiasing Text Embeddings Through Context Injection</title><link>http://arxiv.org/abs/2410.12874v2</link><description>Current advances in Natural Language Processing (NLP) have made itincreasingly feasible to build applications leveraging textual data. Generally,the core of these applications rely on having a good semantic representation oftext into vectors, via embedding models. However, it has been shown that theseembeddings capture and perpetuate biases already present in text. While a fewtechniques have been proposed to debias embeddings, they do not take advantageof the recent advances in context understanding of modern embedding models. Inthis paper, we fill this gap by conducting a review of 19 embedding models byquantifying their biases and how well they respond to context injection as amean of debiasing. We show that higher performing models are more prone tocapturing biases, but are also better at incorporating context. Surprisingly,we find that while models can easily embed affirmative semantics, they fail atembedding neutral semantics. Finally, in a retrieval task, we show that biasesin embeddings can lead to non-desirable outcomes. We use our new-found insightsto design a simple algorithm for top $k$ retrieval, where $k$ is dynamicallyselected. We show that our algorithm is able to retrieve all relevant genderedand neutral chunks.</description><author>Thomas Uriot</author><pubDate>Fri, 18 Oct 2024 15:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12874v2</guid></item><item><title>Train &amp; Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases</title><link>http://arxiv.org/abs/2403.13901v3</link><description>Previous work in phonologically and phonetically grounded language generationhas mainly focused on domains such as puns and poetry. In this article, wepresent new work on the generation of English tongue twisters - a form oflanguage that is required to be conditioned on a phoneme level to maximizesound overlap, while maintaining semantic consistency with an input topic orphrase and still being grammatically correct. We present TwisterLister, apipeline for generating phonologically informed tongue twisters from largelanguage models (LLMs) that we use to generate TwistList 2.0, the largestannotated dataset of tongue twisters to date, consisting of 17K+ examples froma combination of human and LLM authors. Our generation pipeline involves theuse of a phonologically constrained vocabulary alongside LLM prompting togenerate novel, non-derivative tongue twister examples. We additionally presentthe results of automatic and human evaluation of smaller models trained on ourgenerated dataset to demonstrate the extent to which phonologically motivatedlanguage types can be generated without explicit injection of phonologicalknowledge. Additionally, we introduce a phoneme-aware constrained decodingmodule (PACD) that can be integrated into an autoregressive language model anddemonstrate that this method generates good quality tongue twisters both withand without fine-tuning the underlying language model. We also design andimplement a range of automatic metrics for the task of tongue twistergeneration that is phonologically motivated and captures the unique essence oftongue twisters, primarily based on phonemic edit distance (PED)</description><author>Tyler Loakman, Chen Tang, Chenghua Lin</author><pubDate>Fri, 18 Oct 2024 15:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13901v3</guid></item><item><title>A Hybrid Feature Fusion Deep Learning Framework for Leukemia Cancer Detection in Microscopic Blood Sample Using Gated Recurrent Unit and Uncertainty Quantification</title><link>http://arxiv.org/abs/2410.14536v1</link><description>Acute lymphoblastic leukemia (ALL) is the most malignant form of leukemia andthe most common cancer in adults and children. Traditionally, leukemia isdiagnosed by analyzing blood and bone marrow smears under a microscope, withadditional cytochemical tests for confirmation. However, these methods areexpensive, time consuming, and highly dependent on expert knowledge. In recentyears, deep learning, particularly Convolutional Neural Networks (CNNs), hasprovided advanced methods for classifying microscopic smear images, aiding inthe detection of leukemic cells. These approaches are quick, cost effective,and not subject to human bias. However, most methods lack the ability toquantify uncertainty, which could lead to critical misdiagnoses. In thisresearch, hybrid deep learning models (InceptionV3-GRU, EfficientNetB3-GRU,MobileNetV2-GRU) were implemented to classify ALL. Bayesian optimization wasused to fine tune the model's hyperparameters and improve its performance.Additionally, Deep Ensemble uncertainty quantification was applied to addressuncertainty during leukemia image classification. The proposed models weretrained on the publicly available datasets ALL-IDB1 and ALL-IDB2. Their resultswere then aggregated at the score level using the sum rule. The parallelarchitecture used in these models offers a high level of confidence indifferentiating between ALL and non-ALL cases. The proposed method achieved aremarkable detection accuracy rate of 100% on the ALL-IDB1 dataset, 98.07% onthe ALL-IDB2 dataset, and 98.64% on the combined dataset, demonstrating itspotential for accurate and reliable leukemia diagnosis.</description><author>Maksuda Akter, Rabea Khatun, Md Manowarul Islam</author><pubDate>Fri, 18 Oct 2024 15:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14536v1</guid></item><item><title>Comparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map</title><link>http://arxiv.org/abs/2410.14535v1</link><description>With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehiclecommunications, radio propagation modeling tools must adapt to the rapidlychanging nature of the radio channel. Recently, both Differentiable and DynamicRay Tracing frameworks have emerged to address these challenges. However, thereis often confusion about how these approaches differ and which one should beused in specific contexts. In this paper, we provide an overview of these twotechniques and a comparative analysis against two state-of-the-art tools:3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precisecharacterization of the scope of these methods, we introduce a novelsimulation-based metric, the Multipath Lifetime Map, which enables theevaluation of spatial and temporal coherence in radio channels only based onthe geometrical description of the environment. Finally, our metrics areevaluated on a classic urban street canyon scenario, yielding similar resultsto those obtained from measurement campaigns.</description><author>Jérome Eertmans, Enrico Maria Vittuci, Vittorio Degli Esposti, Laurent Jacques, Claude Oestges</author><pubDate>Fri, 18 Oct 2024 15:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14535v1</guid></item><item><title>Inferring Change Points in High-Dimensional Regression via Approximate Message Passing</title><link>http://arxiv.org/abs/2404.07864v2</link><description>We consider the problem of localizing change points in a generalized linearmodel (GLM), a model that covers many widely studied problems in statisticallearning including linear, logistic, and rectified linear regression. Wepropose a novel and computationally efficient Approximate Message Passing (AMP)algorithm for estimating both the signals and the change point locations, andrigorously characterize its performance in the high-dimensional limit where thenumber of parameters $p$ is proportional to the number of samples $n$. Thischaracterization is in terms of a state evolution recursion, which allows us toprecisely compute performance measures such as the asymptotic Hausdorff errorof our change point estimates, and allows us to tailor the algorithm to takeadvantage of any prior structural information on the signals and change points.Moreover, we show how our AMP iterates can be used to efficiently compute aBayesian posterior distribution over the change point locations in thehigh-dimensional limit. We validate our theory via numerical experiments, anddemonstrate the favorable performance of our estimators on both synthetic andreal data in the settings of linear, logistic, and rectified linear regression.</description><author>Gabriel Arpino, Xiaoqi Liu, Julia Gontarek, Ramji Venkataramanan</author><pubDate>Fri, 18 Oct 2024 15:23:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07864v2</guid></item><item><title>Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation</title><link>http://arxiv.org/abs/2406.11580v2</link><description>High-quality Machine Translation (MT) evaluation relies heavily on humanjudgments. Comprehensive error classification methods, such as MultidimensionalQuality Metrics (MQM), are expensive as they are time-consuming and can only bedone by experts, whose availability may be limited especially for low-resourcelanguages. On the other hand, just assigning overall scores, like DirectAssessment (DA), is simpler and faster and can be done by translators of anylevel, but is less reliable. In this paper, we introduce Error Span Annotation(ESA), a human evaluation protocol which combines the continuous rating of DAwith the high-level error severity span marking of MQM. We validate ESA bycomparing it to MQM and DA for 12 MT systems and one human referencetranslation (English to German) from WMT23. The results show that ESA offersfaster and cheaper annotations than MQM at the same quality level, without therequirement of expensive MQM experts.</description><author>Tom Kocmi, Vilém Zouhar, Eleftherios Avramidis, Roman Grundkiewicz, Marzena Karpinska, Maja Popović, Mrinmaya Sachan, Mariya Shmatova</author><pubDate>Fri, 18 Oct 2024 15:20:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11580v2</guid></item><item><title>Kernel Density Estimators in Large Dimensions</title><link>http://arxiv.org/abs/2408.05807v3</link><description>This paper studies Kernel Density Estimation for a high-dimensionaldistribution $\rho(x)$. Traditional approaches have focused on the limit oflarge number of data points $n$ and fixed dimension $d$. We analyze instead theregime where both the number $n$ of data points $y_i$ and their dimensionality$d$ grow with a fixed ratio $\alpha=(\log n)/d$. Our study reveals threedistinct statistical regimes for the kernel-based estimate of the density $\hat\rho_h^{\mathcal {D}}(x)=\frac{1}{n h^d}\sum_{i=1}^nK\left(\frac{x-y_i}{h}\right)$, depending on the bandwidth $h$: a classicalregime for large bandwidth where the Central Limit Theorem (CLT) holds, whichis akin to the one found in traditional approaches. Below a certain value ofthe bandwidth, $h_{CLT}(\alpha)$, we find that the CLT breaks down. Thestatistics of $\hat\rho_h^{\mathcal {D}}(x)$ for a fixed $x$ drawn from$\rho(x)$ is given by a heavy-tailed distribution (an alpha-stabledistribution). In particular below a value $h_G(\alpha)$, we find that$\hat\rho_h^{\mathcal {D}}(x)$ is governed by extreme value statistics: only afew points in the database matter and give the dominant contribution to thedensity estimator. We provide a detailed analysis for high-dimensionalmultivariate Gaussian data. We show that the optimal bandwidth threshold basedon Kullback-Leibler divergence lies in the new statistical regime identified inthis paper. As known by practitioners, when decreasing the bandwidth aKernel-estimated estimated changes from a smooth curve to a collections ofpeaks centred on the data points. Our findings reveal that this generalphenomenon is related to sharp transitions between phases characterized bydifferent statistical properties, and offer new insights for Kernel densityestimation in high-dimensional settings.</description><author>Giulio Biroli, Marc Mézard</author><pubDate>Fri, 18 Oct 2024 15:19:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05807v3</guid></item><item><title>The Traveling Bandit: A Framework for Bayesian Optimization with Movement Costs</title><link>http://arxiv.org/abs/2410.14533v1</link><description>This paper introduces a framework for Bayesian Optimization (BO) with metricmovement costs, addressing a critical challenge in practical applications whereinput alterations incur varying costs. Our approach is a convenient plug-inthat seamlessly integrates with the existing literature on batched algorithms,where designs within batches are observed following the solution of a TravelingSalesman Problem. The proposed method provides a theoretical guarantee ofconvergence in terms of movement costs for BO. Empirically, our methodeffectively reduces average movement costs over time while maintainingcomparable regret performance to conventional BO methods. This framework alsoshows promise for broader applications in various bandit settings with movementcosts.</description><author>Qiyuan Chen, Raed Al Kontar</author><pubDate>Fri, 18 Oct 2024 15:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14533v1</guid></item></channel></rss>