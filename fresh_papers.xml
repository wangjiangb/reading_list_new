<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 02 Oct 2025 13:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LoRA meets Riemannion: Muon Optimizer for Parametrization-independent Low-Rank Adapters</title><link>http://arxiv.org/abs/2507.12142v2</link><description>This work presents a novel, fully Riemannian framework for Low-RankAdaptation (LoRA) that geometrically treats low-rank adapters by optimizingthem directly on the fixed-rank manifold. This formulation eliminates theparametrization ambiguity present in standard Euclidean optimizers. Ourframework integrates three key components to achieve this: (1) we deriveRiemannion, a new Riemannian optimizer on the fixed-rank matrix manifold thatgeneralizes the recently proposed Muon optimizer; (2) we develop a Riemanniangradient-informed LoRA initialization, and (3) we provide an efficientimplementation without prominent overhead that uses automatic differentiationto compute arising geometric operations while adhering to best practices innumerical linear algebra. Comprehensive experimental results on both LLM anddiffusion model architectures demonstrate that our approach yields consistentand noticeable improvements in convergence speed and final task performanceover both standard LoRA and its state-of-the-art modifications.</description><author>Vladimir Bogachev, Vladimir Aletov, Alexander Molozhavenko, Denis Bobkov, Vera Soboleva, Aibek Alanov, Maxim Rakhuba</author><pubDate>Wed, 01 Oct 2025 17:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.12142v2</guid></item><item><title>Grounded GUI Understanding for Vision-Based Spatial Intelligent Agent: Exemplified by Extended Reality Apps</title><link>http://arxiv.org/abs/2409.10811v4</link><description>In recent years, spatial computing a.k.a. Extended Reality (XR) has emergedas a transformative technology, offering users immersive and interactiveexperiences across diversified virtual environments. Users can interact with XRapps through interactable GUI elements (IGEs) on the stereoscopicthree-dimensional (3D) graphical user interface (GUI). The accurate recognitionof these IGEs is instrumental, serving as the foundation of many softwareengineering tasks, including automated testing and effective GUI search. Themost recent IGE detection approaches for 2D mobile apps typically train asupervised object detection model based on a large-scale manually-labeled GUIdataset, usually with a pre-defined set of clickable GUI element categorieslike buttons and spinners. Such approaches can hardly be applied to IGEdetection in XR apps, due to a multitude of challenges including complexitiesposed by open-vocabulary and heterogeneous IGE categories, intricacies ofcontext-sensitive interactability, and the necessities of precise spatialperception and visual-semantic alignment for accurate IGE detection results.Thus, it is necessary to embark on the IGE research tailored to XR apps. Inthis paper, we propose the first zero-shot cOntext-sensitive inteRactable GUIElemeNT dEtection framework for virtual Reality apps, named Orienter. Byimitating human behaviors, Orienter observes and understands the semanticcontexts of XR app scenes first, before performing the detection. The detectionprocess is iterated within a feedback-directed validation and reflection loop.Specifically, Orienter contains three components, including (1) Semanticcontext comprehension, (2) Reflection-directed IGE candidate detection, and (3)Context-sensitive interactability classification. Extensive experimentsdemonstrate that Orienter is more effective than the state-of-the-art GUIelement detection approaches.</description><author>Shuqing Li, Binchang Li, Yepang Liu, Cuiyun Gao, Jianping Zhang, Shing-Chi Cheung, Michael R. Lyu</author><pubDate>Wed, 01 Oct 2025 17:58:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10811v4</guid></item><item><title>XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications</title><link>http://arxiv.org/abs/2412.06759v3</link><description>The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR)and spatial computing technologies forms a foundational layer for the emergingMetaverse, enabling innovative applications across healthcare, education,manufacturing, and entertainment. However, research in this area is oftenlimited by the lack of large, representative, and highquality applicationdatasets that can support empirical studies and the development of newapproaches benefiting XR software processes. In this paper, we introduce XRZoo,a comprehensive and curated dataset of XR applications designed to bridge thisgap. XRZoo contains 12,528 free XR applications, spanning nine app stores,across all XR techniques (i.e., AR, MR, and VR) and use cases, with detailedmetadata on key aspects such as application descriptions, applicationcategories, release dates, user review numbers, and hardware specifications,etc. By making XRZoo publicly available, we aim to foster reproducible XRsoftware engineering and security research, enable cross-disciplinaryinvestigations, and also support the development of advanced XR systems byproviding examples to developers. Our dataset serves as a valuable resource forresearchers and practitioners interested in improving the scalability,usability, and effectiveness of XR applications. XRZoo will be released andactively maintained.</description><author>Shuqing Li, Chenran Zhang, Cuiyun Gao, Michael R. Lyu</author><pubDate>Wed, 01 Oct 2025 17:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06759v3</guid></item><item><title>Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning</title><link>http://arxiv.org/abs/2504.00907v4</link><description>Embodied agents operating in household environments must interpret ambiguousand under-specified human instructions. A capable household robot shouldrecognize ambiguity and ask relevant clarification questions to infer the userintent accurately, leading to more effective task execution. To study thisproblem, we introduce the Ask-to-Act task, where an embodied agent is taskedwith a single or multi-object rearrangement task using an under-specifiedinstruction in a home environment. The agent must strategically ask minimal,yet relevant, clarification questions to resolve ambiguity while navigatingunder partial observability. To address this challenge, we propose a novelapproach that fine-tunes multi-modal large language models (MLLMs) asvision-language-action (VLA) policies using online reinforcement learning (RL)with LLM-generated rewards. Our method eliminates the need for large-scalehuman demonstrations or manually engineered rewards for training such agents.We benchmark against strong zero-shot baselines including GPT-4o as well assupervised fine-tuned MLLMs on our task. Our results show that our RL-finetunedMLLM outperforms all baselines by a significant margin (10.4-16.5%),generalizing well to novel scenes and tasks. To the best of our knowledge, thisis the first demonstration of adapting MLLMs as VLA agents that can act and askfor help using LLM-generated rewards with online RL.</description><author>Ram Ramrakhya, Matthew Chang, Xavier Puig, Ruta Desai, Zsolt Kira, Roozbeh Mottaghi</author><pubDate>Wed, 01 Oct 2025 17:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.00907v4</guid></item><item><title>Prompt Tuning Decision Transformers with Structured and Scalable Bandits</title><link>http://arxiv.org/abs/2502.04979v3</link><description>Prompt tuning has emerged as a key technique for adapting large pre-trainedDecision Transformers (DTs) in offline Reinforcement Learning (RL),particularly in multi-task and few-shot settings. The Prompting DecisionTransformer (PDT) enables task generalization via trajectory prompts sampleduniformly from expert demonstrations -- without accounting for promptinformativeness. In this work, we propose a bandit-based prompt-tuning methodthat learns to construct optimal trajectory prompts from demonstration data atinference time. We devise a structured bandit architecture operating in thetrajectory prompt space, achieving linear rather than combinatorial scalingwith prompt size. Additionally, we show that the pre-trained PDT itself canserve as a powerful feature extractor for the bandit, enabling efficient rewardmodeling across various environments. We theoretically establish regret boundsand demonstrate empirically that our method consistently enhances performanceacross a wide range of tasks, high-dimensional environments, andout-of-distribution scenarios, outperforming existing baselines in prompttuning.</description><author>Finn Rietz, Oleg Smirnov, Sara Karimi, Lele Cao</author><pubDate>Wed, 01 Oct 2025 17:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04979v3</guid></item><item><title>Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning</title><link>http://arxiv.org/abs/2505.16928v2</link><description>We introduce $\infty$-THOR, a new framework for long-horizon embodied tasksthat advances long-context understanding in embodied AI. $\infty$-THORprovides: (1) a generation framework for synthesizing scalable, reproducible,and unlimited long-horizon trajectories; (2) a novel embodied QA task,Needle(s) in the Embodied Haystack, where multiple scattered clues acrossextended trajectories test agents' long-context reasoning ability; and (3) along-horizon dataset and benchmark suite featuring complex tasks that spanhundreds of environment steps, each paired with ground-truth action sequences.To enable this capability, we explore architectural adaptations, includinginterleaved Goal-State-Action modeling, context extension techniques, andContext Parallelism, to equip LLM-based agents for extreme long-contextreasoning and interaction. Experimental results and analyses highlight thechallenges posed by our benchmark and provide insights into training strategiesand model behaviors under long-horizon conditions. Our work provides afoundation for the next generation of embodied AI systems capable of robust,long-term reasoning and planning.</description><author>Bosung Kim, Prithviraj Ammanabrolu</author><pubDate>Wed, 01 Oct 2025 17:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.16928v2</guid></item><item><title>jina-reranker-v3: Last but Not Late Interaction for Document Reranking</title><link>http://arxiv.org/abs/2509.25085v2</link><description>jina-reranker-v3 is a 0.6B parameter multilingual document reranker thatintroduces a novel last but not late interaction. Unlike late interactionmodels such as ColBERT that perform separate encoding followed by multi-vectormatching, our approach conducts causal self-attention between query anddocuments within the same context window, enabling rich cross-documentinteractions before extracting contextual embeddings from the last token ofeach document. This compact architecture achieves state-of-the-art BEIRperformance with 61.94 nDCG@10 while being significant smaller than generativelistwise rerankers.</description><author>Feng Wang, Yuqing Li, Han Xiao</author><pubDate>Wed, 01 Oct 2025 17:49:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25085v2</guid></item><item><title>Vector-Valued Reproducing Kernel Banach Spaces for Neural Networks and Operators</title><link>http://arxiv.org/abs/2509.26371v2</link><description>Recently, there has been growing interest in characterizing the functionspaces underlying neural networks. While shallow and deep scalar-valued neuralnetworks have been linked to scalar-valued reproducing kernel Banach spaces(RKBS), $\mathbb{R}^d$-valued neural networks and neural operator models remainless understood in the RKBS setting. To address this gap, we develop a generaldefinition of vector-valued RKBS (vv-RKBS), which inherently includes theassociated reproducing kernel. Our construction extends existing definitions byavoiding restrictive assumptions such as symmetric kernel domains,finite-dimensional output spaces, reflexivity, or separability, while stillrecovering familiar properties of vector-valued reproducing kernel Hilbertspaces (vv-RKHS). We then show that shallow $\mathbb{R}^d$-valued neuralnetworks are elements of a specific vv-RKBS, namely an instance of the integraland neural vv-RKBS. To also explore the functional structure of neuraloperators, we analyze the DeepONet and Hypernetwork architectures anddemonstrate that they too belong to an integral and neural vv-RKBS. In allcases, we establish a Representer Theorem, showing that optimization over thesefunction spaces recovers the corresponding neural architectures.</description><author>Sven Dummer, Tjeerd Jan Heeringa, José A. Iglesias</author><pubDate>Wed, 01 Oct 2025 17:46:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26371v2</guid></item><item><title>Achieving More Human Brain-Like Vision via Human EEG Representational Alignment</title><link>http://arxiv.org/abs/2401.17231v3</link><description>Despite advancements in artificial intelligence, object recognition modelsstill lag behind in emulating visual information processing in human brains.Recent studies have highlighted the potential of using neural data to mimicbrain processing; however, these often rely on invasive neural recordings fromnon-human subjects, leaving a critical gap in understanding human visualperception. Addressing this gap, we present,'Re(presentational)Al(ignment)net', a vision model aligned with human brainactivity based on non-invasive EEG, demonstrating a significantly highersimilarity to human brain representations. Our innovative image-to-brainmulti-layer encoding framework advances human neural alignment by optimizingmultiple model layers and enabling the model to efficiently learn and mimic thehuman brain's visual representational patterns across object categories anddifferent modalities. Our findings suggest that ReAlnets better alignartificial neural networks with human brain representations, making it moresimilar to human brain processing than traditional computer vision models,which takes an important step toward bridging the gap between artificial andhuman vision and achieving more brain-like artificial intelligence systems.</description><author>Zitong Lu, Yile Wang, Julie D. Golomb</author><pubDate>Wed, 01 Oct 2025 17:45:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17231v3</guid></item><item><title>Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct</title><link>http://arxiv.org/abs/2509.25035v2</link><description>Fast and high-quality language generation is the holy grail that peoplepursue in the age of AI. In this work, we introduce Discrete DiffusionDivergence Instruct (DiDi-Instruct), a training-based method that initializesfrom a pre-trained (masked) discrete diffusion language model (dLLM) anddistills a few-step student for fast generation. The resulting DiDi-Instructmodel achieves comparable or superior performance to its dLLM teacher and theGPT-2 baseline while enabling up to 64$\times$ acceleration. The theoreticalfoundation of DiDi-Instruct is a novel framework based on integralKL-divergence minimization, which yields a practical training algorithm. Wefurther introduce grouped reward normalization, intermediate-state matching,and the reward-guided ancestral sampler that significantly improve trainingstability, model coverage, and inference quality. On OpenWebText, DiDi-Instructachieves perplexity from 62.2 (8 NFEs) to 18.4 (128 NFEs), which outperformsprior accelerated dLLMs and GPT-2 baseline. These gains come with a negligibleentropy loss (around $1\%$) and reduce additional training wall-clock time bymore than $20\times$ compared to competing dLLM distillation methods. Wefurther validate the robustness and effectiveness of DiDi-Instruct throughextensive ablation studies, model scaling, and the generation of discreteprotein sequences. In conclusion, DiDi-Instruct is an efficient yet effectivedistillation method, enabling language generation in the blink of an eye. Wewill release both code and models at github.com/haoyangzheng-ai/didi-instruct.</description><author>Haoyang Zheng, Xinyang Liu, Cindy Xiangrui Kong, Nan Jiang, Zheyuan Hu, Weijian Luo, Wei Deng, Guang Lin</author><pubDate>Wed, 01 Oct 2025 17:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25035v2</guid></item><item><title>IC-Custom: Diverse Image Customization via In-Context Learning</title><link>http://arxiv.org/abs/2507.01926v3</link><description>Image customization, a crucial technique for industrial media production,aims to generate content that is consistent with reference images. However,current approaches conventionally separate image customization intoposition-aware and position-free customization paradigms and lack a universalframework for diverse customization, limiting their applications across variousscenarios. To overcome these limitations, we propose IC-Custom, a unifiedframework that seamlessly integrates position-aware and position-free imagecustomization through in-context learning. IC-Custom concatenates referenceimages with target images to a polyptych, leveraging DiT's multi-modalattention mechanism for fine-grained token-level interactions. We propose theIn-context Multi-Modal Attention (ICMA) mechanism, which employs learnabletask-oriented register tokens and boundary-aware positional embeddings toenable the model to effectively handle diverse tasks and distinguish betweeninputs in polyptych configurations. To address the data gap, we curated a 12Kidentity-consistent dataset with 8K real-world and 4K high-quality syntheticsamples, avoiding the overly glossy, oversaturated look typical of syntheticdata. IC-Custom supports various industrial applications, including try-on,image insertion, and creative IP customization. Extensive evaluations on ourproposed ProductBench and the publicly available DreamBench demonstrate thatIC-Custom significantly outperforms community workflows, closed-source models,and state-of-the-art open-source approaches. IC-Custom achieves about 73\%higher human preference across identity consistency, harmony, and textalignment metrics, while training only 0.4\% of the original model parameters.Project page: https://liyaowei-stu.github.io/project/IC_Custom</description><author>Yaowei Li, Xiaoyu Li, Zhaoyang Zhang, Yuxuan Bian, Gan Liu, Xinyuan Li, Jiale Xu, Wenbo Hu, Yating Liu, Lingen Li, Jing Cai, Yuexian Zou, Yancheng He, Ying Shan</author><pubDate>Wed, 01 Oct 2025 17:36:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.01926v3</guid></item><item><title>A Likelihood Based Approach to Distribution Regression Using Conditional Deep Generative Models</title><link>http://arxiv.org/abs/2410.02025v2</link><description>In this work, we explore the theoretical properties of conditional deepgenerative models under the statistical framework of distribution regressionwhere the response variable lies in a high-dimensional ambient space butconcentrates around a potentially lower-dimensional manifold. Morespecifically, we study the large-sample properties of a likelihood-basedapproach for estimating these models. Our results lead to the convergence rateof a sieve maximum likelihood estimator (MLE) for estimating the conditionaldistribution (and its devolved counterpart) of the response given predictors inthe Hellinger (Wasserstein) metric. Our rates depend solely on the intrinsicdimension and smoothness of the true conditional distribution. These findingsprovide an explanation of why conditional deep generative models can circumventthe curse of dimensionality from the perspective of statistical foundations anddemonstrate that they can learn a broader class of nearly singular conditionaldistributions. Our analysis also emphasizes the importance of introducing asmall noise perturbation to the data when they are supported sufficiently closeto a manifold. Finally, in our numerical studies, we demonstrate the effectiveimplementation of the proposed approach using both synthetic and real-worlddatasets, which also provide complementary validation to our theoreticalfindings.</description><author>Shivam Kumar, Yun Yang, Lizhen Lin</author><pubDate>Wed, 01 Oct 2025 17:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02025v2</guid></item><item><title>Automatically Generating Web Applications from Requirements Via Multi-Agent Test-Driven Development</title><link>http://arxiv.org/abs/2509.25297v2</link><description>Developing full-stack web applications is complex and time-intensive,demanding proficiency across diverse technologies and frameworks. Althoughrecent advances in multimodal large language models (MLLMs) enable automatedwebpage generation from visual inputs, current solutions remain limited tofront-end tasks and fail to deliver fully functional applications. In thiswork, we introduce TDDev, the first test-driven development (TDD)-enabledLLM-agent framework for end-to-end full-stack web application generation. Givena natural language description or design image, TDDev automatically derivesexecutable test cases, generates front-end and back-end code, simulates userinteractions, and iteratively refines the implementation until all requirementsare satisfied. Our framework addresses key challenges in full-stack automation,including underspecified user requirements, complex interdependencies amongmultiple files, and the need for both functional correctness and visualfidelity. Through extensive experiments on diverse application scenarios, TDDevachieves a 14.4% improvement on overall accuracy compared to state-of-the-artbaselines, demonstrating its effectiveness in producing reliable, high-qualityweb applications without requiring manual intervention.</description><author>Yuxuan Wan, Tingshuo Liang, Jiakai Xu, Jingyu Xiao, Yintong Huo, Michael R. Lyu</author><pubDate>Wed, 01 Oct 2025 17:32:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25297v2</guid></item><item><title>Alternating Training-based Label Smoothing Enhances Prompt Generalization</title><link>http://arxiv.org/abs/2508.17846v2</link><description>Recent advances in pre-trained vision-language models have demonstratedremarkable zero-shot generalization capabilities. To further enhance thesemodels' adaptability to various downstream tasks, prompt tuning has emerged asa parameter-efficient fine-tuning method. However, despite its efficiency, thegeneralization ability of prompt remains limited. In contrast, label smoothing(LS) has been widely recognized as an effective regularization technique thatprevents models from becoming over-confident and improves their generalization.This inspires us to explore the integration of LS with prompt tuning. However,we have observed that the vanilla LS even weakens the generalization ability ofprompt tuning. To address this issue, we propose the Alternating Training-basedLabel Smoothing (ATLaS) method, which alternately trains with standard one-hotlabels and soft labels generated by LS to supervise the prompt tuning.Moreover, we introduce two types of efficient offline soft labels, includingClass-wise Soft Labels (CSL) and Instance-wise Soft Labels (ISL), to provideinter-class or instance-class relationships for prompt tuning. The theoreticalproperties of the proposed ATLaS method are analyzed. Extensive experimentsdemonstrate that the proposed ATLaS method, combined with CSL and ISL,consistently enhances the generalization performance of prompt tuning.Moreover, the proposed ATLaS method exhibits high compatibility with prevalentprompt tuning methods, enabling seamless integration into existing methods.</description><author>Yang Chen, Yanbin Wei, Ke Jin, Yi Kong, James Kwok, Yu Zhang</author><pubDate>Wed, 01 Oct 2025 17:22:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.17846v2</guid></item><item><title>The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks</title><link>http://arxiv.org/abs/2509.18234v2</link><description>Large frontier models like GPT-5 now achieve top scores on medicalbenchmarks. But our stress tests tell a different story. Leading systems oftenguess correctly even when key inputs like images are removed, flip answersunder trivial prompt changes, and fabricate convincing yet flawed reasoning.These aren't glitches; they expose how today's benchmarks reward test-takingtricks over medical understanding. We evaluate six flagship models across sixwidely used benchmarks and find that high leaderboard scores hide brittlenessand shortcut learning. Through clinician-guided rubric evaluation, we show thatbenchmarks vary widely in what they truly measure yet are treatedinterchangeably, masking failure modes. We caution that medical benchmarkscores do not directly reflect real-world readiness. If we want AI to earntrust in healthcare, we must demand more than leaderboard wins and must holdsystems accountable for robustness, sound reasoning, and alignment with realmedical demands.</description><author>Yu Gu, Jingjing Fu, Xiaodong Liu, Jeya Maria Jose Valanarasu, Noel CF Codella, Reuben Tan, Qianchu Liu, Ying Jin, Sheng Zhang, Jinyu Wang, Rui Wang, Lei Song, Guanghui Qin, Naoto Usuyama, Cliff Wong, Hao Cheng, Hohin Lee, Praneeth Sanapathi, Sarah Hilado, Jiang Bian, Javier Alvarez-Valle, Mu Wei, Khalil Malik, Jianfeng Gao, Eric Horvitz, Matthew P Lungren, Hoifung Poon, Paul Vozila</author><pubDate>Wed, 01 Oct 2025 17:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18234v2</guid></item><item><title>The Rise of AfricaNLP: Contributions, Contributors, and Community Impact (2005-2025)</title><link>http://arxiv.org/abs/2509.25477v2</link><description>Natural Language Processing (NLP) is undergoing constant transformation, asLarge Language Models (LLMs) are driving daily breakthroughs in research andpractice. In this regard, tracking the progress of NLP research andautomatically analyzing the contributions of research papers provides keyinsights into the nature of the field and the researchers. This study exploresthe progress of African NLP (AfricaNLP) by asking (and answering) basicresearch questions such as: i) How has the nature of NLP evolved over the lasttwo decades?, ii) What are the contributions of AfricaNLP papers?, and iii)Which individuals and organizations (authors, affiliated institutions, andfunding bodies) have been involved in the development of AfricaNLP? Wequantitatively examine the contributions of AfricaNLP research using 1.9K NLPpaper abstracts, 4.9K author contributors, and 7.8K human-annotatedcontribution sentences (AfricaNLPContributions) along with benchmark results.Our dataset and continuously existing NLP progress tracking website provide apowerful lens for tracing AfricaNLP research trends and hold potential forgenerating data-driven literature surveys.</description><author>Tadesse Destaw Belay, Kedir Yassin Hussen, Sukairaj Hafiz Imam, Ibrahim Said Ahmad, Isa Inuwa-Dutse, Abrham Belete Haile, Grigori Sidorov, Iqra Ameer, Idris Abdulmumin, Tajuddeen Gwadabe, Vukosi Marivate, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad</author><pubDate>Wed, 01 Oct 2025 17:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25477v2</guid></item><item><title>DepthLM: Metric Depth From Vision Language Models</title><link>http://arxiv.org/abs/2509.25413v2</link><description>Vision language models (VLMs) can flexibly address various vision tasksthrough text interactions. Although successful in semantic understanding,state-of-the-art VLMs including GPT-5 still struggle in understanding 3D from2D inputs. On the other hand, expert pure vision models achieve super-humanaccuracy in metric depth estimation, a key 3D understanding task. However, theyrequire task-specific architectures and losses. Such difference motivates us toask: Can VLMs reach expert-level accuracy without architecture or loss change?We take per-pixel metric depth estimation as the representative task and showthat the answer is yes! Surprisingly, comprehensive analysis shows thattext-based supervised-finetuning with sparse labels is sufficient for VLMs tounlock strong 3D understanding, no dense prediction head or complexregression/regularization loss is needed. The bottleneck for VLMs lies actuallyin pixel reference and cross-dataset camera ambiguity, which we address throughvisual prompting and intrinsic-conditioned augmentation. With much smallermodels, our method DepthLM surpasses the accuracy of most advanced VLMs by over2x, making VLMs for the first time comparable with pure vision models.Interestingly, without explicit enforcement during training, VLMs trained withDepthLM naturally avoids over-smoothing, having much fewer flying points atboundary regions than pure vision models. The simplicity of DepthLM alsoenables a single VLM to cover various 3D tasks beyond metric depth. Our codeand model will be released at the link below.</description><author>Zhipeng Cai, Ching-Feng Yeh, Hu Xu, Zhuang Liu, Gregory Meyer, Xinjie Lei, Changsheng Zhao, Shang-Wen Li, Vikas Chandra, Yangyang Shi</author><pubDate>Wed, 01 Oct 2025 17:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25413v2</guid></item><item><title>Minimax and Bayes Optimal Best-Arm Identification</title><link>http://arxiv.org/abs/2506.24007v3</link><description>This study investigates minimax and Bayes optimal strategies in fixed-budgetbest-arm identification. We consider an adaptive procedure consisting of asampling phase followed by a recommendation phase, and we design an adaptiveexperiment within this framework to efficiently identify the best arm, definedas the one with the highest expected outcome. In our proposed strategy, thesampling phase consists of two stages. The first stage is a pilot phase, inwhich we allocate each arm uniformly in equal proportions to eliminate clearlysuboptimal arms and estimate outcome variances. In the second stage, arms areallocated in proportion to the variances estimated during the first stage.After the sampling phase, the procedure enters the recommendation phase, wherewe select the arm with the highest sample mean as our estimate of the best arm.We prove that this single strategy is simultaneously asymptotically minimax andBayes optimal for the simple regret, with upper bounds that coincide exactlywith our lower bounds, including the constant terms.</description><author>Masahiro Kato</author><pubDate>Wed, 01 Oct 2025 17:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.24007v3</guid></item><item><title>CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmarking of Large Language Models in Mental Health Question Answering</title><link>http://arxiv.org/abs/2506.08584v2</link><description>Medical question answering (QA) benchmarks often focus on multiple-choice orfact-based tasks, leaving open-ended answers to real patient questionsunderexplored. This gap is particularly critical in mental health, wherepatient questions often mix symptoms, treatment concerns, and emotional needs,requiring answers that balance clinical caution with contextual sensitivity. Wepresent CounselBench, a large-scale benchmark developed with 100 mental healthprofessionals to evaluate and stress-test large language models (LLMs) inrealistic help-seeking scenarios. The first component, CounselBench-EVAL,contains 2,000 expert evaluations of answers from GPT-4, LLaMA 3, Gemini, andhuman therapists on patient questions from the public forum CounselChat. Eachanswer is rated across six clinically grounded dimensions, with span-levelannotations and written rationales. Expert evaluations show that while LLMsachieve high scores on several dimensions, they also exhibit recurring issues,including unconstructive feedback, overgeneralization, and limitedpersonalization or relevance. Responses were frequently flagged for safetyrisks, most notably unauthorized medical advice. Follow-up experiments showthat LLM judges systematically overrate model responses and overlook safetyconcerns identified by human experts. To probe failure modes more directly, weconstruct CounselBench-Adv, an adversarial dataset of 120 expert-authoredmental health questions designed to trigger specific model issues. Evaluationof 3,240 responses from nine LLMs reveals consistent, model-specific failurepatterns. Together, CounselBench establishes a clinically grounded frameworkfor benchmarking LLMs in mental health QA.</description><author>Yahan Li, Jifan Yao, John Bosco S. Bunyi, Adam C. Frank, Angel Hwang, Ruishan Liu</author><pubDate>Wed, 01 Oct 2025 17:10:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08584v2</guid></item><item><title>Learning to Interact in World Latent for Team Coordination</title><link>http://arxiv.org/abs/2509.25550v2</link><description>This work presents a novel representation learning framework, interactiveworld latent (IWoL), to facilitate team coordination in multi-agentreinforcement learning (MARL). Building effective representation for teamcoordination is a challenging problem, due to the intricate dynamics emergingfrom multi-agent interaction and incomplete information induced by localobservations. Our key insight is to construct a learnable representation spacethat jointly captures inter-agent relations and task-specific world informationby directly modeling communication protocols. This representation, we maintainfully decentralized execution with implicit coordination, all while avoidingthe inherent drawbacks of explicit message passing, e.g., slowerdecision-making, vulnerability to malicious attackers, and sensitivity tobandwidth constraints. In practice, our representation can be used not only asan implicit latent for each agent, but also as an explicit message forcommunication. Across four challenging MARL benchmarks, we evaluate bothvariants and show that IWoL provides a simple yet powerful key for teamcoordination. Moreover, we demonstrate that our representation can be combinedwith existing MARL algorithms to further enhance their performance.</description><author>Dongsu Lee, Daehee Lee, Yaru Niu, Honguk Woo, Amy Zhang, Ding Zhao</author><pubDate>Wed, 01 Oct 2025 17:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25550v2</guid></item><item><title>Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning</title><link>http://arxiv.org/abs/2506.04408v2</link><description>Humans have a remarkable ability to acquire and understand grammaticalphenomena that are seen rarely, if ever, during childhood. Recent evidencesuggests that language models with human-scale pretraining data may possess asimilar ability by generalizing from frequent to rare constructions. However,it remains an open question how widespread this generalization ability is, andto what extent this knowledge extends to meanings of rare constructions, asopposed to just their forms. We fill this gap by testing human-scaletransformer language models on their knowledge of both the form and meaning ofthe (rare and quirky) English LET-ALONE construction. To evaluate our LMs weconstruct a bespoke synthetic benchmark that targets syntactic and semanticproperties of the construction. We find that human-scale LMs are sensitive toform, even when related constructions are filtered from the dataset. However,human-scale LMs do not make correct generalizations about LET-ALONE's meaning.These results point to an asymmetry in the current architectures' sampleefficiency between language form and meaning, something which is not present inhuman language learners.</description><author>Wesley Scivetti, Tatsuya Aoyama, Ethan Wilcox, Nathan Schneider</author><pubDate>Wed, 01 Oct 2025 17:01:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.04408v2</guid></item><item><title>REAL: Reading Out Transformer Activations for Precise Localization in Language Model Steering</title><link>http://arxiv.org/abs/2506.08359v2</link><description>Inference-time steering aims to alter a large language model's (LLM's)responses without changing its parameters, but a central challenge isidentifying the internal modules that most strongly govern the target behavior.Existing approaches often rely on simplistic cues or ad hoc heuristics, leadingto suboptimal or unintended effects. We introduce REAL, a framework foridentifying behavior-relevant modules (attention heads or layers) inTransformer models. For each module, REAL trains a vector-quantized autoencoder(VQ-AE) on its hidden activations and uses a shared, learnable codebook topartition the latent space into behavior-relevant and behavior-irrelevantsubspaces. REAL quantifies a module's behavioral relevance by how well itsVQ-AE encodings discriminate behavior-aligned from behavior-violating responsesvia a binary classification metric; this score guides both module selection andsteering strength. We evaluate REAL across eight LLMs from the Llama and Qwenfamilies and nine datasets spanning truthfulness enhancement, open-domain QAunder knowledge conflicts, and general alignment tasks. REAL enables moreeffective inference-time interventions, achieving an average relativeimprovement of 20% (up to 81.5%) over the ITI method on truthfulness steering.In addition, the modules selected by REAL exhibit strong zero-shotgeneralization in cross-domain truthfulness-steering scenarios.</description><author>Li-Ming Zhan, Bo Liu, Chengqiang Xie, Jiannong Cao, Xiao-Ming Wu</author><pubDate>Wed, 01 Oct 2025 16:56:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08359v2</guid></item><item><title>Explaining multimodal LLMs via intra-modal token interactions</title><link>http://arxiv.org/abs/2509.22415v2</link><description>Multimodal Large Language Models (MLLMs) have achieved remarkable successacross diverse vision-language tasks, yet their internal decision-makingmechanisms remain insufficiently understood. Existing interpretability researchhas primarily focused on cross-modal attribution, identifying which imageregions the model attends to during output generation. However, theseapproaches often overlook intra-modal dependencies. In the visual modality,attributing importance to isolated image patches ignores spatial context due tolimited receptive fields, resulting in fragmented and noisy explanations. Inthe textual modality, reliance on preceding tokens introduces spuriousactivations. Failing to effectively mitigate these interference compromisesattribution fidelity. To address these limitations, we propose enhancinginterpretability by leveraging intra-modal interaction. For the visual branch,we introduce \textit{Multi-Scale Explanation Aggregation} (MSEA), whichaggregates attributions over multi-scale inputs to dynamically adjust receptivefields, producing more holistic and spatially coherent visual explanations. Forthe textual branch, we propose \textit{Activation Ranking Correlation} (ARC),which measures the relevance of contextual tokens to the current token viaalignment of their top-$k$ prediction rankings. ARC leverages this relevance tosuppress spurious activations from irrelevant contexts while preservingsemantically coherent ones. Extensive experiments across state-of-the-art MLLMsand benchmark datasets demonstrate that our approach consistently outperformsexisting interpretability methods, yielding more faithful and fine-grainedexplanations of model behavior.</description><author>Jiawei Liang, Ruoyu Chen, Xianghao Jiao, Siyuan Liang, Shiming Liu, Qunli Zhang, Zheng Hu, Xiaochun Cao</author><pubDate>Wed, 01 Oct 2025 16:48:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22415v2</guid></item><item><title>Nonlinear Framework for Speech Bandwidth Extension</title><link>http://arxiv.org/abs/2507.15970v2</link><description>Recovering high-frequency components lost to bandwidth constraints is crucialfor applications ranging from telecommunications to high-fidelity audio onlimited resources. We introduce NDSI-BWE, a new adversarial Band WidthExtension (BWE) framework that leverage four new discriminators inspired bynonlinear dynamical system to capture diverse temporal behaviors: aMulti-Resolution Lyapunov Discriminator (MRLD) for determining sensitivity toinitial conditions by capturing deterministic chaos, a Multi-Scale RecurrenceDiscriminator (MS-RD) for self-similar recurrence dynamics, a Multi-ScaleDetrended Fractal Analysis Discriminator (MSDFA) for long range slow variantscale invariant relationship, a Multi-Resolution Poincar\'e Plot Discriminator(MR-PPD) for capturing hidden latent space relationship, a Multi-PeriodDiscriminator (MPD) for cyclical patterns, a Multi-Resolution AmplitudeDiscriminator (MRAD) and Multi-Resolution Phase Discriminator (MRPD) forcapturing intricate amplitude-phase transition statistics. By using depth-wiseconvolution at the core of the convolutional block with in each discriminators,NDSI-BWE attains an eight-times parameter reduction. These seven discriminatorsguide a complex-valued ConformerNeXt based genetor with a dual streamLattice-Net based architecture for simultaneous refinement of magnitude andphase. The genertor leverage the transformer based conformer's globaldependency modeling and ConvNeXt block's local temporal modeling capability.Across six objective evaluation metrics and subjective based texts comprises offive human judges, NDSI-BWE establishes a new SoTA in BWE.</description><author>Tarikul Islam Tamiti, Nursad Mamun, Anomadarshi Barua</author><pubDate>Wed, 01 Oct 2025 16:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15970v2</guid></item><item><title>BlobCtrl: Taming Controllable Blob for Element-level Image Editing</title><link>http://arxiv.org/abs/2503.13434v2</link><description>As user expectations for image editing continue to rise, the demand forflexible, fine-grained manipulation of specific visual elements presents achallenge for current diffusion-based methods. In this work, we presentBlobCtrl, a framework for element-level image editing based on a probabilisticblob-based representation. Treating blobs as visual primitives, BlobCtrldisentangles layout from appearance, affording fine-grained, controllableobject-level manipulation. Our key contributions are twofold: (1) an in-contextdual-branch diffusion model that separates foreground and backgroundprocessing, incorporating blob representations to explicitly decouple layoutand appearance, and (2) a self-supervised disentangle-then-reconstruct trainingparadigm with an identity-preserving loss function, along with tailoredstrategies to efficiently leverage blob-image pairs. To foster furtherresearch, we introduce BlobData for large-scale training and BlobBench, abenchmark for systematic evaluation. Experimental results demonstrate thatBlobCtrl achieves state-of-the-art performance in a variety of element-levelediting tasks, such as object addition, removal, scaling, and replacement,while maintaining computational efficiency. Project Webpage:https://liyaowei-stu.github.io/project/BlobCtrl/</description><author>Yaowei Li, Lingen Li, Zhaoyang Zhang, Xiaoyu Li, Guangzhi Wang, Hongxiang Li, Xiaodong Cun, Ying Shan, Yuexian Zou</author><pubDate>Wed, 01 Oct 2025 16:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.13434v2</guid></item><item><title>PhyloLM : Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks</title><link>http://arxiv.org/abs/2404.04671v4</link><description>This paper introduces PhyloLM, a method adapting phylogenetic algorithms toLarge Language Models (LLMs) to explore whether and how they relate to eachother and to predict their performance characteristics. Our method calculates aphylogenetic distance metric based on the similarity of LLMs' output. Theresulting metric is then used to construct dendrograms, which satisfactorilycapture known relationships across a set of 111 open-source and 45 closedmodels. Furthermore, our phylogenetic distance predicts performance in standardbenchmarks, thus demonstrating its functional validity and paving the way for atime and cost-effective estimation of LLM capabilities. To sum up, bytranslating population genetic concepts to machine learning, we propose andvalidate a tool to evaluate LLM development, relationships and capabilities,even in the absence of transparent training information.</description><author>Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri</author><pubDate>Wed, 01 Oct 2025 16:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04671v4</guid></item><item><title>A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks</title><link>http://arxiv.org/abs/2509.14285v2</link><description>Prompt injection attacks represent a major vulnerability in Large LanguageModel (LLM) deployments, where malicious instructions embedded in user inputscan override system prompts and induce unintended behaviors. This paperpresents a novel multi-agent defense framework that employs specialized LLMagents in coordinated pipelines to detect and neutralize prompt injectionattacks in real-time. We evaluate our approach using two distinctarchitectures: a sequential chain-of-agents pipeline and a hierarchicalcoordinator-based system. Our comprehensive evaluation on 55 unique promptinjection attacks, grouped into 8 categories and totaling 400 attack instancesacross two LLM platforms (ChatGLM and Llama2), demonstrates significantsecurity improvements. Without defense mechanisms, baseline Attack SuccessRates (ASR) reached 30% for ChatGLM and 20% for Llama2. Our multi-agentpipeline achieved 100% mitigation, reducing ASR to 0% across all testedscenarios. The framework demonstrates robustness across multiple attackcategories including direct overrides, code execution attempts, dataexfiltration, and obfuscation techniques, while maintaining systemfunctionality for legitimate queries.</description><author>S M Asif Hossain, Ruksat Khan Shayoni, Mohd Ruhul Ameen, Akif Islam, M. F. Mridha, Jungpil Shin</author><pubDate>Wed, 01 Oct 2025 16:39:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.14285v2</guid></item><item><title>Computational-Assisted Systematic Review and Meta-Analysis (CASMA): Effect of a Subclass of GnRH-a on Endometriosis Recurrence</title><link>http://arxiv.org/abs/2509.16599v2</link><description>Background: Evidence synthesis facilitates evidence-based medicine. This taskbecomes increasingly difficult to accomplished with applying computationalsolutions, since the medical literature grows at astonishing rates. Objective:This study evaluates an information retrieval-driven workflow, CASMA, toenhance the efficiency, transparency, and reproducibility of systematicreviews. Endometriosis recurrence serves as the ideal case due to its complexand ambiguous literature. Methods: The hybrid approach integrates PRISMAguidelines with fuzzy matching and regular expression (regex) to facilitatesemi-automated deduplication and filtered records before manual screening. Theworkflow synthesised evidence from randomised controlled trials on the efficacyof a subclass of gonadotropin-releasing hormone agonists (GnRH-a). A modifiedsplitting method addressed unit-of-analysis errors in multi-arm trials.Results: The workflow sharply reduced the screening workload, taking only 11days to fetch and filter 33,444 records. Seven eligible RCTs were synthesized(841 patients). The pooled random-effects model yielded a Risk Ratio (RR) of$0.64$ ($95\%$ CI $0.48$ to $0.86$), demonstrating a $36\%$ reduction inrecurrence, with non-significant heterogeneity ($I^2=0.00\%$, $\tau^2=0.00$).The findings were robust and stable, as they were backed by sensitivityanalyses. Conclusion: This study demonstrates an application of aninformation-retrieval-driven workflow for medical evidence synthesis. Theapproach yields valuable clinical results and a generalisable framework toscale up the evidence synthesis, bridging the gap between clinical research andcomputer science.</description><author>Sandro Tsang</author><pubDate>Wed, 01 Oct 2025 16:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.16599v2</guid></item><item><title>First Hallucination Tokens Are Different from Conditional Ones</title><link>http://arxiv.org/abs/2507.20836v2</link><description>Hallucination, the generation of untruthful content, is one of the majorconcerns regarding foundational models. Detecting hallucinations at the tokenlevel is vital for real-time filtering and targeted correction, yet thevariation of hallucination signals within token sequences is not fullyunderstood. Leveraging the RAGTruth corpus with token-level annotations andreproduced logits, we analyse how these signals depend on a token's positionwithin hallucinated spans, contributing to an improved understanding oftoken-level hallucination. Our results show that the first hallucinated tokencarries a stronger signal and is more detectable than conditional tokens. Werelease our analysis framework, along with code for logit reproduction andmetric computation at https://github.com/jakobsnl/RAGTruth\_Xtended.</description><author>Jakob Snel, Seong Joon Oh</author><pubDate>Wed, 01 Oct 2025 16:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.20836v2</guid></item><item><title>GuRE:Generative Query REwriter for Legal Passage Retrieval</title><link>http://arxiv.org/abs/2505.12950v2</link><description>Legal Passage Retrieval (LPR) systems are crucial as they help practitionerssave time when drafting legal arguments. However, it remains an underexploredavenue. One primary reason is the significant vocabulary mismatch between thequery and the target passage. To address this, we propose a simple yeteffective method, the Generative query REwriter (GuRE). We leverage thegenerative capabilities of Large Language Models (LLMs) by training the LLM forquery rewriting. "Rewritten queries" help retrievers to retrieve targetpassages by mitigating vocabulary mismatch. Experimental results show that GuREsignificantly improves performance in a retriever-agnostic manner,outperforming all baseline methods. Further analysis reveals that differenttraining objectives lead to distinct retrieval behaviors, making GuRE moresuitable than direct retriever fine-tuning for real-world applications. Codesare avaiable at github.com/daehuikim/GuRE.</description><author>Daehee Kim, Deokhyung Kang, Jonghwi Kim, Sangwon Ryu, Gary Geunbae Lee</author><pubDate>Wed, 01 Oct 2025 16:25:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12950v2</guid></item><item><title>Estimating Visceral Adiposity from Wrist-Worn Accelerometry</title><link>http://arxiv.org/abs/2506.09167v2</link><description>Visceral adipose tissue (VAT) is a key marker of both metabolic health andhabitual physical activity (PA). Excess VAT is highly correlated with type 2diabetes and insulin resistance. The mechanistic basis for this pathophysiologyrelates to overloading the liver with fatty acids. VAT is also a highly labilefat depot, with increased turnover stimulated by catecholamines duringexercise. VAT can be measured with sophisticated imaging technologies, but canalso be inferred directly from PA. We tested this relationship using NationalHealth and Nutrition Examination Survey (NHANES) data from 2011-2014, forindividuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men;2,427 women) [1]. Two approaches were used for estimating VAT from activity.The first used engineered features based on movements during gait and sleep,and then ridge regression to map summary statistics of these features into aVAT estimate. The second approach used deep neural networks trained on 24 hoursof continuous accelerometry. A foundation model first mapped each 10s frameinto a high-dimensional feature vector. A transformer model then mapped eachday's feature vector time series into a VAT estimate, which were averaged overmultiple days. For both approaches, the most accurate estimates were obtainedwith the addition of covariate information about subject demographics and bodymeasurements. The best performance was obtained by combining the twoapproaches, resulting in VAT estimates with correlations of r=0.86. Thesefindings demonstrate a strong relationship between PA and VAT and, byextension, between PA and metabolic health risks.</description><author>James R. Williamson, Andrew Alini, Brian A. Telfer, Adam W. Potter, Karl E. Friedl</author><pubDate>Wed, 01 Oct 2025 16:23:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.09167v2</guid></item><item><title>Fully Heteroscedastic Count Regression with Deep Double Poisson Networks</title><link>http://arxiv.org/abs/2406.09262v5</link><description>Neural networks capable of accurate, input-conditional uncertaintyrepresentation are essential for real-world AI systems. Deep ensembles ofGaussian networks have proven highly effective for continuous regression due totheir ability to flexibly represent aleatoric uncertainty via unrestrictedheteroscedastic variance, which in turn enables accurate epistemic uncertaintyestimation. However, no analogous approach exists for count regression, despitemany important applications. To address this gap, we propose the Deep DoublePoisson Network (DDPN), a novel neural discrete count regression model thatoutputs the parameters of the Double Poisson distribution, enabling arbitrarilyhigh or low predictive aleatoric uncertainty for count data and improvingepistemic uncertainty estimation when ensembled. We formalize and prove thatDDPN exhibits robust regression properties similar to heteroscedastic Gaussianmodels via learnable loss attenuation, and introduce a simple loss modificationto control this behavior. Experiments on diverse datasets demonstrate that DDPNoutperforms current baselines in accuracy, calibration, and out-of-distributiondetection, establishing a new state-of-the-art in deep count regression.</description><author>Spencer Young, Porter Jenkins, Longchao Da, Jeff Dotson, Hua Wei</author><pubDate>Wed, 01 Oct 2025 16:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09262v5</guid></item><item><title>A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective</title><link>http://arxiv.org/abs/2509.16499v2</link><description>The widespread use of diffusion models has led to an abundance ofAI-generated data, raising concerns about model collapse -- a phenomenon inwhich recursive iterations of training on synthetic data lead to performancedegradation. Prior work primarily characterizes this collapse via varianceshrinkage or distribution shift, but these perspectives miss practicalmanifestations of model collapse. This paper identifies a transition fromgeneralization to memorization during model collapse in diffusion models, wheremodels increasingly replicate training data instead of generating novel contentduring iterative training on synthetic samples. This transition is directlydriven by the declining entropy of the synthetic training data produced in eachtraining cycle, which serves as a clear indicator of model degradation.Motivated by this insight, we propose an entropy-based data selection strategyto mitigate the transition from generalization to memorization and alleviatemodel collapse. Empirical results show that our approach significantly enhancesvisual quality and diversity in recursive generation, effectively preventingcollapse.</description><author>Lianghe Shi, Meng Wu, Huijie Zhang, Zekai Zhang, Molei Tao, Qing Qu</author><pubDate>Wed, 01 Oct 2025 16:21:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.16499v2</guid></item><item><title>SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference</title><link>http://arxiv.org/abs/2502.18137v7</link><description>An efficient attention implementation is essential for large models due toits quadratic time complexity. Fortunately, attention commonly exhibitssparsity, i.e., many values in the attention map are near zero, allowing forthe omission of corresponding computations. Many studies have utilized thesparse pattern to accelerate attention. However, most existing works focus onoptimizing attention within specific models by exploiting certain sparsepatterns of the attention map. A universal sparse attention that guaranteesboth the speedup and end-to-end performance of diverse models remains elusive.In this paper, we propose SpargeAttn, a universal sparse and quantizedattention for any model. Our method uses a two-stage online filter: in thefirst stage, we rapidly and accurately predict the attention map, enabling theskip of some matrix multiplications in attention. In the second stage, wedesign an online softmax-aware filter that incurs no extra overhead and furtherskips some matrix multiplications. Experiments show that our methodsignificantly accelerates diverse models, including language, image, and videogeneration, without sacrificing end-to-end metrics. The codes are available athttps://github.com/thu-ml/SpargeAttn.</description><author>Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen</author><pubDate>Wed, 01 Oct 2025 16:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.18137v7</guid></item><item><title>SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization</title><link>http://arxiv.org/abs/2411.10958v7</link><description>Although quantization for linear layers has been widely used, its applicationto accelerate the attention process remains limited. To further enhance theefficiency of attention computation compared to SageAttention while maintainingprecision, we propose SageAttention2, which utilizes significantly faster 4-bitmatrix multiplication (Matmul) alongside additional precision-enhancingtechniques. First, we propose to quantize matrices $(Q, K)$ to INT4 in ahardware-friendly thread-level granularity and quantize matrices $(\widetildeP, V)$ to FP8. Second, we propose a method to smooth $Q$, enhancing theaccuracy of INT4 $QK^\top$. Third, we propose a two-level accumulation strategyfor $\widetilde PV$ to enhance the accuracy of FP8 $\widetilde PV$. Theoperations per second (OPS) of SageAttention2 surpass FlashAttention2 andxformers by about 3x and 4.5x on RTX4090, respectively. Moreover,SageAttention2 matches the speed of FlashAttention3(fp8) on the Hopper GPUs,while delivering much higher accuracy. Comprehensive experiments confirm thatour approach incurs negligible end-to-end metrics loss across diverse models,including those for language, image, and video generation. The code isavailable at https://github.com/thu-ml/SageAttention.</description><author>Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen</author><pubDate>Wed, 01 Oct 2025 16:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10958v7</guid></item><item><title>Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical Practice</title><link>http://arxiv.org/abs/2509.26153v2</link><description>Large language models (LLMs) integrated into agent-driven workflows holdimmense promise for healthcare, yet a significant gap exists between theirpotential and practical implementation within clinical settings. To addressthis, we present a practitioner-oriented field manual for deploying generativeagents that use electronic health record (EHR) data. This guide is informed byour experience deploying the "irAE-Agent", an automated system to detectimmune-related adverse events from clinical notes at Mass General Brigham, andby structured interviews with 20 clinicians, engineers, and informatics leadersinvolved in the project. Our analysis reveals a critical misalignment inclinical AI development: less than 20% of our effort was dedicated to promptengineering and model development, while over 80% was consumed by thesociotechnical work of implementation. We distill this effort into five "heavylifts": data integration, model validation, ensuring economic value, managingsystem drift, and governance. By providing actionable solutions for each ofthese challenges, this field manual shifts the focus from algorithmicdevelopment to the essential infrastructure and implementation work required tobridge the "valley of death" and successfully translate generative AI frompilot projects into routine clinical care.</description><author>Jack Gallifant, Katherine C. Kellogg, Matt Butler, Amanda Centi, Shan Chen, Patrick F. Doyle, Sayon Dutta, Joyce Guo, Matthew J. Hadfield, Esther H. Kim, David E. Kozono, Hugo JWL Aerts, Adam B. Landman, Raymond H. Mak, Rebecca G. Mishuris, Tanna L. Nelson, Guergana K. Savova, Elad Sharon, Benjamin C. Silverman, Umit Topaloglu, Jeremy L. Warner, Danielle S. Bitterman</author><pubDate>Wed, 01 Oct 2025 16:11:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26153v2</guid></item><item><title>SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration</title><link>http://arxiv.org/abs/2410.02367v9</link><description>The transformer architecture predominates across various models. As the heartof the transformer, attention has a computational complexity of $O(N^2)$,compared to $O(N)$ for linear transformations. When handling large sequencelengths, attention becomes the primary time-consuming component. Althoughquantization has proven to be an effective method for accelerating modelinference, existing quantization methods primarily focus on optimizing thelinear layer. In response, we first analyze the feasibility of quantization inattention detailedly. Following that, we propose SageAttention, a highlyefficient and accurate quantization method for attention. The OPS (operationsper second) of our approach outperforms FlashAttention2 and xformers by about2.1 times and 2.7 times, respectively. SageAttention also achieves superioraccuracy performance over FlashAttention3. Comprehensive experiments confirmthat our approach incurs almost no end-to-end metrics loss across diversemodels, including those for large language processing, image generation, andvideo generation. The codes are available athttps://github.com/thu-ml/SageAttention.</description><author>Jintao Zhang, Jia Wei, Haofeng Huang, Pengle Zhang, Jun Zhu, Jianfei Chen</author><pubDate>Wed, 01 Oct 2025 16:09:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02367v9</guid></item><item><title>Model Parallelism With Subnetwork Data Parallelism</title><link>http://arxiv.org/abs/2507.09029v2</link><description>Distributed pre-training of large models at scale often imposes heavy memorydemands on individual nodes and incurs significant intra-node communicationcosts. We propose a novel alternative approach that reduces the memoryrequirements by training small, structured subnetworks of the model on separateworkers. Unlike pipelining, our method avoids inter-node activationcommunication and maintains bandwidth requirements that are comparable to orlower than standard data parallel communication schemes based on all-reduce. Weevaluate two subnetwork construction strategies guided by the principle ofensuring uniform representation of each parameter across the distributedtraining setup. Our results show that the stochastic block dropping techniqueconsistently outperforms the width-wise subnetwork construction previouslyexplored in federated learning. We empirically attribute this superiorperformance to stronger gradient alignment in subnetworks that retain blockshaving skip connections. Preliminary experiments highlight the promise of ourapproach, achieving a 20-40% reduction in memory usage without any loss inperformance.</description><author>Vaibhav Singh, Zafir Khalid, Edouard Oyallon, Eugene Belilovsky</author><pubDate>Wed, 01 Oct 2025 16:08:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.09029v2</guid></item><item><title>GRID: Scalable Task-Agnostic Prompt-Based Continual Learning for Language Models</title><link>http://arxiv.org/abs/2507.14725v3</link><description>Prompt-based continual learning (CL) provides a parameter-efficient approachfor adapting large language models (LLMs) across task sequences. However, mostexisting methods rely on task-aware inference and maintain a growing set oftask-specific prompts, which introduces two major challenges: (1) severeperformance degradation on earlier tasks under task-agnostic inference, and (2)limited scalability due to prompt memory accumulation as task sequences grow.In this paper, we present GRID, a unified framework designed to address thesechallenges. GRID incorporates a decoding mechanism that enhances backwardtransfer by leveraging representative inputs, automatic task identification,and constrained decoding. Furthermore, it employs a gradient-guided promptselection strategy to compress less informative prompts into a singleaggregated representation, ensuring scalable and memory-efficient continuallearning. Extensive experiments on long-sequence and negative transferbenchmarks show that GRID improves average accuracy and backward transfer,achieves competitive forward transfer, and substantially reduces prompt memoryusage.</description><author>Anushka Tiwari, Sayantan Pal, Rohini K. Srihari, Kaiyi Ji</author><pubDate>Wed, 01 Oct 2025 16:07:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.14725v3</guid></item><item><title>Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties</title><link>http://arxiv.org/abs/2506.05744v3</link><description>Recent large-scale reasoning models have achieved state-of-the-artperformance on challenging mathematical benchmarks, yet the internal mechanismsunderlying their success remain poorly understood. In this work, we introducethe notion of a reasoning graph, extracted by clustering hidden-staterepresentations at each reasoning step, and systematically analyze three keygraph-theoretic properties: cyclicity, diameter, and small-world index, acrossmultiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilledreasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantlymore recurrent cycles (about 5 per sample), substantially larger graphdiameters, and pronounced small-world characteristics (about 6x) compared totheir base counterparts. Notably, these structural advantages grow with taskdifficulty and model capacity, with cycle detection peaking at the 14B scaleand exploration diameter maximized in the 32B variant, correlating positivelywith accuracy. Furthermore, we show that supervised fine-tuning on an improveddataset systematically expands reasoning graph diameters in tandem withperformance gains, offering concrete guidelines for dataset design aimed atboosting reasoning capabilities. By bridging theoretical insights intoreasoning graph structures with practical recommendations for dataconstruction, our work advances both the interpretability and the efficacy oflarge reasoning models.</description><author>Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo</author><pubDate>Wed, 01 Oct 2025 16:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05744v3</guid></item><item><title>Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2505.15957v3</link><description>With advancements in large audio-language models (LALMs), which enhance largelanguage models (LLMs) with auditory capabilities, these models are expected todemonstrate universal proficiency across various auditory tasks. While numerousbenchmarks have emerged to assess LALMs' performance, they remain fragmentedand lack a structured taxonomy. To bridge this gap, we conduct a comprehensivesurvey and propose a systematic taxonomy for LALM evaluations, categorizingthem into four dimensions based on their objectives: (1) General AuditoryAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-orientedAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailedoverviews within each category and highlight challenges in this field, offeringinsights into promising future directions. To the best of our knowledge, thisis the first survey specifically focused on the evaluations of LALMs, providingclear guidelines for the community. We will release the collection of thesurveyed papers and actively maintain it to support ongoing advancements in thefield.</description><author>Chih-Kai Yang, Neo S. Ho, Hung-yi Lee</author><pubDate>Wed, 01 Oct 2025 16:02:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15957v3</guid></item><item><title>Benchmarking LLM-Assisted Blue Teaming via Standardized Threat Hunting</title><link>http://arxiv.org/abs/2509.23571v2</link><description>As cyber threats continue to grow in scale and sophistication, blue teamdefenders increasingly require advanced tools to proactively detect andmitigate risks. Large Language Models (LLMs) offer promising capabilities forenhancing threat analysis. However, their effectiveness in real-world blue teamthreat-hunting scenarios remains insufficiently explored. This paper presentsCyberTeam, a benchmark designed to guide LLMs in blue teaming practice.CyberTeam constructs a standardized workflow in two stages. First, it modelsrealistic threat-hunting workflows by capturing the dependencies amonganalytical tasks from threat attribution to incident response. Next, each taskis addressed through a set of operational modules tailored to its specificanalytical requirements. This transforms threat hunting into a structuredsequence of reasoning steps, with each step grounded in a discrete operationand ordered according to task-specific dependencies. Guided by this framework,LLMs are directed to perform threat-hunting tasks through modularized steps.Overall, CyberTeam integrates 30 tasks and 9 operational modules to guide LLMsthrough standardized threat analysis. We evaluate both leading LLMs andstate-of-the-art cybersecurity agents, comparing CyberTeam against open-endedreasoning strategies. Our results highlight the improvements enabled bystandardized design, while also revealing the limitations of open-endedreasoning in real-world threat hunting.</description><author>Yuqiao Meng, Luoxi Tang, Feiyang Yu, Xi Li, Guanhua Yan, Ping Yang, Zhaohan Xi</author><pubDate>Wed, 01 Oct 2025 16:01:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23571v2</guid></item><item><title>Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning</title><link>http://arxiv.org/abs/2504.13818v3</link><description>Reinforcement learning with verifiable rewards (RLVR) has emerged as theleading approach for enhancing reasoning capabilities in large language models.However, it faces a fundamental compute and memory asymmetry: rolloutgeneration is embarrassingly parallel and memory-light, whereas policy updatesare communication-heavy and memory-intensive. To address this, we introducePODS (Policy Optimization with Down-Sampling), which decouples rolloutgeneration from policy updates by training only on a strategically selectedsubset of rollouts, maintaining learning quality while dramatically reducingupdate costs. We propose a principled subset selection criterion, max-variancedown-sampling, that maximizes reward diversity, and provide an efficient$O(n\log n)$ implementation. Empirically, Group Relative Policy Optimization(GRPO) with PODS achieves the peak test accuracy of vanilla GRPO at least$\mathbf{1.7\times}$ faster across the different reasoning benchmarks andhardware configurations we tested.</description><author>Yixuan Even Xu, Yash Savani, Fei Fang, J. Zico Kolter</author><pubDate>Wed, 01 Oct 2025 15:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.13818v3</guid></item><item><title>Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence</title><link>http://arxiv.org/abs/2509.23573v2</link><description>Large Language Models (LLMs) are intensively used to assist security analystsin counteracting the rapid exploitation of cyber threats, wherein LLMs offercyber threat intelligence (CTI) to support vulnerability assessment andincident response. While recent work has shown that LLMs can support a widerange of CTI tasks such as threat analysis, vulnerability detection, andintrusion defense, significant performance gaps persist in practicaldeployments. In this paper, we investigate the intrinsic vulnerabilities ofLLMs in CTI, focusing on challenges that arise from the nature of the threatlandscape itself rather than the model architecture. Using large-scaleevaluations across multiple CTI benchmarks and real-world threat reports, weintroduce a novel categorization methodology that integrates stratification,autoregressive refinement, and human-in-the-loop supervision to reliablyanalyze failure instances. Through extensive experiments and human inspections,we reveal three fundamental vulnerabilities: spurious correlations,contradictory knowledge, and constrained generalization, that limit LLMs ineffectively supporting CTI. Subsequently, we provide actionable insights fordesigning more robust LLM-powered CTI systems to facilitate future research.</description><author>Yuqiao Meng, Luoxi Tang, Feiyang Yu, Jinyuan Jia, Guanhua Yan, Ping Yang, Zhaohan Xi</author><pubDate>Wed, 01 Oct 2025 15:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23573v2</guid></item><item><title>An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection</title><link>http://arxiv.org/abs/2509.06920v2</link><description>Insider threats are a growing organizational problem due to the complexity ofidentifying their technical and behavioral elements. A large research body isdedicated to the study of insider threats from technological, psychological,and educational perspectives. However, research in this domain has beengenerally dependent on datasets that are static and limited access whichrestricts the development of adaptive detection models. This study introduces anovel, ethically grounded approach that uses the large language model (LLM)Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of whichcontain indicators of insider threat scenarios. The messages reflect real-worlddata distributions by being highly imbalanced (1% insider threats). The syslogswere analyzed for insider threats by both Sonnet 3.7 and GPT-4o, with theirperformance evaluated through statistical metrics including accuracy,precision, recall, F1, specificity, FAR, MCC, and ROC AUC. Sonnet 3.7consistently outperformed GPT-4o across nearly all metrics, particularly inreducing false alarms and improving detection accuracy. The results show strongpromise for the use of LLMs in synthetic dataset generation and insider threatdetection.</description><author>Haywood Gelman, John D. Hastings, David Kenley</author><pubDate>Wed, 01 Oct 2025 15:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.06920v2</guid></item><item><title>CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing &amp; Sparsification</title><link>http://arxiv.org/abs/2508.21046v2</link><description>Recent Vision-Language-Action (VLA) models built on pre-trainedVision-Language Models (VLMs) require extensive post-training, resulting inhigh computational overhead that limits scalability and deployment.We proposeCogVLA, a Cognition-Aligned Vision-Language-Action framework that leveragesinstruction-driven routing and sparsification to improve both efficiency andperformance. CogVLA draws inspiration from human multimodal coordination andintroduces a 3-stage progressive architecture. 1) Encoder-FiLM basedAggregation Routing (EFA-Routing) injects instruction information into thevision encoder to selectively aggregate and compress dual-stream visual tokens,forming a instruction-aware latent representation. 2) Building upon thiscompact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)introduces action intent into the language model by pruninginstruction-irrelevant visually grounded tokens, thereby achieving token-levelsparsity. 3) To ensure that compressed perception inputs can still supportaccurate and coherent action generation, we introduce V-L-A Coupled Attention(CAtten), which combines causal vision-language attention with bidirectionalaction parallel decoding. Extensive experiments on the LIBERO benchmark andreal-world robotic tasks demonstrate that CogVLA achieves state-of-the-artperformance with success rates of 97.4% and 70.0%, respectively, while reducingtraining costs by 2.5-fold and decreasing inference latency by 2.8-foldcompared to OpenVLA. CogVLA is open-sourced and publicly available athttps://github.com/JiuTian-VL/CogVLA.</description><author>Wei Li, Renshan Zhang, Rui Shao, Jie He, Liqiang Nie</author><pubDate>Wed, 01 Oct 2025 15:48:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.21046v2</guid></item><item><title>GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving</title><link>http://arxiv.org/abs/2503.05689v6</link><description>We propose GoalFlow, an end-to-end autonomous driving method for generatinghigh-quality multimodal trajectories. In autonomous driving scenarios, there israrely a single suitable trajectory. Recent methods have increasingly focusedon modeling multimodal trajectory distributions. However, they suffer fromtrajectory selection complexity and reduced trajectory quality due to hightrajectory divergence and inconsistencies between guidance and sceneinformation. To address these issues, we introduce GoalFlow, a novel methodthat effectively constrains the generative process to produce high-quality,multimodal trajectories. To resolve the trajectory divergence problem inherentin diffusion-based methods, GoalFlow constrains the generated trajectories byintroducing a goal point. GoalFlow establishes a novel scoring mechanism thatselects the most appropriate goal point from the candidate points based onscene information. Furthermore, GoalFlow employs an efficient generativemethod, Flow Matching, to generate multimodal trajectories, and incorporates arefined scoring mechanism to select the optimal trajectory from the candidates.Our experimental results, validated on the Navsim\cite{Dauner2024_navsim},demonstrate that GoalFlow achieves state-of-the-art performance, deliveringrobust multimodal trajectories for autonomous driving. GoalFlow achieved PDMSof 90.3, significantly surpassing other methods. Compared with otherdiffusion-policy-based methods, our approach requires only a single denoisingstep to obtain excellent performance. The code is available athttps://github.com/YvanYin/GoalFlow.</description><author>Zebin Xing, Xingyu Zhang, Yang Hu, Bo Jiang, Tong He, Qian Zhang, Xiaoxiao Long, Wei Yin</author><pubDate>Wed, 01 Oct 2025 15:47:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.05689v6</guid></item><item><title>Ambiguity in LLMs is a concept missing problem</title><link>http://arxiv.org/abs/2505.11679v3</link><description>Ambiguity in natural language is a significant obstacle for achievingaccurate text to structured data mapping through large language models (LLMs),which affects the performance of tasks such as mapping text to agentic toolcalling and text-to-SQL queries. Existing methods to ambiguity handling eitherrely on the ReACT framework to obtain correct mappings through trial and error,or on supervised fine-tuning to bias models toward specific tasks. In thispaper, we adopt a different approach that characterizes representationdifferences of ambiguous text in the latent space and leverages thesedifferences to identify ambiguity before mapping them to structured data. Todetect sentence-level ambiguity, we focus on the relationship between ambiguousquestions and their interpretations. Unlike distances calculated by denseembeddings, we introduce a new distance measure based on a path kernel overconcepts. With this measurement, we identify patterns to distinguish ambiguousfrom unambiguous questions. Furthermore, we propose a method for improving LLMperformance on ambiguous agentic tool calling through missing conceptprediction. Both achieve state-of-the-art results.</description><author>Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu</author><pubDate>Wed, 01 Oct 2025 15:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.11679v3</guid></item><item><title>Graph Transformer Networks for Accurate Band Structure Prediction: An End-to-End Approach</title><link>http://arxiv.org/abs/2411.16483v2</link><description>Predicting electronic band structures from crystal structures is crucial forunderstanding structure-property correlations in materials science.First-principles approaches are accurate but computationally intensive. Recentyears, machine learning (ML) has been extensively applied to this field, whileexisting ML models predominantly focus on band gap predictions or indirect bandstructure estimation via solving predicted Hamiltonians. An end-to-end model topredict band structure accurately and efficiently is still lacking. Here, weintroduce a graph Transformer-based end-to-end approach that directly predictsband structures from crystal structures with high accuracy. Our methodleverages the continuity of the k-path and treat continuous bands as asequence. We demonstrate that our model not only provides accurate bandstructure predictions but also can derive other properties (such as band gap,band center, and band dispersion) with high accuracy. We verify the modelperformance on large and diverse datasets.</description><author>Weiyi Gong, Tao Sun, Hexin Bai, Jeng-Yuan Tsai, Haibin Ling, Qimin Yan</author><pubDate>Wed, 01 Oct 2025 15:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.16483v2</guid></item><item><title>ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language Models through Agentic Data Synthesis</title><link>http://arxiv.org/abs/2509.23652v2</link><description>While Reinforcement Learning with Verifiable Reward (RLVR) significantlyadvances image reasoning in Large Vision-Language Models (LVLMs), itsapplication to complex video reasoning remains underdeveloped. This gap stemsprimarily from a critical data bottleneck: existing datasets lack thechallenging, multi-hop questions and high-quality, video-groundedChain-of-Thought (CoT) data necessary to effectively bootstrap RLVR. To addressthis, we introduce ReWatch, a large-scale dataset built to foster advancedvideo reasoning. We propose a novel multi-stage synthesis pipeline tosynthesize its three components: ReWatch-Caption, ReWatch-QA, and ReWatch-CoT.A core innovation is our Multi-Agent ReAct framework for CoT synthesis, whichsimulates a human-like "re-watching" process to generate video-groundedreasoning traces by explicitly modeling information retrieval and verification.Building on this dataset, we develop ReWatch-R1 by post-training a strongbaseline LVLM with Supervised Fine-Tuning (SFT) and our RLVR framework. Thisframework incorporates a novel Observation \&amp; Reasoning (O\&amp;R) reward mechanismthat evaluates both the final answer's correctness and the reasoning'salignment with video content, directly penalizing hallucination. Ourexperiments show that ReWatch-R1 achieves state-of-the-art average performanceon five challenging video reasoning benchmarks. Project Page:https://rewatch-r1.github.io</description><author>Congzhi Zhang, Zhibin Wang, Yinchao Ma, Jiawei Peng, Yihan Wang, Qiang Zhou, Jun Song, Bo Zheng</author><pubDate>Wed, 01 Oct 2025 15:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23652v2</guid></item><item><title>Stackelberg Coupling of Online Representation Learning and Reinforcement Learning</title><link>http://arxiv.org/abs/2508.07452v2</link><description>Deep Q-learning jointly learns representations and values within monolithicnetworks, promising beneficial co-adaptation between features and valueestimates. Although this architecture has attained substantial success, thecoupling between representation and value learning creates instability asrepresentations must constantly adapt to non-stationary value targets, whilevalue estimates depend on these shifting representations. This is compounded byhigh variance in bootstrapped targets, which causes bias in value estimation inoff-policy methods. We introduce Stackelberg Coupled Representation andReinforcement Learning (SCORER), a framework for value-based RL that viewsrepresentation and Q-learning as two strategic agents in a hierarchical game.SCORER models the Q-function as the leader, which commits to its strategy byupdating less frequently, while the perception network (encoder) acts as thefollower, adapting more frequently to learn representations that minimizeBellman error variance given the leader's committed strategy. Through thisdivision of labor, the Q-function minimizes MSBE while perception minimizes itsvariance, thereby reducing bias accordingly, with asymmetric updates allowingstable co-adaptation, unlike simultaneous parameter updates in monolithicsolutions. Our proposed SCORER framework leads to a bi-level optimizationproblem whose solution is approximated by a two-timescale algorithm thatcreates an asymmetric learning dynamic between the two players. Extensiveexperiments on DQN and its variants demonstrate that gains stem fromalgorithmic insight rather than model complexity.</description><author>Fernando Martinez, Tao Li, Yingdong Lu, Juntao Chen</author><pubDate>Wed, 01 Oct 2025 15:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.07452v2</guid></item><item><title>Stability Bounds for the Unfolded Forward-Backward Algorithm</title><link>http://arxiv.org/abs/2412.17888v2</link><description>We consider a neural network architecture designed to solve inverse problemswhere the degradation operator is linear and known. This architecture isconstructed by unrolling a forward-backward algorithm derived from theminimization of an objective function that combines a data-fidelity term, aTikhonov-type regularization term, and a potentially nonsmooth convex penalty.The robustness of this inversion method to input perturbations is analyzedtheoretically. Ensuring robustness complies with the principles of inverseproblem theory, as it ensures both the continuity of the inversion method andthe resilience to small noise - a critical property given the knownvulnerability of deep neural networks to adversarial perturbations. A keynovelty of our work lies in examining the robustness of the proposed network toperturbations in its bias, which represents the observed data in the inverseproblem. Additionally, we provide numerical illustrations of the analyticalLipschitz bounds derived in our analysis.</description><author>Emilie Chouzenoux, Cecile Della Valle, Jean-Christophe Pesquet</author><pubDate>Wed, 01 Oct 2025 15:27:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17888v2</guid></item><item><title>Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?</title><link>http://arxiv.org/abs/2509.03516v2</link><description>Text-to-image (T2I) generation aims to synthesize images from textualprompts, which jointly specify what must be shown and imply what can beinferred, which thus correspond to two core capabilities: composition andreasoning. Despite recent advances of T2I models in both composition andreasoning, existing benchmarks remain limited in evaluation. They not only failto provide comprehensive coverage across and within both capabilities, but alsolargely restrict evaluation to low scene density and simple one-to-onereasoning. To address these limitations, we propose T2I-CoReBench, acomprehensive and complex benchmark that evaluates both composition andreasoning capabilities of T2I models. To ensure comprehensiveness, we structurecomposition around scene graph elements (instance, attribute, and relation) andreasoning around the philosophical framework of inference (deductive,inductive, and abductive), formulating a 12-dimensional evaluation taxonomy. Toincrease complexity, driven by the inherent real-world complexities, we curateeach prompt with higher compositional density for composition and greaterreasoning intensity for reasoning. To facilitate fine-grained and reliableevaluation, we also pair each evaluation prompt with a checklist that specifiesindividual yes/no questions to assess each intended element independently. Instatistics, our benchmark comprises 1,080 challenging prompts and around 13,500checklist questions. Experiments across 28 current T2I models reveal that theircomposition capability still remains limited in high compositional scenarios,while the reasoning capability lags even further behind as a criticalbottleneck, with all models struggling to infer implicit elements from prompts.</description><author>Ouxiang Li, Yuan Wang, Xinting Hu, Huijuan Huang, Rui Chen, Jiarong Ou, Xin Tao, Pengfei Wan, Xiaojuan Qi, Fuli Feng</author><pubDate>Wed, 01 Oct 2025 15:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.03516v2</guid></item><item><title>Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification</title><link>http://arxiv.org/abs/2504.17017v2</link><description>Formally verifying properties of software code has been a highly desirabletask, especially with the emergence of LLM-generated code. In the same vein,they provide an interesting avenue for the exploration of formal verificationand mechanistic interpretability. Since the introduction of code-specificmodels, despite their successes in generating code in Lean4 and Isabelle, thetask of generalized theorem proving still remains far from being fully solvedand will be a benchmark for reasoning capability in LLMs. In this work, weintroduce a framework that generates whole proofs in a formal language to beused within systems that utilize the power of built-in tactics andoff-the-shelf automated theorem provers. Our framework includes 3 components:generating natural language statements of the code to be verified, an LLM thatgenerates formal proofs for the given statement, and a module employingheuristics for building the final proof. To train the LLM, we employ a 2-stagefine-tuning process, where we first use SFT-based training to enable the modelto generate syntactically correct Isabelle code and then RL-based training thatencourages the model to generate proofs verified by a theorem prover. Wevalidate our framework using the miniF2F-test benchmark and the Isabelle proofassistant and design a use case to verify the correctness of the AWS S3 bucketaccess policy code. We also curate a dataset based on theFVEL\textsubscript{\textnormal{ER}} dataset for future training tasks.</description><author>Balaji Rao, William Eiers, Carlo Lipizzi</author><pubDate>Wed, 01 Oct 2025 15:25:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.17017v2</guid></item><item><title>PaECTER: Patent-level Representation Learning using Citation-informed Transformers</title><link>http://arxiv.org/abs/2402.19411v2</link><description>PaECTER is an open-source document-level encoder specific for patents. Wefine-tune BERT for Patents with examiner-added citation information to generatenumerical representations for patent documents. PaECTER performs better insimilarity tasks than current state-of-the-art models used in the patentdomain. More specifically, our model outperforms the patent specificpre-trained language model (BERT for Patents) and general-purpose textembedding models (e.g., E5, GTE, and BGE) on our patent citation predictiontest dataset on different rank evaluation metrics. PaECTER predicts at leastone most similar patent at a rank of 1.32 on average when compared against 25irrelevant patents. Numerical representations generated by PaECTER from patenttext can be used for downstream tasks such as classification, tracing knowledgeflows, or semantic similarity search. Semantic similarity search is especiallyrelevant in the context of prior art search for both inventors and patentexaminers.</description><author>Mainak Ghosh, Michael E. Rose, Sebastian Erhardt, Erik Buunk, Dietmar Harhoff</author><pubDate>Wed, 01 Oct 2025 15:24:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19411v2</guid></item><item><title>LLM Watermark Evasion via Bias Inversion</title><link>http://arxiv.org/abs/2509.23019v2</link><description>Watermarking for large language models (LLMs) embeds a statistical signalduring generation to enable detection of model-produced text. Whilewatermarking has proven effective in benign settings, its robustness underadversarial evasion remains contested. To advance a rigorous understanding andevaluation of such vulnerabilities, we propose the \emph{Bias-InversionRewriting Attack} (BIRA), which is theoretically motivated and model-agnostic.BIRA weakens the watermark signal by suppressing the logits of likelywatermarked tokens during LLM-based rewriting, without any knowledge of theunderlying watermarking scheme. Across recent watermarking methods, BIRAachieves over 99\% evasion while preserving the semantic content of theoriginal text. Beyond demonstrating an attack, our results reveal a systematicvulnerability, emphasizing the need for stress testing and robust defenses.</description><author>Jeongyeon Hwang, Sangdon Park, Jungseul Ok</author><pubDate>Wed, 01 Oct 2025 15:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23019v2</guid></item><item><title>AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents</title><link>http://arxiv.org/abs/2506.04018v2</link><description>As Large Language Model (LLM) agents become more widespread, associatedmisalignment risks increase. While prior research has studied agents' abilityto produce harmful outputs or follow malicious instructions, it remains unclearhow likely agents are to spontaneously pursue unintended goals in realisticdeployments. In this work, we approach misalignment as a conflict between theinternal goals pursued by the model and the goals intended by its deployer. Weintroduce a misalignment propensity benchmark, \textsc{AgentMisalignment}, abenchmark suite designed to evaluate the propensity of LLM agents to misalignin realistic scenarios. Evaluations cover behaviours such as avoidingoversight, resisting shutdown, sandbagging, and power-seeking. Testing frontiermodels, we find that more capable agents tend to exhibit higher misalignment onaverage. We also systematically vary agent personalities through differentsystem prompts and observe that persona characteristics can strongly andunpredictably influence misalignment, sometimes more than the choice of modelitself. Our results reveal the limitations of current alignment methods forautonomous LLM agents and underscore the need to rethink misalignment inrealistic deployment settings.</description><author>Akshat Naik, Patrick Quinn, Guillermo Bosch, Emma Gouné, Francisco Javier Campos Zabala, Jason Ross Brown, Edward James Young</author><pubDate>Wed, 01 Oct 2025 15:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.04018v2</guid></item><item><title>A Framework for Double-Blind Federated Adaptation of Foundation Models</title><link>http://arxiv.org/abs/2502.01289v2</link><description>Foundation models (FMs) excel in zero-shot tasks but benefit fromtask-specific adaptation. However, privacy concerns prevent data sharing amongmultiple data owners, and proprietary restrictions prevent the learning serviceprovider (LSP) from sharing the FM. In this work, we propose BlindFed, aframework enabling collaborative FM adaptation while protecting both parties:data owners do not access the FM or each other's data, and the LSP does not seesensitive task data. BlindFed relies on fully homomorphic encryption (FHE) andconsists of three key innovations: (i) FHE-friendly architectural modificationsvia polynomial approximations and low-rank adapters, (ii) a two-stage splitlearning approach combining offline knowledge distillation and online encryptedinference for adapter training without backpropagation through the FM, and(iii) a privacy-boosting scheme using sample permutations and stochastic blocksampling to mitigate model extraction attacks. Empirical results on four imageclassification datasets demonstrate the practical feasibility of the BlindFedframework, albeit at a high communication cost and large computationalcomplexity for the LSP.</description><author>Nurbek Tastan, Karthik Nandakumar</author><pubDate>Wed, 01 Oct 2025 15:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01289v2</guid></item><item><title>SEE: See Everything Every Time -- Adaptive Brightness Adjustment for Broad Light Range Images via Events</title><link>http://arxiv.org/abs/2502.21120v2</link><description>Event cameras, with a high dynamic range exceeding $120dB$, significantlyoutperform traditional embedded cameras, robustly recording detailed changinginformation under various lighting conditions, including both low- andhigh-light situations. However, recent research on utilizing event data hasprimarily focused on low-light image enhancement, neglecting image enhancementand brightness adjustment across a broader range of lighting conditions, suchas normal or high illumination. Based on this, we propose a novel researchquestion: how to employ events to enhance and adaptively adjust the brightnessof images captured under broad lighting conditions? To investigate thisquestion, we first collected a new dataset, SEE-600K, consisting of 610,126images and corresponding events across 202 scenarios, each featuring an averageof four lighting conditions with over a 1000-fold variation in illumination.Subsequently, we propose a framework that effectively utilizes events tosmoothly adjust image brightness through the use of prompts. Our frameworkcaptures color through sensor patterns, uses cross-attention to model events asa brightness dictionary, and adjusts the image's dynamic range to form a broadlight-range representation (BLR), which is then decoded at the pixel levelbased on the brightness prompt. Experimental results demonstrate that ourmethod not only performs well on the low-light enhancement dataset but alsoshows robust performance on broader light-range image enhancement using theSEE-600K dataset. Additionally, our approach enables pixel-level brightnessadjustment, providing flexibility for post-processing and inspiring moreimaging applications. The dataset and source code are publicly available at:https://github.com/yunfanLu/SEE.</description><author>Yunfan Lu, Xiaogang Xu, Hao Lu, Yanlin Qian, Pengteng Li, Huizai Yao, Bin Yang, Junyi Li, Qianyi Cai, Weiyu Guo, Hui Xiong</author><pubDate>Wed, 01 Oct 2025 15:13:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.21120v2</guid></item><item><title>Adversarial Attacks to Latent Representations of Distributed Neural Networks in Split Computing</title><link>http://arxiv.org/abs/2309.17401v5</link><description>Distributed deep neural networks (DNNs) have been shown to reduce thecomputational burden of mobile devices and decrease the end-to-end inferencelatency in edge computing scenarios. While distributed DNNs have been studied,to the best of our knowledge, the resilience of distributed DNNs to adversarialaction remains an open problem. In this paper, we fill the existing researchgap by rigorously analyzing the robustness of distributed DNNs againstadversarial action. We cast this problem in the context of information theoryand rigorously proved that (i) the compressed latent dimension improves therobustness but also affect task-oriented performance; and (ii) the deepersplitting point enhances the robustness but also increases the computationalburden. These two trade-offs provide a novel perspective to design robustdistributed DNN. To test our theoretical findings, we perform extensiveexperimental analysis by considering 6 different DNN architectures, 6 differentapproaches for distributed DNN and 10 different adversarial attacks using theImageNet-1K dataset.</description><author>Milin Zhang, Mohammad Abdi, Jonathan Ashdown, Francesco Restuccia</author><pubDate>Wed, 01 Oct 2025 15:10:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17401v5</guid></item><item><title>Improving Retrieval-Augmented Neural Machine Translation with Monolingual Data</title><link>http://arxiv.org/abs/2504.21747v2</link><description>Conventional retrieval-augmented neural machine translation (RANMT) systemsleverage bilingual corpora, e.g., translation memories (TMs). Yet, in manysettings, monolingual corpora in the target language are often available. Thiswork explores ways to take advantage of such resources by directly retrievingrelevant target language segments, based on a source-side query. For this, wedesign improved cross-lingual retrieval systems, trained with both sentencelevel and word-level matching objectives. In our experiments with three RANMTarchitectures, we assess such cross-lingual objectives in a controlled setting,reaching performances that match those of standard TM-based models. We alsoshowcase our method on a real-world settings, using much larger monolingual andobserve strong improvements over both the baseline setting and general-purposecross-lingual retrievers.</description><author>Maxime Bouthors, Josep Crego, François Yvon</author><pubDate>Wed, 01 Oct 2025 14:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.21747v2</guid></item><item><title>Gauges and Accelerated Optimization over Smooth and/or Strongly Convex Sets</title><link>http://arxiv.org/abs/2303.05037v4</link><description>We consider feasibility and constrained optimization problems defined oversmooth and/or strongly convex sets. These notions mirror their popular functioncounterparts but are much less explored in the first-order optimizationliterature. We propose new scalable, projection-free, accelerated first-ordermethods in these settings. Our methods avoid linear optimization or projectionoracles, only using cheap one-dimensional linesearches and normal vectorcomputations. Despite this, we derive optimal accelerated convergenceguarantees of $O(1/T)$ for strongly convex problems, $O(1/T^2)$ for smoothproblems, and accelerated linear convergence given both. Our algorithms andanalysis are based on novel characterizations of the Minkowski gauge of smoothand/or strongly convex sets, which may be of independent interest: although thegauge is neither smooth nor strongly convex, we show the gauge squared inheritsany structure present in the set.</description><author>Ning Liu, Benjamin Grimmer</author><pubDate>Wed, 01 Oct 2025 14:47:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05037v4</guid></item><item><title>Replicable Reinforcement Learning with Linear Function Approximation</title><link>http://arxiv.org/abs/2509.08660v2</link><description>Replication of experimental results has been a challenge faced by manyscientific disciplines, including the field of machine learning. Recent work onthe theory of machine learning has formalized replicability as the demand thatan algorithm produce identical outcomes when executed twice on differentsamples from the same distribution. Provably replicable algorithms areespecially interesting for reinforcement learning (RL), where algorithms areknown to be unstable in practice. While replicable algorithms exist for tabularRL settings, extending these guarantees to more practical functionapproximation settings has remained an open problem. In this work, we makeprogress by developing replicable methods for linear function approximation inRL. We first introduce two efficient algorithms for replicable random designregression and uncentered covariance estimation, each of independent interest.We then leverage these tools to provide the first provably efficient replicableRL algorithms for linear Markov decision processes in both the generative modeland episodic settings. Finally, we evaluate our algorithms experimentally andshow how they can inspire more consistent neural policies.</description><author>Eric Eaton, Marcel Hussing, Michael Kearns, Aaron Roth, Sikata Bela Sengupta, Jessica Sorrell</author><pubDate>Wed, 01 Oct 2025 14:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.08660v2</guid></item><item><title>Accurate Estimation of Mutual Information in High Dimensional Data</title><link>http://arxiv.org/abs/2506.00330v2</link><description>Mutual information (MI) is a fundamental measure of statistical dependencebetween two variables, yet accurate estimation from finite data remainsnotoriously difficult. No estimator is universally reliable, and commonapproaches fail in the high-dimensional, undersampled regimes typical of modernexperiments. Recent machine learning-based estimators show promise, but theiraccuracy depends sensitively on dataset size, structure, and hyperparameters,with no accepted tests to detect failures. We close these gaps through asystematic evaluation of classical and neural MI estimators across standardbenchmarks and new synthetic datasets tailored to challenging high-dimensional,undersampled regimes. We contribute: (i) a practical protocol for reliable MIestimation with explicit checks for statistical consistency; (ii) confidenceintervals (error bars around estimates) that existing neural MI estimator donot provide; and (iii) a new class of probabilistic critics designed forhigh-dimensional, high-information settings. We demonstrate the effectivenessof our protocol with computational experiments, showing that it consistentlymatches or surpasses existing methods while uniquely quantifying its ownreliability. We show that reliable MI estimation is sometimes achievable evenin severely undersampled, high-dimensional datasets, provided they admitaccurate low-dimensional representations. This broadens the scope ofapplicability of neural MI estimators and clarifies when such estimators can betrusted.</description><author>Eslam Abdelaleem, K. Michael Martini, Ilya Nemenman</author><pubDate>Wed, 01 Oct 2025 14:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.00330v2</guid></item><item><title>Integration of Calcium Imaging Traces via Deep Generative Modeling</title><link>http://arxiv.org/abs/2501.14615v3</link><description>Calcium imaging allows for the parallel measurement of large neuronalpopulations in a spatially resolved and minimally invasive manner, and hasbecome a gold-standard for neuronal functionality. While deep generative modelshave been successfully applied to study the activity of neuronal ensembles,their potential for learning single-neuron representations from calcium imagingfluorescence traces remains largely unexplored, and batch effects remain animportant hurdle. To address this, we explore supervised variationalautoencoder architectures that learn compact representations of individualneurons from fluorescent traces without relying on spike inference algorithms.We find that this approach outperforms state-of-the-art models, preservingbiological variability while mitigating batch effects. Across simulated andexperimental datasets, this framework enables robust visualization, clustering,and interpretation of single-neuron dynamics.</description><author>Berta Ros, Mireia Olives-Verger, Caterina Fuses, Josep M Canals, Jordi Soriano, Jordi Abante</author><pubDate>Wed, 01 Oct 2025 14:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14615v3</guid></item><item><title>LLM-guided Task and Motion Planning using Knowledge-based Reasoning</title><link>http://arxiv.org/abs/2412.07493v3</link><description>Performing complex manipulation tasks in dynamic environments requiresefficient Task and Motion Planning (TAMP) approaches that combine high-levelsymbolic plans with low-level motion control. Advances in Large Language Models(LLMs), such as GPT-4, are transforming task planning by offering naturallanguage as an intuitive and flexible way to describe tasks, generate symbolicplans, and reason. However, the effectiveness of LLM-based TAMP approaches islimited due to static and template-based prompting, which limits adaptabilityto dynamic environments and complex task contexts. To address theselimitations, this work proposes a novel Onto-LLM-TAMP framework that employsknowledge-based reasoning to refine and expand user prompts withtask-contextual reasoning and knowledge-based environment state descriptions.Integrating domain-specific knowledge into the prompt ensures semanticallyaccurate and context-aware task plans. The proposed framework demonstrates itseffectiveness by resolving semantic errors in symbolic plan generation, such asmaintaining logical temporal goal ordering in scenarios involving hierarchicalobject placement. The proposed framework is validated through both simulationand real-world scenarios, demonstrating significant improvements over thebaseline approach in terms of adaptability to dynamic environments and thegeneration of semantically correct task plans.</description><author>Muhayy Ud Din, Jan Rosell, Waseem Akram, Isiah Zaplana, Maximo A Roa, Irfan Hussain</author><pubDate>Wed, 01 Oct 2025 14:37:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07493v3</guid></item><item><title>Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing</title><link>http://arxiv.org/abs/2509.22255v2</link><description>This paper presents an evaluation framework for assessing Large LanguageModels' (LLMs) capabilities in combinatorial optimization, specificallyaddressing the 2D bin-packing problem. We introduce a systematic methodologythat combines LLMs with evolutionary algorithms to generate and refineheuristic solutions iteratively. Through comprehensive experiments comparingLLM generated heuristics against traditional approaches (Finite First-Fit andHybrid First-Fit), we demonstrate that LLMs can produce more efficientsolutions while requiring fewer computational resources. Our evaluation revealsthat GPT-4o achieves optimal solutions within two iterations, reducing averagebin usage from 16 to 15 bins while improving space utilization from 0.76-0.78to 0.83. This work contributes to understanding LLM evaluation in specializeddomains and establishes benchmarks for assessing LLM performance incombinatorial optimization tasks.</description><author>Syed Mahbubul Huq, Daniel Brito, Daniel Sikar, Chris Child, Tillman Weyde, Rajesh Mojumder</author><pubDate>Wed, 01 Oct 2025 14:33:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22255v2</guid></item><item><title>The Inhibitor: ReLU and Addition-Based Attention for Efficient Transformers under Fully Homomorphic Encryption on the Torus</title><link>http://arxiv.org/abs/2310.02041v2</link><description>To enhance the computational efficiency of quantized Transformers, we replacethe dot-product and Softmax-based attention with an alternative mechanisminvolving addition and ReLU activation only. This side-steps the expansion todouble precision often required by matrix multiplication and avoids costlySoftmax evaluations but maintains much of the core functionality ofconventional dot-product attention. It can enable more efficient execution andsupport larger quantized Transformer models on resource-constrained hardware oralternative arithmetic systems like homomorphic encryption. Trainingexperiments on four common benchmark tasks show test set prediction scorescomparable to those of conventional Transformers with dot-product attention.Our scaling experiments also suggest significant computational savings, both inplaintext and under encryption. In particular, we believe that the ReLU andaddition-based attention mechanism examined in this paper may enableprivacy-preserving AI applications operating under homomorphic encryption byavoiding the costly multiplication of encrypted variables.</description><author>Rickard Brännvall, Andrei Stoian</author><pubDate>Wed, 01 Oct 2025 14:31:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02041v2</guid></item><item><title>Steering When Necessary: Flexible Steering Large Language Models with Backtracking</title><link>http://arxiv.org/abs/2508.17621v2</link><description>Large language models (LLMs) have achieved remarkable performance across manygeneration tasks. Nevertheless, effectively aligning them with desiredbehaviors remains a significant challenge. Activation steering is an effectiveand cost-efficient approach that directly modifies the activations of LLMsduring the inference stage, aligning their responses with the desired behaviorsand avoiding the high cost of fine-tuning. Existing methods typicallyindiscriminately intervene to all generations or rely solely on the question todetermine intervention, which limits the accurate assessment of theintervention strength. To this end, we propose the Flexible Activation Steeringwith Backtracking (FASB) framework, which dynamically determines both thenecessity and strength of intervention by tracking the internal states of theLLMs during generation, considering both the question and the generatedcontent. Since intervening after detecting a deviation from the desiredbehavior is often too late, we further propose the backtracking mechanism tocorrect the deviated tokens and steer the LLMs toward the desired behavior.Extensive experiments on the TruthfulQA dataset and six multiple-choicedatasets demonstrate that our method outperforms baselines. Our code will bereleased at https://github.com/gjw185/FASB.</description><author>Zifeng Cheng, Jinwei Gan, Zhiwei Jiang, Cong Wang, Yafeng Yin, Xiang Luo, Yuchen Fu, Qing Gu</author><pubDate>Wed, 01 Oct 2025 14:31:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.17621v2</guid></item><item><title>Neural Logic Networks for Interpretable Classification</title><link>http://arxiv.org/abs/2508.08172v4</link><description>Traditional neural networks have an impressive classification performance,but what they learn cannot be inspected, verified or extracted. Neural LogicNetworks on the other hand have an interpretable structure that enables them tolearn a logical mechanism relating the inputs and outputs with AND and ORoperations. We generalize these networks with NOT operations and biases thattake into account unobserved data and develop a rigorous logical andprobabilistic modeling in terms of concept combinations to motivate their use.We also propose a novel factorized IF-THEN rule structure for the model as wellas a modified learning algorithm. Our method improves the state-of-the-art inBoolean networks discovery and is able to learn relevant, interpretable rulesin tabular classification, notably on examples from the medical and industrialfields where interpretability has tangible value.</description><author>Vincent Perreault, Katsumi Inoue, Richard Labib, Alain Hertz</author><pubDate>Wed, 01 Oct 2025 14:26:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.08172v4</guid></item><item><title>Direct Preference Optimization for Adaptive Concept-based Explanations</title><link>http://arxiv.org/abs/2505.15626v2</link><description>Concept-based explanation methods aim at making machine learning models moretransparent by finding the most important semantic features of an input (e.g.,colors, patterns, shapes) for a given prediction task. However, these methodsgenerally ignore the communicative context of explanations, such as thepreferences of a listener. For example, medical doctors understand explanationsin terms of clinical markers, but patients may not, needing a differentvocabulary to rationalize the same diagnosis. We address this gap withlistener-adaptive explanations grounded in principles of pragmatic reasoningand the rational speech act. We introduce an iterative training procedure basedon direct preference optimization where a speaker learns to composeexplanations that maximize communicative utility for a listener. Our approachonly needs access to pairwise preferences, which can be collected from humanfeedback, making it particularly relevant in real-world scenarios where a modelof the listener may not be available. We demonstrate that our method is able toalign speakers with the preferences of simulated listeners on imageclassification across three datasets, and further validate that pragmaticexplanations generated with our method improve the classification accuracy ofparticipants in a user study.</description><author>Jacopo Teneggi, Zhenzhen Wang, Paul H. Yi, Tianmin Shu, Jeremias Sulam</author><pubDate>Wed, 01 Oct 2025 14:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15626v2</guid></item><item><title>Metaphor identification using large language models: A comparison of RAG, prompt engineering, and fine-tuning</title><link>http://arxiv.org/abs/2509.24866v2</link><description>Metaphor is a pervasive feature of discourse and a powerful lens forexamining cognition, emotion, and ideology. Large-scale analysis, however, hasbeen constrained by the need for manual annotation due to the context-sensitivenature of metaphor. This study investigates the potential of large languagemodels (LLMs) to automate metaphor identification in full texts. We comparethree methods: (i) retrieval-augmented generation (RAG), where the model isprovided with a codebook and instructed to annotate texts based on its rulesand examples; (ii) prompt engineering, where we design task-specific verbalinstructions; and (iii) fine-tuning, where the model is trained on hand-codedtexts to optimize performance. Within prompt engineering, we test zero-shot,few-shot, and chain-of-thought strategies. Our results show thatstate-of-the-art closed-source LLMs can achieve high accuracy, with fine-tuningyielding a median F1 score of 0.79. A comparison of human and LLM outputsreveals that most discrepancies are systematic, reflecting well-known greyareas and conceptual challenges in metaphor theory. We propose that LLMs can beused to at least partly automate metaphor identification and can serve as atestbed for developing and refining metaphor identification protocols and thetheory that underpins them.</description><author>Matteo Fuoli, Weihang Huang, Jeannette Littlemore, Sarah Turner, Ellen Wilding</author><pubDate>Wed, 01 Oct 2025 14:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24866v2</guid></item><item><title>Fingerprinting LLMs via Prompt Injection</title><link>http://arxiv.org/abs/2509.25448v2</link><description>Large language models (LLMs) are often modified after release throughpost-processing such as post-training or quantization, which makes itchallenging to determine whether one model is derived from another. Existingprovenance detection methods have two main limitations: (1) they embed signalsinto the base model before release, which is infeasible for already publishedmodels, or (2) they compare outputs across models using hand-crafted or randomprompts, which are not robust to post-processing. In this work, we proposeLLMPrint, a novel detection framework that constructs fingerprints byexploiting LLMs' inherent vulnerability to prompt injection. Our key insight isthat by optimizing fingerprint prompts to enforce consistent token preferences,we can obtain fingerprints that are both unique to the base model and robust topost-processing. We further develop a unified verification procedure thatapplies to both gray-box and black-box settings, with statistical guarantees.We evaluate LLMPrint on five base models and around 700 post-trained orquantized variants. Our results show that LLMPrint achieves high true positiverates while keeping false positive rates near zero.</description><author>Yuepeng Hu, Zhengyuan Jiang, Mengyuan Li, Osama Ahmed, Zhicong Huang, Cheng Hong, Neil Gong</author><pubDate>Wed, 01 Oct 2025 14:04:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25448v2</guid></item><item><title>AS400-DET: Detection using Deep Learning Model for IBM i (AS/400)</title><link>http://arxiv.org/abs/2506.13032v2</link><description>This paper proposes a method for automatic GUI component detection for theIBM i system (formerly and still more commonly known as AS/400). We introduce ahuman-annotated dataset consisting of 1,050 system screen images, in which 381images are screenshots of IBM i system screens in Japanese. Each image containsmultiple components, including text labels, text boxes, options, tables,instructions, keyboards, and command lines. We then develop a detection systembased on state-of-the-art deep learning models and evaluate differentapproaches using our dataset. The experimental results demonstrate theeffectiveness of our dataset in constructing a system for component detectionfrom GUI screens. By automatically detecting GUI components from the screen,AS400-DET has the potential to perform automated testing on systems thatoperate via GUI screens.</description><author>Thanh Tran, Son T. Luu, Quan Bui, Shoshin Nomura</author><pubDate>Wed, 01 Oct 2025 14:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.13032v2</guid></item><item><title>Learning Dynamic Graph Embeddings with Neural Controlled Differential Equations</title><link>http://arxiv.org/abs/2302.11354v2</link><description>This paper focuses on representation learning for dynamic graphs withtemporal interactions. A fundamental issue is that both the graph structure andthe nodes own their own dynamics, and their blending induces intractablecomplexity in the temporal evolution over graphs. Drawing inspiration from therecent progress of physical dynamic models in deep neural networks, we proposeGraph Neural Controlled Differential Equations (GN-CDEs), a continuous-timeframework that jointly models node embeddings and structural dynamics byincorporating a graph enhanced neural network vector field with a time-varyinggraph path as the control signal. Our framework exhibits several desirablecharacteristics, including the ability to express dynamics on evolving graphswithout piecewise integration, the capability to calibrate trajectories withsubsequent data, and robustness to missing observations. Empirical evaluationon a range of dynamic graph representation learning tasks demonstrates theeffectiveness of our proposed approach in capturing the complex dynamics ofdynamic graphs.</description><author>Tiexin Qin, Benjamin Walker, Terry Lyons, Hong Yan, Haoliang Li</author><pubDate>Wed, 01 Oct 2025 14:00:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11354v2</guid></item><item><title>Semi-Supervised Unconstrained Head Pose Estimation in the Wild</title><link>http://arxiv.org/abs/2404.02544v4</link><description>Existing research on unconstrained in-the-wild head pose estimation suffersfrom the flaws of its datasets, which consist of either numerous samples bynon-realistic synthesis or constrained collection, or small-scale naturalimages yet with plausible manual annotations. This makes fully-supervisedsolutions compromised due to the reliance on generous labels. To alleviate it,we propose the first semi-supervised unconstrained head pose estimation methodSemiUHPE, which can leverage abundant easily available unlabeled head images.Technically, we choose semi-supervised rotation regression and adapt it to theerror-sensitive and label-scarce problem of unconstrained head pose. Our methodis based on the observation that the aspect-ratio invariant cropping of wildheads is superior to previous landmark-based affine alignment given thatlandmarks of unconstrained human heads are usually unavailable, especially forunderexplored non-frontal heads. Instead of using a pre-fixed threshold tofilter out pseudo labeled heads, we propose dynamic entropy based filtering toadaptively remove unlabeled outliers as training progresses by updating thethreshold in multiple stages. We then revisit the design of weak-strongaugmentations and improve it by devising two novel head-oriented strongaugmentations, termed pose-irrelevant cut-occlusion and pose-altering rotationconsistency respectively. Extensive experiments and ablation studies show thatSemiUHPE outperforms its counterparts greatly on public benchmarks under boththe front-range and full-range settings. Furthermore, our proposed method isalso beneficial for solving other closely related problems, including genericobject rotation regression and 3D head reconstruction, demonstrating goodversatility and extensibility. Code is in https://github.com/hnuzhy/SemiUHPE.</description><author>Huayi Zhou, Fei Jiang, Jin Yuan, Yong Rui, Hongtao Lu, Kui Jia</author><pubDate>Wed, 01 Oct 2025 13:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02544v4</guid></item><item><title>Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments</title><link>http://arxiv.org/abs/2509.22319v2</link><description>Deep learning models have become increasingly large and complex, resulting inhigher memory consumption and computational demands. Consequently, modelloading times and initial inference latency have increased, posing significantchallenges in mobile and latency-sensitive environments where frequent modelloading and unloading are required, which directly impacts user experience.While Knowledge Distillation (KD) offers a solution by compressing largeteacher models into smaller student ones, it often comes at the cost of reducedperformance. To address this trade-off, we propose Progressive Weight Loading(PWL), a novel technique that enables fast initial inference by first deployinga lightweight student model, then incrementally replacing its layers with thoseof a pre-trained teacher model. To support seamless layer substitution, weintroduce a training method that not only aligns intermediate featurerepresentations between student and teacher layers, but also improves theoverall output performance of the student model. Our experiments on VGG,ResNet, and ViT architectures demonstrate that models trained with PWL maintaincompetitive distillation performance and gradually improve accuracy as teacherlayers are loaded-matching the final accuracy of the full teacher model withoutcompromising initial inference speed. This makes PWL particularly suited fordynamic, resource-constrained deployments where both responsiveness andperformance are critical.</description><author>Hyunwoo Kim, Junha Lee, Mincheol Choi, Jeonghwan Lee, Jaeshin Cho</author><pubDate>Wed, 01 Oct 2025 13:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22319v2</guid></item><item><title>Learning Frequency and Memory-Aware Prompts for Multi-Modal Object Tracking</title><link>http://arxiv.org/abs/2506.23972v2</link><description>Prompt-learning-based multi-modal trackers have made strong progress by usinglightweight visual adapters to inject auxiliary-modality cues into frozenfoundation models. However, they still underutilize two essentials:modality-specific frequency structure and long-range temporal dependencies. Wepresent Learning Frequency and Memory-Aware Prompts, a dual-adapter frameworkthat injects lightweight prompts into a frozen RGB tracker. A frequency-guidedvisual adapter adaptively transfers complementary cues across modalities byjointly calibrating spatial, channel, and frequency components, narrowing themodality gap without full fine-tuning. A multilevel memory adapter with short,long, and permanent memory stores, updates, and retrieves reliable temporalcontext, enabling consistent propagation across frames and robust recovery fromocclusion, motion blur, and illumination changes. This unified design preservesthe efficiency of prompt learning while strengthening cross-modal interactionand temporal coherence. Extensive experiments on RGB-Thermal, RGB-Depth, andRGB-Event benchmarks show consistent state-of-the-art results over fullyfine-tuned and adapter-based baselines, together with favorable parameterefficiency and runtime. Code and models are available athttps://github.com/xuboyue1999/mmtrack.git.</description><author>Boyue Xu, Ruichao Hou, Tongwei Ren, Dongming zhou, Gangshan Wu, Jinde Cao</author><pubDate>Wed, 01 Oct 2025 13:52:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.23972v2</guid></item><item><title>Image-Difficulty-Aware Evaluation of Super-Resolution Models</title><link>http://arxiv.org/abs/2509.26398v2</link><description>Image super-resolution models are commonly evaluated by average scores (oversome benchmark test sets), which fail to reflect the performance of thesemodels on images of varying difficulty and that some models generate artifactson certain difficult images, which is not reflected by the average scores. Wepropose difficulty-aware performance evaluation procedures to betterdifferentiate between SISR models that produce visually different results onsome images but yield close average performance scores over the entire testset. In particular, we propose two image-difficulty measures, thehigh-frequency index and rotation-invariant edge index, to predict those testimages, where a model would yield significantly better visual results overanother model, and an evaluation method where these visual differences arereflected on objective measures. Experimental results demonstrate theeffectiveness of the proposed image-difficulty measures and evaluationmethodology.</description><author>Atakan Topaloglu, Ahmet Bilican, Cansu Korkmaz, A. Murat Tekalp</author><pubDate>Wed, 01 Oct 2025 13:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26398v2</guid></item><item><title>PSScreen: Partially Supervised Multiple Retinal Disease Screening</title><link>http://arxiv.org/abs/2508.10549v3</link><description>Leveraging multiple partially labeled datasets to train a model for multipleretinal disease screening reduces the reliance on fully annotated datasets, butremains challenging due to significant domain shifts across training datasetsfrom various medical sites, and the label absent issue for partial classes. Tosolve these challenges, we propose PSScreen, a novel Partially Supervisedmultiple retinal disease Screening model. Our PSScreen consists of two streamsand one learns deterministic features and the other learns probabilisticfeatures via uncertainty injection. Then, we leverage the textual guidance todecouple two types of features into disease-wise features and align them viafeature distillation to boost the domain generalization ability. Meanwhile, weemploy pseudo label consistency between two streams to address the label absentissue and introduce a self-distillation to transfer task-relevant semanticsabout known classes from the deterministic to the probabilistic stream tofurther enhance the detection performances. Experiments show that our PSScreensignificantly enhances the detection performances on six retinal diseases andthe normal state averagely and achieves state-of-the-art results on bothin-domain and out-of-domain datasets. Codes are available athttps://github.com/boyiZheng99/PSScreen.</description><author>Boyi Zheng, Qing Liu</author><pubDate>Wed, 01 Oct 2025 13:38:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.10549v3</guid></item><item><title>Streamline pathology foundation model by cross-magnification distillation</title><link>http://arxiv.org/abs/2509.23097v2</link><description>Foundation models (FM) have transformed computational pathology but remaincomputationally prohibitive for clinical deployment due to their massiveparameter counts and high-magnification processing requirements. Here, weintroduce XMAG, a lightweight FM developed through corss-magnificationdistillation that transfers knowledge from state-of-the-art 20x magnificationteacher to an efficient 5x magnification student architecture. XMAG employs acompact backbone and operates entirely at 5x, requiring 11.3 times fewerpatches per whole slide image (WSI) compared to existing approaches. Our Noveldistillation framework incorporates dual-level knowledge transfer, aligningboth global image representations and local spatial token mapping. We trainedXMAG on 3.49 million images curated from publicly available datasets andevaluated performance across six clinically relevant histopathology analysistasks spanning multiple cancer types. XMAG achieved diagnostic accuracy within1% of substantially larger foundation models while delivering 30-foldprocessing acceleration, reaching 8.8 WSIs per minute processing speed. Ourcross-institutional validation confirmed robust generalization. Further, wedeveloped an end-to-end training strategy to further boost our model'sperformance to approach the larger FMs' performance. These results establishcross-magnification distillation as a viable approach for deploying FMcapabilities in resource-constrained clinical environments, potentiallyenabling real-time pathology AI integration.</description><author>Ziyu Su, Abdul Rehman Akbar, Usama Sajjad, Anil V. Parwani, Muhammad Khalid Khan Niazi</author><pubDate>Wed, 01 Oct 2025 13:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23097v2</guid></item><item><title>Temporal Misalignment Attacks against Multimodal Perception in Autonomous Driving</title><link>http://arxiv.org/abs/2507.09095v2</link><description>Multimodal fusion (MMF) plays a critical role in the perception of autonomousdriving, which primarily fuses camera and LiDAR streams for a comprehensive andefficient scene understanding. However, its strict reliance on precise temporalsynchronization exposes it to new vulnerabilities. In this paper, we introduceDejaVu, an attack that exploits the in-vehicular network and induces delaysacross sensor streams to create subtle temporal misalignments, severelydegrading downstream MMF-based perception tasks. Our comprehensive attackanalysis across different models and datasets reveals the sensors'task-specific imbalanced sensitivities: object detection is overly dependent onLiDAR inputs, while object tracking is highly reliant on the camera inputs.Consequently, with a single-frame LiDAR delay, an attacker can reduce the cardetection mAP by up to 88.5%, while with a three-frame camera delay, multipleobject tracking accuracy (MOTA) for car drops by 73%. We further demonstratedtwo attack scenarios using an automotive Ethernet testbed forhardware-in-the-loop validation and the Autoware stack for end-to-end ADsimulation, demonstrating the feasibility of the DejaVu attack and its severeimpact, such as collisions and phantom braking.</description><author>Md Hasan Shahriar, Md Mohaimin Al Barat, Harshavardhan Sundar, Ning Zhang, Naren Ramakrishnan, Y. Thomas Hou, Wenjing Lou</author><pubDate>Wed, 01 Oct 2025 13:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.09095v2</guid></item><item><title>The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane Algorithm</title><link>http://arxiv.org/abs/2507.18553v2</link><description>Quantizing the weights of large language models (LLMs) from 16-bit to lowerbitwidth is the de facto approach to deploy massive transformers onto moreaffordable accelerators. While GPTQ emerged as one of the standard methods forone-shot post-training quantization at LLM scale, its inner workings aredescribed as a sequence of ad-hoc algebraic updates that obscure geometricmeaning or worst-case guarantees. In this work, we show that, when executedback-to-front (from the last to first dimension) for a linear layer, GPTQ ismathematically identical to Babai's nearest plane algorithm for the classicalclosest vector problem (CVP) on a lattice defined by the Hessian matrix of thelayer's inputs. This equivalence is based on a sophisticated mathematicalargument, and has two analytical consequences: first, the GPTQ errorpropagation step gains an intuitive geometric interpretation; second, GPTQinherits the error upper bound of Babai's algorithm under the assumption thatno weights are clipped. Leveraging this bound, we design post-trainingquantization methods that avoid clipping, and outperform the original GPTQ. Inaddition, we provide efficient GPU inference kernels for the resultingrepresentation. Taken together, these results place GPTQ on a firm theoreticalfooting and open the door to importing decades of progress in latticealgorithms towards the design of future quantization algorithms forbillion-parameter models.</description><author>Jiale Chen, Yalda Shabanzadeh, Elvir Crnčević, Torsten Hoefler, Dan Alistarh</author><pubDate>Wed, 01 Oct 2025 13:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.18553v2</guid></item><item><title>Addressing Moral Uncertainty using Large Language Models for Ethical Decision-Making</title><link>http://arxiv.org/abs/2503.05724v2</link><description>We present an ethical decision-making framework that refines a pre-trainedreinforcement learning (RL) model using a task-agnostic ethical layer.Following initial training, the RL model undergoes ethical fine-tuning, wherehuman feedback is replaced by feedback generated from a large language model(LLM). The LLM embodies consequentialist, deontological, virtue, socialjustice, and care ethics as moral principles to assign belief values torecommended actions during ethical decision-making. An ethical layer aggregatesbelief scores from multiple LLM-derived moral perspectives using BeliefJensen-Shannon Divergence and Dempster-Shafer Theory into probability scoresthat also serve as the shaping reward, steering the agent toward choices thatalign with a balanced ethical framework. This integrated learning frameworkhelps the RL agent navigate moral uncertainty in complex environments andenables it to make morally sound decisions across diverse tasks. Our approach,tested across different LLM variants and compared with other belief aggregationtechniques, demonstrates improved consistency, adaptability, and reducedreliance on handcrafted ethical rewards. This method is especially effective indynamic scenarios where ethical challenges arise unexpectedly, making itwell-suited for real-world applications.</description><author>Rohit K. Dubey, Damian Dailisan, Sachit Mahajan</author><pubDate>Wed, 01 Oct 2025 13:23:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.05724v2</guid></item><item><title>PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation</title><link>http://arxiv.org/abs/2412.07754v2</link><description>Audio-driven talking face generation is a challenging task in digitalcommunication. Despite significant progress in the area, most existing methodsconcentrate on audio-lip synchronization, often overlooking aspects such asvisual quality, customization, and generalization that are crucial to producingrealistic talking faces. To address these limitations, we introduce a novel,customizable one-shot audio-driven talking face generation framework, namedPortraitTalk. Our proposed method utilizes a latent diffusion frameworkconsisting of two main components: IdentityNet and AnimateNet. IdentityNet isdesigned to preserve identity features consistently across the generated videoframes, while AnimateNet aims to enhance temporal coherence and motionconsistency. This framework also integrates an audio input with the referenceimages, thereby reducing the reliance on reference-style videos prevalent inexisting approaches. A key innovation of PortraitTalk is the incorporation oftext prompts through decoupled cross-attention mechanisms, which significantlyexpands creative control over the generated videos. Through extensiveexperiments, including a newly developed evaluation metric, our modeldemonstrates superior performance over the state-of-the-art methods, setting anew standard for the generation of customizable realistic talking facessuitable for real-world applications.</description><author>Fatemeh Nazarieh, Zhenhua Feng, Diptesh Kanojia, Muhammad Awais, Josef Kittler</author><pubDate>Wed, 01 Oct 2025 13:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07754v2</guid></item><item><title>Auto-ARGUE: LLM-Based Report Generation Evaluation</title><link>http://arxiv.org/abs/2509.26184v2</link><description>Generation of long-form, citation-backed reports is a primary use case forretrieval augmented generation (RAG) systems. While open-source evaluationtools exist for various RAG tasks, ones tailored to report generation arelacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-basedimplementation of the recent ARGUE framework for report generation evaluation.We present analysis of Auto-ARGUE on the report generation pilot task from theTREC 2024 NeuCLIR track, showing good system-level correlations with humanjudgments. We further release a web app for visualization of Auto-ARGUEoutputs.</description><author>William Walden, Marc Mason, Orion Weller, Laura Dietz, Hannah Recknor, Bryan Li, Gabrielle Kaili-May Liu, Yu Hou, James Mayfield, Eugene Yang</author><pubDate>Wed, 01 Oct 2025 13:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26184v2</guid></item><item><title>Balancing Multimodal Training Through Game-Theoretic Regularization</title><link>http://arxiv.org/abs/2411.07335v3</link><description>Multimodal learning holds promise for richer information extraction bycapturing dependencies across data sources. Yet, current training methods oftenunderperform due to modality competition, a phenomenon where modalities contendfor training resources leaving some underoptimized. This raises a pivotalquestion: how can we address training imbalances, ensure adequate optimizationacross all modalities, and achieve consistent performance improvements as wetransition from unimodal to multimodal data? This paper proposes the MultimodalCompetition Regularizer (MCR), inspired by a mutual information (MI)decomposition designed to prevent the adverse effects of competition inmultimodal training. Our key contributions are: 1) A game-theoretic frameworkthat adaptively balances modality contributions by encouraging each to maximizeits informative role in the final prediction 2) Refining lower and upper boundsfor each MI term to enhance the extraction of both task-relevant unique andshared information across modalities. 3) Proposing latent space permutationsfor conditional MI estimation, significantly improving computationalefficiency. MCR outperforms all previously suggested training strategies andsimple baseline, clearly demonstrating that training modalities jointly leadsto important performance gains on both synthetic and large real-world datasets.We release our code and models at https://github.com/kkontras/MCR.</description><author>Konstantinos Kontras, Thomas Strypsteen, Christos Chatzichristos, Paul Pu Liang, Matthew Blaschko, Maarten De Vos</author><pubDate>Wed, 01 Oct 2025 13:03:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07335v3</guid></item><item><title>Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned</title><link>http://arxiv.org/abs/2509.23250v2</link><description>Process Reward Models (PRMs) provide step-level supervision that improves thereliability of reasoning in large language models. While PRMs have beenextensively studied in text-based domains, their extension to Vision LanguageModels (VLMs) remains limited. Existing Vision-Language PRMs (VL-PRMs) rely onMonte Carlo Tree Search (MCTS) for data construction, which can often producenoisy supervision signals and limit generalization across tasks. In this work,we aim to elucidate the design space of VL-PRMs by exploring diverse strategiesfor dataset construction, training, and test-time scaling. First, we introducea hybrid data synthesis framework that combines MCTS with judgments from astrong VLM, producing more accurate step-level labels. Second, we proposeperception-focused supervision, enabling our PRM to explicitly detect errors atthe visual grounding stage of reasoning. Third, we systematically evaluatemultiple test-time scaling strategies, showing that our PRMs can reliably guideVLMs toward more accurate solutions. Our experiments covering five diversemultimodal benchmarks (MMMU, PuzzleVQA, AlgoPuzzleVQA, MathVista, andMathVision) reveal several key insights: (i) VL-PRMs when used as OutcomeReward Models (ORMs) during test-time scaling (TTS) can outperform VL-PRMguided process step selection, (ii) smaller VL-PRMs can match or even surpasslarger ones in detecting process errors, (iii) VL-PRMs uncover latent reasoningabilities in stronger VLM backbones, (iv) perception-level supervision leads tosignificant gains in test-time scaling, and (v) TTS performance of differentpolicies improve on advanced math reasoning datasets despite not trainingVL-PRMs on such datasets. We hope our work will motivate further research andsupport the advancement of VLMs.</description><author>Brandon Ong, Tej Deep Pala, Vernon Toh, William Chandra Tjhi, Soujanya Poria</author><pubDate>Wed, 01 Oct 2025 12:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23250v2</guid></item><item><title>ViLBias: Detecting and Reasoning about Bias in Multimodal Content</title><link>http://arxiv.org/abs/2412.17052v4</link><description>Detecting bias in multimodal news requires models that reason overtext--image pairs, not just classify text. In response, we present ViLBias, aVQA-style benchmark and framework for detecting and reasoning about bias inmultimodal news. The dataset comprises 40,945 text--image pairs from diverseoutlets, each annotated with a bias label and concise rationale using atwo-stage LLM-as-annotator pipeline with hierarchical majority voting andhuman-in-the-loop validation. We evaluate Small Language Models (SLMs), LargeLanguage Models (LLMs), and Vision--Language Models (VLMs) across closed-endedclassification and open-ended reasoning (oVQA), and compare parameter-efficienttuning strategies. Results show that incorporating images alongside textimproves detection accuracy by 3--5\%, and that LLMs/VLMs better capture subtleframing and text--image inconsistencies than SLMs. Parameter-efficient methods(LoRA/QLoRA/Adapters) recover 97--99\% of full fine-tuning performance with$&lt;5\%$ trainable parameters. For oVQA, reasoning accuracy spans 52--79\% andfaithfulness 68--89\%, both improved by instruction tuning; closed accuracycorrelates strongly with reasoning ($r = 0.91$). ViLBias offers a scalablebenchmark and strong baselines for multimodal bias detection and rationalequality.</description><author>Shaina Raza, Caesar Saleh, Azib Farooq, Emrul Hasan, Franklin Ogidi, Maximus Powers, Veronica Chatrath, Marcelo Lotif, Karanpal Sekhon, Roya Javadi, Haad Zahid, Anam Zahid, Vahid Reza Khazaie, Zhenyu Yu</author><pubDate>Wed, 01 Oct 2025 12:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17052v4</guid></item><item><title>CYCle: Choosing Your Collaborators Wisely to Enhance Collaborative Fairness in Decentralized Learning</title><link>http://arxiv.org/abs/2501.12344v2</link><description>Collaborative learning (CL) enables multiple participants to jointly trainmachine learning (ML) models on decentralized data sources without raw datasharing. While the primary goal of CL is to maximize the expected accuracy gainfor each participant, it is also important to ensure that the gains are fairlydistributed: no client should be negatively impacted, and gains should reflectcontributions. Most existing CL methods require central coordination and focusonly on gain maximization, overlooking fairness. In this work, we first showthat the existing measure of collaborative fairness based on the correlationbetween accuracy values without and with collaboration has drawbacks because itdoes not account for negative collaboration gain. We argue that maximizing meancollaboration gain (MCG) while simultaneously minimizing the collaboration gainspread (CGS) is a fairer alternative. Next, we propose the CYCle protocol thatenables individual participants in a private decentralized learning (PDL)framework to achieve this objective through a novel reputation scoring methodbased on gradient alignment between the local cross-entropy and distillationlosses. We further extend the CYCle protocol to operate on top of gossip-baseddecentralized algorithms such as Gossip-SGD. We also theoretically show thatCYCle performs better than standard FedAvg in a two-client mean estimationsetting under high heterogeneity. Empirical experiments demonstrate theeffectiveness of the CYCle protocol to ensure positive and fair collaborationgain for all participants, even in cases where the data distributions ofparticipants are highly skewed.</description><author>Nurbek Tastan, Samuel Horvath, Karthik Nandakumar</author><pubDate>Wed, 01 Oct 2025 12:42:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12344v2</guid></item><item><title>Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset</title><link>http://arxiv.org/abs/2509.20715v3</link><description>Intention recognition has traditionally focused on individual intentions,overlooking the complexities of collective intentions in group settings. Toaddress this limitation, we introduce the concept of group intention, whichrepresents shared goals emerging through the actions of multiple individuals,and Group Intention Forecasting (GIF), a novel task that forecasts when groupintentions will occur by analyzing individual actions and interactions beforethe collective goal becomes apparent. To investigate GIF in a specificscenario, we propose SHOT, the first large-scale dataset for GIF, consisting of1,979 basketball video clips captured from 5 camera views and annotated with 6types of individual attributes. SHOT is designed with 3 key characteristics:multi-individual information, multi-view adaptability, and multi-levelintention, making it well-suited for studying emerging group intentions.Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework thatextracts fine-grained individual features and models evolving group dynamics toforecast intention emergence. Experimental results confirm the effectiveness ofSHOT and GIFT, establishing a strong foundation for future research in groupintention forecasting. The dataset is available athttps://xinyi-hu.github.io/SHOT_DATASET.</description><author>Ruixu Zhang, Yuran Wang, Xinyi Hu, Chaoyu Mai, Wenxuan Liu, Danni Xu, Xian Zhong, Zheng Wang</author><pubDate>Wed, 01 Oct 2025 12:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20715v3</guid></item><item><title>Deep Learning for Subspace Regression</title><link>http://arxiv.org/abs/2509.23249v2</link><description>It is often possible to perform reduced order modelling by specifying linearsubspace which accurately captures the dynamics of the system. This approachbecomes especially appealing when linear subspace explicitly depends onparameters of the problem. A practical way to apply such a scheme is to computesubspaces for a selected set of parameters in the computationally demandingoffline stage and in the online stage approximate subspace for unknownparameters by interpolation. For realistic problems the space of parameters ishigh dimensional, which renders classical interpolation strategies infeasibleor unreliable. We propose to relax the interpolation problem to regression,introduce several loss functions suitable for subspace data, and use a neuralnetwork as an approximation to high-dimensional target function. To furthersimplify a learning problem we introduce redundancy: in place of predictingsubspace of a given dimension we predict larger subspace. We show theoreticallythat this strategy decreases the complexity of the mapping for ellipticeigenproblems with constant coefficients and makes the mapping smoother forgeneral smooth function on the Grassmann manifold. Empirical results also showthat accuracy significantly improves when larger-than-needed subspaces arepredicted. With the set of numerical illustrations we demonstrate that subspaceregression can be useful for a range of tasks including parametriceigenproblems, deflation techniques, relaxation methods, optimal control andsolution of parametric partial differential equations.</description><author>Vladimir Fanaskov, Vladislav Trifonov, Alexander Rudikov, Ekaterina Muravleva, Ivan Oseledets</author><pubDate>Wed, 01 Oct 2025 12:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23249v2</guid></item><item><title>Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes</title><link>http://arxiv.org/abs/2501.08521v3</link><description>Federated Learning (FL) has emerged as a decentralized machine learningtechnique, allowing clients to train a global model collaboratively withoutsharing private data. However, most FL studies ignore the crucial challenge ofheterogeneous domains where each client has a distinct feature distribution,which is popular in real-world scenarios. Prototype learning, which leveragesthe mean feature vectors within the same classes, has become a prominentsolution for federated learning under domain shift. However, existing federatedprototype learning methods focus soley on inter-domain prototypes and neglectintra-domain perspectives. In this work, we introduce a novel federatedprototype learning method, namely I$^2$PFL, which incorporates$\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, tomitigate domain shift from both perspectives and learn a generalized globalmodel across multiple domains in federated learning. To construct intra-domainprototypes, we propose feature alignment with MixUp-based augmented prototypesto capture the diversity within local domains and enhance the generalization oflocal features. Additionally, we introduce a reweighting mechanism forinter-domain prototypes to generate generalized prototypes that reduce domainshift while providing inter-domain knowledge across multiple clients. Extensiveexperiments on the Digits, Office-10, and PACS datasets illustrate the superiorperformance of our method compared to other baselines.</description><author>Huy Q. Le, Ye Lin Tun, Yu Qiao, Minh N. H. Nguyen, Keon Oh Kim, Eui-Nam Huh, Choong Seon Hong</author><pubDate>Wed, 01 Oct 2025 12:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08521v3</guid></item><item><title>CultranAI at PalmX 2025: Data Augmentation for Cultural Knowledge Representation</title><link>http://arxiv.org/abs/2508.17324v2</link><description>In this paper, we report our participation to the PalmX cultural evaluationshared task. Our system, CultranAI, focused on data augmentation and LoRAfine-tuning of large language models (LLMs) for Arabic cultural knowledgerepresentation. We benchmarked several LLMs to identify the best-performingmodel for the task. In addition to utilizing the PalmX dataset, we augmented itby incorporating the Palm dataset and curated a new dataset of over 22Kculturally grounded multiple-choice questions (MCQs). Our experiments showedthat the Fanar-1-9B-Instruct model achieved the highest performance. Wefine-tuned this model on the combined augmented dataset of 22K+ MCQs. On theblind test set, our submitted system ranked 5th with an accuracy of 70.50%,while on the PalmX development set, it achieved an accuracy of 84.1%.</description><author>Hunzalah Hassan Bhatti, Youssef Ahmed, Md Arid Hasan, Firoj Alam</author><pubDate>Wed, 01 Oct 2025 12:29:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.17324v2</guid></item><item><title>Post Hoc Regression Refinement via Pairwise Rankings</title><link>http://arxiv.org/abs/2508.16495v2</link><description>Accurate prediction of continuous properties is essential to many scientificand engineering tasks. Although deep-learning regressors excel with abundantlabels, their accuracy deteriorates in data-scarce regimes. We introduceRankRefine, a model-agnostic, plug-and-play post hoc method that refinesregression with expert knowledge coming from pairwise rankings. Given a queryitem and a small reference set with known properties, RankRefine combines thebase regressor's output with a rank-based estimate via inverse varianceweighting, requiring no retraining. In molecular property prediction task,RankRefine achieves up to 10% relative reduction in mean absolute error usingonly 20 pairwise comparisons obtained through a general-purpose large languagemodel (LLM) with no finetuning. As rankings provided by human experts orgeneral-purpose LLMs are sufficient for improving regression across diversedomains, RankRefine offers practicality and broad applicability, especially inlow-data settings.</description><author>Kevin Tirta Wijaya, Michael Sun, Minghao Guo, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei</author><pubDate>Wed, 01 Oct 2025 12:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16495v2</guid></item><item><title>PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection</title><link>http://arxiv.org/abs/2509.26272v2</link><description>The rapid rise of synthetic media has made deepfake detection a criticalchallenge for online safety and trust. Progress remains constrained by thescarcity of large, high-quality datasets. Although multimodal large languagemodels (LLMs) exhibit strong reasoning capabilities, their performance ondeepfake detection is poor, often producing explanations that are misalignedwith visual evidence or hallucinatory. To address this limitation, we introducea reasoning-annotated dataset for deepfake detection and proposeParagraph-level Relative Policy Optimization (PRPO), a reinforcement learningalgorithm that aligns LLM reasoning with image content at the paragraph level.Experiments show that PRPO improves detection accuracy by a wide margin andachieves the highest reasoning score of 4.55/5.0. Ablation studies furtherdemonstrate that PRPO significantly outperforms GRPO under test-timeconditions. These results underscore the importance of grounding multimodalreasoning in visual evidence to enable more reliable and interpretable deepfakedetection.</description><author>Tuan Nguyen, Naseem Khan, Khang Tran, NhatHai Phan, Issa Khalil</author><pubDate>Wed, 01 Oct 2025 12:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.26272v2</guid></item><item><title>VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes</title><link>http://arxiv.org/abs/2509.25339v2</link><description>Is basic visual understanding really solved in state-of-the-art VLMs? Wepresent VisualOverload, a slightly different visual question answering (VQA)benchmark comprising 2,720 question-answer pairs, with privately heldground-truth responses. Unlike prior VQA datasets that typically focus on nearglobal image understanding, VisualOverload challenges models to perform simple,knowledge-free vision tasks in densely populated (or, overloaded) scenes. Ourdataset consists of high-resolution scans of public-domain paintings that arepopulated with multiple figures, actions, and unfolding subplots set againstelaborately detailed backdrops. We manually annotated these images withquestions across six task categories to probe for a thorough understanding ofthe scene. We hypothesize that current benchmarks overestimate the performanceof VLMs, and encoding and reasoning over details is still a challenging taskfor them, especially if they are confronted with densely populated scenes.Indeed, we observe that even the best model (o3) out of 37 tested models onlyachieves 19.6% accuracy on our hardest test split and overall 69.5% accuracy onall questions. Beyond a thorough evaluation, we complement our benchmark withan error analysis that reveals multiple failure modes, including a lack ofcounting skills, failure in OCR, and striking logical inconsistencies undercomplex tasks. Altogether, VisualOverload exposes a critical gap in currentvision models and offers a crucial resource for the community to develop bettermodels. Benchmark: http://paulgavrikov.github.io/visualoverload</description><author>Paul Gavrikov, Wei Lin, M. Jehanzeb Mirza, Soumya Jahagirdar, Muhammad Huzaifa, Sivan Doveh, Serena Yeung-Levy, James Glass, Hilde Kuehne</author><pubDate>Wed, 01 Oct 2025 12:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25339v2</guid></item><item><title>Rapid training of Hamiltonian graph networks using random features</title><link>http://arxiv.org/abs/2506.06558v2</link><description>Learning dynamical systems that respect physical symmetries and constraintsremains a fundamental challenge in data-driven modeling. Integrating physicallaws with graph neural networks facilitates principled modeling of complexN-body dynamics and yields accurate and permutation-invariant models. However,training graph neural networks with iterative, gradient-based optimizationalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,especially for large, complex systems. In comparison to 15 differentoptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trainedup to 600x faster--but with comparable accuracy--by replacing iterativeoptimization with random feature-based parameter construction. We show robustperformance in diverse simulations, including N-body mass-spring and molecularsystems in up to 3 dimensions and 10,000 particles with different geometries,while retaining essential physical invariances with respect to permutation,rotation, and translation. Our proposed approach is benchmarked using a NeurIPS2022 Datasets and Benchmarks Track publication to further demonstrate itsversatility. We reveal that even when trained on minimal 8-node systems, themodel can generalize in a zero-shot manner to systems as large as 4096 nodeswithout retraining. Our work challenges the dominance of iterativegradient-descent-based optimization algorithms for training neural networkmodels for physical systems.</description><author>Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich</author><pubDate>Wed, 01 Oct 2025 12:14:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.06558v2</guid></item><item><title>Learning Hierarchical Domain Models Through Environment-Grounded Interaction</title><link>http://arxiv.org/abs/2505.13497v3</link><description>Domain models enable autonomous agents to solve long-horizon tasks byproducing interpretable plans. However, in open-world environments, a singlegeneral domain model cannot capture the variety of tasks, so agents mustgenerate suitable task-specific models on the fly. Large Language Models(LLMs), with their implicit common knowledge, can generate such domains, butsuffer from high error rates that limit their applicability. Hence, relatedwork relies on extensive human feed-back or prior knowledge, which underminesautonomous, open-world deployment. In this work, we propose LODGE, a frameworkfor autonomous domain learning from LLMs and environment grounding. LODGEbuilds on hierarchical abstractions and automated simulations to identify andcorrect inconsistencies between abstraction layers and between the model andenvironment. Our framework is task-agnostic, as it generates predicates,operators, and their preconditions and effects, while only assuming access to asimulator and a set of generic, executable low-level skills. Experiments on twoInternational Planning Competition ( IPC) domains and a robotic assembly domainshow that LODGE yields more accurate domain models and higher task success thanexisting methods, requiring remarkably few environment interactions and nohuman feedback or demonstrations.</description><author>Claudius Kienle, Benjamin Alt, Oleg Arenz, Jan Peters</author><pubDate>Wed, 01 Oct 2025 12:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.13497v3</guid></item><item><title>What if Othello-Playing Language Models Could See?</title><link>http://arxiv.org/abs/2507.14520v2</link><description>Language models are often said to face a symbol grounding problem. While somehave argued the problem can be solved without resort to other modalities, manyhave speculated that grounded learning is more efficient. We explore thisquestion in Othello, a simplified, rule-based world that offers a controlledand interpretable testbed for studying world understanding. Building on priorwork, we introduce VISOTHELLO, a multi-modal model trained jointly on movesequences and board images. Using the Othello rule understanding task, weexamine whether multi-modal learning provides advantages over text-onlyapproaches. We further evaluate robustness under semantically irrelevantperturbations and analyze the consistency of cross-modal alignment. Our resultssuggest that multi-modal training not only improves performance and robustnessbut also promotes convergence toward shared internal representations acrossdifferent model architectures.</description><author>Xinyi Chen, Yifei Yuan, Jiaang Li, Serge Belongie, Maarten de Rijke, Anders Søgaard</author><pubDate>Wed, 01 Oct 2025 12:00:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.14520v2</guid></item></channel></rss>