<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 13 Jun 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>No Free Lunch: The Hazards of Over-Expressive Representations in Anomaly Detection</title><link>http://arxiv.org/abs/2306.07284v1</link><description>Anomaly detection methods, powered by deep learning, have recently beenmaking significant progress, mostly due to improved representations. It istempting to hypothesize that anomaly detection can improve indefinitely byincreasing the scale of our networks, making their representations moreexpressive. In this paper, we provide theoretical and empirical evidence to thecontrary. In fact, we empirically show cases where very expressiverepresentations fail to detect even simple anomalies when evaluated beyond thewell-studied object-centric datasets. To investigate this phenomenon, we beginby introducing a novel theoretical toy model for anomaly detection performance.The model uncovers a fundamental trade-off between representation sufficiencyand over-expressivity. It provides evidence for a no-free-lunch theorem inanomaly detection stating that increasing representation expressivity willeventually result in performance degradation. Instead, guidance must beprovided to focus the representation on the attributes relevant to theanomalies of interest. We conduct an extensive empirical investigationdemonstrating that state-of-the-art representations often suffer fromover-expressivity, failing to detect many types of anomalies. Our investigationdemonstrates how this over-expressivity impairs image anomaly detection inpractical settings. We conclude with future directions for mitigating thisissue.</description><author>Tal Reiss, Niv Cohen, Yedid Hoshen</author><pubDate>Mon, 12 Jun 2023 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07284v1</guid></item><item><title>Waffling around for Performance: Visual Classification with Random Words and Broad Concepts</title><link>http://arxiv.org/abs/2306.07282v1</link><description>The visual classification performance of vision-language models such as CLIPcan benefit from additional semantic knowledge, e.g. via large language models(LLMs) such as GPT-3. Further extending classnames with LLM-generated classdescriptors, e.g. ``waffle, \textit{which has a round shape}'', or averagingretrieval scores over multiple such descriptors, has been shown to improvegeneralization performance. In this work, we study this behavior in detail andpropose \texttt{Waffle}CLIP, a framework for zero-shot visual classificationwhich achieves similar performance gains on a large number of visualclassification tasks by simply replacing LLM-generated descriptors with randomcharacter and word descriptors \textbf{without} querying external models. Weextend these results with an extensive experimental study on the impact andshortcomings of additional semantics introduced via LLM-generated descriptors,and showcase how semantic context is better leveraged by automatically queryingLLMs for high-level concepts, while jointly resolving potential class nameambiguities. Link to the codebase: https://github.com/ExplainableML/WaffleCLIP.</description><author>Karsten Roth, Jae Myung Kim, A. Sophia Koepke, Oriol Vinyals, Cordelia Schmid, Zeynep Akata</author><pubDate>Mon, 12 Jun 2023 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07282v1</guid></item><item><title>Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations</title><link>http://arxiv.org/abs/2206.15462v3</link><description>We propose a margin-based loss for vision-language model pretraining thatencourages gradient-based explanations that are consistent with region-levelannotations. We refer to this objective as Attention Mask Consistency (AMC) anddemonstrate that it produces superior visual grounding performance compared tomodels that rely instead on region-level annotations for explicitly training anobject detector such as Faster R-CNN. AMC works by encouraging gradient-basedexplanation masks that focus their attention scores mostly within annotatedregions of interest for images that contain such annotations. Particularly, amodel trained with AMC on top of standard vision-language modeling objectivesobtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual groundingbenchmark, an absolute improvement of 5.48% when compared to the best previousmodel. Our approach also performs exceedingly well on established benchmarksfor referring expression comprehension and offers the added benefit by designof gradient-based explanations that better align with human annotations.</description><author>Ziyan Yang, Kushal Kafle, Franck Dernoncourt, Vicente Ordonez</author><pubDate>Mon, 12 Jun 2023 18:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.15462v3</guid></item><item><title>Controlling Text-to-Image Diffusion by Orthogonal Finetuning</title><link>http://arxiv.org/abs/2306.07280v1</link><description>Large text-to-image diffusion models have impressive capabilities ingenerating photorealistic images from text prompts. How to effectively guide orcontrol these powerful models to perform different downstream tasks becomes animportant open problem. To tackle this challenge, we introduce a principledfinetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-imagediffusion models to downstream tasks. Unlike existing methods, OFT can provablypreserve hyperspherical energy which characterizes the pairwise neuronrelationship on the unit hypersphere. We find that this property is crucial forpreserving the semantic generation ability of text-to-image diffusion models.To improve finetuning stability, we further propose Constrained OrthogonalFinetuning (COFT) which imposes an additional radius constraint to thehypersphere. Specifically, we consider two important finetuning text-to-imagetasks: subject-driven generation where the goal is to generate subject-specificimages given a few images of a subject and a text prompt, and controllablegeneration where the goal is to enable the model to take in additional controlsignals. We empirically show that our OFT framework outperforms existingmethods in generation quality and convergence speed.</description><author>Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu, Dan Zhang, Adrian Weller, Bernhard Schölkopf</author><pubDate>Mon, 12 Jun 2023 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07280v1</guid></item><item><title>Scalable 3D Captioning with Pretrained Models</title><link>http://arxiv.org/abs/2306.07279v1</link><description>We introduce Cap3D, an automatic approach for generating descriptive text for3D objects. This approach utilizes pretrained models from image captioning,image-text alignment, and LLM to consolidate captions from multiple views of a3D asset, completely side-stepping the time-consuming and costly process ofmanual annotation. We apply Cap3D to the recently introduced large-scale 3Ddataset, Objaverse, resulting in 660k 3D-text pairs. Our evaluation, conductedusing 41k human annotations from the same dataset, demonstrates that Cap3Dsurpasses human-authored descriptions in terms of quality, cost, and speed.Through effective prompt engineering, Cap3D rivals human performance ingenerating geometric descriptions on 17k collected annotations from the ABOdataset. Finally, we finetune Text-to-3D models on Cap3D and human captions,and show Cap3D outperforms; and benchmark the SOTA including Point-E, Shape-E,and DreamFusion.</description><author>Tiange Luo, Chris Rockwell, Honglak Lee, Justin Johnson</author><pubDate>Mon, 12 Jun 2023 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07279v1</guid></item><item><title>Mathematical conjecture generation using machine intelligence</title><link>http://arxiv.org/abs/2306.07277v1</link><description>Conjectures have historically played an important role in the development ofpure mathematics. We propose a systematic approach to finding abstract patternsin mathematical data, in order to generate conjectures about mathematicalinequalities, using machine intelligence. We focus on strict inequalities oftype f &lt; g and associate them with a vector space. By geometerising this space,which we refer to as a conjecture space, we prove that this space is isomorphicto a Banach manifold. We develop a structural understanding of this conjecturespace by studying linear automorphisms of this manifold and show that thisspace admits several free group actions. Based on these insights, we propose analgorithmic pipeline to generate novel conjectures using geometric gradientdescent, where the metric is informed by the invariances of the conjecturespace. As proof of concept, we give a toy algorithm to generate novelconjectures about the prime counting function and diameters of Cayley graphs ofnon-abelian simple groups. We also report private communications withcolleagues in which some conjectures were proved, and highlight that someconjectures generated using this procedure are still unproven. Finally, wepropose a pipeline of mathematical discovery in this space and highlight theimportance of domain expertise in this pipeline.</description><author>Challenger Mishra, Subhayan Roy Moulik, Rahul Sarkar</author><pubDate>Mon, 12 Jun 2023 18:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07277v1</guid></item><item><title>Transcendental Idealism of Planner: Evaluating Perception from Planning Perspective for Autonomous Driving</title><link>http://arxiv.org/abs/2306.07276v1</link><description>Evaluating the performance of perception modules in autonomous driving is oneof the most critical tasks in developing the complex intelligent system. Whilemodule-level unit test metrics adopted from traditional computer vision tasksare feasible to some extent, it remains far less explored to measure the impactof perceptual noise on the driving quality of autonomous vehicles in aconsistent and holistic manner. In this work, we propose a principled frameworkthat provides a coherent and systematic understanding of the impact an error inthe perception module imposes on an autonomous agent's planning that actuallycontrols the vehicle. Specifically, the planning process is formulated asexpected utility maximisation, where all input signals from upstream modulesjointly provide a world state description, and the planner strives for theoptimal action by maximising the expected utility determined by both worldstates and actions. We show that, under practical conditions, the objectivefunction can be represented as an inner product between the world statedescription and the utility function in a Hilbert space. This geometricinterpretation enables a novel way to analyse the impact of noise in worldstate estimation on planning and leads to a universal metric for evaluatingperception. The whole framework resembles the idea of transcendental idealismin the classical philosophical literature, which gives the name to ourapproach.</description><author>Wei-Xin Li, Xiaodong Yang</author><pubDate>Mon, 12 Jun 2023 18:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07276v1</guid></item><item><title>Reconstructing Heterogeneous Cryo-EM Molecular Structures by Decomposing Them into Polymer Chains</title><link>http://arxiv.org/abs/2306.07274v1</link><description>Cryogenic electron microscopy (cryo-EM) has transformed structural biology byallowing to reconstruct 3D biomolecular structures up to near-atomicresolution. However, the 3D reconstruction process remains challenging, as the3D structures may exhibit substantial shape variations, while the 2D imageacquisition suffers from a low signal-to-noise ratio, requiring to acquire verylarge datasets that are time-consuming to process. Current reconstructionmethods are precise but computationally expensive, or faster but lack aphysically-plausible model of large molecular shape variations. To fill thisgap, we propose CryoChains that encodes large deformations of biomolecules viarigid body transformation of their polymer instances (chains), whilerepresenting their finer shape variations with the normal mode analysisframework of biophysics. Our synthetic data experiments on the human$\text{GABA}_{\text{B}}$ and heat shock protein show that CryoChains gives abiophysically-grounded quantification of the heterogeneous conformations ofbiomolecules, while reconstructing their 3D molecular structures at an improvedresolution compared to the current fastest, interpretable deep learning method.</description><author>Bongjin Koo, Julien Martel, Ariana Peck, Axel Levy, Frédéric Poitevin, Nina Miolane</author><pubDate>Mon, 12 Jun 2023 18:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07274v1</guid></item><item><title>Gaussian Membership Inference Privacy</title><link>http://arxiv.org/abs/2306.07273v1</link><description>We propose a new privacy notion called $f$-Membership Inference Privacy($f$-MIP), which explicitly considers the capabilities of realistic adversariesunder the membership inference attack threat model. By doing so $f$-MIP offersinterpretable privacy guarantees and improved utility (e.g., betterclassification accuracy). Our novel theoretical analysis of likelihoodratio-based membership inference attacks on noisy stochastic gradient descent(SGD) results in a parametric family of $f$-MIP guarantees that we refer to as$\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysisadditionally yields an analytical membership inference attack that offersdistinct advantages over previous approaches. First, unlike existing methods,our attack does not require training hundreds of shadow models to approximatethe likelihood ratio. Second, our analytical attack enables straightforwardauditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes theimportance of various factors, such as hyperparameters (e.g., batch size,number of model parameters) and data specific characteristics in controlling anattacker's success in reliably inferring a given point's membership to thetraining set. We demonstrate the effectiveness of our method on models trainedacross vision and tabular datasets.</description><author>Tobias Leemann, Martin Pawelczyk, Gjergji Kasneci</author><pubDate>Mon, 12 Jun 2023 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07273v1</guid></item><item><title>Zero-shot Composed Text-Image Retrieval</title><link>http://arxiv.org/abs/2306.07272v1</link><description>In this paper, we consider the problem of composed image retrieval (CIR), itaims to train a model that can fuse multi-modal information, e.g., text andimages, to accurately retrieve images that match the query, extending theuser's expression ability. We make the following contributions: (i) we initiatea scalable pipeline to automatically construct datasets for training CIR model,by simply exploiting a large-scale dataset of image-text pairs, e.g., a subsetof LAION-5B; (ii) we introduce a transformer-based adaptive aggregation model,TransAgg, which employs a simple yet efficient fusion mechanism, to adaptivelycombine information from diverse modalities; (iii) we conduct extensiveablation studies to investigate the usefulness of our proposed dataconstruction procedure, and the effectiveness of core components in TransAgg;(iv) when evaluating on the publicly available benckmarks under the zero-shotscenario, i.e., training on the automatically constructed datasets, thendirectly conduct inference on target downstream datasets, e.g., CIRR andFashionIQ, our proposed approach either performs on par with or significantlyoutperforms the existing state-of-the-art (SOTA) models. Project page:https://code-kunkun.github.io/ZS-CIR/</description><author>Yikun Liu, Jiangchao Yao, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Mon, 12 Jun 2023 18:56:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07272v1</guid></item><item><title>Data Augmentation Approaches for Source Code Models: A Survey</title><link>http://arxiv.org/abs/2305.19915v2</link><description>The increasingly popular adoption of source code in many critical tasksmotivates the development of data augmentation (DA) techniques to enhancetraining data and improve various capabilities (e.g., robustness andgeneralizability) of these models. Although a series of DA methods have beenproposed and tailored for source code models, there lacks a comprehensivesurvey and examination to understand their effectiveness and implications. Thispaper fills this gap by conducting a comprehensive and integrative survey ofdata augmentation for source code, wherein we systematically compile andencapsulate existing literature to provide a comprehensive overview of thefield. We start by constructing a taxonomy of DA for source code models modelapproaches, followed by a discussion on prominent, methodologicallyillustrative approaches. Next, we highlight the general strategies andtechniques to optimize the DA quality. Subsequently, we underscore techniquesthat find utility in widely-accepted source code scenarios and downstreamtasks. Finally, we outline the prevailing challenges and potentialopportunities for future research. In essence, this paper endeavors todemystify the corpus of existing literature on DA for source code models, andfoster further exploration in this sphere. Complementing this, we present acontinually updated GitHub repository that hosts a list of update-to-datepapers on DA for source code models, accessible at\url{https://github.com/terryyz/DataAug4Code}.</description><author>Terry Yue Zhuo, Zhou Yang, Zhensu Sun, Yufei Wang, Li Li, Xiaoning Du, Zhenchang Xing, David Lo</author><pubDate>Mon, 12 Jun 2023 18:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19915v2</guid></item><item><title>Operator Learning with Neural Fields: Tackling PDEs on General Geometries</title><link>http://arxiv.org/abs/2306.07266v1</link><description>Machine learning approaches for solving partial differential equationsrequire learning mappings between function spaces. While convolutional or graphneural networks are constrained to discretized functions, neural operatorspresent a promising milestone toward mapping functions directly. Despiteimpressive results they still face challenges with respect to the domaingeometry and typically rely on some form of discretization. In order toalleviate such limitations, we present CORAL, a new method that leveragescoordinate-based networks for solving PDEs on general geometries. CORAL isdesigned to remove constraints on the input mesh, making it applicable to anyspatial sampling and geometry. Its ability extends to diverse problem domains,including PDE solving, spatio-temporal forecasting, and inverse problems likegeometric design. CORAL demonstrates robust performance across multipleresolutions and performs well in both convex and non-convex domains, surpassingor performing on par with state-of-the-art models.</description><author>Louis Serrano, Lise Le Boudec, Armand Kassaï Koupaï, Thomas X Wang, Yuan Yin, Jean-Noël Vittaut, Patrick Gallinari</author><pubDate>Mon, 12 Jun 2023 18:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07266v1</guid></item><item><title>detrex: Benchmarking Detection Transformers</title><link>http://arxiv.org/abs/2306.07265v1</link><description>The DEtection TRansformer (DETR) algorithm has received considerableattention in the research community and is gradually emerging as a mainstreamapproach for object detection and other perception tasks. However, the currentfield lacks a unified and comprehensive benchmark specifically tailored forDETR-based models. To address this issue, we develop a unified, highly modular,and lightweight codebase called detrex, which supports a majority of themainstream DETR-based instance recognition algorithms, covering variousfundamental tasks, including object detection, segmentation, and poseestimation. We conduct extensive experiments under detrex and perform acomprehensive benchmark for DETR-based models. Moreover, we enhance theperformance of detection transformers through the refinement of traininghyper-parameters, providing strong baselines for supported algorithms.We hopethat detrex could offer research communities a standardized and unifiedplatform to evaluate and compare different DETR-based models while fostering adeeper understanding and driving advancements in DETR-based instancerecognition. Our code is available at https://github.com/IDEA-Research/detrex.The project is currently being actively developed. We encourage the communityto use detrex codebase for further development and contributions.</description><author>Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang, Xingyu Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng, Xianbiao Qi, Yuhui Yuan, Jianwei Yang, Lei Zhang</author><pubDate>Mon, 12 Jun 2023 18:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07265v1</guid></item><item><title>Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title><link>http://arxiv.org/abs/2206.04615v3</link><description>Language models demonstrate both quantitative improvement and new qualitativecapabilities with increasing scale. Despite their potentially transformativeimpact, these new capabilities are as yet poorly characterized. In order toinform future research, prepare for disruptive new model capabilities, andameliorate socially harmful effects, it is vital that we understand the presentand near-future capabilities and limitations of language models. To addressthis challenge, we introduce the Beyond the Imitation Game benchmark(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450authors across 132 institutions. Task topics are diverse, drawing problems fromlinguistics, childhood development, math, common-sense reasoning, biology,physics, social bias, software development, and beyond. BIG-bench focuses ontasks that are believed to be beyond the capabilities of current languagemodels. We evaluate the behavior of OpenAI's GPT models, Google-internal densetransformer architectures, and Switch-style sparse transformers on BIG-bench,across model sizes spanning millions to hundreds of billions of parameters. Inaddition, a team of human expert raters performed all tasks in order to providea strong baseline. Findings include: model performance and calibration bothimprove with scale, but are poor in absolute terms (and when compared withrater performance); performance is remarkably similar across model classes,though with benefits from sparsity; tasks that improve gradually andpredictably commonly involve a large knowledge or memorization component,whereas tasks that exhibit "breakthrough" behavior at a critical scale ofteninvolve multiple steps or components, or brittle metrics; social bias typicallyincreases with scale in settings with ambiguous context, but this can beimproved with prompting.</description><author>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew Dai, Andrew La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Er</author><pubDate>Mon, 12 Jun 2023 18:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.04615v3</guid></item><item><title>Unprocessing Seven Years of Algorithmic Fairness</title><link>http://arxiv.org/abs/2306.07261v1</link><description>Seven years ago, researchers proposed a postprocessing method to equalize theerror rates of a model across different demographic groups. The work launchedhundreds of papers purporting to improve over the postprocessing baseline. Weempirically evaluate these claims through thousands of model evaluations onseveral tabular datasets. We find that the fairness-accuracy Pareto frontierachieved by postprocessing contains all other methods we were feasibly able toevaluate. In doing so, we address two common methodological errors that haveconfounded previous observations. One relates to the comparison of methods withdifferent unconstrained base models. The other concerns methods achievingdifferent levels of constraint relaxation. At the heart of our study is asimple idea we call unprocessing that roughly corresponds to the inverse ofpostprocessing. Unprocessing allows for a direct comparison of methods usingdifferent underlying models and levels of relaxation. Interpreting ourfindings, we recall a widely overlooked theoretical argument, present sevenyears ago, that accurately predicted what we observe.</description><author>André F. Cruz, Moritz Hardt</author><pubDate>Mon, 12 Jun 2023 18:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07261v1</guid></item><item><title>Frozen Overparameterization: A Double Descent Perspective on Transfer Learning of Deep Neural Networks</title><link>http://arxiv.org/abs/2211.11074v2</link><description>We study the generalization behavior of transfer learning of deep neuralnetworks (DNNs). We adopt the overparameterization perspective -- featuringinterpolation of the training data (i.e., approximately zero train error) andthe double descent phenomenon -- to explain the delicate effect of the transferlearning setting on generalization performance. We study how the generalizationbehavior of transfer learning is affected by the dataset size in the source andtarget tasks, the number of transferred layers that are kept frozen in thetarget DNN training, and the similarity between the source and target tasks. Weshow that the test error evolution during the target DNN training has a moresignificant double descent effect when the target training dataset issufficiently large. In addition, a larger source training dataset can yield aslower target DNN training. Moreover, we demonstrate that the number of frozenlayers can determine whether the transfer learning is effectivelyunderparameterized or overparameterized and, in turn, this may induce afreezing-wise double descent phenomenon that determines the relative success orfailure of learning. Also, we show that the double descent phenomenon may makea transfer from a less related source task better than a transfer from a morerelated source task. We establish our results using image classificationexperiments with the ResNet, DenseNet and the vision transformer (ViT)architectures.</description><author>Yehuda Dar, Lorenzo Luzi, Richard G. Baraniuk</author><pubDate>Mon, 12 Jun 2023 18:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11074v2</guid></item><item><title>MovieFactory: Automatic Movie Creation from Text using Large Generative Models for Language and Images</title><link>http://arxiv.org/abs/2306.07257v1</link><description>In this paper, we present MovieFactory, a powerful framework to generatecinematic-picture (3072$\times$1280), film-style (multi-scene), andmulti-modality (sounding) movies on the demand of natural languages. As thefirst fully automated movie generation model to the best of our knowledge, ourapproach empowers users to create captivating movies with smooth transitionsusing simple text inputs, surpassing existing methods that produce soundlessvideos limited to a single scene of modest quality. To facilitate thisdistinctive functionality, we leverage ChatGPT to expand user-provided textinto detailed sequential scripts for movie generation. Then we bring scripts tolife visually and acoustically through vision generation and audio retrieval.To generate videos, we extend the capabilities of a pretrained text-to-imagediffusion model through a two-stage process. Firstly, we employ spatialfinetuning to bridge the gap between the pretrained image model and the newvideo dataset. Subsequently, we introduce temporal learning to capture objectmotion. In terms of audio, we leverage sophisticated retrieval models to selectand align audio elements that correspond to the plot and visual content of themovie. Extensive experiments demonstrate that our MovieFactory produces movieswith realistic visuals, diverse scenes, and seamlessly fitting audio, offeringusers a novel and immersive experience. Generated samples can be found inYouTube or Bilibili (1080P).</description><author>Junchen Zhu, Huan Yang, Huiguo He, Wenjing Wang, Zixi Tuo, Wen-Huang Cheng, Lianli Gao, Jingkuan Song, Jianlong Fu</author><pubDate>Mon, 12 Jun 2023 18:31:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07257v1</guid></item><item><title>Conditional Matrix Flows for Gaussian Graphical Models</title><link>http://arxiv.org/abs/2306.07255v1</link><description>Studying conditional independence structure among many variables with fewobservations is a challenging task. Gaussian Graphical Models (GGMs) tacklethis problem by encouraging sparsity in the precision matrix through an $l_p$regularization with $p\leq1$. However, since the objective is highly non-convexfor sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In thiscase frequentist approaches allow to elegantly compute the solution path as afunction of the shrinkage parameter $\lambda$. Instead of optimizing thepenalized likelihood, the Bayesian formulation introduces a Laplace prior onthe precision matrix. However, posterior inference for different $\lambda$values requires repeated runs of expensive Gibbs samplers. We propose a verygeneral framework for variational inference in GGMs that unifies the benefitsof frequentist and Bayesian frameworks. Specifically, we propose to approximatethe posterior with a matrix-variate Normalizing Flow defined on the space ofsymmetric positive definite matrices. As a key improvement on previous work, wetrain a continuum of sparse regression models jointly for all regularizationparameters $\lambda$ and all $l_p$ norms, including non-convex sub-$l_1$pseudo-norms. This is achieved by conditioning the flow on $p&gt;0$ and on theshrinkage parameter $\lambda$. We have then access with one model to (i) theevolution of the posterior for any $\lambda$ and for any $l_p$ (pseudo-) norms,(ii) the marginal log-likelihood for model selection, and (iii) we can recoverthe frequentist solution paths as the MAP, which is obtained through simulatedannealing.</description><author>Marcello Massimo Negri, F. Arend Torres, Volker Roth</author><pubDate>Mon, 12 Jun 2023 18:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07255v1</guid></item><item><title>Modeling Dynamic Environments with Scene Graph Memory</title><link>http://arxiv.org/abs/2305.17537v4</link><description>Embodied AI agents that search for objects in large environments such ashouseholds often need to make efficient decisions by predicting objectlocations based on partial information. We pose this as a new type of linkprediction problem: link prediction on partially observable dynamic graphs. Ourgraph is a representation of a scene in which rooms and objects are nodes, andtheir relationships are encoded in the edges; only parts of the changing graphare known to the agent at each timestep. This partial observability poses achallenge to existing link prediction approaches, which we address. We proposea novel state representation -- Scene Graph Memory (SGM) -- with captures theagent's accumulated set of observations, as well as a neural net architecturecalled a Node Edge Predictor (NEP) that extracts information from the SGM tosearch efficiently. We evaluate our method in the Dynamic House Simulator, anew benchmark that creates diverse dynamic graphs following the semanticpatterns typically seen at homes, and show that NEP can be trained to predictthe locations of objects in a variety of environments with diverse objectmovement dynamics, outperforming baselines both in terms of new sceneadaptability and overall accuracy. The codebase and more can be found athttps://www.scenegraphmemory.com.</description><author>Andrey Kurenkov, Michael Lingelbach, Tanmay Agarwal, Emily Jin, Chengshu Li, Ruohan Zhang, Li Fei-Fei, Jiajun Wu, Silvio Savarese, Roberto Martín-Martín</author><pubDate>Mon, 12 Jun 2023 18:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17537v4</guid></item><item><title>On the Expected Size of Conformal Prediction Sets</title><link>http://arxiv.org/abs/2306.07254v1</link><description>While conformal predictors reap the benefits of rigorous statisticalguarantees for their error frequency, the size of their correspondingprediction sets is critical to their practical utility. Unfortunately, there iscurrently a lack of finite-sample analysis and guarantees for their predictionset sizes. To address this shortfall, we theoretically quantify the expectedsize of the prediction set under the split conformal prediction framework. Asthis precise formulation cannot usually be calculated directly, we furtherderive point estimates and high probability intervals that can be easilycomputed, providing a practical method for characterizing the expectedprediction set size across different possible realizations of the test andcalibration data. Additionally, we corroborate the efficacy of our results withexperiments on real-world datasets, for both regression and classificationproblems.</description><author>Guneet S. Dhillon, George Deligiannidis, Tom Rainforth</author><pubDate>Mon, 12 Jun 2023 18:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07254v1</guid></item><item><title>On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling</title><link>http://arxiv.org/abs/2306.07252v1</link><description>We study the properties of conformal prediction for network data undervarious sampling mechanisms that commonly arise in practice but often result ina non-representative sample of nodes. We interpret these sampling mechanisms asselection rules applied to a superpopulation and study the validity ofconformal prediction conditional on an appropriate selection event. We showthat the sampled subarray is exchangeable conditional on the selection event ifthe selection rule satisfies a permutation invariance property and a jointexchangeability condition holds for the superpopulation. Our result implies thefinite-sample validity of conformal prediction for certain selection eventsrelated to ego networks and snowball sampling. We also show that when data aresampled via a random walk on a graph, a variant of weighted conformalprediction yields asymptotically valid prediction sets for an independentlyselected node from the population.</description><author>Robert Lunde</author><pubDate>Mon, 12 Jun 2023 18:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07252v1</guid></item><item><title>CLADE: Cycle Loss Augmented Degradation Enhancement for Unpaired Super-Resolution of Anisotropic Medical Images</title><link>http://arxiv.org/abs/2303.11831v2</link><description>Three-dimensional (3D) imaging is extremely popular in medical imaging as itenables diagnosis and disease monitoring through complete anatomical coverage.Computed Tomography or Magnetic Resonance Imaging (MRI) techniques are commonlyused, however, anisotropic volumes with thick slices are often acquired toreduce scan times. Deep learning (DL) can be used to recover high-resolutionfeatures in the low-resolution dimension through super-resolutionreconstruction (SRR). However, this often relies on paired training data whichis unavailable in many medical applications. We describe a novel approach thatonly requires native anisotropic 3D medical images for training. This methodrelies on the observation that small 2D patches extracted from a 3D volumecontain similar visual features, irrespective of their orientation. Therefore,it is possible to leverage disjoint patches from the high-resolution plane, tolearn SRR in the low-resolution plane. Our proposed unpaired approach uses amodified CycleGAN architecture with a cycle-consistent gradient mapping loss:Cycle Loss Augmented Degradation Enhancement (CLADE). We show the feasibilityof CLADE in an exemplar application; anisotropic 3D abdominal MRI data. Wedemonstrate superior quantitative image quality with CLADE over supervisedlearning and conventional CycleGAN architectures. CLADE also shows improvementsover anisotopic volumes in terms of qualitative image ranking and quantitativeedge sharpness and signal-to-noise ratio. This paper demonstrates the potentialof using CLADE for super-resolution reconstruction of anisotropic 3D medicalimaging data without the need for paired training data.</description><author>Michele Pascale, Vivek Muthurangu, Javier Montalt Tordera, Heather E Fitzke, Gauraang Bhatnagar, Stuart Taylor, Jennifer Steeden</author><pubDate>Mon, 12 Jun 2023 18:14:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11831v2</guid></item><item><title>Reliable machine learning potentials based on artificial neural network for graphene</title><link>http://arxiv.org/abs/2306.07246v1</link><description>Graphene is one of the most researched two dimensional (2D) material due toits unique combination of mechanical, thermal and electrical properties.Special 2D structure of graphene enables it to exhibit a wide range of peculiarmaterial properties like high Young's modulus, high specific strength etc.which are critical for myriad of applications including light weight structuralmaterials, multi-functional coating and flexible electronics. It is quitechallenging and costly to experimentally investigate graphene/graphene basednanocomposites, computational simulations such as molecular dynamics (MD)simulations are widely adopted for understanding the microscopic origins oftheir unique properties. However, disparate results were reported fromcomputational studies, especially MD simulations using various empiricalinter-atomic potentials. In this work, an artificial neural network basedinteratomic potential has been developed for graphene to represent thepotential energy surface based on first principle calculations. The developedmachine learning potential (MLP) facilitates high fidelity MD simulations toapproach the accuracy of ab initio methods but with a fraction of computationalcost, which allows larger simulation size/length, and thereby enablesaccelerated discovery/design of graphene-based novel materials. Latticeparameter, coefficient of thermal expansion (CTE), Young's modulus and yieldstrength are estimated using machine learning accelerated MD simulations(MLMD), which are compared to experimental/first principle calculations fromprevious literatures. It is demonstrated that MLMD can capture the dominatingmechanism governing CTE of graphene, including effects from lattice parameterand out of plane rippling.</description><author>Akash Singh, Yumeng Li</author><pubDate>Mon, 12 Jun 2023 18:12:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07246v1</guid></item><item><title>Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications</title><link>http://arxiv.org/abs/2202.12396v7</link><description>This paper studies stochastic optimization for a sum of compositionalfunctions, where the inner-level function of each summand is coupled with thecorresponding summation index. We refer to this family of problems asfinite-sum coupled compositional optimization (FCCO). It has broad applicationsin machine learning for optimizing non-convex or convex compositionalmeasures/objectives such as average precision (AP), p-norm push, listwiseranking losses, neighborhood component analysis (NCA), deep survival analysis,deep latent variable models, etc., which deserves finer analysis. Yet, existingalgorithms and analyses are restricted in one or other aspects. Thecontribution of this paper is to provide a comprehensive convergence analysisof a simple stochastic algorithm for both non-convex and convex objectives. Ourkey result is the improved oracle complexity with the parallel speed-up byusing the moving-average based estimator with mini-batching. Our theoreticalanalysis also exhibits new insights for improving the practical implementationby sampling the batches of equal size for the outer and inner levels. Numericalexperiments on AP maximization, NCA, and p-norm push corroborate some aspectsof the theory.</description><author>Bokun Wang, Tianbao Yang</author><pubDate>Mon, 12 Jun 2023 18:11:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.12396v7</guid></item><item><title>RB-Dust -- A Reference-based Dataset for Vision-based Dust Removal</title><link>http://arxiv.org/abs/2306.07244v1</link><description>Dust in the agricultural landscape is a significant challenge and influences,for example, the environmental perception of autonomous agricultural machines.Image enhancement algorithms can be used to reduce dust. However, these requiredusty and dust-free images of the same environment for validation. In fact, todate, there is no dataset that we are aware of that addresses this issue.Therefore, we present the agriscapes RB-Dust dataset, which is named after itspurpose of reference-based dust removal. It is not possible to take picturesfrom the cabin during tillage, as this would cause shifts in the images.Because of this, we built a setup from which it is possible to take images froma stationary position close to the passing tractor. The test setup was based ona half-sided gate through which the tractor could drive. The field tests werecarried out on a farm in Bavaria, Germany, during tillage. During the fieldtests, other parameters such as soil moisture and wind speed were controlled,as these significantly affect dust development. We validated our dataset withcontrast enhancement and image dehazing algorithms and analyzed thegeneralizability from recordings from the moving tractor. Finally, wedemonstrate the application of dust removal based on a high-level vision task,such as person classification. Our empirical study confirms the validity ofRB-Dust for vision-based dust removal in agriculture.</description><author>Peter Buckel, Timo Oksanen, Thomas Dietmueller</author><pubDate>Mon, 12 Jun 2023 18:09:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07244v1</guid></item><item><title>Mean Shift Mask Transformer for Unseen Object Instance Segmentation</title><link>http://arxiv.org/abs/2211.11679v2</link><description>Segmenting unseen objects from images is a critical perception skill that arobot needs to acquire. In robot manipulation, it can facilitate a robot tograsp and manipulate unseen objects. Mean shift clustering is a widely usedmethod for image segmentation tasks. However, the traditional mean shiftclustering algorithm is not differentiable, making it difficult to integrate itinto an end-to-end neural network training framework. In this work, we proposethe Mean Shift Mask Transformer (MSMFormer), a new transformer architecturethat simulates the von Mises-Fisher (vMF) mean shift clustering algorithm,allowing for the joint training and inference of both the feature extractor andthe clustering. Its central component is a hypersphere attention mechanism,which updates object queries on a hypersphere. To illustrate the effectivenessof our method, we apply MSMFormer to unseen object instance segmentation. Ourexperiments show that MSMFormer achieves competitive performance compared tostate-of-the-art methods for unseen object instance segmentation. The video andcode are available at https://irvlutd.github.io/MSMFormer</description><author>Yangxiao Lu, Yuqiao Chen, Nicholas Ruozzi, Yu Xiang</author><pubDate>Mon, 12 Jun 2023 18:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11679v2</guid></item><item><title>SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning</title><link>http://arxiv.org/abs/2305.19442v2</link><description>Federated bilevel optimization (FBO) has shown great potential recently inmachine learning and edge computing due to the emerging nested optimizationstructure in meta-learning, fine-tuning, hyperparameter tuning, etc. However,existing FBO algorithms often involve complicated computations and requiremultiple sub-loops per iteration, each of which contains a number ofcommunication rounds. In this paper, we propose a simple and flexible FBOframework named SimFBO, which is easy to implement without sub-loops, andincludes a generalized server-side aggregation and update for improvingcommunication efficiency. We further propose System-level heterogeneity robustFBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneouslocal computation. We show that SimFBO and ShroFBO provably achieve a linearconvergence speedup with partial client participation and client samplingwithout replacement, as well as improved sample and communication complexities.Experiments demonstrate the effectiveness of the proposed methods over existingFBO algorithms.</description><author>Yifan Yang, Peiyao Xiao, Kaiyi Ji</author><pubDate>Mon, 12 Jun 2023 18:04:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19442v2</guid></item><item><title>Method for the semantic indexing of concept hierarchies, uniform representation, use of relational database systems and generic and case-based reasoning</title><link>http://arxiv.org/abs/1910.01539v2</link><description>This paper presents a method for semantic indexing and describes itsapplication in the field of knowledge representation. Starting point of thesemantic indexing is the knowledge represented by concept hierarchies. The goalis to assign keys to nodes (concepts) that are hierarchically ordered andsyntactically and semantically correct. With the indexing algorithm, keys arecomputed such that concepts are partially unifiable with all more specificconcepts and only semantically correct concepts are allowed to be added. Thekeys represent terminological relationships. Correctness and completeness ofthe underlying indexing algorithm are proven. The use of classical relationaldatabases for the storage of instances is described. Because of the uniformrepresentation, inference can be done using case-based reasoning and genericproblem solving methods.</description><author>Uwe Petersohn, Sandra Zimmer, Jens Lehmann</author><pubDate>Mon, 12 Jun 2023 18:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.01539v2</guid></item><item><title>Accelerating Primal-dual Methods for Regularized Markov Decision Processes</title><link>http://arxiv.org/abs/2202.10506v2</link><description>Entropy regularized Markov decision processes have been widely used inreinforcement learning. This paper is concerned with the primal-dualformulation of the entropy regularized problems. Standard first-order methodssuffer from slow convergence due to the lack of strict convexity and concavity.To address this issue, we first introduce a new quadratically convexifiedprimal-dual formulation. The natural gradient ascent descent of the newformulation enjoys global convergence guarantee and exponential convergencerate. We also propose a new interpolating metric that further accelerates theconvergence significantly. Numerical results are provided to demonstrate theperformance of the proposed methods under multiple settings.</description><author>Haoya Li, Hsiang-fu Yu, Lexing Ying, Inderjit Dhillon</author><pubDate>Mon, 12 Jun 2023 17:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.10506v2</guid></item><item><title>Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale Outdoor Scene</title><link>http://arxiv.org/abs/2301.12972v3</link><description>This paper proposes EyeNet, a novel semantic segmentation network for pointclouds that addresses the critical yet often overlooked parameter of coveragearea size. Inspired by human peripheral vision, EyeNet overcomes thelimitations of conventional networks by introducing a simple but efficientmulti-contour input and a parallel processing network with connection blocksbetween parallel streams. The proposed approach effectively addresses thechallenges of dense point clouds, as demonstrated by our ablation studies andstate-of-the-art performance on Large-Scale Outdoor datasets.</description><author>Sunghwan Yoo, Yeongjeong Jeong, Maryam Jameela, Gunho Sohn</author><pubDate>Mon, 12 Jun 2023 17:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12972v3</guid></item><item><title>Deep Gaussian Mixture Ensembles</title><link>http://arxiv.org/abs/2306.07235v1</link><description>This work introduces a novel probabilistic deep learning technique calleddeep Gaussian mixture ensembles (DGMEs), which enables accurate quantificationof both epistemic and aleatoric uncertainty. By assuming the data generatingprocess follows that of a Gaussian mixture, DGMEs are capable of approximatingcomplex probability distributions, such as heavy-tailed or multimodaldistributions. Our contributions include the derivation of anexpectation-maximization (EM) algorithm used for learning the model parameters,which results in an upper-bound on the log-likelihood of training data overthat of standard deep ensembles. Additionally, the proposed EM trainingprocedure allows for learning of mixture weights, which is not commonly done inensembles. Our experimental results demonstrate that DGMEs outperformstate-of-the-art uncertainty quantifying deep learning models in handlingcomplex predictive densities.</description><author>Yousef El-Laham, Niccolò Dalmasso, Elizabeth Fons, Svitlana Vyetrenko</author><pubDate>Mon, 12 Jun 2023 17:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07235v1</guid></item><item><title>Adversarial Rewards in Universal Learning for Contextual Bandits</title><link>http://arxiv.org/abs/2302.07186v2</link><description>We study the fundamental limits of learning in contextual bandits, where alearner's rewards depend on their actions and a known context, which extendsthe canonical multi-armed bandit to the case where side-information isavailable. We are interested in universally consistent algorithms, whichachieve sublinear regret compared to any measurable fixed policy, without anyfunction class restriction. For stationary contextual bandits, when theunderlying reward mechanism is time-invariant, Blanchard et. al (2022)characterized learnable context processes for which universal consistency isachievable; and further gave algorithms ensuring universal consistency wheneverthis is achievable, a property known as optimistic universal consistency. It iswell understood, however, that reward mechanisms can evolve over time, possiblyadversarially, and depending on the learner's actions. We show that optimisticuniversal learning for contextual bandits with adversarial rewards isimpossible in general, contrary to all previously studied settings in onlinelearning -- including standard supervised learning. We also give necessary andsufficient conditions for universal learning under various adversarial rewardmodels, and an exact characterization for online rewards. In particular, theset of learnable processes for these reward models is still extremely general-- larger than i.i.d., stationary or ergodic -- but in general strictly smallerthan that for supervised learning or stationary contextual bandits, sheddinglight on new adversarial phenomena.</description><author>Moise Blanchard, Steve Hanneke, Patrick Jaillet</author><pubDate>Mon, 12 Jun 2023 17:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07186v2</guid></item><item><title>Generative Plug and Play: Posterior Sampling for Inverse Problems</title><link>http://arxiv.org/abs/2306.07233v1</link><description>Over the past decade, Plug-and-Play (PnP) has become a popular method forreconstructing images using a modular framework consisting of a forward andprior model. The great strength of PnP is that an image denoiser can be used asa prior model while the forward model can be implemented using more traditionalphysics-based approaches. However, a limitation of PnP is that it reconstructsonly a single deterministic image. In this paper, we introduce Generative Plug-and-Play (GPnP), a generalizationof PnP to sample from the posterior distribution. As with PnP, GPnP has amodular framework using a physics-based forward model and an image denoisingprior model. However, in GPnP these models are extended to become proximalgenerators, which sample from associated distributions. GPnP applies theseproximal generators in alternation to produce samples from the posterior. Wepresent experimental simulations using the well-known BM3D denoiser. Ourresults demonstrate that the GPnP method is robust, easy to implement, andproduces intuitively reasonable samples from the posterior for sparseinterpolation and tomographic reconstruction. Code to accompany this paper isavailable at https://github.com/gbuzzard/generative-pnp-allerton .</description><author>Charles A. Bouman, Gregery T. Buzzard</author><pubDate>Mon, 12 Jun 2023 17:49:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07233v1</guid></item><item><title>AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment</title><link>http://arxiv.org/abs/2306.04717v2</link><description>With the rapid advancements of the text-to-image generative model,AI-generated images (AGIs) have been widely applied to entertainment,education, social media, etc. However, considering the large quality varianceamong different AGIs, there is an urgent need for quality models that areconsistent with human subjective ratings. To address this issue, we extensivelyconsider various popular AGI models, generated AGI through different promptsand model parameters, and collected subjective scores at the perceptual qualityand text-to-image alignment, thus building the most comprehensive AGIsubjective quality database AGIQA-3K so far. Furthermore, we conduct abenchmark experiment on this database to evaluate the consistency between thecurrent Image Quality Assessment (IQA) model and human perception, whileproposing StairReward that significantly improves the assessment performance ofsubjective text-to-image alignment. We believe that the fine-grained subjectivescores in AGIQA-3K will inspire subsequent AGI quality models to fit humansubjective perception mechanisms at both perception and alignment levels and tooptimize the generation result of future AGI models. The database is releasedon https://github.com/lcysyzxdxc/AGIQA-3k-Database.</description><author>Chunyi Li, Zicheng Zhang, Haoning Wu, Wei Sun, Xiongkuo Min, Xiaohong Liu, Guangtao Zhai, Weisi Lin</author><pubDate>Mon, 12 Jun 2023 17:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04717v2</guid></item><item><title>NeRF-GAN Distillation for Memory-Efficient 3D-Aware Generation with Convolutions</title><link>http://arxiv.org/abs/2303.12865v2</link><description>Pose-conditioned convolutional generative models struggle with high-quality3D-consistent image generation from single-view datasets, due to their lack ofsufficient 3D priors. Recently, the integration of Neural Radiance Fields(NeRFs) and generative models, such as Generative Adversarial Networks (GANs),has transformed 3D-aware generation from single-view images. NeRF-GANs exploitthe strong inductive bias of 3D neural representations and volumetric renderingat the cost of higher computational complexity. This study aims at revisitingpose-conditioned 2D GANs for memory-efficient 3D-aware generation at inferencetime by distilling 3D knowledge from pretrained NeRF-GANS. We propose a simpleand effective method, based on re-using the well-disentangled latent space of apre-trained NeRF-GAN in a pose-conditioned convolutional network to directlygenerate 3D-consistent images corresponding to the underlying 3Drepresentations. Experiments on several datasets demonstrate that the proposedmethod obtains results comparable with volumetric rendering in terms of qualityand 3D consistency while benefiting from the superior computational advantageof convolutional networks. The code will be available at:https://github.com/mshahbazi72/NeRF-GAN-Distillation</description><author>Mohamad Shahbazi, Evangelos Ntavelis, Alessio Tonioni, Edo Collins, Danda Pani Paudel, Martin Danelljan, Luc Van Gool</author><pubDate>Mon, 12 Jun 2023 17:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12865v2</guid></item><item><title>Convergence of mean-field Langevin dynamics: Time and space discretization, stochastic gradient, and variance reduction</title><link>http://arxiv.org/abs/2306.07221v1</link><description>The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of theLangevin dynamics that incorporates a distribution-dependent drift, and itnaturally arises from the optimization of two-layer neural networks via (noisy)gradient descent. Recent works have shown that MFLD globally minimizes anentropy-regularized convex functional in the space of measures. However, allprior analyses assumed the infinite-particle or continuous-time limit, andcannot handle stochastic gradient updates. We provide an general framework toprove a uniform-in-time propagation of chaos for MFLD that takes into accountthe errors due to finite-particle approximation, time-discretization, andstochastic gradient approximation. To demonstrate the wide applicability ofthis framework, we establish quantitative convergence rate guarantees to theregularized global optimal solution under (i) a wide range of learning problemssuch as neural network in the mean-field regime and MMD minimization, and (ii)different gradient estimators including SGD and SVRG. Despite the generality ofour results, we achieve an improved convergence rate in both the SGD and SVRGsettings when specialized to the standard Langevin dynamics.</description><author>Taiji Suzuki, Denny Wu, Atsushi Nitanda</author><pubDate>Mon, 12 Jun 2023 17:28:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07221v1</guid></item><item><title>Strokes2Surface: Recovering Curve Networks From 4D Architectural Design Sketches</title><link>http://arxiv.org/abs/2306.07220v1</link><description>We present Strokes2Surface, an offline geometry-reconstruction pipeline builtupon a 4D Sketching Interface, MR.Sketch, targeted at architectural design. Thepipeline recovers a curve network from designer-drawn strokes, thus bridgingbetween concept design and digital modeling stages in architectural design. Theinput to our pipeline consists of 3D strokes' polyline vertices and theircorresponding timestamps (as of the fourth dimension), along with additionalgeometric and stylus-related recorded properties. Inspired by sketchconsolidation and sketch-based modeling methods, our pipeline leverages suchdata and combines three Machine Learning (ML) models; a classifier and twoclustering models. In particular, based on observations of practices designerstypically employ in architectural design sketches, we solve a binaryclassification problem to recognize whether a stroke depicts a boundary andedge or is used to fill in the enclosing areas and faces of the intendedarchitectural object. Followed by the two clustering models, strokes of eachtype are further parsed into groups, each representing either a single edge ora single face. Next, groups representing edges are approximated with B-splinecurves, followed by a topology-recovering process identifying and fixingdesired connectivities between the curves forming a well-connected curvenetwork. Next, groups representing the faces are employed to detect the cyclesbounding patches in the curve network, resulting in the final surface meshgeometry of the architectural object. We confirm the usability ofStrokes2Surface via a user study and further validate and compare our resultsagainst a range of reconstructions computed using alternative methods. We alsointroduce our manually labeled dataset of 4D architectural design sketches forfurther use in the community.</description><author>S. Rasoulzadeh, M. Wimmer, I. Kovacic</author><pubDate>Mon, 12 Jun 2023 17:26:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07220v1</guid></item><item><title>A Protocol for Continual Explanation of SHAP</title><link>http://arxiv.org/abs/2306.07218v1</link><description>Continual Learning trains models on a stream of data, with the aim oflearning new information without forgetting previous knowledge. Given thedynamic nature of such environments, explaining the predictions of these modelscan be challenging. We study the behavior of SHAP values explanations inContinual Learning and propose an evaluation protocol to robustly assess thechange of explanations in Class-Incremental scenarios. We observed that, whileReplay strategies enforce the stability of SHAP values infeedforward/convolutional models, they are not able to do the same withfully-trained recurrent models. We show that alternative recurrent approaches,like randomized recurrent models, are more effective in keeping theexplanations stable over time.</description><author>Andrea Cossu, Francesco Spinnato, Riccardo Guidotti, Davide Bacciu</author><pubDate>Mon, 12 Jun 2023 17:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07218v1</guid></item><item><title>Adaptation Approaches for Nearest Neighbor Language Models</title><link>http://arxiv.org/abs/2211.07828v2</link><description>Semi-parametric Nearest Neighbor Language Models ($k$NN-LMs) have producedimpressive gains over purely parametric LMs, by leveraging large-scaleneighborhood retrieval over external memory datastores. However, there has beenlittle investigation into adapting such models for new domains. This workattempts to fill that gap and suggests the following approaches for adapting$k$NN-LMs -- 1) adapting the underlying LM (using Adapters), 2) expandingneighborhood retrieval over an additional adaptation datastore, and 3) adaptingthe weights (scores) of retrieved neighbors using a learned Rescorer module. Westudy each adaptation strategy separately, as well as the combined performanceimprovement through ablation experiments and an extensive set of evaluationsrun over seven adaptation domains. Our combined adaptation approachconsistently outperforms purely parametric adaptation and zero-shot ($k$NN-LM)baselines that construct datastores from the adaptation data. On average, wesee perplexity improvements of 17.1% and 16% for these respective baselines,across domains.</description><author>Rishabh Bhardwaj, George Polovets, Monica Sunkara</author><pubDate>Mon, 12 Jun 2023 17:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07828v2</guid></item><item><title>Efficient Quantization-aware Training with Adaptive Coreset Selection</title><link>http://arxiv.org/abs/2306.07215v1</link><description>The expanding model size and computation of deep neural networks (DNNs) haveincreased the demand for efficient model deployment methods. Quantization-awaretraining (QAT) is a representative model compression method to leverageredundancy in weights and activations. However, most existing QAT methodsrequire end-to-end training on the entire dataset, which suffers from longtraining time and high energy costs. Coreset selection, aiming to improve dataefficiency utilizing the redundancy of training data, has also been widely usedfor efficient training. In this work, we propose a new angle through thecoreset selection to improve the training efficiency of quantization-awaretraining. Based on the characteristics of QAT, we propose two metrics: errorvector score and disagreement score, to quantify the importance of each sampleduring training. Guided by these two metrics of importance, we proposed aquantization-aware adaptive coreset selection (ACS) method to select the datafor the current training epoch. We evaluate our method on various networks(ResNet-18, MobileNetV2), datasets(CIFAR-100, ImageNet-1K), and under differentquantization settings. Compared with previous coreset selection methods, ourmethod significantly improves QAT performance with different dataset fractions.Our method can achieve an accuracy of 68.39% of 4-bit quantized ResNet-18 onthe ImageNet-1K dataset with only a 10% subset, which has an absolute gain of4.24% compared to the baseline.</description><author>Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng</author><pubDate>Mon, 12 Jun 2023 17:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07215v1</guid></item><item><title>Polyhedral Complex Extraction from ReLU Networks using Edge Subdivision</title><link>http://arxiv.org/abs/2306.07212v1</link><description>A neural network consisting of piecewise affine building blocks, such asfully-connected layers and ReLU activations, is itself a piecewise affinefunction supported on a polyhedral complex. This complex has been previouslystudied to characterize theoretical properties of neural networks, but, inpractice, extracting it remains a challenge due to its high combinatorialcomplexity. A natural idea described in previous works is to subdivide theregions via intersections with hyperplanes induced by each neuron. However, weargue that this view leads to computational redundancy. Instead of regions, wepropose to subdivide edges, leading to a novel method for polyhedral complexextraction. A key to this are sign-vectors, which encode the combinatorialstructure of the complex. Our approach allows to use standard tensor operationson a GPU, taking seconds for millions of cells on a consumer grade machine.Motivated by the growing interest in neural shape representation, we use thespeed and differentiability of our method to optimize geometric properties ofthe complex. The code is available athttps://github.com/arturs-berzins/relu_edge_subdivision .</description><author>Arturs Berzins</author><pubDate>Mon, 12 Jun 2023 17:17:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07212v1</guid></item><item><title>Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow</title><link>http://arxiv.org/abs/2306.07209v1</link><description>Various industries such as finance, meteorology, and energy generate vastamounts of heterogeneous data every day. There is a natural demand for humansto manage, process, and display data efficiently. However, it necessitateslabor-intensive efforts and a high level of expertise for these data-relatedtasks. Considering that large language models (LLMs) have showcased promisingcapabilities in semantic understanding and reasoning, we advocate that thedeployment of LLMs could autonomously manage and process massive amounts ofdata while displaying and interacting in a human-friendly manner. Based on thisbelief, we propose Data-Copilot, an LLM-based system that connects numerousdata sources on one end and caters to diverse human demands on the other end.Acting like an experienced expert, Data-Copilot autonomously transforms rawdata into visualization results that best match the user's intent.Specifically, Data-Copilot autonomously designs versatile interfaces (tools)for data management, processing, prediction, and visualization. In real-timeresponse, it automatically deploys a concise workflow by invoking correspondinginterfaces step by step for the user's request. The interface design anddeployment processes are fully controlled by Data-Copilot itself, without humanassistance. Besides, we create a Data-Copilot demo that links abundant datafrom different domains (stock, fund, company, economics, and live news) andaccurately respond to diverse requests, serving as a reliable AI assistant.</description><author>Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang</author><pubDate>Mon, 12 Jun 2023 17:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07209v1</guid></item><item><title>Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference</title><link>http://arxiv.org/abs/2211.10526v3</link><description>Vision Transformers (ViTs) have shown impressive performance but stillrequire a high computation cost as compared to convolutional neural networks(CNNs), one reason is that ViTs' attention measures global similarities andthus has a quadratic complexity with the number of input tokens. Existingefficient ViTs adopt local attention (e.g., Swin) or linear attention (e.g.,Performer), which sacrifice ViTs' capabilities of capturing either global orlocal context. In this work, we ask an important research question: Can ViTslearn both global and local context while being more efficient duringinference? To this end, we propose a framework called Castling-ViT, whichtrains ViTs using both linear-angular attention and masked softmax-basedquadratic attention, but then switches to having only linear angular attentionduring ViT inference. Our Castling-ViT leverages angular kernels to measure thesimilarities between queries and keys via spectral angles. And we furthersimplify it with two techniques: (1) a novel linear-angular attentionmechanism: we decompose the angular kernels into linear terms and high-orderresiduals, and only keep the linear terms; and (2) we adopt two parameterizedmodules to approximate high-order residuals: a depthwise convolution and anauxiliary masked softmax attention to help learn both global and localinformation, where the masks for softmax attention are regularized to graduallybecome zeros and thus incur no overhead during ViT inference. Extensiveexperiments and ablation studies on three tasks consistently validate theeffectiveness of the proposed Castling-ViT, e.g., achieving up to a 1.8% higheraccuracy or 40% MACs reduction on ImageNet classification and 1.2 higher mAP onCOCO detection under comparable FLOPs, as compared to ViTs with vanillasoftmax-based attentions.</description><author>Haoran You, Yunyang Xiong, Xiaoliang Dai, Bichen Wu, Peizhao Zhang, Haoqi Fan, Peter Vajda, Yingyan, Lin</author><pubDate>Mon, 12 Jun 2023 17:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10526v3</guid></item><item><title>Valley: Video Assistant with Large Language model Enhanced abilitY</title><link>http://arxiv.org/abs/2306.07207v1</link><description>Recently, several multi-modal models have been developed for joint image andlanguage understanding, which have demonstrated impressive chat abilities byutilizing advanced large language models (LLMs). The process of developing suchmodels is straightforward yet effective. It involves pre-training an adaptationmodule to align the semantics of the vision encoder and language model,followed by fine-tuning on the instruction-following data. However, despite thesuccess of this pipeline in image and language understanding, its effectivenessin joint video and language understanding has not been widely explored. In thispaper, we aim to develop a novel multi-modal foundation model capable ofperceiving video, image, and language within a general framework. To achievethis goal, we introduce Valley: Video Assistant with Large Language modelEnhanced ability. Specifically, our proposed Valley model is designed with asimple projection module that bridges video, image, and language modalities,and is further unified with a multi-lingual LLM. We also collect multi-sourcevision-text pairs and adopt a spatio-temporal pooling strategy to obtain aunified vision encoding of video and image input for pre-training. Furthermore,we generate multi-task instruction-following video data, including multi-shotcaptions, long video descriptions, action recognition, causal relationshipinference, etc. To obtain the instruction-following data, we design diverserounds of task-oriented conversations between humans and videos, facilitated byChatGPT. Qualitative examples demonstrate that our proposed model has thepotential to function as a highly effective multilingual video assistant thatcan make complex video understanding scenarios easy. Code, data, and modelswill be available at https://github.com/RupertLuo/Valley.</description><author>Ruipu Luo, Ziwang Zhao, Min Yang, Junwei Dong, Minghui Qiu, Pengcheng Lu, Tao Wang, Zhongyu Wei</author><pubDate>Mon, 12 Jun 2023 17:11:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07207v1</guid></item><item><title>RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation</title><link>http://arxiv.org/abs/2306.07206v1</link><description>Endowing chatbots with a consistent persona is essential to an engagingconversation, yet it remains an unresolved challenge. In this work, we proposea new retrieval-enhanced approach for personalized response generation.Specifically, we design a hierarchical transformer retriever trained ondialogue domain data to perform personalized retrieval and a context-awareprefix encoder that fuses the retrieved information to the decoder moreeffectively. Extensive experiments on a real-world dataset demonstrate theeffectiveness of our model at generating more fluent and personalizedresponses. We quantitatively evaluate our model's performance under a suite ofhuman and automatic metrics and find it to be superior compared tostate-of-the-art baselines on English Reddit conversations.</description><author>Shuai Liu, Hyundong J. Cho, Marjorie Freedman, Xuezhe Ma, Jonathan May</author><pubDate>Mon, 12 Jun 2023 17:10:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07206v1</guid></item><item><title>Tight conditions for when the NTK approximation is valid</title><link>http://arxiv.org/abs/2305.13141v2</link><description>We study when the neural tangent kernel (NTK) approximation is valid fortraining a model with the square loss. In the lazy training setting of Chizatet al. 2019, we show that rescaling the model by a factor of $\alpha = O(T)$suffices for the NTK approximation to be valid until training time $T$. Ourbound is tight and improves on the previous bound of Chizat et al. 2019, whichrequired a larger rescaling factor of $\alpha = O(T^2)$.</description><author>Enric Boix-Adsera, Etai Littwin</author><pubDate>Mon, 12 Jun 2023 17:04:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13141v2</guid></item><item><title>LTCR: Long-Text Chinese Rumor Detection Dataset</title><link>http://arxiv.org/abs/2306.07201v1</link><description>The Long-Text Chinese Rumor detection dataset we developed is focusing on theidentification of misleading information in the context of rumor verification.Especially in the current era of the COVID-19 pandemic, false informationspread rapidly on social media platforms and can negatively impact people'shealth behaviors and responses to health emergencies. By providing a resourcefor accurate misinformation detection, the LTCR dataset offers a resource forimproving the identification of fake news, particularly longer and more complextexts. The dataset consists of 1,729 and 500 pieces of real and fake news,respectively. The average lengths of real and fake news are approximately 230and 152 characters. We also propose \method, Salience-aware Fake News DetectionModel, which achieves the highest accuracy (95.85%), fake news recall (90.91%)and F-score (90.60%) on the dataset.(https://github.com/Enderfga/DoubleCheck)</description><author>Ziyang Ma, Mengsha Liu, Guian Fang, Ying Shen</author><pubDate>Mon, 12 Jun 2023 17:03:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07201v1</guid></item><item><title>Fill-Up: Balancing Long-Tailed Data with Generative Models</title><link>http://arxiv.org/abs/2306.07200v1</link><description>Modern text-to-image synthesis models have achieved an exceptional level ofphotorealism, generating high-quality images from arbitrary text descriptions.In light of the impressive synthesis ability, several studies have exhibitedpromising results in exploiting generated data for image recognition. However,directly supplementing data-hungry situations in the real-world (e.g. few-shotor long-tailed scenarios) with existing approaches result in marginalperformance gains, as they suffer to thoroughly reflect the distribution of thereal data. Through extensive experiments, this paper proposes a new imagesynthesis pipeline for long-tailed situations using Textual Inversion. Thestudy demonstrates that generated images from textual-inverted text tokenseffectively aligns with the real domain, significantly enhancing therecognition ability of a standard ResNet50 backbone. We also show thatreal-world data imbalance scenarios can be successfully mitigated by filling upthe imbalanced data with synthetic images. In conjunction with techniques inthe area of long-tailed recognition, our method achieves state-of-the-artresults on standard long-tailed benchmarks when trained from scratch.</description><author>Joonghyuk Shin, Minguk Kang, Jaesik Park</author><pubDate>Mon, 12 Jun 2023 17:01:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07200v1</guid></item><item><title>A Survey of Vision-Language Pre-training from the Lens of Multimodal Machine Translation</title><link>http://arxiv.org/abs/2306.07198v1</link><description>Large language models such as BERT and the GPT series started a paradigmshift that calls for building general-purpose models via pre-training on largedatasets, followed by fine-tuning on task-specific datasets. There is now aplethora of large pre-trained models for Natural Language Processing andComputer Vision. Recently, we have seen rapid developments in the jointVision-Language space as well, where pre-trained models such as CLIP (Radfordet al., 2021) have demonstrated improvements in downstream tasks like imagecaptioning and visual question answering. However, surprisingly there iscomparatively little work on exploring these models for the task of multimodalmachine translation, where the goal is to leverage image/video modality intext-to-text translation. To fill this gap, this paper surveys the landscape oflanguage-and-vision pre-training from the lens of multimodal machinetranslation. We summarize the common architectures, pre-training objectives,and datasets from literature and conjecture what further is needed to makeprogress on multimodal machine translation.</description><author>Jeremy Gwinnup, Kevin Duh</author><pubDate>Mon, 12 Jun 2023 16:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07198v1</guid></item><item><title>AROID: Improving Adversarial Robustness through Online Instance-wise Data Augmentation</title><link>http://arxiv.org/abs/2306.07197v1</link><description>Deep neural networks are vulnerable to adversarial examples. Adversarialtraining (AT) is an effective defense against adversarial examples. However, ATis prone to overfitting which degrades robustness substantially. Recently, dataaugmentation (DA) was shown to be effective in mitigating robust overfitting ifappropriately designed and optimized for AT. This work proposes a new method toautomatically learn online, instance-wise, DA policies to improve robustgeneralization for AT. A novel policy learning objective, consisting ofVulnerability, Affinity and Diversity, is proposed and shown to be sufficientlyeffective and efficient to be practical for automatic DA generation during AT.This allows our method to efficiently explore a large search space for a moreeffective DA policy and evolve the policy as training progresses. Empirically,our method is shown to outperform or match all competitive DA methods acrossvarious model architectures (CNNs and ViTs) and datasets (CIFAR10, SVHN andImagenette). Our DA policy reinforced vanilla AT to surpass severalstate-of-the-art AT methods (with baseline DA) in terms of both accuracy androbustness. It can also be combined with those advanced AT methods to produce afurther boost in robustness.</description><author>Lin Li, Jianing Qiu, Michael Spratling</author><pubDate>Mon, 12 Jun 2023 16:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07197v1</guid></item><item><title>Retrieval-Enhanced Contrastive Vision-Text Models</title><link>http://arxiv.org/abs/2306.07196v1</link><description>Contrastive image-text models such as CLIP form the building blocks of manystate-of-the-art systems. While they excel at recognizing common genericconcepts, they still struggle on fine-grained entities which are rare, or evenabsent from the pre-training dataset. Hence, a key ingredient to their successhas been the use of large-scale curated pre-training data aiming at expandingthe set of concepts that they can memorize during the pre-training stage. Inthis work, we explore an alternative to encoding fine-grained knowledgedirectly into the model's parameters: we instead train the model to retrievethis knowledge from an external memory. Specifically, we propose to equipexisting vision-text models with the ability to refine their embedding withcross-modal retrieved information from a memory at inference time, whichgreatly improves their zero-shot predictions. Remarkably, we show that this canbe done with a light-weight, single-layer, fusion transformer on top of afrozen CLIP. Our experiments validate that our retrieval-enhanced contrastive(RECO) training improves CLIP performance substantially on several challengingfine-grained tasks: for example +10.9 on Stanford Cars, +10.2 on CUB-2011 and+7.3 on the recent OVEN benchmark.</description><author>Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid</author><pubDate>Mon, 12 Jun 2023 16:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07196v1</guid></item><item><title>Large language models and (non-)linguistic recursion</title><link>http://arxiv.org/abs/2306.07195v1</link><description>Recursion is one of the hallmarks of human language. While many designfeatures of language have been shown to exist in animal communication systems,recursion has not. Previous research shows that GPT-4 is the first largelanguage model (LLM) to exhibit metalinguistic abilities (Begu\v{s},D\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimedat eliciting and analyzing recursive behavior in LLMs, both linguistic andnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can bothproduce and analyze recursive structures. Thus, we present one of the firststudies investigating whether meta-linguistic awareness of recursion -- auniquely human cognitive property -- can emerge in transformers with a highnumber of parameters such as GPT-4.</description><author>Maksymilian Dąbkowski, Gašper Beguš</author><pubDate>Mon, 12 Jun 2023 16:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07195v1</guid></item><item><title>Weakly-Supervised Scientific Document Classification via Retrieval-Augmented Multi-Stage Training</title><link>http://arxiv.org/abs/2306.07193v1</link><description>Scientific document classification is a critical task for a wide range ofapplications, but the cost of obtaining massive amounts of human-labeled datacan be prohibitive. To address this challenge, we propose a weakly-supervisedapproach for scientific document classification using label names only. Inscientific domains, label names often include domain-specific concepts that maynot appear in the document corpus, making it difficult to match labels anddocuments precisely. To tackle this issue, we propose WANDER, which leveragesdense retrieval to perform matching in the embedding space to capture thesemantics of label names. We further design the label name expansion module toenrich the label name representations. Lastly, a self-training step is used torefine the predictions. The experiments on three datasets show that WANDERoutperforms the best baseline by 11.9% on average. Our code will be publishedat https://github.com/ritaranx/wander.</description><author>Ran Xu, Yue Yu, Joyce C. Ho, Carl Yang</author><pubDate>Mon, 12 Jun 2023 16:50:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07193v1</guid></item><item><title>Fair Learning to Rank with Distribution-free Risk Control</title><link>http://arxiv.org/abs/2306.07188v1</link><description>Learning to Rank (LTR) methods are vital in online economies, affecting usersand item providers. Fairness in LTR models is crucial to allocate exposureproportionally to item relevance. The deterministic ranking model can lead tounfair exposure distribution when items with the same relevance receiveslightly different scores. Stochastic LTR models, incorporating thePlackett-Luce (PL) model, address fairness issues but have limitations incomputational cost and performance guarantees. To overcome these limitations,we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RCleverages a pretrained scoring function to create a stochastic LTR model,eliminating the need for expensive training. Furthermore, FairLTR-RC providesfinite-sample guarantees on a user-specified utility using distribution-freerisk control framework. By additionally incorporating the Thresholded PL (TPL)model, we are able to achieve an effective trade-off between utility andfairness. Experimental results on several benchmark datasets demonstrate thatFairLTR-RC significantly improves fairness in widely-used deterministic LTRmodels while guaranteeing a specified level of utility.</description><author>Ruocheng Guo, Jean-François Ton, Yang Liu</author><pubDate>Mon, 12 Jun 2023 16:44:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07188v1</guid></item><item><title>Video-to-Music Recommendation using Temporal Alignment of Segments</title><link>http://arxiv.org/abs/2306.07187v1</link><description>We study cross-modal recommendation of music tracks to be used as soundtracksfor videos. This problem is known as the music supervision task. We build on aself-supervised system that learns a content association between music andvideo. In addition to the adequacy of content, adequacy of structure is crucialin music supervision to obtain relevant recommendations. We propose a novelapproach to significantly improve the system's performance usingstructure-aware recommendation. The core idea is to consider not only the fullaudio-video clips, but rather shorter segments for training and inference. Wefind that using semantic segments and ranking the tracks according to sequencealignment costs significantly improves the results. We investigate the impactof different ranking metrics and segmentation methods.</description><author>Laure Prétet, Gaël Richard, Clément Souchier, Geoffroy Peeters</author><pubDate>Mon, 12 Jun 2023 16:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07187v1</guid></item><item><title>CD-CTFM: A Lightweight CNN-Transformer Network for Remote Sensing Cloud Detection Fusing Multiscale Features</title><link>http://arxiv.org/abs/2306.07186v1</link><description>Clouds in remote sensing images inevitably affect information extraction,which hinder the following analysis of satellite images. Hence, cloud detectionis a necessary preprocessing procedure. However, the existing methods havenumerous calculations and parameters. In this letter, a lightweightCNN-Transformer network, CD-CTFM, is proposed to solve the problem. CD-CTFM isbased on encoder-decoder architecture and incorporates the attention mechanism.In the decoder part, we utilize a lightweight network combing CNN andTransformer as backbone, which is conducive to extract local and globalfeatures simultaneously. Moreover, a lightweight feature pyramid module isdesigned to fuse multiscale features with contextual information. In thedecoder part, we integrate a lightweight channel-spatial attention module intoeach skip connection between encoder and decoder, extracting low-level featureswhile suppressing irrelevant information without introducing many parameters.Finally, the proposed model is evaluated on two cloud datasets, 38-Cloud andMODIS. The results demonstrate that CD-CTFM achieves comparable accuracy as thestate-of-art methods. At the same time, CD-CTFM outperforms state-of-artmethods in terms of efficiency.</description><author>Wenxuan Ge, Xubing Yang, Li Zhang</author><pubDate>Mon, 12 Jun 2023 16:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07186v1</guid></item><item><title>The Effect of Masking Strategies on Knowledge Retention by Language Models</title><link>http://arxiv.org/abs/2306.07185v1</link><description>Language models retain a significant amount of world knowledge from theirpre-training stage. This allows knowledgeable models to be applied toknowledge-intensive tasks prevalent in information retrieval, such as rankingor question answering. Understanding how and which factual information isacquired by our models is necessary to build responsible models. However,limited work has been done to understand the effect of pre-training tasks onthe amount of knowledge captured and forgotten by language models duringpre-training. Building a better understanding of knowledge acquisition is thegoal of this paper. Therefore, we utilize a selection of pre-training tasks toinfuse knowledge into our model. In the following steps, we test the model'sknowledge retention by measuring its ability to answer factual questions. Ourexperiments show that masking entities and principled masking of correlatedspans based on pointwise mutual information lead to more factual knowledgebeing retained than masking random tokens. Our findings demonstrate that, likethe ability to perform a task, the (factual) knowledge acquired from beingtrained on that task is forgotten when a model is trained to perform anothertask (catastrophic forgetting) and how to prevent this phenomenon. To fosterreproducibility, the code, as well as the data used in this paper, are openlyavailable.</description><author>Jonas Wallat, Tianyi Zhang, Avishek Anand</author><pubDate>Mon, 12 Jun 2023 16:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07185v1</guid></item><item><title>Generative Pretraining for Black-Box Optimization</title><link>http://arxiv.org/abs/2206.10786v3</link><description>Many problems in science and engineering involve optimizing an expensiveblack-box function over a high-dimensional space. For such black-boxoptimization (BBO) problems, we typically assume a small budget for onlinefunction evaluations, but also often have access to a fixed, offline datasetfor pretraining. Prior approaches seek to utilize the offline data toapproximate the function or its inverse but are not sufficiently accurate farfrom the data distribution. We propose BONET, a generative framework forpretraining a novel black-box optimizer using offline datasets. In BONET, wetrain an autoregressive model on fixed-length trajectories derived from anoffline dataset. We design a sampling strategy to synthesize trajectories fromoffline data using a simple heuristic of rolling out monotonic transitions fromlow-fidelity to high-fidelity samples. Empirically, we instantiate BONET usinga causally masked Transformer and evaluate it on Design-Bench, where we rankthe best on average, outperforming state-of-the-art baselines.</description><author>Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, Aditya Grover</author><pubDate>Mon, 12 Jun 2023 16:32:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.10786v3</guid></item><item><title>Discrete Key-Value Bottleneck</title><link>http://arxiv.org/abs/2207.11240v3</link><description>Deep neural networks perform well on classification tasks where data streamsare i.i.d. and labeled data is abundant. Challenges emerge with non-stationarytraining data streams such as continual learning. One powerful approach thathas addressed this challenge involves pre-training of large encoders on volumesof readily available data, followed by task-specific tuning. Given a new task,however, updating the weights of these encoders is challenging as a largenumber of weights needs to be fine-tuned, and as a result, they forgetinformation about the previous tasks. In the present work, we propose a modelarchitecture to address this issue, building upon a discrete bottleneckcontaining pairs of separate and learnable key-value codes. Our paradigm willbe to encode; process the representation via a discrete bottleneck; and decode.Here, the input is fed to the pre-trained encoder, the output of the encoder isused to select the nearest keys, and the corresponding values are fed to thedecoder to solve the current task. The model can only fetch and re-use a sparsenumber of these key-value pairs during inference, enabling localized andcontext-dependent model updates. We theoretically investigate the ability ofthe discrete key-value bottleneck to minimize the effect of learning underdistribution shifts and show that it reduces the complexity of the hypothesisclass. We empirically verify the proposed method under challengingclass-incremental learning scenarios and show that the proposed model - withoutany task boundaries - reduces catastrophic forgetting across a wide variety ofpre-trained models, outperforming relevant baselines on this task.</description><author>Frederik Träuble, Anirudh Goyal, Nasim Rahaman, Michael Mozer, Kenji Kawaguchi, Yoshua Bengio, Bernhard Schölkopf</author><pubDate>Mon, 12 Jun 2023 16:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.11240v3</guid></item><item><title>Diffusion Models for Black-Box Optimization</title><link>http://arxiv.org/abs/2306.07180v1</link><description>The goal of offline black-box optimization (BBO) is to optimize an expensiveblack-box function using a fixed dataset of function evaluations. Prior worksconsider forward approaches that learn surrogates to the black-box function andinverse approaches that directly map function values to corresponding points inthe input domain of the black-box function. These approaches are limited by thequality of the offline dataset and the difficulty in learning one-to-manymappings in high dimensions, respectively. We propose Denoising DiffusionOptimization Models (DDOM), a new inverse approach for offline black-boxoptimization based on diffusion models. Given an offline dataset, DDOM learns aconditional generative model over the domain of the black-box functionconditioned on the function values. We investigate several design choices inDDOM, such as re-weighting the dataset to focus on high function values and theuse of classifier-free guidance at test-time to enable generalization tofunction values that can even exceed the dataset maxima. Empirically, weconduct experiments on the Design-Bench benchmark and show that DDOM achievesresults competitive with state-of-the-art baselines.</description><author>Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, Aditya Grover</author><pubDate>Mon, 12 Jun 2023 16:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07180v1</guid></item><item><title>Benchmarking Neural Network Training Algorithms</title><link>http://arxiv.org/abs/2306.07179v1</link><description>Training algorithms, broadly construed, are an essential part of every deeplearning pipeline. Training algorithm improvements that speed up trainingacross a wide variety of workloads (e.g., better update rules, tuningprotocols, learning rate schedules, or data selection schemes) could save time,save computational resources, and lead to better, more accurate, models.Unfortunately, as a community, we are currently unable to reliably identifytraining algorithm improvements, or even determine the state-of-the-arttraining algorithm. In this work, using concrete experiments, we argue thatreal progress in speeding up training requires new benchmarks that resolvethree basic challenges faced by empirical comparisons of training algorithms:(1) how to decide when training is complete and precisely measure trainingtime, (2) how to handle the sensitivity of measurements to exact workloaddetails, and (3) how to fairly compare algorithms that require hyperparametertuning. In order to address these challenges, we introduce a new, competitive,time-to-result benchmark using multiple workloads running on fixed hardware,the AlgoPerf: Training Algorithms benchmark. Our benchmark includes a set ofworkload variants that make it possible to detect benchmark submissions thatare more robust to workload changes than current widely-used methods. Finally,we evaluate baseline submissions constructed using various optimizers thatrepresent current practice, as well as other optimizers that have recentlyreceived attention in the literature. These baseline results collectivelydemonstrate the feasibility of our benchmark, show that non-trivial gapsbetween methods exist, and set a provisional state-of-the-art for futurebenchmark submissions to try and surpass.</description><author>George E. Dahl, Frank Schneider, Zachary Nado, Naman Agarwal, Chandramouli Shama Sastry, Philipp Hennig, Sourabh Medapati, Runa Eschenhagen, Priya Kasimbeg, Daniel Suo, Juhan Bae, Justin Gilmer, Abel L. Peirson, Bilal Khan, Rohan Anil, Mike Rabbat, Shankar Krishnan, Daniel Snider, Ehsan Amid, Kongtao Chen, Chris J. Maddison, Rakshith Vasudev, Michal Badura, Ankush Garg, Peter Mattson</author><pubDate>Mon, 12 Jun 2023 16:21:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07179v1</guid></item><item><title>Frequency-Based Vulnerability Analysis of Deep Learning Models against Image Corruptions</title><link>http://arxiv.org/abs/2306.07178v1</link><description>Deep learning models often face challenges when handling real-world imagecorruptions. In response, researchers have developed image corruption datasetsto evaluate the performance of deep neural networks in handling suchcorruptions. However, these datasets have a significant limitation: they do notaccount for all corruptions encountered in real-life scenarios. To address thisgap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed toidentify the specific types of corruptions that can cause models to fail. Ouralgorithm identifies the combination of image frequency components that rendera model susceptible to misclassification while preserving the semanticsimilarity to the original image. We find that even state-of-the-art modelstrained to be robust against known common corruptions struggle against the lowvisibility-based corruptions crafted by MUFIA. This highlights the need formore comprehensive approaches to enhance model robustness against a wider rangeof real-world image corruptions.</description><author>Harshitha Machiraju, Michael H. Herzog, Pascal Frossard</author><pubDate>Mon, 12 Jun 2023 16:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07178v1</guid></item><item><title>Unbalanced Optimal Transport meets Sliced-Wasserstein</title><link>http://arxiv.org/abs/2306.07176v1</link><description>Optimal transport (OT) has emerged as a powerful framework to compareprobability measures, a fundamental task in many statistical and machinelearning problems. Substantial advances have been made over the last decade indesigning OT variants which are either computationally and statistically moreefficient, or more robust to the measures and datasets to compare. Among them,sliced OT distances have been extensively used to mitigate optimal transport'scubic algorithmic complexity and curse of dimensionality. In parallel,unbalanced OT was designed to allow comparisons of more general positivemeasures, while being more robust to outliers. In this paper, we propose tocombine these two concepts, namely slicing and unbalanced OT, to develop ageneral framework for efficiently comparing positive measures. We propose twonew loss functions based on the idea of slicing unbalanced OT, and study theirinduced topology and statistical properties. We then develop a fastFrank-Wolfe-type algorithm to compute these loss functions, and show that theresulting methodology is modular as it encompasses and extends prior relatedwork. We finally conduct an empirical analysis of our loss functions andmethodology on both synthetic and real datasets, to illustrate their relevanceand applicability.</description><author>Thibault Séjourné, Clément Bonet, Kilian Fatras, Kimia Nadjahi, Nicolas Courty</author><pubDate>Mon, 12 Jun 2023 16:15:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07176v1</guid></item><item><title>Augmenting Language Models with Long-Term Memory</title><link>http://arxiv.org/abs/2306.07174v1</link><description>Existing large language models (LLMs) can only afford fix-sized inputs due tothe input length limit, preventing them from utilizing rich long-contextinformation from past inputs. To address this, we propose a framework, LanguageModels Augmented with Long-Term Memory (LongMem), which enables LLMs tomemorize long history. We design a novel decoupled network architecture withthe original backbone LLM frozen as a memory encoder and an adaptive residualside-network as a memory retriever and reader. Such a decoupled memory designcan easily cache and update long-term past contexts for memory retrievalwithout suffering from memory staleness. Enhanced with memory-augmentedadaptation training, LongMem can thus memorize long past context and uselong-term memory for language modeling. The proposed memory retrieval modulecan handle unlimited-length context in its memory bank to benefit variousdownstream tasks. Typically, LongMem can enlarge the long-form memory to 65ktokens and thus cache many-shot extra demonstration examples as long-formmemory for in-context learning. Experiments show that our method outperformsstrong long-context models on ChapterBreak, a challenging long-context modelingbenchmark, and achieves remarkable improvements on memory-augmented in-contextlearning over LLMs. The results demonstrate that the proposed method iseffective in helping language models to memorize and utilize long-formcontents. Our code is open-sourced at https://aka.ms/LongMem.</description><author>Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, Furu Wei</author><pubDate>Mon, 12 Jun 2023 16:13:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07174v1</guid></item><item><title>Echoes of Biases: How Stigmatizing Language Affects AI Performance</title><link>http://arxiv.org/abs/2305.10201v4</link><description>Electronic health records (EHRs) serve as an essential data source for theenvisioned artificial intelligence (AI)-driven transformation in healthcare.However, clinician biases reflected in EHR notes can lead to AI modelsinheriting and amplifying these biases, perpetuating health disparities. Thisstudy investigates the impact of stigmatizing language (SL) in EHR notes onmortality prediction using a Transformer-based deep learning model andexplainable AI (XAI) techniques. Our findings demonstrate that SL written byclinicians adversely affects AI performance, particularly so for blackpatients, highlighting SL as a source of racial disparity in AI modeldevelopment. To explore an operationally efficient way to mitigate SL's impact,we investigate patterns in the generation of SL through a clinicians'collaborative network, identifying central clinicians as having a strongerimpact on racial disparity in the AI model. We find that removing SL written bycentral clinicians is a more efficient bias reduction strategy than eliminatingall SL in the entire corpus of data. This study provides actionable insightsfor responsible AI development and contributes to understanding clinicianbehavior and EHR note writing in healthcare.</description><author>Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal</author><pubDate>Mon, 12 Jun 2023 16:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10201v4</guid></item><item><title>Shapley Value on Probabilistic Classifiers</title><link>http://arxiv.org/abs/2306.07171v1</link><description>Data valuation has become an increasingly significant discipline in datascience due to the economic value of data. In the context of machine learning(ML), data valuation methods aim to equitably measure the contribution of eachdata point to the utility of an ML model. One prevalent method is Shapleyvalue, which helps identify data points that are beneficial or detrimental toan ML model. However, traditional Shapley-based data valuation methods may noteffectively distinguish between beneficial and detrimental training data pointsfor probabilistic classifiers. In this paper, we propose Probabilistic Shapley(P-Shapley) value by constructing a probability-wise utility function thatleverages the predicted class probabilities of probabilistic classifiers ratherthan binarized prediction results in the traditional Shapley value. We alsooffer several activation functions for confidence calibration to effectivelyquantify the marginal contribution of each data point to the probabilisticclassifiers. Extensive experiments on four real-world datasets demonstrate theeffectiveness of our proposed P-Shapley value in evaluating the importance ofdata for building a high-usability and trustworthy ML model.</description><author>Xiang Li, Haocheng Xia, Jinfei Liu</author><pubDate>Mon, 12 Jun 2023 16:09:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07171v1</guid></item><item><title>Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning</title><link>http://arxiv.org/abs/2306.07170v1</link><description>Social determinants of health (SDOH) documented in the electronic healthrecord through unstructured text are increasingly being studied to understandhow SDOH impacts patient health outcomes. In this work, we utilize the SocialHistory Annotation Corpus (SHAC), a multi-institutional corpus of de-identifiedsocial history sections annotated for SDOH, including substance use,employment, and living status information. We explore the automatic extractionof SDOH information with SHAC in both standoff and inline annotation formatsusing GPT-4 in a one-shot prompting setting. We compare GPT-4 extractionperformance with a high-performing supervised approach and perform thorougherror analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 onthe SHAC test set, similar to the 7th best-performing system among all teams inthe n2c2 challenge with SHAC.</description><author>Giridhar Kaushik Ramachandran, Yujuan Fu, Bin Han, Kevin Lybarger, Nicholas J Dobbins, Özlem Uzuner, Meliha Yetisgen</author><pubDate>Mon, 12 Jun 2023 16:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07170v1</guid></item><item><title>Explainable AI and Machine Learning Towards Human Gait Deterioration Analysis</title><link>http://arxiv.org/abs/2306.07165v1</link><description>Gait analysis, an expanding research area, employs non invasive sensors andmachine learning techniques for a range of applicatio ns. In this study, weconcentrate on gait analysis for detecting cognitive decline in Parkinson'sdisease (PD) and under dual task conditions. Using convolutional neuralnetworks (CNNs) and explainable machine learning, we objectively analyze gaitdata and associate findings with clinically relevant biomarkers. This isaccomplished by connecting machine learning outputs to decisions based on humanvisual observations or derived quantitative gait parameters, which are testedand routinely implemented in curr ent healthcare practice. Our analysis of gaitdeterioration due to cognitive decline in PD enables robust results using theproposed methods for assessing PD severity from ground reaction force (GRF)data. We achieved classification accuracies of 98% F1 sc ores for eachPhysioNet.org dataset and 95.5% F1 scores for the combined PhysioNet dataset.By linking clinically observable features to the model outputs, we demonstratethe impact of PD severity on gait. Furthermore, we explore the significance ofcognit ive load in healthy gait analysis, resulting in robust classificationaccuracies of 100% F1 scores for subject identity verification. We alsoidentify weaker features crucial for model predictions using Layer WiseRelevance Propagation. A notable finding o f this study reveals that cognitivedeterioration's effect on gait influences body balance and foot landing/liftingdynamics in both classification cases: cognitive load in healthy gait andcognitive decline in PD gait.</description><author>Abdullah Alharthi</author><pubDate>Mon, 12 Jun 2023 15:53:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07165v1</guid></item><item><title>General Transformation for Consistent Online Approximation Algorithms</title><link>http://arxiv.org/abs/2306.07163v1</link><description>We introduce a transformation framework that can be utilized to developonline algorithms with low $\epsilon$-approximate regret in the random-ordermodel from offline approximation algorithms. We first give a general reductiontheorem that transforms an offline approximation algorithm with low averagesensitivity to an online algorithm with low $\epsilon$-approximate regret. Wethen demonstrate that offline approximation algorithms can be transformed intoa low-sensitivity version using a coreset construction method. To showcase theversatility of our approach, we apply it to various problems, including online$(k,z)$-clustering, online matrix approximation, and online regression, andsuccessfully achieve polylogarithmic $\epsilon$-approximate regret for eachproblem. Moreover, we show that in all three cases, our algorithm also enjoyslow inconsistency, which may be desired in some online applications.</description><author>Jing Dong, Yuichi Yoshida</author><pubDate>Mon, 12 Jun 2023 15:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07163v1</guid></item><item><title>Stochastic Gradient Descent and Anomaly of Variance-flatness Relation in Artificial Neural Networks</title><link>http://arxiv.org/abs/2207.04932v2</link><description>Stochastic gradient descent (SGD), a widely used algorithm in deep-learningneural networks has attracted continuing studies for the theoretical principlesbehind its success. A recent work reports an anomaly (inverse) relation betweenthe variance of neural weights and the landscape flatness of the loss functiondriven under SGD [Feng &amp; Tu, PNAS 118, 0027 (2021)]. To investigate thisseemingly violation of statistical physics principle, the properties of SGDnear fixed points are analysed via a dynamic decomposition method. Our approachrecovers the true "energy" function under which the universal Boltzmanndistribution holds. It differs from the cost function in general and resolvesthe paradox raised by the the anomaly. The study bridges the gap between theclassical statistical mechanics and the emerging discipline of artificialintelligence, with potential for better algorithms to the latter.</description><author>Xia Xiong, Yong-Cong Chen, Chunxiao Shi, Ping Ao</author><pubDate>Mon, 12 Jun 2023 15:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.04932v2</guid></item><item><title>Semantic Information Recovery in Wireless Networks</title><link>http://arxiv.org/abs/2204.13366v4</link><description>Motivated by the recent success of Machine Learning (ML) tools in wirelesscommunications, the idea of semantic communication by Weaver from 1949 hasgained attention. It breaks with Shannon's classic design paradigm by aiming totransmit the meaning of a message, i.e., semantics, rather than its exactversion and thus allows for savings in information rate. In this work, weextend the fundamental approach from Basu et al. for modeling semantics to thecomplete communications Markov chain. Thus, we model semantics by means ofhidden random variables and define the semantic communication task as thedata-reduced and reliable transmission of messages over a communication channelsuch that semantics is best preserved. We cast this task as an end-to-endInformation Bottleneck problem, allowing for compression while preservingrelevant information most. As a solution approach, we propose the ML-basedsemantic communication system SINFONY and use it for a distributed multipointscenario: SINFONY communicates the meaning behind multiple messages that areobserved at different senders to a single receiver for semantic recovery. Weanalyze SINFONY by processing images as message examples. Numerical resultsreveal a tremendous rate-normalized SNR shift up to 20 dB compared toclassically designed communication systems.</description><author>Edgar Beck, Carsten Bockelmann, Armin Dekorsy</author><pubDate>Mon, 12 Jun 2023 15:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.13366v4</guid></item><item><title>On the Computation-Communication Trade-Off with A Flexible Gradient Tracking Approach</title><link>http://arxiv.org/abs/2306.07159v1</link><description>We propose a flexible gradient tracking approach with adjustable computationand communication steps for solving distributed stochastic optimization problemover networks. The proposed method allows each node to perform multiple localgradient updates and multiple inter-node communications in each round, aimingto strike a balance between computation and communication costs according tothe properties of objective functions and network topology in non-i.i.d.settings. Leveraging a properly designed Lyapunov function, we derive both thecomputation and communication complexities for achieving arbitrary accuracy onsmooth and strongly convex objective functions. Our analysis demonstrates sharpdependence of the convergence performance on graph topology and properties ofobjective functions, highlighting the trade-off between computation andcommunication. Numerical experiments are conducted to validate our theoreticalfindings.</description><author>Yan Huang, Jinming Xu</author><pubDate>Mon, 12 Jun 2023 15:46:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07159v1</guid></item><item><title>Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations</title><link>http://arxiv.org/abs/2306.05880v2</link><description>Although widely explored, time series modeling continues to encountersignificant challenges when confronted with real-world data. We propose a novelmodeling approach leveraging Implicit Neural Representations (INR). Thisapproach enables us to effectively capture the continuous aspect of time seriesand provides a natural solution to recurring modeling issues such as handlingmissing data, dealing with irregular sampling, or unaligned observations frommultiple sensors. By introducing conditional modulation of INR parameters andleveraging meta-learning techniques, we address the issue of generalization toboth unseen samples and time window shifts. Through extensive experimentation,our model demonstrates state-of-the-art performance in forecasting andimputation tasks, while exhibiting flexibility in handling a wide range ofchallenging scenarios that competing models cannot.</description><author>Etienne Le Naour, Louis Serrano, Léon Migus, Yuan Yin, Ghislain Agoua, Nicolas Baskiotis, Patrick Gallinari, Vincent Guigue</author><pubDate>Mon, 12 Jun 2023 15:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05880v2</guid></item><item><title>Riemannian Laplace approximations for Bayesian neural networks</title><link>http://arxiv.org/abs/2306.07158v1</link><description>Bayesian neural networks often approximate the weight-posterior with aGaussian distribution. However, practical posteriors are often, even locally,highly non-Gaussian, and empirical performance deteriorates. We propose asimple parametric approximate posterior that adapts to the shape of the trueposterior through a Riemannian metric that is determined by the log-posteriorgradient. We develop a Riemannian Laplace approximation where samples naturallyfall into weight-regions with low negative log-posterior. We show that thesesamples can be drawn by solving a system of ordinary differential equations,which can be done efficiently by leveraging the structure of the Riemannianmetric and automatic differentiation. Empirically, we demonstrate that ourapproach consistently improves over the conventional Laplace approximationacross tasks. We further show that, unlike the conventional Laplaceapproximation, our method is not overly sensitive to the choice of prior, whichalleviates a practical pitfall of current approaches.</description><author>Federico Bergamin, Pablo Moreno-Muñoz, Søren Hauberg, Georgios Arvanitidis</author><pubDate>Mon, 12 Jun 2023 15:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07158v1</guid></item><item><title>InstructP2P: Learning to Edit 3D Point Clouds with Text Instructions</title><link>http://arxiv.org/abs/2306.07154v1</link><description>Enhancing AI systems to perform tasks following human instructions cansignificantly boost productivity. In this paper, we present InstructP2P, anend-to-end framework for 3D shape editing on point clouds, guided by high-leveltextual instructions. InstructP2P extends the capabilities of existing methodsby synergizing the strengths of a text-conditioned point cloud diffusion model,Point-E, and powerful language models, enabling color and geometry editingusing language instructions. To train InstructP2P, we introduce a new shapeediting dataset, constructed by integrating a shape segmentation dataset,off-the-shelf shape programs, and diverse edit instructions generated by alarge language model, ChatGPT. Our proposed method allows for editing bothcolor and geometry of specific regions in a single forward pass, while leavingother regions unaffected. In our experiments, InstructP2P shows generalizationcapabilities, adapting to novel shape categories and instructions, despitebeing trained on a limited amount of data.</description><author>Jiale Xu, Xintao Wang, Yan-Pei Cao, Weihao Cheng, Ying Shan, Shenghua Gao</author><pubDate>Mon, 12 Jun 2023 15:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07154v1</guid></item><item><title>Measuring Sentiment Bias in Machine Translation</title><link>http://arxiv.org/abs/2306.07152v1</link><description>Biases induced to text by generative models have become an increasingly largetopic in recent years. In this paper we explore how machine translation mightintroduce a bias in sentiments as classified by sentiment analysis models. Forthis, we compare three open access machine translation models for fivedifferent languages on two parallel corpora to test if the translation processcauses a shift in sentiment classes recognized in the texts. Though ourstatistic test indicate shifts in the label probability distributions, we findnone that appears consistent enough to assume a bias induced by the translationprocess.</description><author>Kai Hartung, Aaricia Herygers, Shubham Kurlekar, Khabbab Zakaria, Taylan Volkan, Sören Gröttrup, Munir Georges</author><pubDate>Mon, 12 Jun 2023 15:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07152v1</guid></item><item><title>Evolving Testing Scenario Generation Method and Intelligence Evaluation Framework for Automated Vehicles</title><link>http://arxiv.org/abs/2306.07142v1</link><description>Interaction between the background vehicles (BVs) and automated vehicles(AVs) in scenario-based testing plays a critical role in evaluating theintelligence of the AVs. Current testing scenarios typically employ predefinedor scripted BVs, which inadequately reflect the complexity of human-like socialbehaviors in real-world driving scenarios, and also lack a systematic metricfor evaluating the comprehensive intelligence of AVs. Therefore, this paperproposes an evolving scenario generation method that utilizes deepreinforcement learning (DRL) to create human-like BVs for testing andintelligence evaluation of AVs. Firstly, a class of driver models withhuman-like competitive, cooperative, and mutual driving motivations isdesigned. Then, utilizing an improved "level-k" training procedure, the threedistinct driver models acquire game-based interactive driving policies. Andthese models are assigned to BVs for generating evolving scenarios in which allBVs can interact continuously and evolve diverse contents. Next, a frameworkincluding safety, driving efficiency, and interaction utility are presented toevaluate and quantify the intelligence performance of 3 systems under test(SUTs), indicating the effectiveness of the evolving scenario for intelligencetesting. Finally, the complexity and fidelity of the proposed evolving testingscenario are validated. The results demonstrate that the proposed evolvingscenario exhibits the highest level of complexity compared to other baselinescenarios and has more than 85% similarity to naturalistic driving data. Thishighlights the potential of the proposed method to facilitate the developmentand evaluation of high-level AVs in a realistic and challenging environment.</description><author>Yining Ma, Wei Jiang, Lingtong Zhang, Junyi Chen, Hong Wang, Chen Lv, Xuesong Wang, Lu Xiong</author><pubDate>Mon, 12 Jun 2023 15:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07142v1</guid></item><item><title>Decentralized SGD and Average-direction SAM are Asymptotically Equivalent</title><link>http://arxiv.org/abs/2306.02913v2</link><description>Decentralized stochastic gradient descent (D-SGD) allows collaborativelearning on massive devices simultaneously without the control of a centralserver. However, existing theories claim that decentralization invariablyundermines generalization. In this paper, we challenge the conventional beliefand present a completely new perspective for understanding decentralizedlearning. We prove that D-SGD implicitly minimizes the loss function of anaverage-direction Sharpness-aware minimization (SAM) algorithm under generalnon-convex non-$\beta$-smooth settings. This surprising asymptotic equivalencereveals an intrinsic regularization-optimization trade-off and three advantagesof decentralization: (1) there exists a free uncertainty evaluation mechanismin D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradientsmoothing effect; and (3) the sharpness regularization effect of D-SGD does notdecrease as total batch size increases, which justifies the potentialgeneralization benefit of D-SGD over centralized SGD (C-SGD) in large-batchscenarios.</description><author>Tongtian Zhu, Fengxiang He, Kaixuan Chen, Mingli Song, Dacheng Tao</author><pubDate>Mon, 12 Jun 2023 15:25:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02913v2</guid></item><item><title>Evaluating the Social Impact of Generative AI Systems in Systems and Society</title><link>http://arxiv.org/abs/2306.05949v2</link><description>Generative AI systems across modalities, ranging from text, image, audio, andvideo, have broad social impacts, but there exists no official standard formeans of evaluating those impacts and which impacts should be evaluated. Wemove toward a standard approach in evaluating a generative AI system for anymodality, in two overarching categories: what is able to be evaluated in a basesystem that has no predetermined application and what is able to be evaluatedin society. We describe specific social impact categories and how to approachand conduct evaluations in the base technical system, then in people andsociety. Our framework for a base system defines seven categories of socialimpact: bias, stereotypes, and representational harms; cultural values andsensitive content; disparate performance; privacy and data protection;financial costs; environmental costs; and data and content moderation laborcosts. Suggested methods for evaluation apply to all modalities and analyses ofthe limitations of existing evaluations serve as a starting point for necessaryinvestment in future evaluations. We offer five overarching categories for whatis able to be evaluated in society, each with their own subcategories:trustworthiness and autonomy; inequality, marginalization, and violence;concentration of authority; labor and creativity; and ecosystem andenvironment. Each subcategory includes recommendations for mitigating harm. Weare concurrently crafting an evaluation repository for the AI researchcommunity to contribute existing evaluations along the given categories. Thisversion will be updated following a CRAFT session at ACM FAccT 2023.</description><author>Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Hal Daumé III, Jesse Dodge, Ellie Evans, Sara Hooker, Yacine Jernite, Alexandra Sasha Luccioni, Alberto Lusoli, Margaret Mitchell, Jessica Newman, Marie-Therese Png, Andrew Strait, Apostol Vassilev</author><pubDate>Mon, 12 Jun 2023 15:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05949v2</guid></item><item><title>Revisiting Weighted Aggregation in Federated Learning with Neural Networks</title><link>http://arxiv.org/abs/2302.10911v4</link><description>In federated learning (FL), weighted aggregation of local models is conductedto generate a global model, and the aggregation weights are normalized (the sumof weights is 1) and proportional to the local data sizes. In this paper, werevisit the weighted aggregation process and gain new insights into thetraining dynamics of FL. First, we find that the sum of weights can be smallerthan 1, causing global weight shrinking effect (analogous to weight decay) andimproving generalization. We explore how the optimal shrinking factor isaffected by clients' data heterogeneity and local epochs. Second, we dive intothe relative aggregation weights among clients to depict the clients'importance. We develop client coherence to study the learning dynamics and finda critical point that exists. Before entering the critical point, more coherentclients play more essential roles in generalization. Based on the aboveinsights, we propose an effective method for Federated Learning with LearnableAggregation Weights, named as FedLAW. Extensive experiments verify that ourmethod can improve the generalization of the global model by a large margin ondifferent datasets and models.</description><author>Zexi Li, Tao Lin, Xinyi Shang, Chao Wu</author><pubDate>Mon, 12 Jun 2023 15:19:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10911v4</guid></item><item><title>On the Amplification of Linguistic Bias through Unintentional Self-reinforcement Learning by Generative Language Models -- A Perspective</title><link>http://arxiv.org/abs/2306.07135v1</link><description>Generative Language Models (GLMs) have the potential to significantly shapeour linguistic landscape due to their expansive use in various digitalapplications. However, this widespread adoption might inadvertently trigger aself-reinforcement learning cycle that can amplify existing linguistic biases.This paper explores the possibility of such a phenomenon, where the initialbiases in GLMs, reflected in their generated text, can feed into the learningmaterial of subsequent models, thereby reinforcing and amplifying these biases.Moreover, the paper highlights how the pervasive nature of GLMs might influencethe linguistic and cognitive development of future generations, as they mayunconsciously learn and reproduce these biases. The implications of thispotential self-reinforcement cycle extend beyond the models themselves,impacting human language and discourse. The advantages and disadvantages ofthis bias amplification are weighed, considering educational benefits and easeof future GLM learning against threats to linguistic diversity and dependenceon initial GLMs. This paper underscores the need for rigorous research tounderstand and address these issues. It advocates for improved modeltransparency, bias-aware training techniques, development of methods todistinguish between human and GLM-generated text, and robust measures forfairness and bias evaluation in GLMs. The aim is to ensure the effective, safe,and equitable use of these powerful technologies, while preserving the richnessand diversity of human language.</description><author>Minhyeok Lee</author><pubDate>Mon, 12 Jun 2023 15:17:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07135v1</guid></item><item><title>Collaborative Robotic Biopsy with Trajectory Guidance and Needle Tip Force Feedback</title><link>http://arxiv.org/abs/2306.07129v1</link><description>The diagnostic value of biopsies is highly dependent on the placement ofneedles. Robotic trajectory guidance has been shown to improve needlepositioning, but feedback for real-time navigation is limited. Haptic displayof needle tip forces can provide rich feedback for needle navigation byenabling localization of tissue structures along the insertion path. We presenta collaborative robotic biopsy system that combines trajectory guidance withkinesthetic feedback to assist the physician in needle placement. The robotaligns the needle while the insertion is performed in collaboration with amedical expert who controls the needle position on site. We present a needledesign that senses forces at the needle tip based on optical coherencetomography and machine learning for real-time data processing. Our roboticsetup allows operators to sense deep tissue interfaces independent offrictional forces to improve needle placement relative to a desired targetstructure. We first evaluate needle tip force sensing in ex-vivo tissue in aphantom study. We characterize the tip forces during insertions with constantvelocity and demonstrate the ability to detect tissue interfaces in acollaborative user study. Participants are able to detect 91% of ex-vivo tissueinterfaces based on needle tip force feedback alone. Finally, we demonstratethat even smaller, deep target structures can be accurately sampled byperforming post-mortem in situ biopsies of the pancreas.</description><author>Robin Mieling, Maximilian Neidhardt, Sarah Latus, Carolin Stapper, Stefan Gerlach, Inga Kniep, Axel Heinemann, Benjamin Ondruschka, Alexander Schlaefer</author><pubDate>Mon, 12 Jun 2023 15:07:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07129v1</guid></item><item><title>LLM as A Robotic Brain: Unifying Egocentric Memory and Control</title><link>http://arxiv.org/abs/2304.09349v4</link><description>Embodied AI focuses on the study and development of intelligent systems thatpossess a physical or virtual embodiment (i.e. robots) and are able todynamically interact with their environment. Memory and control are the twoessential parts of an embodied system and usually require separate frameworksto model each of them. In this paper, we propose a novel and generalizableframework called LLM-Brain: using Large-scale Language Model as a robotic brainto unify egocentric memory and control. The LLM-Brain framework integratesmultiple multimodal language models for robotic tasks, utilizing a zero-shotlearning approach. All components within LLM-Brain communicate using naturallanguage in closed-loop multi-round dialogues that encompass perception,planning, control, and memory. The core of the system is an embodied LLM tomaintain egocentric memory and control the robot. We demonstrate LLM-Brain byexamining two downstream tasks: active exploration and embodied questionanswering. The active exploration tasks require the robot to extensivelyexplore an unknown environment within a limited number of actions. Meanwhile,the embodied question answering tasks necessitate that the robot answersquestions based on observations acquired during prior explorations.</description><author>Jinjie Mai, Jun Chen, Bing Li, Guocheng Qian, Mohamed Elhoseiny, Bernard Ghanem</author><pubDate>Mon, 12 Jun 2023 15:07:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09349v4</guid></item><item><title>Meta-Learning Priors for Safe Bayesian Optimization</title><link>http://arxiv.org/abs/2210.00762v3</link><description>In robotics, optimizing controller parameters under safety constraints is animportant challenge. Safe Bayesian optimization (BO) quantifies uncertainty inthe objective and constraints to safely guide exploration in such settings.Hand-designing a suitable probabilistic model can be challenging, however. Inthe presence of unknown safety constraints, it is crucial to choose reliablemodel hyper-parameters to avoid safety violations. Here, we propose adata-driven approach to this problem by meta-learning priors for safe BO fromoffline data. We build on a meta-learning algorithm, F-PACOH, capable ofproviding reliable uncertainty quantification in settings of data scarcity. Ascore contribution, we develop a novel framework for choosing safety-compliantpriors in a data-riven manner via empirical uncertainty metrics and a frontiersearch algorithm. On benchmark functions and a high-precision motion system, wedemonstrate that our meta-learned priors accelerate the convergence of safe BOapproaches while maintaining safety.</description><author>Jonas Rothfuss, Christopher Koenig, Alisa Rupenyan, Andreas Krause</author><pubDate>Mon, 12 Jun 2023 15:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.00762v3</guid></item><item><title>Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases</title><link>http://arxiv.org/abs/2303.05470v3</link><description>The problem of spurious correlations (SCs) arises when a classifier relies onnon-predictive features that happen to be correlated with the labels in thetraining data. For example, a classifier may misclassify dog breeds based onthe background of dog images. This happens when the backgrounds are correlatedwith other breeds in the training data, leading to misclassifications duringtest time. Previous SC benchmark datasets suffer from varying issues, e.g.,over-saturation or only containing one-to-one (O2O) SCs, but no many-to-many(M2M) SCs arising between groups of spurious attributes and classes. In thispaper, we present \benchmark-\{O2O, M2M\}-\{Easy, Medium, Hard\}, an imageclassification benchmark suite containing spurious correlations between classesand backgrounds. To create this dataset, we employ a text-to-image model togenerate photo-realistic images and an image captioning model to filter outunsuitable ones. The resulting dataset is of high quality and containsapproximately 152k images. Our experimental results demonstrate thatstate-of-the-art group robustness methods struggle with \benchmark, mostnotably on the Hard-splits with none of them getting over $70\%$ accuracy onthe hardest split using a ResNet50 pretrained on ImageNet. By examining modelmisclassifications, we detect reliances on spurious backgrounds, demonstratingthat our dataset provides a significant challenge.</description><author>Aengus Lynch, Gbètondji J-S Dovonon, Jean Kaddour, Ricardo Silva</author><pubDate>Mon, 12 Jun 2023 15:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05470v3</guid></item><item><title>A Gamified Interaction with a Humanoid Robot to explain Therapeutic Procedures in Pediatric Asthma</title><link>http://arxiv.org/abs/2306.04422v2</link><description>In chronic diseases, obtaining a correct diagnosis and providing the mostappropriate treatments often is not enough to guarantee an improvement of theclinical condition of a patient. Poor adherence to medical prescriptionsconstitutes one of the main causes preventing achievement of therapeutic goals.This is generally true especially for certain diseases and specific targetpatients, such as children. An engaging and entertaining technology can beexploited in support of clinical practices to achieve better health outcomes.Our assumption is that a gamified session with a humanoid robot, compared tothe usual methodologies for therapeutic education, can be more incisive inlearning the correct inhalation procedure in children affected by asthma. Inthis perspective, we describe an interactive module implemented on the Pepperrobotic platform and the setting of a study that was planned in 2020 to be heldat the Pneumoallergology Pediatric clinic of CNR in Palermo. The study wascanceled due to the COVID-19 pandemic. Our long-term goal is to assess, bymeans of a qualitative-quantitative survey plan, the impact of such aneducational action, evaluating possible improvement in the adherence to thetreatment.</description><author>Laura Montalbano, Agnese Augello, Giovanni Pilato, Stefania La Grutta</author><pubDate>Mon, 12 Jun 2023 15:04:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04422v2</guid></item><item><title>Argumentative Characterizations of (Extended) Disjunctive Logic Programs</title><link>http://arxiv.org/abs/2306.07126v1</link><description>This paper continues an established line of research about the relationsbetween argumentation theory, particularly assumption-based argumentation, anddifferent kinds of logic programs. In particular, we extend known result ofCaminada, Schultz and Toni by showing that assumption-based argumentation canrepresent not only normal logic programs, but also disjunctive logic programsand their extensions. For this, we consider some inference rules fordisjunction that the core logic of the argumentation frameworks should respect,and show the correspondence to the handling of disjunctions in the heads of thelogic programs' rules.</description><author>Jesse Heyninck, Ofer Arieli</author><pubDate>Mon, 12 Jun 2023 15:01:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07126v1</guid></item><item><title>On the Dynamics of Learning Time-Aware Behavior with Recurrent Neural Networks</title><link>http://arxiv.org/abs/2306.07125v1</link><description>Recurrent Neural Networks (RNNs) have shown great success in modelingtime-dependent patterns, but there is limited research on their learnedrepresentations of latent temporal features and the emergence of theserepresentations during training. To address this gap, we use timed automata(TA) to introduce a family of supervised learning tasks modeling behaviordependent on hidden temporal variables whose complexity is directlycontrollable. Building upon past studies from the perspective of dynamicalsystems, we train RNNs to emulate temporal flipflops, a new collection of TAthat emphasizes the need for time-awareness over long-term memory. We find thatthese RNNs learn in phases: they quickly perfect any time-independent behavior,but they initially struggle to discover the hidden time-dependent features. Inthe case of periodic "time-of-day" aware automata, we show that the RNNs learnto switch between periodic orbits that encode time modulo the period of thetransition rules. We subsequently apply fixed point stability analysis tomonitor changes in the RNN dynamics during training, and we observe that thelearning phases are separated by a bifurcation from which the periodic behavioremerges. In this way, we demonstrate how dynamical systems theory can provideinsights into not only the learned representations of these models, but alsothe dynamics of the learning process itself. We argue that this style ofanalysis may provide insights into the training pathologies of recurrentarchitectures in contexts outside of time-awareness.</description><author>Peter DelMastro, Rushiv Arora, Edward Rietman, Hava T. Siegelmann</author><pubDate>Mon, 12 Jun 2023 15:01:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07125v1</guid></item><item><title>Diverse Projection Ensembles for Distributional Reinforcement Learning</title><link>http://arxiv.org/abs/2306.07124v1</link><description>In contrast to classical reinforcement learning, distributional reinforcementlearning algorithms aim to learn the distribution of returns rather than theirexpected value. Since the nature of the return distribution is generallyunknown a priori or arbitrarily complex, a common approach finds approximationswithin a set of representable, parametric distributions. Typically, thisinvolves a projection of the unconstrained distribution onto the set ofsimplified distributions. We argue that this projection step entails a stronginductive bias when coupled with neural networks and gradient descent, therebyprofoundly impacting the generalization behavior of learned models. In order tofacilitate reliable uncertainty estimation through diversity, this work studiesthe combination of several different projections and representations in adistributional ensemble. We establish theoretical properties of such projectionensembles and derive an algorithm that uses ensemble disagreement, measured bythe average $1$-Wasserstein distance, as a bonus for deep exploration. Weevaluate our algorithm on the behavior suite benchmark and find that diverseprojection ensembles lead to significant performance improvements over existingmethods on a wide variety of tasks with the most pronounced gains in directedexploration problems.</description><author>Moritz A. Zanger, Wendelin Böhmer, Matthijs T. J. Spaan</author><pubDate>Mon, 12 Jun 2023 14:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07124v1</guid></item><item><title>Analysis of the Relative Entropy Asymmetry in the Regularization of Empirical Risk Minimization</title><link>http://arxiv.org/abs/2306.07123v1</link><description>The effect of the relative entropy asymmetry is analyzed in the empiricalrisk minimization with relative entropy regularization (ERM-RER) problem. Anovel regularization is introduced, coined Type-II regularization, that allowsfor solutions to the ERM-RER problem with a support that extends outside thesupport of the reference measure. The solution to the new ERM-RER Type-IIproblem is analytically characterized in terms of the Radon-Nikodym derivativeof the reference measure with respect to the solution. The analysis of thesolution unveils the following properties of relative entropy when it acts as aregularizer in the ERM-RER problem: i) relative entropy forces the support ofthe Type-II solution to collapse into the support of the reference measure,which introduces a strong inductive bias that dominates the evidence providedby the training data; ii) Type-II regularization is equivalent to classicalrelative entropy regularization with an appropriate transformation of theempirical risk function. Closed-form expressions of the expected empirical riskas a function of the regularization parameters are provided.</description><author>Francisco Daunas, Iñaki Esnaola, Samir M. Perlaza, H. Vincent Poor</author><pubDate>Mon, 12 Jun 2023 14:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07123v1</guid></item><item><title>Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast</title><link>http://arxiv.org/abs/2306.07119v1</link><description>A common forecasting setting in real world applications considers a set ofpossibly heterogeneous time series of the same domain. Due to differentproperties of each time series such as length, obtaining forecasts for eachindividual time series in a straight-forward way is challenging. This paperproposes a general framework utilizing a similarity measure in Dynamic TimeWarping to find similar time series to build neighborhoods in a k-NearestNeighbor fashion, and improve forecasts of possibly simple models by averaging.Several ways of performing the averaging are suggested, and theoreticalarguments underline the usefulness of averaging for forecasting. Additionally,diagnostics tools are proposed allowing a deep understanding of the procedure.</description><author>Lukas Neubauer, Peter Filzmoser</author><pubDate>Mon, 12 Jun 2023 14:52:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07119v1</guid></item><item><title>On building machine learning pipelines for Android malware detection: a procedural survey of practices, challenges and opportunities</title><link>http://arxiv.org/abs/2306.07118v1</link><description>As the smartphone market leader, Android has been a prominent target formalware attacks. The number of malicious applications (apps) identified for ithas increased continually over the past decade, creating an immense challengefor all parties involved. For market holders and researchers, in particular,the large number of samples has made manual malware detection unfeasible,leading to an influx of research that investigate Machine Learning (ML)approaches to automate this process. However, while some of the proposedapproaches achieve high performance, rapidly evolving Android malware has madethem unable to maintain their accuracy over time. This has created a need inthe community to conduct further research, and build more flexible MLpipelines. Doing so, however, is currently hindered by a lack of systematicoverview of the existing literature, to learn from and improve upon theexisting solutions. Existing survey papers often focus only on parts of the MLprocess (e.g., data collection or model deployment), while omitting otherimportant stages, such as model evaluation and explanation. In this paper, weaddress this problem with a review of 42 highly-cited papers, spanning a decadeof research (from 2011 to 2021). We introduce a novel procedural taxonomy ofthe published literature, covering how they have used ML algorithms, whatfeatures they have engineered, which dimensionality reduction techniques theyhave employed, what datasets they have employed for training, and what theirevaluation and explanation strategies are. Drawing from this taxonomy, we alsoidentify gaps in knowledge and provide ideas for improvement and future work.</description><author>Masoud Mehrabi Koushki, Ibrahim AbuAlhaol, Anandharaju Durai Raju, Yang Zhou, Ronnie Salvador Giagone, Huang Shengqiang</author><pubDate>Mon, 12 Jun 2023 14:52:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07118v1</guid></item><item><title>Language of Bargaining</title><link>http://arxiv.org/abs/2306.07117v1</link><description>Leveraging an established exercise in negotiation education, we build a noveldataset for studying how the use of language shapes bilateral bargaining. Ourdataset extends existing work in two ways: 1) we recruit participants viabehavioral labs instead of crowdsourcing platforms and allow participants tonegotiate through audio, enabling more naturalistic interactions; 2) we add acontrol setting where participants negotiate only through alternating, writtennumeric offers.Despite the two contrasting forms of communication, we find thatthe average agreed prices of the two treatments are identical. But whensubjects can talk, fewer offers are exchanged, negotiations finish faster, thelikelihood of reaching agreement rises, and the variance of prices at whichsubjects agree drops substantially. We further propose a taxonomy of speechacts in negotiation and enrich the dataset with annotated speech acts. We setup prediction tasks to predict negotiation success and find that being reactiveto the arguments of the other party is advantageous over driving thenegotiation.</description><author>Mourad Heddaya, Solomon Dworkin, Chenhao Tan, Rob Voigt, Alexander Zentefis</author><pubDate>Mon, 12 Jun 2023 14:52:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07117v1</guid></item><item><title>Exploring Attention Mechanisms for Multimodal Emotion Recognition in an Emergency Call Center Corpus</title><link>http://arxiv.org/abs/2306.07115v1</link><description>The emotion detection technology to enhance human decision-making is animportant research issue for real-world applications, but real-life emotiondatasets are relatively rare and small. The experiments conducted in this paperuse the CEMO, which was collected in a French emergency call center. Twopre-trained models based on speech and text were fine-tuned for speech emotionrecognition. Using pre-trained Transformer encoders mitigates our data'slimited and sparse nature. This paper explores the different fusion strategiesof these modality-specific models. In particular, fusions with and withoutcross-attention mechanisms were tested to gather the most relevant informationfrom both the speech and text encoders. We show that multimodal fusion bringsan absolute gain of 4-9% with respect to either single modality and that theSymmetric multi-headed cross-attention mechanism performed better than lateclassical fusion approaches. Our experiments also suggest that for thereal-life CEMO corpus, the audio component encodes more emotive informationthan the textual one.</description><author>Théo Deschamps-Berger, Lori Lamel, Laurence Devillers</author><pubDate>Mon, 12 Jun 2023 14:43:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07115v1</guid></item><item><title>Coupled Attention Networks for Multivariate Time Series Anomaly Detection</title><link>http://arxiv.org/abs/2306.07114v1</link><description>Multivariate time series anomaly detection (MTAD) plays a vital role in awide variety of real-world application domains. Over the past few years, MTADhas attracted rapidly increasing attention from both academia and industry.Many deep learning and graph learning models have been developed for effectiveanomaly detection in multivariate time series data, which enable advancedapplications such as smart surveillance and risk management with unprecedentedcapabilities. Nevertheless, MTAD is facing critical challenges deriving fromthe dependencies among sensors and variables, which often change over time. Toaddress this issue, we propose a coupled attention-based neural networkframework (CAN) for anomaly detection in multivariate time series datafeaturing dynamic variable relationships. We combine adaptive graph learningmethods with graph attention to generate a global-local graph that canrepresent both global correlations and dynamic local correlations amongsensors. To capture inter-sensor relationships and temporal dependencies, aconvolutional neural network based on the global-local graph is integrated witha temporal self-attention module to construct a coupled attention module. Inaddition, we develop a multilevel encoder-decoder architecture thataccommodates reconstruction and prediction tasks to better characterizemultivariate time series data. Extensive experiments on real-world datasetshave been conducted to evaluate the performance of the proposed CAN approach,and the results show that CAN significantly outperforms state-of-the-artbaselines.</description><author>Feng Xia, Xin Chen, Shuo Yu, Mingliang Hou, Mujie Liu, Linlin You</author><pubDate>Mon, 12 Jun 2023 14:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07114v1</guid></item><item><title>Linear Classifier: An Often-Forgotten Baseline for Text Classification</title><link>http://arxiv.org/abs/2306.07111v1</link><description>Large-scale pre-trained language models such as BERT are popular solutionsfor text classification. Due to the superior performance of these advancedmethods, nowadays, people often directly train them for a few epochs and deploythe obtained model. In this opinion paper, we point out that this way may onlysometimes get satisfactory results. We argue the importance of running a simplebaseline like linear classifiers on bag-of-words features along with advancedmethods. First, for many text data, linear methods show competitiveperformance, high efficiency, and robustness. Second, advanced models such asBERT may only achieve the best results if properly applied. Simple baselineshelp to confirm whether the results of advanced models are acceptable. Ourexperimental results fully support these points.</description><author>Yu-Chen Lin, Si-An Chen, Jie-Jyun Liu, Chih-Jen Lin</author><pubDate>Mon, 12 Jun 2023 14:39:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07111v1</guid></item><item><title>Rotation and Translation Invariant Representation Learning with Implicit Neural Representations</title><link>http://arxiv.org/abs/2304.13995v2</link><description>In many computer vision applications, images are acquired with arbitrary orrandom rotations and translations, and in such setups, it is desirable toobtain semantic representations disentangled from the image orientation.Examples of such applications include semiconductor wafer defect inspection,plankton microscope images, and inference on single-particle cryo-electronmicroscopy (cryo-EM) micro-graphs. In this work, we propose InvariantRepresentation Learning with Implicit Neural Representation (IRL-INR), whichuses an implicit neural representation (INR) with a hypernetwork to obtainsemantic representations disentangled from the orientation of the image. Weshow that IRL-INR can effectively learn disentangled semantic representationson more complex images compared to those considered in prior works and showthat these semantic representations synergize well with SCAN to producestate-of-the-art unsupervised clustering results.</description><author>Sehyun Kwon, Joo Young Choi, Ernest K. Ryu</author><pubDate>Mon, 12 Jun 2023 14:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13995v2</guid></item><item><title>Adversarial Constrained Bidding via Minimax Regret Optimization with Causality-Aware Reinforcement Learning</title><link>http://arxiv.org/abs/2306.07106v1</link><description>The proliferation of the Internet has led to the emergence of onlineadvertising, driven by the mechanics of online auctions. In these repeatedauctions, software agents participate on behalf of aggregated advertisers tooptimize for their long-term utility. To fulfill the diverse demands, biddingstrategies are employed to optimize advertising objectives subject to differentspending constraints. Existing approaches on constrained bidding typically relyon i.i.d. train and test conditions, which contradicts the adversarial natureof online ad markets where different parties possess potentially conflictingobjectives. In this regard, we explore the problem of constrained bidding inadversarial bidding environments, which assumes no knowledge about theadversarial factors. Instead of relying on the i.i.d. assumption, our insightis to align the train distribution of environments with the potential testdistribution meanwhile minimizing policy regret. Based on this insight, wepropose a practical Minimax Regret Optimization (MiRO) approach thatinterleaves between a teacher finding adversarial environments for tutoring anda learner meta-learning its policy over the given distribution of environments.In addition, we pioneer to incorporate expert demonstrations for learningbidding strategies. Through a causality-aware policy design, we improve uponMiRO by distilling knowledge from the experts. Extensive experiments on bothindustrial data and synthetic data show that our method, MiRO withCausality-aware reinforcement Learning (MiROCL), outperforms prior methods byover 30%.</description><author>Haozhe Wang, Chao Du, Panyan Fang, Li He, Liang Wang, Bo Zheng</author><pubDate>Mon, 12 Jun 2023 14:31:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07106v1</guid></item><item><title>Unveiling the Hessian's Connection to the Decision Boundary</title><link>http://arxiv.org/abs/2306.07104v1</link><description>Understanding the properties of well-generalizing minima is at the heart ofdeep learning research. On the one hand, the generalization of neural networkshas been connected to the decision boundary complexity, which is hard to studyin the high-dimensional input space. Conversely, the flatness of a minimum hasbecome a controversial proxy for generalization. In this work, we provide themissing link between the two approaches and show that the Hessian topeigenvectors characterize the decision boundary learned by the neural network.Notably, the number of outliers in the Hessian spectrum is proportional to thecomplexity of the decision boundary. Based on this finding, we provide a newand straightforward approach to studying the complexity of a high-dimensionaldecision boundary; show that this connection naturally inspires a newgeneralization measure; and finally, we develop a novel margin estimationtechnique which, in combination with the generalization measure, preciselyidentifies minima with simple wide-margin boundaries. Overall, this analysisestablishes the connection between the Hessian and the decision boundary andprovides a new method to identify minima with simple wide-margin decisionboundaries.</description><author>Mahalakshmi Sabanayagam, Freya Behrens, Urte Adomaityte, Anna Dawid</author><pubDate>Mon, 12 Jun 2023 14:27:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07104v1</guid></item><item><title>Does Debiasing Inevitably Degrade the Model Performance</title><link>http://arxiv.org/abs/2211.07350v2</link><description>Gender bias in language models has attracted sufficient attention because itthreatens social justice. However, most of the current debiasing methodsdegraded the model's performance on other tasks while the degradation mechanismis still mysterious. We propose a theoretical framework explaining the threecandidate mechanisms of the language model's gender bias. We use ourtheoretical framework to explain why the current debiasing methods causeperformance degradation. We also discover a pathway through which debiasingwill not degrade the model performance. We further develop acausality-detection fine-tuning approach to correct gender bias. The numericalexperiment demonstrates that our method is able to lead to double dividends:partially mitigating gender bias while avoiding performance degradation.</description><author>Yiran Liu, Xiao Liu, Haotian Chen, Yang Yu</author><pubDate>Mon, 12 Jun 2023 14:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07350v2</guid></item></channel></rss>