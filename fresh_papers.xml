<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 24 Aug 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Randomized Quantization: A Generic Augmentation for Data Agnostic Self-supervised Learning</title><link>http://arxiv.org/abs/2212.08663v2</link><description>Self-supervised representation learning follows a paradigm of withholdingsome part of the data and tasking the network to predict it from the remainingpart. Among many techniques, data augmentation lies at the core for creatingthe information gap. Towards this end, masking has emerged as a generic andpowerful tool where content is withheld along the sequential dimension, e.g.,spatial in images, temporal in audio, and syntactic in language. In this paper,we explore the orthogonal channel dimension for generic data augmentation byexploiting precision redundancy. The data for each channel is quantized througha non-uniform quantizer, with the quantized value sampled randomly withinrandomly sampled quantization bins. From another perspective, quantization isanalogous to channel-wise masking, as it removes the information within eachbin, but preserves the information across bins. Our approach significantlysurpasses existing generic data augmentation methods, while showing on parperformance against modality-specific augmentations. We comprehensivelyevaluate our approach on vision, audio, 3D point clouds, as well as the DABSbenchmark which is comprised of various data modalities. The code is availableat https: //github.com/microsoft/random_quantize.</description><author>Huimin Wu, Chenyang Lei, Xiao Sun, Peng-Shuai Wang, Qifeng Chen, Kwang-Ting Cheng, Stephen Lin, Zhirong Wu</author><pubDate>Wed, 23 Aug 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08663v2</guid></item><item><title>CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images</title><link>http://arxiv.org/abs/2308.12288v1</link><description>We present a method for teaching machines to understand and model theunderlying spatial common sense of diverse human-object interactions in 3D in aself-supervised way. This is a challenging task, as there exist specificmanifolds of the interactions that can be considered human-like and natural,but the human pose and the geometry of objects can vary even for similarinteractions. Such diversity makes the annotating task of 3D interactionsdifficult and hard to scale, which limits the potential to reason about that ina supervised way. One way of learning the 3D spatial relationship betweenhumans and objects during interaction is by showing multiple 2D images capturedfrom different viewpoints when humans interact with the same type of objects.The core idea of our method is to leverage a generative model that produceshigh-quality 2D images from an arbitrary text prompt input as an "unbounded"data generator with effective controllability and view diversity. Despite itsimperfection of the image quality over real images, we demonstrate that thesynthesized images are sufficient to learn the 3D human-object spatialrelations. We present multiple strategies to leverage the synthesized images,including (1) the first method to leverage a generative image model for 3Dhuman-object spatial relation learning; (2) a framework to reason about the 3Dspatial relations from inconsistent 2D cues in a self-supervised manner via 3Doccupancy reasoning with pose canonicalization; (3) semantic clustering todisambiguate different types of interactions with the same object types; and(4) a novel metric to assess the quality of 3D spatial learning of interaction.Project Page: https://jellyheadandrew.github.io/projects/chorus</description><author>Sookwan Han, Hanbyul Joo</author><pubDate>Wed, 23 Aug 2023 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12288v1</guid></item><item><title>D4: Improving LLM Pretraining via Document De-Duplication and Diversification</title><link>http://arxiv.org/abs/2308.12284v1</link><description>Over recent years, an increasing amount of compute and data has been pouredinto training large language models (LLMs), usually by doing one-pass learningon as many tokens as possible randomly selected from large-scale web corpora.While training on ever-larger portions of the internet leads to consistentperformance improvements, the size of these improvements diminishes with scale,and there has been little work exploring the effect of data selection onpre-training and downstream performance beyond simple de-duplication methodssuch as MinHash. Here, we show that careful data selection (on top ofde-duplicated data) via pre-trained model embeddings can speed up training (20%efficiency gains) and improves average downstream accuracy on 16 NLP tasks (upto 2%) at the 6.7B model scale. Furthermore, we show that repeating dataintelligently consistently outperforms baseline training (while repeatingrandom data performs worse than baseline training). Our results indicate thatclever data selection can significantly improve LLM pre-training, calls intoquestion the common practice of training for a single epoch on as much data aspossible, and demonstrates a path to keep improving our models past the limitsof randomly sampling web data.</description><author>Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos</author><pubDate>Wed, 23 Aug 2023 18:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12284v1</guid></item><item><title>Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve</title><link>http://arxiv.org/abs/2308.12280v1</link><description>This research enhances linear regression models by integrating a Kalmanfilter and analysing curve areas to minimize loss. The goal is to develop anoptimal linear regression equation using stochastic gradient descent (SGD) forweight updating. Our approach involves a stepwise process, starting withuser-defined parameters. The linear regression model is trained using SGD,tracking weights and loss separately and zipping them finally. A Kalman filteris then trained based on weight and loss arrays to predict the nextconsolidated weights. Predictions result from multiplying input averages withweights, evaluated for loss to form a weight-versus-loss curve. The curve'sequation is derived using the two-point formula, and area under the curve iscalculated via integration. The linear regression equation with minimum areabecomes the optimal curve for prediction. Benefits include avoiding constantweight updates via gradient descent and working with partial datasets, unlikemethods needing the entire set. However, computational complexity should beconsidered. The Kalman filter's accuracy might diminish beyond a certainprediction range.</description><author>Gokulprasath R</author><pubDate>Wed, 23 Aug 2023 18:50:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12280v1</guid></item><item><title>On-Manifold Projected Gradient Descent</title><link>http://arxiv.org/abs/2308.12279v1</link><description>This work provides a computable, direct, and mathematically rigorousapproximation to the differential geometry of class manifolds forhigh-dimensional data, along with nonlinear projections from input space ontothese class manifolds. The tools are applied to the setting of neural networkimage classifiers, where we generate novel, on-manifold data samples, andimplement a projected gradient descent algorithm for on-manifold adversarialtraining. The susceptibility of neural networks (NNs) to adversarial attackhighlights the brittle nature of NN decision boundaries in input space.Introducing adversarial examples during training has been shown to reduce thesusceptibility of NNs to adversarial attack; however, it has also been shown toreduce the accuracy of the classifier if the examples are not valid examplesfor that class. Realistic "on-manifold" examples have been previously generatedfrom class manifolds in the latent of an autoencoder. Our work explores thesephenomena in a geometric and computational setting that is much closer to theraw, high-dimensional input space than can be provided by VAE or other blackbox dimensionality reductions. We employ conformally invariant diffusion maps(CIDM) to approximate class manifolds in diffusion coordinates, and develop theNystr\"{o}m projection to project novel points onto class manifolds in thissetting. On top of the manifold approximation, we leverage the spectralexterior calculus (SEC) to determine geometric quantities such as tangentvectors of the manifold. We use these tools to obtain adversarial examples thatreside on a class manifold, yet fool a classifier. These misclassificationsthen become explainable in terms of human-understandable manipulations withinthe data, by expressing the on-manifold adversary in the semantic basis on themanifold.</description><author>Aaron Mahler, Tyrus Berry, Tom Stephens, Harbir Antil, Michael Merritt, Jeanie Schreiber, Ioannis Kevrekidis</author><pubDate>Wed, 23 Aug 2023 18:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12279v1</guid></item><item><title>Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models</title><link>http://arxiv.org/abs/2308.12272v1</link><description>Foundational Language Models (FLMs) have advanced natural language processing(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,T5) to enable contextualized language representation, classification, andgeneration. While developing larger FLMs has been of significant advantage, itis also a liability concerning hallucination and predictive uncertainty.Fundamentally, larger FLMs are built on the same foundations as smaller FLMs(e.g., BERT); hence, one must recognize the potential of smaller FLMs which canbe realized through an ensemble. In the current research, we perform a realitycheck on FLMs and their ensemble on benchmark and real-world datasets. Wehypothesize that the ensembling of FLMs can influence the individualisticattention of FLMs and unravel the strength of coordination and cooperation ofdifferent FLMs. We utilize BERT and define three other ensemble techniques:{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces aknowledge-guided reinforcement learning approach. We discovered that thesuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, bya factor of many times using datasets that show the usefulness of NLP insensitive fields, such as mental health.</description><author>Nancy Tyagi, Aidin Shiri, Surjodeep Sarkar, Abhishek Kumar Umrawal, Manas Gaur</author><pubDate>Wed, 23 Aug 2023 18:40:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12272v1</guid></item><item><title>Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation</title><link>http://arxiv.org/abs/2307.03833v2</link><description>Learning-based methods have dominated the 3D human pose estimation (HPE)tasks with significantly better performance in most benchmarks than traditionaloptimization-based methods. Nonetheless, 3D HPE in the wild is still thebiggest challenge of learning-based models, whether with 2D-3D lifting,image-to-3D, or diffusion-based methods, since the trained networks implicitlylearn camera intrinsic parameters and domain-based 3D human pose distributionsand estimate poses by statistical average. On the other hand, theoptimization-based methods estimate results case-by-case, which can predictmore diverse and sophisticated human poses in the wild. By combining theadvantages of optimization-based and learning-based methods, we propose theZero-shot Diffusion-based Optimization (ZeDO) pipeline for 3D HPE to solve theproblem of cross-domain and in-the-wild 3D HPE. Our multi-hypothesis ZeDOachieves state-of-the-art (SOTA) performance on Human3.6M as minMPJPE $51.4$mmwithout training with any 2D-3D or image-3D pairs. Moreover, oursingle-hypothesis ZeDO achieves SOTA performance on 3DPW dataset with PA-MPJPE$42.6$mm on cross-dataset evaluation, which even outperforms learning-basedmethods trained on 3DPW.</description><author>Zhongyu Jiang, Zhuoran Zhou, Lei Li, Wenhao Chai, Cheng-Yen Yang, Jenq-Neng Hwang</author><pubDate>Wed, 23 Aug 2023 18:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03833v2</guid></item><item><title>A Generative Approach for Image Registration of Visible-Thermal (VT) Cancer Faces</title><link>http://arxiv.org/abs/2308.12271v1</link><description>Since thermal imagery offers a unique modality to investigate pain, the U.S.National Institutes of Health (NIH) has collected a large and diverse set ofcancer patient facial thermograms for AI-based pain research. However,differing angles from camera capture between thermal and visible sensors hasled to misalignment between Visible-Thermal (VT) images. We modernize theclassic computer vision task of image registration by applying and modifying agenerative alignment algorithm to register VT cancer faces, without the needfor a reference or alignment parameters. By registering VT faces, wedemonstrate that the quality of thermal images produced in the generative AIdownstream task of Visible-to-Thermal (V2T) image translation significantlyimproves up to 52.5\%, than without registration. Images in this paper havebeen approved by the NIH NCI for public dissemination.</description><author>Catherine Ordun, Alexandra Cha, Edward Raff, Sanjay Purushotham, Karen Kwok, Mason Rule, James Gulley</author><pubDate>Wed, 23 Aug 2023 18:39:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12271v1</guid></item><item><title>Language Reward Modulation for Pretraining Reinforcement Learning</title><link>http://arxiv.org/abs/2308.12270v1</link><description>Using learned reward functions (LRFs) as a means to solve sparse-rewardreinforcement learning (RL) tasks has yielded some steady progress intask-complexity through the years. In this work, we question whether today'sLRFs are best-suited as a direct replacement for task rewards. Instead, wepropose leveraging the capabilities of LRFs as a pretraining signal for RL.Concretely, we propose $\textbf{LA}$nguage Reward $\textbf{M}$odulated$\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities ofVision-Language Models (VLMs) as a $\textit{pretraining}$ utility for RL asopposed to a downstream task reward. LAMP uses a frozen, pretrained VLM toscalably generate noisy, albeit shaped exploration rewards by computing thecontrastive alignment between a highly diverse collection of languageinstructions and the image observations of an agent in its pretrainingenvironment. LAMP optimizes these rewards in conjunction with standardnovelty-seeking exploration rewards with reinforcement learning to acquire alanguage-conditioned, pretrained policy. Our VLM pretraining approach, which isa departure from previous attempts to use LRFs, can warmstart sample-efficientlearning on robot manipulation tasks in RLBench.</description><author>Ademi Adeniji, Amber Xie, Carmelo Sferrazza, Younggyo Seo, Stephen James, Pieter Abbeel</author><pubDate>Wed, 23 Aug 2023 18:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12270v1</guid></item><item><title>Tryage: Real-time, intelligent Routing of User Prompts to Large Language Models</title><link>http://arxiv.org/abs/2308.11601v2</link><description>The introduction of the transformer architecture and the self-attentionmechanism has led to an explosive production of language models trained onspecific downstream tasks and data domains. With over 200, 000 models in theHugging Face ecosystem, users grapple with selecting and optimizing models tosuit multifaceted workflows and data domains while addressing computational,security, and recency concerns. There is an urgent need for machine learningframeworks that can eliminate the burden of model selection and customizationand unleash the incredible power of the vast emerging model library for endusers. Here, we propose a context-aware routing system, Tryage, that leveragesa language model router for optimal selection of expert models from a modellibrary based on analysis of individual input prompts. Inspired by the thalamicrouter in the brain, Tryage employs a perceptive router to predict down-streammodel performance on prompts and, then, makes a routing decision using anobjective function that integrates performance predictions with user goals andconstraints that are incorporated through flags (e.g., model size, modelrecency). Tryage allows users to explore a Pareto front and automaticallytrade-off between task accuracy and secondary goals including minimization ofmodel size, recency, security, verbosity, and readability. Across heterogeneousdata sets that include code, text, clinical data, and patents, the Tryageframework surpasses Gorilla and GPT3.5 turbo in dynamic model selectionidentifying the optimal model with an accuracy of 50.9% , compared to 23.6% byGPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates howrouting models can be applied to program and control the behavior ofmulti-model LLM systems to maximize efficient use of the expanding and evolvinglanguage model ecosystem.</description><author>Surya Narayanan Hari, Matt Thomson</author><pubDate>Wed, 23 Aug 2023 18:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11601v2</guid></item><item><title>FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning</title><link>http://arxiv.org/abs/2308.12264v1</link><description>With the increasing usage, scale, and complexity of Deep Learning (DL)models, their rapidly growing energy consumption has become a critical concern.Promoting green development and energy awareness at different granularities isthe need of the hour to limit carbon emissions of DL systems. However, the lackof standard and repeatable tools to accurately measure and optimize energyconsumption at a fine granularity (e.g., at method level) hinders progress inthis area. In this paper, we introduce FECoM (Fine-grained Energy ConsumptionMeter), a framework for fine-grained DL energy consumption measurement.Specifically, FECoM provides researchers and developers a mechanism to profileDL APIs. FECoM addresses the challenges of measuring energy consumption atfine-grained level by using static instrumentation and considering variousfactors, including computational load and temperature stability. We assessFECoM's capability to measure fine-grained energy consumption for one of themost popular open-source DL frameworks, namely TensorFlow. Using FECoM, we alsoinvestigate the impact of parameter size and execution time on energyconsumption, enriching our understanding of TensorFlow APIs' energy profiles.Furthermore, we elaborate on the considerations, issues, and challenges thatone needs to consider while designing and implementing a fine-grained energyconsumption measurement tool. We hope this work will facilitate furtheradvances in DL energy measurement and the development of energy-aware practicesfor DL systems.</description><author>Saurabhsingh Rajput, Tim Widmayer, Ziyuan Shang, Maria Kechagia, Federica Sarro, Tushar Sharma</author><pubDate>Wed, 23 Aug 2023 18:32:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12264v1</guid></item><item><title>Prompt2Model: Generating Deployable Models from Natural Language Instructions</title><link>http://arxiv.org/abs/2308.12261v1</link><description>Large language models (LLMs) enable system builders today to create competentNLP systems through prompting, where they only need to describe the task innatural language and provide a few examples. However, in other ways, LLMs are astep backward from traditional special-purpose NLP models; they requireextensive computational resources for deployment and can be gated behind APIs.In this paper, we propose Prompt2Model, a general-purpose method that takes anatural language task description like the prompts provided to LLMs, and usesit to train a special-purpose model that is conducive to deployment. This isdone through a multi-step process of retrieval of existing datasets andpretrained models, dataset generation using LLMs, and supervised fine-tuning onthese retrieved and generated datasets. Over three tasks, we demonstrate thatgiven the same few-shot prompt as input, Prompt2Model trains models thatoutperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20%while being up to 700 times smaller. We also show that this data can be used toobtain reliable performance estimates of model performance, enabling modeldevelopers to assess model reliability before deployment. Prompt2Model isavailable open-source at https://github.com/neulab/prompt2model.</description><author>Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, Graham Neubig</author><pubDate>Wed, 23 Aug 2023 18:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12261v1</guid></item><item><title>Towards Interactive Reinforcement Learning with Intrinsic Feedback</title><link>http://arxiv.org/abs/2112.01575v3</link><description>Reinforcement learning (RL) and brain-computer interfaces (BCI) haveexperienced significant growth over the past decade. With rising interest inhuman-in-the-loop (HITL), incorporating human input with RL algorithms hasgiven rise to the sub-field of interactive RL. Adjacently, the field of BCI haslong been interested in extracting informative brain signals from neuralactivity for use in human-computer interactions. A key link between thesefields lies in the interpretation of neural activity as feedback such thatinteractive RL approaches can be employed. We denote this new and emergingmedium of feedback as intrinsic feedback. Despite intrinsic feedback's abilityto be conveyed automatically and even unconsciously, proper explorationsurrounding this key link has largely gone unaddressed by both communities.Thus, to help facilitate a deeper understanding and a more effectiveutilization, we provide a tutorial-style review covering the motivations,approaches, and open problems of intrinsic feedback and its foundationalconcepts.</description><author>Benjamin Poole, Minwoo Lee</author><pubDate>Wed, 23 Aug 2023 18:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.01575v3</guid></item><item><title>Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders</title><link>http://arxiv.org/abs/2308.12256v1</link><description>Sequential recommenders have been widely used in industry due to theirstrength in modeling user preferences. While these models excel at learning auser's positive interests, less attention has been paid to learning fromnegative user feedback. Negative user feedback is an important lever of usercontrol, and comes with an expectation that recommenders should respond quicklyand reduce similar recommendations to the user. However, negative feedbacksignals are often ignored in the training objective of sequential retrievalmodels, which primarily aim at predicting positive user interactions. In thiswork, we incorporate explicit and implicit negative user feedback into thetraining objective of sequential recommenders in the retrieval stage using a"not-to-recommend" loss function that optimizes for the log-likelihood of notrecommending items with negative feedback. We demonstrate the effectiveness ofthis approach using live experiments on a large-scale industrial recommendersystem. Furthermore, we address a challenge in measuring recommenderresponsiveness to negative feedback by developing a counterfactual simulationframework to compare recommender responses between different user actions,showing improved responsiveness from the modeling change.</description><author>Yueqi Wang, Yoni Halpern, Shuo Chang, Jingchen Feng, Elaine Ya Le, Longfei Li, Xujian Liang, Min-Cheng Huang, Shane Li, Alex Beutel, Yaping Zhang, Shuchao Bi</author><pubDate>Wed, 23 Aug 2023 18:16:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12256v1</guid></item><item><title>How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy</title><link>http://arxiv.org/abs/2308.12252v1</link><description>End-to-end learning has emerged as a major paradigm for developing autonomoussystems. Unfortunately, with its performance and convenience comes an evengreater challenge of safety assurance. A key factor of this challenge is theabsence of the notion of a low-dimensional and interpretable dynamical state,around which traditional assurance methods revolve. Focusing on the onlinesafety prediction problem, this paper proposes a configurable family oflearning pipelines based on generative world models, which do not requirelow-dimensional states. To implement these pipelines, we overcome thechallenges of learning safety-informed latent representations and missingsafety labels under prediction-induced distribution shift. These pipelines comewith statistical calibration guarantees on their safety chance predictionsbased on conformal prediction. We perform an extensive evaluation of theproposed learning pipelines on two case studies of image-controlled systems: aracing car and a cartpole.</description><author>Zhenjiang Mao, Carson Sobolewski, Ivan Ruchkin</author><pubDate>Wed, 23 Aug 2023 18:01:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12252v1</guid></item><item><title>The Common Intuition to Transfer Learning Can Win or Lose: Case Studies for Linear Regression</title><link>http://arxiv.org/abs/2103.05621v3</link><description>We study a fundamental transfer learning process from source to target linearregression tasks, including overparameterized settings where there are morelearned parameters than data samples. The target task learning is addressed byusing its training data together with the parameters previously computed forthe source task. We define a transfer learning approach to the target task as alinear regression optimization with a regularization on the distance betweenthe to-be-learned target parameters and the already-learned source parameters.We analytically characterize the generalization performance of our transferlearning approach and demonstrate its ability to resolve the peak ingeneralization errors in double descent phenomena of the minimum L2-normsolution to linear regression. Moreover, we show that for sufficiently relatedtasks, the optimally tuned transfer learning approach can outperform theoptimally tuned ridge regression method, even when the true parameter vectorconforms to an isotropic Gaussian prior distribution. Namely, we demonstratethat transfer learning can beat the minimum mean square error (MMSE) solutionof the independent target task. Our results emphasize the ability of transferlearning to extend the solution space to the target task and, by that, to havean improved MMSE solution. We formulate the linear MMSE solution to ourtransfer learning setting and point out its key differences from the commondesign philosophy to transfer learning.</description><author>Yehuda Dar, Daniel LeJeune, Richard G. Baraniuk</author><pubDate>Wed, 23 Aug 2023 17:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.05621v3</guid></item><item><title>How Good Are Large Language Models at Out-of-Distribution Detection?</title><link>http://arxiv.org/abs/2308.10261v2</link><description>Out-of-distribution (OOD) detection plays a vital role in enhancing thereliability of machine learning (ML) models. The emergence of large languagemodels (LLMs) has catalyzed a paradigm shift within the ML community,showcasing their exceptional capabilities across diverse natural languageprocessing tasks. While existing research has probed OOD detection withrelative small-scale Transformers like BERT, RoBERTa and GPT-2, the starkdifferences in scales, pre-training objectives, and inference paradigms callinto question the applicability of these findings to LLMs. This paper embarkson a pioneering empirical investigation of OOD detection in the domain of LLMs,focusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluatecommonly-used OOD detectors, scrutinizing their performance in both zero-gradand fine-tuning scenarios. Notably, we alter previous discriminativein-distribution fine-tuning into generative fine-tuning, aligning thepre-training objective of LLMs with downstream tasks. Our findings unveil thata simple cosine distance OOD detector demonstrates superior efficacy,outperforming other OOD detectors. We provide an intriguing explanation forthis phenomenon by highlighting the isotropic nature of the embedding spaces ofLLMs, which distinctly contrasts with the anisotropic property observed insmaller BERT family models. The new insight enhances our understanding of howLLMs detect OOD data, thereby enhancing their adaptability and reliability indynamic environments.</description><author>Bo Liu, Liming Zhan, Zexin Lu, Yujie Feng, Lei Xue, Xiao-Ming Wu</author><pubDate>Wed, 23 Aug 2023 17:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10261v2</guid></item><item><title>How to Protect Copyright Data in Optimization of Large Language Models?</title><link>http://arxiv.org/abs/2308.12247v1</link><description>Large language models (LLMs) and generative AI have played a transformativerole in computer research and applications. Controversy has arisen as towhether these models output copyrighted data, which can occur if the data themodels are trained on is copyrighted. LLMs are built on the transformer neuralnetwork architecture, which in turn relies on a mathematical computation calledAttention that uses the softmax function. In this paper, we show that large language model training and optimizationcan be seen as a softmax regression problem. We then establish a method ofefficiently performing softmax regression, in a way that prevents theregression function from generating copyright data. This establishes atheoretical method of training large language models in a way that avoidsgenerating copyright data.</description><author>Timothy Chu, Zhao Song, Chiwun Yang</author><pubDate>Wed, 23 Aug 2023 17:48:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12247v1</guid></item><item><title>Unsupervised Selective Labeling for More Effective Semi-Supervised Learning</title><link>http://arxiv.org/abs/2110.03006v4</link><description>Given an unlabeled dataset and an annotation budget, we study how toselectively label a fixed number of instances so that semi-supervised learning(SSL) on such a partially labeled dataset is most effective. We focus onselecting the right data to label, in addition to usual SSL's propagatinglabels from labeled data to the rest unlabeled data. This instance selectiontask is challenging, as without any labeled data we do not know what theobjective of learning should be. Intuitively, no matter what the downstreamtask is, instances to be labeled must be representative and diverse: The formerwould facilitate label propagation to unlabeled data, whereas the latter wouldensure coverage of the entire dataset. We capture this idea by selectingcluster prototypes, either in a pretrained feature space, or along with featureoptimization, both without labels. Our unsupervised selective labelingconsistently improves SSL methods over state-of-the-art active learning givenlabeled data, by 8 to 25 times in label efficiency. For example, it boostsFixMatch by 10% (14%) in accuracy on CIFAR-10 (ImageNet-1K) with 0.08% (0.2%)labeled data, demonstrating that small computation spent on selecting what datato label brings significant gain especially under a low annotation budget. Ourwork sets a new standard for practical and efficient SSL.</description><author>Xudong Wang, Long Lian, Stella X. Yu</author><pubDate>Wed, 23 Aug 2023 17:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.03006v4</guid></item><item><title>Towards Top-Down Automated Development in Limited Scopes: A Neuro-Symbolic Framework from Expressibles to Executables</title><link>http://arxiv.org/abs/2209.01566v3</link><description>Deep code generation is a topic of deep learning for software engineering(DL4SE), which adopts neural models to generate code for the intendedfunctions. Since end-to-end neural methods lack domain knowledge and softwarehierarchy awareness, they tend to perform poorly w.r.t project-level tasks. Tosystematically explore the potential improvements of code generation, we let itparticipate in the whole top-down development from \emph{expressibles} to\emph{executables}, which is possible in limited scopes. In the process, itbenefits from massive samples, features, and knowledge. As the foundation, wesuggest building a taxonomy on code data, namely code taxonomy, leveraging thecategorization of code information. Moreover, we introduce a three-layersemantic pyramid (SP) to associate text data and code data. It identifies theinformation of different abstraction levels, and thus introduces the domainknowledge on development and reveals the hierarchy of software. Furthermore, wepropose a semantic pyramid framework (SPF) as the approach, focusing onsoftware of high modularity and low complexity. SPF divides the code generationprocess into stages and reserves spots for potential interactions. In addition,we conceived preliminary applications in software development to confirm theneuro-symbolic framework.</description><author>Jian Gu, Harald C. Gall</author><pubDate>Wed, 23 Aug 2023 17:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01566v3</guid></item><item><title>Multi-Objective Optimization for Sparse Deep Neural Network Training</title><link>http://arxiv.org/abs/2308.12243v1</link><description>Different conflicting optimization criteria arise naturally in various DeepLearning scenarios. These can address different main tasks (i.e., in thesetting of Multi-Task Learning), but also main and secondary tasks such as lossminimization versus sparsity. The usual approach is a simple weighting of thecriteria, which formally only works in the convex setting. In this paper, wepresent a Multi-Objective Optimization algorithm using a modified WeightedChebyshev scalarization for training Deep Neural Networks (DNNs) with respectto several tasks. By employing this scalarization technique, the algorithm canidentify all optimal solutions of the original problem while reducing itscomplexity to a sequence of single-objective problems. The simplified problemsare then solved using an Augmented Lagrangian method, enabling the use ofpopular optimization techniques such as Adam and Stochastic Gradient Descent,while efficaciously handling constraints. Our work aims to address the(economical and also ecological) sustainability issue of DNN models, with aparticular focus on Deep Multi-Task models, which are typically designed with avery large number of weights to perform equally well on multiple tasks. Throughexperiments conducted on two Machine Learning datasets, we demonstrate thepossibility of adaptively sparsifying the model during training withoutsignificantly impacting its performance, if we are willing to applytask-specific adaptations to the network weights. Code is available athttps://github.com/salomonhotegni/MDMTN.</description><author>S. S. Hotegni, S. Peitz, M. Berkemeier</author><pubDate>Wed, 23 Aug 2023 17:42:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12243v1</guid></item><item><title>LLMRec: Benchmarking Large Language Models on Recommendation Task</title><link>http://arxiv.org/abs/2308.12241v1</link><description>Recently, the fast development of Large Language Models (LLMs) such asChatGPT has significantly advanced NLP tasks by enhancing the capabilities ofconversational models. However, the application of LLMs in the recommendationdomain has not been thoroughly investigated. To bridge this gap, we proposeLLMRec, a LLM-based recommender system designed for benchmarking LLMs onvarious recommendation tasks. Specifically, we benchmark several popularoff-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendationtasks, including rating prediction, sequential recommendation, directrecommendation, explanation generation, and review summarization. Furthermore,we investigate the effectiveness of supervised finetuning to improve LLMs'instruction compliance ability. The benchmark results indicate that LLMsdisplayed only moderate proficiency in accuracy-based tasks such as sequentialand direct recommendation. However, they demonstrated comparable performance tostate-of-the-art methods in explainability-based tasks. We also conductqualitative evaluations to further evaluate the quality of contents generatedby different models, and the results show that LLMs can truly understand theprovided information and generate clearer and more reasonable results. Weaspire that this benchmark will serve as an inspiration for researchers todelve deeper into the potential of LLMs in enhancing recommendationperformance. Our codes, processed data and benchmark results are available athttps://github.com/williamliujl/LLMRec.</description><author>Junling Liu, Chao Liu, Peilin Zhou, Qichen Ye, Dading Chong, Kang Zhou, Yueqi Xie, Yuwei Cao, Shoujin Wang, Chenyu You, Philip S. Yu</author><pubDate>Wed, 23 Aug 2023 17:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12241v1</guid></item><item><title>Low-Resource Authorship Style Transfer: Can Non-Famous Authors Be Imitated?</title><link>http://arxiv.org/abs/2212.08986v2</link><description>Authorship style transfer involves altering text to match the style of atarget author whilst preserving the original meaning. Existing unsupervisedapproaches like STRAP have largely focused on style transfer to target authorswith many examples of their writing style in books, speeches, or otherpublished works. This high-resource training data requirement (often greaterthan 100,000 words) makes these approaches primarily useful for style transferto published authors, politicians, or other well-known figures and authorshipstyles, while style transfer to non-famous authors has not been well-studied.We introduce the \textit{low-resource authorship style transfer} task, a morechallenging class of authorship style transfer where only a limited amount oftext in the target author's style may exist. In our experiments, wespecifically choose source and target authors from Reddit and style transfertheir Reddit posts, limiting ourselves to just 16 posts (on average ~500 words)of the target author's style. Style transfer accuracy is typically measured byhow often a classifier or human judge will classify an output as written by thetarget author. Recent authorship representations models excel at authorshipidentification even with just a few writing samples, making automaticevaluation of this task possible for the first time through evaluation metricswe propose. Our results establish an in-context learning technique we developas the strongest baseline, though we find current approaches do not yet achievemastery of this challenging task. We release our data and implementations toencourage further investigation.</description><author>Ajay Patel, Nicholas Andrews, Chris Callison-Burch</author><pubDate>Wed, 23 Aug 2023 17:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08986v2</guid></item><item><title>Score diffusion models without early stopping: finite Fisher information is all you need</title><link>http://arxiv.org/abs/2308.12240v1</link><description>Diffusion models are a new class of generative models that revolve around theestimation of the score function associated with a stochastic differentialequation. Subsequent to its acquisition, the approximated score function isthen harnessed to simulate the corresponding time-reversal process, ultimatelyenabling the generation of approximate data samples. Despite their evidentpractical significance these models carry, a notable challenge persists in theform of a lack of comprehensive quantitative results, especially in scenariosinvolving non-regular scores and estimators. In almost all reported bounds inKullback Leibler (KL) divergence, it is assumed that either the score functionor its approximation is Lipschitz uniformly in time. However, this condition isvery restrictive in practice or appears to be difficult to establish. To circumvent this issue, previous works mainly focused on establishingconvergence bounds in KL for an early stopped version of the diffusion modeland a smoothed version of the data distribution, or assuming that the datadistribution is supported on a compact manifold. These explorations have leadto interesting bounds in either Wasserstein or Fortet-Mourier metrics. However,the question remains about the relevance of such early-stopping procedure orcompactness conditions. In particular, if there exist a natural and mildcondition ensuring explicit and sharp convergence bounds in KL. In this article, we tackle the aforementioned limitations by focusing onscore diffusion models with fixed step size stemming from theOrnstein-Ulhenbeck semigroup and its kinetic counterpart. Our study provides arigorous analysis, yielding simple, improved and sharp convergence bounds in KLapplicable to any data distribution with finite Fisher information with respectto the standard Gaussian distribution.</description><author>Giovanni Conforti, Alain Durmus, Marta Gentiloni Silveri</author><pubDate>Wed, 23 Aug 2023 17:31:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12240v1</guid></item><item><title>Methods and datasets for segmentation of minimally invasive surgical instruments in endoscopic images and videos: A review of the state of the art</title><link>http://arxiv.org/abs/2304.13014v2</link><description>In the field of computer- and robot-assisted minimally invasive surgery,enormous progress has been made in recent years based on the recognition ofsurgical instruments in endoscopic images and videos. In particular, thedetermination of the position and type of instruments is of great interest.Current work involves both spatial and temporal information, with the idea thatpredicting the movement of surgical tools over time may improve the quality ofthe final segmentations. The provision of publicly available datasets hasrecently encouraged the development of new methods, mainly based on deeplearning. In this review, we identify and characterize datasets used for methoddevelopment and evaluation and quantify their frequency of use in theliterature. We further present an overview of the current state of researchregarding the segmentation and tracking of minimally invasive surgicalinstruments in endoscopic images and videos. The paper focuses on methods thatwork purely visually, without markers of any kind attached to the instruments,considering both single-frame semantic and instance segmentation approaches, aswell as those that incorporate temporal information. The publications analyzedwere identified through the platforms Google Scholar, Web of Science, andPubMed. The search terms used were "instrument segmentation", "instrumenttracking", "surgical tool segmentation", and "surgical tool tracking",resulting in a total of 741 articles published between 01/2015 and 07/2023, ofwhich 123 were included using systematic selection criteria. A discussion ofthe reviewed literature is provided, highlighting existing shortcomings andemphasizing the available potential for future developments.</description><author>Tobias Rueckert, Daniel Rueckert, Christoph Palm</author><pubDate>Wed, 23 Aug 2023 17:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13014v2</guid></item><item><title>Emergent segmentation from participation dynamics and multi-learner retraining</title><link>http://arxiv.org/abs/2206.02667v2</link><description>The choice to participate in a data-driven service, often made on the basisof quality of that service, influences the ability of the service to learn andimprove. We study the participation and retraining dynamics that arise whenboth the learners and sub-populations of users are \emph{risk-reducing}, whichcover a broad class of updates including gradient descent, multiplicativeweights, etc. Suppose, for example, that individuals choose to spend their timeamongst social media platforms proportionally to how well each platform worksfor them. Each platform also gathers data about its active users, which it usesto update parameters with a gradient step. For this example and for our generalclass of dynamics, we show that the only asymptotically stable equilibria aresegmented, with sub-populations allocated to a single learner. Under mildassumptions, the utilitarian social optimum is a stable equilibrium. Incontrast to previous work, which shows that repeated risk minimization canresult in representation disparity and high overall loss for a single learner\citep{hashimoto2018fairness,miller2021outside}, we find that repeated myopicupdates with multiple learners lead to better outcomes. We illustrate thephenomena via a simulated example initialized from real data.</description><author>Sarah Dean, Mihaela Curmei, Lillian J. Ratliff, Jamie Morgenstern, Maryam Fazel</author><pubDate>Wed, 23 Aug 2023 17:18:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.02667v2</guid></item><item><title>Identifying Backdoor Attacks in Federated Learning via Anomaly Detection</title><link>http://arxiv.org/abs/2202.04311v2</link><description>Federated learning has seen increased adoption in recent years in response tothe growing regulatory demand for data privacy. However, the opaque localtraining process of federated learning also sparks rising concerns about modelfaithfulness. For instance, studies have revealed that federated learning isvulnerable to backdoor attacks, whereby a compromised participant canstealthily modify the model's behavior in the presence of backdoor triggers.This paper proposes an effective defense against the attack by examining sharedmodel updates. We begin with the observation that the embedding of backdoorsinfluences the participants' local model weights in terms of the magnitude andorientation of their model gradients, which can manifest as distinguishabledisparities. We enable a robust identification of backdoors by studying thestatistical distribution of the models' subsets of gradients. Concretely, wefirst segment the model gradients into fragment vectors that represent smallportions of model parameters. We then employ anomaly detection to locate thedistributionally skewed fragments and prune the participants with the mostoutliers. We embody the findings in a novel defense method, ARIBA. Wedemonstrate through extensive analyses that our proposed methods effectivelymitigate state-of-the-art backdoor attacks with minimal impact on task utility.</description><author>Yuxi Mi, Yiheng Sun, Jihong Guan, Shuigeng Zhou</author><pubDate>Wed, 23 Aug 2023 17:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.04311v2</guid></item><item><title>Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition</title><link>http://arxiv.org/abs/2308.11489v2</link><description>We are concerned with a challenging scenario in unpaired multiview videolearning. In this case, the model aims to learn comprehensive multiviewrepresentations while the cross-view semantic information exhibits variations.We propose Semantics-based Unpaired Multiview Learning (SUM-L) to tackle thisunpaired multiview learning problem. The key idea is to build cross-viewpseudo-pairs and do view-invariant alignment by leveraging the semanticinformation of videos. To facilitate the data efficiency of multiview learning,we further perform video-text alignment for first-person and third-personvideos, to fully leverage the semantic knowledge to improve videorepresentations. Extensive experiments on multiple benchmark datasets verifythe effectiveness of our framework. Our method also outperforms multipleexisting view-alignment methods, under the more challenging scenario thantypical paired or unpaired multimodal or multiview learning. Our code isavailable at https://github.com/wqtwjt1996/SUM-L.</description><author>Qitong Wang, Long Zhao, Liangzhe Yuan, Ting Liu, Xi Peng</author><pubDate>Wed, 23 Aug 2023 17:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11489v2</guid></item><item><title>MolGrapher: Graph-based Visual Recognition of Chemical Structures</title><link>http://arxiv.org/abs/2308.12234v1</link><description>The automatic analysis of chemical literature has immense potential toaccelerate the discovery of new materials and drugs. Much of the criticalinformation in patent documents and scientific articles is contained infigures, depicting the molecule structures. However, automatically parsing theexact chemical structure is a formidable challenge, due to the amount ofdetailed information, the diversity of drawing styles, and the need fortraining data. In this work, we introduce MolGrapher to recognize chemicalstructures visually. First, a deep keypoint detector detects the atoms. Second,we treat all candidate atoms and bonds as nodes and put them in a graph. Thisconstruct allows a natural graph representation of the molecule. Last, weclassify atom and bond nodes in the graph with a Graph Neural Network. Toaddress the lack of real training data, we propose a synthetic data generationpipeline producing diverse and realistic results. In addition, we introduce alarge-scale benchmark of annotated real molecule images, USPTO-30K, to spurresearch on this critical topic. Extensive experiments on five datasets showthat our approach significantly outperforms classical and learning-basedmethods in most settings. Code, models, and datasets are available.</description><author>Lucas Morin, Martin Danelljan, Maria Isabel Agea, Ahmed Nassar, Valery Weber, Ingmar Meijer, Peter Staar, Fisher Yu</author><pubDate>Wed, 23 Aug 2023 17:16:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12234v1</guid></item><item><title>SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation</title><link>http://arxiv.org/abs/2308.12231v1</link><description>Image segmentation plays an essential role in nuclei image analysis.Recently, the segment anything model has made a significant breakthrough insuch tasks. However, the current model exists two major issues for cellsegmentation: (1) the image encoder of the segment anything model involves alarge number of parameters. Retraining or even fine-tuning the model stillrequires expensive computational resources. (2) in point prompt mode, pointsare sampled from the center of the ground truth and more than one set of pointsis expected to achieve reliable performance, which is not efficient forpractical applications. In this paper, a single-point prompt network isproposed for nuclei image segmentation, called SPPNet. We replace the originalimage encoder with a lightweight vision transformer. Also, an effectiveconvolutional block is added in parallel to extract the low-level semanticinformation from the image and compensate for the performance degradation dueto the small image encoder. We propose a new point-sampling method based on theGaussian kernel. The proposed model is evaluated on the MoNuSeg-2018 dataset.The result demonstrated that SPPNet outperforms existing U-shape architecturesand shows faster convergence in training. Compared to the segment anythingmodel, SPPNet shows roughly 20 times faster inference, with 1/70 parameters andcomputational cost. Particularly, only one set of points is required in boththe training and inference phases, which is more reasonable for clinicalapplications. The code for our work and more technical details can be found athttps://github.com/xq141839/SPPNet.</description><author>Qing Xu, Wenwei Kuang, Zeyu Zhang, Xueyao Bao, Haoran Chen, Wenting Duan</author><pubDate>Wed, 23 Aug 2023 17:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12231v1</guid></item><item><title>Advancing Volumetric Medical Image Segmentation via Global-Local Masked Autoencoder</title><link>http://arxiv.org/abs/2306.08913v2</link><description>Masked autoencoder (MAE) is a promising self-supervised pre-trainingtechnique that can improve the representation learning of a neural networkwithout human intervention. However, applying MAE directly to volumetricmedical images poses two challenges: (i) a lack of global information that iscrucial for understanding the clinical context of the holistic data, (ii) noguarantee of stabilizing the representations learned from randomly maskedinputs. To address these limitations, we propose the\textbf{G}lobal-\textbf{L}ocal \textbf{M}asked \textbf{A}uto\textbf{E}ncoder(GL-MAE), a simple yet effective self-supervised pre-training strategy. Inaddition to reconstructing masked local views, as in previous methods, GL-MAEincorporates global context learning by reconstructing masked global views.Furthermore, a complete global view is integrated as an anchor to guide thereconstruction and stabilize the learning process through global-to-globalconsistency learning and global-to-local consistency learning. Finetuningresults on multiple datasets demonstrate the superiority of our method overother state-of-the-art self-supervised algorithms, highlighting itseffectiveness on versatile volumetric medical image segmentation tasks, evenwhen annotations are scarce. Our codes and models will be released uponacceptance.</description><author>Jia-Xin Zhuang, Luyang Luo, Hao Chen</author><pubDate>Wed, 23 Aug 2023 17:07:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08913v2</guid></item><item><title>Enhancing cardiovascular risk prediction through AI-enabled calcium-omics</title><link>http://arxiv.org/abs/2308.12224v1</link><description>Background. Coronary artery calcium (CAC) is a powerful predictor of majoradverse cardiovascular events (MACE). Traditional Agatston score simply sumsthe calcium, albeit in a non-linear way, leaving room for improvedcalcification assessments that will more fully capture the extent of disease. Objective. To determine if AI methods using detailed calcification features(i.e., calcium-omics) can improve MACE prediction. Methods. We investigated additional features of calcification includingassessment of mass, volume, density, spatial distribution, territory, etc. Weused a Cox model with elastic-net regularization on 2457 CT calcium score(CTCS) enriched for MACE events obtained from a large no-cost CLARIFY program(ClinicalTri-als.gov Identifier: NCT04075162). We employed sampling techniquesto enhance model training. We also investigated Cox models with selectedfeatures to identify explainable high-risk characteristics. Results. Our proposed calcium-omics model with modified synthetic downsampling and up sampling gave C-index (80.5%/71.6%) and two-year AUC(82.4%/74.8%) for (80:20, training/testing), respectively (sampling was appliedto the training set only). Results compared favorably to Agatston which gaveC-index (71.3%/70.3%) and AUC (71.8%/68.8%), respectively. Among calcium-omicsfeatures, numbers of calcifications, LAD mass, and diffusivity (a measure ofspatial distribution) were important determinants of increased risk, with densecalcification (&gt;1000HU) associated with lower risk. The calcium-omics modelreclassified 63% of MACE patients to the high risk group in a held-out test.The categorical net-reclassification index was NRI=0.153. Conclusions. AI analysis of coronary calcification can lead to improvedresults as compared to Agatston scoring. Our findings suggest the utility ofcalcium-omics in improved prediction of risk.</description><author>Ammar Hoori, Sadeer Al-Kindi, Tao Hu, Yingnan Song, Hao Wu, Juhwan Lee, Nour Tashtish, Pingfu Fu, Robert Gilkeson, Sanjay Rajagopalan, David L. Wilson</author><pubDate>Wed, 23 Aug 2023 17:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12224v1</guid></item><item><title>Critical Learning Periods Emerge Even in Deep Linear Networks</title><link>http://arxiv.org/abs/2308.12221v1</link><description>Critical learning periods are periods early in development where temporarysensory deficits can have a permanent effect on behavior and learnedrepresentations. Despite the radical differences between biological andartificial networks, critical learning periods have been empirically observedin both systems. This suggests that critical periods may be fundamental tolearning and not an accident of biology. Yet, why exactly critical periodsemerge in deep networks is still an open question, and in particular it isunclear whether the critical periods observed in both systems depend onparticular architectural or optimization details. To isolate the key underlyingfactors, we focus on deep linear network models, and show that, surprisingly,such networks also display much of the behavior seen in biology and artificialnetworks, while being amenable to analytical treatment. We show that criticalperiods depend on the depth of the model and structure of the datadistribution. We also show analytically and in simulations that the learning offeatures is tied to competition between sources. Finally, we extend ouranalysis to multi-task learning to show that pre-training on certain tasks candamage the transfer performance on new tasks, and show how this depends on therelationship between tasks and the duration of the pre-training stage. To thebest of our knowledge, our work provides the first analytically tractable modelthat sheds light into why critical learning periods emerge in biological andartificial networks.</description><author>Michael Kleinman, Alessandro Achille, Stefano Soatto</author><pubDate>Wed, 23 Aug 2023 17:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12221v1</guid></item><item><title>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</title><link>http://arxiv.org/abs/2308.12219v1</link><description>The recent surge of generative AI has been fueled by the generative power ofdiffusion probabilistic models and the scalable capabilities of large languagemodels. Despite their potential, it remains elusive whether diffusion languagemodels can solve general language tasks comparable to their autoregressivecounterparts. This paper demonstrates that scaling diffusion models w.r.t.data, sizes, and tasks can effectively make them strong language learners. Webuild competent diffusion language models at scale by first acquiring knowledgefrom massive data via masked language modeling pretraining thanks to theirintrinsic connections. We then reprogram pretrained masked language models intodiffusion language models via diffusive adaptation, wherein task-specificfinetuning and instruction finetuning are explored to unlock their versatilityin solving general language tasks. Experiments show that scaling diffusionlanguage models consistently improves performance across downstream languagetasks. We further discover that instruction finetuning can elicit zero-shot andfew-shot in-context learning abilities that help tackle many unseen tasks byfollowing natural language instructions, and show promise in advanced andchallenging abilities such as reasoning</description><author>Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu</author><pubDate>Wed, 23 Aug 2023 17:01:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12219v1</guid></item><item><title>CIParsing: Unifying Causality Properties into Multiple Human Parsing</title><link>http://arxiv.org/abs/2308.12218v1</link><description>Existing methods of multiple human parsing (MHP) apply statistical models toacquire underlying associations between images and labeled body parts. However,acquired associations often contain many spurious correlations that degrademodel generalization, leading statistical models to be vulnerable to visuallycontextual variations in images (e.g., unseen image styles/externalinterventions). To tackle this, we present a causality inspired parsingparadigm termed CIParsing, which follows fundamental causal principlesinvolving two causal properties for human parsing (i.e., the causal diversityand the causal invariance). Specifically, we assume that an input image isconstructed by a mix of causal factors (the characteristics of body parts) andnon-causal factors (external contexts), where only the former ones cause thegeneration process of human parsing.Since causal/non-causal factors areunobservable, a human parser in proposed CIParsing is required to constructlatent representations of causal factors and learns to enforce representationsto satisfy the causal properties. In this way, the human parser is able to relyon causal factors w.r.t relevant evidence rather than non-causal factors w.r.tspurious correlations, thus alleviating model degradation and yielding improvedparsing ability. Notably, the CIParsing is designed in a plug-and-play fashionand can be integrated into any existing MHP models. Extensive experimentsconducted on two widely used benchmarks demonstrate the effectiveness andgeneralizability of our method.</description><author>Xiaojia Chen, Xuanhan Wang, Lianli Gao, Beitao Chen, Jingkuan Song, HenTao Shen</author><pubDate>Wed, 23 Aug 2023 16:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12218v1</guid></item><item><title>SG-Former: Self-guided Transformer with Evolving Token Reallocation</title><link>http://arxiv.org/abs/2308.12216v1</link><description>Vision Transformer has demonstrated impressive success across various visiontasks. However, its heavy computation cost, which grows quadratically withrespect to the token sequence length, largely limits its power in handlinglarge feature maps. To alleviate the computation cost, previous works rely oneither fine-grained self-attentions restricted to local small regions, orglobal self-attentions but to shorten the sequence length resulting in coarsegranularity. In this paper, we propose a novel model, termed as Self-guidedTransformer~(SG-Former), towards effective global self-attention with adaptivefine granularity. At the heart of our approach is to utilize a significancemap, which is estimated through hybrid-scale self-attention and evolves itselfduring training, to reallocate tokens based on the significance of each region.Intuitively, we assign more tokens to the salient regions for achievingfine-grained attention, while allocating fewer tokens to the minor regions inexchange for efficiency and global receptive fields. The proposed SG-Formerachieves performance superior to state of the art: our base size model achieves\textbf{84.7\%} Top-1 accuracy on ImageNet-1K, \textbf{51.2mAP} bbAP on CoCo,\textbf{52.7mIoU} on ADE20K surpassing the Swin Transformer by \textbf{+1.3\% /+2.7 mAP/ +3 mIoU}, with lower computation costs and fewer parameters. The codeis available at\href{https://github.com/OliverRensu/SG-Former}{https://github.com/OliverRensu/SG-Former}</description><author>Sucheng Ren, Xingyi Yang, Songhua Liu, Xinchao Wang</author><pubDate>Wed, 23 Aug 2023 16:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12216v1</guid></item><item><title>The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection</title><link>http://arxiv.org/abs/2308.12215v1</link><description>We examine the disconnect between scholarship and practice in applyingmachine learning to trust and safety problems, using misinformation detectionas a case study. We systematize literature on automated detection ofmisinformation across a corpus of 270 well-cited papers in the field. We thenexamine subsets of papers for data and code availability, design missteps,reproducibility, and generalizability. We find significant shortcomings in theliterature that call into question claimed performance and practicality.Detection tasks are often meaningfully distinct from the challenges that onlineservices actually face. Datasets and model evaluation are oftennon-representative of real-world contexts, and evaluation frequently is notindependent of model training. Data and code availability is poor. Models donot generalize well to out-of-domain data. Based on these results, we offerrecommendations for evaluating machine learning applications to trust andsafety problems. Our aim is for future work to avoid the pitfalls that weidentify.</description><author>Madelyne Xiao, Jonathan Mayer</author><pubDate>Wed, 23 Aug 2023 16:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12215v1</guid></item><item><title>CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No</title><link>http://arxiv.org/abs/2308.12213v1</link><description>Out-of-distribution (OOD) detection refers to training the model on anin-distribution (ID) dataset to classify whether the input images come fromunknown classes. Considerable effort has been invested in designing various OODdetection methods based on either convolutional neural networks ortransformers. However, zero-shot OOD detection methods driven by CLIP, whichonly require class names for ID, have received less attention. This paperpresents a novel method, namely CLIP saying "no" (\textbf{CLIPN}), whichempowers the logic of saying "no" within CLIP. Our key motivation is to equipCLIP with the capability of distinguishing OOD and ID samples usingpositive-semantic prompts and negation-semantic prompts. Specifically, wedesign a novel learnable "no" prompt and a "no" text encoder to capturenegation semantics within images. Subsequently, we introduce two lossfunctions: the image-text binary-opposite loss and the text semantic-oppositeloss, which we use to teach CLIPN to associate images with "no" prompts,thereby enabling it to identify unknown samples. Furthermore, we propose twothreshold-free inference algorithms to perform OOD detection by utilizingnegation semantics from "no" prompts and the text encoder. Experimental resultson 9 benchmark datasets (3 ID datasets and 6 OOD datasets) for the OODdetection task demonstrate that CLIPN, based on ViT-B-16, outperforms 7well-used algorithms by at least 2.34\% and 11.64\% in terms of AUROC and FPR95for zero-shot OOD detection on ImageNet-1K. Our CLIPN can serve as a solidfoundation for effectively leveraging CLIP in downstream OOD tasks. The code isavailable onhttps://github.com/xmed-lab/CLIPN}{https://github.com/xmed-lab/CLIPN.</description><author>Hualiang Wang, Yi Li, Huifeng Yao, Xiaomeng Li</author><pubDate>Wed, 23 Aug 2023 16:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12213v1</guid></item><item><title>Learning to Learn Financial Networks for Optimising Momentum Strategies</title><link>http://arxiv.org/abs/2308.12212v1</link><description>Network momentum provides a novel type of risk premium, which exploits theinterconnections among assets in a financial network to predict future returns.However, the current process of constructing financial networks relies heavilyon expensive databases and financial expertise, limiting accessibility forsmall-sized and academic institutions. Furthermore, the traditional approachtreats network construction and portfolio optimisation as separate tasks,potentially hindering optimal portfolio performance. To address thesechallenges, we propose L2GMOM, an end-to-end machine learning framework thatsimultaneously learns financial networks and optimises trading signals fornetwork momentum strategies. The model of L2GMOM is a neural network with ahighly interpretable forward propagation architecture, which is derived fromalgorithm unrolling. The L2GMOM is flexible and can be trained with diverseloss functions for portfolio performance, e.g. the negative Sharpe ratio.Backtesting on 64 continuous future contracts demonstrates a significantimprovement in portfolio profitability and risk control, with a Sharpe ratio of1.74 across a 20-year period.</description><author>Xingyue, Pu, Stefan Zohren, Stephen Roberts, Xiaowen Dong</author><pubDate>Wed, 23 Aug 2023 16:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12212v1</guid></item><item><title>Label-Efficient Online Continual Object Detection in Streaming Video</title><link>http://arxiv.org/abs/2206.00309v2</link><description>Humans can watch a continuous video stream and effortlessly perform continualacquisition and transfer of new knowledge with minimal supervision yetretaining previously learnt experiences. In contrast, existing continuallearning (CL) methods require fully annotated labels to effectively learn fromindividual frames in a video stream. Here, we examine a more realistic andchallenging problem$\unicode{x2014}$Label-Efficient Online Continual ObjectDetection (LEOCOD) in streaming video. We propose a plug-and-play module,Efficient-CLS, that can be easily inserted into and improve existing continuallearners for object detection in video streams with reduced data annotationcosts and model retraining time. We show that our method has achievedsignificant improvement with minimal forgetting across all supervision levelson two challenging CL benchmarks for streaming real-world videos. Remarkably,with only 25% annotated video frames, our method still outperforms the base CLlearners, which are trained with 100% annotations on all video frames. The dataand source code will be publicly available athttps://github.com/showlab/Efficient-CLS.</description><author>Jay Zhangjie Wu, David Junhao Zhang, Wynne Hsu, Mengmi Zhang, Mike Zheng Shou</author><pubDate>Wed, 23 Aug 2023 16:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.00309v2</guid></item><item><title>ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy</title><link>http://arxiv.org/abs/2308.12210v1</link><description>Differentially Private Federated Learning (DP-FL) has garnered attention as acollaborative machine learning approach that ensures formal privacy. Most DP-FLapproaches ensure DP at the record-level within each silo for cross-silo FL.However, a single user's data may extend across multiple silos, and the desireduser-level DP guarantee for such a setting remains unknown. In this study, wepresent ULDP-FL, a novel FL framework designed to guarantee user-level DP incross-silo FL where a single user's data may belong to multiple silos. Ourproposed algorithm directly ensures user-level DP through per-user weightedclipping, departing from group-privacy approaches. We provide a theoreticalanalysis of the algorithm's privacy and utility. Additionally, we enhance thealgorithm's utility and showcase its private implementation using cryptographicbuilding blocks. Empirical experiments on real-world datasets show substantialimprovements in our methods in privacy-utility trade-offs under user-level DPcompared to baseline methods. To the best of our knowledge, our work is thefirst FL framework that effectively provides user-level DP in the generalcross-silo FL setting.</description><author>Fumiyuki Kato, Li Xiong, Shun Takagi, Yang Cao, Masatoshi Yoshikawa</author><pubDate>Wed, 23 Aug 2023 16:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12210v1</guid></item><item><title>Curriculum Learning with Adam: The Devil Is in the Wrong Details</title><link>http://arxiv.org/abs/2308.12202v1</link><description>Curriculum learning (CL) posits that machine learning models -- similar tohumans -- may learn more efficiently from data that match their currentlearning progress. However, CL methods are still poorly understood and, inparticular for natural language processing (NLP), have achieved only limitedsuccess. In this paper, we explore why. Starting from an attempt to replicateand extend a number of recent curriculum methods, we find that their resultsare surprisingly brittle when applied to NLP. A deep dive into the(in)effectiveness of the curricula in some scenarios shows us why: whencurricula are employed in combination with the popular Adam optimisationalgorithm, they oftentimes learn to adapt to suboptimally chosen optimisationparameters for this algorithm. We present a number of different case studieswith different common hand-crafted and automated CL approaches to illustratethis phenomenon, and we find that none of them outperforms optimisation withonly Adam with well-chosen hyperparameters. As such, our results contribute tounderstanding why CL methods work, but at the same time urge caution whenclaiming positive results.</description><author>Lucas Weber, Jaap Jumelet, Paul Michel, Elia Bruni, Dieuwke Hupkes</author><pubDate>Wed, 23 Aug 2023 16:39:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12202v1</guid></item><item><title>Towards Real-Time Analysis of Broadcast Badminton Videos</title><link>http://arxiv.org/abs/2308.12199v1</link><description>Analysis of player movements is a crucial subset of sports analysis. Existingplayer movement analysis methods use recorded videos after the match is over.In this work, we propose an end-to-end framework for player movement analysisfor badminton matches on live broadcast match videos. We only use the visualinputs from the match and, unlike other approaches which use multi-modal sensordata, our approach uses only visual cues. We propose a method to calculate theon-court distance covered by both the players from the video feed of a livebroadcast badminton match. To perform this analysis, we focus on the gameplayby removing replays and other redundant parts of the broadcast match. We thenperform player tracking to identify and track the movements of both players ineach frame. Finally, we calculate the distance covered by each player and theaverage speed with which they move on the court. We further show a heatmap ofthe areas covered by the player on the court which is useful for analyzing thegameplay of the player. Our proposed framework was successfully used to analyzelive broadcast matches in real-time during the Premier Badminton League 2019(PBL 2019), with commentators and broadcasters appreciating the utility.</description><author>Nitin Nilesh, Tushar Sharma, Anurag Ghosh, C. V. Jawahar</author><pubDate>Wed, 23 Aug 2023 16:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12199v1</guid></item><item><title>Self-Supervised Knowledge-Driven Deep Learning for 3D Magnetic Inversion</title><link>http://arxiv.org/abs/2308.12193v1</link><description>The magnetic inversion method is one of the non-destructive geophysicalmethods, which aims to estimate the subsurface susceptibility distribution fromsurface magnetic anomaly data. Recently, supervised deep learning methods havebeen widely utilized in lots of geophysical fields including magneticinversion. However, these methods rely heavily on synthetic training data,whose performance is limited since the synthetic data is not independently andidentically distributed with the field data. Thus, we proposed to realizemagnetic inversion by self-supervised deep learning. The proposedself-supervised knowledge-driven 3D magnetic inversion method (SSKMI) learns onthe target field data by a closed loop of the inversion and forward models.Given that the parameters of the forward model are preset, SSKMI can optimizethe inversion model by minimizing the mean absolute error between observed andre-estimated surface magnetic anomalies. Besides, there is a knowledge-drivenmodule in the proposed inversion model, which makes the deep learning methodmore explicable. Meanwhile, comparative experiments demonstrate that theknowledge-driven module can accelerate the training of the proposed method andachieve better results. Since magnetic inversion is an ill-pose task, SSKMIproposed to constrain the inversion model by a guideline in the auxiliary loop.The experimental results demonstrate that the proposed method is a reliablemagnetic inversion method with outstanding performance.</description><author>Yinshuo Li, Zhuo Jia, Wenkai Lu, Cao Song</author><pubDate>Wed, 23 Aug 2023 16:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12193v1</guid></item><item><title>Robustness Analysis of Continuous-Depth Models with Lagrangian Techniques</title><link>http://arxiv.org/abs/2308.12192v1</link><description>This paper presents, in a unified fashion, deterministic as well asstatistical Lagrangian-verification techniques. They formally quantify thebehavioral robustness of any time-continuous process, formulated as acontinuous-depth model. To this end, we review LRT-NG, SLR, and GoTube,algorithms for constructing a tight reachtube, that is, an over-approximationof the set of states reachable within a given time-horizon, and provideguarantees for the reachtube bounds. We compare the usage of the variationalequations, associated to the system equations, the mean value theorem, and theLipschitz constants, in achieving deterministic and statistical guarantees. InLRT-NG, the Lipschitz constant is used as a bloating factor of the initialperturbation, to compute the radius of an ellipsoid in an optimal metric, whichover-approximates the set of reachable states. In SLR and GoTube, we getstatistical guarantees, by using the Lipschitz constants to compute local ballsaround samples. These are needed to calculate the probability of having foundan upper bound, of the true maximum perturbation at every timestep. Ourexperiments demonstrate the superior performance of Lagrangian techniques, whencompared to LRT, Flow*, and CAPD, and illustrate their use in the robustnessanalysis of various continuous-depth models.</description><author>Sophie A. Neubauer, Radu Grosu</author><pubDate>Wed, 23 Aug 2023 16:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12192v1</guid></item><item><title>Sign Language Translation with Iterative Prototype</title><link>http://arxiv.org/abs/2308.12191v1</link><description>This paper presents IP-SLT, a simple yet effective framework for signlanguage translation (SLT). Our IP-SLT adopts a recurrent structure andenhances the semantic representation (prototype) of the input sign languagevideo via an iterative refinement manner. Our idea mimics the behavior of humanreading, where a sentence can be digested repeatedly, till reaching accurateunderstanding. Technically, IP-SLT consists of feature extraction, prototypeinitialization, and iterative prototype refinement. The initialization modulegenerates the initial prototype based on the visual feature extracted by thefeature extraction module. Then, the iterative refinement module leverages thecross-attention mechanism to polish the previous prototype by aggregating itwith the original video feature. Through repeated refinement, the prototypefinally converges to a more stable and accurate state, leading to a fluent andappropriate translation. In addition, to leverage the sequential dependence ofprototypes, we further propose an iterative distillation loss to compress theknowledge of the final iteration into previous ones. As the autoregressivedecoding process is executed only once in inference, our IP-SLT is ready toimprove various SLT systems with acceptable overhead. Extensive experiments areconducted on public benchmarks to demonstrate the effectiveness of the IP-SLT.</description><author>Huijie Yao, Wengang Zhou, Hao Feng, Hezhen Hu, Hao Zhou, Houqiang Li</author><pubDate>Wed, 23 Aug 2023 16:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12191v1</guid></item><item><title>Development and external validation of a lung cancer risk estimation tool using gradient-boosting</title><link>http://arxiv.org/abs/2308.12188v1</link><description>Lung cancer is a significant cause of mortality worldwide, emphasizing theimportance of early detection for improved survival rates. In this study, wepropose a machine learning (ML) tool trained on data from the PLCO CancerScreening Trial and validated on the NLST to estimate the likelihood of lungcancer occurrence within five years. The study utilized two datasets, the PLCO(n=55,161) and NLST (n=48,595), consisting of comprehensive information on riskfactors, clinical measurements, and outcomes related to lung cancer. Datapreprocessing involved removing patients who were not current or former smokersand those who had died of causes unrelated to lung cancer. Additionally, afocus was placed on mitigating bias caused by censored data. Feature selection,hyper-parameter optimization, and model calibration were performed usingXGBoost, an ensemble learning algorithm that combines gradient boosting anddecision trees. The ML model was trained on the pre-processed PLCO dataset andtested on the NLST dataset. The model incorporated features such as age,gender, smoking history, medical diagnoses, and family history of lung cancer.The model was well-calibrated (Brier score=0.044). ROC-AUC was 82% on the PLCOdataset and 70% on the NLST dataset. PR-AUC was 29% and 11% respectively. Whencompared to the USPSTF guidelines for lung cancer screening, our model providedthe same recall with a precision of 13.1% vs. 9.3% on the PLCO dataset and 3.2%vs. 3.1% on the NLST dataset. The developed ML tool provides a freely availableweb application for estimating the likelihood of developing lung cancer withinfive years. By utilizing risk factors and clinical data, individuals can assesstheir risk and make informed decisions regarding lung cancer screening. Thisresearch contributes to the efforts in early detection and preventionstrategies, aiming to reduce lung cancer-related mortality rates.</description><author>Pierre-Louis Benveniste, Julie Alberge, Lei Xing, Jean-Emmanuel Bibault</author><pubDate>Wed, 23 Aug 2023 16:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12188v1</guid></item><item><title>ProtoBandit: Efficient Prototype Selection via Multi-Armed Bandits</title><link>http://arxiv.org/abs/2210.01860v4</link><description>In this work, we propose a multi-armed bandit-based framework for identifyinga compact set of informative data instances (i.e., the prototypes) from asource dataset $S$ that best represents a given target set $T$. Prototypicalexamples of a given dataset offer interpretable insights into the underlyingdata distribution and assist in example-based reasoning, thereby influencingevery sphere of human decision-making. Current state-of-the-art prototypeselection approaches require $O(|S||T|)$ similarity comparisons between sourceand target data points, which becomes prohibitively expensive for large-scalesettings. We propose to mitigate this limitation by employing stochastic greedysearch in the space of prototypical examples and multi-armed bandits forreducing the number of similarity comparisons. Our randomized algorithm,ProtoBandit, identifies a set of $k$ prototypes incurring $O(k^3|S|)$similarity comparisons, which is independent of the size of the target set. Aninteresting outcome of our analysis is for the $k$-medoids clustering problem$T = S$ setting) in which we show that our algorithm ProtoBandit approximatesthe BUILD step solution of the partitioning around medoids (PAM) method in$O(k^3|S|)$ complexity. Empirically, we observe that ProtoBandit reduces thenumber of similarity computation calls by several orders of magnitudes($100-1000$ times) while obtaining solutions similar in quality to those fromstate-of-the-art approaches.</description><author>Arghya Roy Chaudhuri, Pratik Jawanpuria, Bamdev Mishra</author><pubDate>Wed, 23 Aug 2023 16:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01860v4</guid></item><item><title>Non-Exemplar Online Class-incremental Continual Learning via Dual-prototype Self-augment and Refinement</title><link>http://arxiv.org/abs/2303.10891v2</link><description>This paper investigates a new, practical, but challenging problem namedNon-exemplar Online Class-incremental continual Learning (NO-CL), which aims topreserve the discernibility of base classes without buffering data examples andefficiently learn novel classes continuously in a single-pass (i.e., online)data stream. The challenges of this task are mainly two-fold: (1) Both base andnovel classes suffer from severe catastrophic forgetting as no previous samplesare available for replay. (2) As the online data can only be observed once,there is no way to fully re-train the whole model, e.g., re-calibrate thedecision boundaries via prototype alignment or feature distillation. In thispaper, we propose a novel Dual-prototype Self-augment and Refinement method(DSR) for NO-CL problem, which consists of two strategies: 1) Dual classprototypes: vanilla and high-dimensional prototypes are exploited to utilizethe pre-trained information and obtain robust quasi-orthogonal representationsrather than example buffers for both privacy preservation and memory reduction.2) Self-augment and refinement: Instead of updating the whole network, weoptimize high-dimensional prototypes alternatively with the extra projectionmodule based on self-augment vanilla prototypes, through a bi-leveloptimization problem. Extensive experiments demonstrate the effectiveness andsuperiority of the proposed DSR in NO-CL.</description><author>Fushuo Huo, Wenchao Xu, Jingcai Guo, Haozhao Wang, Yunfeng Fan, Song Guo</author><pubDate>Wed, 23 Aug 2023 16:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10891v2</guid></item><item><title>Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review</title><link>http://arxiv.org/abs/2304.10410v2</link><description>Driven by deep learning techniques, perception technology in autonomousdriving has developed rapidly in recent years, enabling vehicles to accuratelydetect and interpret surrounding environment for safe and efficient navigation.To achieve accurate and robust perception capabilities, autonomous vehicles areoften equipped with multiple sensors, making sensor fusion a crucial part ofthe perception system. Among these fused sensors, radars and cameras enable acomplementary and cost-effective perception of the surrounding environmentregardless of lighting and weather conditions. This review aims to provide acomprehensive guideline for radar-camera fusion, particularly concentrating onperception tasks related to object detection and semantic segmentation.Based onthe principles of the radar and camera sensors, we delve into the dataprocessing process and representations, followed by an in-depth analysis andsummary of radar-camera fusion datasets. In the review of methodologies inradar-camera fusion, we address interrogative questions, including "why tofuse", "what to fuse", "where to fuse", "when to fuse", and "how to fuse",subsequently discussing various challenges and potential research directionswithin this domain. To ease the retrieval and comparison of datasets and fusionmethods, we also provide an interactive website:https://radar-camera-fusion.github.io.</description><author>Shanliang Yao, Runwei Guan, Xiaoyu Huang, Zhuoxiao Li, Xiangyu Sha, Yong Yue, Eng Gee Lim, Hyungjoon Seo, Ka Lok Man, Xiaohui Zhu, Yutao Yue</author><pubDate>Wed, 23 Aug 2023 16:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10410v2</guid></item><item><title>A Survey on Dataset Distillation: Approaches, Applications and Future Directions</title><link>http://arxiv.org/abs/2305.01975v2</link><description>Dataset distillation is attracting more attention in machine learning astraining sets continue to grow and the cost of training state-of-the-art modelsbecomes increasingly high. By synthesizing datasets with high informationdensity, dataset distillation offers a range of potential applications,including support for continual learning, neural architecture search, andprivacy protection. Despite recent advances, we lack a holistic understandingof the approaches and applications. Our survey aims to bridge this gap by firstproposing a taxonomy of dataset distillation, characterizing existingapproaches, and then systematically reviewing the data modalities, and relatedapplications. In addition, we summarize the challenges and discuss futuredirections for this field of research.</description><author>Jiahui Geng, Zongxiong Chen, Yuandou Wang, Herbert Woisetschlaeger, Sonja Schimmler, Ruben Mayer, Zhiming Zhao, Chunming Rong</author><pubDate>Wed, 23 Aug 2023 16:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01975v2</guid></item><item><title>Black-box Source-free Domain Adaptation via Two-stage Knowledge Distillation</title><link>http://arxiv.org/abs/2305.07881v3</link><description>Source-free domain adaptation aims to adapt deep neural networks using onlypre-trained source models and target data. However, accessing the source modelstill has a potential concern about leaking the source data, which reveals thepatient's privacy. In this paper, we study the challenging but practicalproblem: black-box source-free domain adaptation where only the outputs of thesource model and target data are available. We propose a simple but effectivetwo-stage knowledge distillation method. In Stage\uppercase\expandafter{\romannumeral1}, we train the target model from scratchwith soft pseudo-labels generated by the source model in a knowledgedistillation manner. In Stage \uppercase\expandafter{\romannumeral2}, weinitialize another model as the new student model to avoid the erroraccumulation caused by noisy pseudo-labels. We feed the images with weakaugmentation to the teacher model to guide the learning of the student model.Our method is simple and flexible, and achieves surprising results on threecross-domain segmentation tasks.</description><author>Shuai Wang, Daoan Zhang, Zipei Yan, Shitong Shao, Rui Li</author><pubDate>Wed, 23 Aug 2023 15:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07881v3</guid></item><item><title>Unsupervised anomalies detection in IIoT edge devices networks using federated learning</title><link>http://arxiv.org/abs/2308.12175v1</link><description>In a connection of many IoT devices that each collect data, normally traininga machine learning model would involve transmitting the data to a centralserver which requires strict privacy rules. However, some owners are reluctantof availing their data out of the company due to data security concerns.Federated learning(FL) as a distributed machine learning approach performstraining of a machine learning model on the device that gathered the dataitself. In this scenario, data is not share over the network for trainingpurpose. Fedavg as one of FL algorithms permits a model to be copied toparticipating devices during a training session. The devices could be chosen atrandom, and a device can be aborted. The resulting models are sent to thecoordinating server and then average models from the devices that finishedtraining. The process is repeated until a desired model accuracy is achieved.By doing this, FL approach solves the privacy problem for IoT/ IIoT devicesthat held sensitive data for the owners. In this paper, we leverage thebenefits of FL and implemented Fedavg algorithm on a recent dataset thatrepresent the modern IoT/ IIoT device networks. The results were almost thesame as the centralized machine learning approach. We also evaluated someshortcomings of Fedavg such as unfairness that happens during the training whenstruggling devices do not participate for every stage of training. Thisinefficient training of local or global model could lead in a high number offalse alarms in intrusion detection systems for IoT/IIoT gadgets developedusing Fedavg. Hence, after evaluating the FedAv deep auto encoder withcentralized deep auto encoder ML, we further proposed and designed a FairFedavg algorithm that will be evaluated in the future work.</description><author>Niyomukiza Thamar, Hossam Samy Elsaid Sharara</author><pubDate>Wed, 23 Aug 2023 15:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12175v1</guid></item><item><title>Learning Interpretable Dynamics from Images of a Freely Rotating 3D Rigid Body</title><link>http://arxiv.org/abs/2209.11355v3</link><description>In many real-world settings, image observations of freely rotating 3D rigidbodies, such as satellites, may be available when low-dimensional measurementsare not. However, the high-dimensionality of image data precludes the use ofclassical estimation techniques to learn the dynamics and a lack ofinterpretability reduces the usefulness of standard deep learning methods. Inthis work, we present a physics-informed neural network model to estimate andpredict 3D rotational dynamics from image sequences. We achieve this using amulti-stage prediction pipeline that maps individual images to a latentrepresentation homeomorphic to $\mathbf{SO}(3)$, computes angular velocitiesfrom latent pairs, and predicts future latent states using the Hamiltonianequations of motion with a learned representation of the Hamiltonian. Wedemonstrate the efficacy of our approach on a new rotating rigid-body datasetwith sequences of rotating cubes and rectangular prisms with uniform andnon-uniform density.</description><author>Justice Mason, Christine Allen-Blanchette, Nicholas Zolman, Elizabeth Davison, Naomi Leonard</author><pubDate>Wed, 23 Aug 2023 15:51:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.11355v3</guid></item><item><title>Tumor-Centered Patching for Enhanced Medical Image Segmentation</title><link>http://arxiv.org/abs/2308.12168v1</link><description>The realm of medical image diagnosis has advanced significantly with theintegration of computer-aided diagnosis and surgical systems. However,challenges persist, particularly in achieving precise image segmentation. Whiledeep learning techniques show potential, obstacles like limited resources, slowconvergence, and class imbalance impede their effectiveness. Traditionalpatch-based methods, though common, struggle to capture intricate tumorboundaries and often lead to redundant samples, compromising computationalefficiency and feature quality. To tackle these issues, this researchintroduces an innovative approach centered on the tumor itself for patch-basedimage analysis. This novel tumor-centered patching method aims to address theclass imbalance and boundary deficiencies, enabling focused and accurate tumorsegmentation. By aligning patches with the tumor's anatomical context, thistechnique enhances feature extraction accuracy and reduces computational load.Experimental results demonstrate improved class imbalance, with segmentationscores of 0.78, 0.76, and 0.71 for whole, core, and enhancing tumors,respectively using a lightweight simple U-Net. This approach shows potentialfor enhancing medical image segmentation and improving computer-aided diagnosissystems.</description><author>Mutyyba Asghar, Ahmad Raza Shahid, Akhtar Jamil, Kiran Aftab, Syed Ather Enam</author><pubDate>Wed, 23 Aug 2023 15:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12168v1</guid></item><item><title>Large Language Model as a User Simulator</title><link>http://arxiv.org/abs/2308.11534v2</link><description>The unparalleled performance of closed-sourced ChatGPT has sparked effortstowards its democratization, with notable strides made by leveraging real userand ChatGPT conversations, as evidenced by Vicuna. However, while currentendeavors like Baize and UltraChat aim to auto-generate conversational data dueto challenges in gathering human participation, they primarily rely on ChatGPTto simulate human behaviors based on directives rather than genuine humanlearning. This results in a limited scope, diminished diversity, and an absenceof genuine multi-round conversational dynamics. To address the above issues, weinnovatively target human questions extracted from genuine human-machineconversations as a learning goal and train a user simulator, UserGPT, toproduce a high-quality human-centric synthetic conversation dataset, RealChat.Subsequently, this dataset trains our assistant model, ReaLM. Experimentally,ReaLM outpaces baseline models in both Vicuna-Bench and MT-Bench by pairwisecomparison when considering equivalent training set sizes, and manualevaluation also shows that our model is highly competitive. Impressively, whenfine-tuned with the latest LLaMA 2 model, ReaLM secured a leading score of 6.33in the MT-Bench, outshining the contemporary same-scale models, including theLLaMA-2-7B-chat model. Further in-depth analysis demonstrates the scalabilityand transferability of our approach. A preliminary exploration into theinterplay between training set data quality and resultant model performance isalso undertaken, laying a robust groundwork for future investigations. The codeis available at https://github.com/FreedomIntelligence/ReaLM.</description><author>Chuyi Kong, Yaxin Fan, Xiang Wan, Feng Jiang, Benyou Wang</author><pubDate>Wed, 23 Aug 2023 15:33:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11534v2</guid></item><item><title>NPF-200: A Multi-Modal Eye Fixation Dataset and Method for Non-Photorealistic Videos</title><link>http://arxiv.org/abs/2308.12163v1</link><description>Non-photorealistic videos are in demand with the wave of the metaverse, butlack of sufficient research studies. This work aims to take a step forward tounderstand how humans perceive non-photorealistic videos with eye fixation(\ie, saliency detection), which is critical for enhancing media production,artistic design, and game user experience. To fill in the gap of missing asuitable dataset for this research line, we present NPF-200, the firstlarge-scale multi-modal dataset of purely non-photorealistic videos with eyefixations. Our dataset has three characteristics: 1) it contains soundtracksthat are essential according to vision and psychological studies; 2) itincludes diverse semantic content and videos are of high-quality; 3) it hasrich motions across and within videos. We conduct a series of analyses to gaindeeper insights into this task and compare several state-of-the-art methods toexplore the gap between natural images and non-photorealistic data.Additionally, as the human attention system tends to extract visual and audiofeatures with different frequencies, we propose a universal frequency-awaremulti-modal non-photorealistic saliency detection model called NPSNet,demonstrating the state-of-the-art performance of our task. The results uncoverstrengths and weaknesses of multi-modal network design and multi-domaintraining, opening up promising directions for future works. {Our dataset andcode can be found at \url{https://github.com/Yangziyu/NPF200}}.</description><author>Ziyu Yang, Sucheng Ren, Zongwei Wu, Nanxuan Zhao, Junle Wang, Jing Qin, Shengfeng He</author><pubDate>Wed, 23 Aug 2023 15:25:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12163v1</guid></item><item><title>AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes</title><link>http://arxiv.org/abs/2308.07221v5</link><description>We propose a method named AudioFormer,which learns audio featurerepresentations through the acquisition of discrete acoustic codes andsubsequently fine-tunes them for audio classification tasks. Initially,weintroduce a novel perspective by considering the audio classification task as aform of natural language understanding (NLU). Leveraging an existing neuralaudio codec model,we generate discrete acoustic codes and utilize them to traina masked language model (MLM),thereby obtaining audio feature representations.Furthermore,we pioneer the integration of a Multi-Positive sample Contrastive(MPC) learning approach. This method enables the learning of jointrepresentations among multiple discrete acoustic codes within the same audioinput. In our experiments,we treat discrete acoustic codes as textual data andtrain a masked language model using a cloze-like methodology,ultimatelyderiving high-quality audio representations. Notably,the MPC learning techniqueeffectively captures collaborative representations among distinct positivesamples. Our research outcomes demonstrate that AudioFormer attainssignificantly improved performance compared to prevailing monomodal audioclassification models across multiple datasets,and even outperformsaudio-visual multimodal classification models on select datasets.Specifically,our approach achieves remarkable results on datasets includingAudioSet (2M,20K),and FSD50K,with performance scores of 53.9,45.1,and65.6,respectively. We have openly shared both the code and models:https://github.com/LZH-0225/AudioFormer.git.</description><author>Zhaohui Li, Haitao Wang, Xinghua Jiang</author><pubDate>Wed, 23 Aug 2023 15:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07221v5</guid></item><item><title>Domain Specific Question Answering Over Knowledge Graphs Using Logical Programming and Large Language Models</title><link>http://arxiv.org/abs/2303.02206v2</link><description>Answering questions over domain-specific graphs requires a tailored approachdue to the limited number of relations and the specific nature of the domain.Our approach integrates classic logical programming languages into largelanguage models (LLMs), enabling the utilization of logical reasoningcapabilities to tackle the KGQA task. By representing the questions as Prologqueries, which are readable and near close to natural language inrepresentation, we facilitate the generation of programmatically derivedanswers. To validate the effectiveness of our approach, we evaluate it using awell-known benchmark dataset, MetaQA. Our experimental results demonstrate thatour method achieves accurate identification of correct answer entities for alltest questions, even when trained on a small fraction of annotated data.Overall, our work presents a promising approach to addressing questionanswering over domain-specific graphs, offering an explainable and robustsolution by incorporating logical programming languages.</description><author>Navid Madani, Rohini K. Srihari, Kenneth Joseph</author><pubDate>Wed, 23 Aug 2023 15:23:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02206v2</guid></item><item><title>Data-driven decision-focused surrogate modeling</title><link>http://arxiv.org/abs/2308.12161v1</link><description>We introduce the concept of decision-focused surrogate modeling for solvingcomputationally challenging nonlinear optimization problems in real-timesettings. The proposed data-driven framework seeks to learn a simpler, e.g.convex, surrogate optimization model that is trained to minimize the decisionprediction error, which is defined as the difference between the optimalsolutions of the original and the surrogate optimization models. The learningproblem, formulated as a bilevel program, can be viewed as a data-driveninverse optimization problem to which we apply a decomposition-based solutionalgorithm from previous work. We validate our framework through numericalexperiments involving the optimization of common nonlinear chemical processessuch as chemical reactors, heat exchanger networks, and material blendingsystems. We also present a detailed comparison of decision-focused surrogatemodeling with standard data-driven surrogate modeling methods and demonstratethat our approach is significantly more data-efficient while producing simplesurrogate models with high decision prediction accuracy.</description><author>Rishabh Gupta, Qi Zhang</author><pubDate>Wed, 23 Aug 2023 15:23:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12161v1</guid></item><item><title>Evaluation of Faithfulness Using the Longest Supported Subsequence</title><link>http://arxiv.org/abs/2308.12157v1</link><description>As increasingly sophisticated language models emerge, their trustworthinessbecomes a pivotal issue, especially in tasks such as summarization andquestion-answering. Ensuring their responses are contextually grounded andfaithful is challenging due to the linguistic diversity and the myriad ofpossible answers. In this paper, we introduce a novel approach to evaluatefaithfulness of machine-generated text by computing the longest noncontinuoussubstring of the claim that is supported by the context, which we refer to asthe Longest Supported Subsequence (LSS). Using a new human-annotated dataset,we finetune a model to generate LSS. We introduce a new method of evaluationand demonstrate that these metrics correlate better with human ratings when LSSis employed, as opposed to when it is not. Our proposed metric demonstrates an18% enhancement over the prevailing state-of-the-art metric for faithfulness onour dataset. Our metric consistently outperforms other metrics on asummarization dataset across six different models. Finally, we compare severalpopular Large Language Models (LLMs) for faithfulness using this metric. Werelease the human-annotated dataset built for predicting LSS and our fine-tunedmodel for evaluating faithfulness.</description><author>Anirudh Mittal, Timo Schick, Mikel Artetxe, Jane Dwivedi-Yu</author><pubDate>Wed, 23 Aug 2023 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12157v1</guid></item><item><title>On the link between generative semi-supervised learning and generative open-set recognition</title><link>http://arxiv.org/abs/2303.11702v4</link><description>This study investigates the relationship between semi-supervised learning(SSL, which is training off partially labelled datasets) and open-setrecognition (OSR, which is classification with simultaneous novelty detection)under the context of generative adversarial networks (GANs). Although noprevious study has formally linked SSL and OSR, their respective methods sharestriking similarities. Specifically, SSL-GANs and OSR-GANs require theirgenerators to produce 'bad-looking' samples which are used to regularise theirclassifier networks. We hypothesise that the definitions of bad-looking samplesin SSL and OSR represents the same concept and realises the same goal. Moreformally, bad-looking samples lie in the complementary space, which is the areabetween and around the boundaries of the labelled categories within theclassifier's embedding space. By regularising a classifier with samples in thecomplementary space, classifiers achieve improved generalisation for SSL andalso generalise the open space for OSR. To test this hypothesis, we compare afoundational SSL-GAN with the state-of-the-art OSR-GAN under the same SSL-OSRexperimental conditions. Our results find that SSL-GANs achieve near identicalresults to OSR-GANs, proving the SSL-OSR link. Subsequently, to further thisnew research path, we compare several SSL-GANs various SSL-OSR setups whichthis first benchmark results. A combined framework of SSL-OSR certainlyimproves the practicality and cost-efficiency of classifier training, and sofurther theoretical and application studies are also discussed.</description><author>Emile Reyn Engelbrecht, Johan du Preez</author><pubDate>Wed, 23 Aug 2023 15:18:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11702v4</guid></item><item><title>Multimodal Latent Emotion Recognition from Micro-expression and Physiological Signals</title><link>http://arxiv.org/abs/2308.12156v1</link><description>This paper discusses the benefits of incorporating multimodal data forimproving latent emotion recognition accuracy, focusing on micro-expression(ME) and physiological signals (PS). The proposed approach presents a novelmultimodal learning framework that combines ME and PS, including a 1D separableand mixable depthwise inception network, a standardised normal distributionweighted feature fusion method, and depth/physiology guided attention modulesfor multimodal learning. Experimental results show that the proposed approachoutperforms the benchmark method, with the weighted fusion method and guidedattention modules both contributing to enhanced performance.</description><author>Liangfei Zhang, Yifei Qian, Ognjen Arandjelovic, Anthony Zhu</author><pubDate>Wed, 23 Aug 2023 15:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12156v1</guid></item><item><title>A Probabilistic Fluctuation based Membership Inference Attack for Generative Models</title><link>http://arxiv.org/abs/2308.12143v1</link><description>Membership Inference Attack (MIA) identifies whether a record exists in amachine learning model's training set by querying the model. MIAs on theclassic classification models have been well-studied, and recent works havestarted to explore how to transplant MIA onto generative models. Ourinvestigation indicates that existing MIAs designed for generative modelsmainly depend on the overfitting in target models. However, overfitting can beavoided by employing various regularization techniques, whereas existing MIAsdemonstrate poor performance in practice. Unlike overfitting, memorization isessential for deep learning models to attain optimal performance, making it amore prevalent phenomenon. Memorization in generative models leads to anincreasing trend in the probability distribution of generating records aroundthe member record. Therefore, we propose a Probabilistic Fluctuation AssessingMembership Inference Attack (PFAMI), a black-box MIA that infers memberships bydetecting these trends via analyzing the overall probabilistic fluctuationsaround given records. We conduct extensive experiments across multiplegenerative models and datasets, which demonstrate PFAMI can improve the attacksuccess rate (ASR) by about 27.9% when compared with the best baseline.</description><author>Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang</author><pubDate>Wed, 23 Aug 2023 15:00:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12143v1</guid></item><item><title>Exploring the Landscape of Natural Language Processing Research</title><link>http://arxiv.org/abs/2307.10652v4</link><description>As an efficient approach to understand, generate, and process naturallanguage texts, research in natural language processing (NLP) has exhibited arapid spread and wide adoption in recent years. Given the increasing researchwork in this area, several NLP-related approaches have been surveyed in theresearch community. However, a comprehensive study that categorizes establishedtopics, identifies trends, and outlines areas for future research remainsabsent. Contributing to closing this gap, we have systematically classified andanalyzed research papers in the ACL Anthology. As a result, we present astructured overview of the research landscape, provide a taxonomy of fields ofstudy in NLP, analyze recent developments in NLP, summarize our findings, andhighlight directions for future work.</description><author>Tim Schopf, Karim Arabi, Florian Matthes</author><pubDate>Wed, 23 Aug 2023 15:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10652v4</guid></item><item><title>Backdooring Textual Inversion for Concept Censorship</title><link>http://arxiv.org/abs/2308.10718v2</link><description>Recent years have witnessed success in AIGC (AI Generated Content). Peoplecan make use of a pre-trained diffusion model to generate images of highquality or freely modify existing pictures with only prompts in naturelanguage. More excitingly, the emerging personalization techniques make itfeasible to create specific-desired images with only a few images asreferences. However, this induces severe threats if such advanced techniquesare misused by malicious users, such as spreading fake news or defamingindividual reputations. Thus, it is necessary to regulate personalizationmodels (i.e., concept censorship) for their development and advancement. In this paper, we focus on the personalization technique dubbed TextualInversion (TI), which is becoming prevailing for its lightweight nature andexcellent performance. TI crafts the word embedding that contains detailedinformation about a specific object. Users can easily download the wordembedding from public websites like Civitai and add it to their own stablediffusion model without fine-tuning for personalization. To achieve the conceptcensorship of a TI model, we propose leveraging the backdoor technique for goodby injecting backdoors into the Textual Inversion embeddings. Briefly, weselect some sensitive words as triggers during the training of TI, which willbe censored for normal use. In the subsequent generation stage, if the triggersare combined with personalized embeddings as final prompts, the model willoutput a pre-defined target image rather than images including the desiredmalicious concept. To demonstrate the effectiveness of our approach, we conduct extensiveexperiments on Stable Diffusion, a prevailing open-sourced text-to-image model.Our code, data, and results are available athttps://concept-censorship.github.io.</description><author>Yutong Wu, Jie Zhang, Florian Kerschbaum, Tianwei Zhang</author><pubDate>Wed, 23 Aug 2023 14:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10718v2</guid></item><item><title>Mesh Conflation of Oblique Photogrammetric Models using Virtual Cameras and Truncated Signed Distance Field</title><link>http://arxiv.org/abs/2308.12139v1</link><description>Conflating/stitching 2.5D raster digital surface models (DSM) into a largeone has been a running practice in geoscience applications, however, conflatingfull-3D mesh models, such as those from oblique photogrammetry, is extremelychallenging. In this letter, we propose a novel approach to address thischallenge by conflating multiple full-3D oblique photogrammetric models into asingle, and seamless mesh for high-resolution site modeling. Given two or moreindividually collected and created photogrammetric meshes, we first propose tocreate a virtual camera field (with a panoramic field of view) to incubatevirtual spaces represented by Truncated Signed Distance Field (TSDF), animplicit volumetric field friendly for linear 3D fusion; then we adaptivelyleverage the truncated bound of meshes in TSDF to conflate them into a singleand accurate full 3D site model. With drone-based 3D meshes, we show that ourapproach significantly improves upon traditional methods for model conflations,to drive new potentials to create excessively large and accurate full 3D meshmodels in support of geoscience and environmental applications.</description><author>Shuang Song, Rongjun Qin</author><pubDate>Wed, 23 Aug 2023 14:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12139v1</guid></item><item><title>Select-and-Combine (SAC): A Novel Multi-Stereo Depth Fusion Algorithm for Point Cloud Generation via Efficient Local Markov Netlets</title><link>http://arxiv.org/abs/2308.12138v1</link><description>Many practical systems for image-based surface reconstruction employ astereo/multi-stereo paradigm, due to its ability to scale for large scenes andits ease of implementation for out-of-core operations. In this process,multiple and abundant depth maps from stereo matching must be combined andfused into a single, consistent, and clean point cloud. However, the noises andoutliers caused by stereo matching and the heterogenous geometric errors of theposes present a challenge for existing fusion algorithms, since they mostlyassume Gaussian errors and predict fused results based on data from localspatial neighborhoods, which may inherit uncertainties from multiple depthsresulting in lowered accuracy. In this paper, we propose a novel depth fusionparadigm, that instead of numerically fusing points from multiple depth maps,selects the best depth map per point, and combines them into a single and cleanpoint cloud. This paradigm, called select-and-combine (SAC), is achievedthrough modeling the point level fusion using local Markov Netlets, amicro-network over point across neighboring views for depth/view selection,followed by a Netlets collapse process for point combination. The MarkovNetlets are optimized such that they can inherently leverage spatialconsistencies among depth maps of neighboring views, thus they can addresserrors beyond Gaussian ones. Our experiment results show that our approachoutperforms existing depth fusion approaches by increasing the F1 score thatconsiders both accuracy and completeness by 2.07% compared to the best existingmethod. Finally, our approach generates clearer point clouds that are 18% lessredundant while with a higher accuracy before fusion</description><author>Mostafa Elhashash, Rongjun Qin</author><pubDate>Wed, 23 Aug 2023 14:51:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12138v1</guid></item><item><title>A real-time dynamic obstacle tracking and mapping system for UAV navigation and collision avoidance with an RGB-D camera</title><link>http://arxiv.org/abs/2209.08258v3</link><description>The real-time dynamic environment perception has become vital for autonomousrobots in crowded spaces. Although the popular voxel-based mapping methods canefficiently represent 3D obstacles with arbitrarily complex shapes, they canhardly distinguish between static and dynamic obstacles, leading to the limitedperformance of obstacle avoidance. While plenty of sophisticated learning-baseddynamic obstacle detection algorithms exist in autonomous driving, thequadcopter's limited computation resources cannot achieve real-time performanceusing those approaches. To address these issues, we propose a real-time dynamicobstacle tracking and mapping system for quadcopter obstacle avoidance using anRGB-D camera. The proposed system first utilizes a depth image with anoccupancy voxel map to generate potential dynamic obstacle regions asproposals. With the obstacle region proposals, the Kalman filter and ourcontinuity filter are applied to track each dynamic obstacle. Finally, theenvironment-aware trajectory prediction method is proposed based on the Markovchain using the states of tracked dynamic obstacles. We implemented theproposed system with our custom quadcopter and navigation planner. Thesimulation and physical experiments show that our methods can successfullytrack and represent obstacles in dynamic environments in real-time and safelyavoid obstacles.</description><author>Zhefan Xu, Xiaoyang Zhan, Baihan Chen, Yumeng Xiu, Chenhao Yang, Kenji Shimada</author><pubDate>Wed, 23 Aug 2023 14:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.08258v3</guid></item><item><title>Physics-informed neural networks with unknown measurement noise</title><link>http://arxiv.org/abs/2211.15498v2</link><description>Physics-informed neural networks (PINNs) constitute a flexible approach toboth finding solutions and identifying parameters of partial differentialequations. Most works on the topic assume noiseless data, or data contaminatedby weak Gaussian noise. We show that the standard PINN framework breaks down incase of non-Gaussian noise. We give a way of resolving this fundamental issueand we propose to jointly train an energy-based model (EBM) to learn thecorrect noise distribution. We illustrate the improved performance of ourapproach using multiple examples.</description><author>Philipp Pilar, Niklas Wahlstrm</author><pubDate>Wed, 23 Aug 2023 14:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15498v2</guid></item><item><title>Vision-aided UAV navigation and dynamic obstacle avoidance using gradient-based B-spline trajectory optimization</title><link>http://arxiv.org/abs/2209.07003v2</link><description>Navigating dynamic environments requires the robot to generate collision-freetrajectories and actively avoid moving obstacles. Most previous works designedpath planning algorithms based on one single map representation, such as thegeometric, occupancy, or ESDF map. Although they have shown success in staticenvironments, due to the limitation of map representation, those methods cannotreliably handle static and dynamic obstacles simultaneously. To address theproblem, this paper proposes a gradient-based B-spline trajectory optimizationalgorithm utilizing the robot's onboard vision. The depth vision enables therobot to track and represent dynamic objects geometrically based on the voxelmap. The proposed optimization first adopts the circle-based guide-pointalgorithm to approximate the costs and gradients for avoiding static obstacles.Then, with the vision-detected moving objects, our receding-horizon distancefield is simultaneously used to prevent dynamic collisions. Finally, theiterative re-guide strategy is applied to generate the collision-freetrajectory. The simulation and physical experiments prove that our method canrun in real-time to navigate dynamic environments safely.</description><author>Zhefan Xu, Yumeng Xiu, Xiaoyang Zhan, Baihan Chen, Kenji Shimada</author><pubDate>Wed, 23 Aug 2023 14:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07003v2</guid></item><item><title>Lite-HRNet Plus: Fast and Accurate Facial Landmark Detection</title><link>http://arxiv.org/abs/2308.12133v1</link><description>Facial landmark detection is an essential technology for driver statustracking and has been in demand for real-time estimations. As a landmarkcoordinate prediction, heatmap-based methods are known to achieve a highaccuracy, and Lite-HRNet can achieve a fast estimation. However, withLite-HRNet, the problem of a heavy computational cost of the fusion block,which connects feature maps with different resolutions, has yet to be solved.In addition, the strong output module used in HRNetV2 is not applied toLite-HRNet. Given these problems, we propose a novel architecture calledLite-HRNet Plus. Lite-HRNet Plus achieves two improvements: a novel fusionblock based on a channel attention and a novel output module with lesscomputational intensity using multi-resolution feature maps. Throughexperiments conducted on two facial landmark datasets, we confirmed thatLite-HRNet Plus further improved the accuracy in comparison with conventionalmethods, and achieved a state-of-the-art accuracy with a computationalcomplexity with the range of 10M FLOPs.</description><author>Sota Kato, Kazuhiro Hotta, Yuhki Hatakeyama, Yoshinori Konishi</author><pubDate>Wed, 23 Aug 2023 14:43:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12133v1</guid></item><item><title>Semantic Change Detection for the Romanian Language</title><link>http://arxiv.org/abs/2308.12131v1</link><description>Automatic semantic change methods try to identify the changes that appearover time in the meaning of words by analyzing their usage in diachroniccorpora. In this paper, we analyze different strategies to create static andcontextual word embedding models, i.e., Word2Vec and ELMo, on real-worldEnglish and Romanian datasets. To test our pipeline and determine theperformance of our models, we first evaluate both word embedding models on anEnglish dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on aRomanian dataset, and we underline different aspects of semantic changes inthis low-resource language, such as meaning acquisition and loss. Theexperimental results show that, depending on the corpus, the most importantfactors to consider are the choice of model and the distance to calculate ascore for detecting semantic change.</description><author>Ciprian-Octavian Truic, Victor Tudose, Elena-Simona Apostol</author><pubDate>Wed, 23 Aug 2023 14:37:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12131v1</guid></item><item><title>Masking Strategies for Background Bias Removal in Computer Vision Models</title><link>http://arxiv.org/abs/2308.12127v1</link><description>Models for fine-grained image classification tasks, where the differencebetween some classes can be extremely subtle and the number of samples perclass tends to be low, are particularly prone to picking up background-relatedbiases and demand robust methods to handle potential examples without-of-distribution (OOD) backgrounds. To gain deeper insights into thiscritical problem, our research investigates the impact of background-inducedbias on fine-grained image classification, evaluating standard backbone modelssuch as Convolutional Neural Network (CNN) and Vision Transformers (ViT). Weexplore two masking strategies to mitigate background-induced bias: Earlymasking, which removes background information at the (input) image level, andlate masking, which selectively masks high-level spatial features correspondingto the background. Extensive experiments assess the behavior of CNN and ViTmodels under different masking strategies, with a focus on their generalizationto OOD backgrounds. The obtained findings demonstrate that both proposedstrategies enhance OOD performance compared to the baseline models, with earlymasking consistently exhibiting the best OOD performance. Notably, a ViTvariant employing GAP-Pooled Patch token-based classification combined withearly masking achieves the highest OOD robustness.</description><author>Ananthu Aniraj, Cassio F. Dantas, Dino Ienco, Diego Marcos</author><pubDate>Wed, 23 Aug 2023 14:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12127v1</guid></item><item><title>An Accelerated Block Proximal Framework with Adaptive Momentum for Nonconvex and Nonsmooth Optimization</title><link>http://arxiv.org/abs/2308.12126v1</link><description>We propose an accelerated block proximal linear framework with adaptivemomentum (ABPL$^+$) for nonconvex and nonsmooth optimization. We analyze thepotential causes of the extrapolation step failing in some algorithms, andresolve this issue by enhancing the comparison process that evaluates thetrade-off between the proximal gradient step and the linear extrapolation stepin our algorithm. Furthermore, we extends our algorithm to any scenarioinvolving updating block variables with positive integers, allowing each cycleto randomly shuffle the update order of the variable blocks. Additionally,under mild assumptions, we prove that ABPL$^+$ can monotonically decrease thefunction value without strictly restricting the extrapolation parameters andstep size, demonstrates the viability and effectiveness of updating theseblocks in a random order, and we also more obviously and intuitivelydemonstrate that the derivative set of the sequence generated by our algorithmis a critical point set. Moreover, we demonstrate the global convergence aswell as the linear and sublinear convergence rates of our algorithm byutilizing the Kurdyka-Lojasiewicz (K{\L}) condition. To enhance theeffectiveness and flexibility of our algorithm, we also expand the study to theimprecise version of our algorithm and construct an adaptive extrapolationparameter strategy, which improving its overall performance. We apply ouralgorithm to multiple non-negative matrix factorization with the $\ell_0$ norm,nonnegative tensor decomposition with the $\ell_0$ norm, and perform extensivenumerical experiments to validate its effectiveness and efficiency.</description><author>Weifeng Yang, Wenwen Min</author><pubDate>Wed, 23 Aug 2023 14:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12126v1</guid></item><item><title>Randomized Coordinate Subgradient Method for Nonsmooth Composite Optimization</title><link>http://arxiv.org/abs/2206.14981v3</link><description>Coordinate-type subgradient methods for addressing nonsmooth optimizationproblems are relatively underexplored due to the set-valued nature of thesubdifferential. In this work, our study focuses on nonsmooth compositeoptimization problems, encompassing a wide class of convex and weakly convex(nonconvex nonsmooth) problems. By utilizing the chain rule of the compositestructure properly, we introduce the Randomized Coordinate Subgradient method(RCS) for tackling this problem class. To the best of our knowledge, this isthe first coordinate subgradient method for solving general nonsmooth compositeoptimization problems. In theory, we consider the linearly bounded subgradientsassumption for the objective function, which is more general than thetraditional Lipschitz continuity assumption, to account for practicalscenarios. We then conduct convergence analysis for RCS in both convex andweakly convex cases based on this generalized Lipschitz-type assumption.Specifically, we establish the $\widetilde{\mathcal{O}}$$(1/\sqrt{k})$convergence rate in expectation and the $\tilde o(1/\sqrt{k})$ almost sureasymptotic convergence rate in terms of the suboptimality gap when $f$ isconvex. For the case when $f$ is weakly convex and its subdifferentialsatisfies the global metric subregularity property, we derive the$\mathcal{O}(\varepsilon^{-4})$ iteration complexity in expectation. We alsoestablish an asymptotic convergence result. To justify the global metricsubregularity property utilized in the analysis, we establish this error boundcondition for the concrete (real-valued) robust phase retrieval problem. Wealso provide a convergence lemma and the relationship between the global metricsubregularity properties of a weakly convex function and its Moreau envelope.Finally, we conduct several experiments to demonstrate the possible superiorityof RCS over the subgradient method.</description><author>Lei Zhao, Ding Chen, Daoli Zhu, Xiao Li</author><pubDate>Wed, 23 Aug 2023 14:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.14981v3</guid></item><item><title>Knowledge-Aware Federated Active Learning with Non-IID Data</title><link>http://arxiv.org/abs/2211.13579v2</link><description>Federated learning enables multiple decentralized clients to learncollaboratively without sharing the local training data. However, the expensiveannotation cost to acquire data labels on local clients remains an obstacle inutilizing local data. In this paper, we propose a federated active learningparadigm to efficiently learn a global model with limited annotation budgetwhile protecting data privacy in a decentralized learning way. The mainchallenge faced by federated active learning is the mismatch between the activesampling goal of the global model on the server and that of the asynchronouslocal clients. This becomes even more significant when data is distributednon-IID across local clients. To address the aforementioned challenge, wepropose Knowledge-Aware Federated Active Learning (KAFAL), which consists ofKnowledge-Specialized Active Sampling (KSAS) and Knowledge-CompensatoryFederated Update (KCFU). KSAS is a novel active sampling method tailored forthe federated active learning problem. It deals with the mismatch challenge bysampling actively based on the discrepancies between local and global models.KSAS intensifies specialized knowledge in local clients, ensuring the sampleddata to be informative for both the local clients and the global model. KCFU,in the meantime, deals with the client heterogeneity caused by limited data andnon-IID data distributions. It compensates for each client's ability in weakclasses by the assistance of the global model. Extensive experiments andanalyses are conducted to show the superiority of KSAS over thestate-of-the-art active learning methods and the efficiency of KCFU under thefederated active learning framework.</description><author>Yu-Tong Cao, Ye Shi, Baosheng Yu, Jingya Wang, Dacheng Tao</author><pubDate>Wed, 23 Aug 2023 14:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13579v2</guid></item><item><title>An Open-Source ML-Based Full-Stack Optimization Framework for Machine Learning Accelerators</title><link>http://arxiv.org/abs/2308.12120v1</link><description>Parameterizable machine learning (ML) accelerators are the product of recentbreakthroughs in ML. To fully enable their design space exploration (DSE), wepropose a physical-design-driven, learning-based prediction framework forhardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. Itadopts a unified approach that combines backend power, performance, and area(PPA) analysis with frontend performance simulation, thereby achieving arealistic estimation of both backend PPA and system metrics such as runtime andenergy. In addition, our framework includes a fully automated DSE technique,which optimizes backend and system metrics through an automated search ofarchitectural and backend parameters. Experimental studies show that ourapproach consistently predicts backend PPA and system metrics with an average7% or less prediction error for the ASIC implementation of two deep learningaccelerator platforms, VTA and VeriGOOD-ML, in both a commercial 12 nm processand a research-oriented 45 nm process.</description><author>Hadi Esmaeilzadeh, Soroush Ghodrati, Andrew B. Kahng, Joon Kyung Kim, Sean Kinzer, Sayak Kundu, Rohan Mahapatra, Susmita Dey Manasi, Sachin Sapatnekar, Zhiang Wang, Ziqing Zeng</author><pubDate>Wed, 23 Aug 2023 14:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12120v1</guid></item><item><title>Zero-Shot In-Distribution Detection in Multi-Object Settings Using Vision-Language Foundation Models</title><link>http://arxiv.org/abs/2304.04521v3</link><description>Extracting in-distribution (ID) images from noisy images scraped from theInternet is an important preprocessing for constructing datasets, which hastraditionally been done manually. Automating this preprocessing with deeplearning techniques presents two key challenges. First, images should becollected using only the name of the ID class without training on the ID data.Second, as we can see why COCO was created, it is crucial to identify imagescontaining not only ID objects but also both ID and out-of-distribution (OOD)objects as ID images to create robust recognizers. In this paper, we propose anovel problem setting called zero-shot in-distribution (ID) detection, where weidentify images containing ID objects as ID images (even if they contain OODobjects), and images lacking ID objects as OOD images without any training. Tosolve this problem, we leverage the powerful zero-shot capability of CLIP andpresent a simple and effective approach, Global-Local Maximum Concept Matching(GL-MCM), based on both global and local visual-text alignments of CLIPfeatures. Extensive experiments demonstrate that GL-MCM outperforms comparisonmethods on both multi-object datasets and single-object ImageNet benchmarks.The code will be available via https://github.com/AtsuMiyai/GL-MCM.</description><author>Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa</author><pubDate>Wed, 23 Aug 2023 14:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04521v3</guid></item><item><title>The TYC Dataset for Understanding Instance-Level Semantics and Motions of Cells in Microstructures</title><link>http://arxiv.org/abs/2308.12116v1</link><description>Segmenting cells and tracking their motion over time is a common task inbiomedical applications. However, predicting accurate instance-wisesegmentation and cell motions from microscopy imagery remains a challengingtask. Using microstructured environments for analyzing single cells in aconstant flow of media adds additional complexity. While large-scale labeledmicroscopy datasets are available, we are not aware of any large-scale dataset,including both cells and microstructures. In this paper, we introduce thetrapped yeast cell (TYC) dataset, a novel dataset for understandinginstance-level semantics and motions of cells in microstructures. We release$105$ dense annotated high-resolution brightfield microscopy images, includingabout $19$k instance masks. We also release $261$ curated video clips composedof $1293$ high-resolution microscopy images to facilitate unsupervisedunderstanding of cell motions and morphology. TYC offers ten times moreinstance annotations than the previously largest dataset, including cells andmicrostructures. Our effort also exceeds previous attempts in terms ofmicrostructure variability, resolution, complexity, and capturing device(microscopy) variability. We facilitate a unified comparison on our noveldataset by introducing a standardized evaluation strategy. TYC and evaluationcode are publicly available under CC BY 4.0 license.</description><author>Christoph Reich, Tim Prangemeier, Heinz Koeppl</author><pubDate>Wed, 23 Aug 2023 14:10:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12116v1</guid></item><item><title>Less is More -- Towards parsimonious multi-task models using structured sparsity</title><link>http://arxiv.org/abs/2308.12114v1</link><description>Group sparsity in Machine Learning (ML) encourages simpler, moreinterpretable models with fewer active parameter groups. This work aims toincorporate structured group sparsity into the shared parameters of aMulti-Task Learning (MTL) framework, to develop parsimonious models that caneffectively address multiple tasks with fewer parameters while maintainingcomparable or superior performance to a dense model. Sparsifying the modelduring training helps decrease the model's memory footprint, computationrequirements, and prediction time during inference. We use channel-wise l1/l2group sparsity in the shared layers of the Convolutional Neural Network (CNN).This approach not only facilitates the elimination of extraneous groups(channels) but also imposes a penalty on the weights, thereby enhancing thelearning of all tasks. We compare the outcomes of single-task and multi-taskexperiments under group sparsity on two publicly available MTL datasets, NYU-v2and CelebAMask-HQ. We also investigate how changing the sparsification degreeimpacts both the performance of the model and the sparsity of groups.</description><author>Richa Upadhyay, Ronald Phlypo, Rajkumar Saini, Marcus Liwicki</author><pubDate>Wed, 23 Aug 2023 14:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12114v1</guid></item><item><title>Advancements in Point Cloud Data Augmentation for Deep Learning: A Survey</title><link>http://arxiv.org/abs/2308.12113v1</link><description>Point cloud has a wide range of applications in areas such as autonomousdriving, mapping, navigation, scene reconstruction, and medical imaging. Due toits great potentials in these applications, point cloud processing has gainedgreat attention in the field of computer vision. Among various point cloudprocessing techniques, deep learning (DL) has become one of the mainstream andeffective methods for tasks such as detection, segmentation and classification.To reduce overfitting during training DL models and improve model performanceespecially when the amount and/or diversity of training data are limited,augmentation is often crucial. Although various point cloud data augmentationmethods have been widely used in different point cloud processing tasks, thereare currently no published systematic surveys or reviews of these methods.Therefore, this article surveys and discusses these methods and categorizesthem into a taxonomy framework. Through the comprehensive evaluation andcomparison of the augmentation methods, this article identifies theirpotentials and limitations and suggests possible future research directions.This work helps researchers gain a holistic understanding of the current statusof point cloud data augmentation and promotes its wider application anddevelopment.</description><author>Qinfeng Zhu, Lei Fan, Ningxin Weng</author><pubDate>Wed, 23 Aug 2023 14:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12113v1</guid></item><item><title>Exact Manifold Gaussian Variational Bayes</title><link>http://arxiv.org/abs/2210.14598v2</link><description>We propose an optimization algorithm for Variational Inference (VI) incomplex models. Our approach relies on natural gradient updates where thevariational space is a Riemann manifold. We develop an efficient algorithm forGaussian Variational Inference that implicitly satisfies the positive definiteconstraint on the variational covariance matrix. Our Exact manifold GaussianVariational Bayes (EMGVB) provides exact but simple update rules and isstraightforward to implement. Due to its black-box nature, EMGVB stands as aready-to-use solution for VI in complex models. Over five datasets, weempirically validate our feasible approach on different statistical,econometric, and deep learning models, discussing its performance with respectto baseline methods.</description><author>Martin Magris, Mostafa Shabani, Alexandros Iosifidis</author><pubDate>Wed, 23 Aug 2023 14:04:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14598v2</guid></item><item><title>Generalized Continual Category Discovery</title><link>http://arxiv.org/abs/2308.12112v1</link><description>Most of Continual Learning (CL) methods push the limit of supervised learningsettings, where an agent is expected to learn new labeled tasks and not forgetprevious knowledge. However, these settings are not well aligned with real-lifescenarios, where a learning agent has access to a vast amount of unlabeled dataencompassing both novel (entirely unlabeled) classes and examples from knownclasses. Drawing inspiration from Generalized Category Discovery (GCD), weintroduce a novel framework that relaxes this assumption. Precisely, in anytask, we allow for the existence of novel and known classes, and one must usecontinual version of unsupervised learning methods to discover them. We callthis setting Generalized Continual Category Discovery (GCCD). It unifies CL andGCD, bridging the gap between synthetic benchmarks and real-life scenarios.With a series of experiments, we present that existing methods fail toaccumulate knowledge from subsequent tasks in which unlabeled samples of novelclasses are present. In light of these limitations, we propose a method thatincorporates both supervised and unsupervised signals and mitigates theforgetting through the use of centroid adaptation. Our method surpasses strongCL methods adopted for GCD techniques and presents a superior representationlearning performance.</description><author>Daniel Marczak, Grzegorz Rype, Sebastian Cygert, Tomasz Trzciski, Bartomiej Twardowski</author><pubDate>Wed, 23 Aug 2023 14:02:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12112v1</guid></item><item><title>Cross-Modality Proposal-guided Feature Mining for Unregistered RGB-Thermal Pedestrian Detection</title><link>http://arxiv.org/abs/2308.12111v1</link><description>RGB-Thermal (RGB-T) pedestrian detection aims to locate the pedestrians inRGB-T image pairs to exploit the complementation between the two modalities forimproving detection robustness in extreme conditions. Most existing algorithmsassume that the RGB-T image pairs are well registered, while in the real worldthey are not aligned ideally due to parallax or different field-of-view of thecameras. The pedestrians in misaligned image pairs may locate at differentpositions in two images, which results in two challenges: 1) how to achieveinter-modality complementation using spatially misaligned RGB-T pedestrianpatches, and 2) how to recognize the unpaired pedestrians at the boundary. Todeal with these issues, we propose a new paradigm for unregistered RGB-Tpedestrian detection, which predicts two separate pedestrian locations in theRGB and thermal images, respectively. Specifically, we propose a cross-modalityproposal-guided feature mining (CPFM) mechanism to extract the two precisefusion features for representing the pedestrian in the two modalities, even ifthe RGB-T image pair is unaligned. It enables us to effectively exploit thecomplementation between the two modalities. With the CPFM mechanism, we build atwo-stream dense detector; it predicts the two pedestrian locations in the twomodalities based on the corresponding fusion feature mined by the CPFMmechanism. Besides, we design a data augmentation method, named Homography, tosimulate the discrepancy in scales and views between images. We alsoinvestigate two non-maximum suppression (NMS) methods for post-processing.Favorable experimental results demonstrate the effectiveness and robustness ofour method in dealing with unregistered pedestrians with different shifts.</description><author>Chao Tian, Zikun Zhou, Yuqing Huang, Gaojun Li, Zhenyu He</author><pubDate>Wed, 23 Aug 2023 13:58:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12111v1</guid></item><item><title>Quantifying degeneracy in singular models via the learning coefficient</title><link>http://arxiv.org/abs/2308.12108v1</link><description>Deep neural networks (DNN) are singular statistical models which exhibitcomplex degeneracies. In this work, we illustrate how a quantity known as the\emph{learning coefficient} introduced in singular learning theory quantifiesprecisely the degree of degeneracy in deep neural networks. Importantly, wewill demonstrate that degeneracy in DNN cannot be accounted for by simplycounting the number of "flat" directions. We propose a computationally scalableapproximation of a localized version of the learning coefficient usingstochastic gradient Langevin dynamics. To validate our approach, we demonstrateits accuracy in low-dimensional models with known theoretical values.Importantly, the local learning coefficient can correctly recover the orderingof degeneracy between various parameter regions of interest. An experiment onMNIST shows the local learning coefficient can reveal the inductive bias ofstochastic opitmizers for more or less degenerate critical points.</description><author>Edmund Lau, Daniel Murfet, Susan Wei</author><pubDate>Wed, 23 Aug 2023 13:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12108v1</guid></item><item><title>Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing</title><link>http://arxiv.org/abs/2304.02051v2</link><description>Fashion illustration is used by designers to communicate their vision and tobring the design idea from conceptualization to realization, showing howclothes interact with the human body. In this context, computer vision can thusbe used to improve the fashion design process. Differently from previous worksthat mainly focused on the virtual try-on of garments, we propose the task ofmultimodal-conditioned fashion image editing, guiding the generation ofhuman-centric fashion images by following multimodal prompts, such as text,human body poses, and garment sketches. We tackle this problem by proposing anew architecture based on latent diffusion models, an approach that has notbeen used before in the fashion domain. Given the lack of existing datasetssuitable for the task, we also extend two existing fashion datasets, namelyDress Code and VITON-HD, with multimodal annotations collected in asemi-automatic manner. Experimental results on these new datasets demonstratethe effectiveness of our proposal, both in terms of realism and coherence withthe given multimodal inputs. Source code and collected multimodal annotationsare publicly available at:https://github.com/aimagelab/multimodal-garment-designer.</description><author>Alberto Baldrati, Davide Morelli, Giuseppe Cartella, Marcella Cornia, Marco Bertini, Rita Cucchiara</author><pubDate>Wed, 23 Aug 2023 13:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02051v2</guid></item><item><title>Instruction Position Matters in Sequence Generation with Large Language Models</title><link>http://arxiv.org/abs/2308.12097v1</link><description>Large language models (LLMs) are capable of performing conditional sequencegeneration tasks, such as translation or summarization, through instructionfine-tuning. The fine-tuning data is generally sequentially concatenated from aspecific task instruction, an input sentence, and the corresponding response.Considering the locality modeled by the self-attention mechanism of LLMs, thesemodels face the risk of instruction forgetting when generating responses forlong input sentences. To mitigate this issue, we propose enhancing theinstruction-following capability of LLMs by shifting the position of taskinstructions after the input sentences. Theoretical analysis suggests that ourstraightforward method can alter the model's learning focus, therebyemphasizing the training of instruction-following capabilities. Concurrently,experimental results demonstrate that our approach consistently outperformstraditional settings across various model scales (1B / 7B / 13B) and differentsequence generation tasks (translation and summarization), without anyadditional data or annotation costs. Notably, our method significantly improvesthe zero-shot performance on conditional sequence generation, e.g., up to 9.7BLEU points on WMT zero-shot translation tasks.</description><author>Yijin Liu, Xianfeng Zeng, Fandong Meng, Jie Zhou</author><pubDate>Wed, 23 Aug 2023 13:36:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12097v1</guid></item><item><title>Cached Operator Reordering: A Unified View for Fast GNN Training</title><link>http://arxiv.org/abs/2308.12093v1</link><description>Graph Neural Networks (GNNs) are a powerful tool for handling structuredgraph data and addressing tasks such as node classification, graphclassification, and clustering. However, the sparse nature of GNN computationposes new challenges for performance optimization compared to traditional deepneural networks. We address these challenges by providing a unified view of GNNcomputation, I/O, and memory. By analyzing the computational graphs of theGraph Convolutional Network (GCN) and Graph Attention (GAT) layers -- twowidely used GNN layers -- we propose alternative computation strategies. Wepresent adaptive operator reordering with caching, which achieves a speedup ofup to 2.43x for GCN compared to the current state-of-the-art. Furthermore, anexploration of different caching schemes for GAT yields a speedup of up to1.94x. The proposed optimizations save memory, are easily implemented acrossvarious hardware platforms, and have the potential to alleviate performancebottlenecks in training large-scale GNN models.</description><author>Julia Bazinska, Andrei Ivanov, Tal Ben-Nun, Nikoli Dryden, Maciej Besta, Siyuan Shen, Torsten Hoefler</author><pubDate>Wed, 23 Aug 2023 13:27:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12093v1</guid></item><item><title>Estimating Driver Personality Traits from On-Road Driving Data</title><link>http://arxiv.org/abs/2302.10898v2</link><description>This paper focuses on the estimation of a driver's psychologicalcharacteristics using driving data for driving assistance systems. Drivingassistance systems that support drivers by adapting individual psychologicalcharacteristics can provide appropriate feedback and prevent traffic accidents.As a first step toward implementing such adaptive assistance systems, thisresearch aims to develop a model to estimate drivers' psychologicalcharacteristics, such as cognitive function, psychological driving style, andworkload sensitivity, from on-road driving behavioral data using machinelearning and deep learning techniques. We also investigated the relationshipbetween driving behavior and various cognitive functions, including the TrailMaking Test (TMT) and Useful Field of View (UFOV) test, through regressionmodeling. The proposed method focuses on road type information and capturesvarious durations of time-series data observed from driving behaviors. First,we segment the driving time-series data into two road types, namely, arterialroads and intersections, to consider driving situations. Second, we furthersegment data into many sequences of various durations. Third, statistics arecalculated from each sequence. Finally, these statistics are used as inputfeatures of machine learning models to estimate psychological characteristics.The experimental results show that our model can estimate a driver's cognitivefunction, namely, the TMT~(B) and UFOV test scores, with Pearson correlationcoefficients $r$ of 0.579 and 0.708, respectively. Some characteristics, suchas psychological driving style and workload sensitivity, are estimated withhigh accuracy, but whether various duration segmentation improves accuracydepends on the characteristics, and it is not effective for allcharacteristics.</description><author>Ryusei Kimura, Takahiro Tanaka, Yuki Yoshihara, Kazuhiro Fujikake, Hitoshi Kanamori, Shogo Okada</author><pubDate>Wed, 23 Aug 2023 13:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10898v2</guid></item><item><title>Comparison of Machine Learning Methods for Assigning Software Issues to Team Members</title><link>http://arxiv.org/abs/2307.00009v2</link><description>Software issues contain units of work to fix, improve, or create new threadsduring the development and facilitate communication among the team members.Assigning an issue to the most relevant team member and determining a categoryof an issue is a tedious and challenging task. Wrong classifications causedelays and rework in the project and trouble among the team members. This paperproposes a set of carefully curated linguistic features for shallow machinelearning methods and compares the performance of shallow and ensemble methodswith deep language models. Unlike the state-of-the-art, we assign issues tofour roles (designer, developer, tester, and leader) rather than to specificindividuals or teams to contribute to the generality of our solution. We alsoconsider the level of experience of the developers to reflect the industrialpractices in our solution formulation. We collect and annotate five industrialdata sets from one of the top three global television producers to evaluate ourproposal and compare it with deep language models. Our data sets contain 5324issues in total. We show that an ensemble classifier of shallow techniquesachieves 0.92 for issue assignment in accuracy which is statisticallycomparable to the state-of-the-art deep language models. The contributionsinclude the public sharing of five annotated industrial issue data sets, thedevelopment of a clear and comprehensive feature set, the introduction of anovel label set, and the validation of the efficacy of an ensemble classifierof shallow machine learning techniques.</description><author>Bra Tabak, Fatma Baak Aydemir</author><pubDate>Wed, 23 Aug 2023 13:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00009v2</guid></item><item><title>Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments</title><link>http://arxiv.org/abs/2308.12086v1</link><description>Large Language Models (LLMs) have gained widespread popularity across diversedomains involving text generation, summarization, and various natural languageprocessing tasks. Despite their inherent limitations, LLM-based designs haveshown promising capabilities in planning and navigating open-world scenarios.This paper introduces a novel application of pre-trained LLMs as agents withincybersecurity network environments, focusing on their utility for sequentialdecision-making processes. We present an approach wherein pre-trained LLMs are leveraged as attackingagents in two reinforcement learning environments. Our proposed agentsdemonstrate similar or better performance against state-of-the-art agentstrained for thousands of episodes in most scenarios and configurations. Inaddition, the best LLM agents perform similarly to human testers of theenvironment without any additional training process. This design highlights thepotential of LLMs to efficiently address complex decision-making tasks withincybersecurity. Furthermore, we introduce a new network security environment namedNetSecGame. The environment is designed to eventually support complexmulti-agent scenarios within the network security domain. The proposedenvironment mimics real network attacks and is designed to be highly modularand adaptable for various scenarios.</description><author>Maria Rigaki, Ondej Luk, Carlos A. Catania, Sebastian Garcia</author><pubDate>Wed, 23 Aug 2023 13:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12086v1</guid></item><item><title>h-analysis and data-parallel physics-informed neural networks</title><link>http://arxiv.org/abs/2302.08835v3</link><description>We explore the data-parallel acceleration of physics-informed machinelearning (PIML) schemes, with a focus on physics-informed neural networks(PINNs) for multiple graphics processing units (GPUs) architectures. In orderto develop scale-robust and high-throughput PIML models for sophisticatedapplications which may require a large number of training points (e.g.,involving complex and high-dimensional domains, non-linear operators ormulti-physics), we detail a novel protocol based on $h$-analysis anddata-parallel acceleration through the Horovod training framework. The protocolis backed by new convergence bounds for the generalization error and thetrain-test gap. We show that the acceleration is straightforward to implement,does not compromise training, and proves to be highly efficient andcontrollable, paving the way towards generic scale-robust PIML. Extensivenumerical experiments with increasing complexity illustrate its robustness andconsistency, offering a wide range of possibilities for real-world simulations.</description><author>Paul Escapil-Inchausp, Gonzalo A. Ruz</author><pubDate>Wed, 23 Aug 2023 13:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08835v3</guid></item><item><title>DISGAN: Wavelet-informed Discriminator Guides GAN to MRI Super-resolution with Noise Cleaning</title><link>http://arxiv.org/abs/2308.12084v1</link><description>MRI super-resolution (SR) and denoising tasks are fundamental challenges inthe field of deep learning, which have traditionally been treated as distincttasks with separate paired training data. In this paper, we propose aninnovative method that addresses both tasks simultaneously using a single deeplearning model, eliminating the need for explicitly paired noisy and cleanimages during training. Our proposed model is primarily trained for SR, butalso exhibits remarkable noise-cleaning capabilities in the super-resolvedimages. Instead of conventional approaches that introduce frequency-relatedoperations into the generative process, our novel approach involves the use ofa GAN model guided by a frequency-informed discriminator. To achieve this, weharness the power of the 3D Discrete Wavelet Transform (DWT) operation as afrequency constraint within the GAN framework for the SR task on magneticresonance imaging (MRI) data. Specifically, our contributions include: 1) a 3Dgenerator based on residual-in-residual connected blocks; 2) the integration ofthe 3D DWT with $1\times 1$ convolution into a DWT+conv unit within a 3D Unetfor the discriminator; 3) the use of the trained model for high-quality imageSR, accompanied by an intrinsic denoising process. We dub the model "DenoisingInduced Super-resolution GAN (DISGAN)" due to its dual effects of SR imagegeneration and simultaneous denoising. Departing from the traditional approachof training SR and denoising tasks as separate models, our proposed DISGAN istrained only on the SR task, but also achieves exceptional performance indenoising. The model is trained on 3D MRI data from dozens of subjects from theHuman Connectome Project (HCP) and further evaluated on previously unseen MRIdata from subjects with brain tumours and epilepsy to assess its denoising andSR performance.</description><author>Qi Wang, Lucas Mahler, Julius Steiglechner, Florian Birk, Klaus Scheffler, Gabriele Lohmann</author><pubDate>Wed, 23 Aug 2023 13:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12084v1</guid></item><item><title>Policy-Guided Lazy Search with Feedback for Task and Motion Planning</title><link>http://arxiv.org/abs/2210.14055v4</link><description>PDDLStream solvers have recently emerged as viable solutions for Task andMotion Planning (TAMP) problems, extending PDDL to problems with continuousaction spaces. Prior work has shown how PDDLStream problems can be reduced to asequence of PDDL planning problems, which can then be solved usingoff-the-shelf planners. However, this approach can suffer from long runtimes.In this paper we propose LAZY, a solver for PDDLStream problems that maintainsa single integrated search over action skeletons, which gets progressively moregeometrically informed, as samples of possible motions are lazily drawn duringmotion planning. We explore how learned models of goal-directed policies andcurrent motion sampling data can be incorporated in LAZY to adaptively guidethe task planner. We show that this leads to significant speed-ups in thesearch for a feasible solution evaluated over unseen test environments ofvarying numbers of objects, goals, and initial conditions. We evaluate our TAMPapproach by comparing to existing solvers for PDDLStream problems on a range ofsimulated 7DoF rearrangement/manipulation problems.</description><author>Mohamed Khodeir, Atharv Sonwane, Ruthrash Hari, Florian Shkurti</author><pubDate>Wed, 23 Aug 2023 13:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14055v4</guid></item><item><title>Learnable Differencing Center for Nighttime Depth Perception</title><link>http://arxiv.org/abs/2306.14538v3</link><description>Depth completion is the task of recovering dense depth maps from sparse ones,usually with the help of color images. Existing image-guided methods performwell on daytime depth perception self-driving benchmarks, but struggle innighttime scenarios with poor visibility and complex illumination. To addressthese challenges, we propose a simple yet effective framework called LDCNet.Our key idea is to use Recurrent Inter-Convolution Differencing (RICD) andIllumination-Affinitive Intra-Convolution Differencing (IAICD) to enhance thenighttime color images and reduce the negative effects of the varyingillumination, respectively. RICD explicitly estimates global illumination bydifferencing two convolutions with different kernels, treating thesmall-kernel-convolution feature as the center of the large-kernel-convolutionfeature in a new perspective. IAICD softly alleviates local relative lightintensity by differencing a single convolution, where the center is dynamicallyaggregated based on neighboring pixels and the estimated illumination map inRICD. On both nighttime depth completion and depth estimation tasks, extensiveexperiments demonstrate the effectiveness of our LDCNet, reaching the state ofthe art.</description><author>Zhiqiang Yan, Yupeng Zheng, Chongyi Li, Jun Li, Jian Yang</author><pubDate>Wed, 23 Aug 2023 13:03:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14538v3</guid></item><item><title>Deletion and Insertion Tests in Regression Models</title><link>http://arxiv.org/abs/2205.12423v3</link><description>A basic task in explainable AI (XAI) is to identify the most importantfeatures behind a prediction made by a black box function $f$. The insertionand deletion tests of Petsiuk et al. (2018) can be used to judge the quality ofalgorithms that rank pixels from most to least important for a classification.Motivated by regression problems we establish a formula for their area underthe curve (AUC) criteria in terms of certain main effects and interactions inan anchored decomposition of $f$. We find an expression for the expected valueof the AUC under a random ordering of inputs to $f$ and propose an alternativearea above a straight line for the regression setting. We use this criterion tocompare feature importances computed by integrated gradients (IG) to thosecomputed by Kernel SHAP (KS) as well as LIME, DeepLIFT, vanilla gradient andinput$\times$gradient methods. KS has the best overall performance in twodatasets we consider but it is very expensive to compute. We find that IG isnearly as good as KS while being much faster. Our comparison problems includesome binary inputs that pose a challenge to IG because it must use valuesbetween the possible variable levels and so we consider ways to handle binaryvariables in IG. We show that sorting variables by their Shapley value does notnecessarily give the optimal ordering for an insertion-deletion test. It willhowever do that for monotone functions of additive models, such as logisticregression.</description><author>Naofumi Hama, Masayoshi Mase, Art B. Owen</author><pubDate>Wed, 23 Aug 2023 13:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.12423v3</guid></item><item><title>Learning to Search in Task and Motion Planning with Streams</title><link>http://arxiv.org/abs/2111.13144v6</link><description>Task and motion planning problems in robotics combine symbolic planning overdiscrete task variables with motion optimization over continuous state andaction variables. Recent works such as PDDLStream have focused on optimisticplanning with an incrementally growing set of objects until a feasibletrajectory is found. However, this set is exhaustively expanded in abreadth-first manner, regardless of the logical and geometric structure of theproblem at hand, which makes long-horizon reasoning with large numbers ofobjects prohibitively time-consuming. To address this issue, we propose ageometrically informed symbolic planner that expands the set of objects andfacts in a best-first manner, prioritized by a Graph Neural Network that islearned from prior search computations. We evaluate our approach on a diverseset of problems and demonstrate an improved ability to plan in difficultscenarios. We also apply our algorithm on a 7DOF robotic arm in block-stackingmanipulation tasks.</description><author>Mohamed Khodeir, Ben Agro, Florian Shkurti</author><pubDate>Wed, 23 Aug 2023 12:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.13144v6</guid></item><item><title>Stabilizing RNN Gradients through Pre-training</title><link>http://arxiv.org/abs/2308.12075v1</link><description>Numerous theories of learning suggest to prevent the gradient variance fromexponential growth with depth or time, to stabilize and improve training.Typically, these analyses are conducted on feed-forward fully-connected neuralnetworks or single-layer recurrent neural networks, given their mathematicaltractability. In contrast, this study demonstrates that pre-training thenetwork to local stability can be effective whenever the architectures are toocomplex for an analytical initialization. Furthermore, we extend knownstability theories to encompass a broader family of deep recurrent networks,requiring minimal assumptions on data and parameter distribution, a theory thatwe refer to as the Local Stability Condition (LSC). Our investigation revealsthat the classical Glorot, He, and Orthogonal initialization schemes satisfythe LSC when applied to feed-forward fully-connected neural networks. However,analysing deep recurrent networks, we identify a new additive source ofexponential explosion that emerges from counting gradient paths in arectangular grid in depth and time. We propose a new approach to mitigate thisissue, that consists on giving a weight of a half to the time and depthcontributions to the gradient, instead of the classical weight of one. Ourempirical results confirm that pre-training both feed-forward and recurrentnetworks to fulfill the LSC often results in improved final performance acrossmodels. This study contributes to the field by providing a means to stabilizenetworks of any complexity. Our approach can be implemented as an additionalstep before pre-training on large augmented datasets, and as an alternative tofinding stable initializations analytically.</description><author>Luca Herranz-Celotti, Jean Rouat</author><pubDate>Wed, 23 Aug 2023 12:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12075v1</guid></item><item><title>HiFace: High-Fidelity 3D Face Reconstruction by Learning Static and Dynamic Details</title><link>http://arxiv.org/abs/2303.11225v2</link><description>3D Morphable Models (3DMMs) demonstrate great potential for reconstructingfaithful and animatable 3D facial surfaces from a single image. The facialsurface is influenced by the coarse shape, as well as the static detail (e,g.,person-specific appearance) and dynamic detail (e.g., expression-drivenwrinkles). Previous work struggles to decouple the static and dynamic detailsthrough image-level supervision, leading to reconstructions that are notrealistic. In this paper, we aim at high-fidelity 3D face reconstruction andpropose HiFace to explicitly model the static and dynamic details.Specifically, the static detail is modeled as the linear combination of adisplacement basis, while the dynamic detail is modeled as the linearinterpolation of two displacement maps with polarized expressions. We exploitseveral loss functions to jointly learn the coarse shape and fine details withboth synthetic and real-world datasets, which enable HiFace to reconstructhigh-fidelity 3D shapes with animatable details. Extensive quantitative andqualitative experiments demonstrate that HiFace presents state-of-the-artreconstruction quality and faithfully recovers both the static and dynamicdetails. Our project page can be found at https://project-hiface.github.io.</description><author>Zenghao Chai, Tianke Zhang, Tianyu He, Xu Tan, Tadas Baltruaitis, HsiangTao Wu, Runnan Li, Sheng Zhao, Chun Yuan, Jiang Bian</author><pubDate>Wed, 23 Aug 2023 12:46:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11225v2</guid></item></channel></rss>