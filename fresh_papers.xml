<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 07 Oct 2025 13:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration</title><link>http://arxiv.org/abs/2510.05102v1</link><description>Graph Neural Networks (GNNs) have shown remarkable success across variousscientific fields, yet their adoption in critical decision-making is oftenhindered by a lack of interpretability. Recently, intrinsically interpretableGNNs have been studied to provide insights into model predictions byidentifying rationale substructures in graphs. However, existing methods facechallenges when the underlying rationale subgraphs are complex and varied. Inthis work, we propose TopInG: Topologically Interpretable Graph Learning, anovel topological framework that leverages persistent homology to identifypersistent rationale subgraphs. TopInG employs a rationale filtration learningapproach to model an autoregressive generation process of rationale subgraphs,and introduces a self-adjusted topological constraint, termed topologicaldiscrepancy, to enforce a persistent topological distinction between rationalesubgraphs and irrelevant counterparts. We provide theoretical guarantees thatour loss function is uniquely optimized by the ground truth under specificconditions. Extensive experiments demonstrate TopInG's effectiveness intackling key challenges, such as handling variform rationale subgraphs,balancing predictive performance with interpretability, and mitigating spuriouscorrelations. Results show that our approach improves upon state-of-the-artmethods on both predictive accuracy and interpretation quality.</description><author>Cheng Xin, Fan Xu, Xin Ding, Jie Gao, Jiaxin Ding</author><pubDate>Mon, 06 Oct 2025 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05102v1</guid></item><item><title>Pulp Motion: Framing-aware multimodal camera and human motion generation</title><link>http://arxiv.org/abs/2510.05097v1</link><description>Treating human motion and camera trajectory generation separately overlooks acore principle of cinematography: the tight interplay between actor performanceand camera work in the screen space. In this paper, we are the first to castthis task as a text-conditioned joint generation, aiming to maintain consistenton-screen framing while producing two heterogeneous, yet intrinsically linked,modalities: human motion and camera trajectories. We propose a simple,model-agnostic framework that enforces multimodal coherence via an auxiliarymodality: the on-screen framing induced by projecting human joints onto thecamera. This on-screen framing provides a natural and effective bridge betweenmodalities, promoting consistency and leading to more precise jointdistribution. We first design a joint autoencoder that learns a shared latentspace, together with a lightweight linear transform from the human and cameralatents to a framing latent. We then introduce auxiliary sampling, whichexploits this linear transform to steer generation toward a coherent framingmodality. To support this task, we also introduce the PulpMotion dataset, ahuman-motion and camera-trajectory dataset with rich captions, and high-qualityhuman motions. Extensive experiments across DiT- and MAR-based architecturesshow the generality and effectiveness of our method in generating on-framecoherent human-camera motions, while also achieving gains on textual alignmentfor both modalities. Our qualitative results yield more cinematographicallymeaningful framings setting the new state of the art for this task. Code,models and data are available in our\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{projectpage}.</description><author>Robin Courant, Xi Wang, David Loiseaux, Marc Christie, Vicky Kalogeiton</author><pubDate>Mon, 06 Oct 2025 17:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05097v1</guid></item><item><title>Paper2Video: Automatic Video Generation from Scientific Papers</title><link>http://arxiv.org/abs/2510.05096v1</link><description>Academic presentation videos have become an essential medium for researchcommunication, yet producing them remains highly labor-intensive, oftenrequiring hours of slide design, recording, and editing for a short 2 to 10minutes video. Unlike natural video, presentation video generation involvesdistinctive challenges: inputs from research papers, dense multi-modalinformation (text, figures, tables), and the need to coordinate multiplealigned channels such as slides, subtitles, speech, and human talker. Toaddress these challenges, we introduce PaperTalker, the first benchmark of 101research papers paired with author-created presentation videos, slides, andspeaker metadata. We further design four tailored evaluation metrics--MetaSimilarity, PresentArena, PresentQuiz, and IP Memory--to measure how videosconvey the paper's information to the audience. Building on this foundation, wepropose PaperTalker, the first multi-agent framework for academic presentationvideo generation. It integrates slide generation with effective layoutrefinement by a novel effective tree search visual choice, cursor grounding,subtitling, speech synthesis, and talking-head rendering, while parallelizingslide-wise generation for efficiency. Experiments on Paper2Video demonstratethat the presentation videos produced by our approach are more faithful andinformative than existing baselines, establishing a practical step towardautomated and ready-to-use academic video generation. Our dataset, agent, andcode are available at https://github.com/showlab/Paper2Video.</description><author>Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou</author><pubDate>Mon, 06 Oct 2025 17:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05096v1</guid></item><item><title>From Noisy Traces to Stable Gradients: Bias-Variance Optimized Preference Optimization for Aligning Large Reasoning Models</title><link>http://arxiv.org/abs/2510.05095v1</link><description>Large reasoning models (LRMs) generate intermediate reasoning traces beforeproducing final answers, yielding strong gains on multi-step and mathematicaltasks. Yet aligning LRMs with human preferences, a crucial prerequisite formodel deployment, remains underexplored. The statistically correct objectivefor preference alignment requires marginalizing over reasoning traces, but thiscomputation is intractable in practice. A common workaround optimizes a singlesampled trajectory, which introduces substantial gradient variance fromstochastic trace sampling. To address this challenge, we frame preferenceoptimization for LRMs through the lens of the bias--variance trade-off andpropose Bias--Variance Optimized Preference Optimization (BVPO), a simple,drop-in method that mixes two gradient estimators: a high-variance trace-basedestimator and a low-variance empty-trace estimator obtained by disablingreasoning trace generation. Our theory shows that BVPO strictly reducestrace-induced variance for any nontrivial mixture, provides a closed-formchoice of the mixing weight that minimizes mean-squared error relative to thetrue marginal gradient, and under standard smoothness and step-size conditions,tightens classical convergence bounds for stochastic gradient descent.Empirically, BVPO improves alignment over the best baseline by up to 7.8 pointson AlpacaEval~2 and 6.8 points on Arena-Hard. Despite being trained only ongeneral conversational data, BVPO also boosts reasoning performance for basemodels by up to 4.0 points on the average of six math reasoning benchmarks.These results identify variance from trace sampling as a key bottleneck anddemonstrate that directly optimizing the bias--variance trade-off yields morestable training and stronger overall performance.</description><author>Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia</author><pubDate>Mon, 06 Oct 2025 17:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05095v1</guid></item><item><title>VChain: Chain-of-Visual-Thought for Reasoning in Video Generation</title><link>http://arxiv.org/abs/2510.05094v1</link><description>Recent video generation models can produce smooth and visually appealingclips, but they often struggle to synthesize complex dynamics with a coherentchain of consequences. Accurately modeling visual outcomes and statetransitions over time remains a core challenge. In contrast, large language andmultimodal models (e.g., GPT-4o) exhibit strong visual state reasoning andfuture prediction capabilities. To bridge these strengths, we introduce VChain,a novel inference-time chain-of-visual-thought framework that injects visualreasoning signals from multimodal models into video generation. Specifically,VChain contains a dedicated pipeline that leverages large multimodal models togenerate a sparse set of critical keyframes as snapshots, which are then usedto guide the sparse inference-time tuning of a pre-trained video generator onlyat these key moments. Our approach is tuning-efficient, introduces minimaloverhead and avoids dense supervision. Extensive experiments on complex,multi-step scenarios show that VChain significantly enhances the quality ofgenerated videos.</description><author>Ziqi Huang, Ning Yu, Gordon Chen, Haonan Qiu, Paul Debevec, Ziwei Liu</author><pubDate>Mon, 06 Oct 2025 17:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05094v1</guid></item><item><title>Character Mixing for Video Generation</title><link>http://arxiv.org/abs/2510.05093v1</link><description>Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos wherecharacters interact naturally across different worlds? We study inter-characterinteraction in text-to-video generation, where the key challenge is to preserveeach character's identity and behaviors while enabling coherent cross-contextinteraction. This is difficult because characters may never have coexisted andbecause mixing styles often causes style delusion, where realistic charactersappear cartoonish or vice versa. We introduce a framework that tackles theseissues with Cross-Character Embedding (CCE), which learns identity andbehavioral logic across multimodal sources, and Cross-Character Augmentation(CCA), which enriches training with synthetic co-existence and mixed-styledata. Together, these techniques allow natural interactions between previouslyuncoexistent characters without losing stylistic fidelity. Experiments on acurated benchmark of cartoons and live-action series with 10 characters showclear improvements in identity preservation, interaction quality, androbustness to style delusion, enabling new forms of generativestorytelling.Additional results and videos are available on our project page:https://tingtingliao.github.io/mimix/.</description><author>Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou</author><pubDate>Mon, 06 Oct 2025 17:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05093v1</guid></item><item><title>Learning to Interpret Weight Differences in Language Models</title><link>http://arxiv.org/abs/2510.05092v1</link><description>Finetuning (pretrained) language models is a standard approach for updatingtheir internal parametric knowledge and specializing them to new tasks anddomains. However, the corresponding model weight changes ("weight diffs") arenot generally interpretable. While inspecting the finetuning dataset can give asense of how the model might have changed, these datasets are often notpublicly available or are too large to work with directly. Towards the goal ofcomprehensively understanding weight diffs in natural language, we introduceDiff Interpretation Tuning (DIT), a method that trains models to describe theirown finetuning-induced modifications. Our approach uses synthetic, labeledweight diffs to train a DIT adapter, which can be applied to a compatiblefinetuned model to make it describe how it has changed. We demonstrate in twoproof-of-concept settings (reporting hidden behaviors and summarizing finetunedknowledge) that our method enables models to describe their finetuning-inducedmodifications using accurate natural language descriptions.</description><author>Avichal Goel, Yoon Kim, Nir Shavit, Tony T. Wang</author><pubDate>Mon, 06 Oct 2025 17:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05092v1</guid></item><item><title>MALT: Improving Reasoning with Multi-Agent LLM Training</title><link>http://arxiv.org/abs/2412.01928v3</link><description>Large Language Models (LLMs) often produce answers with a singlechain-of-thought, which restricts their ability to explore reasoning paths orself-correct flawed outputs in complex tasks. In this paper, we introduce MALT(Multi-Agent LLM Training), a novel post-training strategy that divides thereasoning process into generation, verification, and refinement steps using asequential pipeline of heterogeneous agents. During data generation, each agentis repeatedly sampled to form a multi-agent search tree, where final outputsare graded against ground-truth data. We then apply value iteration topropagate reward signals back to each role-conditioned model, automaticallyproducing multi-agent post-training data without human or teacher-modelsupervision. Our off-policy approach allows each agent to specialize bylearning from correct and incorrect trajectories, ultimately improving theend-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the samebaseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40%respectively, making it an important advance towards multi-agent cooperativetraining.</description><author>Sumeet Ramesh Motwani, Chandler Smith, Rocktim Jyoti Das, Rafael Rafailov, Ivan Laptev, Philip H. S. Torr, Fabio Pizzati, Ronald Clark, Christian Schroeder de Witt</author><pubDate>Mon, 06 Oct 2025 17:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01928v3</guid></item><item><title>Factuality Matters: When Image Generation and Editing Meet Structured Visuals</title><link>http://arxiv.org/abs/2510.05091v1</link><description>While modern visual generation models excel at creating aestheticallypleasing natural images, they struggle with producing or editing structuredvisuals like charts, diagrams, and mathematical figures, which demandcomposition planning, text rendering, and multimodal reasoning for factualfidelity. To address this, we present the first comprehensive, systematicinvestigation of this domain, encompassing data construction, model training,and an evaluation benchmark. First, we construct a large-scale dataset of 1.3million high-quality structured image pairs derived from executable drawingprograms and augmented with chain-of-thought reasoning annotations. Building onit, we train a unified model that integrates a VLM with FLUX.1 Kontext via alightweight connector for enhanced multimodal understanding. A three-stagetraining curriculum enables progressive feature alignment, knowledge infusion,and reasoning-augmented generation, further boosted by an external reasoner atinference time. Finally, we introduce StructBench, a novel benchmark forgeneration and editing with over 1,700 challenging instances, and anaccompanying evaluation metric, StructScore, which employs a multi-round Q\&amp;Aprotocol to assess fine-grained factual accuracy. Evaluations of 15 modelsreveal that even leading closed-source systems remain far from satisfactory.Our model attains strong editing performance, and inference-time reasoningyields consistent gains across diverse architectures. By releasing the dataset,model, and benchmark, we aim to advance unified multimodal foundations forstructured visuals.</description><author>Le Zhuo, Songhao Han, Yuandong Pu, Boxiang Qiu, Sayak Paul, Yue Liao, Yihao Liu, Jie Shao, Xi Chen, Si Liu, Hongsheng Li</author><pubDate>Mon, 06 Oct 2025 17:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05091v1</guid></item><item><title>Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models</title><link>http://arxiv.org/abs/2510.05090v1</link><description>Diffusion large language models (dLLMs) have recently emerged as a promisingalternative to autoregressive (AR) models, offering advantages such asaccelerated parallel decoding and bidirectional context modeling. However, thevanilla decoding strategy in discrete dLLMs suffers from a critical limitation:once a token is accepted, it can no longer be revised in subsequent steps. As aresult, early mistakes persist across iterations, harming both intermediatepredictions and final output quality. To address this issue, we proposeTolerator (Token-Level Cross-Validation Refinement), a training-free decodingstrategy that leverages cross-validation among predicted tokens. Unlikeexisting methods that follow a single progressive unmasking procedure,Tolerator introduces a two-stage process: (i) sequence fill-up and (ii)iterative refinement by remasking and decoding a subset of tokens whiletreating the remaining as context. This design enables previously acceptedtokens to be reconsidered and corrected when necessary, leading to morereliable diffusion decoding outputs. We evaluate Tolerator on five standardbenchmarks covering language understanding, code generation, and mathematics.Experiments show that our method achieves consistent improvements over thebaselines under the same computational budget. These findings suggest thatdecoding algorithms are crucial to realizing the full potential of diffusionlarge language models. Code and data are publicly available.</description><author>Runchu Tian, Junxia Cui, Xueqiang Xu, Feng Yao, Jingbo Shang</author><pubDate>Mon, 06 Oct 2025 17:56:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05090v1</guid></item><item><title>TeachLM: Post-Training LLMs for Education Using Authentic Learning Data</title><link>http://arxiv.org/abs/2510.05087v1</link><description>The promise of generative AI to revolutionize education is constrained by thepedagogical limits of large language models (LLMs). A major issue is the lackof access to high-quality training data that reflect the learning of actualstudents. Prompt engineering has emerged as a stopgap, but the ability ofprompts to encode complex pedagogical strategies in rule-based natural languageis inherently limited. To address this gap we introduce TeachLM - an LLMoptimized for teaching through parameter-efficient fine-tuning ofstate-of-the-art models. TeachLM is trained on a dataset comprised of 100,000hours of one-on-one, longitudinal student-tutor interactions maintained byPolygence, which underwent a rigorous anonymization process to protect privacy.We use parameter-efficient fine-tuning to develop an authentic student modelthat enables the generation of high-fidelity synthetic student-tutor dialogues.Building on this capability, we propose a novel multi-turn evaluation protocolthat leverages synthetic dialogue generation to provide fast, scalable, andreproducible assessments of the dialogical capabilities of LLMs. Ourevaluations demonstrate that fine-tuning on authentic learning datasignificantly improves conversational and pedagogical performance - doublingstudent talk time, improving questioning style, increasing dialogue turns by50%, and greater personalization of instruction.</description><author>Janos Perczel, Jin Chow, Dorottya Demszky</author><pubDate>Mon, 06 Oct 2025 17:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05087v1</guid></item><item><title>Learning Penalty for Optimal Partitioning via Automatic Feature Extraction</title><link>http://arxiv.org/abs/2505.07413v2</link><description>Changepoint detection identifies significant shifts in data sequences, makingit important in areas like finance, genetics, and healthcare. The OptimalPartitioning algorithms efficiently detect these changes, using a penaltyparameter to limit the changepoints count. Determining the optimal value forthis penalty can be challenging. Traditionally, this process involved manuallyextracting statistical features, such as sequence length or variance to makethe prediction. This study proposes a novel approach that uses recurrentnetworks to learn this penalty directly from raw sequences by automaticallyextracting features. Experiments conducted on 20 benchmark genomic datasetsshow that this novel method generally outperforms traditional ones inchangepoint detection accuracy.</description><author>Tung L Nguyen, Toby Hocking</author><pubDate>Mon, 06 Oct 2025 17:53:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.07413v2</guid></item><item><title>Conformal Prediction for Long-Tailed Classification</title><link>http://arxiv.org/abs/2507.06867v2</link><description>Many real-world classification problems, such as plant identification, haveextremely long-tailed class distributions. In order for prediction sets to beuseful in such settings, they should (i) provide good class-conditionalcoverage, ensuring that rare classes are not systematically omitted from theprediction sets, and (ii) be a reasonable size, allowing users to easily verifycandidate labels. Unfortunately, existing conformal prediction methods, whenapplied to the long-tailed setting, force practitioners to make a binary choicebetween small sets with poor class-conditional coverage or sets with very goodclass-conditional coverage but that are extremely large. We propose methodswith guaranteed marginal coverage that smoothly trade off between set size andclass-conditional coverage. First, we introduce a new conformal score functioncalled prevalence-adjusted softmax that targets macro-coverage, a relaxednotion of class-conditional coverage. Second, we propose a new procedure thatinterpolates between marginal and class-conditional conformal prediction bylinearly interpolating their conformal score thresholds. We demonstrate ourmethods on Pl@ntNet-300K and iNaturalist-2018, two long-tailed image datasetswith 1,081 and 8,142 classes, respectively.</description><author>Tiffany Ding, Jean-Baptiste Fermanian, Joseph Salmon</author><pubDate>Mon, 06 Oct 2025 17:52:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.06867v2</guid></item><item><title>Using cognitive models to reveal value trade-offs in language models</title><link>http://arxiv.org/abs/2506.20666v3</link><description>Value trade-offs are an integral part of human decision-making and languageuse, however, current tools for interpreting such dynamic and multi-facetednotions of values in LLMs are limited. In cognitive science, so-called"cognitive models" provide formal accounts of such trade-offs in humans, bymodeling the weighting of a speaker's competing utility functions in choosingan action or utterance. Here we use a leading cognitive model of polite speechto systematically evaluate value trade-offs in two encompassing model settings:degrees of reasoning "effort" in frontier black-box models, and RLpost-training dynamics of open-source models. Our results highlight patterns ofhigher informational utility than social utility in reasoning models' defaultbehavior, and demonstrate that these patterns shift in predictable ways whenmodels are prompted to prioritize certain goals over others. Our findings fromLLMs' training dynamics suggest large shifts in utility values early on intraining with persistent effects of the choice of base model and pretrainingdata, compared to feedback dataset or alignment method. Our framework offers aflexible tool for probing value trade-offs across diverse model types,providing insights for generating hypotheses about other social behaviors suchas sycophancy and for shaping training regimes that better control trade-offsbetween values during model development.</description><author>Sonia K. Murthy, Rosie Zhao, Jennifer Hu, Sham Kakade, Markus Wulfmeier, Peng Qian, Tomer Ullman</author><pubDate>Mon, 06 Oct 2025 17:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.20666v3</guid></item><item><title>Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning</title><link>http://arxiv.org/abs/2412.10924v6</link><description>Tokenization is a necessary component within the current architecture of manylanguage models, including the transformer-based large language models (LLMs)of Generative AI, yet its impact on the model's cognition is often overlooked.We argue that LLMs demonstrate that the Distributional Hypothesis (DH) issufficient for reasonably human-like language performance, and that theemergence of human-meaningful linguistic units among tokens and currentstructural constraints motivate changes to existing, linguistically-agnostictokenization techniques, particularly with respect to their roles as (1)semantic primitives and as (2) vehicles for conveying salient distributionalpatterns from human language to the model. We explore tokenizations from a BPEtokenizer; extant model vocabularies obtained from Hugging Face and tiktoken;and the information in exemplar token vectors as they move through the layersof a RoBERTa (large) model. Besides creating sub-optimal semantic buildingblocks and obscuring the model's access to the necessary distributionalpatterns, we describe how tokens and pretraining can act as a backdoor for biasand other unwanted content, which current alignment practices may notremediate. Additionally, we relay evidence that the tokenization algorithm'sobjective function impacts the LLM's cognition, despite being arguablymeaningfully insulated from the main system intelligence. [First uploaded toarXiv in December, 2024.]</description><author>Julia Witte Zimmerman, Denis Hudon, Kathryn Cramer, Alejandro J. Ruiz, Calla Beauregard, Ashley Fehr, Mikaela Irene Fudolig, Bradford Demarest, Yoshi Meke Bird, Milo Z. Trujillo, Christopher M. Danforth, Peter Sheridan Dodds</author><pubDate>Mon, 06 Oct 2025 17:52:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10924v6</guid></item><item><title>PENEX: AdaBoost-Inspired Neural Network Regularization</title><link>http://arxiv.org/abs/2510.02107v2</link><description>AdaBoost sequentially fits so-called weak learners to minimize an exponentialloss, which penalizes mislabeled data points more severely than other lossfunctions like cross-entropy. Paradoxically, AdaBoost generalizes well inpractice as the number of weak learners grows. In the present work, weintroduce Penalized Exponential Loss (PENEX), a new formulation of themulti-class exponential loss that is theoretically grounded and, in contrast tothe existing formulation, amenable to optimization via first-order methods. Wedemonstrate both empirically and theoretically that PENEX implicitly maximizesmargins of data points. Also, we show that gradient increments on PENEXimplicitly parameterize weak learners in the boosting framework. Acrosscomputer vision and language tasks, we show that PENEX exhibits a regularizingeffect often better than established methods with similar computational cost.Our results highlight PENEX's potential as an AdaBoost-inspired alternative foreffective training and fine-tuning of deep neural networks.</description><author>Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach</author><pubDate>Mon, 06 Oct 2025 17:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02107v2</guid></item><item><title>SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder</title><link>http://arxiv.org/abs/2510.05081v1</link><description>Large-scale text-to-image diffusion models have become the backbone of modernimage editing, yet text prompts alone do not offer adequate control over theediting process. Two properties are especially desirable: disentanglement,where changing one attribute does not unintentionally alter others, andcontinuous control, where the strength of an edit can be smoothly adjusted. Weintroduce a method for disentangled and continuous editing through token-levelmanipulation of text embeddings. The edits are applied by manipulating theembeddings along carefully chosen directions, which control the strength of thetarget attribute. To identify such directions, we employ a Sparse Autoencoder(SAE), whose sparse latent space exposes semantically isolated dimensions. Ourmethod operates directly on text embeddings without modifying the diffusionprocess, making it model agnostic and broadly applicable to various imagesynthesis backbones. Experiments show that it enables intuitive and efficientmanipulations with continuous control across diverse attributes and domains.</description><author>Ronen Kamenetsky, Sara Dorfman, Daniel Garibi, Roni Paiss, Or Patashnik, Daniel Cohen-Or</author><pubDate>Mon, 06 Oct 2025 17:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05081v1</guid></item><item><title>MICROTRIPS: MICRO-geography TRavel Intelligence and Pattern Synthesis</title><link>http://arxiv.org/abs/2510.05080v1</link><description>This study presents a novel small-area estimation framework to enhance urbantransportation planning through detailed characterization of travel behavior.Our approach improves on the four-step travel model by employing publiclyavailable microdata files and machine learning methods to predict travelbehavior for a representative, synthetic population at small geographic areas.This approach enables high-resolution estimation of trip generation, tripdistribution, mode choice, and route assignment. Validation using ACS/PUMSwork-commute datasets demonstrates that our framework achieves higher accuracycompared to conventional approaches. The resulting granular insights enable thetailoring of interventions to address localized situations and support a rangeof policy applications and targeted interventions, including the optimalplacement of micro-fulfillment centers, effective curb-space management, andthe design of more inclusive transportation solutions particularly forvulnerable communities.</description><author>Yangyang Wang, Tayo Fabusuyi</author><pubDate>Mon, 06 Oct 2025 17:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05080v1</guid></item><item><title>Slm-mux: Orchestrating small language models for reasoning</title><link>http://arxiv.org/abs/2510.05077v1</link><description>With the rapid development of language models, the number of small languagemodels (SLMs) has grown significantly. Although they do not achievestate-of-the-art accuracy, they are more efficient and often excel at specifictasks. This raises a natural question: can multiple SLMs be orchestrated into asystem where each contributes effectively, achieving higher accuracy than anyindividual model? Existing orchestration methods have primarily targetedfrontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. Toaddress this gap, we propose a three-stage approach for orchestrating SLMs.First, we introduce SLM-MUX, a multi-model architecture that effectivelycoordinates multiple SLMs. Building on this, we develop two optimizationstrategies: (i) a model selection search that identifies the most complementarySLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Ourapproach delivers strong results: Compared to existing orchestration methods,our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA andGSM8K, and matches its performance on MATH. We further provide theoreticalanalyses to substantiate the advantages of our method. In summary, wedemonstrate that SLMs can be effectively orchestrated into more accurate andefficient systems through the proposed approach.</description><author>Chenyu Wang, Zishen Wan, Hao Kang, Emma Chen, Zhiqiang Xie, Tushar Krishna, Vijay Janapa Reddi, Yilun Du</author><pubDate>Mon, 06 Oct 2025 17:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05077v1</guid></item><item><title>The Telephone Game: Evaluating Semantic Drift in Unified Models</title><link>http://arxiv.org/abs/2509.04438v2</link><description>Employing a single, unified model (UM) for both visual understanding(image-to-text: I2T) and visual generation (text-to-image: T2I) has opened anew direction in Visual Language Model (VLM) research. While UMs can alsosupport broader unimodal tasks (e.g., text-to-text, image-to-image), we focuson the core cross-modal pair T2I and I2T. Existing evaluation benchmarksconsider these capabilities in isolation: FID and GenEval for T2I, andbenchmarks such as MME, MMBench for I2T. These isolated single-pass metrics donot reveal cross-consistency: whether a model that "understands" a concept canalso "render" it, nor whether semantic meaning is preserved when cyclingbetween image and text modalities. To address this, we introduce the SemanticDrift Protocol (SDP) for Unified Models, a cyclic evaluation protocol thatalternates I2T and T2I over multiple generations to quantify semantic drift. Wepropose two metrics: (i) Mean Cumulative Drift (MCD), an embedding-basedmeasure of overall semantic drift; and (ii) Multi-Generation GenEval (MGG), anobject-level compliance score extending GenEval. To assess generalizationbeyond COCO dataset, which is widely used in training; we create a newbenchmark Nocaps+Docci400, sampled from NoCaps and DOCCI and evaluated on sevenrecent models. SDP reveals substantial variation in cross-modal stability: somemodels like BAGEL maintain semantic meaning over many alternations, whereasothers like VILA-U drift quickly despite strong single-pass scores. Our resultshighlight SDP as a necessary complement to standard I2T and T2I evaluations.Code is available athttps://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models</description><author>Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir, Mubarak Shah</author><pubDate>Mon, 06 Oct 2025 17:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.04438v2</guid></item><item><title>Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces</title><link>http://arxiv.org/abs/2510.05071v1</link><description>Efficient and accurate classification of waste and industrial surface defectsis essential for ensuring sustainable waste management and maintaining highstandards in quality control. This paper introduces the Neuroplastic ModularClassifier, a novel hybrid architecture designed for robust and adaptive imageclassification in dynamic environments. The model combines a ResNet-50 backbonefor localized feature extraction with a Vision Transformer (ViT) to captureglobal semantic context. Additionally, FAISS-based similarity retrieval isincorporated to provide a memory-like reference to previously encountered data,enriching the model's feature space. A key innovation of our architecture isthe neuroplastic modular design composed of expandable, learnable blocks thatdynamically grow during training when performance plateaus. Inspired bybiological learning systems, this mechanism allows the model to adapt to datacomplexity over time, improving generalization. Beyond garbage classification,we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),which involves industrial defect detection on metal surfaces. Experimentalresults across domains show that the proposed architecture outperformstraditional static models in both accuracy and adaptability. The NeuroplasticModular Classifier offers a scalable, high-performance solution for real-worldimage classification, with strong applicability in both environmental andindustrial domains.</description><author>Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami</author><pubDate>Mon, 06 Oct 2025 17:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05071v1</guid></item><item><title>ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning</title><link>http://arxiv.org/abs/2510.05070v1</link><description>Humanoid whole-body loco-manipulation promises transformative capabilitiesfor daily service and warehouse tasks. While recent advances in general motiontracking (GMT) have enabled humanoids to reproduce diverse human motions, thesepolicies lack the precision and object awareness required forloco-manipulation. To this end, we introduce ResMimic, a two-stage residuallearning framework for precise and expressive humanoid control from humanmotion data. First, a GMT policy, trained on large-scale human-only motion,serves as a task-agnostic base for generating human-like whole-body movements.An efficient but precise residual policy is then learned to refine the GMToutputs to improve locomotion and incorporate object interaction. To furtherfacilitate efficient training, we design (i) a point-cloud-based objecttracking reward for smoother optimization, (ii) a contact reward thatencourages accurate humanoid body-object interactions, and (iii) acurriculum-based virtual object controller to stabilize early training. Weevaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Resultsshow substantial gains in task success, training efficiency, and robustnessover strong baselines. Videos are available at https://resmimic.github.io/ .</description><author>Siheng Zhao, Yanjie Ze, Yue Wang, C. Karen Liu, Pieter Abbeel, Guanya Shi, Rocky Duan</author><pubDate>Mon, 06 Oct 2025 17:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05070v1</guid></item><item><title>SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs</title><link>http://arxiv.org/abs/2510.05069v1</link><description>Recent work shows that, beyond discrete reasoning through explicitchain-of-thought steps, which are limited by the boundaries of naturallanguages, large language models (LLMs) can also reason continuously in latentspace, allowing richer information per step and thereby improving tokenefficiency. Despite this promise, latent reasoning still faces two challenges,especially in training-free settings: 1) purely latent reasoning broadens thesearch distribution by maintaining multiple implicit paths, which diffusesprobability mass, introduces noise, and impedes convergence to a singlehigh-confidence solution, thereby hurting accuracy; and 2) overthinkingpersists even without explicit text, wasting tokens and degrading efficiency.To address these issues, we introduce SwiReasoning, a training-free frameworkfor LLM reasoning which features two key innovations: 1) SwiReasoningdynamically switches between explicit and latent reasoning, guided byblock-wise confidence estimated from entropy trends in next-tokendistributions, to balance exploration and exploitation and promote timelyconvergence. 2) By limiting the maximum number of thinking-block switches,SwiReasoning curbs overthinking and improves token efficiency across varyingproblem difficulties. On widely used mathematics and STEM benchmarks,SwiReasoning consistently improves average accuracy by 1.5%-2.8% acrossreasoning LLMs of different model families and scales. Furthermore, underconstrained budgets, SwiReasoning improves average token efficiency by 56%-79%,with larger gains as budgets tighten.</description><author>Dachuan Shi, Abedelkadir Asi, Keying Li, Xiangchi Yuan, Leyan Pan, Wenke Lee, Wen Xiao</author><pubDate>Mon, 06 Oct 2025 17:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05069v1</guid></item><item><title>Diffusion^2: Turning 3D Environments into Radio Frequency Heatmaps</title><link>http://arxiv.org/abs/2510.02274v2</link><description>Modeling radio frequency (RF) signal propagation is essential forunderstanding the environment, as RF signals offer valuable insights beyond thecapabilities of RGB cameras, which are limited by the visible-light spectrum,lens coverage, and occlusions. It is also useful for supporting wirelessdiagnosis, deployment, and optimization. However, accurately predicting RFsignals in complex environments remains a challenge due to interactions withobstacles such as absorption and reflection. We introduce Diffusion^2, adiffusion-based approach that uses 3D point clouds to model the propagation ofRF signals across a wide range of frequencies, from Wi-Fi to millimeter waves.To effectively capture RF-related features from 3D data, we present the RF-3DEncoder, which encapsulates the complexities of 3D geometry along withsignal-specific details. These features undergo multi-scale embedding tosimulate the actual RF signal dissemination process. Our evaluation, based onsynthetic and real-world measurements, demonstrates that Diffusion^2 accuratelyestimates the behavior of RF signals in various frequency bands andenvironmental conditions, with an error margin of just 1.9 dB and 27x fasterthan existing methods, marking a significant advancement in the field. Refer tohttps://rfvision-project.github.io/ for more information.</description><author>Kyoungjun Park, Yifan Yang, Changhan Ge, Lili Qiu, Shiqi Jiang</author><pubDate>Mon, 06 Oct 2025 17:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02274v2</guid></item><item><title>Boomerang Distillation Enables Zero-Shot Model Size Interpolation</title><link>http://arxiv.org/abs/2510.05064v1</link><description>Large language models (LLMs) are typically deployed under diverse memory andcompute constraints. Existing approaches build model families by training eachsize independently, which is prohibitively expensive and provides onlycoarse-grained size options. In this work, we identify a novel phenomenon thatwe call boomerang distillation: starting from a large base model (the teacher),one first distills down to a small student and then progressively reconstructsintermediate-sized models by re-incorporating blocks of teacher layers into thestudent without any additional training. This process produces zero-shotinterpolated models of many intermediate sizes whose performance scalessmoothly between the student and teacher, often matching or surpassingpretrained or distilled models of the same size. We further analyze when thistype of interpolation succeeds, showing that alignment between teacher andstudent through pruning and distillation is essential. Boomerang distillationthus provides a simple and efficient way to generate fine-grained modelfamilies, dramatically reducing training cost while enabling flexibleadaptation across deployment environments. The code and models are available athttps://github.com/dcml-lab/boomerang-distillation.</description><author>Sara Kangaslahti, Nihal V. Nayak, Jonathan Geuter, Marco Fumero, Francesco Locatello, David Alvarez-Melis</author><pubDate>Mon, 06 Oct 2025 17:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05064v1</guid></item><item><title>VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL</title><link>http://arxiv.org/abs/2510.02282v2</link><description>With the rapid advancement of AI-generated videos, there is an urgent needfor effective detection tools to mitigate societal risks such as misinformationand reputational harm. In addition to accurate classification, it is essentialthat detection models provide interpretable explanations to ensure transparencyfor regulators and end users. To address these challenges, we introduceVidGuard-R1, the first video authenticity detector that fine-tunes amulti-modal large language model (MLLM) using group relative policyoptimization (GRPO). Our model delivers both highly accurate judgments andinsightful reasoning. We curate a challenging dataset of 140k real andAI-generated videos produced by state-of-the-art generation models, carefullydesigning the generation process to maximize discrimination difficulty. We thenfine-tune Qwen-VL using GRPO with two specialized reward models that targettemporal artifacts and generation complexity. Extensive experiments demonstratethat VidGuard-R1 achieves state-of-the-art zero-shot performance on existingbenchmarks, with additional training pushing accuracy above 95%. Case studiesfurther show that VidGuard-R1 produces precise and interpretable rationalesbehind its predictions. The code is publicly available athttps://VidGuard-R1.github.io.</description><author>Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz, Lili Qiu</author><pubDate>Mon, 06 Oct 2025 17:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02282v2</guid></item><item><title>ResCP: Reservoir Conformal Prediction for Time Series Forecasting</title><link>http://arxiv.org/abs/2510.05060v1</link><description>Conformal prediction offers a powerful framework for buildingdistribution-free prediction intervals for exchangeable data. Existing methodsthat extend conformal prediction to sequential data rely on fitting arelatively complex model to capture temporal dependencies. However, thesemethods can fail if the sample size is small and often require expensiveretraining when the underlying data distribution changes. To overcome theselimitations, we propose Reservoir Conformal Prediction (ResCP), a noveltraining-free conformal prediction method for time series. Our approachleverages the efficiency and representation learning capabilities of reservoircomputing to dynamically reweight conformity scores. In particular, we computesimilarity scores among reservoir states and use them to adaptively reweightthe observed residuals at each step. With this approach, ResCP enables us toaccount for local temporal dynamics when modeling the error distributionwithout compromising computational scalability. We prove that, under reasonableassumptions, ResCP achieves asymptotic conditional coverage, and we empiricallydemonstrate its effectiveness across diverse forecasting tasks.</description><author>Roberto Neglia, Andrea Cini, Michael M. Bronstein, Filippo Maria Bianchi</author><pubDate>Mon, 06 Oct 2025 17:37:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05060v1</guid></item><item><title>Staircase Streaming for Low-Latency Multi-Agent Inference</title><link>http://arxiv.org/abs/2510.05059v1</link><description>Recent advances in large language models (LLMs) opened up new directions forleveraging the collective expertise of multiple LLMs. These methods, such asMixture-of-Agents, typically employ additional inference steps to generateintermediate outputs, which are then used to produce the final response. Whilemulti-agent inference can enhance response quality, it can significantlyincrease the time to first token (TTFT), posing a challenge forlatency-sensitive applications and hurting user experience. To address thisissue, we propose staircase streaming for low-latency multi-agent inference.Instead of waiting for the complete intermediate outputs from previous steps,we begin generating the final response as soon as we receive partial outputsfrom these steps. Experimental results demonstrate that staircase streamingreduces TTFT by up to 93% while maintaining response quality.</description><author>Junlin Wang, Jue Wang, Zhen, Xu, Ben Athiwaratkun, Bhuwan Dhingra, Ce Zhang, James Zou</author><pubDate>Mon, 06 Oct 2025 17:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05059v1</guid></item><item><title>StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation</title><link>http://arxiv.org/abs/2510.05057v1</link><description>A fundamental challenge in embodied intelligence is developing expressive andcompact state representations for efficient world modeling and decision making.However, existing methods often fail to achieve this balance, yieldingrepresentations that are either overly redundant or lacking in task-criticalinformation. We propose an unsupervised approach that learns a highlycompressed two-token state representation using a lightweight encoder and apre-trained Diffusion Transformer (DiT) decoder, capitalizing on its stronggenerative prior. Our representation is efficient, interpretable, andintegrates seamlessly into existing VLA-based models, improving performance by14.3% on LIBERO and 30% in real-world task success with minimal inferenceoverhead. More importantly, we find that the difference between these tokens,obtained via latent interpolation, naturally serves as a highly effectivelatent action, which can be further decoded into executable robot actions. Thisemergent capability reveals that our representation captures structureddynamics without explicit supervision. We name our method StaMo for its abilityto learn generalizable robotic Motion from compact State representation, whichis encoded from static images, challenging the prevalent dependence to learninglatent action on complex architectures and video data. The resulting latentactions also enhance policy co-training, outperforming prior methods by 10.4%with improved interpretability. Moreover, our approach scales effectivelyacross diverse data sources, including real-world robot data, simulation, andhuman egocentric video.</description><author>Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen, Chunhua Shen</author><pubDate>Mon, 06 Oct 2025 17:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05057v1</guid></item><item><title>Modeling Student Learning with 3.8 Million Program Traces</title><link>http://arxiv.org/abs/2510.05056v1</link><description>As programmers write code, they often edit and retry multiple times, creatingrich "interaction traces" that reveal how they approach coding tasks andprovide clues about their level of skill development. For novice programmers inparticular, these traces reflect the diverse reasoning processes they employ tocode, such as exploratory behavior to understand how a programming conceptworks, re-strategizing in response to bugs, and personalizing stylisticchoices. In this work, we explore what can be learned from training languagemodels on such reasoning traces: not just about code, but about coders, andparticularly students learning to program. We introduce a dataset of over 3.8million programming reasoning traces from users of Pencil Code, a free onlineeducational platform used by students to learn simple programming concepts.Compared to models trained only on final programs or synthetically-generatedtraces, we find that models trained on real traces are stronger at modelingdiverse student behavior. Through both behavioral and probing analyses, we alsofind that many properties of code traces, such as goal backtracking or numberof comments, can be predicted from learned representations of the students whowrite them. Building on this result, we show that we can help students recoverfrom mistakes by steering code generation models to identify a sequence ofedits that will results in more correct code while remaining close to theoriginal student's style. Together, our results suggest that many properties ofcode are properties of individual students and that training on edit traces canlead to models that are more steerable, more predictive of student behaviorwhile programming, and better at generating programs in their final states.Code and data is available at https://github.com/meghabyte/pencilcode-public</description><author>Alexis Ross, Megha Srivastava, Jeremiah Blanchard, Jacob Andreas</author><pubDate>Mon, 06 Oct 2025 17:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05056v1</guid></item><item><title>Learning-Augmented Robust Algorithmic Recourse</title><link>http://arxiv.org/abs/2410.01580v2</link><description>Algorithmic recourse provides individuals who receive undesirable outcomesfrom machine learning systems with minimum-cost improvements to achieve adesirable outcome. However, machine learning models often get updated, so therecourse may not lead to the desired outcome. The robust recourse frameworkchooses recourses that are less sensitive to adversarial model changes, butthis comes at a higher cost. To address this, we initiate the study oflearning-augmented algorithmic recourse and evaluate the extent to which adesigner equipped with a prediction of the future model can reduce the cost ofrecourse when the prediction is accurate (consistency) while also limiting thecost even when the prediction is inaccurate (robustness). We propose a novelalgorithm, study the robustness-consistency trade-off, and analyze howprediction accuracy affects performance.</description><author>Kshitij Kayastha, Vasilis Gkatzelis, Shahin Jabbari</author><pubDate>Mon, 06 Oct 2025 17:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01580v2</guid></item><item><title>HybridFlow: Quantification of Aleatoric and Epistemic Uncertainty with a Single Hybrid Model</title><link>http://arxiv.org/abs/2510.05054v1</link><description>Uncertainty quantification is critical for ensuring robustness in high-stakesmachine learning applications. We introduce HybridFlow, a modular hybridarchitecture that unifies the modeling of aleatoric and epistemic uncertaintyby combining a Conditional Masked Autoregressive normalizing flow forestimating aleatoric uncertainty with a flexible probabilistic predictor forepistemic uncertainty. The framework supports integration with anyprobabilistic model class, allowing users to easily adapt HybridFlow toexisting architectures without sacrificing predictive performance. HybridFlowimproves upon previous uncertainty quantification frameworks across a range ofregression tasks, such as depth estimation, a collection of regressionbenchmarks, and a scientific case study of ice sheet emulation. We also provideempirical results of the quantified uncertainty, showing that the uncertaintyquantified by HybridFlow is calibrated and better aligns with model error thanexisting methods for quantifying aleatoric and epistemic uncertainty.HybridFlow addresses a key challenge in Bayesian deep learning, unifyingaleatoric and epistemic uncertainty modeling in a single robust framework.</description><author>Peter Van Katwyk, Karianne J. Bergen</author><pubDate>Mon, 06 Oct 2025 17:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05054v1</guid></item><item><title>No-reference Quality Assessment of Contrast-distorted Images using Contrast-enhanced Pseudo Reference</title><link>http://arxiv.org/abs/2510.05053v1</link><description>Contrast change is an important factor that affects the quality of images.During image capturing, unfavorable lighting conditions can cause contrastchange and visual quality loss. While various methods have been proposed toassess the quality of images under different distortions such as blur andnoise, contrast distortion has been largely overlooked as its visual impact andproperties are different from other conventional types of distortions. In thispaper, we propose a no-reference image quality assessment (NR-IQA) metric forcontrast-distorted images. Using a set of contrast enhancement algorithms, weaim to generate pseudo-reference images that are visually close to the actualreference image, such that the NR problem is transformed to a Full-reference(FR) assessment with higher accuracy. To this end, a large dataset ofcontrast-enhanced images is produced to train a classification network that canselect the most suitable contrast enhancement algorithm based on image contentand distortion for pseudo-reference image generation. Finally, the evaluationis performed in the FR manner to assess the quality difference between thecontrast-enhanced (pseudoreference) and degraded images. Performance evaluationof the proposed method on three databases containing contrast distortions(CCID2014, TID2013, and CSIQ), indicates the promising performance of theproposed method.</description><author>Mohammad-Ali Mahmoudpour, Saeed Mahmoudpour</author><pubDate>Mon, 06 Oct 2025 17:32:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05053v1</guid></item><item><title>Proactive defense against LLM Jailbreak</title><link>http://arxiv.org/abs/2510.05052v1</link><description>The proliferation of powerful large language models (LLMs) has necessitatedrobust safety alignment, yet these models remain vulnerable to evolvingadversarial attacks, including multi-turn jailbreaks that iteratively searchfor successful queries. Current defenses, primarily reactive and static, oftenfail to counter these search-based attacks. In this paper, we introduce ProAct,a novel proactive defense framework designed to disrupt and mislead autonomousjailbreaking processes. Our core idea is to intentionally provide adversarieswith "spurious responses" that appear to be results of successful jailbreakattacks but contain no actual harmful content. These misleading responsesprovide false signals to the attacker's internal optimization loop, causing theadversarial search to terminate prematurely and effectively jailbreaking thejailbreak. By conducting extensive experiments across state-of-the-art LLMs,jailbreaking frameworks, and safety benchmarks, our method consistently andsignificantly reduces attack success rates by up to 92\%. When combined withother defense frameworks, it further reduces the success rate of the latestattack strategies to 0\%. ProAct represents an orthogonal defense strategy thatcan serve as an additional guardrail to enhance LLM safety against the mosteffective jailbreaking attacks.</description><author>Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang</author><pubDate>Mon, 06 Oct 2025 17:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05052v1</guid></item><item><title>SegMASt3R: Geometry Grounded Segment Matching</title><link>http://arxiv.org/abs/2510.05051v1</link><description>Segment matching is an important intermediate task in computer vision thatestablishes correspondences between semantically or geometrically coherentregions across images. Unlike keypoint matching, which focuses on localizedfeatures, segment matching captures structured regions, offering greaterrobustness to occlusions, lighting variations, and viewpoint changes. In thispaper, we leverage the spatial understanding of 3D foundation models to tacklewide-baseline segment matching, a challenging setting involving extremeviewpoint shifts. We propose an architecture that uses the inductive bias ofthese 3D foundation models to match segments across image pairs with up to 180degree view-point change. Extensive experiments show that our approachoutperforms state-of-the-art methods, including the SAM2 video propagator andlocal feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++and Replica datasets. We further demonstrate benefits of the proposed model onrelevant downstream tasks, including 3D instance segmentation and image-goalnavigation. Project Page: https://segmast3r.github.io/</description><author>Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna</author><pubDate>Mon, 06 Oct 2025 17:31:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05051v1</guid></item><item><title>KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings</title><link>http://arxiv.org/abs/2510.05049v1</link><description>Machine learning in healthcare requires effective representation ofstructured medical codes, but current methods face a trade off: knowledge graphbased approaches capture formal relationships but miss real world patterns,while data driven methods learn empirical associations but often overlookstructured knowledge in medical terminologies. We present KEEP (Knowledgepreserving and Empirically refined Embedding Process), an efficient frameworkthat bridges this gap by combining knowledge graph embeddings with adaptivelearning from clinical data. KEEP first generates embeddings from knowledgegraphs, then employs regularized training on patient records to adaptivelyintegrate empirical patterns while preserving ontological relationships.Importantly, KEEP produces final embeddings without task specific auxiliary orend to end training enabling KEEP to support multiple downstream applicationsand model architectures. Evaluations on structured EHR from UK Biobank andMIMIC IV demonstrate that KEEP outperforms both traditional and Language Modelbased approaches in capturing semantic relationships and predicting clinicaloutcomes. Moreover, KEEP's minimal computational requirements make itparticularly suitable for resource constrained environments.</description><author>Ahmed Elhussein, Paul Meddeb, Abigail Newbury, Jeanne Mirone, Martin Stoll, Gamze Gursoy</author><pubDate>Mon, 06 Oct 2025 17:27:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05049v1</guid></item><item><title>A Unified Optimization Framework for Multiclass Classification with Structured Hyperplane Arrangements</title><link>http://arxiv.org/abs/2510.05047v1</link><description>In this paper, we propose a new mathematical optimization model formulticlass classification based on arrangements of hyperplanes. Our approachpreserves the core support vector machine (SVM) paradigm of maximizing classseparation while minimizing misclassification errors, and it is computationallymore efficient than a previous formulation. We present a kernel-based extensionthat allows it to construct nonlinear decision boundaries. Furthermore, we showhow the framework can naturally incorporate alternative geometric structures,including classification trees, $\ell_p$-SVMs, and models with discrete featureselection. To address large-scale instances, we develop a dynamic clusteringmatheuristic that leverages the proposed MIP formulation. Extensivecomputational experiments demonstrate the efficiency of the proposed model anddynamic clustering heuristic, and we report competitive classificationperformance on both synthetic datasets and real-world benchmarks from the UCIMachine Learning Repository, comparing our method with state-of-the-artimplementations available in scikit-learn.</description><author>Víctor Blanco, Harshit Kothari, James Luedtke</author><pubDate>Mon, 06 Oct 2025 17:26:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05047v1</guid></item><item><title>Look-ahead Reasoning with a Learned Model in Imperfect Information Games</title><link>http://arxiv.org/abs/2510.05048v1</link><description>Test-time reasoning significantly enhances pre-trained AI agents'performance. However, it requires an explicit environment model, oftenunavailable or overly complex in real-world scenarios. While MuZero enableseffective model learning for search in perfect information games, extendingthis paradigm to imperfect information games presents substantial challengesdue to more nuanced look-ahead reasoning techniques and large number of statesrelevant for individual decisions. This paper introduces an algorithm LAMIRthat learns an abstracted model of an imperfect information game directly fromthe agent-environment interaction. During test time, this trained model is usedto perform look-ahead reasoning. The learned abstraction limits the size ofeach subgame to a manageable size, making theoretically principled look-aheadreasoning tractable even in games where previous methods could not scale. Weempirically demonstrate that with sufficient capacity, LAMIR learns the exactunderlying game structure, and with limited capacity, it still learns avaluable abstraction, which improves game playing performance of thepre-trained agents even in large games.</description><author>Ondřej Kubíček, Viliam Lisý</author><pubDate>Mon, 06 Oct 2025 17:26:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05048v1</guid></item><item><title>COLE: a Comprehensive Benchmark for French Language Understanding Evaluation</title><link>http://arxiv.org/abs/2510.05046v1</link><description>To address the need for a more comprehensive evaluation of French NaturalLanguage Understanding (NLU), we introduce COLE, a new benchmark composed of 23diverse task covering a broad range of NLU capabilities, including sentimentanalysis, paraphrase detection, grammatical judgment, and reasoning, with aparticular focus on linguistic phenomena relevant to the French language. Webenchmark 94 large language models (LLM), providing an extensive analysis ofthe current state of French NLU. Our results highlight a significantperformance gap between closed- and open-weights models and identify keychallenging frontiers for current LLMs, such as zero-shot extractivequestion-answering (QA), fine-grained word sense disambiguation, andunderstanding of regional language variations. We release COLE as a publicresource to foster further progress in French language modelling.</description><author>David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury</author><pubDate>Mon, 06 Oct 2025 17:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05046v1</guid></item><item><title>Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse Reinforcement Learning</title><link>http://arxiv.org/abs/2410.12491v3</link><description>Large language models (LLMs) trained with Reinforcement Learning from HumanFeedback (RLHF) have demonstrated remarkable capabilities, but their underlyingreward functions and decision-making processes remain opaque. This paperintroduces a novel approach to interpreting LLMs by applying inversereinforcement learning (IRL) to recover their implicit reward functions. Weconduct experiments on toxicity-aligned LLMs of varying sizes, extractingreward models that achieve up to 85% accuracy in predicting human preferences.Our analysis reveals key insights into the non-identifiability of rewardfunctions, the relationship between model size and interpretability, andpotential pitfalls in the RLHF process. We demonstrate that IRL-derived rewardmodels can be used to fine-tune new LLMs, resulting in comparable or improvedperformance on toxicity benchmarks. This work provides a new lens forunderstanding and improving LLM alignment, with implications for theresponsible development and deployment of these powerful systems.</description><author>Jared Joselowitz, Ritam Majumdar, Arjun Jagota, Matthieu Bou, Nyal Patel, Satyapriya Krishna, Sonali Parbhoo</author><pubDate>Mon, 06 Oct 2025 17:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12491v3</guid></item><item><title>Rethinking Exact Unlearning under Exposure: Extracting Forgotten Data under Exact Unlearning in Large Language Model</title><link>http://arxiv.org/abs/2505.24379v2</link><description>Large Language Models are typically trained on datasets collected from theweb, which may inadvertently contain harmful or sensitive personal information.To address growing privacy concerns, unlearning methods have been proposed toremove the influence of specific data from trained models. Of these, exactunlearning -- which retrains the model from scratch without the target data --is widely regarded the gold standard for mitigating privacy risks indeployment. In this paper, we revisit this assumption in a practical deploymentsetting where both the pre- and post-unlearning logits API are exposed, such asin open-weight scenarios. Targeting this setting, we introduce a novel dataextraction attack that leverages signals from the pre-unlearning model to guidethe post-unlearning model, uncovering patterns that reflect the removed datadistribution. Combining model guidance with a token filtering strategy, ourattack significantly improves extraction success rates -- doubling performancein some cases -- across common benchmarks such as MUSE, TOFU, and WMDP.Furthermore, we demonstrate our attack's effectiveness on a simulated medicaldiagnosis dataset to highlight real-world privacy risks associated with exactunlearning. In light of our findings, which suggest that unlearning may, in acontradictory way, increase the risk of privacy leakage during real-worlddeployments, we advocate for evaluation of unlearning methods to considerbroader threat models that account not only for post-unlearning models but alsofor adversarial access to prior checkpoints. Code is publicly available at:https://github.com/Nicholas0228/unlearned_data_extraction_llm.</description><author>Xiaoyu Wu, Yifei Pang, Terrance Liu, Zhiwei Steven Wu</author><pubDate>Mon, 06 Oct 2025 17:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.24379v2</guid></item><item><title>Analysis of the Geometric Structure of Neural Networks and Neural ODEs via Morse Functions</title><link>http://arxiv.org/abs/2405.09351v3</link><description>Besides classical feed-forward neural networks such as multilayerperceptrons, also neural ordinary differential equations (neural ODEs) havegained particular interest in recent years. Neural ODEs can be interpreted asan infinite depth limit of feed-forward or residual neural networks. We studythe input-output dynamics of finite and infinite depth neural networks withscalar output. In the finite depth case, the input is a state associated with afinite number of nodes, which maps under multiple non-linear transformations tothe state of one output node. In analogy, a neural ODE maps an affine lineartransformation of the input to an affine linear transformation of its time-$T$map. We show that, depending on the specific structure of the network, theinput-output map has different properties regarding the existence andregularity of critical points. These properties can be characterized via Morsefunctions, which are scalar functions where every critical point isnon-degenerate. We prove that critical points cannot exist if the dimension ofthe hidden layer is monotonically decreasing or the dimension of the phasespace is smaller than or equal to the input dimension. In the case thatcritical points exist, we classify their regularity depending on the specificarchitecture of the network. We show that except for a Lebesgue measure zeroset in the weight space, each critical point is non-degenerate if for finitedepth neural networks the underlying graph has no bottleneck, and if for neuralODEs, the affine linear transformations used have full rank. For each type ofarchitecture, the proven properties are comparable in the finite and infinitedepth cases. The established theorems allow us to formulate results onuniversal embedding and universal approximation, i.e., on the exact andapproximate representation of maps by neural networks and neural ODEs.</description><author>Christian Kuehn, Sara-Viola Kuntz</author><pubDate>Mon, 06 Oct 2025 17:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09351v3</guid></item><item><title>Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts</title><link>http://arxiv.org/abs/2510.05040v1</link><description>Diffusion-based large language models (dLLMs) are trained flexibly to modelextreme dependence in the data distribution; however, how to best utilize thisinformation at inference time remains an open problem. In this work, we uncoveran interesting property of these models: dLLMs trained on textual dataimplicitly learn a mixture of semi-autoregressive experts, where differentgeneration orders reveal different specialized behaviors. We show thatcommitting to any single, fixed inference time schedule, a common practice,collapses performance by failing to leverage this latent ensemble. To addressthis, we introduce HEX (Hidden semiautoregressive EXperts for test-timescaling), a training-free inference method that ensembles across heterogeneousblock schedules. By doing a majority vote over diverse block-sized generationpaths, HEX robustly avoids failure modes associated with any single fixedschedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to3.56X (from 24.72% to 88.10%), outperforming top-K margin inference andspecialized fine-tuned methods like GRPO, without additional training. HEX evenyields significant gains on MATH benchmark from 16.40% to 40.00%, scientificreasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%.Our results establish a new paradigm for test-time scaling in diffusion-basedLLMs (dLLMs), revealing that the sequence in which masking is performed plays acritical role in determining performance during inference.</description><author>Jihoon Lee, Hoyeon Moon, Kevin Zhai, Arun Kumar Chithanar, Anit Kumar Sahu, Soummya Kar, Chul Lee, Souradip Chakraborty, Amrit Singh Bedi</author><pubDate>Mon, 06 Oct 2025 17:16:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05040v1</guid></item><item><title>RealKIE: Five Novel Datasets for Enterprise Key Information Extraction</title><link>http://arxiv.org/abs/2403.20101v2</link><description>We introduce RealKIE, a benchmark of five challenging datasets aimed atadvancing key information extraction methods, with an emphasis on enterpriseapplications. The datasets include a diverse range of documents including SECS1 Filings, US Non-disclosure Agreements, UK Charity Reports, FCC Invoices, andResource Contracts. Each presents unique challenges: poor text serialization,sparse annotations in long documents, and complex tabular layouts. Thesedatasets provide a realistic testing ground for key information extractiontasks like investment analysis and contract analysis. In addition to presentingthese datasets, we offer an in-depth description of the annotation process,document processing techniques, and baseline modeling approaches. Thiscontribution facilitates the development of NLP models capable of handlingpractical challenges and supports further research into information extractiontechnologies applicable to industry-specific problems. The annotated data, OCRoutputs, and code to reproduce baselines are available to download athttps://indicodatasolutions.github.io/RealKIE/.</description><author>Benjamin Townsend, Madison May, Katherine Mackowiak, Christopher Wells</author><pubDate>Mon, 06 Oct 2025 17:14:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20101v2</guid></item><item><title>RowDetr: End-to-End Crop Row Detection Using Polynomials</title><link>http://arxiv.org/abs/2412.10525v3</link><description>Crop row detection enables autonomous robots to navigate in gps deniedenvironments. Vision based strategies often struggle in the environments due togaps, curved crop rows and require post-processing steps. Furthermore, labelingcrop rows in under the canopy environments accurately is very difficult due toocclusions. This study introduces RowDetr, an efficient end-to-endtransformer-based neural network for crop row detection in precisionagriculture. RowDetr leverages a lightweight backbone and a hybrid encoder tomodel straight, curved, or occluded crop rows with high precision. Central tothe architecture is a novel polynomial representation that enables directparameterization of crop rows, eliminating computationally expensivepost-processing. Key innovations include a PolySampler module and multi-scaledeformable attention, which work together with PolyOptLoss, an energy-basedloss function designed to optimize geometric alignment between predicted andthe annotated crop rows, while also enhancing robustness against labelingnoise. RowDetr was evaluated against other state-of-the-art end-to-end crop rowdetection methods like AgroNav and RolColAttention on a diverse dataset of6,962 high-resolution images, used for training, validation, and testing acrossmultiple crop types with annotated crop rows. The system demonstrated superiorperformance, achieved an F1 score up to 0.74 and a lane position deviation aslow as 0.405. Furthermore, RowDetr achieves a real-time inference latency of6.7ms, which was optimized to 3.5ms with INT8 quantization on an NVIDIA JetsonOrin AGX. This work highlighted the critical efficiency of polynomialparameterization, making RowDetr particularly suitable for deployment on edgecomputing devices in agricultural robotics and autonomous farming equipment.Index terms &gt; Crop Row Detection, Under Canopy Navigation, Transformers,RT-DETR, RT-DETRv2</description><author>Rahul Harsha Cheppally, Ajay Sharda</author><pubDate>Mon, 06 Oct 2025 17:12:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10525v3</guid></item><item><title>Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization</title><link>http://arxiv.org/abs/2510.05038v1</link><description>Multimodal encoders have pushed the boundaries of visual document retrieval,matching textual query tokens directly to image patches and achievingstate-of-the-art performance on public benchmarks. Recent models relying onthis paradigm have massively scaled the sizes of their query and documentrepresentations, presenting obstacles to deployment and scalability inreal-world pipelines. Furthermore, purely vision-centric approaches may beconstrained by the inherent modality gap still exhibited by modernvision-language models. In this work, we connect these challenges to theparadigm of hybrid retrieval, investigating whether a lightweight dense textretriever can enhance a stronger vision-centric model. Existing hybrid methods,which rely on coarse-grained fusion of ranks or scores, fail to exploit therich interactions within each model's representation space. To address this, weintroduce Guided Query Refinement (GQR), a novel test-time optimization methodthat refines a primary retriever's query embedding using guidance from acomplementary retriever's scores. Through extensive experiments on visualdocument retrieval benchmarks, we demonstrate that GQR allows vision-centricmodels to match the performance of models with significantly largerrepresentations, while being up to 14x faster and requiring 54x less memory.Our findings show that GQR effectively pushes the Pareto frontier forperformance and efficiency in multimodal retrieval. We release our code athttps://github.com/IBM/test-time-hybrid-retrieval</description><author>Omri Uzan, Asaf Yehudai, Roi pony, Eyal Shnarch, Ariel Gera</author><pubDate>Mon, 06 Oct 2025 17:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05038v1</guid></item><item><title>Graph-Aware Diffusion for Signal Generation</title><link>http://arxiv.org/abs/2510.05036v1</link><description>We study the problem of generating graph signals from unknown distributionsdefined over given graphs, relevant to domains such as recommender systems orsensor networks. Our approach builds on generative diffusion models, which arewell established in vision and graph generation but remain underexplored forgraph signals. Existing methods lack generality, either ignoring the graphstructure in the forward process or designing graph-aware mechanisms tailoredto specific domains. We adopt a forward process that incorporates the graphthrough the heat equation. Rather than relying on the standard formulation, weconsider a time-warped coefficient to mitigate the exponential decay of thedrift term, yielding a graph-aware generative diffusion model (GAD). We analyzeits forward dynamics, proving convergence to a Gaussian Markov random fieldwith covariance parametrized by the graph Laplacian, and interpret the backwarddynamics as a sequence of graph-signal denoising problems. Finally, wedemonstrate the advantages of GAD on synthetic data, real traffic speedmeasurements, and a temperature sensor network.</description><author>Sergio Rozada, Vimal K. B., Andrea Cavallo, Antonio G. Marques, Hadi Jamali-Rad, Elvin Isufi</author><pubDate>Mon, 06 Oct 2025 17:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05036v1</guid></item><item><title>Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models</title><link>http://arxiv.org/abs/2510.05034v1</link><description>Video understanding represents the most challenging frontier in computervision, requiring models to reason about complex spatiotemporal relationships,long-term dependencies, and multimodal evidence. The recent emergence ofVideo-Large Multimodal Models (Video-LMMs), which integrate visual encoderswith powerful decoder-based language models, has demonstrated remarkablecapabilities in video understanding tasks. However, the critical phase thattransforms these models from basic perception systems into sophisticatedreasoning engines, post-training, remains fragmented across the literature.This survey provides the first comprehensive examination of post-trainingmethodologies for Video-LMMs, encompassing three fundamental pillars:supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)from verifiable objectives, and test-time scaling (TTS) through enhancedinference computation. We present a structured taxonomy that clarifies theroles, interconnections, and video-specific adaptations of these techniques,addressing unique challenges such as temporal localization, spatiotemporalgrounding, long video efficiency, and multimodal evidence integration. Throughsystematic analysis of representative methods, we synthesize key designprinciples, insights, and evaluation protocols while identifying critical openchallenges in reward design, scalability, and cost-performance optimization. Wefurther curate essential benchmarks, datasets, and metrics to facilitaterigorous assessment of post-training effectiveness. This survey aims to provideresearchers and practitioners with a unified framework for advancing Video-LMMcapabilities. Additional resources and updates are maintained at:https://github.com/yunlong10/Awesome-Video-LMM-Post-Training</description><author>Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua, Junjia Guo, Yunzhong Xiao, Chao Huang, Zhiyuan Wang, Susan Liang, Xinyi Liu, Yizhi Song, Yuhe Nie, Jia-Xing Zhong, Bozheng Li, Daiqing Qi, Ziyun Zeng, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Daiki Shimada, Han Liu, Jiebo Luo, Chenliang Xu</author><pubDate>Mon, 06 Oct 2025 17:10:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05034v1</guid></item><item><title>Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory</title><link>http://arxiv.org/abs/2509.18057v4</link><description>We explore whether techniques from AI can help discover new combinatorialstructures that improve on known limits on efficient algorithms. Specifically,we use AlphaEvolve (an LLM coding agent) to study two settings: a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve arecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set onrandom 3- and 4-regular graphs. Our improved lower bounds are obtained byconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, usingAlphaEvolve. Additionally, via analytical arguments we strengthen the upperbounds to settle the computational hardness of these questions up to an errorin the third decimal place. b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain newinapproximability results, proving that it is NP-hard to approximate MAX-4-CUTand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, usingAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improvesupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the currentbest gadget-based inapproximability result of $0.9853$, but falls short ofimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadgetreduction from "standard" H{\aa}stad-style PCPs. A key technical challenge we faced: verifying a candidate constructionproduced by AlphaEvolve is costly (often requiring exponential time). In bothsettings above, our results were enabled by using AlphaEvolve itself to evolvethe verification procedure to be faster (sometimes by $10,000\times$). Weconclude with a discussion of norms by which to assess the assistance from AIin developing proofs.</description><author>Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta</author><pubDate>Mon, 06 Oct 2025 17:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18057v4</guid></item><item><title>Causal Abstractions, Categorically Unified</title><link>http://arxiv.org/abs/2510.05033v1</link><description>We present a categorical framework for relating causal models that representthe same system at different levels of abstraction. We define a causalabstraction as natural transformations between appropriate Markov functors,which concisely consolidate desirable properties a causal abstraction shouldexhibit. Our approach unifies and generalizes previously considered causalabstractions, and we obtain categorical proofs and generalizations of existingresults on causal abstractions. Using string diagrammatical tools, we canexplicitly describe the graphs that serve as consistent abstractions of alow-level graph under interventions. We discuss how methods from mechanisticinterpretability, such as circuit analysis and sparse autoencoders, fit withinour categorical framework. We also show how applying do-calculus on ahigh-level graphical abstraction of an acyclic-directed mixed graph (ADMG),when unobserved confounders are present, gives valid results on the low-levelgraph, thus generalizing an earlier statement by Anand et al. (2023). We arguethat our framework is more suitable for modeling causal abstractions comparedto existing categorical frameworks. Finally, we discuss how notions such as$\tau$-consistency and constructive $\tau$-abstractions can be recovered withour framework.</description><author>Markus Englberger, Devendra Singh Dhami</author><pubDate>Mon, 06 Oct 2025 17:09:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05033v1</guid></item><item><title>Exploration-Exploitation-Evaluation (EEE): A Framework for Metaheuristic Algorithms in Combinatorial Optimization</title><link>http://arxiv.org/abs/2510.05027v1</link><description>We introduce a framework for applying metaheuristic algorithms, such as antcolony optimization (ACO), to combinatorial optimization problems (COPs) likethe traveling salesman problem (TSP). The framework consists of threesequential stages: broad exploration of the parameter space, exploitation oftop-performing parameters, and uncertainty quantification (UQ) to assess thereliability of results. As a case study, we apply ACO to the TSPLIB berlin52dataset, which has a known optimal tour length of 7542. Using our framework, wecalculate that the probability of ACO finding the global optimum isapproximately 1/40 in a single run and improves to 1/5 when aggregated over tenruns.</description><author>Ethan Davis</author><pubDate>Mon, 06 Oct 2025 17:04:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05027v1</guid></item><item><title>A Set of Quebec-French Corpus of Regional Expressions and Terms</title><link>http://arxiv.org/abs/2510.05026v1</link><description>The tasks of idiom understanding and dialect understanding are bothwell-established benchmarks in natural language processing. In this paper, wepropose combining them, and using regional idioms as a test of dialectunderstanding. Towards this end, we propose two new benchmark datasets for theQuebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomaticphrases, and QFrCoRT, which comprises 171 regional instances of idiomaticwords. We explain how to construct these corpora, so that our methodology canbe replicated for other dialects. Our experiments with 94 LLM demonstrate thatour regional idiom benchmarks are a reliable tool for measuring a model'sproficiency in a specific dialect.</description><author>David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury</author><pubDate>Mon, 06 Oct 2025 17:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05026v1</guid></item><item><title>Imperceptible Jailbreaking against Large Language Models</title><link>http://arxiv.org/abs/2510.05025v1</link><description>Jailbreaking attacks on the vision modality typically rely on imperceptibleadversarial perturbations, whereas attacks on the textual modality aregenerally assumed to require visible modifications (e.g., non-semanticsuffixes). In this paper, we introduce imperceptible jailbreaks that exploit aclass of Unicode characters called variation selectors. By appending invisiblevariation selectors to malicious questions, the jailbreak prompts appearvisually identical to original malicious questions on screen, while theirtokenization is "secretly" altered. We propose a chain-of-search pipeline togenerate such adversarial suffixes to induce harmful responses. Our experimentsshow that our imperceptible jailbreaks achieve high attack success ratesagainst four aligned LLMs and generalize to prompt injection attacks, allwithout producing any visible modifications in the written prompt. Our code isavailable at https://github.com/sail-sg/imperceptible-jailbreaks.</description><author>Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang</author><pubDate>Mon, 06 Oct 2025 17:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05025v1</guid></item><item><title>Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment</title><link>http://arxiv.org/abs/2510.05024v1</link><description>Large language models are sometimes trained with imperfect oversight signals,leading to undesired behaviors such as reward hacking and sycophancy. Improvingoversight quality can be expensive or infeasible, motivating methods thatimprove learned behavior despite an imperfect training signal. We introduceInoculation Prompting (IP), a simple but counterintuitive technique thatprevents learning of an undesired behavior by modifying training prompts toexplicitly request it. For example, to inoculate against reward hacking, wemodify the prompts used in supervised fine-tuning to request code that onlyworks on provided test cases but fails on other inputs. Across four settings wefind that IP reduces the learning of undesired behavior without substantiallyreducing the learning of desired capabilities. We also show that prompts whichmore strongly elicit the undesired behavior prior to fine-tuning moreeffectively inoculate against the behavior when used during training; thisserves as a heuristic to identify promising inoculation prompts. Overall, IP isa simple yet effective way to control how models generalize from fine-tuning,preventing learning of undesired behaviors without substantially disruptingdesired capabilities.</description><author>Nevan Wichers, Aram Ebtekar, Ariana Azarbal, Victor Gillioz, Christine Ye, Emil Ryd, Neil Rathi, Henry Sleight, Alex Mallen, Fabien Roger, Samuel Marks</author><pubDate>Mon, 06 Oct 2025 17:02:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05024v1</guid></item><item><title>Rethinking Langevin Thompson Sampling from A Stochastic Approximation Perspective</title><link>http://arxiv.org/abs/2510.05023v1</link><description>Most existing approximate Thompson Sampling (TS) algorithms for multi-armedbandits use Stochastic Gradient Langevin Dynamics (SGLD) or its variants ineach round to sample from the posterior, relaxing the need for conjugacyassumptions between priors and reward distributions in vanilla TS. However,they often require approximating a different posterior distribution indifferent round of the bandit problem. This requires tricky, round-specifictuning of hyperparameters such as dynamic learning rates, causing challenges inboth theoretical analysis and practical implementation. To alleviate thisnon-stationarity, we introduce TS-SA, which incorporates stochasticapproximation (SA) within the TS framework. In each round, TS-SA constructs aposterior approximation only using the most recent reward(s), performs aLangevin Monte Carlo (LMC) update, and applies an SA step to average noisyproposals over time. This can be interpreted as approximating a stationaryposterior target throughout the entire algorithm, which further yields a fixedstep-size, a unified convergence analysis framework, and improved posteriorestimates through temporal averaging. We establish near-optimal regret boundsfor TS-SA, with a simplified and more intuitive theoretical analysis enabled byinterpreting the entire algorithm as a simulation of a stationary SGLD process.Our empirical results demonstrate that even a single-step Langevin update withcertain warm-up outperforms existing methods substantially on bandit tasks.</description><author>Weixin Wang, Haoyang Zheng, Guang Lin, Wei Deng, Pan Xu</author><pubDate>Mon, 06 Oct 2025 17:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05023v1</guid></item><item><title>Fast constrained sampling in pre-trained diffusion models</title><link>http://arxiv.org/abs/2410.18804v3</link><description>Large denoising diffusion models, such as Stable Diffusion, have been trainedon billions of image-caption pairs to perform text-conditioned imagegeneration. As a byproduct of this training, these models have acquired generalknowledge about image statistics, which can be useful for other inferencetasks. However, when confronted with sampling an image under new constraints,e.g. generating the missing parts of an image, using large pre-trainedtext-to-image diffusion models is inefficient and often unreliable. Previousapproaches either utilized backpropagation through the denoiser network, makingthem significantly slower and more memory-demanding than simple text-to-imagegeneration, or only enforced the constraint locally, failing to capturecritical long-range correlations in the sampled image. In this work, we proposean algorithm that enables fast, high-quality generation under arbitraryconstraints. We show that in denoising diffusion models, we can employ anapproximation to Newton's optimization method that allows us to speed upinference and avoid the expensive backpropagation operations. Our approachproduces results that rival or surpass the state-of-the-art training-freeinference methods while requiring a fraction of the time. We demonstrate theeffectiveness of our algorithm under both linear (inpainting, super-resolution)and non-linear (style-guided generation) constraints. An implementation isprovided at https://github.com/cvlab-stonybrook/fast-constrained-sampling.</description><author>Alexandros Graikos, Nebojsa Jojic, Dimitris Samaras</author><pubDate>Mon, 06 Oct 2025 16:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18804v3</guid></item><item><title>Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation</title><link>http://arxiv.org/abs/2509.08825v2</link><description>Large language models are rapidly transforming social science research byenabling the automation of labor-intensive tasks like data annotation and textanalysis. However, LLM outputs vary significantly depending on theimplementation choices made by researchers (e.g., model selection or promptingstrategy). Such variation can introduce systematic biases and random errors,which propagate to downstream analyses and cause Type I (false positive), TypeII (false negative), Type S (wrong sign), or Type M (exaggerated effect)errors. We call this phenomenon where configuration choices lead to incorrectconclusions LLM hacking. We find that intentional LLM hacking is strikingly simple. By replicating 37data annotation tasks from 21 published social science studies, we show that,with just a handful of prompt paraphrases, virtually anything can be presentedas statistically significant. Beyond intentional manipulation, our analysis of 13 million labels from 18different LLMs across 2361 realistic hypotheses shows that there is also a highrisk of accidental LLM hacking, even when following standard researchpractices. We find incorrect conclusions in approximately 31% of hypotheses forstate-of-the-art LLMs, and in half the hypotheses for smaller language models.While higher task performance and stronger general model capabilities reduceLLM hacking risk, even highly accurate models remain susceptible. The risk ofLLM hacking decreases as effect sizes increase, indicating the need for morerigorous verification of LLM-based findings near significance thresholds. Weanalyze 21 mitigation techniques and find that human annotations providecrucial protection against false positives. Common regression estimatorcorrection techniques can restore valid inference but trade off Type I vs. TypeII errors. We publish a list of practical recommendations to prevent LLM hacking.</description><author>Joachim Baumann, Paul Röttger, Aleksandra Urman, Albert Wendsjö, Flor Miriam Plaza-del-Arco, Johannes B. Gruber, Dirk Hovy</author><pubDate>Mon, 06 Oct 2025 16:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.08825v2</guid></item><item><title>Large Language Models Achieve Gold Medal Performance at International Astronomy &amp; Astrophysics Olympiad</title><link>http://arxiv.org/abs/2510.05016v1</link><description>While task-specific demonstrations show early success in applying largelanguage models (LLMs) to automate some astronomical research tasks, they onlyprovide incomplete views of all necessary capabilities in solving astronomyproblems, calling for more thorough understanding of LLMs' strengths andlimitations. So far, existing benchmarks and evaluations focus on simplequestion-answering that primarily tests astronomical knowledge and fails toevaluate the complex reasoning required for real-world research in thediscipline. Here, we address this gap by systematically benchmarking fivestate-of-the-art LLMs on the International Olympiad on Astronomy andAstrophysics (IOAA) exams, which are designed to examine deep conceptualunderstanding, multi-step derivations, and multimodal analysis. With averagescores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performingmodels) not only achieve gold medal level performance but also rank in the toptwo among ~200-300 participants in all four IOAA theory exams evaluated(2022-2025). In comparison, results on the data analysis exams show moredivergence. GPT-5 still excels in the exams with an 88.5% average score,ranking top 10 among the participants in the four most recent IOAAs, whileother models' performances drop to 48-76%. Furthermore, our in-depth erroranalysis underscores conceptual reasoning, geometric reasoning, and spatialvisualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence,although LLMs approach peak human performance in theory exams, critical gapsmust be addressed before they can serve as autonomous research agents inastronomy.</description><author>Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun</author><pubDate>Mon, 06 Oct 2025 16:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05016v1</guid></item><item><title>Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns</title><link>http://arxiv.org/abs/2510.05015v1</link><description>Parkinson's disease (PD) is a progressive neurodegenerative conditioncharacterized by the death of dopaminergic neurons, leading to various movementdisorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects,yet traditional diagnostic methods are often cumbersome and costly. In thisstudy, a machine learning-based approach is proposed using hand-drawn spiraland wave images as potential biomarkers for PD detection. Our methodologyleverages convolutional neural networks (CNNs), transfer learning, andattention mechanisms to improve model performance and resilience againstoverfitting. To enhance the diversity and richness of both spiral and wavecategories, the training dataset undergoes augmentation to increase the numberof images. The proposed architecture comprises three phases: utilizingpre-trained CNNs, incorporating custom convolutional layers, and ensemblevoting. Employing hard voting further enhances performance by aggregatingpredictions from multiple models. Experimental results show promising accuracyrates. For spiral images, weighted average precision, recall, and F1-score are90%, and for wave images, they are 96.67%. After combining the predictionsthrough ensemble hard voting, the overall accuracy is 93.3%. These findingsunderscore the potential of machine learning in early PD diagnosis, offering anon-invasive and cost-effective solution to improve patient outcomes.</description><author>Nabil Daiyan, Md Rakibul Haque</author><pubDate>Mon, 06 Oct 2025 16:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05015v1</guid></item><item><title>Think Then Embed: Generative Context Improves Multimodal Embedding</title><link>http://arxiv.org/abs/2510.05014v1</link><description>There is a growing interest in Universal Multimodal Embeddings (UME), wheremodels are required to generate task-specific representations. While recentstudies show that Multimodal Large Language Models (MLLMs) perform well on suchtasks, they treat MLLMs solely as encoders, overlooking their generativecapacity. However, such an encoding paradigm becomes less effective asinstructions become more complex and require compositional reasoning. Inspiredby the proven effectiveness of chain-of-thought reasoning, we propose a generalThink-Then-Embed (TTE) framework for UME, composed of a reasoner and anembedder. The reasoner MLLM first generates reasoning traces that explaincomplex queries, followed by an embedder that produces representationsconditioned on both the original query and the intermediate reasoning. Thisexplicit reasoning step enables more nuanced understanding of complexmultimodal instructions. Our contributions are threefold. First, by leveraginga powerful MLLM reasoner, we achieve state-of-the-art performance on theMMEB-V2 benchmark, surpassing proprietary models trained on massive in-housedatasets. Second, to reduce the dependency on large MLLM reasoners, we finetunea smaller MLLM reasoner using high-quality embedding-centric reasoning traces,achieving the best performance among open-source models with a 7% absolute gainover recently proposed models. Third, we investigate strategies for integratingthe reasoner and embedder into a unified model for improved efficiency withoutsacrificing performance.</description><author>Xuanming Cui, Jianpeng Cheng, Hong-you Chen, Satya Narayan Shukla, Abhijeet Awasthi, Xichen Pan, Chaitanya Ahuja, Shlok Kumar Mishra, Qi Guo, Ser-Nam Lim, Aashu Singh, Xiangjun Fan</author><pubDate>Mon, 06 Oct 2025 16:53:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05014v1</guid></item><item><title>Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration</title><link>http://arxiv.org/abs/2510.05013v1</link><description>Human infants acquire language and action co-developmentally, achievingremarkable generalization capabilities from only a minimal number of learningexamples. In contrast, recent large language models require exposure tobillions of training tokens to achieve such generalization. What mechanismsunderlie such efficient developmental learning in humans? This study addressesthis question through simulation experiments in which robots learn to performvarious actions corresponding to imperative sentences (e.g., \textit{push redcube}) via trials of self-guided exploration. Our approach integrates theactive inference framework with reinforcement learning, enablingcuriosity-driven developmental learning. The simulations yielded severalnontrivial findings: i) Curiosity-driven exploration combined with motor noisesubstantially outperforms learning without curiosity. ii) Simpler,prerequisite-like actions emerge earlier in development, while more complexactions involving these prerequisites develop later. iii) Rote pairing ofsentences and actions occurs before the emergence of compositionalgeneralization. iv) Generalization is drastically improved as the number ofcompositional elements increases. These results shed light into possiblemechanisms underlying efficient co-developmental learning in infants andprovide computational parallels to findings in developmental psychology.</description><author>Theodore Jerome Tinker, Kenji Doya, Jun Tani</author><pubDate>Mon, 06 Oct 2025 16:53:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05013v1</guid></item><item><title>Latent Uncertainty Representations for Video-based Driver Action and Intention Recognition</title><link>http://arxiv.org/abs/2510.05006v1</link><description>Deep neural networks (DNNs) are increasingly applied to safety-critical tasksin resource-constrained environments, such as video-based driver action andintention recognition. While last layer probabilistic deep learning (LL-PDL)methods can detect out-of-distribution (OOD) instances, their performancevaries. As an alternative to last layer approaches, we propose extendingpre-trained DNNs with transformation layers to produce multiple latentrepresentations to estimate the uncertainty. We evaluate our latent uncertaintyrepresentation (LUR) and repulsively trained LUR (RLUR) approaches againsteight PDL methods across four video-based driver action and intentionrecognition datasets, comparing classification performance, calibration, anduncertainty-based OOD detection. We also contribute 28,000 frame-level actionlabels and 1,194 video-level intention labels for the NuScenes dataset. Ourresults show that LUR and RLUR achieve comparable in-distributionclassification performance to other LL-PDL approaches. For uncertainty-basedOOD detection, LUR matches top-performing PDL methods while being moreefficient to train and easier to tune than approaches that require Markov-ChainMonte Carlo sampling or repulsive training procedures.</description><author>Koen Vellenga, H. Joe Steinhauer, Jonas Andersson, Anders Sjögren</author><pubDate>Mon, 06 Oct 2025 16:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05006v1</guid></item><item><title>In-Context Learning for Pure Exploration</title><link>http://arxiv.org/abs/2506.01876v2</link><description>We study the problem active sequential hypothesis testing, also known as pureexploration: given a new task, the learner adaptively collects data from theenvironment to efficiently determine an underlying correct hypothesis. Aclassical instance of this problem is the task of identifying the best arm in amulti-armed bandit problem (a.k.a. BAI, Best-Arm Identification), where actionsindex hypotheses. Another important case is generalized search, a problem ofdetermining the correct label through a sequence of strategically selectedqueries that indirectly reveal information about the label. In this work, weintroduce In-Context Pure Exploration (ICPE), which meta-trains Transformers tomap observation histories to query actions and a predicted hypothesis, yieldinga model that transfers in-context. At inference time, ICPE actively gathersevidence on new tasks and infers the true hypothesis without parameter updates.Across deterministic, stochastic, and structured benchmarks, including BAI andgeneralized search, ICPE is competitive with adaptive baselines while requiringno explicit modeling of information structure. Our results support Transformersas practical architectures for general sequential testing.</description><author>Alessio Russo, Ryan Welch, Aldo Pacchiano</author><pubDate>Mon, 06 Oct 2025 16:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.01876v2</guid></item><item><title>Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2510.05003v1</link><description>Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstratedremarkable reasoning abilities but require significant computational resourcesfor fine-tuning. This paper presents a resource-efficient fine-tuning approachfor LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operatingunder constrained GPU and memory settings. Using parameter-efficient tuningtechniques such as LoRA and QLoRA, we adapt the base model on publiclyavailable medical reasoning datasets. The model achieves improved reasoningcoherence and factual accuracy while reducing memory usage by up to 60%compared to standard full fine-tuning. Experimental evaluation demonstratesthat lightweight adaptations can retain strong reasoning capability in medicalquestion-answering tasks. This work highlights practical strategies fordeploying LLMs in low-resource research environments and provides insights intobalancing efficiency and domain specialization for medical AI systems.</description><author>Imran Mansha</author><pubDate>Mon, 06 Oct 2025 16:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05003v1</guid></item><item><title>Cooperative Decentralized Backdoor Attacks on Vertical Federated Learning</title><link>http://arxiv.org/abs/2501.09320v2</link><description>Federated learning (FL) is vulnerable to backdoor attacks, where adversariesalter model behavior on target classification labels by embedding triggers intodata samples. While these attacks have received considerable attention inhorizontal FL, they are less understood for vertical FL (VFL), where deviceshold different features of the samples, and only the server holds the labels.In this work, we propose a novel backdoor attack on VFL which (i) does not relyon gradient information from the server and (ii) considers potential collusionamong multiple adversaries for sample selection and trigger embedding. Ourlabel inference model augments variational autoencoders with metric learning,which adversaries can train locally. A consensus process over the adversarygraph topology determines which datapoints to poison. We further proposemethods for trigger splitting across the adversaries, with an intensity-basedimplantation scheme skewing the server towards the trigger. Our convergenceanalysis reveals the impact of backdoor perturbations on VFL indicated by astationarity gap for the trained model, which we verify empirically as well. Weconduct experiments comparing our attack with recent backdoor VFL approaches,finding that ours obtains significantly higher success rates for the same maintask performance despite not using server information. Additionally, ourresults verify the impact of collusion on attack performance.</description><author>Seohyun Lee, Wenzhi Fang, Anindya Bijoy Das, Seyyedali Hosseinalipour, David J. Love, Christopher G. Brinton</author><pubDate>Mon, 06 Oct 2025 16:41:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09320v2</guid></item><item><title>QDFlow: A Python package for physics simulations of quantum dot devices</title><link>http://arxiv.org/abs/2509.13298v2</link><description>Recent advances in machine learning (ML) have accelerated progress incalibrating and operating quantum dot (QD) devices. However, most ML approachesrely on access to large, representative datasets designed to capture the fullspectrum of data quality encountered in practice, with both high- andlow-quality data for training, benchmarking, and validation, with labelscapturing key features of the device state. Collating such datasetsexperimentally is challenging due to limited data availability, slowmeasurement bandwidths, and the labor-intensive nature of labeling. QDFlow isan open-source physics simulator for multi-QD arrays that generates realisticsynthetic data with ground-truth labels. QDFlow combines a self-consistentThomas-Fermi solver, a dynamic capacitance model, and flexible noise modules tosimulate charge stability diagrams and ray-based data closely resemblingexperiments. With an extensive set of parameters that can be varied andcustomizable noise models, QDFlow supports the creation of large, diversedatasets for ML development, benchmarking, and quantum device research.</description><author>Donovan L. Buterakos, Sandesh S. Kalantre, Joshua Ziegler, Jacob M Taylor, Justyna P. Zwolak</author><pubDate>Mon, 06 Oct 2025 16:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.13298v2</guid></item><item><title>Bridging Text and Video Generation: A Survey</title><link>http://arxiv.org/abs/2510.04999v1</link><description>Text-to-video (T2V) generation technology holds potential to transformmultiple domains such as education, marketing, entertainment, and assistivetechnologies for individuals with visual or reading comprehension challenges,by creating coherent visual content from natural language prompts. From itsinception, the field has advanced from adversarial models to diffusion-basedmodels, yielding higher-fidelity, temporally consistent outputs. Yet challengespersist, such as alignment, long-range coherence, and computational efficiency.Addressing this evolving landscape, we present a comprehensive survey oftext-to-video generative models, tracing their development from early GANs andVAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how thesemodels work, what limitations they addressed in their predecessors, and whyshifts toward new architectural paradigms were necessary to overcome challengesin quality, coherence, and control. We provide a systematic account of thedatasets, which the surveyed text-to-video models were trained and evaluatedon, and, to support reproducibility and assess the accessibility of trainingsuch models, we detail their training configurations, including their hardwarespecifications, GPU counts, batch sizes, learning rates, optimizers, epochs,and other key hyperparameters. Further, we outline the evaluation metricscommonly used for evaluating such models and present their performance acrossstandard benchmarks, while also discussing the limitations of these metrics andthe emerging shift toward more holistic, perception-aligned evaluationstrategies. Finally, drawing from our analysis, we outline the current openchallenges and propose a few promising future directions, laying out aperspective for future researchers to explore and build upon in advancing T2Vresearch and applications.</description><author>Nilay Kumar, Priyansh Bhandari, G. Maragatham</author><pubDate>Mon, 06 Oct 2025 16:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04999v1</guid></item><item><title>AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault Analysis</title><link>http://arxiv.org/abs/2510.04997v1</link><description>Understanding software faults is essential for empirical research in softwaredevelopment and maintenance. However, traditional fault analysis, whilevaluable, typically involves multiple expert-driven steps such as collectingpotential faults, filtering, and manual investigation. These processes are bothlabor-intensive and time-consuming, creating bottlenecks that hinderlarge-scale fault studies in complex yet critical software systems and slow thepace of iterative empirical research. In this paper, we decompose the process of empirical software fault studyinto three key phases: (1) research objective definition, (2) data preparation,and (3) fault analysis, and we conduct an initial exploration study of applyingLarge Language Models (LLMs) for fault analysis of open-source software.Specifically, we perform the evaluation on 3,829 software faults drawn from ahigh-quality empirical study. Our results show that LLMs can substantiallyimprove efficiency in fault analysis, with an average processing time of abouttwo hours, compared to the weeks of manual effort typically required. Weconclude by outlining a detailed research plan that highlights both thepotential of LLMs for advancing empirical fault studies and the open challengesthat required be addressed to achieve fully automated, end-to-end softwarefault analysis.</description><author>Jiongchi Yu, Weipeng Jiang, Xiaoyu Zhang, Qiang Hu, Xiaofei Xie, Chao Shen</author><pubDate>Mon, 06 Oct 2025 16:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04997v1</guid></item><item><title>Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training</title><link>http://arxiv.org/abs/2510.04996v1</link><description>Reinforcement learning applied to large language models (LLMs) for reasoningtasks is often bottlenecked by unstable gradient estimates due to fixed anduniform sampling of responses across prompts. Prior work such as GVM-RAFTaddresses this by dynamically allocating inference budget per prompt tominimize stochastic gradient variance under a budget constraint. Inspired bythis insight, we propose Reinforce-Ada, an adaptive sampling framework foronline RL post-training of LLMs that continuously reallocates sampling effortto the prompts with the greatest uncertainty or learning potential. Unlikeconventional two-stage allocation methods, Reinforce-Ada interleaves estimationand sampling in an online successive elimination process, and automaticallystops sampling for a prompt once sufficient signal is collected. To stabilizeupdates, we form fixed-size groups with enforced reward diversity and computeadvantage baselines using global statistics aggregated over the adaptivesampling phase. Empirical results across multiple model architectures andreasoning benchmarks show that Reinforce-Ada accelerates convergence andimproves final performance compared to GRPO, especially when using the balancedsampling variant. Our work highlights the central role of variance-aware,adaptive data curation in enabling efficient and reliable reinforcementlearning for reasoning-capable LLMs. Code is available athttps://github.com/RLHFlow/Reinforce-Ada.</description><author>Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof Monz, Jiang Bian, Nan Jiang, Tong Zhang</author><pubDate>Mon, 06 Oct 2025 16:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04996v1</guid></item><item><title>Power Transform Revisited: Numerically Stable, and Federated</title><link>http://arxiv.org/abs/2510.04995v1</link><description>Power transforms are popular parametric techniques for making data moreGaussian-like, and are widely used as preprocessing steps in statisticalanalysis and machine learning. However, we find that direct implementations ofpower transforms suffer from severe numerical instabilities, which can lead toincorrect results or even crashes. In this paper, we provide a comprehensiveanalysis of the sources of these instabilities and propose effective remedies.We further extend power transforms to the federated learning setting,addressing both numerical and distributional challenges that arise in thiscontext. Experiments on real-world datasets demonstrate that our methods areboth effective and robust, substantially improving stability compared toexisting approaches.</description><author>Xuefeng Xu, Graham Cormode</author><pubDate>Mon, 06 Oct 2025 16:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04995v1</guid></item><item><title>Data-Driven Performance Guarantees for Classical and Learned Optimizers</title><link>http://arxiv.org/abs/2404.13831v3</link><description>We introduce a data-driven approach to analyze the performance of continuousoptimization algorithms using generalization guarantees from statisticallearning theory. We study classical and learned optimizers to solve families ofparametric optimization problems. We build generalization guarantees forclassical optimizers, using a sample convergence bound, and for learnedoptimizers, using the Probably Approximately Correct (PAC)-Bayes framework. Totrain learned optimizers, we use a gradient-based algorithm to directlyminimize the PAC-Bayes upper bound. Numerical experiments in signal processing,control, and meta-learning showcase the ability of our framework to providestrong generalization guarantees for both classical and learned optimizersgiven a fixed budget of iterations. For classical optimizers, our bounds aremuch tighter than those that worst-case guarantees provide. For learnedoptimizers, our bounds outperform the empirical outcomes observed in theirnon-learned counterparts.</description><author>Rajiv Sambharya, Bartolomeo Stellato</author><pubDate>Mon, 06 Oct 2025 16:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13831v3</guid></item><item><title>Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity</title><link>http://arxiv.org/abs/2510.01171v2</link><description>Post-training alignment often reduces LLM diversity, leading to a phenomenonknown as mode collapse. Unlike prior work that attributes this effect toalgorithmic limitations, we identify a fundamental, pervasive data-leveldriver: typicality bias in preference data, whereby annotators systematicallyfavor familiar text as a result of well-established findings in cognitivepsychology. We formalize this bias theoretically, verify it on preferencedatasets empirically, and show that it plays a central role in mode collapse.Motivated by this analysis, we introduce Verbalized Sampling, a simple,training-free prompting strategy to circumvent mode collapse. VS prompts themodel to verbalize a probability distribution over a set of responses (e.g.,"Generate 5 jokes about coffee and their corresponding probabilities").Comprehensive experiments show that VS significantly improves performanceacross creative writing (poems, stories, jokes), dialogue simulation,open-ended QA, and synthetic data generation, without sacrificing factualaccuracy and safety. For instance, in creative writing, VS increases diversityby 1.6-2.1x over direct prompting. We further observe an emergent trend thatmore capable models benefit more from VS. In sum, our work provides a newdata-centric perspective on mode collapse and a practical inference-time remedythat helps unlock pre-trained generative diversity.</description><author>Jiayi Zhang, Simon Yu, Derek Chong, Anthony Sicilia, Michael R. Tomz, Christopher D. Manning, Weiyan Shi</author><pubDate>Mon, 06 Oct 2025 16:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01171v2</guid></item><item><title>Critical Points of Random Neural Networks</title><link>http://arxiv.org/abs/2505.17000v2</link><description>This work investigates the expected number of critical points of randomneural networks with different activation functions as the depth increases inthe infinite-width limit. Under suitable regularity conditions, we deriveprecise asymptotic formulas for the expected number of critical points of fixedindex and those exceeding a given threshold. Our analysis reveals threedistinct regimes depending on the value of the first derivative of thecovariance evaluated at 1: the expected number of critical points may converge,grow polynomially, or grow exponentially with depth. The theoreticalpredictions are supported by numerical experiments. Moreover, we providenumerical evidence suggesting that, when the regularity condition is notsatisfied (e.g. for neural networks with ReLU as activation function), thenumber of critical points increases as the map resolution increases, indicatinga potential divergence in the number of critical points.</description><author>Simmaco Di Lillo</author><pubDate>Mon, 06 Oct 2025 16:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17000v2</guid></item><item><title>Physics-informed Value Learner for Offline Goal-Conditioned Reinforcement Learning</title><link>http://arxiv.org/abs/2509.06782v2</link><description>Offline Goal-Conditioned Reinforcement Learning (GCRL) holds great promisefor domains such as autonomous navigation and locomotion, where collectinginteractive data is costly and unsafe. However, it remains challenging inpractice due to the need to learn from datasets with limited coverage of thestate-action space and to generalize across long-horizon tasks. To improve onthese challenges, we propose a \emph{Physics-informed (Pi)} regularized lossfor value learning, derived from the Eikonal Partial Differential Equation(PDE) and which induces a geometric inductive bias in the learned valuefunction. Unlike generic gradient penalties that are primarily used tostabilize training, our formulation is grounded in continuous-time optimalcontrol and encourages value functions to align with cost-to-go structures. Theproposed regularizer is broadly compatible with temporal-difference-based valuelearning and can be integrated into existing Offline GCRL algorithms. Whencombined with Hierarchical Implicit Q-Learning (HIQL), the resulting method,Eikonal-regularized HIQL (Eik-HIQL), yields significant improvements in bothperformance and generalization, with pronounced gains in stitching regimes andlarge-scale navigation tasks.</description><author>Vittorio Giammarino, Ruiqi Ni, Ahmed H. Qureshi</author><pubDate>Mon, 06 Oct 2025 16:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.06782v2</guid></item><item><title>Adaptive Memory Momentum via a Model-Based Framework for Deep Learning Optimization</title><link>http://arxiv.org/abs/2510.04988v1</link><description>The vast majority of modern deep learning models are trained withmomentum-based first-order optimizers. The momentum term governs theoptimizer's memory by determining how much each past gradient contributes tothe current convergence direction. Fundamental momentum methods, such asNesterov Accelerated Gradient and the Heavy Ball method, as well as more recentoptimizers such as AdamW and Lion, all rely on the momentum coefficient that iscustomarily set to $\beta = 0.9$ and kept constant during model training, astrategy widely used by practitioners, yet suboptimal. In this paper, weintroduce an \textit{adaptive memory} mechanism that replaces constant momentumwith a dynamic momentum coefficient that is adjusted online duringoptimization. We derive our method by approximating the objective functionusing two planes: one derived from the gradient at the current iterate and theother obtained from the accumulated memory of the past gradients. To the bestof our knowledge, such a proximal framework was never used for momentum-basedoptimization. Our proposed approach is novel, extremely simple to use, and doesnot rely on extra assumptions or hyperparameter tuning. We implement adaptivememory variants of both SGD and AdamW across a wide range of learning tasks,from simple convex problems to large-scale deep learning scenarios,demonstrating that our approach can outperform standard SGD and Adam withhand-tuned momentum coefficients. Finally, our work opens doors for new ways ofinducing adaptivity in optimization.</description><author>Kristi Topollai, Anna Choromanska</author><pubDate>Mon, 06 Oct 2025 16:24:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04988v1</guid></item><item><title>Another look at inference after prediction</title><link>http://arxiv.org/abs/2411.19908v5</link><description>From structural biology to epidemiology, predictions from machine learning(ML) models increasingly complement costly gold-standard data to enable faster,more affordable, and scalable scientific inquiry. In response, prediction-based(PB) inference has emerged to accommodate statistical analysis using a largevolume of predictions together with a small amount of gold-standard data. Thegoals of PB inference are two-fold: (i) to mitigate bias from errors inpredictions and (ii) to improve efficiency relative to classical inferenceusing only the gold-standard data. While early PB inference methods focused onbias, their ability to enhance efficiency remains a focus of ongoing research.We revisit a foundational PB inference method and show that a simplemodification can be applied to guarantee provable improvements in efficiency.In doing so, we establish new connections between augmented inverse probabilityweighted estimators (AIPW) and several recently proposed PB inference methodswith a similar focus. The utility of our proposal, which leveragesprediction-based outcomes to enhance efficiency, is demonstrated throughextensive simulation studies and an application to real data from the UKBiobank. Further, we contextualize PB inference by drawing connections tohistorical literature from economics and statistics, highlighting how classicmethods directly inform this contemporary problem.</description><author>Jessica Gronsbell, Jianhui Gao, Yaqi Shi, Zachary R. McCaw, David Cheng</author><pubDate>Mon, 06 Oct 2025 16:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.19908v5</guid></item><item><title>What your brain activity says about you: A review of neuropsychiatric disorders identified in resting-state and sleep EEG data</title><link>http://arxiv.org/abs/2510.04984v1</link><description>Electroencephalogram monitoring devices and online data repositories holdlarge amounts of data from individuals participating in research and medicalstudies without direct reference to personal identifiers. This paper exploreswhat types of personal and health information have been detected and classifiedwithin task-free EEG data. Additionally, we investigate key characteristics ofthe collected resting-state and sleep data, in order to determine the privacyrisks involved with openly available EEG data. We used Google Scholar, Web ofScience and searched relevant journals to find studies which classified ordetected the presence of various disorders and personal information in restingstate and sleep EEG. Only English full-text peer-reviewed journal articles orconference papers about classifying the presence of medical disorders betweenindividuals were included. A quality analysis carried out by 3 reviewersdetermined general paper quality based on specified evaluation criteria. Inresting state EEG, various disorders including Autism Spectrum Disorder,Parkinson's disease, and alcohol use disorder have been classified with highclassification accuracy, often requiring only 5 mins of data or less. Sleep EEGtends to hold classifiable information about sleep disorders such as sleepapnea, insomnia, and REM sleep disorder, but usually involve longer recordingsor data from multiple sleep stages. Many classification methods are stilldeveloping but even today, access to a person's EEG can reveal sensitivepersonal health information. With an increasing ability of machine learningmethods to re-identify individuals from their EEG data, this reviewdemonstrates the importance of anonymization, and the development of improvedtools for keeping study participants and medical EEG users' privacy safe.</description><author>J. E. M. Scanlon, A. Pelzer, M. Gharleghi, K. C. Fuhrmeister, T. Köllmer, P. Aichroth, R. Göder, C. Hansen, K. I. Wolf</author><pubDate>Mon, 06 Oct 2025 16:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04984v1</guid></item><item><title>AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives</title><link>http://arxiv.org/abs/2510.04983v1</link><description>Identifying cultural capital (CC) themes in student reflections can offervaluable insights that help foster equitable learning environments inclassrooms. However, themes such as aspirational goals or family support areoften woven into narratives, rather than appearing as direct keywords. Thismakes them difficult to detect for standard NLP models that process sentencesin isolation. The core challenge stems from a lack of awareness, as standardmodels are pre-trained on general corpora, leaving them blind to thedomain-specific language and narrative context inherent to the data. To addressthis, we introduce AWARE, a framework that systematically attempts to improve atransformer model's awareness for this nuanced task. AWARE has three corecomponents: 1) Domain Awareness, adapting the model's vocabulary to thelinguistic style of student reflections; 2) Context Awareness, generatingsentence embeddings that are aware of the full essay context; and 3) ClassOverlap Awareness, employing a multi-label strategy to recognize thecoexistence of themes in a single sentence. Our results show that by making themodel explicitly aware of the properties of the input, AWARE outperforms astrong baseline by 2.1 percentage points in Macro-F1 and shows considerableimprovements across all themes. This work provides a robust and generalizablemethodology for any text classification task in which meaning depends on thecontext of the narrative.</description><author>Khalid Mehtab Khan, Anagha Kulkarni</author><pubDate>Mon, 06 Oct 2025 16:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04983v1</guid></item><item><title>LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game</title><link>http://arxiv.org/abs/2510.04980v1</link><description>Effective multi-agent collaboration requires agents to infer the rationalebehind others' actions, a capability rooted in Theory-of-Mind (ToM). Whilerecent Large Language Models (LLMs) excel at logical inference, their abilityto infer rationale in dynamic, collaborative settings remains under-explored.This study introduces LLM-Hanabi, a novel benchmark that uses the cooperativegame Hanabi to evaluate the rationale inference and ToM of LLMs. Our frameworkfeatures an automated evaluation system that measures both game performance andToM proficiency. Across a range of models, we find a significant positivecorrelation between ToM and in-game success. Notably, first-order ToM(interpreting others' intent) correlates more strongly with performance thansecond-order ToM (predicting others' interpretations). These findings highlightthat for effective AI collaboration, the ability to accurately interpret apartner's rationale is more critical than higher-order reasoning. We concludethat prioritizing first-order ToM is a promising direction for enhancing thecollaborative capabilities of future models.</description><author>Fangzhou Liang, Tianshi Zheng, Chunkit Chan, Yauwai Yim, Yangqiu Song</author><pubDate>Mon, 06 Oct 2025 16:17:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04980v1</guid></item><item><title>Federated Computation of ROC and PR Curves</title><link>http://arxiv.org/abs/2510.04979v1</link><description>Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves arefundamental tools for evaluating machine learning classifiers, offeringdetailed insights into the trade-offs between true positive rate vs. falsepositive rate (ROC) or precision vs. recall (PR). However, in FederatedLearning (FL) scenarios, where data is distributed across multiple clients,computing these curves is challenging due to privacy and communicationconstraints. Specifically, the server cannot access raw prediction scores andclass labels, which are used to compute the ROC and PR curves in a centralizedsetting. In this paper, we propose a novel method for approximating ROC and PRcurves in a federated setting by estimating quantiles of the prediction scoredistribution under distributed differential privacy. We provide theoreticalbounds on the Area Error (AE) between the true and estimated curves,demonstrating the trade-offs between approximation accuracy, privacy, andcommunication cost. Empirical results on real-world datasets demonstrate thatour method achieves high approximation accuracy with minimal communication andstrong privacy guarantees, making it practical for privacy-preserving modelevaluation in federated systems.</description><author>Xuefeng Xu, Graham Cormode</author><pubDate>Mon, 06 Oct 2025 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04979v1</guid></item><item><title>SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning</title><link>http://arxiv.org/abs/2505.19099v8</link><description>We present SeePhys, a large-scale multimodal benchmark for LLM reasoninggrounded in physics questions ranging from middle school to PhD qualifyingexams. The benchmark covers 7 fundamental domains spanning the physicsdiscipline, incorporating 21 categories of highly heterogeneous diagrams. Incontrast to prior works where visual elements mainly serve auxiliary purposes,our benchmark features a substantial proportion of vision-essential problems(75%) that mandate visual information extraction for correct solutions. Throughextensive evaluation, we observe that even the most advanced visual reasoningmodels (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on ourbenchmark. These results reveal fundamental challenges in current largelanguage models' visual understanding capabilities, particularly in: (i)establishing rigorous coupling between diagram interpretation and physicsreasoning, and (ii) overcoming their persistent reliance on textual cues ascognitive shortcuts.</description><author>Kun Xiang, Heng Li, Terry Jingchen Zhang, Yinya Huang, Zirong Liu, Peixin Qu, Jixi He, Jiaqi Chen, Yu-Jie Yuan, Jianhua Han, Hang Xu, Hanhui Li, Mrinmaya Sachan, Xiaodan Liang</author><pubDate>Mon, 06 Oct 2025 16:16:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.19099v8</guid></item><item><title>Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI</title><link>http://arxiv.org/abs/2510.04978v1</link><description>The rapid advancement of embodied intelligence and world models hasintensified efforts to integrate physical laws into AI systems, yet physicalperception and symbolic physics reasoning have developed along separatetrajectories without a unified bridging framework. This work provides acomprehensive overview of physical AI, establishing clear distinctions betweentheoretical physics reasoning and applied physical understanding whilesystematically examining how physics-grounded methods enhance AI's real-worldcomprehension across structured symbolic reasoning, embodied systems, andgenerative models. Through rigorous analysis of recent advances, we advocatefor intelligent systems that ground learning in both physical principles andembodied reasoning processes, transcending pattern recognition toward genuineunderstanding of physical laws. Our synthesis envisions next-generation worldmodels capable of explaining physical phenomena and predicting future states,advancing safe, generalizable, and interpretable AI systems. We maintain acontinuously updated resource athttps://github.com/AI4Phys/Awesome-AI-for-Physics.</description><author>Kun Xiang, Terry Jingchen Zhang, Yinya Huang, Jixi He, Zirong Liu, Yueling Tang, Ruizhe Zhou, Lijing Luo, Youpeng Wen, Xiuwei Chen, Bingqian Lin, Jianhua Han, Hang Xu, Hanhui Li, Bin Dong, Xiaodan Liang</author><pubDate>Mon, 06 Oct 2025 16:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04978v1</guid></item><item><title>Multi-Turn Human-LLM Interaction Through the Lens of a Two-Way Intelligibility Protocol</title><link>http://arxiv.org/abs/2410.20600v3</link><description>Our interest is in the design of software systems involving a human-expertinteracting -- using natural language -- with a large language model (LLM) ondata analysis tasks. For complex problems, it is possible that LLMs can harnesshuman expertise and creativity to find solutions that were otherwise elusive.On one level, this interaction takes place through multiple turns of promptsfrom the human and responses from the LLM. Here we investigate a morestructured approach based on an abstract protocol described in [3] forinteraction between agents. The protocol is motivated by a notion of "two-wayintelligibility" and is modelled by a pair of communicating finite-statemachines. We provide an implementation of the protocol, and provide empiricalevidence of using the implementation to mediate interactions between an LLM anda human-agent in two areas of scientific interest (radiology and drug design).We conduct controlled experiments with a human proxy (a database), anduncontrolled experiments with human subjects. The results provide evidence insupport of the protocol's capability of capturing one- and two-wayintelligibility in human-LLM interaction; and for the utility of two-wayintelligibility in the design of human-machine systems. Our code is availableat https://github.com/karannb/interact.</description><author>Harshvardhan Mestha, Karan Bania, Shreyas V Sathyanarayana, Sidong Liu, Ashwin Srinivasan</author><pubDate>Mon, 06 Oct 2025 16:15:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20600v3</guid></item><item><title>StructuralDecompose: A Modular Framework for Robust Time Series Decomposition in R</title><link>http://arxiv.org/abs/2510.04974v1</link><description>We present StructuralDecompose, an R package for modular and interpretabletime series decomposition. Unlike existing approaches that treat decompositionas a monolithic process, StructuralDecompose separates the analysis intodistinct components: changepoint detection, anomaly detection, smoothing, anddecomposition. This design provides flexibility and robust- ness, allowingusers to tailor methods to specific time series characteristics. We demonstratethe package on simulated and real-world datasets, benchmark its performanceagainst state-of-the- art tools such as Rbeast and autostsm, and discuss itsrole in interpretable machine learning workflows.</description><author>Allen Daniel Sunny</author><pubDate>Mon, 06 Oct 2025 16:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04974v1</guid></item><item><title>A Deterministic Information Bottleneck Method for Clustering Mixed-Type Data</title><link>http://arxiv.org/abs/2407.03389v4</link><description>In this paper, we present an information-theoretic method for clusteringmixed-type data, that is, data consisting of both continuous and categoricalvariables. The proposed approach extends the Information Bottleneck principleto heterogeneous data through generalised product kernels, integratingcontinuous, nominal, and ordinal variables within a unified optimizationframework. We address the following challenges: developing a systematicbandwidth selection strategy that equalises contributions across variabletypes, and proposing an adaptive hyperparameter updating scheme that ensures avalid solution into a predetermined number of potentially imbalanced clusters.Through simulations on 28,800 synthetic data sets and ten publicly availablebenchmarks, we demonstrate that the proposed method, named DIBmix, achievessuperior performance compared to four established methods (KAMILA,K-Prototypes, FAMD with K-Means, and PAM with Gower's dissimilarity). Resultsshow DIBmix particularly excels when clusters exhibit size imbalances, datacontain low or moderate cluster overlap, and categorical and continuousvariables are equally represented. The method presents a significant advantageover traditional centroid-based algorithms, establishing DIBmix as acompetitive and theoretically grounded alternative for mixed-type dataclustering.</description><author>Efthymios Costa, Ioanna Papatsouma, Angelos Markos</author><pubDate>Mon, 06 Oct 2025 16:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03389v4</guid></item><item><title>Pivotal CLTs for Pseudolikelihood via Conditional Centering in Dependent Random Fields</title><link>http://arxiv.org/abs/2510.04972v1</link><description>In this paper, we study fluctuations of conditionally centered statistics ofthe form $$N^{-1/2}\sum_{i=1}^Nc_i(g(\sigma_i)-\mathbb{E}_N[g(\sigma_i)|\sigma_j,j\neq i])$$ where$(\sigma_1,\ldots ,\sigma_N)$ are sampled from a dependent random field, and$g$ is some bounded function. Our first main result shows that under weaksmoothness assumptions on the conditional means (which cover both sparse anddense interactions), the above statistic converges to a Gaussian \emph{scalemixture} with a random scale determined by a \emph{quadratic variance} and an\emph{interaction component}. We also show that under appropriatestudentization, the limit becomes a pivotal Gaussian. We leverage this theoryto develop a general asymptotic framework for maximum pseudolikelihood (MPLE)inference in dependent random fields. We apply our results to Ising models withpairwise as well as higher-order interactions and exponential random graphmodels (ERGMs). In particular, we obtain a joint central limit theorem for theinverse temperature and magnetization parameters via the joint MPLE (to ourknowledge, the first such result in dense, irregular regimes), and we deriveconditionally centered edge CLTs and marginal MPLE CLTs for ERGMs withoutrestricting to the ``sub-critical" region. Our proof is based on a method ofmoments approach via combinatorial decision-tree pruning, which may be ofindependent interest.</description><author>Nabarun Deb</author><pubDate>Mon, 06 Oct 2025 16:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04972v1</guid></item><item><title>Pragmatic Embodied Spoken Instruction Following in Human-Robot Collaboration with Theory of Mind</title><link>http://arxiv.org/abs/2409.10849v2</link><description>Spoken language instructions are ubiquitous in agent collaboration. However,in real-world human-robot collaboration, following human spoken instructionscan be challenging due to various speaker and environmental factors, such asbackground noise or mispronunciation. When faced with noisy auditory inputs,humans can leverage the collaborative context in the embodied environment tointerpret noisy spoken instructions and take pragmatic assistive actions. Inthis paper, we present a cognitively inspired neurosymbolic model, SpokenInstruction Following through Theory of Mind (SIFToM), which leverages aVision-Language Model with model-based mental inference to enable robots topragmatically follow human instructions under diverse speech conditions. Wetest SIFToM in both simulated environments (VirtualHome) and real-worldhuman-robot collaborative settings with human evaluations. Results show thatSIFToM can significantly improve the performance of a lightweight base VLM(Gemini 2.5 Flash), outperforming state-of-the-art VLMs (Gemini 2.5 Pro) andapproaching human-level accuracy on challenging spoken instruction followingtasks.</description><author>Lance Ying, Xinyi Li, Shivam Aarya, Yizirui Fang, Yifan Yin, Jason Xinyu Liu, Stefanie Tellex, Joshua B. Tenenbaum, Tianmin Shu</author><pubDate>Mon, 06 Oct 2025 16:05:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10849v2</guid></item><item><title>Embracing Discrete Search: A Reasonable Approach to Causal Structure Learning</title><link>http://arxiv.org/abs/2510.04970v1</link><description>We present FLOP (Fast Learning of Order and Parents), a score-based causaldiscovery algorithm for linear models. It pairs fast parent selection withiterative Cholesky-based score updates, cutting run-times over prioralgorithms. This makes it feasible to fully embrace discrete search, enablingiterated local search with principled order initialization to find graphs withscores at or close to the global optimum. The resulting structures are highlyaccurate across benchmarks, with near-perfect recovery in standard settings.This performance calls for revisiting discrete search over graphs as areasonable approach to causal discovery.</description><author>Marcel Wienöbst, Leonard Henckel, Sebastian Weichwald</author><pubDate>Mon, 06 Oct 2025 16:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04970v1</guid></item><item><title>RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis</title><link>http://arxiv.org/abs/2507.05193v3</link><description>Rheumatoid arthritis (RA) is a common autoimmune disease that has been thefocus of research in computer-aided diagnosis (CAD) and disease monitoring. Inclinical settings, conventional radiography (CR) is widely used for thescreening and evaluation of RA due to its low cost and accessibility. The wristis a critical region for the diagnosis of RA. However, CAD research in thisarea remains limited, primarily due to the challenges in acquiring high-qualityinstance-level annotations. (i) The wrist comprises numerous small bones withnarrow joint spaces, complex structures, and frequent overlaps, requiringdetailed anatomical knowledge for accurate annotation. (ii) Disease progressionin RA often leads to osteophyte, bone erosion (BE), and even bony ankylosis,which alter bone morphology and increase annotation difficulty, necessitatingexpertise in rheumatology. This work presents a multi-task dataset for wristbone in CR, including two tasks: (i) wrist bone instance segmentation and (ii)Sharp/van der Heijde (SvdH) BE scoring, which is the first public resource forwrist bone instance segmentation. This dataset comprises 1048 wristconventional radiographs of 388 patients from six medical centers, withpixel-level instance segmentation annotations for 618 images and SvdH BE scoresfor 800 images. This dataset can potentially support a wide range of researchtasks related to RA, including joint space narrowing (JSN) progressionquantification, BE detection, bone deformity evaluation, and osteophytedetection. It may also be applied to other wrist-related tasks, such as carpalbone fracture localization. We hope this dataset will significantly lower thebarrier to research on wrist RA and accelerate progress in CAD research withinthe RA-related domain.</description><author>Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima, Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi</author><pubDate>Mon, 06 Oct 2025 15:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.05193v3</guid></item><item><title>ActiveMark: on watermarking of visual foundation models via massive activations</title><link>http://arxiv.org/abs/2510.04966v1</link><description>Being trained on large and vast datasets, visual foundation models (VFMs) canbe fine-tuned for diverse downstream tasks, achieving remarkable performanceand efficiency in various computer vision applications. The high computationcost of data collection and training motivates the owners of some VFMs todistribute them alongside the license to protect their intellectual propertyrights. However, a dishonest user of the protected model's copy may illegallyredistribute it, for example, to make a profit. As a consequence, thedevelopment of reliable ownership verification tools is of great importancetoday, since such methods can be used to differentiate between a redistributedcopy of the protected model and an independent model. In this paper, we proposean approach to ownership verification of visual foundation models byfine-tuning a small set of expressive layers of a VFM along with a smallencoder-decoder network to embed digital watermarks into an internalrepresentation of a hold-out set of input images. Importantly, the watermarksembedded remain detectable in the functional copies of the protected model,obtained, for example, by fine-tuning the VFM for a particular downstream task.Theoretically and experimentally, we demonstrate that the proposed methodyields a low probability of false detection of a non-watermarked model and alow probability of false misdetection of a watermarked model.</description><author>Anna Chistyakova, Mikhail Pautov</author><pubDate>Mon, 06 Oct 2025 15:58:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04966v1</guid></item><item><title>Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution</title><link>http://arxiv.org/abs/2504.05424v4</link><description>Efficiency is essential to support ever-growing datasets, especially for DeepLearning (DL) systems. DL frameworks have traditionally embraced deferredexecution-style DL code -- supporting symbolic, graph-based Deep Neural Network(DNN) computation. While scalable, such development is error-prone,non-intuitive, and difficult to debug. Consequently, more natural, imperativeDL frameworks encouraging eager execution have emerged but at the expense ofrun-time performance. Though hybrid approaches aim for the "best of bothworlds," using them effectively requires subtle considerations. Our key insightis that, while DL programs typically execute sequentially, hybridizingimperative DL code resembles parallelizing sequential code in traditionalsystems. Inspired by this, we present an automated refactoring approach thatassists developers in determining which otherwise eagerly-executed imperativeDL functions could be effectively and efficiently executed as graphs. Theapproach features novel static imperative tensor and side-effect analyses forPython. Due to its inherent dynamism, analyzing Python may be unsound; however,the conservative approach leverages a speculative (keyword-based) analysis forresolving difficult cases that informs developers of any assumptions made. Theapproach is: (i) implemented as a plug-in to the PyDev Eclipse IDE thatintegrates the WALA Ariadne analysis framework and (ii) evaluated on nineteenDL projects consisting of 132 KLOC. The results show that 326 of 766 candidatefunctions (42.56%) were refactorable, and an average relative speedup of 2.16xon performance tests was observed with negligible differences in modelaccuracy. The results indicate that the approach is useful in optimizingimperative DL code to its full potential.</description><author>Raffi Khatchadourian, Tatiana Castro Vélez, Mehdi Bagherzadeh, Nan Jia, Anita Raja</author><pubDate>Mon, 06 Oct 2025 15:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.05424v4</guid></item><item><title>SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization</title><link>http://arxiv.org/abs/2510.04961v1</link><description>Tokenizers are a key component of state-of-the-art generative image models,extracting the most important features from the signal while reducing datadimension and redundancy. Most current tokenizers are based on KL-regularizedvariational autoencoders (KL-VAE), trained with reconstruction, perceptual andadversarial losses. Diffusion decoders have been proposed as a more principledalternative to model the distribution over images conditioned on the latent.However, matching the performance of KL-VAE still requires adversarial losses,as well as a higher decoding time due to iterative sampling. To address theselimitations, we introduce a new pixel diffusion decoder architecture forimproved scaling and training stability, benefiting from transformer componentsand GAN-free training. We use distillation to replicate the performance of thediffusion decoder in an efficient single-step decoder. This makes SSDD thefirst diffusion decoder optimized for single-step reconstruction trainedwithout adversarial losses, reaching higher reconstruction quality and fastersampling than KL-VAE. In particular, SSDD improves reconstruction FID from$0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generationquality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used asa drop-in replacement for KL-VAE, and for building higher-quality and fastergenerative models.</description><author>Théophane Vallaeys, Jakob Verbeek, Matthieu Cord</author><pubDate>Mon, 06 Oct 2025 15:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04961v1</guid></item><item><title>A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation</title><link>http://arxiv.org/abs/2509.22229v2</link><description>Source-Free Unsupervised Domain Adaptation (SFUDA) addresses the realisticchallenge of adapting a source-trained model to a target domain without accessto the source data, driven by concerns over privacy and cost. Existing SFUDAmethods either exploit only the source model's predictions or fine-tune largemultimodal models, yet both neglect complementary insights and the latentstructure of target data. In this paper, we propose the Experts CooperativeLearning (EXCL). EXCL contains the Dual Experts framework andRetrieval-Augmentation-Interaction optimization pipeline. The Dual Expertsframework places a frozen source-domain model (augmented with Conv-Adapter) anda pretrained vision-language model (with a trainable text prompt) on equalfooting to mine consensus knowledge from unlabeled target samples. Toeffectively train these plug-in modules under purely unsupervised conditions,we introduce Retrieval-Augmented-Interaction(RAIN), a three-stage pipeline that(1) collaboratively retrieves pseudo-source and complex target samples, (2)separately fine-tunes each expert on its respective sample set, and (3)enforces learning object consistency via a shared learning result. Extensiveexperiments on four benchmark datasets demonstrate that our approach matchesstate-of-the-art performance.</description><author>Jiaping Yu, Muli Yang, Jiapeng Ji, Jiexi Yan, Cheng Deng</author><pubDate>Mon, 06 Oct 2025 15:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22229v2</guid></item><item><title>MuFFIN: Multifaceted Pronunciation Feedback Model with Interactive Hierarchical Neural Modeling</title><link>http://arxiv.org/abs/2510.04956v1</link><description>Computer-assisted pronunciation training (CAPT) manages to facilitatesecond-language (L2) learners to practice pronunciation skills by offeringtimely and instructive feedback. To examine pronunciation proficiency frommultiple facets, existing methods for CAPT broadly fall into two categories:mispronunciation detection and diagnosis (MDD) as well as automaticpronunciation assessment (APA). The former aims to pinpoint phoneticpronunciation errors and provide diagnostic feedback, while the latter seeksinstead to quantify pronunciation proficiency pertaining to various aspects.Despite the natural complementarity between MDD and APA, researchers andpractitioners, however, often treat them as independent tasks with disparatemodeling paradigms. In light of this, we in this paper first introduce MuFFIN,a Multi-Faceted pronunciation Feedback model with an Interactive hierarchicalNeural architecture, to jointly address the tasks of MDD and APA. To bettercapture the nuanced distinctions between phonemes in the feature space, a novelphoneme-contrastive ordinal regularization mechanism is then put forward tooptimize the proposed model to generate more phoneme-discriminative featureswhile factoring in the ordinality of the aspect scores. In addition, to addressthe intricate data imbalance problem in MDD, we design a simple yet effectivetraining objective, which is specifically tailored to perturb the outputs of aphoneme classifier with the phoneme-specific variations, so as to better renderthe distribution of predicted phonemes meanwhile considering theirmispronunciation characteristics. A series of experiments conducted on theSpeechocean762 benchmark dataset demonstrates the efficacy of our method inrelation to several cutting-edge baselines, showing state-of-the-artperformance on both the APA and MDD tasks.</description><author>Bi-Cheng Yan, Ming-Kang Tsai, Berlin Chen</author><pubDate>Mon, 06 Oct 2025 15:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04956v1</guid></item><item><title>CHARME: A chain-based reinforcement learning approach for the minor embedding problem</title><link>http://arxiv.org/abs/2406.07124v2</link><description>Quantum annealing (QA) has great potential to solve combinatorialoptimization problems efficiently. However, the effectiveness of QA algorithmsis heavily based on the embedding of problem instances, represented as logicalgraphs, into the quantum processing unit (QPU) whose topology is in the form ofa limited connectivity graph, known as the minor embedding problem. Because theminor embedding problem is an NP-hard problem~\mbox{\cite{Goodrich2018}},existing methods for the minor embedding problem suffer from scalability issueswhen faced with larger problem sizes. In this paper, we propose a novelapproach utilizing Reinforcement Learning (RL) techniques to address the minorembedding problem, named CHARME. CHARME includes three key components: a GraphNeural Network (GNN) architecture for policy modeling, a state transitionalgorithm that ensures solution validity, and an order exploration strategy foreffective training. Through comprehensive experiments on synthetic andreal-world instances, we demonstrate the efficiency of our proposed orderexploration strategy as well as our proposed RL framework, CHARME. Inparticular, CHARME yields superior solutions in terms of qubit usage comparedto fast embedding methods such as Minorminer and ATOM. Moreover, our methodsurpasses the OCT-based approach, known for its slower runtime but high-qualitysolutions, in several cases. In addition, our proposed exploration enhances theefficiency of the training of the CHARME framework by providing bettersolutions compared to the greedy strategy.</description><author>Hoang M. Ngo, Nguyen H K. Do, Minh N. Vu, Tre' R. Jeter, Tamer Kahveci, My T. Thai</author><pubDate>Mon, 06 Oct 2025 15:52:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07124v2</guid></item><item><title>Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits</title><link>http://arxiv.org/abs/2510.04952v1</link><description>We present a cross-market algorithmic trading system that balances executionquality with rigorous compliance enforcement. The architecture comprises ahigh-level planner, a reinforcement learning execution agent, and anindependent compliance agent. We formulate trade execution as a constrainedMarkov decision process with hard constraints on participation limits, pricebands, and self-trading avoidance. The execution agent is trained with proximalpolicy optimization, while a runtime action-shield projects any unsafe actioninto a feasible set. To support auditability without exposing proprietarysignals, we add a zero-knowledge compliance audit layer that producescryptographic proofs that all actions satisfied the constraints. We evaluate ina multi-venue, ABIDES-based simulator and compare against standard baselines(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall andvariance while exhibiting no observed constraint violations across stressscenarios including elevated latency, partial fills, compliance moduletoggling, and varying constraint limits. We report effects at the 95%confidence level using paired t-tests and examine tail risk via CVaR. Wesituate the work at the intersection of optimal execution, safe reinforcementlearning, regulatory technology, and verifiable AI, and discuss ethicalconsiderations, limitations (e.g., modeling assumptions and computationaloverhead), and paths to real-world deployment.</description><author>Ailiya Borjigin, Cong He</author><pubDate>Mon, 06 Oct 2025 15:52:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04952v1</guid></item><item><title>Feasibility-Aware Decision-Focused Learning for Predicting Parameters in the Constraints</title><link>http://arxiv.org/abs/2510.04951v1</link><description>When some parameters of a constrained optimization problem (COP) areuncertain, this gives rise to a predict-then-optimize (PtO) problem, comprisingtwo stages -- the prediction of the unknown parameters from contextualinformation and the subsequent optimization using those predicted parameters.Decision-focused learning (DFL) implements the first stage by training amachine learning (ML) model to optimize the quality of the decisions made usingthe predicted parameters. When parameters in the constraints of a COP arepredicted, the predicted parameters can lead to infeasible solutions.Therefore, it is important to simultaneously manage both feasibility anddecision quality. We develop a DFL framework for predicting constraintparameters in a generic COP. While prior works typically assume that theunderlying optimization problem is a linear program (LP) or integer linearprogram (ILP), our approach makes no such assumption. We derive two novel lossfunctions based on maximum likelihood estimation (MLE): the first one penalizesinfeasibility (by penalizing when the predicted parameters lead to infeasiblesolutions), and the second one penalizes suboptimal decisions (by penalizingwhen the true optimal solution is infeasible under the predicted parameters).We introduce a single tunable parameter to form a weighted average of the twolosses, allowing decision-makers to balance suboptimality and feasibility. Weexperimentally demonstrate that adjusting this parameter provides adecision-maker the control over the trade-off between the two. Moreover, acrossseveral COP instances, we find that for a single value of the tunableparameter, our method matches the performance of the existing baselines onsuboptimality and feasibility.</description><author>Jayanta Mandi, Marianne Defresne, Senne Berden, Tias Guns</author><pubDate>Mon, 06 Oct 2025 15:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04951v1</guid></item><item><title>Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)</title><link>http://arxiv.org/abs/2510.04950v1</link><description>The wording of natural language prompts has been shown to influence theperformance of large language models (LLMs), yet the role of politeness andtone remains underexplored. In this study, we investigate how varying levels ofprompt politeness affect model accuracy on multiple-choice questions. Wecreated a dataset of 50 base questions spanning mathematics, science, andhistory, each rewritten into five tone variants: Very Polite, Polite, Neutral,Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, weevaluated responses across these conditions and applied paired sample t-teststo assess statistical significance. Contrary to expectations, impolite promptsconsistently outperformed polite ones, with accuracy ranging from 80.8% forVery Polite prompts to 84.8% for Very Rude prompts. These findings differ fromearlier studies that associated rudeness with poorer outcomes, suggesting thatnewer LLMs may respond differently to tonal variation. Our results highlightthe importance of studying pragmatic aspects of prompting and raise broaderquestions about the social dimensions of human-AI interaction.</description><author>Om Dobariya, Akhil Kumar</author><pubDate>Mon, 06 Oct 2025 15:50:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04950v1</guid></item><item><title>What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale</title><link>http://arxiv.org/abs/2504.14815v2</link><description>Diffusion models (DMs) have revolutionized text-to-image generation, enablingthe creation of highly realistic and customized images from text prompts. Withthe rise of parameter-efficient fine-tuning (PEFT) techniques, users can nowcustomize powerful pre-trained models using minimal computational resources.However, the widespread sharing of fine-tuned DMs on open platforms raisesgrowing ethical and legal concerns, as these models may inadvertently ordeliberately generate sensitive or unauthorized content. Despite increasingregulatory attention on generative AI, there are currently no practical toolsfor systematically auditing these models before deployment. In this paper, we address the problem of concept auditing: determiningwhether a fine-tuned DM has learned to generate a specific target concept.Existing approaches typically rely on prompt-based input crafting andoutput-based image classification but they suffer from critical limitations,including prompt uncertainty, concept drift, and poor scalability. To overcomethese challenges, we introduce Prompt-Agnostic Image-Free Auditing (PAIA), anovel, model-centric concept auditing framework. By treating the DM as theobject of inspection, PAIA enables direct analysis of internal model behavior,bypassing the need for optimized prompts or generated images. We evaluate PAIAon 320 controlled models trained with curated concept datasets and 771real-world community models sourced from a public DM sharing platform.Evaluation results show that PAIA achieves over 90% detection accuracy whilereducing auditing time by 18 - 40X compared to existing baselines. To ourknowledge, PAIA is the first scalable and practical solution for pre-deploymentconcept auditing of diffusion models, providing a practical foundation forsafer and more transparent diffusion model sharing.</description><author>Xiaoyong Yuan, Xiaolong Ma, Linke Guo, Lan Zhang</author><pubDate>Mon, 06 Oct 2025 15:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.14815v2</guid></item><item><title>Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion</title><link>http://arxiv.org/abs/2510.04947v1</link><description>Dual-view mammography, including craniocaudal (CC) and mediolateral oblique(MLO) projections, offers complementary anatomical views crucial for breastcancer diagnosis. However, in real-world clinical workflows, one view may bemissing, corrupted, or degraded due to acquisition errors or compressionartifacts, limiting the effectiveness of downstream analysis. View-to-viewtranslation can help recover missing views and improve lesion alignment. Unlikenatural images, this task in mammography is highly challenging due to largenon-rigid deformations and severe tissue overlap in X-ray projections, whichobscure pixel-level correspondences. In this paper, we propose Column-Aware andImplicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram viewtranslation framework based on conditional diffusion model. To addresscross-view structural misalignment, we first design a column-awarecross-attention mechanism that leverages the geometric property thatanatomically corresponding regions tend to lie in similar column positionsacross views. A Gaussian-decayed bias is applied to emphasize local column-wisecorrelations while suppressing distant mismatches. Furthermore, we introduce animplicit 3D structure reconstruction module that back-projects noisy 2D latentsinto a coarse 3D feature volume based on breast-view projection geometry. Thereconstructed 3D structure is refined and injected into the denoising UNet toguide cross-view generation with enhanced anatomical awareness. Extensiveexperiments demonstrate that CA3D-Diff achieves superior performance inbidirectional tasks, outperforming state-of-the-art methods in visual fidelityand structural consistency. Furthermore, the synthesized views effectivelyimprove single-view malignancy classification in screening settings,demonstrating the practical value of our method in real-world diagnostics.</description><author>Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang</author><pubDate>Mon, 06 Oct 2025 15:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.04947v1</guid></item></channel></rss>