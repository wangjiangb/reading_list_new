<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 11 Jun 2024 06:00:50 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>IllumiNeRF: 3D Relighting without Inverse Rendering</title><link>http://arxiv.org/abs/2406.06527v1</link><description>Existing methods for relightable view synthesis -- using a set of images ofan object under unknown lighting to recover a 3D representation that can berendered from novel viewpoints under a target illumination -- are based oninverse rendering, and attempt to disentangle the object geometry, materials,and lighting that explain the input images. Furthermore, this typicallyinvolves optimization through differentiable Monte Carlo rendering, which isbrittle and computationally-expensive. In this work, we propose a simplerapproach: we first relight each input image using an image diffusion modelconditioned on lighting and then reconstruct a Neural Radiance Field (NeRF)with these relit images, from which we render novel views under the targetlighting. We demonstrate that this strategy is surprisingly competitive andachieves state-of-the-art results on multiple relighting benchmarks. Please seeour project page at https://illuminerf.github.io/.</description><author>Xiaoming Zhao, Pratul P. Srinivasan, Dor Verbin, Keunhong Park, Ricardo Martin Brualla, Philipp Henzler</author><pubDate>Mon, 10 Jun 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06527v1</guid></item><item><title>GaussianCity: Generative Gaussian Splatting for Unbounded 3D City Generation</title><link>http://arxiv.org/abs/2406.06526v1</link><description>3D city generation with NeRF-based methods shows promising generation resultsbut is computationally inefficient. Recently 3D Gaussian Splatting (3D-GS) hasemerged as a highly efficient alternative for object-level 3D generation.However, adapting 3D-GS from finite-scale 3D objects and humans toinfinite-scale 3D cities is non-trivial. Unbounded 3D city generation entailssignificant storage overhead (out-of-memory issues), arising from the need toexpand points to billions, often demanding hundreds of Gigabytes of VRAM for acity scene spanning 10km^2. In this paper, we propose GaussianCity, agenerative Gaussian Splatting framework dedicated to efficiently synthesizingunbounded 3D cities with a single feed-forward pass. Our key insights aretwo-fold: 1) Compact 3D Scene Representation: We introduce BEV-Point as ahighly compact intermediate representation, ensuring that the growth in VRAMusage for unbounded scenes remains constant, thus enabling unbounded citygeneration. 2) Spatial-aware Gaussian Attribute Decoder: We presentspatial-aware BEV-Point decoder to produce 3D Gaussian attributes, whichleverages Point Serializer to integrate the structural and contextualcharacteristics of BEV points. Extensive experiments demonstrate thatGaussianCity achieves state-of-the-art results in both drone-view andstreet-view 3D city generation. Notably, compared to CityDreamer, GaussianCityexhibits superior performance with a speedup of 60 times (10.72 FPS v.s. 0.18FPS).</description><author>Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu</author><pubDate>Mon, 10 Jun 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06526v1</guid></item><item><title>CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples</title><link>http://arxiv.org/abs/2402.13254v3</link><description>We propose CounterCurate, a framework to comprehensively improve thevisio-linguistic compositional reasoning capability for both contrastive andgenerative multimodal models. In particular, we identify two criticalunder-explored problems: the neglect of the physically grounded reasoning(counting and position understanding) and the potential of using highly capabletext and image generation models for semantic counterfactual fine-tuning. Ourwork pioneers an approach that addresses these gaps. We first spotlight thenear-chance performance of multimodal models like CLIP and LLaVA in physicallygrounded compositional reasoning. We then apply simple data augmentation usinggrounded image generation model GLIGEN to generate fine-tuning data, resultingin significant performance improvements: +33% and +37% for CLIP and LLaVA,respectively, on our newly curated Flickr30k-Positions benchmark. Moreover, weexploit the capabilities of high-performing text generation and imagegeneration models, specifically GPT-4V and DALLE-3, to curate challengingsemantic counterfactuals, thereby further enhancing compositional reasoningcapabilities on benchmarks such as SugarCrepe, where CounterCurate outperformsGPT-4V. To facilitate future research, we release our code, dataset, benchmark,and checkpoints at https://countercurate.github.io.</description><author>Jianrui Zhang, Mu Cai, Tengyang Xie, Yong Jae Lee</author><pubDate>Mon, 10 Jun 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13254v3</guid></item><item><title>Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation</title><link>http://arxiv.org/abs/2406.06525v1</link><description>We introduce LlamaGen, a new family of image generation models that applyoriginal ``next-token prediction'' paradigm of large language models to visualgeneration domain. It is an affirmative answer to whether vanillaautoregressive models, e.g., Llama, without inductive biases on visual signalscan achieve state-of-the-art image generation performance if scaling properly.We reexamine design spaces of image tokenizers, scalability properties of imagegeneration models, and their training data quality. The outcome of thisexploration consists of: (1) An image tokenizer with downsample ratio of 16,reconstruction quality of 0.94 rFID and codebook usage of 97% on ImageNetbenchmark. (2) A series of class-conditional image generation models rangingfrom 111M to 3.1B parameters, achieving 2.18 FID on ImageNet 256x256benchmarks, outperforming the popular diffusion models such as LDM, DiT. (3) Atext-conditional image generation model with 775M parameters, from two-stagetraining on LAION-COCO and high aesthetics quality images, demonstratingcompetitive performance of visual quality and text alignment. (4) We verify theeffectiveness of LLM serving frameworks in optimizing the inference speed ofimage generation models and achieve 326% - 414% speedup. We release all modelsand codes to facilitate open-source community of visual generation andmultimodal foundation models.</description><author>Peize Sun, Yi Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, Ping Luo, Zehuan Yuan</author><pubDate>Mon, 10 Jun 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06525v1</guid></item><item><title>NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing</title><link>http://arxiv.org/abs/2406.06523v1</link><description>We propose a video editing framework, NaRCan, which integrates a hybriddeformation field and diffusion prior to generate high-quality naturalcanonical images to represent the input video. Our approach utilizes homographyto model global motion and employs multi-layer perceptrons (MLPs) to capturelocal residual deformations, enhancing the model's ability to handle complexvideo dynamics. By introducing a diffusion prior from the early stages oftraining, our model ensures that the generated images retain a high-qualitynatural appearance, making the produced canonical images suitable for variousdownstream tasks in video editing, a capability not achieved by currentcanonical-based methods. Furthermore, we incorporate low-rank adaptation (LoRA)fine-tuning and introduce a noise and diffusion prior update schedulingtechnique that accelerates the training process by 14 times. Extensiveexperimental results show that our method outperforms existing approaches invarious video editing tasks and produces coherent and high-quality edited videosequences. See our project page for video results athttps://koi953215.github.io/NaRCan_page/.</description><author>Ting-Hsuan Chen, Jiewen Chan, Hau-Shiang Shiu, Shih-Han Yen, Chang-Han Yeh, Yu-Lun Liu</author><pubDate>Mon, 10 Jun 2024 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06523v1</guid></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>http://arxiv.org/abs/2404.02905v2</link><description>We present Visual AutoRegressive modeling (VAR), a new generation paradigmthat redefines the autoregressive learning on images as coarse-to-fine"next-scale prediction" or "next-resolution prediction", diverging from thestandard raster-scan "next-token prediction". This simple, intuitivemethodology allows autoregressive (AR) transformers to learn visualdistributions fast and generalize well: VAR, for the first time, makes GPT-likeAR models surpass diffusion transformers in image generation. On ImageNet256x256 benchmark, VAR significantly improve AR baseline by improving Frechetinception distance (FID) from 18.65 to 1.73, inception score (IS) from 80.4 to350.2, with around 20x faster inference speed. It is also empirically verifiedthat VAR outperforms the Diffusion Transformer (DiT) in multiple dimensionsincluding image quality, inference speed, data efficiency, and scalability.Scaling up VAR models exhibits clear power-law scaling laws similar to thoseobserved in LLMs, with linear correlation coefficients near -0.998 as solidevidence. VAR further showcases zero-shot generalization ability in downstreamtasks including image in-painting, out-painting, and editing. These resultssuggest VAR has initially emulated the two important properties of LLMs:Scaling Laws and zero-shot task generalization. We have released all models andcodes to promote the exploration of AR/VAR models for visual generation andunified learning.</description><author>Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, Liwei Wang</author><pubDate>Mon, 10 Jun 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02905v2</guid></item><item><title>PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction</title><link>http://arxiv.org/abs/2406.06521v1</link><description>Recently, 3D Gaussian Splatting (3DGS) has attracted widespread attention dueto its high-quality rendering, and ultra-fast training and rendering speed.However, due to the unstructured and irregular nature of Gaussian point clouds,it is difficult to guarantee geometric reconstruction accuracy and multi-viewconsistency simply by relying on image reconstruction loss. Although manystudies on surface reconstruction based on 3DGS have emerged recently, thequality of their meshes is generally unsatisfactory. To address this problem,we propose a fast planar-based Gaussian splatting reconstruction representation(PGSR) to achieve high-fidelity surface reconstruction while ensuringhigh-quality rendering. Specifically, we first introduce an unbiased depthrendering method, which directly renders the distance from the camera origin tothe Gaussian plane and the corresponding normal map based on the Gaussiandistribution of the point cloud, and divides the two to obtain the unbiaseddepth. We then introduce single-view geometric, multi-view photometric, andgeometric regularization to preserve global geometric accuracy. We also proposea camera exposure compensation model to cope with scenes with largeillumination variations. Experiments on indoor and outdoor scenes show that ourmethod achieves fast training and rendering while maintaining high-fidelityrendering and geometric reconstruction, outperforming 3DGS-based and NeRF-basedmethods.</description><author>Danpeng Chen, Hai Li, Weicai Ye, Yifan Wang, Weijian Xie, Shangjin Zhai, Nan Wang, Haomin Liu, Hujun Bao, Guofeng Zhang</author><pubDate>Mon, 10 Jun 2024 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06521v1</guid></item><item><title>Point-VOS: Pointing Up Video Object Segmentation</title><link>http://arxiv.org/abs/2402.05917v2</link><description>Current state-of-the-art Video Object Segmentation (VOS) methods rely ondense per-object mask annotations both during training and testing. Thisrequires time-consuming and costly video annotation mechanisms. We propose anovel Point-VOS task with a spatio-temporally sparse point-wise annotationscheme that substantially reduces the annotation effort. We apply ourannotation scheme to two large-scale video datasets with text descriptions andannotate over 19M points across 133K objects in 32K videos. Based on ourannotations, we propose a new Point-VOS benchmark, and a correspondingpoint-based training mechanism, which we use to establish strong baselineresults. We show that existing VOS methods can easily be adapted to leverageour point annotations during training, and can achieve results close to thefully-supervised performance when trained on pseudo-masks generated from thesepoints. In addition, we show that our data can be used to improve models thatconnect vision and language, by evaluating it on the Video Narrative Grounding(VNG) task. We will make our code and annotations available athttps://pointvos.github.io.</description><author>Idil Esen Zulfikar, Sabarinath Mahadevan, Paul Voigtlaender, Bastian Leibe</author><pubDate>Mon, 10 Jun 2024 18:58:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05917v2</guid></item><item><title>Decentralized Personalized Federated Learning</title><link>http://arxiv.org/abs/2406.06520v1</link><description>This work tackles the challenges of data heterogeneity and communicationlimitations in decentralized federated learning. We focus on creating acollaboration graph that guides each client in selecting suitable collaboratorsfor training personalized models that leverage their local data effectively.Our approach addresses these issues through a novel, communication-efficientstrategy that enhances resource efficiency. Unlike traditional methods, ourformulation identifies collaborators at a granular level by consideringcombinatorial relations of clients, enhancing personalization while minimizingcommunication overhead. We achieve this through a bi-level optimizationframework that employs a constrained greedy algorithm, resulting in aresource-efficient collaboration graph for personalized learning. Extensiveevaluation against various baselines across diverse datasets demonstrates thesuperiority of our method, named DPFL. DPFL consistently outperforms otherapproaches, showcasing its effectiveness in handling real-world dataheterogeneity, minimizing communication overhead, enhancing resourceefficiency, and building personalized models in decentralized federatedlearning scenarios.</description><author>Salma Kharrat, Marco Canini, Samuel Horvath</author><pubDate>Mon, 10 Jun 2024 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06520v1</guid></item><item><title>Data Augmentation for Multivariate Time Series Classification: An Experimental Study</title><link>http://arxiv.org/abs/2406.06518v1</link><description>Our study investigates the impact of data augmentation on the performance ofmultivariate time series models, focusing on datasets from the UCR archive.Despite the limited size of these datasets, we achieved classification accuracyimprovements in 10 out of 13 datasets using the Rocket and InceptionTimemodels. This highlights the essential role of sufficient data in trainingeffective models, paralleling the advancements seen in computer vision. Ourwork delves into adapting and applying existing methods in innovative ways tothe domain of multivariate time series classification. Our comprehensiveexploration of these techniques sets a new standard for addressing datascarcity in time series analysis, emphasizing that diverse augmentationstrategies are crucial for unlocking the potential of both traditional and deeplearning models. Moreover, by meticulously analyzing and applying a variety ofaugmentation techniques, we demonstrate that strategic data enrichment canenhance model accuracy. This not only establishes a benchmark for futureresearch in time series analysis but also underscores the importance ofadopting varied augmentation approaches to improve model performance in theface of limited data availability.</description><author>Romain Ilbert, Thai V. Hoang, Zonghua Zhang</author><pubDate>Mon, 10 Jun 2024 18:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06518v1</guid></item><item><title>Genomics-guided Representation Learning for Pathologic Pan-cancer Tumor Microenvironment Subtype Prediction</title><link>http://arxiv.org/abs/2406.06517v1</link><description>The characterization of Tumor MicroEnvironment (TME) is challenging due toits complexity and heterogeneity. Relatively consistent TME characteristicsembedded within highly specific tissue features, render them difficult topredict. The capability to accurately classify TME subtypes is of criticalsignificance for clinical tumor diagnosis and precision medicine. Based on theobservation that tumors with different origins share similar microenvironmentpatterns, we propose PathoTME, a genomics-guided Siamese representationlearning framework employing Whole Slide Image (WSI) for pan-cancer TMEsubtypes prediction. Specifically, we utilize Siamese network to leveragegenomic information as a regularization factor to assist WSI embeddingslearning during the training phase. Additionally, we employ Domain AdversarialNeural Network (DANN) to mitigate the impact of tissue type variations. Toeliminate domain bias, a dynamic WSI prompt is designed to further unleash themodel's capabilities. Our model achieves better performance than otherstate-of-the-art methods across 23 cancer types on TCGA dataset. Our code isavailable at https://github.com/Mengflz/PathoTME.</description><author>Fangliangzi Meng, Hongrun Zhang, Ruodan Yan, Guohui Chuai, Chao Li, Qi Liu</author><pubDate>Mon, 10 Jun 2024 18:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06517v1</guid></item><item><title>Distribution-Free Predictive Inference under Unknown Temporal Drift</title><link>http://arxiv.org/abs/2406.06516v1</link><description>Distribution-free prediction sets play a pivotal role in uncertaintyquantification for complex statistical models. Their validity hinges onreliable calibration data, which may not be readily available as real-worldenvironments often undergo unknown changes over time. In this paper, we proposea strategy for choosing an adaptive window and use the data therein toconstruct prediction sets. The window is selected by optimizing an estimatedbias-variance tradeoff. We provide sharp coverage guarantees for our method,showing its adaptivity to the underlying temporal drift. We also illustrate itsefficacy through numerical experiments on synthetic and real data.</description><author>Elise Han, Chengpiao Huang, Kaizheng Wang</author><pubDate>Mon, 10 Jun 2024 18:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06516v1</guid></item><item><title>Random Features Approximation for Control-Affine Systems</title><link>http://arxiv.org/abs/2406.06514v1</link><description>Modern data-driven control applications call for flexible nonlinear modelsthat are amenable to principled controller synthesis and realtime feedback.Many nonlinear dynamical systems of interest are control affine. We propose twonovel classes of nonlinear feature representations which capture control affinestructure while allowing for arbitrary complexity in the state dependence. Ourmethods make use of random features (RF) approximations, inheriting theexpressiveness of kernel methods at a lower computational cost. We formalizethe representational capabilities of our methods by showing their relationshipto the Affine Dot Product (ADP) kernel proposed by Casta\~neda et al. (2021)and a novel Affine Dense (AD) kernel that we introduce. We further illustratethe utility by presenting a case study of data-driven optimization-basedcontrol using control certificate functions (CCF). Simulation experiments on adouble pendulum empirically demonstrate the advantages of our methods.</description><author>Kimia Kazemian, Yahya Sattar, Sarah Dean</author><pubDate>Mon, 10 Jun 2024 18:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06514v1</guid></item><item><title>Merlin: A Vision Language Foundation Model for 3D Computed Tomography</title><link>http://arxiv.org/abs/2406.06512v1</link><description>Over 85 million computed tomography (CT) scans are performed annually in theUS, of which approximately one quarter focus on the abdomen. Given the currentradiologist shortage, there is a large impetus to use artificial intelligenceto alleviate the burden of interpreting these complex imaging studies. Priorstate-of-the-art approaches for automated medical image interpretation leveragevision language models (VLMs). However, current medical VLMs are generallylimited to 2D images and short reports, and do not leverage electronic healthrecord (EHR) data for supervision. We introduce Merlin - a 3D VLM that we trainusing paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes(1.8+ million codes), and radiology reports (6+ million tokens). We evaluateMerlin on 6 task types and 752 individual tasks. The non-adapted(off-the-shelf) tasks include zero-shot findings classification (31 findings),phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval(image to findings and image to impressions), while model adapted tasks include5-year disease prediction (6 diseases), radiology report generation, and 3Dsemantic segmentation (20 organs). We perform internal validation on a test setof 5,137 CTs, and external validation on 7,000 clinical CTs and on two publicCT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevantevaluations, we assess the efficacy of various network architectures andtraining strategies to depict that Merlin has favorable performance to existingtask-specific baselines. We derive data scaling laws to empirically assesstraining data needs for requisite downstream task performance. Furthermore,unlike conventional VLMs that require hundreds of GPUs for training, we performall training on a single GPU.</description><author>Louis Blankemeier, Joseph Paul Cohen, Ashwin Kumar, Dave Van Veen, Syed Jamal Safdar Gardezi, Magdalini Paschali, Zhihong Chen, Jean-Benoit Delbrouck, Eduardo Reis, Cesar Truyts, Christian Bluethgen, Malte Engmann Kjeldskov Jensen, Sophie Ostmeier, Maya Varma, Jeya Maria Jose Valanarasu, Zhongnan Fang, Zepeng Huo, Zaid Nabulsi, Diego Ardila, Wei-Hung Weng, Edson Amaro Junior, Neera Ahuja, Jason Fries, Nigam H. Shah, Andrew Johnston, Robert D. Boutin, Andrew Wentland, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, Akshay S. Chaudhari</author><pubDate>Mon, 10 Jun 2024 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06512v1</guid></item><item><title>AlpaCare:Instruction-tuned Large Language Models for Medical Application</title><link>http://arxiv.org/abs/2310.14558v4</link><description>Instruction-finetuning (IFT) has become crucial in aligning Large LanguageModels (LLMs) with diverse human needs and has shown great potential in medicalapplications. However, previous studies mainly fine-tune LLMs on biomedicaldatasets with limited diversity, which often rely on benchmarks or narrow taskscopes, and hence significantly limit the effectiveness on their medicalinstruction-following ability and generalizability. To bridge this gap, wepropose creating a diverse, machine-generated medical IFT dataset,MedInstruct-52k, using GPT-4 and ChatGPT with a high-quality expert-curatedseed set. We then fine-tune LLaMA-series models on the dataset to developAlpaCare. Despite using a smaller domain-specific dataset than previous medicalLLMs, AlpaCare not only demonstrates superior performance on medicalapplications, with up to 38.1% absolute gain over best baselines in medicalfree-form instruction evaluations, but also achieves 6.7% absolute gainsaveraged over multiple general domain benchmarks. Human evaluation furthershows that AlpaCare consistently outperforms best baselines in terms of bothcorrectness and helpfulness. We offer public access to our data, model, andcodebase in https://github.com/XZhang97666/AlpaCare.</description><author>Xinlu Zhang, Chenxin Tian, Xianjun Yang, Lichang Chen, Zekun Li, Linda Ruth Petzold</author><pubDate>Mon, 10 Jun 2024 18:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14558v4</guid></item><item><title>Model Editing at Scale leads to Gradual and Catastrophic Forgetting</title><link>http://arxiv.org/abs/2401.07453v4</link><description>Editing knowledge in large language models is an attractive capability tohave which allows us to correct incorrectly learnt facts during pre-training,as well as update the model with an ever-growing list of new facts. Whileexisting model editing techniques have shown promise, they are usuallyevaluated using metrics for reliability, specificity and generalization overone or few edits. We argue that for model editing to have practical utility, wemust be able to make multiple edits to the same model. With this in mind, weevaluate the current model editing methods at scale, focusing on two state ofthe art methods: ROME and MEMIT. We find that as the model is editedsequentially with multiple facts, it continually forgets previously editedfacts and the ability to perform downstream tasks. This forgetting happens intwo phases -- an initial gradual but progressive forgetting phase followed byabrupt or catastrophic forgetting phase. Both gradual and catastrophicforgetting limit the usefulness of model editing methods at scale -- the formermaking model editing less effective as multiple edits are made to the modelwhile the latter caps the scalability of such model editing methods. Ouranalysis also highlights other key limitations of ROME and MEMIT at scale. Withour work, we push for the development and evaluation of model editing methodskeeping scalability in mind.</description><author>Akshat Gupta, Anurag Rao, Gopala Anumanchipalli</author><pubDate>Mon, 10 Jun 2024 18:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07453v4</guid></item><item><title>Robust Distribution Learning with Local and Global Adversarial Corruptions</title><link>http://arxiv.org/abs/2406.06509v1</link><description>We consider learning in an adversarial environment, where an$\varepsilon$-fraction of samples from a distribution $P$ are arbitrarilymodified (*global* corruptions) and the remaining perturbations have averagemagnitude bounded by $\rho$ (*local* corruptions). Given access to $n$ suchcorrupted samples, we seek a computationally efficient estimator $\hat{P}_n$that minimizes the Wasserstein distance $\mathsf{W}_1(\hat{P}_n,P)$. In fact,we attack the fine-grained task of minimizing $\mathsf{W}_1(\Pi_\# \hat{P}_n,\Pi_\# P)$ for all orthogonal projections $\Pi \in \mathbb{R}^{d \times d}$,with performance scaling with $\mathrm{rank}(\Pi) = k$. This allows us toaccount simultaneously for mean estimation ($k=1$), distribution estimation($k=d$), as well as the settings interpolating between these two extremes. Wecharacterize the optimal population-limit risk for this task and then developan efficient finite-sample algorithm with error bounded by $\sqrt{\varepsilonk} + \rho + d^{O(1)}\tilde{O}(n^{-1/k})$ when $P$ has bounded moments of order$2+\delta$, for constant $\delta &gt; 0$. For data distributions with boundedcovariance, our finite-sample bounds match the minimax population-level optimumfor large sample sizes. Our efficient procedure relies on a novel trace normapproximation of an ideal yet intractable 2-Wasserstein projection estimator.We apply this algorithm to robust stochastic optimization, and, in the process,uncover a new method for overcoming the curse of dimensionality in Wassersteindistributionally robust optimization.</description><author>Sloan Nietert, Ziv Goldfeld, Soroosh Shafiee</author><pubDate>Mon, 10 Jun 2024 18:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06509v1</guid></item><item><title>Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer</title><link>http://arxiv.org/abs/2406.06508v1</link><description>Given the remarkable results of motion synthesis with diffusion models, anatural question arises: how can we effectively leverage these models formotion editing? Existing diffusion-based motion editing methods overlook theprofound potential of the prior embedded within the weights of pre-trainedmodels, which enables manipulating the latent feature space; hence, theyprimarily center on handling the motion space. In this work, we explore theattention mechanism of pre-trained motion diffusion models. We uncover theroles and interactions of attention elements in capturing and representingintricate human motion patterns, and carefully integrate these elements totransfer a leader motion to a follower one while maintaining the nuancedcharacteristics of the follower, resulting in zero-shot motion transfer.Editing features associated with selected motions allows us to confront achallenge observed in prior motion diffusion approaches, which use generaldirectives (e.g., text, music) for editing, ultimately failing to convey subtlenuances effectively. Our work is inspired by how a monkey closely imitates whatit sees while maintaining its unique motion patterns; hence we call it MonkeySee, Monkey Do, and dub it MoMo. Employing our technique enables accomplishingtasks such as synthesizing out-of-distribution motions, style transfer, andspatial editing. Furthermore, diffusion inversion is seldom employed formotions; as a result, editing efforts focus on generated motions, limiting theeditability of real ones. MoMo harnesses motion inversion, extending itsapplication to both real and generated motions. Experimental results show theadvantage of our approach over the current art. In particular, unlike methodstailored for specific applications through training, our approach is applied atinference time, requiring no training. Our webpage is athttps://monkeyseedocg.github.io.</description><author>Sigal Raab, Inbar Gat, Nathan Sala, Guy Tevet, Rotem Shalev-Arkushin, Ohad Fried, Amit H. Bermano, Daniel Cohen-Or</author><pubDate>Mon, 10 Jun 2024 18:47:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06508v1</guid></item><item><title>Verification-Guided Shielding for Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2406.06507v1</link><description>In recent years, Deep Reinforcement Learning (DRL) has emerged as aneffective approach to solving real-world tasks. However, despite theirsuccesses, DRL-based policies suffer from poor reliability, which limits theirdeployment in safety-critical domains. As a result, various methods have beenput forth to address this issue by providing formal safety guarantees. Two mainapproaches include shielding and verification. While shielding ensures the safebehavior of the policy by employing an external online component (i.e., a``shield'') that overruns potentially dangerous actions, this approach has asignificant computational cost as the shield must be invoked at runtime tovalidate every decision. On the other hand, verification is an offline processthat can identify policies that are unsafe, prior to their deployment, yet,without providing alternative actions when such a policy is deemed unsafe. Inthis work, we present verification-guided shielding -- a novel approach thatbridges the DRL reliability gap by integrating these two methods. Our approachcombines both formal and probabilistic verification tools to partition theinput domain into safe and unsafe regions. In addition, we employ clusteringand symbolic representation procedures that compress the unsafe regions into acompact representation. This, in turn, allows to temporarily activate theshield solely in (potentially) unsafe regions, in an efficient manner. Ournovel approach allows to significantly reduce runtime overhead while stillpreserving formal safety guarantees. We extensively evaluate our approach ontwo benchmarks from the robotic navigation domain, as well as provide anin-depth analysis of its scalability and completeness.</description><author>Davide Corsi, Guy Amir, Andoni Rodriguez, Cesar Sanchez, Guy Katz, Roy Fox</author><pubDate>Mon, 10 Jun 2024 18:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06507v1</guid></item><item><title>Online Newton Method for Bandit Convex Optimisation</title><link>http://arxiv.org/abs/2406.06506v1</link><description>We introduce a computationally efficient algorithm for zeroth-order banditconvex optimisation and prove that in the adversarial setting its regret is atmost $d^{3.5} \sqrt{n} \mathrm{polylog}(n, d)$ with high probability where $d$is the dimension and $n$ is the time horizon. In the stochastic setting thebound improves to $M d^{2} \sqrt{n} \mathrm{polylog}(n, d)$ where $M \in[d^{-1/2}, d^{-1 / 4}]$ is a constant that depends on the geometry of theconstraint set and the desired computational properties.</description><author>Hidde Fokkema, Dirk van der Hoeven, Tor Lattimore, Jack J. Mayo</author><pubDate>Mon, 10 Jun 2024 18:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06506v1</guid></item><item><title>Equivariant Neural Tangent Kernels</title><link>http://arxiv.org/abs/2406.06504v1</link><description>Equivariant neural networks have in recent years become an importanttechnique for guiding architecture selection for neural networks with manyapplications in domains ranging from medical image analysis to quantumchemistry. In particular, as the most general linear equivariant layers withrespect to the regular representation, group convolutions have been highlyimpactful in numerous applications. Although equivariant architectures havebeen studied extensively, much less is known about the training dynamics ofequivariant neural networks. Concurrently, neural tangent kernels (NTKs) haveemerged as a powerful tool to analytically understand the training dynamics ofwide neural networks. In this work, we combine these two fields for the firsttime by giving explicit expressions for NTKs of group convolutional neuralnetworks. In numerical experiments, we demonstrate superior performance forequivariant NTKs over non-equivariant NTKs on a classification task for medicalimages.</description><author>Philipp Misof, Pan Kessel, Jan E. Gerken</author><pubDate>Mon, 10 Jun 2024 18:43:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06504v1</guid></item><item><title>Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding -- A Survey</title><link>http://arxiv.org/abs/2402.17944v3</link><description>Recent breakthroughs in large language modeling have facilitated rigorousexploration of their application in diverse tasks related to tabular datamodeling, such as prediction, tabular data synthesis, question answering, andtable understanding. Each task presents unique challenges and opportunities.However, there is currently a lack of comprehensive review that summarizes andcompares the key techniques, metrics, datasets, models, and optimizationapproaches in this research domain. This survey aims to address this gap byconsolidating recent progress in these areas, offering a thorough survey andtaxonomy of the datasets, metrics, and methodologies utilized. It identifiesstrengths, limitations, unexplored territories, and gaps in the existingliterature, while providing some insights for future research directions inthis vital and rapidly evolving field. It also provides relevant code anddatasets references. Through this comprehensive review, we hope to provideinterested readers with pertinent references and insightful perspectives,empowering them with the necessary tools and knowledge to effectively navigateand address the prevailing challenges in the field.</description><author>Xi Fang, Weijie Xu, Fiona Anting Tan, Jiani Zhang, Ziqing Hu, Yanjun Qi, Scott Nickleach, Diego Socolinsky, Srinivasan Sengamedu, Christos Faloutsos</author><pubDate>Mon, 10 Jun 2024 18:41:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17944v3</guid></item><item><title>Improving Alignment and Robustness with Circuit Breakers</title><link>http://arxiv.org/abs/2406.04313v2</link><description>AI systems can take harmful actions and are highly vulnerable to adversarialattacks. We present an approach, inspired by recent advances in representationengineering, that interrupts the models as they respond with harmful outputswith "circuit breakers." Existing techniques aimed at improving alignment, suchas refusal training, are often bypassed. Techniques such as adversarialtraining try to plug these holes by countering specific attacks. As analternative to refusal training and adversarial training, circuit-breakingdirectly controls the representations that are responsible for harmful outputsin the first place. Our technique can be applied to both text-only andmultimodal language models to prevent the generation of harmful outputs withoutsacrificing utility -- even in the presence of powerful unseen attacks.Notably, while adversarial robustness in standalone image recognition remainsan open challenge, circuit breakers allow the larger multimodal system toreliably withstand image "hijacks" that aim to produce harmful content.Finally, we extend our approach to AI agents, demonstrating considerablereductions in the rate of harmful actions when they are under attack. Ourapproach represents a significant step forward in the development of reliablesafeguards to harmful behavior and adversarial attacks.</description><author>Andy Zou, Long Phan, Justin Wang, Derek Duenas, Maxwell Lin, Maksym Andriushchenko, Rowan Wang, Zico Kolter, Matt Fredrikson, Dan Hendrycks</author><pubDate>Mon, 10 Jun 2024 18:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04313v2</guid></item><item><title>BloomVQA: Assessing Hierarchical Multi-modal Comprehension</title><link>http://arxiv.org/abs/2312.12716v3</link><description>We propose a novel VQA dataset, BloomVQA, to facilitate comprehensiveevaluation of large vision-language models on comprehension tasks. Unlikecurrent benchmarks that often focus on fact-based memorization and simplereasoning tasks without theoretical grounding, we collect multiple-choicesamples based on picture stories that reflect different levels ofcomprehension, as laid out in Bloom's Taxonomy, a classic framework forlearning assessment widely adopted in education research. Our data maps to anovel hierarchical graph representation which enables automatic dataaugmentation and novel measures characterizing model consistency. We performgraded evaluation and reliability analysis on recent multi-modal models. Incomparison to low-level tasks, we observe decreased performance on tasksrequiring advanced comprehension and cognitive skills with up to 38.0\% drop inVQA accuracy. In comparison to earlier models, GPT-4V demonstrates improvedaccuracy over all comprehension levels and shows a tendency of bypassing visualinputs especially for higher-level tasks. Current models also show consistencypatterns misaligned with human comprehension in various scenarios,demonstrating the need for improvement based on theoretically-groundedcriteria.</description><author>Yunye Gong, Robik Shrestha, Jared Claypoole, Michael Cogswell, Arijit Ray, Christopher Kanan, Ajay Divakaran</author><pubDate>Mon, 10 Jun 2024 18:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12716v3</guid></item><item><title>An unsupervised approach towards promptable defect segmentation in laser-based additive manufacturing by Segment Anything</title><link>http://arxiv.org/abs/2312.04063v2</link><description>Foundation models are currently driving a paradigm shift in computer visiontasks for various fields including biology, astronomy, and robotics amongothers, leveraging user-generated prompts to enhance their performance. In themanufacturing domain, accurate image-based defect segmentation is imperative toensure product quality and facilitate real-time process control. However, suchtasks are often characterized by multiple challenges including the absence oflabels and the requirement for low latency inference among others. To addressthese issues, we construct a framework for image segmentation using astate-of-the-art Vision Transformer (ViT) based Foundation model (SegmentAnything Model) with a novel multi-point prompt generation scheme usingunsupervised clustering. Utilizing our framework we perform porositysegmentation in a case study of laser-based powder bed fusion (L-PBF) andobtain high accuracy without using any labeled data to guide the prompt tuningprocess. By capitalizing on lightweight foundation model inference combinedwith unsupervised prompt generation, we envision constructing a real-timeanomaly detection pipeline that could revolutionize current laser additivemanufacturing processes, thereby facilitating the shift towards Industry 4.0and promoting defect-free production along with operational efficiency.</description><author>Israt Zarin Era, Imtiaz Ahmed, Zhichao Liu, Srinjoy Das</author><pubDate>Mon, 10 Jun 2024 18:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04063v2</guid></item><item><title>Adaptive Opponent Policy Detection in Multi-Agent MDPs: Real-Time Strategy Switch Identification Using Running Error Estimation</title><link>http://arxiv.org/abs/2406.06500v1</link><description>In Multi-agent Reinforcement Learning (MARL), accurately perceivingopponents' strategies is essential for both cooperative and adversarialcontexts, particularly within dynamic environments. While Proximal PolicyOptimization (PPO) and related algorithms such as Actor-Critic with ExperienceReplay (ACER), Trust Region Policy Optimization (TRPO), and Deep DeterministicPolicy Gradient (DDPG) perform well in single-agent, stationary environments,they suffer from high variance in MARL due to non-stationary and hiddenpolicies of opponents, leading to diminished reward performance. Additionally,existing methods in MARL face significant challenges, including the need forinter-agent communication, reliance on explicit reward information, highcomputational demands, and sampling inefficiencies. These issues render themless effective in continuous environments where opponents may abruptly changetheir policies without prior notice. Against this background, we presentOPS-DeMo (Online Policy Switch-Detection Model), an online algorithm thatemploys dynamic error decay to detect changes in opponents' policies. OPS-DeMocontinuously updates its beliefs using an Assumed Opponent Policy (AOP) Bankand selects corresponding responses from a pre-trained Response Policy Bank.Each response policy is trained against consistently strategizing opponents,reducing training uncertainty and enabling the effective use of algorithms likePPO in multi-agent environments. Comparative assessments show that our approachoutperforms PPO-trained models in dynamic scenarios like the Predator-Preysetting, providing greater robustness to sudden policy shifts and enabling moreinformed decision-making through precise opponent policy insights.</description><author>Mohidul Haque Mridul, Mohammad Foysal Khan, Redwan Ahmed Rizvee, Md Mosaddek Khan</author><pubDate>Mon, 10 Jun 2024 18:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06500v1</guid></item><item><title>NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative</title><link>http://arxiv.org/abs/2406.06499v1</link><description>Existing video captioning benchmarks and models lack coherent representationsof causal-temporal narrative, which is sequences of events linked through causeand effect, unfolding over time and driven by characters or agents. This lackof narrative restricts models' ability to generate text descriptions thatcapture the causal and temporal dynamics inherent in video content. To addressthis gap, we propose NarrativeBridge, an approach comprising of: (1) a novelCausal-Temporal Narrative (CTN) captions benchmark generated using a largelanguage model and few-shot prompting, explicitly encoding cause-effecttemporal relationships in video descriptions, evaluated automatically to ensurecaption quality and relevance; and (2) a dedicated Cause-Effect Network (CEN)architecture with separate encoders for capturing cause and effect dynamicsindependently, enabling effective learning and generation of captions withcausal-temporal narrative. Extensive experiments demonstrate that CEN is moreaccurate in articulating the causal and temporal aspects of video content thanthe second best model (GIT): 17.88 and 17.44 CIDEr on the MSVD and MSR-VTTdatasets, respectively. The proposed framework understands and generatesnuanced text descriptions with intricate causal-temporal narrative structurespresent in videos, addressing a critical limitation in video captioning. Forproject details, visit https://narrativebridge.github.io/.</description><author>Asmar Nadeem, Faegheh Sardari, Robert Dawes, Syed Sameed Husain, Adrian Hilton, Armin Mustafa</author><pubDate>Mon, 10 Jun 2024 18:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06499v1</guid></item><item><title>Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation</title><link>http://arxiv.org/abs/2406.06496v1</link><description>Recent advances in generative vision-language models (VLMs) have excitingpotential implications for AI in radiology, yet VLMs are also known to producehallucinations, nonsensical text, and other unwanted behaviors that can wasteclinicians' time and cause patient harm. Drawing on recent work on directpreference optimization (DPO), we propose a simple method for modifying thebehavior of pretrained VLMs performing radiology report generation bysuppressing unwanted types of generations. We apply our method to theprevention of hallucinations of prior exams, addressing a long-establishedproblem behavior in models performing chest X-ray report generation. Across ourexperiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction inlines hallucinating prior exams while maintaining model performance on clinicalaccuracy metrics. Our work is, to the best of our knowledge, the first work toapply DPO to medical VLMs, providing a data- and compute- efficient way tosuppress problem behaviors while maintaining overall clinical accuracy.</description><author>Oishi Banerjee, Hong-Yu Zhou, Subathra Adithan, Stephen Kwak, Kay Wu, Pranav Rajpurkar</author><pubDate>Mon, 10 Jun 2024 18:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06496v1</guid></item><item><title>Boosting Robustness in Preference-Based Reinforcement Learning with Dynamic Sparsity</title><link>http://arxiv.org/abs/2406.06495v1</link><description>For autonomous agents to successfully integrate into human-centeredenvironments, agents should be able to learn from and adapt to humans in theirnative settings. Preference-based reinforcement learning (PbRL) is a promisingapproach that learns reward functions from human preferences. This enables RLagents to adapt their behavior based on human desires. However, humans live ina world full of diverse information, most of which is not relevant tocompleting a particular task. It becomes essential that agents learn to focuson the subset of task-relevant environment features. Unfortunately, prior workhas largely ignored this aspect; primarily focusing on improving PbRLalgorithms in standard RL environments that are carefully constructed tocontain only task-relevant features. This can result in algorithms that may noteffectively transfer to a more noisy real-world setting. To that end, this workproposes R2N (Robust-to-Noise), the first PbRL algorithm that leveragesprinciples of dynamic sparse training to learn robust reward models that canfocus on task-relevant features. We study the effectiveness of R2N in theExtremely Noisy Environment setting, an RL problem setting where up to 95% ofthe state features are irrelevant distractions. In experiments with a simulatedteacher, we demonstrate that R2N can adapt the sparse connectivity of itsneural networks to focus on task-relevant features, enabling R2N tosignificantly outperform several state-of-the-art PbRL algorithms in multiplelocomotion and control environments.</description><author>Calarina Muslimani, Bram Grooten, Deepak Ranganatha Sastry Mamillapalli, Mykola Pechenizkiy, Decebal Constantin Mocanu, Matthew E. Taylor</author><pubDate>Mon, 10 Jun 2024 18:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06495v1</guid></item><item><title>AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents</title><link>http://arxiv.org/abs/2405.14573v2</link><description>Autonomous agents that execute human tasks by controlling computers canenhance human productivity and application accessibility. However, progress inthis field will be driven by realistic and reproducible benchmarks. We presentAndroidWorld, a fully functional Android environment that provides rewardsignals for 116 programmatic tasks across 20 real-world Android apps. Unlikeexisting interactive environments, which provide a static test set,AndroidWorld dynamically constructs tasks that are parameterized and expressedin natural language in unlimited ways, thus enabling testing on a much largerand more realistic suite of tasks. Reward signals are derived from thecomputer's system state, making them durable across task variations andextensible across different apps. To demonstrate AndroidWorld's benefits andmode of operation, we introduce a new computer control agent, M3A. M3A cancomplete 30.6% of the AndroidWorld's tasks, leaving ample room for future work.Furthermore, we adapt a popular desktop web agent to work on Android, which wefind to be less effective on mobile, suggesting future research is needed toachieve universal, cross-domain agents. Finally, we conduct a robustnessanalysis by testing M3A against a range of task variations on a representativesubset of tasks, demonstrating that variations in task parameters cansignificantly alter a task's complexity and, consequently, an agent'sperformance, highlighting the importance of testing agents under diverseconditions. AndroidWorld and the experiments in this paper are available athttps://github.com/google-research/android_world.</description><author>Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva</author><pubDate>Mon, 10 Jun 2024 18:30:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14573v2</guid></item><item><title>Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits</title><link>http://arxiv.org/abs/2406.06494v1</link><description>Probabilistic integral circuits (PICs) have been recently introduced asprobabilistic models enjoying the key ingredient behind expressive generativemodels: continuous latent variables (LVs). PICs are symbolic computationalgraphs defining continuous LV models as hierarchies of functions that aresummed and multiplied together, or integrated over some LVs. They are tractableif LVs can be analytically integrated out, otherwise they can be approximatedby tractable probabilistic circuits (PC) encoding a hierarchical numericalquadrature process, called QPCs. So far, only tree-shaped PICs have been explored, and training them vianumerical quadrature requires memory-intensive processing at scale. In thispaper, we address these issues, and present: (i) a pipeline for buildingDAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure fortraining PICs using tensorized circuit architectures, and (iii) neuralfunctional sharing techniques to allow scalable training. In extensiveexperiments, we showcase the effectiveness of functional sharing and thesuperiority of QPCs over traditional PCs.</description><author>Gennaro Gala, Cassio de Campos, Antonio Vergari, Erik Quaeghebeur</author><pubDate>Mon, 10 Jun 2024 18:30:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06494v1</guid></item><item><title>When is Multicalibration Post-Processing Necessary?</title><link>http://arxiv.org/abs/2406.06487v1</link><description>Calibration is a well-studied property of predictors which guaranteesmeaningful uncertainty estimates. Multicalibration is a related notion --originating in algorithmic fairness -- which requires predictors to besimultaneously calibrated over a potentially complex and overlapping collectionof protected subpopulations (such as groups defined by ethnicity, race, orincome). We conduct the first comprehensive study evaluating the usefulness ofmulticalibration post-processing across a broad set of tabular, image, andlanguage datasets for models spanning from simple decision trees to 90 millionparameter fine-tuned LLMs. Our findings can be summarized as follows: (1)models which are calibrated out of the box tend to be relativelymulticalibrated without any additional post-processing; (2) multicalibrationpost-processing can help inherently uncalibrated models; and (3) traditionalcalibration measures may sometimes provide multicalibration implicitly. Moregenerally, we also distill many independent observations which may be usefulfor practical and effective applications of multicalibration post-processing inreal-world contexts.</description><author>Dutch Hansen, Siddartha Devic, Preetum Nakkiran, Vatsal Sharan</author><pubDate>Mon, 10 Jun 2024 18:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06487v1</guid></item><item><title>Continuum Attention for Neural Operators</title><link>http://arxiv.org/abs/2406.06486v1</link><description>Transformers, and the attention mechanism in particular, have becomeubiquitous in machine learning. Their success in modeling nonlocal, long-rangecorrelations has led to their widespread adoption in natural languageprocessing, computer vision, and time-series problems. Neural operators, whichmap spaces of functions into spaces of functions, are necessarily bothnonlinear and nonlocal if they are universal; it is thus natural to ask whetherthe attention mechanism can be used in the design of neural operators.Motivated by this, we study transformers in the function space setting. Weformulate attention as a map between infinite dimensional function spaces andprove that the attention mechanism as implemented in practice is a Monte Carloor finite difference approximation of this operator. The function spaceformulation allows for the design of transformer neural operators, a class ofarchitectures designed to learn mappings between function spaces, for which weprove a universal approximation result. The prohibitive cost of applying theattention operator to functions defined on multi-dimensional domains leads tothe need for more efficient attention-based architectures. For this reason wealso introduce a function space generalization of the patching strategy fromcomputer vision, and introduce a class of associated neural operators.Numerical results, on an array of operator learning problems, demonstrate thepromise of our approaches to function space formulations of attention and theiruse in neural operators.</description><author>Edoardo Calvello, Nikola B. Kovachki, Matthew E. Levine, Andrew M. Stuart</author><pubDate>Mon, 10 Jun 2024 18:25:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06486v1</guid></item><item><title>Can Language Models Serve as Text-Based World Simulators?</title><link>http://arxiv.org/abs/2406.06485v1</link><description>Virtual environments play a key role in benchmarking advances in complexplanning and decision-making tasks but are expensive and complicated to buildby hand. Can current language models themselves serve as world simulators,correctly predicting how actions change different world states, thus bypassingthe need for extensive manual coding? Our goal is to answer this question inthe context of text-based simulators. Our approach is to build and use a newbenchmark, called ByteSized32-State-Prediction, containing a dataset of textgame state transitions and accompanying game tasks. We use this to directlyquantify, for the first time, how well LLMs can serve as text-based worldsimulators. We test GPT-4 on this dataset and find that, despite its impressiveperformance, it is still an unreliable world simulator without furtherinnovations. This work thus contributes both new insights into current LLM'scapabilities and weaknesses, as well as a novel benchmark to track futureprogress as new models appear.</description><author>Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, Marc-Alexandre Ct, Peter Clark, Peter Jansen</author><pubDate>Mon, 10 Jun 2024 18:24:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06485v1</guid></item><item><title>Parallelizing Linear Transformers with the Delta Rule over Sequence Length</title><link>http://arxiv.org/abs/2406.06484v1</link><description>Transformers with linear attention (i.e., linear transformers) andstate-space models have recently been suggested as a viable linear-timealternative to transformers with softmax attention. However, these models stillunderperform transformers especially on tasks that require in-contextretrieval. While more expressive variants of linear transformers which replacethe additive outer-product update in linear transformers with the delta rulehave been found to be more effective at associative recall, existing algorithmsfor training such models do not parallelize over sequence length and are thusinefficient to train on modern hardware. This work describes ahardware-efficient algorithm for training linear transformers with the deltarule, which exploits a memory-efficient representation for computing productsof Householder matrices. This algorithm allows us to scale up DeltaNet tostandard language modeling settings. We train a 1.3B model for 100B tokens andfind that it outperforms recent linear-time baselines such as Mamba and GLA interms of perplexity and zero-shot performance on downstream tasks (including ontasks that focus on recall). We also experiment with two hybrid models whichcombine DeltaNet layers with (1) sliding-window attention layers every otherlayer or (2) two global attention layers, and find that these hybrid modelsoutperform strong transformer baselines.</description><author>Songlin Yang, Bailin Wang, Yu Zhang, Yikang Shen, Yoon Kim</author><pubDate>Mon, 10 Jun 2024 18:24:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06484v1</guid></item><item><title>GenHeld: Generating and Editing Handheld Objects</title><link>http://arxiv.org/abs/2406.05059v2</link><description>Grasping is an important human activity that has long been studied inrobotics, computer vision, and cognitive science. Most existing works studygrasping from the perspective of synthesizing hand poses conditioned on 3D or2D object representations. We propose GenHeld to address the inverse problem ofsynthesizing held objects conditioned on 3D hand model or 2D image. Given a 3Dmodel of hand, GenHeld 3D can select a plausible held object from a largedataset using compact object representations called object codes.The selectedobject is then positioned and oriented to form a plausible grasp withoutchanging hand pose. If only a 2D hand image is available, GenHeld 2D can editthis image to add or replace a held object. GenHeld 2D operates by combiningthe abilities of GenHeld 3D with diffusion-based image editing. Results andexperiments show that we outperform baselines and can generate plausible heldobjects in both 2D and 3D. Our experiments demonstrate that our method achieveshigh quality and plausibility of held object synthesis in both 3D and 2D.</description><author>Chaerin Min, Srinath Sridhar</author><pubDate>Mon, 10 Jun 2024 18:23:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05059v2</guid></item><item><title>EchoMamba4Rec: Harmonizing Bidirectional State Space Models with Spectral Filtering for Advanced Sequential Recommendation</title><link>http://arxiv.org/abs/2406.02638v2</link><description>Predicting user preferences and sequential dependencies based on historicalbehavior is the core goal of sequential recommendation. Althoughattention-based models have shown effectiveness in this field, they oftenstruggle with inference inefficiency due to the quadratic computationalcomplexity inherent in attention mechanisms, especially with long-rangebehavior sequences. Drawing inspiration from the recent advancements of statespace models (SSMs) in control theory, which provide a robust framework formodeling and controlling dynamic systems, we introduce EchoMamba4Rec. Controltheory emphasizes the use of SSMs for managing long-range dependencies andmaintaining inferential efficiency through structured state matrices.EchoMamba4Rec leverages these control relationships in sequentialrecommendation and integrates bi-directional processing with frequency-domainfiltering to capture complex patterns and dependencies in user interaction datamore effectively. Our model benefits from the ability of state space models(SSMs) to learn and perform parallel computations, significantly enhancingcomputational efficiency and scalability. It features a bi-directional Mambamodule that incorporates both forward and reverse Mamba components, leveraginginformation from both past and future interactions. Additionally, a filterlayer operates in the frequency domain using learnable Fast Fourier Transform(FFT) and learnable filters, followed by an inverse FFT to refine itemembeddings and reduce noise. We also integrate Gate Linear Units (GLU) todynamically control information flow, enhancing the model's expressiveness andtraining stability. Experimental results demonstrate that EchoMambasignificantly outperforms existing models, providing more accurate andpersonalized recommendations.</description><author>Yuda Wang, Xuxin He, Shengxin Zhu</author><pubDate>Mon, 10 Jun 2024 18:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02638v2</guid></item><item><title>Quantum Equilibrium Propagation for efficient training of quantum systems based on Onsager reciprocity</title><link>http://arxiv.org/abs/2406.06482v1</link><description>The widespread adoption of machine learning and artificial intelligence inall branches of science and technology has created a need for energy-efficient,alternative hardware platforms. While such neuromorphic approaches have beenproposed and realised for a wide range of platforms, physically extracting thegradients required for training remains challenging as generic approaches onlyexist in certain cases. Equilibrium propagation (EP) is such a procedure thathas been introduced and applied to classical energy-based models which relax toan equilibrium. Here, we show a direct connection between EP and Onsagerreciprocity and exploit this to derive a quantum version of EP. This can beused to optimize loss functions that depend on the expectation values ofobservables of an arbitrary quantum system. Specifically, we illustrate thisnew concept with supervised and unsupervised learning examples in which theinput or the solvable task is of quantum mechanical nature, e.g., therecognition of quantum many-body ground states, quantum phase exploration,sensing and phase boundary exploration. We propose that in the future quantumEP may be used to solve tasks such as quantum phase discovery with a quantumsimulator even for Hamiltonians which are numerically hard to simulate or evenpartially unknown. Our scheme is relevant for a variety of quantum simulationplatforms such as ion chains, superconducting qubit arrays, neutral atomRydberg tweezer arrays and strongly interacting atoms in optical lattices.</description><author>Clara C. Wanjura, Florian Marquardt</author><pubDate>Mon, 10 Jun 2024 18:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06482v1</guid></item><item><title>Physics-informed deep learning and compressive collocation for high-dimensional diffusion-reaction equations: practical existence theory and numerics</title><link>http://arxiv.org/abs/2406.01539v2</link><description>On the forefront of scientific computing, Deep Learning (DL), i.e., machinelearning with Deep Neural Networks (DNNs), has emerged a powerful new tool forsolving Partial Differential Equations (PDEs). It has been observed that DNNsare particularly well suited to weakening the effect of the curse ofdimensionality, a term coined by Richard E. Bellman in the late `50s todescribe challenges such as the exponential dependence of the samplecomplexity, i.e., the number of samples required to solve an approximationproblem, on the dimension of the ambient space. However, although DNNs havebeen used to solve PDEs since the `90s, the literature underpinning theirmathematical efficiency in terms of numerical analysis (i.e., stability,accuracy, and sample complexity), is only recently beginning to emerge. In thispaper, we leverage recent advancements in function approximation usingsparsity-based techniques and random sampling to develop and analyze anefficient high-dimensional PDE solver based on DL. We show, both theoreticallyand numerically, that it can compete with a novel stable and accuratecompressive spectral collocation method. In particular, we demonstrate a newpractical existence theorem, which establishes the existence of a class oftrainable DNNs with suitable bounds on the network architecture and asufficient condition on the sample complexity, with logarithmic or, at worst,linear scaling in dimension, such that the resulting networks stably andaccurately approximate a diffusion-reaction PDE with high probability.</description><author>Simone Brugiapaglia, Nick Dexter, Samir Karam, Weiqi Wang</author><pubDate>Mon, 10 Jun 2024 18:22:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01539v2</guid></item><item><title>Graph-Based Bidirectional Transformer Decision Threshold Adjustment Algorithm for Class-Imbalanced Molecular Data</title><link>http://arxiv.org/abs/2406.06479v1</link><description>Data sets with imbalanced class sizes, often where one class size is muchsmaller than that of others, occur extremely often in various applications,including those with biological foundations, such as drug discovery and diseasediagnosis. Thus, it is extremely important to be able to identify data elementsof classes of various sizes, as a failure to detect can result in heavy costs.However, many data classification algorithms do not perform well on imbalanceddata sets as they often fail to detect elements belonging to underrepresentedclasses. In this paper, we propose the BTDT-MBO algorithm, incorporatingMerriman-Bence-Osher (MBO) techniques and a bidirectional transformer, as wellas distance correlation and decision threshold adjustments, for dataclassification problems on highly imbalanced molecular data sets, where thesizes of the classes vary greatly. The proposed method not only integratesadjustments in the classification threshold for the MBO algorithm in order tohelp deal with the class imbalance, but also uses a bidirectional transformermodel based on an attention mechanism for self-supervised learning.Additionally, the method implements distance correlation as a weight functionfor the similarity graph-based framework on which the adjusted MBO algorithmoperates. The proposed model is validated using six molecular data sets, and wealso provide a thorough comparison to other competing algorithms. Thecomputational experiments show that the proposed method performs better thancompeting techniques even when the class imbalance ratio is very high.</description><author>Nicole Hayes, Ekaterina Merkurjev, Guo-Wei Wei</author><pubDate>Mon, 10 Jun 2024 18:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06479v1</guid></item><item><title>Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality</title><link>http://arxiv.org/abs/2402.19442v2</link><description>We study the dynamics of gradient flow for training a multi-head softmaxattention model for in-context learning of multi-task linear regression. Weestablish the global convergence of gradient flow under suitable choices ofinitialization. In addition, we prove that an interesting "task allocation"phenomenon emerges during the gradient flow dynamics, where each attention headfocuses on solving a single task of the multi-task model. Specifically, weprove that the gradient flow dynamics can be split into three phases -- awarm-up phase where the loss decreases rather slowly and the attention headsgradually build up their inclination towards individual tasks, an emergencephase where each head selects a single task and the loss rapidly decreases, anda convergence phase where the attention parameters converge to a limit.Furthermore, we prove the optimality of gradient flow in the sense that thelimiting model learned by gradient flow is on par with the best possiblemulti-head softmax attention model up to a constant factor. Our analysis alsodelineates a strict separation in terms of the prediction accuracy of ICLbetween single-head and multi-head attention models. The key technique for ourconvergence analysis is to map the gradient flow dynamics in the parameterspace to a set of ordinary differential equations in the spectral domain, wherethe relative magnitudes of the semi-singular values of the attention weightsdetermines task allocation. To our best knowledge, our work provides the firstconvergence result for the multi-head softmax attention model.</description><author>Siyu Chen, Heejune Sheen, Tianhao Wang, Zhuoran Yang</author><pubDate>Mon, 10 Jun 2024 18:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19442v2</guid></item><item><title>Survey for Landing Generative AI in Social and E-commerce Recsys -- the Industry Perspectives</title><link>http://arxiv.org/abs/2406.06475v1</link><description>Recently, generative AI (GAI), with their emerging capabilities, havepresented unique opportunities for augmenting and revolutionizing industrialrecommender systems (Recsys). Despite growing research efforts at theintersection of these fields, the integration of GAI into industrial Recsysremains in its infancy, largely due to the intricate nature of modernindustrial Recsys infrastructure, operations, and product sophistication.Drawing upon our experiences in successfully integrating GAI into several majorsocial and e-commerce platforms, this survey aims to comprehensively examinethe underlying system and AI foundations, solution frameworks, connections tokey research advancements, as well as summarize the practical insights andchallenges encountered in the endeavor to integrate GAI into industrial Recsys.As pioneering work in this domain, we hope outline the representativedevelopments of relevant fields, shed lights on practical GAI adoptions in theindustry, and motivate future research.</description><author>Da Xu, Danqing Zhang, Guangyu Yang, Bo Yang, Shuyuan Xu, Lingling Zheng, Cindy Liang</author><pubDate>Mon, 10 Jun 2024 18:16:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06475v1</guid></item><item><title>Towards a Personal Health Large Language Model</title><link>http://arxiv.org/abs/2406.06474v1</link><description>In health, most large language model (LLM) research has focused on clinicaltasks. However, mobile and wearable devices, which are rarely integrated intosuch tasks, provide rich, longitudinal data for personal health monitoring.Here we present Personal Health Large Language Model (PH-LLM), fine-tuned fromGemini for understanding and reasoning over numerical time-series personalhealth data. We created and curated three datasets that test 1) production ofpersonalized insights and recommendations from sleep patterns, physicalactivity, and physiological responses, 2) expert domain knowledge, and 3)prediction of self-reported sleep outcomes. For the first task we designed 857case studies in collaboration with domain experts to assess real-worldscenarios in sleep and fitness. Through comprehensive evaluation ofdomain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are notstatistically different from expert performance in fitness and, while expertsremain superior for sleep, fine-tuning PH-LLM provided significant improvementsin using relevant domain knowledge and personalizing information for sleepinsights. We evaluated PH-LLM domain knowledge using multiple choice sleepmedicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% onfitness, exceeding average scores from a sample of human experts. Finally, wetrained PH-LLM to predict self-reported sleep quality outcomes from textual andmultimodal encoding representations of wearable data, and demonstrate thatmultimodal encoding is required to match performance of specializeddiscriminative models. Although further development and evaluation arenecessary in the safety-critical personal health domain, these resultsdemonstrate both the broad knowledge and capabilities of Gemini models and thebenefit of contextualizing physiological data for personal health applicationsas done with PH-LLM.</description><author>Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean</author><pubDate>Mon, 10 Jun 2024 18:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06474v1</guid></item><item><title>Evolving Assembly Code in an Adversarial Environment</title><link>http://arxiv.org/abs/2403.19489v2</link><description>In this work, we evolve Assembly code for the CodeGuru competition. The goalis to create a survivor -- an Assembly program that runs the longest in sharedmemory, by resisting attacks from adversary survivors and finding theirweaknesses. For evolving top-notch solvers, we specify a Backus Normal Form(BNF) for the Assembly language and synthesize the code from scratch usingGenetic Programming (GP). We evaluate the survivors by running CodeGuru gamesagainst human-written winning survivors. Our evolved programs found weaknessesin the programs they were trained against and utilized them. To push evolutionfurther, we implemented memetic operators that utilize machine learning toexplore the solution space effectively. This work has important applicationsfor cyber-security as we utilize evolution to detect weaknesses in survivors.The Assembly BNF is domain-independent; thus, by modifying the fitnessfunction, it can detect code weaknesses and help fix them. Finally, theCodeGuru competition offers a novel platform for analyzing GP and codeevolution in adversarial environments. To support further research in thisdirection, we provide a thorough qualitative analysis of the evolved survivorsand the weaknesses found.</description><author>Irina Maliukov, Gera Weiss, Oded Margalit, Achiya Elyasaf</author><pubDate>Mon, 10 Jun 2024 18:16:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19489v2</guid></item><item><title>GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations</title><link>http://arxiv.org/abs/2402.12348v2</link><description>As Large Language Models (LLMs) are integrated into critical real-worldapplications, their strategic and logical reasoning abilities are increasinglycrucial. This paper evaluates LLMs' reasoning abilities in competitiveenvironments through game-theoretic tasks, e.g., board and card games thatrequire pure logic and strategic reasoning to compete with opponents. We firstpropose GTBench, a language-driven environment composing 10 widely recognizedtasks, across a comprehensive game taxonomy: complete versus incompleteinformation, dynamic versus static, and probabilistic versus deterministicscenarios. Then, we (1) Characterize the game-theoretic reasoning of LLMs; and(2) Perform LLM-vs.-LLM competitions as reasoning evaluation. We observe that(1) LLMs have distinct behaviors regarding various gaming scenarios; forexample, LLMs fail in complete and deterministic games yet they are competitivein probabilistic gaming scenarios; (2) Most open-source LLMs, e.g.,CodeLlama-34b-Instruct and Llama-2-70b-chat, are less competitive thancommercial LLMs, e.g., GPT-4, in complex games, yet the recently releasedLlama-3-70b-Instruct makes up for this shortcoming. In addition,code-pretraining greatly benefits strategic reasoning, while advanced reasoningmethods such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) do not alwayshelp. We further characterize the game-theoretic properties of LLMs, such asequilibrium and Pareto Efficiency in repeated games. Detailed error profilesare provided for a better understanding of LLMs' behavior. We hope our researchprovides standardized protocols and serves as a foundation to spur furtherexplorations in the strategic reasoning of LLMs.</description><author>Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, Kaidi Xu</author><pubDate>Mon, 10 Jun 2024 18:14:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12348v2</guid></item><item><title>The fast committor machine: Interpretable prediction with kernels</title><link>http://arxiv.org/abs/2405.10410v2</link><description>In the study of stochastic systems, the committor function describes theprobability that a system starting from an initial configuration $x$ will reacha set $B$ before a set $A$. This paper introduces an efficient andinterpretable algorithm for approximating the committor, called the "fastcommittor machine" (FCM). The FCM uses simulated trajectory data to build akernel-based model of the committor. The kernel function is constructed toemphasize low-dimensional subspaces which optimally describe the $A$ to $B$transitions. The coefficients in the kernel model are determined usingrandomized linear algebra, leading to a runtime that scales linearly in thenumber of data points. In numerical experiments involving a triple-wellpotential and alanine dipeptide, the FCM yields higher accuracy and trains morequickly than a neural network with the same number of parameters. The FCM isalso more interpretable than the neural net.</description><author>D. Aristoff, M. Johnson, G. Simpson, R. J. Webber</author><pubDate>Mon, 10 Jun 2024 18:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10410v2</guid></item><item><title>GKAN: Graph Kolmogorov-Arnold Networks</title><link>http://arxiv.org/abs/2406.06470v1</link><description>We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neuralnetwork architecture that extends the principles of the recently proposedKolmogorov-Arnold Networks (KAN) to graph-structured data. By adopting theunique characteristics of KANs, notably the use of learnable univariatefunctions instead of fixed linear weights, we develop a powerful model forgraph-based learning tasks. Unlike traditional Graph Convolutional Networks(GCNs) that rely on a fixed convolutional architecture, GKANs implementlearnable spline-based functions between layers, transforming the wayinformation is processed across the graph structure. We present two differentways to incorporate KAN layers into GKAN: architecture 1 -- where the learnablefunctions are applied to input features after aggregation and architecture 2 --where the learnable functions are applied to input features before aggregation.We evaluate GKAN empirically using a semi-supervised graph learning task on areal-world dataset (Cora). We find that architecture generally performs better.We find that GKANs achieve higher accuracy in semi-supervised learning tasks ongraphs compared to the traditional GCN model. For example, when considering 100features, GCN provides an accuracy of 53.5 while a GKAN with a comparablenumber of parameters gives an accuracy of 61.76; with 200 features, GCNprovides an accuracy of 61.24 while a GKAN with a comparable number ofparameters gives an accuracy of 67.66. We also present results on the impact ofvarious parameters such as the number of hidden nodes, grid-size, and thepolynomial-degree of the spline on the performance of GKAN.</description><author>Mehrdad Kiamari, Mohammad Kiamari, Bhaskar Krishnamachari</author><pubDate>Mon, 10 Jun 2024 18:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06470v1</guid></item><item><title>Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning</title><link>http://arxiv.org/abs/2406.06469v1</link><description>Language agents perform complex tasks by using tools to execute each stepprecisely. However, most existing agents are based on proprietary models ordesigned to target specific tasks, such as mathematics or multi-hop questionanswering. We introduce Husky, a holistic, open-source language agent thatlearns to reason over a unified action space to address a diverse set ofcomplex tasks involving numerical, tabular, and knowledge-based reasoning.Husky iterates between two stages: 1) generating the next action to taketowards solving a given task and 2) executing the action using expert modelsand updating the current solution state. We identify a thorough ontology ofactions for addressing complex tasks and curate high-quality data to trainexpert models for executing these actions. Our experiments show that Huskyoutperforms prior language agents across 14 evaluation datasets. Moreover, weintroduce HuskyQA, a new evaluation set which stress tests language agents formixed-tool reasoning, with a focus on retrieving missing knowledge andperforming numerical reasoning. Despite using 7B models, Husky matches or evenexceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy ofour holistic approach in addressing complex reasoning problems. Our code andmodels are available at https://github.com/agent-husky/Husky-v1.</description><author>Joongwon Kim, Bhargavi Paranjape, Tushar Khot, Hannaneh Hajishirzi</author><pubDate>Mon, 10 Jun 2024 18:07:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06469v1</guid></item><item><title>Active Neural 3D Reconstruction with Colorized Surface Voxel-based View Selection</title><link>http://arxiv.org/abs/2405.02568v2</link><description>Active view selection in 3D scene reconstruction has been widely studiedsince training on informative views is critical for reconstruction. Recently,Neural Radiance Fields (NeRF) variants have shown promising results in active3D reconstruction using uncertainty-guided view selection. They utilizeuncertainties estimated with neural networks that encode scene geometry andappearance. However, the choice of uncertainty integration methods, eithervoxel-based or neural rendering, has conventionally depended on the types ofscene uncertainty being estimated, whether geometric or appearance-related. Inthis paper, we introduce Colorized Surface Voxel (CSV)-based view selection, anew next-best view (NBV) selection method exploiting surface voxel-basedmeasurement of uncertainty in scene appearance. CSV encapsulates theuncertainty of estimated scene appearance (e.g., color uncertainty) andestimated geometric information (e.g., surface). Using the geometryinformation, we interpret the uncertainty of scene appearance 3D-wise duringthe aggregation of the per-voxel uncertainty. Consequently, the uncertaintyfrom occluded and complex regions is recognized under challenging scenarioswith limited input data. Our method outperforms previous works on populardatasets, DTU and Blender, and our new dataset with imbalanced viewpoints,showing that the CSV-based view selection significantly improves performance byup to 30%.</description><author>Hyunseo Kim, Hyeonseo Yang, Taekyung Kim, YoonSung Kim, Jin-Hwa Kim, Byoung-Tak Zhang</author><pubDate>Mon, 10 Jun 2024 18:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02568v2</guid></item><item><title>How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad</title><link>http://arxiv.org/abs/2406.06467v1</link><description>Can Transformers predict new syllogisms by composing established ones? Moregenerally, what type of targets can be learned by such models from scratch?Recent works show that Transformers can be Turing-complete in terms ofexpressivity, but this does not address the learnability objective. This paperputs forward the notion of 'distribution locality' to capture when weaklearning is efficiently achievable by regular Transformers, where the localitymeasures the least number of tokens required in addition to the tokenshistogram to correlate nontrivially with the target. As shown experimentallyand theoretically under additional assumptions, distributions with highlocality cannot be learned efficiently. In particular, syllogisms cannot becomposed on long chains. Furthermore, we show that (i) an agnostic scratchpadcannot help to break the locality barrier, (ii) an educated scratchpad can helpif it breaks the locality at each step, (iii) a notion of 'inductivescratchpad' can both break the locality and improve the out-of-distributiongeneralization, e.g., generalizing to almost double input size for somearithmetic tasks.</description><author>Emmanuel Abbe, Samy Bengio, Aryo Lotfi, Colin Sandon, Omid Saremi</author><pubDate>Mon, 10 Jun 2024 18:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06467v1</guid></item><item><title>Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis: A Review</title><link>http://arxiv.org/abs/2404.11597v2</link><description>As the manufacturing industry advances with sensor integration andautomation, the opaque nature of deep learning models in machine learning posesa significant challenge for fault detection and diagnosis. And despite therelated predictive insights Artificial Intelligence (AI) can deliver, advancedmachine learning engines often remain a black box. This paper reviews theeXplainable AI (XAI) tools and techniques in this context. We explore variousXAI methodologies, focusing on their role in making AI decision-makingtransparent, particularly in critical scenarios where humans are involved. Wealso discuss current limitations and potential future research that aims tobalance explainability with model performance while improving trustworthinessin the context of AI applications for critical industrial use cases.</description><author>Ahmed Maged, Salah Haridy, Herman Shen</author><pubDate>Mon, 10 Jun 2024 18:04:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11597v2</guid></item><item><title>AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction</title><link>http://arxiv.org/abs/2406.06465v1</link><description>Text-guided video prediction (TVP) involves predicting the motion of futureframes from the initial frame according to an instruction, which has wideapplications in virtual reality, robotics, and content creation. Previous TVPmethods make significant breakthroughs by adapting Stable Diffusion for thistask. However, they struggle with frame consistency and temporal stabilityprimarily due to the limited scale of video datasets. We observe thatpretrained Image2Video diffusion models possess good priors for video dynamicsbut they lack textual control. Hence, transferring Image2Video models toleverage their video dynamic priors while injecting instruction control togenerate controllable videos is both a meaningful and challenging task. Toachieve this, we introduce the Multi-Modal Large Language Model (MLLM) topredict future video states based on initial frames and text instructions. Morespecifically, we design a dual query transformer (DQFormer) architecture, whichintegrates the instructions and frames into the conditional embeddings forfuture frame prediction. Additionally, we develop Long-Short Term TemporalAdapters and Spatial Adapters that can quickly transfer general video diffusionmodels to specific scenarios with minimal training costs. Experimental resultsshow that our method significantly outperforms state-of-the-art techniques onfour datasets: Something Something V2, Epic Kitchen-100, Bridge Data, andUCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge andSSv2 respectively, demonstrating its effectiveness in various domains. Moreexamples can be found at our website https://chenhsing.github.io/AID.</description><author>Zhen Xing, Qi Dai, Zejia Weng, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Mon, 10 Jun 2024 18:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06465v1</guid></item><item><title>Transforming Wearable Data into Health Insights using Large Language Model Agents</title><link>http://arxiv.org/abs/2406.06464v1</link><description>Despite the proliferation of wearable health trackers and the importance ofsleep and exercise to health, deriving actionable personalized insights fromwearable data remains a challenge because doing so requires non-trivialopen-ended analysis of these data. The recent rise of large language model(LLM) agents, which can use tools to reason about and interact with the world,presents a promising opportunity to enable such personalized analysis at scale.Yet, the application of LLM agents in analyzing personal health is stilllargely untapped. In this paper, we introduce the Personal Health InsightsAgent (PHIA), an agent system that leverages state-of-the-art code generationand information retrieval tools to analyze and interpret behavioral health datafrom wearables. We curate two benchmark question-answering datasets of over4000 health insights questions. Based on 650 hours of human and expertevaluation we find that PHIA can accurately address over 84% of factualnumerical questions and more than 83% of crowd-sourced open-ended questions.This work has implications for advancing behavioral health across thepopulation, potentially enabling individuals to interpret their own wearabledata, and paving the way for a new era of accessible, personalized wellnessregimens that are informed by data-driven insights.</description><author>Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, Kumar Ayush, Hao-Wei Su, Qian He, Cory McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu</author><pubDate>Mon, 10 Jun 2024 18:00:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06464v1</guid></item><item><title>VCR: Visual Caption Restoration</title><link>http://arxiv.org/abs/2406.06462v1</link><description>We introduce Visual Caption Restoration (VCR), a novel vision-language taskthat challenges models to accurately restore partially obscured texts usingpixel-level hints within images. This task stems from the observation that textembedded in images is intrinsically different from common visual elements andnatural language due to the need to align the modalities of vision, text, andtext embedded in images. While numerous works have integrated text embedded inimages into visual question-answering tasks, approaches to these tasksgenerally rely on optical character recognition or masked language modeling,thus reducing the task to mainly text-based processing. However, text-basedprocessing becomes ineffective in VCR as accurate text restoration depends onthe combined information from provided images, context, and subtle cues fromthe tiny exposed areas of masked texts. We develop a pipeline to generatesynthetic images for the VCR task using image-caption pairs, with adjustablecaption visibility to control the task difficulty. With this pipeline, weconstruct a dataset for VCR called VCR-Wiki using images with captions fromWikipedia, comprising 2.11M English and 346K Chinese entities in both easy andhard split variants. Our results reveal that current vision language modelssignificantly lag behind human performance in the VCR task, and merelyfine-tuning the models on our dataset does not lead to notable improvements. Werelease VCR-Wiki and the data construction code to facilitate future research.</description><author>Tianyu Zhang, Suyuchen Wang, Lu Li, Ge Zhang, Perouz Taslakian, Sai Rajeswar, Jie Fu, Bang Liu, Yoshua Bengio</author><pubDate>Mon, 10 Jun 2024 17:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06462v1</guid></item><item><title>Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies</title><link>http://arxiv.org/abs/2406.06461v1</link><description>A diverse array of reasoning strategies has been proposed to elicit thecapabilities of large language models. However, in this paper, we point outthat traditional evaluations which focus solely on performance metrics miss akey factor: the increased effectiveness due to additional compute. Byoverlooking this aspect, a skewed view of strategy efficiency is oftenpresented. This paper introduces a framework that incorporates the computebudget into the evaluation, providing a more informative comparison that takesinto account both performance metrics and computational cost. In thisbudget-aware perspective, we find that complex reasoning strategies often don'tsurpass simpler baselines purely due to algorithmic ingenuity, but rather dueto the larger computational resources allocated. When we provide a simplebaseline like chain-of-thought self-consistency with comparable computeresources, it frequently outperforms reasoning strategies proposed in theliterature. In this scale-aware perspective, we find that unlikeself-consistency, certain strategies such as multi-agent debate or Reflexioncan become worse if more compute budget is utilized.</description><author>Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, Ben Athiwaratkun</author><pubDate>Mon, 10 Jun 2024 17:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06461v1</guid></item><item><title>Towards Real-World Efficiency: Domain Randomization in Reinforcement Learning for Pre-Capture of Free-Floating Moving Targets by Autonomous Robots</title><link>http://arxiv.org/abs/2406.06460v1</link><description>In this research, we introduce a deep reinforcement learning-based controlapproach to address the intricate challenge of the robotic pre-grasping phaseunder microgravity conditions. Leveraging reinforcement learning eliminates thenecessity for manual feature design, therefore simplifying the problem andempowering the robot to learn pre-grasping policies through trial and error.Our methodology incorporates an off-policy reinforcement learning framework,employing the soft actor-critic technique to enable the gripper to proficientlyapproach a free-floating moving object, ensuring optimal pre-grasp success. Foreffective learning of the pre-grasping approach task, we developed a rewardfunction that offers the agent clear and insightful feedback. Our case studyexamines a pre-grasping task where a Robotiq 3F gripper is required to navigatetowards a free-floating moving target, pursue it, and subsequently positionitself at the desired pre-grasp location. We assessed our approach through aseries of experiments in both simulated and real-world environments. The sourcecode, along with recordings of real-world robot grasping, is available atFanuc_Robotiq_Grasp.</description><author>Bahador Beigomi, Zheng H. Zhu</author><pubDate>Mon, 10 Jun 2024 17:54:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06460v1</guid></item><item><title>How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?</title><link>http://arxiv.org/abs/2406.06459v1</link><description>Bayesian optimization (BO) is an integral part of automated scientificdiscovery -- the so-called self-driving lab -- where human inputs are ideallyminimal or at least non-blocking. However, scientists often have strongintuition, and thus human feedback is still useful. Nevertheless, prior worksin enhancing BO with expert feedback, such as by incorporating it in an offlineor online but blocking (arrives at each BO iteration) manner, are incompatiblewith the spirit of self-driving labs. In this work, we study whether a smallamount of randomly arriving expert feedback that is being incorporated in anon-blocking manner can improve a BO campaign. To this end, we run anadditional, independent computing thread on top of the BO loop to handle thefeedback-gathering process. The gathered feedback is used to learn a Bayesianpreference model that can readily be incorporated into the BO thread, to steerits exploration-exploitation process. Experiments on toy and chemistry datasetssuggest that even just a few intermittent, asynchronous expert feedback can beuseful for improving or constraining BO. This can especially be useful for itsimplication in improving self-driving labs, e.g. making them moredata-efficient and less costly.</description><author>Agustinus Kristiadi, Felix Strieth-Kalthoff, Sriram Ganapathi Subramanian, Vincent Fortuin, Pascal Poupart, Geoff Pleiss</author><pubDate>Mon, 10 Jun 2024 17:53:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06459v1</guid></item><item><title>Evaluating the Retrieval Component in LLM-Based Question Answering Systems</title><link>http://arxiv.org/abs/2406.06458v1</link><description>Question answering systems (QA) utilizing Large Language Models (LLMs)heavily depend on the retrieval component to provide them with domain-specificinformation and reduce the risk of generating inaccurate responses orhallucinations. Although the evaluation of retrievers dates back to the earlyresearch in Information Retrieval, assessing their performance within LLM-basedchatbots remains a challenge. This study proposes a straightforward baseline for evaluating retrievers inRetrieval-Augmented Generation (RAG)-based chatbots. Our findings demonstratethat this evaluation framework provides a better image of how the retrieverperforms and is more aligned with the overall performance of the QA system.Although conventional metrics such as precision, recall, and F1 score may notfully capture LLMs' capabilities - as they can yield accurate responses despiteimperfect retrievers - our method considers LLMs' strengths to ignoreirrelevant contexts, as well as potential errors and hallucinations in theirresponses.</description><author>Ashkan Alinejad, Krtin Kumar, Ali Vahdat</author><pubDate>Mon, 10 Jun 2024 17:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06458v1</guid></item><item><title>A Large Language Model Pipeline for Breast Cancer Oncology</title><link>http://arxiv.org/abs/2406.06455v1</link><description>Large language models (LLMs) have demonstrated potential in the innovation ofmany disciplines. However, how they can best be developed for oncology remainsunderdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinicaldataset and clinical guidelines text corpus for two important cancer treatmentfactors, adjuvant radiation therapy and chemotherapy, using a novel Langchainprompt engineering pipeline. A high accuracy (0.85+) was achieved in theclassification of adjuvant radiation therapy and chemotherapy for breast cancerpatients. Furthermore, a confidence interval was formed from observational dataon the quality of treatment from human oncologists to estimate the proportionof scenarios in which the model must outperform the original oncologist in itstreatment prediction to be a better solution overall as 8.2% to 13.3%. Due toindeterminacy in the outcomes of cancer treatment decisions, futureinvestigation, potentially a clinical trial, would be required to determine ifthis threshold was met by the models. Nevertheless, with 85% of U.S. cancerpatients receiving treatment at local community facilities, these kinds ofmodels could play an important part in expanding access to quality care withoutcomes that lie, at minimum, close to a human oncologist.</description><author>Tristen Pool, Dennis Trujillo</author><pubDate>Mon, 10 Jun 2024 17:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06455v1</guid></item><item><title>Estimating Heterogeneous Treatment Effects by Combining Weak Instruments and Observational Data</title><link>http://arxiv.org/abs/2406.06452v1</link><description>Accurately predicting conditional average treatment effects (CATEs) iscrucial in personalized medicine and digital platform analytics. Since oftenthe treatments of interest cannot be directly randomized, observational data isleveraged to learn CATEs, but this approach can incur significant bias fromunobserved confounding. One strategy to overcome these limitations is to seeklatent quasi-experiments in instrumental variables (IVs) for the treatment, forexample, a randomized intent to treat or a randomized product recommendation.This approach, on the other hand, can suffer from low compliance, i.e., IVweakness. Some subgroups may even exhibit zero compliance meaning we cannotinstrument for their CATEs at all. In this paper we develop a novel approach tocombine IV and observational data to enable reliable CATE estimation in thepresence of unobserved confounding in the observational data and low compliancein the IV data, including no compliance for some subgroups. We propose atwo-stage framework that first learns biased CATEs from the observational data,and then applies a compliance-weighted correction using IV data, effectivelyleveraging IV strength variability across covariates. We characterize theconvergence rates of our method and validate its effectiveness through asimulation study. Additionally, we demonstrate its utility with real data byanalyzing the heterogeneous effects of 401(k) plan participation on wealth.</description><author>Miruna Oprescu, Nathan Kallus</author><pubDate>Mon, 10 Jun 2024 17:40:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06452v1</guid></item><item><title>Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course</title><link>http://arxiv.org/abs/2406.06451v1</link><description>The capability of large language models (LLMs) to generate, debug, andexplain code has sparked the interest of researchers and educators inundergraduate programming, with many anticipating their transformativepotential in programming education. However, decisions about why and how to useLLMs in programming education may involve more than just the assessment of anLLM's technical capabilities. Using the social shaping of technology theory asa guiding framework, our study explores how students' social perceptionsinfluence their own LLM usage. We then examine the correlation of self-reportedLLM usage with students' self-efficacy and midterm performances in anundergraduate programming course. Triangulating data from an anonymousend-of-course student survey (n = 158), a mid-course self-efficacy survey(n=158), student interviews (n = 10), self-reported LLM usage on homework, andmidterm performances, we discovered that students' use of LLMs was associatedwith their expectations for their future careers and their perceptions of peerusage. Additionally, early self-reported LLM usage in our context correlatedwith lower self-efficacy and lower midterm scores, while students' perceivedover-reliance on LLMs, rather than their usage itself, correlated withdecreased self-efficacy later in the course.</description><author>Aadarsh Padiyath, Xinying Hou, Amy Pang, Diego Viramontes Vargas, Xingjian Gu, Tamara Nelson-Fromm, Zihan Wu, Mark Guzdial, Barbara Ericson</author><pubDate>Mon, 10 Jun 2024 17:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06451v1</guid></item><item><title>Cometh: A continuous-time discrete-state graph diffusion model</title><link>http://arxiv.org/abs/2406.06449v1</link><description>Discrete-state denoising diffusion models led to state-of-the-art performancein graph generation, especially in the molecular domain. Recently, they havebeen transposed to continuous time, allowing more flexibility in the reverseprocess and a better trade-off between sampling efficiency and quality. Here,to leverage the benefits of both approaches, we propose Cometh, acontinuous-time discrete-state graph diffusion model, integrating graph datainto a continuous-time diffusion model framework. Empirically, we show thatintegrating continuous time leads to significant improvements across variousmetrics over state-of-the-art discrete-state diffusion models on a large set ofmolecular and non-molecular benchmark datasets.</description><author>Antoine Siraudin, Fragkiskos D. Malliaros, Christopher Morris</author><pubDate>Mon, 10 Jun 2024 17:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06449v1</guid></item><item><title>Deep Generative Modeling Reshapes Compression and Transmission: From Efficiency to Resiliency</title><link>http://arxiv.org/abs/2406.06446v1</link><description>Information theory and machine learning are inextricably linked and have evenbeen referred to as "two sides of the same coin". One particularly elegantconnection is the essential equivalence between probabilistic generativemodeling and data compression or transmission. In this article, we reveal thedual-functionality of deep generative models that reshapes both datacompression for efficiency and transmission error concealment for resiliency.We present how the contextual predictive capabilities of powerful generativemodels can be well positioned to be strong compressors and estimators. In thissense, we advocate for viewing the deep generative modeling problem through thelens of end-to-end communications, and evaluate the compression and errorrestoration capabilities of foundation generative models. We show that thekernel of many large generative models is powerful predictor that can capturecomplex relationships among semantic latent variables, and the communicationviewpoints provide novel insights into semantic feature tokenization,contextual learning, and usage of deep generative models. In summary, ourarticle highlights the essential connections of generative AI to source andchannel coding techniques, and motivates researchers to make furtherexplorations in this emerging topic.</description><author>Jincheng Dai, Xiaoqi Qin, Sixian Wang, Lexi Xu, Kai Niu, Ping Zhang</author><pubDate>Mon, 10 Jun 2024 17:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06446v1</guid></item><item><title>LLM Dataset Inference: Did you train on my dataset?</title><link>http://arxiv.org/abs/2406.06443v1</link><description>The proliferation of large language models (LLMs) in the real world has comewith a rise in copyright cases against companies for training their models onunlicensed data from the internet. Recent works have presented methods toidentify if individual text sequences were members of the model's trainingdata, known as membership inference attacks (MIAs). We demonstrate that theapparent success of these MIAs is confounded by selecting non-members (textsequences not used for training) belonging to a different distribution from themembers (e.g., temporally shifted recent Wikipedia articles compared with onesused to train the model). This distribution shift makes membership inferenceappear successful. However, most MIA methods perform no better than randomguessing when discriminating between members and non-members from the samedistribution (e.g., in this case, the same period of time). Even when MIAswork, we find that different MIAs succeed at inferring membership of samplesfrom different distributions. Instead, we propose a new dataset inferencemethod to accurately identify the datasets used to train large language models.This paradigm sits realistically in the modern-day copyright landscape, whereauthors claim that an LLM is trained over multiple documents (such as a book)written by them, rather than one particular paragraph. While dataset inferenceshares many of the challenges of membership inference, we solve it byselectively combining the MIAs that provide positive signal for a givendistribution, and aggregating them to perform a statistical test on a givendataset. Our approach successfully distinguishes the train and test sets ofdifferent subsets of the Pile with statistically significant p-values &lt; 0.1,without any false positives.</description><author>Pratyush Maini, Hengrui Jia, Nicolas Papernot, Adam Dziedzic</author><pubDate>Mon, 10 Jun 2024 17:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06443v1</guid></item><item><title>Interpretability of Language Models via Task Spaces</title><link>http://arxiv.org/abs/2406.06441v1</link><description>The usual way to interpret language models (LMs) is to test their performanceon different benchmarks and subsequently infer their internal processes. Inthis paper, we present an alternative approach, concentrating on the quality ofLM processing, with a focus on their language abilities. To this end, weconstruct 'linguistic task spaces' -- representations of an LM's languageconceptualisation -- that shed light on the connections LMs draw betweenlanguage phenomena. Task spaces are based on the interactions of the learningsignals from different linguistic phenomena, which we assess via a method wecall 'similarity probing'. To disentangle the learning signals of linguisticphenomena, we further introduce a method called 'fine-tuning via gradientdifferentials' (FTGD). We apply our methods to language models of threedifferent scales and find that larger models generalise better to overarchinggeneral concepts for linguistic tasks, making better use of their sharedstructure. Further, the distributedness of linguistic processing increases withpre-training through increased parameter sharing between related linguistictasks. The overall generalisation patterns are mostly stable throughouttraining and not marked by incisive stages, potentially explaining the lack ofsuccessful curriculum strategies for LMs.</description><author>Lucas Weber, Jaap Jumelet, Elia Bruni, Dieuwke Hupkes</author><pubDate>Mon, 10 Jun 2024 17:34:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06441v1</guid></item><item><title>Multimodal Contextualized Semantic Parsing from Speech</title><link>http://arxiv.org/abs/2406.06438v1</link><description>We introduce Semantic Parsing in Contextual Environments (SPICE), a taskdesigned to enhance artificial agents' contextual awareness by integratingmultimodal inputs with prior contexts. SPICE goes beyond traditional semanticparsing by offering a structured, interpretable framework for dynamicallyupdating an agent's knowledge with new information, mirroring the complexity ofhuman communication. We develop the VG-SPICE dataset, crafted to challengeagents with visual scene graph construction from spoken conversationalexchanges, highlighting speech and visual data integration. We also present theAudio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE.These innovations aim to improve multimodal information processing andintegration. Both the VG-SPICE dataset and the AViD-SP model are publiclyavailable.</description><author>Jordan Voas, Raymond Mooney, David Harwath</author><pubDate>Mon, 10 Jun 2024 17:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06438v1</guid></item><item><title>An Empirical Study on Fault Detection and Root Cause Analysis of Indium Tin Oxide Electrodes by Processing S-parameter Patterns</title><link>http://arxiv.org/abs/2308.11639v2</link><description>In the field of optoelectronics, indium tin oxide (ITO) electrodes play acrucial role in various applications, such as displays, sensors, and solarcells. Effective fault diagnosis and root cause analysis of the ITO electrodesare essential to ensure the performance and reliability of the devices.However, traditional visual inspection is challenging with transparent ITOelectrodes, and existing fault diagnosis methods have limitations indetermining the root causes of the defects, often requiring destructiveevaluations and secondary material characterization techniques. In this study,a fault diagnosis method with root cause analysis is proposed using scatteringparameter (S-parameter) patterns, offering early detection, high diagnosticaccuracy, and noise robustness. A comprehensive S-parameter pattern database isobtained according to various defect states of the ITO electrodes. Deeplearning (DL) approaches, including multilayer perceptron (MLP), convolutionalneural network (CNN), and transformer, are then used to simultaneously analyzethe cause and severity of defects. Notably, it is demonstrated that thediagnostic performance under additive noise levels can be significantlyenhanced by combining different channels of the S-parameters as input to thelearning algorithms, as confirmed through the t-distributed stochastic neighborembedding (t-SNE) dimension reduction visualization of the S-parameterpatterns.</description><author>Tae Yeob Kang, Haebom Lee, Sungho Suh</author><pubDate>Mon, 10 Jun 2024 17:29:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11639v2</guid></item><item><title>Self-explainable Graph Neural Network for Alzheimer's Disease And Related Dementias Risk Prediction</title><link>http://arxiv.org/abs/2309.06584v4</link><description>Background: Alzheimer's disease and related dementias (ADRD) ranks as the sixth leadingcause of death in the US, underlining the importance of accurate ADRD riskprediction. While recent advancement in ADRD risk prediction have primarilyrelied on imaging analysis, yet not all patients undergo medical imaging beforean ADRD diagnosis. Merging machine learning with claims data can revealadditional risk factors and uncover interconnections among diverse medicalcodes. Objective: Our goal is to utilize Graph Neural Networks (GNNs) with claims data for ADRDrisk prediction. Addressing the lack of human-interpretable reasons behindthese predictions, we introduce an innovative method to evaluate relationshipimportance and its influence on ADRD risk prediction, ensuring comprehensiveinterpretation. Methods: We employed Variationally Regularized Encoder-decoder Graph Neural Network(VGNN) for estimating ADRD likelihood. We created three scenarios to assess themodel's efficiency, using Random Forest and Light Gradient Boost Machine asbaselines. We further used our relation importance method to clarify the keyrelationships for ADRD risk prediction. Results: VGNN surpassed other baseline models by 10% in the area under the receiveroperating characteristic. The integration of the GNN model and relationimportance interpretation could potentially play an essential role in providingvaluable insight into factors that may contribute to or delay ADRD progression. Conclusions: Employing a GNN approach with claims data enhances ADRD risk prediction andprovides insights into the impact of interconnected medical code relationships.This methodology not only enables ADRD risk modeling but also shows potentialfor other image analysis predictions using claims data.</description><author>Xinyue Hu, Zenan Sun, Yi Nian, Yichen Wang, Yifang Dang, Fang Li, Jingna Feng, Evan Yu, Cui Tao</author><pubDate>Mon, 10 Jun 2024 17:29:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06584v4</guid></item><item><title>Adaptive Interface-PINNs (AdaI-PINNs): An Efficient Physics-informed Neural Networks Framework for Interface Problems</title><link>http://arxiv.org/abs/2406.04626v2</link><description>We present an efficient physics-informed neural networks (PINNs) framework,termed Adaptive Interface-PINNs (AdaI-PINNs), to improve the modeling ofinterface problems with discontinuous coefficients and/or interfacial jumps.This framework is an enhanced version of its predecessor, Interface PINNs orI-PINNs (Sarma et al.; https://dx.doi.org/10.2139/ssrn.4766623), which involvesdomain decomposition and assignment of different predefined activationfunctions to the neural networks in each subdomain across a sharp interface,while keeping all other parameters of the neural networks identical. InAdaI-PINNs, the activation functions vary solely in their slopes, which aretrained along with the other parameters of the neural networks. This makes theAdaI-PINNs framework fully automated without requiring preset activationfunctions. Comparative studies on one-dimensional, two-dimensional, andthree-dimensional benchmark elliptic interface problems reveal that AdaI-PINNsoutperform I-PINNs, reducing computational costs by 2-6 times while producingsimilar or better accuracy.</description><author>Sumanta Roy, Chandrasekhar Annavarapu, Pratanu Roy, Antareep Kumar Sarma</author><pubDate>Mon, 10 Jun 2024 17:28:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04626v2</guid></item><item><title>Ranking Large Language Models without Ground Truth</title><link>http://arxiv.org/abs/2402.14860v4</link><description>Evaluation and ranking of large language models (LLMs) has become animportant problem with the proliferation of these models and their impact.Evaluation methods either require human responses which are expensive toacquire or use pairs of LLMs to evaluate each other which can be unreliable. Inthis paper, we provide a novel perspective where, given a dataset of prompts(viz. questions, instructions, etc.) and a set of LLMs, we rank them withoutaccess to any ground truth or reference responses. Inspired by real life whereboth an expert and a knowledgeable person can identify a novice our main ideais to consider triplets of models, where each one of them evaluates the othertwo, correctly identifying the worst model in the triplet with highprobability. We also analyze our idea and provide sufficient conditions for itto succeed. Applying this idea repeatedly, we propose two methods to rank LLMs.In experiments on different generative tasks (summarization, multiple-choice,and dialog), our methods reliably recover close to true rankings withoutreference data. This points to a viable low-resource mechanism for practicaluse.</description><author>Amit Dhurandhar, Rahul Nair, Moninder Singh, Elizabeth Daly, Karthikeyan Natesan Ramamurthy</author><pubDate>Mon, 10 Jun 2024 17:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14860v4</guid></item><item><title>Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain</title><link>http://arxiv.org/abs/2406.06435v1</link><description>In difficult decision-making scenarios, it is common to have conflictingopinions among expert human decision-makers as there may not be a single rightanswer. Such decisions may be guided by different attributes that can be usedto characterize an individual's decision. We introduce a novel dataset formedical triage decision-making, labeled with a set of decision-maker attributes(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,including ethical principles such as fairness and moral desert. We present anovel software framework for human-aligned decision-making by utilizing theseDMAs, paving the way for trustworthy AI with better guardrails. Specifically,we demonstrate how large language models (LLMs) can serve as ethicaldecision-makers, and how their decisions can be aligned to different DMAs usingzero-shot prompting. Our experiments focus on different open-source models withvarying sizes and training techniques, such as Falcon, Mistral, and Llama 2.Finally, we also introduce a new form of weighted self-consistency thatimproves the overall quantified performance. Our results provide new researchdirections in the use of LLMs as alignable decision-makers. The dataset andopen-source software are publicly available at:https://github.com/ITM-Kitware/llm-alignable-dm.</description><author>Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat</author><pubDate>Mon, 10 Jun 2024 17:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06435v1</guid></item><item><title>Spatiotemporal Graph Neural Network Modelling Perfusion MRI</title><link>http://arxiv.org/abs/2406.06434v1</link><description>Perfusion MRI (pMRI) offers valuable insights into tumor vascularity andpromises to predict tumor genotypes, thus benefiting prognosis for gliomapatients, yet effective models tailored to 4D pMRI are still lacking. Thisstudy presents the first attempt to model 4D pMRI using a GNN-basedspatiotemporal model PerfGAT, integrating spatial information and temporalkinetics to predict Isocitrate DeHydrogenase (IDH) mutation status in gliomapatients. Specifically, we propose a graph structure learning approach based onedge attention and negative graphs to optimize temporal correlations modeling.Moreover, we design a dual-attention feature fusion module to integratespatiotemporal features while addressing tumor-related brain regions. Further,we develop a class-balanced augmentation methods tailored to spatiotemporaldata, which could mitigate the common label imbalance issue in clinicaldatasets. Our experimental results demonstrate that the proposed methodoutperforms other state-of-the-art approaches, promising to model pMRIeffectively for patient characterization.</description><author>Ruodan Yan, Carola-Bibiane Schnlieb, Chao Li</author><pubDate>Mon, 10 Jun 2024 17:24:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06434v1</guid></item><item><title>DISCO: An End-to-End Bandit Framework for Personalised Discount Allocation</title><link>http://arxiv.org/abs/2406.06433v1</link><description>Personalised discount codes provide a powerful mechanism for managingcustomer relationships and operational spend in e-commerce. Bandits are wellsuited for this product area, given the partial information nature of theproblem, as well as the need for adaptation to the changing businessenvironment. Here, we introduce DISCO, an end-to-end contextual banditframework for personalised discount code allocation at ASOS.com. DISCO adaptsthe traditional Thompson Sampling algorithm by integrating it within an integerprogram, thereby allowing for operational cost control. Because bandit learningis often worse with high dimensional actions, we focused on building lowdimensional action and context representations that were nonetheless capable ofgood accuracy. Additionally, we sought to build a model that preserved therelationship between price and sales, in which customers increasing theirpurchasing in response to lower prices ("negative price elasticity"). Theseaims were achieved by using radial basis functions to represent the continuous(i.e. infinite armed) action space, in combination with context embeddingsextracted from a neural network. These feature representations were used withina Thompson Sampling framework to facilitate exploration, and further integratedwith an integer program to allocate discount codes across ASOS's customer base.These modelling decisions result in a reward model that (a) enables pooledlearning across similar actions, (b) is highly accurate, including inextrapolation, and (c) preserves the expected negative price elasticity.Through offline analysis, we show that DISCO is able to effectively enactexploration and improves its performance over time, despite the globalconstraint. Finally, we subjected DISCO to a rigorous online A/B test, and findthat it achieves a significant improvement of &gt;1% in average basket value,relative to the legacy systems.</description><author>Jason Shuo Zhang, Benjamin Howson, Panayiota Savva, Eleanor Loh</author><pubDate>Mon, 10 Jun 2024 17:24:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06433v1</guid></item><item><title>SYM3D: Learning Symmetric Triplanes for Better 3D-Awareness of GANs</title><link>http://arxiv.org/abs/2406.06432v1</link><description>Despite the growing success of 3D-aware GANs, which can be trained on 2Dimages to generate high-quality 3D assets, they still rely on multi-view imageswith camera annotations to synthesize sufficient details from all viewingdirections. However, the scarce availability of calibrated multi-view imagedatasets, especially in comparison to single-view images, has limited thepotential of 3D GANs. Moreover, while bypassing camera pose annotations with acamera distribution constraint reduces dependence on exact camera parameters,it still struggles to generate a consistent orientation of 3D assets. To thisend, we propose SYM3D, a novel 3D-aware GAN designed to leverage the prevalentreflectional symmetry structure found in natural and man-made objects,alongside a proposed view-aware spatial attention mechanism in learning the 3Drepresentation. We evaluate SYM3D on both synthetic (ShapeNet Chairs, Cars, andAirplanes) and real-world datasets (ABO-Chair), demonstrating its superiorperformance in capturing detailed geometry and texture, even when trained ononly single-view images. Finally, we demonstrate the effectiveness ofincorporating symmetry regularization in helping reduce artifacts in themodeling of 3D assets in the text-to-3D task.</description><author>Jing Yang, Kyle Fogarty, Fangcheng Zhong, Cengiz Oztireli</author><pubDate>Mon, 10 Jun 2024 17:24:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06432v1</guid></item><item><title>Multivariate Stochastic Dominance via Optimal Transport and Applications to Models Benchmarking</title><link>http://arxiv.org/abs/2406.06425v1</link><description>Stochastic dominance is an important concept in probability theory,econometrics and social choice theory for robustly modeling agents' preferencesbetween random outcomes. While many works have been dedicated to the univariatecase, little has been done in the multivariate scenario, wherein an agent hasto decide between different multivariate outcomes. By exploiting acharacterization of multivariate first stochastic dominance in terms ofcouplings, we introduce a statistic that assesses multivariate almoststochastic dominance under the framework of Optimal Transport with a smoothcost. Further, we introduce an entropic regularization of this statistic, andestablish a central limit theorem (CLT) and consistency of the bootstrapprocedure for the empirical statistic. Armed with this CLT, we propose ahypothesis testing framework as well as an efficient implementation using theSinkhorn algorithm. We showcase our method in comparing and benchmarking LargeLanguage Models that are evaluated on multiple metrics. Our multivariatestochastic dominance test allows us to capture the dependencies between themetrics in order to make an informed and statistically significant decision onthe relative performance of the models.</description><author>Gabriel Rioux, Apoorva Nitsure, Mattia Rigotti, Kristjan Greenewald, Youssef Mroueh</author><pubDate>Mon, 10 Jun 2024 17:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06425v1</guid></item><item><title>Margin-aware Preference Optimization for Aligning Diffusion Models without Reference</title><link>http://arxiv.org/abs/2406.06424v1</link><description>Modern alignment techniques based on human preferences, such as RLHF and DPO,typically employ divergence regularization relative to the reference model toensure training stability. However, this often limits the flexibility of modelsduring alignment, especially when there is a clear distributional discrepancybetween the preference data and the reference model. In this paper, we focus onthe alignment of recent text-to-image diffusion models, such as StableDiffusion XL (SDXL), and find that this "reference mismatch" is indeed asignificant problem in aligning these models due to the unstructured nature ofvisual modalities: e.g., a preference for a particular stylistic aspect caneasily induce such a discrepancy. Motivated by this observation, we propose anovel and memory-friendly preference alignment method for diffusion models thatdoes not depend on any reference model, coined margin-aware preferenceoptimization (MaPO). MaPO jointly maximizes the likelihood margin between thepreferred and dispreferred image sets and the likelihood of the preferred sets,simultaneously learning general stylistic features and preferences. Forevaluation, we introduce two new pairwise preference datasets, which compriseself-generated image pairs from SDXL, Pick-Style and Pick-Safety, simulatingdiverse scenarios of reference mismatch. Our experiments validate that MaPO cansignificantly improve alignment on Pick-Style and Pick-Safety and generalpreference alignment when used with Pick-a-Pic v2, surpassing the base SDXL andother existing methods. Our code, models, and datasets are publicly availablevia https://mapo-t2i.github.io</description><author>Jiwoo Hong, Sayak Paul, Noah Lee, Kashif Rasul, James Thorne, Jongheon Jeong</author><pubDate>Mon, 10 Jun 2024 17:14:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06424v1</guid></item><item><title>Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving</title><link>http://arxiv.org/abs/2406.06423v1</link><description>In autonomous driving, the most challenging scenarios are the ones that canonly be detected within their temporal context. Most video anomaly detectionapproaches focus either on surveillance or traffic accidents, which are only asubfield of autonomous driving. In this work, we present HF$^2$-VAD$_{AD}$, avariation of the HF$^2$-VAD surveillance video anomaly detection method forautonomous driving. We learn a representation of normality from a vehicle's egoperspective and evaluate pixel-wise anomaly detections in rare and criticalscenarios.</description><author>Daniel Bogdoll, Jan Imhof, Tim Joseph, J. Marius Zllner</author><pubDate>Mon, 10 Jun 2024 17:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06423v1</guid></item><item><title>An Improved Empirical Fisher Approximation for Natural Gradient Descent</title><link>http://arxiv.org/abs/2406.06420v1</link><description>Approximate Natural Gradient Descent (NGD) methods are an important family ofoptimisers for deep learning models, which use approximate Fisher informationmatrices to pre-condition gradients during training. The empirical Fisher (EF)method approximates the Fisher information matrix empirically by reusing theper-sample gradients collected during back-propagation. Despite its ease ofimplementation, the EF approximation has its theoretical and practicallimitations. This paper first investigates the inversely-scaled projectionissue of EF, which is shown to be a major cause of the poor empiricalapproximation quality. An improved empirical Fisher (iEF) method, motivated asa generalised NGD method from a loss reduction perspective, is proposed toaddress this issue, meanwhile retaining the practical convenience of EF. Theexact iEF and EF methods are experimentally evaluated using practical deeplearning setups, including widely-used setups for parameter-efficientfine-tuning of pre-trained models (T5-base with LoRA and Prompt-Tuning on GLUEtasks, and ViT with LoRA for CIFAR100). Optimisation experiments show thatapplying exact iEF as an optimiser provides strong convergence andgeneralisation. It achieves the best test performance and the lowest trainingloss for majority of the tasks, even when compared with well-tunedAdamW/Adafactor baselines. Additionally, under a novel empirical evaluationframework, the proposed iEF method shows consistently better approximationquality to the exact Natural Gradient updates than both EF and the moreexpensive sampled Fisher (SF). Further investigation also shows that thesuperior approximation quality of iEF is robust to damping across tasks andtraining stages. Improving existing approximate NGD optimisers with iEF isexpected to lead to better convergence ability and stronger robustness tochoice of damping.</description><author>Xiaodong Wu, Wenyi Yu, Chao Zhang, Philip Woodland</author><pubDate>Mon, 10 Jun 2024 17:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06420v1</guid></item><item><title>Foundation Inference Models for Markov Jump Processes</title><link>http://arxiv.org/abs/2406.06419v1</link><description>Markov jump processes are continuous-time stochastic processes which describedynamical systems evolving in discrete state spaces. These processes find wideapplication in the natural sciences and machine learning, but their inferenceis known to be far from trivial. In this work we introduce a methodology forzero-shot inference of Markov jump processes (MJPs), on bounded state spaces,from noisy and sparse observations, which consists of two components. First, abroad probability distribution over families of MJPs, as well as over possibleobservation times and noise mechanisms, with which we simulate a syntheticdataset of hidden MJPs and their noisy observation process. Second, a neuralnetwork model that processes subsets of the simulated observations, and that istrained to output the initial condition and rate matrix of the target MJP in asupervised way. We empirically demonstrate that one and the same (pretrained)model can infer, in a zero-shot fashion, hidden MJPs evolving in state spacesof different dimensionalities. Specifically, we infer MJPs which describe (i)discrete flashing ratchet systems, which are a type of Brownian motors, and theconformational dynamics in (ii) molecular simulations, (iii) experimental ionchannel data and (iv) simple protein folding models. What is more, we show thatour model performs on par with state-of-the-art models which are finetuned tothe target datasets.</description><author>David Berghaus, Kostadin Cvejoski, Patrick Seifner, Cesar Ojeda, Ramses J. Sanchez</author><pubDate>Mon, 10 Jun 2024 17:12:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06419v1</guid></item><item><title>Explainable Graph Neural Networks Under Fire</title><link>http://arxiv.org/abs/2406.06417v1</link><description>Predictions made by graph neural networks (GNNs) usually lackinterpretability due to their complex computational behavior and the abstractnature of graphs. In an attempt to tackle this, many GNN explanation methodshave emerged. Their goal is to explain a model's predictions and thereby obtaintrust when GNN models are deployed in decision critical applications. Most GNNexplanation methods work in a post-hoc manner and provide explanations in theform of a small subset of important edges and/or nodes. In this paper wedemonstrate that these explanations can unfortunately not be trusted, as commonGNN explanation methods turn out to be highly susceptible to adversarialperturbations. That is, even small perturbations of the original graphstructure that preserve the model's predictions may yield drastically differentexplanations. This calls into question the trustworthiness and practicalutility of post-hoc explanation methods for GNNs. To be able to attack GNNexplanation models, we devise a novel attack method dubbed \textit{GXAttack},the first \textit{optimization-based} adversarial attack method for post-hocGNN explanations under such settings. Due to the devastating effectiveness ofour attack, we call for an adversarial evaluation of future GNN explainers todemonstrate their robustness.</description><author>Zhong Li, Simon Geisler, Yuhang Wang, Stephan Gnnemann, Matthijs van Leeuwen</author><pubDate>Mon, 10 Jun 2024 17:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06417v1</guid></item><item><title>Reproducibility study of FairAC</title><link>http://arxiv.org/abs/2406.03314v2</link><description>This work aims to reproduce the findings of the paper "Fair AttributeCompletion on Graph with Missing Attributes" written by Guo, Chu, and LiarXiv:2302.12977 by investigating the claims made in the paper. This papersuggests that the results of the original paper are reproducible and thus, theclaims hold. However, the claim that FairAC is a generic framework for manydownstream tasks is very broad and could therefore only be partially tested.Moreover, we show that FairAC is generalizable to various datasets andsensitive attributes and show evidence that the improvement in group fairnessof the FairAC framework does not come at the expense of individual fairness.Lastly, the codebase of FairAC has been refactored and is now easily applicablefor various datasets and models.</description><author>Gijs de Jong, Macha J. Meijer, Derck W. E. Prinzhorn, Harold Ruiter</author><pubDate>Mon, 10 Jun 2024 17:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03314v2</guid></item><item><title>Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games: A Usability Assessment</title><link>http://arxiv.org/abs/2309.07773v3</link><description>This paper presents an empirical investigation of the extent to which spokenHumanoid Embodied Conversational Agents (HECAs) can foster usability in mobileserious game (MSG) applications. The aim of the research is to assess theimpact of multiple agents and illusion of humanness on the quality of theinteraction. The experiment investigates two styles of agent presentation: anagent of high human-likeness (HECA) and an agent of low human-likeness (text).The purpose of the experiment is to assess whether and how agents of highhumanlikeness can evoke the illusion of humanness and affect usability. Agentsof high human-likeness were designed by following the ECA design model that isa proposed guide for ECA development. The results of the experiment with 90participants show that users prefer to interact with the HECAs. The differencebetween the two versions is statistically significant with a large effect size(d=1.01), with many of the participants justifying their choice by saying thatthe human-like characteristics of the HECA made the version more appealing.This research provides key information on the potential effect of HECAs onserious games, which can provide insight into the design of future mobileserious games.</description><author>Danai Korre, Judy Robertson</author><pubDate>Mon, 10 Jun 2024 17:08:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07773v3</guid></item><item><title>Differentially Private Best-Arm Identification</title><link>http://arxiv.org/abs/2406.06408v1</link><description>Best Arm Identification (BAI) problems are progressively used fordata-sensitive applications, such as designing adaptive clinical trials, tuninghyper-parameters, and conducting user studies. Motivated by the data privacyconcerns invoked by these applications, we study the problem of BAI with fixedconfidence in both the local and central models, i.e. $\epsilon$-local and$\epsilon$-global Differential Privacy (DP). First, to quantify the cost ofprivacy, we derive lower bounds on the sample complexity of any$\delta$-correct BAI algorithm satisfying $\epsilon$-global DP or$\epsilon$-local DP. Our lower bounds suggest the existence of two privacyregimes. In the high-privacy regime, the hardness depends on a coupled effectof privacy and novel information-theoretic quantities involving the TotalVariation. In the low-privacy regime, the lower bounds reduce to thenon-private lower bounds. We propose $\epsilon$-local DP and $\epsilon$-globalDP variants of a Top Two algorithm, namely CTB-TT and AdaP-TT*, respectively.For $\epsilon$-local DP, CTB-TT is asymptotically optimal by plugging in aprivate estimator of the means based on Randomised Response. For$\epsilon$-global DP, our private estimator of the mean runs in arm-dependentadaptive episodes and adds Laplace noise to ensure a good privacy-utilitytrade-off. By adapting the transportation costs, the expected sample complexityof AdaP-TT* reaches the asymptotic lower bound up to multiplicative constants.</description><author>Achraf Azize, Marc Jourdan, Aymen Al Marjani, Debabrota Basu</author><pubDate>Mon, 10 Jun 2024 17:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06408v1</guid></item><item><title>The Structure and Dynamics of Knowledge Graphs, with Superficiality</title><link>http://arxiv.org/abs/2305.08116v4</link><description>Large knowledge graphs combine human knowledge garnered from projects rangingfrom academia and institutions to enterprises and crowdsourcing. Within suchgraphs, each relationship between two nodes represents a basic fact involvingthese two entities. The diversity of the semantics of relationships constitutesthe richness of knowledge graphs, leading to the emergence of singulartopologies, sometimes chaotic in appearance. However, this complexcharacteristic can be modeled in a simple way by introducing the concept ofsuperficiality, which controls the overlap between relationships whose factsare generated independently. With this model, superficiality also regulates thebalance of the global distribution of knowledge by determining the proportionof misdescribed entities. This is the first model for the structure anddynamics of knowledge graphs. It leads to a better understanding of formalknowledge acquisition and organization.</description><author>Lock Lhote, Batrice Markhoff, Arnaud Soulet</author><pubDate>Mon, 10 Jun 2024 17:02:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08116v4</guid></item><item><title>A Taxonomy of Challenges to Curating Fair Datasets</title><link>http://arxiv.org/abs/2406.06407v1</link><description>Despite extensive efforts to create fairer machine learning (ML) datasets,there remains a limited understanding of the practical aspects of datasetcuration. Drawing from interviews with 30 ML dataset curators, we present acomprehensive taxonomy of the challenges and trade-offs encountered throughoutthe dataset curation lifecycle. Our findings underscore overarching issueswithin the broader fairness landscape that impact data curation. We concludewith recommendations aimed at fostering systemic changes to better facilitatefair dataset curation practices.</description><author>Dora Zhao, Morgan Klaus Scheuerman, Pooja Chitre, Jerone T. A. Andrews, Georgia Panagiotidou, Shawn Walker, Kathleen H. Pine, Alice Xiang</author><pubDate>Mon, 10 Jun 2024 16:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06407v1</guid></item><item><title>Copycats: the many lives of a publicly available medical imaging dataset</title><link>http://arxiv.org/abs/2402.06353v2</link><description>Medical Imaging (MI) datasets are fundamental to artificial intelligence inhealthcare. The accuracy, robustness, and fairness of diagnostic algorithmsdepend on the data (and its quality) used to train and evaluate the models. MIdatasets used to be proprietary, but have become increasingly available to thepublic, including on community-contributed platforms (CCPs) like Kaggle orHuggingFace. While open data is important to enhance the redistribution ofdata's public value, we find that the current CCP governance model fails touphold the quality needed and recommended practices for sharing, documenting,and evaluating datasets. In this paper, we conduct an analysis of publiclyavailable machine learning datasets on CCPs, discussing datasets' context, andidentifying limitations and gaps in the current CCP landscape. We highlightdifferences between MI and computer vision datasets, particularly in thepotentially harmful downstream effects from poor adoption of recommendeddataset management practices. We compare the analyzed datasets across severaldimensions, including data sharing, data documentation, and maintenance. Wefind vague licenses, lack of persistent identifiers and storage, duplicates,and missing metadata, with differences between the platforms. Our researchcontributes to efforts in responsible data curation and AI algorithms forhealthcare.</description><author>Amelia Jimnez-Snchez, Natalia-Rozalia Avlona, Dovile Juodelyte, Tho Sourget, Caroline Vang-Larsen, Anna Rogers, Hubert Dariusz Zajc, Veronika Cheplygina</author><pubDate>Mon, 10 Jun 2024 16:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06353v2</guid></item><item><title>Controlling Emotion in Text-to-Speech with Natural Language Prompts</title><link>http://arxiv.org/abs/2406.06406v1</link><description>In recent years, prompting has quickly become one of the standard ways ofsteering the outputs of generative machine learning models, due to itsintuitive use of natural language. In this work, we propose a systemconditioned on embeddings derived from an emotionally rich text that serves asprompt. Thereby, a joint representation of speaker and prompt embeddings isintegrated at several points within a transformer-based architecture. Ourapproach is trained on merged emotional speech and text datasets and variesprompts in each training iteration to increase the generalization capabilitiesof the model. Objective and subjective evaluation results demonstrate theability of the conditioned synthesis system to accurately transfer the emotionspresent in a prompt to speech. At the same time, precise tractability ofspeaker identities as well as overall high speech quality and intelligibilityare maintained.</description><author>Thomas Bott, Florian Lux, Ngoc Thang Vu</author><pubDate>Mon, 10 Jun 2024 16:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06406v1</guid></item><item><title>Meta Learning Text-to-Speech Synthesis in over 7000 Languages</title><link>http://arxiv.org/abs/2406.06403v1</link><description>In this work, we take on the challenging task of building a singletext-to-speech synthesis system that is capable of generating speech in over7000 languages, many of which lack sufficient data for traditional TTSdevelopment. By leveraging a novel integration of massively multilingualpretraining and meta learning to approximate language representations, ourapproach enables zero-shot speech synthesis in languages without any availabledata. We validate our system's performance through objective measures and humanevaluation across a diverse linguistic landscape. By releasing our code andmodels publicly, we aim to empower communities with limited linguisticresources and foster further innovation in the field of speech technology.</description><author>Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanul A. P. Habets, Ngoc Thang Vu</author><pubDate>Mon, 10 Jun 2024 16:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06403v1</guid></item><item><title>INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition</title><link>http://arxiv.org/abs/2406.06401v1</link><description>We revisit the INTERSPEECH 2009 Emotion Challenge -- the first ever speechemotion recognition (SER) challenge -- and evaluate a series of deep learningmodels that are representative of the major advances in SER research in thetime since then. We start by training each model using a fixed set ofhyperparameters, and further fine-tune the best-performing models of thatinitial setup with a grid search. Results are always reported on the officialtest set with a separate validation set only used for early stopping. Mostmodels score below or close to the official baseline, while they marginallyoutperform the original challenge winners after hyperparameter tuning. Our workillustrates that, despite recent progress, FAU-AIBO remains a very challengingbenchmark. An interesting corollary is that newer methods do not consistentlyoutperform older ones, showing that progress towards `solving' SER is notnecessarily monotonic.</description><author>Andreas Triantafyllopoulos, Anton Batliner, Simon Rampp, Manuel Milling, Bjrn Schuller</author><pubDate>Mon, 10 Jun 2024 16:55:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06401v1</guid></item><item><title>An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics</title><link>http://arxiv.org/abs/2406.06400v1</link><description>The integration of Large Language Models (LLMs) in social robotics presents aunique set of ethical challenges and social impacts. This research is set outto identify ethical considerations that arise in the design and development ofthese two technologies in combination. Using LLMs for social robotics mayprovide benefits, such as enabling natural language open-domain dialogues.However, the intersection of these two technologies also gives rise to ethicalconcerns related to misinformation, non-verbal cues, emotional disruption, andbiases. The robot's physical social embodiment adds complexity, as ethicalhazards associated with LLM-based Social AI, such as hallucinations andmisinformation, can be exacerbated due to the effects of physical embodiment onsocial perception and communication. To address these challenges, this studyemploys an empirical design justice-based methodology, focusing on identifyingsocio-technical ethical considerations through a qualitative co-design andinteraction study. The purpose of the study is to identify ethicalconsiderations relevant to the process of co-design of, and interaction with ahumanoid social robot as the interface of a LLM, and to evaluate how a designjustice methodology can be used in the context of designing LLMs-based socialrobotics. The findings reveal a mapping of ethical considerations arising infour conceptual dimensions: interaction, co-design, terms of service andrelationship and evaluates how a design justice approach can be usedempirically in the intersection of LLMs and social robotics.</description><author>Alva Markelius</author><pubDate>Mon, 10 Jun 2024 16:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06400v1</guid></item><item><title>Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue</title><link>http://arxiv.org/abs/2406.06399v1</link><description>We study the limitations of Large Language Models (LLMs) for the task ofresponse generation in human-machine dialogue. Several techniques have beenproposed in the literature for different dialogue types (e.g., Open-Domain).However, the evaluations of these techniques have been limited in terms of baseLLMs, dialogue types and evaluation metrics. In this work, we extensivelyanalyze different LLM adaptation techniques when applied to different dialoguetypes. We have selected two base LLMs, Llama-2 and Mistral, and four dialoguetypes Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering.We evaluate the performance of in-context learning and fine-tuning techniquesacross datasets selected for each dialogue type. We assess the impact ofincorporating external knowledge to ground the generation in both scenarios ofRetrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistentevaluation and explainability criteria for automatic metrics and humanevaluation protocols. Our analysis shows that there is no universalbest-technique for adapting large language models as the efficacy of eachtechnique depends on both the base LLM and the specific type of dialogue. Lastbut not least, the assessment of the best adaptation technique should includehuman evaluation to avoid false expectations and outcomes derived fromautomatic metrics.</description><author>Simone Alghisi, Massimo Rizzoli, Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi</author><pubDate>Mon, 10 Jun 2024 16:52:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06399v1</guid></item><item><title>Lessons from Generalization Error Analysis of Federated Learning: You May Communicate Less Often!</title><link>http://arxiv.org/abs/2306.05862v2</link><description>We investigate the generalization error of statistical learning models in aFederated Learning (FL) setting. Specifically, we study the evolution of thegeneralization error with the number of communication rounds $R$ between $K$clients and a parameter server (PS), i.e., the effect on the generalizationerror of how often the clients' local models are aggregated at PS. In oursetup, the more the clients communicate with PS the less data they use forlocal training in each round, such that the amount of training data per clientis identical for distinct values of $R$. We establish PAC-Bayes andrate-distortion theoretic bounds on the generalization error that accountexplicitly for the effect of the number of rounds $R$, in addition to thenumber of participating devices $K$ and individual datasets size $n$. Thebounds, which apply to a large class of loss functions and learning algorithms,appear to be the first of their kind for the FL setting. Furthermore, we applyour bounds to FL-type Support Vector Machines (FSVM); and derive (more)explicit bounds in this case. In particular, we show that the generalizationbound of FSVM increases with $R$, suggesting that more frequent communicationwith PS diminishes the generalization power. This implies that the populationrisk decreases less fast with $R$ than does the empirical risk. Moreover, ourbound suggests that the generalization error of FSVM decreases faster than thatof centralized learning by a factor of $\mathcal{O}(\sqrt{\log(K)/K})$.Finally, we provide experimental results obtained using neural networks(ResNet-56) which show evidence that not only may our observations for FSVMhold more generally but also that the population risk may even start toincrease beyond some value of $R$.</description><author>Milad Sefidgaran, Romain Chor, Abdellatif Zaidi, Yijun Wan</author><pubDate>Mon, 10 Jun 2024 16:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05862v2</guid></item><item><title>RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors</title><link>http://arxiv.org/abs/2405.07940v2</link><description>Many commercial and open-source models claim to detect machine-generated textwith extremely high accuracy (99% or more). However, very few of thesedetectors are evaluated on shared benchmark datasets and even when they are,the datasets used for evaluation are insufficiently challenging-lackingvariations in sampling strategy, adversarial attacks, and open-sourcegenerative models. In this work we present RAID: the largest and mostchallenging benchmark dataset for machine-generated text detection. RAIDincludes over 6 million generations spanning 11 models, 8 domains, 11adversarial attacks and 4 decoding strategies. Using RAID, we evaluate theout-of-domain and adversarial robustness of 8 open- and 4 closed-sourcedetectors and find that current detectors are easily fooled by adversarialattacks, variations in sampling strategies, repetition penalties, and unseengenerative models. We release our data along with a leaderboard to encouragefuture research.</description><author>Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch</author><pubDate>Mon, 10 Jun 2024 16:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07940v2</guid></item><item><title>Contrastive learning of T cell receptor representations</title><link>http://arxiv.org/abs/2406.06397v1</link><description>Computational prediction of the interaction of T cell receptors (TCRs) andtheir ligands is a grand challenge in immunology. Despite advances inhigh-throughput assays, specificity-labelled TCR data remains sparse. In otherdomains, the pre-training of language models on unlabelled data has beensuccessfully used to address data bottlenecks. However, it is unclear how tobest pre-train protein language models for TCR specificity prediction. Here weintroduce a TCR language model called SCEPTR (Simple Contrastive Embedding ofthe Primary sequence of T cell Receptors), capable of data-efficient transferlearning. Through our model, we introduce a novel pre-training strategycombining autocontrastive learning and masked-language modelling, which enablesSCEPTR to achieve its state-of-the-art performance. In contrast, existingprotein language models and a variant of SCEPTR pre-trained withoutautocontrastive learning are outperformed by sequence alignment-based methods.We anticipate that contrastive learning will be a useful paradigm to decode therules of TCR specificity.</description><author>Yuta Nagano, Andrew Pyo, Martina Milighetti, James Henderson, John Shawe-Taylor, Benny Chain, Andreas Tiffeau-Mayer</author><pubDate>Mon, 10 Jun 2024 16:50:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06397v1</guid></item><item><title>STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics</title><link>http://arxiv.org/abs/2406.06393v1</link><description>Recent advances in multi-modal algorithms have driven and been driven by theincreasing availability of large image-text datasets, leading to significantstrides in various fields, including computational pathology. However, in mostexisting medical image-text datasets, the text typically provides high-levelsummaries that may not sufficiently describe sub-tile regions within a largepathology image. For example, an image might cover an extensive tissue areacontaining cancerous and healthy regions, but the accompanying text might onlyspecify that this image is a cancer slide, lacking the nuanced details neededfor in-depth analysis. In this study, we introduce STimage-1K4M, a noveldataset designed to bridge this gap by providing genomic features for sub-tileimages. STimage-1K4M contains 1,149 images derived from spatial transcriptomicsdata, which captures gene expression information at the level of individualspatial spots within a pathology image. Specifically, each image in the datasetis broken down into smaller sub-image tiles, with each tile paired with15,000-30,000 dimensional gene expressions. With 4,293,195 pairs of sub-tileimages and gene expressions, STimage-1K4M offers unprecedented granularity,paving the way for a wide range of advanced research in multi-modal dataanalysis an innovative applications in computational pathology, and beyond.</description><author>Jiawen Chen, Muqing Zhou, Wenrong Wu, Jinwei Zhang, Yun Li, Didong Li</author><pubDate>Mon, 10 Jun 2024 16:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06393v1</guid></item><item><title>Towards Lifelong Learning of Large Language Models: A Survey</title><link>http://arxiv.org/abs/2406.06391v1</link><description>As the applications of large language models (LLMs) expand across diversefields, the ability of these models to adapt to ongoing changes in data, tasks,and user preferences becomes crucial. Traditional training methods, relying onstatic datasets, are increasingly inadequate for coping with the dynamic natureof real-world information. Lifelong learning, also known as continual orincremental learning, addresses this challenge by enabling LLMs to learncontinuously and adaptively over their operational lifetime, integrating newknowledge while retaining previously learned information and preventingcatastrophic forgetting. This survey delves into the sophisticated landscape oflifelong learning, categorizing strategies into two primary groups: InternalKnowledge and External Knowledge. Internal Knowledge includes continualpretraining and continual finetuning, each enhancing the adaptability of LLMsin various scenarios. External Knowledge encompasses retrieval-based andtool-based lifelong learning, leveraging external data sources andcomputational tools to extend the model's capabilities without modifying coreparameters. The key contributions of our survey are: (1) Introducing a noveltaxonomy categorizing the extensive literature of lifelong learning into 12scenarios; (2) Identifying common techniques across all lifelong learningscenarios and classifying existing literature into various technique groupswithin each scenario; (3) Highlighting emerging techniques such as modelexpansion and data selection, which were less explored in the pre-LLM era.Through a detailed examination of these groups and their respective categories,this survey aims to enhance the adaptability, reliability, and overallperformance of LLMs in real-world applications.</description><author>Junhao Zheng, Shengjie Qiu, Chengming Shi, Qianli Ma</author><pubDate>Mon, 10 Jun 2024 16:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06391v1</guid></item><item><title>FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography</title><link>http://arxiv.org/abs/2406.06386v1</link><description>Digital mammography is essential to breast cancer detection, and deeplearning offers promising tools for faster and more accurate mammogramanalysis. In radiology and other high-stakes environments, uninterpretable("black box") deep learning models are unsuitable and there is a call in thesefields to make interpretable models. Recent work in interpretable computervision provides transparency to these formerly black boxes by utilizingprototypes for case-based explanations, achieving high accuracy in applicationsincluding mammography. However, these models struggle with precise featurelocalization, reasoning on large portions of an image when only a small part isrelevant. This paper addresses this gap by proposing a novel multi-scaleinterpretable deep learning model for mammographic mass margin classification.Our contribution not only offers an interpretable model with reasoning alignedwith radiologist practices, but also provides a general architecture forcomputer vision with user-configurable prototypes from coarse- to fine-grainedprototypes.</description><author>Julia Yang, Alina Jade Barnett, Jon Donnelly, Satvik Kishore, Jerry Fang, Fides Regina Schwartz, Chaofan Chen, Joseph Y. Lo, Cynthia Rudin</author><pubDate>Mon, 10 Jun 2024 16:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06386v1</guid></item><item><title>Low-Rank Quantization-Aware Training for LLMs</title><link>http://arxiv.org/abs/2406.06385v1</link><description>Large language models (LLMs) are omnipresent, however their practicaldeployment is challenging due to their ever increasing computational and memorydemands. Quantization is one of the most effective ways to make them morecompute and memory efficient. Quantization-aware training (QAT) methods,generally produce the best quantized performance, however it comes at the costof potentially long training time and excessive memory usage, making itimpractical when applying for LLMs. Inspired by parameter-efficient fine-tuning(PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- alightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs severalcomponents to save memory without sacrificing predictive performance: (a)low-rank auxiliary weights that are aware of the quantization grid; (b) adowncasting operator using fixed-point or double-packed integers and (c)checkpointing. Unlike most related work, our method (i) is inference-efficient,leading to no additional overhead compared to traditional PTQ; (ii) can be seenas a general extended pretraining framework, meaning that the resulting modelcan still be utilized for any downstream task afterwards; (iii) can be appliedacross a wide range of quantization settings, such as different choicesquantization granularity, activation quantization, and seamlessly combined withmany PTQ techniques. We apply LR-QAT to the LLaMA-2/3 and Mistral modelfamilies and validate its effectiveness on several downstream tasks. Our methodoutperforms common post-training quantization (PTQ) approaches and reaches thesame model performance as full-model QAT at the fraction of its memory usage.Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB ofmemory.</description><author>Yelysei Bondarenko, Riccardo Del Chiaro, Markus Nagel</author><pubDate>Mon, 10 Jun 2024 16:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06385v1</guid></item><item><title>Generalizing to Unseen Domains in Diabetic Retinopathy with Disentangled Representations</title><link>http://arxiv.org/abs/2406.06384v1</link><description>Diabetic Retinopathy (DR), induced by diabetes, poses a significant risk ofvisual impairment. Accurate and effective grading of DR aids in the treatmentof this condition. Yet existing models experience notable performancedegradation on unseen domains due to domain shifts. Previous methods addressthis issue by simulating domain style through simple visual transformation andmitigating domain noise via learning robust representations. However, domainshifts encompass more than image styles. They overlook biases caused byimplicit factors such as ethnicity, age, and diagnostic criteria. In our work,we propose a novel framework where representations of paired data fromdifferent domains are decoupled into semantic features and domain noise. Theresulting augmented representation comprises original retinal semantics anddomain noise from other domains, aiming to generate enhanced representationsaligned with real-world clinical needs, incorporating rich information fromdiverse domains. Subsequently, to improve the robustness of the decoupledrepresentations, class and domain prototypes are employed to interpolate thedisentangled representations while data-aware weights are designed to focus onrare classes and domains. Finally, we devise a robust pixel-level semanticalignment loss to align retinal semantics decoupled from features, maintaininga balance between intra-class diversity and dense class features. Experimentalresults on multiple benchmarks demonstrate the effectiveness of our method onunseen domains. The code implementations are accessible onhttps://github.com/richard-peng-xia/DECO.</description><author>Peng Xia, Ming Hu, Feilong Tang, Wenxue Li, Wenhao Zheng, Lie Ju, Peibo Duan, Huaxiu Yao, Zongyuan Ge</author><pubDate>Mon, 10 Jun 2024 16:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06384v1</guid></item><item><title>Learning a Reward Function for User-Preferred Appliance Scheduling</title><link>http://arxiv.org/abs/2310.07389v2</link><description>Accelerated development of demand response service provision by theresidential sector is crucial for reducing carbon-emissions in the powersector. Along with the infrastructure advancement, encouraging the end users toparticipate is crucial. End users highly value their privacy and control, andwant to be included in the service design and decision-making process whencreating the daily appliance operation schedules. Furthermore, unless they arefinancially or environmentally motivated, they are generally not prepared tosacrifice their comfort to help balance the power system. In this paper, wepresent an inverse-reinforcement-learning-based model that helps create the endusers' daily appliance schedules without asking them to explicitly state theirneeds and wishes. By using their past consumption data, the end consumers willimplicitly participate in the creation of those decisions and will thus bemotivated to continue participating in the provision of demand responseservices.</description><author>Nikolina ovi, Jochen L. Cremer, Hrvoje Pandi</author><pubDate>Mon, 10 Jun 2024 16:43:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07389v2</guid></item></channel></rss>