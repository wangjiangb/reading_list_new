<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 03 Jun 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis</title><link>http://arxiv.org/abs/2405.21075v1</link><description>In the quest for artificial general intelligence, Multi-modal Large LanguageModels (MLLMs) have emerged as a focal point in recent advancements. However,the predominant focus remains on developing their capabilities in static imageunderstanding. The potential of MLLMs in processing sequential visual data isstill insufficiently explored, highlighting the absence of a comprehensive,high-quality assessment of their performance. In this paper, we introduceVideo-MME, the first-ever full-spectrum, Multi-Modal Evaluation benchmark ofMLLMs in Video analysis. Our work distinguishes from existing benchmarksthrough four key features: 1) Diversity in video types, spanning 6 primaryvisual domains with 30 subfields to ensure broad scenario generalizability; 2)Duration in temporal dimension, encompassing both short-, medium-, andlong-term videos, ranging from 11 seconds to 1 hour, for robust contextualdynamics; 3) Breadth in data modalities, integrating multi-modal inputs besidesvideo frames, including subtitles and audios, to unveil the all-roundcapabilities of MLLMs; 4) Quality in annotations, utilizing rigorous manuallabeling by expert annotators to facilitate precise and reliable modelassessment. 900 videos with a total of 256 hours are manually selected andannotated by repeatedly viewing all the video content, resulting in 2,700question-answer pairs. With Video-MME, we extensively evaluate variousstate-of-the-art MLLMs, including GPT-4 series and Gemini 1.5 Pro, as well asopen-source image models like InternVL-Chat-V1.5 and video models likeLLaVA-NeXT-Video. Our experiments reveal that Gemini 1.5 Pro is thebest-performing commercial model, significantly outperforming the open-sourcemodels. Our dataset along with these findings underscores the need for furtherimprovements in handling longer sequences and multi-modal data. Project Page:https://video-mme.github.io</description><author>Chaoyou Fu, Yuhan Dai, Yondong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, Peixian Chen, Yanwei Li, Shaohui Lin, Sirui Zhao, Ke Li, Tong Xu, Xiawu Zheng, Enhong Chen, Rongrong Ji, Xing Sun</author><pubDate>Fri, 31 May 2024 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21075v1</guid></item><item><title>Resampling methods for Private Statistical Inference</title><link>http://arxiv.org/abs/2402.07131v2</link><description>We consider the task of constructing confidence intervals with differentialprivacy. We propose two private variants of the non-parametric bootstrap, whichprivately compute the median of the results of multiple "little" bootstraps runon partitions of the data and give asymptotic bounds on the coverage error ofthe resulting confidence intervals. For a fixed differential privacy parameter$\epsilon$, our methods enjoy the same error rates as that of the non-privatebootstrap to within logarithmic factors in the sample size $n$. We empiricallyvalidate the performance of our methods for mean estimation, median estimation,and logistic regression with both real and synthetic data. Our methods achievesimilar coverage accuracy to existing methods (and non-private baselines) whileproviding notably shorter ($\gtrsim 10$ times) confidence intervals thanprevious approaches.</description><author>Karan Chadha, John Duchi, Rohith Kuditipudi</author><pubDate>Fri, 31 May 2024 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07131v2</guid></item><item><title>Latent Intrinsics Emerge from Training to Relight</title><link>http://arxiv.org/abs/2405.21074v1</link><description>Image relighting is the task of showing what a scene from a source imagewould look like if illuminated differently. Inverse graphics schemes recover anexplicit representation of geometry and a set of chosen intrinsics, thenrelight with some form of renderer. However error control for inverse graphicsis difficult, and inverse graphics methods can represent only the effects ofthe chosen intrinsics. This paper describes a relighting method that isentirely data-driven, where intrinsics and lighting are each represented aslatent variables. Our approach produces SOTA relightings of real scenes, asmeasured by standard metrics. We show that albedo can be recovered from ourlatent intrinsics without using any example albedos, and that the albedosrecovered are competitive with SOTA methods.</description><author>Xiao Zhang, William Gao, Seemandhar Jain, Michael Maire, David. A. Forsyth, Anand Bhattad</author><pubDate>Fri, 31 May 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21074v1</guid></item><item><title>Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights</title><link>http://arxiv.org/abs/2405.21070v1</link><description>Severe data imbalance naturally exists among web-scale vision-languagedatasets. Despite this, we find CLIP pre-trained thereupon exhibits notablerobustness to the data imbalance compared to supervised learning, anddemonstrates significant effectiveness in learning generalizablerepresentations. With an aim to investigate the reasons behind this finding, weconduct controlled experiments to study various underlying factors, and revealthat CLIP's pretext task forms a dynamic classification problem wherein only asubset of classes is present in training. This isolates the bias from dominantclasses and implicitly balances the learning signal. Furthermore, therobustness and discriminability of CLIP improve with more descriptive languagesupervision, larger data scale, and broader open-world concepts, which areinaccessible to supervised learning. Our study not only uncovers the mechanismsbehind CLIP's generalizability beyond data imbalance but also providestransferable insights for the research community. The findings are validated inboth supervised and self-supervised learning, enabling models trained onimbalanced data to achieve CLIP-level performance on diverse recognition tasks.Code will be available at: https://github.com/CVMI-Lab/clip-beyond-tail.</description><author>Xin Wen, Bingchen Zhao, Yilun Chen, Jiangmiao Pang, Xiaojuan Qi</author><pubDate>Fri, 31 May 2024 18:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21070v1</guid></item><item><title>Code Pretraining Improves Entity Tracking Abilities of Language Models</title><link>http://arxiv.org/abs/2405.21068v1</link><description>Recent work has provided indirect evidence that pretraining language modelson code improves the ability of models to track state changes of discourseentities expressed in natural language. In this work, we systematically testthis claim by comparing pairs of language models on their entity trackingperformance. Critically, the pairs consist of base models and models trained ontop of these base models with additional code data. We extend this analysis toadditionally examine the effect of math training, another highly structureddata type, and alignment tuning, an important step for enhancing the usabilityof models. We find clear evidence that models additionally trained on largeamounts of code outperform the base models. On the other hand, we find noconsistent benefit of additional math training or alignment tuning acrossvarious model families.</description><author>Najoung Kim, Sebastian Schuster, Shubham Toshniwal</author><pubDate>Fri, 31 May 2024 18:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21068v1</guid></item><item><title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</title><link>http://arxiv.org/abs/2312.00752v2</link><description>Foundation models, now powering most of the exciting applications in deeplearning, are almost universally based on the Transformer architecture and itscore attention module. Many subquadratic-time architectures such as linearattention, gated convolution and recurrent models, and structured state spacemodels (SSMs) have been developed to address Transformers' computationalinefficiency on long sequences, but they have not performed as well asattention on important modalities such as language. We identify that a keyweakness of such models is their inability to perform content-based reasoning,and make several improvements. First, simply letting the SSM parameters befunctions of the input addresses their weakness with discrete modalities,allowing the model to selectively propagate or forget information along thesequence length dimension depending on the current token. Second, even thoughthis change prevents the use of efficient convolutions, we design ahardware-aware parallel algorithm in recurrent mode. We integrate theseselective SSMs into a simplified end-to-end neural network architecture withoutattention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\times$higher throughput than Transformers) and linear scaling in sequence length, andits performance improves on real data up to million-length sequences. As ageneral sequence model backbone, Mamba achieves state-of-the-art performanceacross several modalities such as language, audio, and genomics. On languagemodeling, our Mamba-3B model outperforms Transformers of the same size andmatches Transformers twice its size, both in pretraining and downstreamevaluation.</description><author>Albert Gu, Tri Dao</author><pubDate>Fri, 31 May 2024 18:55:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00752v2</guid></item><item><title>Mixed Diffusion for 3D Indoor Scene Synthesis</title><link>http://arxiv.org/abs/2405.21066v1</link><description>Realistic conditional 3D scene synthesis significantly enhances andaccelerates the creation of virtual environments, which can also provideextensive training data for computer vision and robotics research among otherapplications. Diffusion models have shown great performance in relatedapplications, e.g., making precise arrangements of unordered sets. However,these models have not been fully explored in floor-conditioned scene synthesisproblems. We present MiDiffusion, a novel mixed discrete-continuous diffusionmodel architecture, designed to synthesize plausible 3D indoor scenes fromgiven room types, floor plans, and potentially pre-existing objects. Werepresent a scene layout by a 2D floor plan and a set of objects, each definedby its category, location, size, and orientation. Our approach uniquelyimplements structured corruption across the mixed discrete semantic andcontinuous geometric domains, resulting in a better conditioned problem for thereverse denoising step. We evaluate our approach on the 3D-FRONT dataset. Ourexperimental results demonstrate that MiDiffusion substantially outperformsstate-of-the-art autoregressive and diffusion models in floor-conditioned 3Dscene synthesis. In addition, our models can handle partial object constraintsvia a corruption-and-masking strategy without task specific training. We showMiDiffusion maintains clear advantages over existing approaches in scenecompletion and furniture arrangement experiments.</description><author>Siyi Hu, Diego Martin Arroyo, Stephanie Debats, Fabian Manhardt, Luca Carlone, Federico Tombari</author><pubDate>Fri, 31 May 2024 18:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21066v1</guid></item><item><title>Recurrent neural networks: vanishing and exploding gradients are not the end of the story</title><link>http://arxiv.org/abs/2405.21064v1</link><description>Recurrent neural networks (RNNs) notoriously struggle to learn long-termmemories, primarily due to vanishing and exploding gradients. The recentsuccess of state-space models (SSMs), a subclass of RNNs, to overcome suchdifficulties challenges our theoretical understanding. In this paper, we delveinto the optimization challenges of RNNs and discover that, as the memory of anetwork increases, changes in its parameters result in increasingly largeoutput variations, making gradient-based learning highly sensitive, evenwithout exploding gradients. Our analysis further reveals the importance of theelement-wise recurrence design pattern combined with careful parametrizationsin mitigating this effect. This feature is present in SSMs, as well as in otherarchitectures, such as LSTMs. Overall, our insights provide a new explanationfor some of the difficulties in gradient-based learning of RNNs and why somearchitectures perform better than others.</description><author>Nicolas Zucchet, Antonio Orvieto</author><pubDate>Fri, 31 May 2024 18:53:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21064v1</guid></item><item><title>Neural Network Verification with Branch-and-Bound for General Nonlinearities</title><link>http://arxiv.org/abs/2405.21063v1</link><description>Branch-and-bound (BaB) is among the most effective methods for neural network(NN) verification. However, existing works on BaB have mostly focused on NNswith piecewise linear activations, especially ReLU networks. In this paper, wedevelop a general framework, named GenBaB, to conduct BaB for generalnonlinearities in general computational graphs based on linear boundpropagation. To decide which neuron to branch, we design a new branchingheuristic which leverages linear bounds as shortcuts to efficiently estimatethe potential improvement after branching. To decide nontrivial branchingpoints for general nonlinear functions, we propose to optimize branching pointsoffline, which can be efficiently leveraged during verification with a lookuptable. We demonstrate the effectiveness of our GenBaB on verifying a wide rangeof NNs, including networks with activation functions such as Sigmoid, Tanh,Sine and GeLU, as well as networks involving multi-dimensional nonlinearoperations such as multiplications in LSTMs and Vision Transformers. Ourframework also allows the verification of general nonlinear computation graphsand enables verification applications beyond simple neural networks,particularly for AC Optimal Power Flow (ACOPF). GenBaB is part of the latest$\alpha,\!\beta$-CROWN, the winner of the 4th International Verification ofNeural Networks Competition (VNN-COMP 2023).</description><author>Zhouxing Shi, Qirui Jin, Zico Kolter, Suman Jana, Cho-Jui Hsieh, Huan Zhang</author><pubDate>Fri, 31 May 2024 18:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21063v1</guid></item><item><title>Graph External Attention Enhanced Transformer</title><link>http://arxiv.org/abs/2405.21061v1</link><description>The Transformer architecture has recently gained considerable attention inthe field of graph representation learning, as it naturally overcomes severallimitations of Graph Neural Networks (GNNs) with customized attentionmechanisms or positional and structural encodings. Despite making someprogress, existing works tend to overlook external information of graphs,specifically the correlation between graphs. Intuitively, graphs with similarstructures should have similar representations. Therefore, we propose GraphExternal Attention (GEA) -- a novel attention mechanism that leverages multipleexternal node/edge key-value units to capture inter-graph correlationsimplicitly. On this basis, we design an effective architecture called GraphExternal Attention Enhanced Transformer (GEAET), which integrates localstructure and global interaction information for more comprehensive graphrepresentations. Extensive experiments on benchmark datasets demonstrate thatGEAET achieves state-of-the-art empirical performance. The source code isavailable for reproducibility at: https://github.com/icm1018/GEAET.</description><author>Jianqing Liang, Min Chen, Jiye Liang</author><pubDate>Fri, 31 May 2024 18:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21061v1</guid></item><item><title>Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality</title><link>http://arxiv.org/abs/2405.21060v1</link><description>While Transformers have been the main architecture behind deep learning'ssuccess in language modeling, state-space models (SSMs) such as Mamba haverecently been shown to match or outperform Transformers at small to mediumscale. We show that these families of models are actually quite closelyrelated, and develop a rich framework of theoretical connections between SSMsand variants of attention, connected through various decompositions of awell-studied class of structured semiseparable matrices. Our state spaceduality (SSD) framework allows us to design a new architecture (Mamba-2) whosecore layer is an a refinement of Mamba's selective SSM that is 2-8X faster,while continuing to be competitive with Transformers on language modeling.</description><author>Tri Dao, Albert Gu</author><pubDate>Fri, 31 May 2024 18:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21060v1</guid></item><item><title>Unified Directly Denoising for Both Variance Preserving and Variance Exploding Diffusion Models</title><link>http://arxiv.org/abs/2405.21059v1</link><description>Previous work has demonstrated that, in the Variance Preserving (VP)scenario, the nascent Directly Denoising Diffusion Models (DDDM) can generatehigh-quality images in one step while achieving even better performance inmultistep sampling. However, the Pseudo-LPIPS loss used in DDDM leads toconcerns about the bias in assessment. Here, we propose a unified DDDM (uDDDM)framework that generates images in one-step/multiple steps for both VariancePreserving (VP) and Variance Exploding (VE) cases. We provide theoreticalproofs of the existence and uniqueness of the model's solution paths, as wellas the non-intersecting property of the sampling paths. Additionally, wepropose an adaptive Pseudo-Huber loss function to balance the convergence tothe true solution and the stability of convergence process.Through acomprehensive evaluation, we demonstrate that uDDDMs achieve FID scorescomparable to the best-performing methods available for CIFAR-10 in both VP andVE. Specifically, uDDDM achieves one-step generation on CIFAR10 with FID of2.63 and 2.53 for VE and VP respectively. By extending the sampling to 1000steps, we further reduce FID score to 1.71 and 1.65 for VE and VP respectively,setting state-of-the-art performance in both cases.</description><author>Jingjing Wang, Dan Zhang, Feng Luo</author><pubDate>Fri, 31 May 2024 18:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21059v1</guid></item><item><title>Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models</title><link>http://arxiv.org/abs/2402.15938v3</link><description>Recent statements about the impressive capabilities of large language models(LLMs) are usually supported by evaluating on open-access benchmarks.Considering the vast size and wide-ranging sources of LLMs' training data, itcould explicitly or implicitly include test data, leading to LLMs being moresusceptible to data contamination. However, due to the opacity of trainingdata, the black-box access of models, and the rapid growth of synthetictraining data, detecting and mitigating data contamination for LLMs facessignificant challenges. In this paper, we propose CDD, which stands forContamination Detection via output Distribution for LLMs. CDD necessitates onlythe sampled texts to detect data contamination, by identifying the peakednessof LLM's output distribution. To mitigate the impact of data contamination inevaluation, we also present TED: Trustworthy Evaluation via outputDistribution, based on the correction of LLM's output distribution. Tofacilitate this study, we introduce two benchmarks, i.e., DetCon and ComiEval,for data contamination detection and contamination mitigation evaluation tasks.Extensive experimental results show that CDD achieves the average relativeimprovements of 21.8\%-30.2\% over other contamination detection approaches interms of Accuracy, F1 Score, and AUC metrics, and can effectively detectimplicit contamination. TED substantially mitigates performance improvements upto 66.9\% attributed to data contamination across various contamination setups.In real-world applications, we reveal that ChatGPT exhibits a high potential tosuffer from data contamination on HumanEval benchmark.</description><author>Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, Bin Gu, Mengfei Yang, Ge Li</author><pubDate>Fri, 31 May 2024 18:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15938v3</guid></item><item><title>P4: Towards private, personalized, and Peer-to-Peer learning</title><link>http://arxiv.org/abs/2405.17697v2</link><description>Personalized learning is a proposed approach to address the problem of dataheterogeneity in collaborative machine learning. In a decentralized setting,the two main challenges of personalization are client clustering and dataprivacy. In this paper, we address these challenges by developing P4(Personalized Private Peer-to-Peer) a method that ensures that each clientreceives a personalized model while maintaining differential privacy guaranteeof each client's local dataset during and after the training. Our approachincludes the design of a lightweight algorithm to identify similar clients andgroup them in a private, peer-to-peer (P2P) manner. Once grouped, we developdifferentially-private knowledge distillation for clients to co-train withminimal impact on accuracy. We evaluate our proposed method on three benchmarkdatasets (FEMNIST or Federated EMNIST, CIFAR-10 and CIFAR-100) and twodifferent neural network architectures (Linear and CNN-based networks) across arange of privacy parameters. The results demonstrate the potential of P4, as itoutperforms the state-of-the-art of differential private P2P by up to 40percent in terms of accuracy. We also show the practicality of P4 byimplementing it on resource constrained devices, and validating that it hasminimal overhead, e.g., about 7 seconds to run collaborative training betweentwo clients.</description><author>Mohammad Mahdi Maheri, Sandra Siby, Sina Abdollahi, Anastasia Borovykh, Hamed Haddadi</author><pubDate>Fri, 31 May 2024 18:47:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17697v2</guid></item><item><title>SpeechVerse: A Large-scale Generalizable Audio Language Model</title><link>http://arxiv.org/abs/2405.08295v2</link><description>Large language models (LLMs) have shown incredible proficiency in performingtasks that require semantic understanding of natural language instructions.Recently, many works have further expanded this capability to perceivemultimodal audio and text inputs, but their capabilities are often limited tospecific fine-tuned tasks such as automatic speech recognition and translation.We therefore develop SpeechVerse, a robust multi-task training and curriculumlearning framework that combines pre-trained speech and text foundation modelsvia a small set of learnable parameters, while keeping the pre-trained modelsfrozen during training. The models are instruction finetuned using continuouslatent representations extracted from the speech foundation model to achieveoptimal zero-shot performance on a diverse range of speech processing tasksusing natural language instructions. We perform extensive benchmarking thatincludes comparing our model performance against traditional baselines acrossseveral datasets and tasks. Furthermore, we evaluate the model's capability forgeneralized instruction following by testing on out-of-domain datasets, novelprompts, and unseen tasks. Our empirical experiments reveal that our multi-taskSpeechVerse model is even superior to conventional task-specific baselines on 9out of the 11 tasks.</description><author>Nilaksh Das, Saket Dingliwal, Srikanth Ronanki, Rohit Paturi, Zhaocheng Huang, Prashant Mathur, Jie Yuan, Dhanush Bekal, Xing Niu, Sai Muralidhar Jayanthi, Xilai Li, Karel Mundnich, Monica Sunkara, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff</author><pubDate>Fri, 31 May 2024 18:47:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08295v2</guid></item><item><title>An Organic Weed Control Prototype using Directed Energy and Deep Learning</title><link>http://arxiv.org/abs/2405.21056v1</link><description>Organic weed control is a vital to improve crop yield with a sustainableapproach. In this work, a directed energy weed control robot prototypespecifically designed for organic farms is proposed. The robot uses a noveldistributed array robot (DAR) unit for weed treatment. Soybean and corndatabases are built to train deep learning neural nets to perform weedrecognition. The initial deep learning neural nets show a high performance inclassifying crops. The robot uses a patented directed energy plant eradicationrecipe that is completely organic and UV-C free, with no chemical damage orphysical disturbance to the soil. The deep learning can classify 8 common weedspecies in a soybean field under natural environment with up to 98% accuracy.</description><author>Deng Cao, Hongbo Zhang, Rajveer Dhillon</author><pubDate>Fri, 31 May 2024 18:47:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21056v1</guid></item><item><title>Dynamic Conditional Optimal Transport through Simulation-Free Flows</title><link>http://arxiv.org/abs/2404.04240v2</link><description>We study the geometry of conditional optimal transport (COT) and prove adynamical formulation which generalizes the Benamou-Brenier Theorem. Equippedwith these tools, we propose a simulation-free flow-based method forconditional generative modeling. Our method couples an arbitrary sourcedistribution to a specified target distribution through a triangular COT plan,and a conditional generative model is obtained by approximating the geodesicpath of measures induced by this COT plan. Our theory and methods areapplicable in infinite-dimensional settings, making them well suited for a wideclass of Bayesian inverse problems. Empirically, we demonstrate that our methodis competitive on several challenging conditional generation tasks, includingan infinite-dimensional inverse problem.</description><author>Gavin Kerrigan, Giosue Migliorini, Padhraic Smyth</author><pubDate>Fri, 31 May 2024 18:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04240v2</guid></item><item><title>Spectrum-Aware Parameter Efficient Fine-Tuning for Diffusion Models</title><link>http://arxiv.org/abs/2405.21050v1</link><description>Adapting large-scale pre-trained generative models in a parameter-efficientmanner is gaining traction. Traditional methods like low rank adaptationachieve parameter efficiency by imposing constraints but may not be optimal fortasks requiring high representation capacity. We propose a novel spectrum-awareadaptation framework for generative models. Our method adjusts both singularvalues and their basis vectors of pretrained weights. Using the Kroneckerproduct and efficient Stiefel optimizers, we achieve parameter-efficientadaptation of orthogonal matrices. We introduce Spectral OrthogonalDecomposition Adaptation (SODA), which balances computational efficiency andrepresentation capacity. Extensive evaluations on text-to-image diffusionmodels demonstrate SODA's effectiveness, offering a spectrum-aware alternativeto existing fine-tuning methods.</description><author>Xinxi Zhang, Song Wen, Ligong Han, Felix Juefei-Xu, Akash Srivastava, Junzhou Huang, Hao Wang, Molei Tao, Dimitris N. Metaxas</author><pubDate>Fri, 31 May 2024 18:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21050v1</guid></item><item><title>Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling</title><link>http://arxiv.org/abs/2405.21048v1</link><description>Diffusion models have emerged as a powerful tool for generating high-qualityimages from textual descriptions. Despite their successes, these models oftenexhibit limited diversity in the sampled images, particularly when samplingwith a high classifier-free guidance weight. To address this issue, we presentKaleido, a novel approach that enhances the diversity of samples byincorporating autoregressive latent priors. Kaleido integrates anautoregressive language model that encodes the original caption and generateslatent variables, serving as abstract and intermediary representations forguiding and facilitating the image generation process. In this paper, weexplore a variety of discrete latent representations, including textualdescriptions, detection bounding boxes, object blobs, and visual tokens. Theserepresentations diversify and enrich the input conditions to the diffusionmodels, enabling more diverse outputs. Our experimental results demonstratethat Kaleido effectively broadens the diversity of the generated image samplesfrom a given textual description while maintaining high image quality.Furthermore, we show that Kaleido adheres closely to the guidance provided bythe generated latent variables, demonstrating its capability to effectivelycontrol and direct the image generation process.</description><author>Jiatao Gu, Ying Shen, Shuangfei Zhai, Yizhe Zhang, Navdeep Jaitly, Joshua M. Susskind</author><pubDate>Fri, 31 May 2024 18:41:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21048v1</guid></item><item><title>Grammar-Aligned Decoding</title><link>http://arxiv.org/abs/2405.21047v1</link><description>Large Language Models (LLMs) struggle with reliably generating highlystructured outputs, such as program code, mathematical formulas, or well-formedmarkup. Constrained decoding approaches mitigate this problem by greedilyrestricting what tokens an LLM can output at each step to guarantee that theoutput matches a given constraint. Specifically, in grammar-constraineddecoding (GCD), the LLM's output must follow a given grammar. In this paper wedemonstrate that GCD techniques (and in general constrained decodingtechniques) can distort the LLM's distribution, leading to outputs that aregrammatical but appear with likelihoods that are not proportional to the onesgiven by the LLM, and so ultimately are low-quality. We call the problem ofaligning sampling with a grammar constraint, grammar-aligned decoding (GAD),and propose adaptive sampling with approximate expected futures (ASAp), adecoding algorithm that guarantees the output to be grammatical while provablyproducing outputs that match the conditional probability of the LLM'sdistribution conditioned on the given grammar constraint. Our algorithm usesprior sample outputs to soundly overapproximate the future grammaticality ofdifferent output prefixes. Our evaluation on code generation and structured NLPtasks shows how ASAp often produces outputs with higher likelihood (accordingto the LLM's distribution) than existing GCD techniques, while still enforcingthe desired grammatical constraints.</description><author>Kanghee Park, Jiayu Wang, Taylor Berg-Kirkpatrick, Nadia Polikarpova, Loris D'Antoni</author><pubDate>Fri, 31 May 2024 18:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21047v1</guid></item><item><title>Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF</title><link>http://arxiv.org/abs/2405.21046v1</link><description>Reinforcement learning from human feedback (RLHF) has emerged as a centraltool for language model alignment. We consider online exploration in RLHF,which exploits interactive access to human or AI feedback by deliberatelyencouraging the model to produce diverse, maximally informative responses. Byallowing RLHF to confidently stray from the pre-trained model, onlineexploration offers the possibility of novel, potentially super-humancapabilities, but its full potential as a paradigm for language model traininghas yet to be realized, owing to computational and statistical bottlenecks indirectly adapting existing reinforcement learning techniques. We propose a newalgorithm for online exploration in RLHF, Exploratory Preference Optimization(XPO), which is simple and practical -- a one-line change to (online) DirectPreference Optimization (DPO; Rafailov et al., 2023) -- yet enjoys thestrongest known provable guarantees and promising empirical performance. XPOaugments the DPO objective with a novel and principled exploration bonus,empowering the algorithm to explore outside the support of the initial modeland human feedback data. In theory, we show that XPO is provablysample-efficient and converges to a near-optimal language model policy undernatural exploration conditions, irrespective of whether the initial model hasgood coverage. Our analysis, which builds on the observation that DPOimplicitly performs a form of $Q^{\star}$-approximation (or, Bellman errorminimization), combines previously disparate techniques from language modelingand theoretical reinforcement learning in a serendipitous fashion through theperspective of KL-regularized Markov decision processes. Empirically, we findthat XPO is more sample-efficient than non-exploratory DPO variants in apreliminary evaluation.</description><author>Tengyang Xie, Dylan J. Foster, Akshay Krishnamurthy, Corby Rosset, Ahmed Awadallah, Alexander Rakhlin</author><pubDate>Fri, 31 May 2024 18:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21046v1</guid></item><item><title>SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning</title><link>http://arxiv.org/abs/2404.18239v2</link><description>Large Language Models (LLMs) have highlighted the necessity of effectiveunlearning mechanisms to comply with data regulations and ethical AI practices.LLM unlearning aims at removing undesired data influences and associated modelcapabilities without compromising utility out of the scope of unlearning. Whileinterest in studying LLM unlearning is growing,the impact of the optimizerchoice for LLM unlearning remains under-explored. In this work, we shed lighton the significance of optimizer selection in LLM unlearning for the firsttime, establishing a clear connection between {second-order optimization} andinfluence unlearning (a classical approach using influence functions to updatethe model for data influence removal). This insight propels us to develop asecond-order unlearning framework, termed SOUL, built upon the second-orderclipped stochastic optimization (Sophia)-based LLM training method. SOULextends the static, one-shot model update using influence unlearning to adynamic, iterative unlearning process. Our extensive experiments show that SOULconsistently outperforms conventional first-order methods across variousunlearning tasks, models, and metrics, suggesting the promise of second-orderoptimization in providing a scalable and easily implementable solution for LLMunlearning.</description><author>Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu</author><pubDate>Fri, 31 May 2024 18:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18239v2</guid></item><item><title>An Attention-Based Multi-Context Convolutional Encoder-Decoder Neural Network for Work Zone Traffic Impact Prediction</title><link>http://arxiv.org/abs/2405.21045v1</link><description>Work zone is one of the major causes of non-recurrent traffic congestion androad incidents. Despite the significance of its impact, studies on predictingthe traffic impact of work zones remain scarce. In this paper, we propose adata integration pipeline that enhances the utilization of work zone andtraffic data from diversified platforms, and introduce a novel deep learningmodel to predict the traffic speed and incident likelihood during planned workzone events. The proposed model transforms traffic patterns into 2D space-timeimages for both model input and output and employs an attention-basedmulti-context convolutional encoder-decoder architecture to capture thespatial-temporal dependencies between work zone events and traffic variations.Trained and validated on four years of archived work zone traffic data fromMaryland, USA, the model demonstrates superior performance over baseline modelsin predicting traffic speed, incident likelihood, and inferred trafficattributes such as queue length and congestion timings (i.e., start time andduration). Specifically, the proposed model outperforms the baseline models byreducing the prediction error of traffic speed by 5% to 34%, queue length by11% to 29%, congestion timing by 6% to 17%, and increasing the accuracy ofincident predictions by 5% to 7%. Consequently, this model offers substantialpromise for enhancing the planning and traffic management of work zones.</description><author>Qinhua Jiang, Xishun Liao, Yaofa Gong, Jiaqi Ma</author><pubDate>Fri, 31 May 2024 18:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21045v1</guid></item><item><title>Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation</title><link>http://arxiv.org/abs/2405.21043v1</link><description>We prove that the combination of a target network and over-parameterizedlinear function approximation establishes a weaker convergence condition forbootstrapped value estimation in certain cases, even with off-policy data. Ourcondition is naturally satisfied for expected updates over the entirestate-action space or learning with a batch of complete trajectories fromepisodic Markov decision processes. Notably, using only a target network or anover-parameterized model does not provide such a convergence guarantee.Additionally, we extend our results to learning with truncated trajectories,showing that convergence is achievable for all tasks with minor modifications,akin to value truncation for the final states in trajectories. Our primaryresult focuses on temporal difference estimation for prediction, providinghigh-probability value estimation error bounds and empirical analysis onBaird's counterexample and a Four-room task. Furthermore, we explore thecontrol setting, demonstrating that similar convergence conditions apply toQ-learning.</description><author>Fengdi Che, Chenjun Xiao, Jincheng Mei, Bo Dai, Ramki Gummadi, Oscar A Ramirez, Christopher K Harris, A. Rupam Mahmood, Dale Schuurmans</author><pubDate>Fri, 31 May 2024 18:36:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21043v1</guid></item><item><title>Comparing information content of representation spaces for disentanglement with VAE ensembles</title><link>http://arxiv.org/abs/2405.21042v1</link><description>Disentanglement is the endeavour to use machine learning to divideinformation about a dataset into meaningful fragments. In practice thesefragments are representation (sub)spaces, often the set of channels in thelatent space of a variational autoencoder (VAE). Assessments of disentanglementpredominantly employ metrics that are coarse-grained at the model level, butthis approach can obscure much about the process of information fragmentation.Here we propose to study the learned channels in aggregate, as the fragments ofinformation learned by an ensemble of repeat training runs. Additionally, wedepart from prior work where measures of similarity between individualsubspaces neglected the nature of data embeddings as probability distributions.Instead, we view representation subspaces as communication channels thatperform a soft clustering of the data; consequently, we generalize two classicinformation-theoretic measures of similarity between clustering assignments tocompare representation spaces. We develop a lightweight method of estimationbased on fingerprinting representation subspaces by their ability todistinguish dataset samples, allowing us to identify, analyze, and leveragemeaningful structure in ensembles of VAEs trained on synthetic and naturaldatasets. Using this fully unsupervised pipeline we identify "hotspots" in thespace of information fragments: groups of nearly identical representationsubspaces that appear repeatedly in an ensemble of VAEs, particularly asregularization is increased. Finally, we leverage the proposed methodology toachieve ensemble learning with VAEs, boosting the information content of a setof weak learners -- a capability not possible with previous methods ofassessing channel similarity.</description><author>Kieran A. Murphy, Sam Dillavou, Dani S. Bassett</author><pubDate>Fri, 31 May 2024 18:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21042v1</guid></item><item><title>API Pack: A Massive Multi-Programming Language Dataset for API Call Generation</title><link>http://arxiv.org/abs/2402.09615v3</link><description>We introduce API Pack, a massive multi-programming language datasetcontaining more than 1 million instruction-API call pairs to improve the APIcall generation capabilities of large language models. By fine-tuningCodeLlama-13B on 20,000 Python instances from API Pack, we achieved around 10%and 5% higher accuracy compared to GPT-3.5 and GPT-4, respectively, ingenerating unseen API calls. Fine-tuning on API Pack enables cross-programminglanguage generalization by leveraging a large amount of data in one languageand small amounts of data from other languages. Scaling the training data to 1million instances further improves the model's generalization to new APIs notencountered during training. We open-source the API Pack dataset, trainedmodels, and associated source code at https://github.com/zguo0525/API-Pack tofacilitate further research.</description><author>Zhen Guo, Adriana Meza Soria, Wei Sun, Yikang Shen, Rameswar Panda</author><pubDate>Fri, 31 May 2024 18:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09615v3</guid></item><item><title>Direct Alignment of Language Models via Quality-Aware Self-Refinement</title><link>http://arxiv.org/abs/2405.21040v1</link><description>Reinforcement Learning from Human Feedback (RLHF) has been commonly used toalign the behaviors of Large Language Models (LLMs) with human preferences.Recently, a popular alternative is Direct Policy Optimization (DPO), whichreplaces an LLM-based reward model with the policy itself, thus obviating theneed for extra memory and training time to learn the reward model. However, DPOdoes not consider the relative qualities of the positive and negativeresponses, and can lead to sub-optimal training outcomes. To alleviate thisproblem, we investigate the use of intrinsic knowledge within the on-the-flyfine-tuning LLM to obtain relative qualities and help to refine the lossfunction. Specifically, we leverage the knowledge of the LLM to design arefinement function to estimate the quality of both the positive and negativeresponses. We show that the constructed refinement function can helpself-refine the loss function under mild assumptions. The refinement functionis integrated into DPO and its variant Identity Policy Optimization (IPO).Experiments across various evaluators indicate that they can improve theperformance of the fine-tuned models over DPO and IPO.</description><author>Runsheng Yu, Yong Wang, Xiaoqi Jiao, Youzhi Zhang, James T. Kwok</author><pubDate>Fri, 31 May 2024 18:31:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21040v1</guid></item><item><title>II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering</title><link>http://arxiv.org/abs/2402.11058v2</link><description>Visual Question Answering (VQA) often involves diverse reasoning scenariosacross Vision and Language (V&amp;L). Most prior VQA studies, however, have merelyfocused on assessing the model's overall accuracy without evaluating it ondifferent reasoning cases. Furthermore, some recent works observe thatconventional Chain-of-Thought (CoT) prompting fails to generate effectivereasoning for VQA, especially for complex scenarios requiring multi-hopreasoning. In this paper, we propose II-MMR, a novel idea to identify andimprove multi-modal multi-hop reasoning in VQA. In specific, II-MMR takes a VQAquestion with an image and finds a reasoning path to reach its answer using twonovel language promptings: (i) answer prediction-guided CoT prompt, or (ii)knowledge triplet-guided prompt. II-MMR then analyzes this path to identifydifferent reasoning cases in current VQA benchmarks by estimating how many hopsand what types (i.e., visual or beyond-visual) of reasoning are required toanswer the question. On popular benchmarks including GQA and A-OKVQA, II-MMRobserves that most of their VQA questions are easy to answer, simply demanding"single-hop" reasoning, whereas only a few questions require "multi-hop"reasoning. Moreover, while the recent V&amp;L model struggles with such complexmulti-hop reasoning questions even using the traditional CoT method, II-MMRshows its effectiveness across all reasoning cases in both zero-shot andfine-tuning settings.</description><author>Jihyung Kil, Farideh Tavazoee, Dongyeop Kang, Joo-Kyung Kim</author><pubDate>Fri, 31 May 2024 18:30:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11058v2</guid></item><item><title>Introducing sgboost: A Practical Guide and Implementation of sparse-group boosting in R</title><link>http://arxiv.org/abs/2405.21037v1</link><description>This paper introduces the sgboost package in R, which implements sparse-groupboosting for modeling high-dimensional data with natural groupings incovariates. Sparse-group boosting offers a flexible approach for both group andindividual variable selection, reducing overfitting and enhancing modelinterpretability. The package uses regularization techniques based on thedegrees of freedom of individual and group base-learners, and is designed to beused in conjunction with the mboost package. Through comparisons with existingmethods and demonstration of its unique functionalities, this paper provides apractical guide on utilizing sparse-group boosting in R, accompanied by codeexamples to facilitate its application in various research domains. Overall,this paper serves as a valuable resource for researchers and practitionersseeking to use sparse-group boosting for efficient and interpretablehigh-dimensional data analysis.</description><author>Fabian Obster, Christian Heumann</author><pubDate>Fri, 31 May 2024 18:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21037v1</guid></item><item><title>A-PETE: Adaptive Prototype Explanations of Tree Ensembles</title><link>http://arxiv.org/abs/2405.21036v1</link><description>The need for interpreting machine learning models is addressed throughprototype explanations within the context of tree ensembles. An algorithm namedAdaptive Prototype Explanations of Tree Ensembles (A-PETE) is proposed toautomatise the selection of prototypes for these classifiers. Its uniquecharacteristics is using a specialised distance measure and a modified k-medoidapproach. Experiments demonstrated its competitive predictive accuracy withrespect to earlier explanation algorithms. It also provides a a sufficientnumber of prototypes for the purpose of interpreting the random forestclassifier.</description><author>Jacek Karolczak, Jerzy Stefanowski</author><pubDate>Fri, 31 May 2024 18:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21036v1</guid></item><item><title>Standards for Belief Representations in LLMs</title><link>http://arxiv.org/abs/2405.21030v1</link><description>As large language models (LLMs) continue to demonstrate remarkable abilitiesacross various domains, computer scientists are developing methods tounderstand their cognitive processes, particularly concerning how (and if) LLMsinternally represent their beliefs about the world. However, this fieldcurrently lacks a unified theoretical foundation to underpin the study ofbelief in LLMs. This article begins filling this gap by proposing adequacyconditions for a representation in an LLM to count as belief-like. We arguethat, while the project of belief measurement in LLMs shares striking featureswith belief measurement as carried out in decision theory and formalepistemology, it also differs in ways that should change how we measure belief.Thus, drawing from insights in philosophy and contemporary practices of machinelearning, we establish four criteria that balance theoretical considerationswith practical constraints. Our proposed criteria include accuracy, coherence,uniformity, and use, which together help lay the groundwork for a comprehensiveunderstanding of belief representation in LLMs. We draw on empirical workshowing the limitations of using various criteria in isolation to identifybelief representations.</description><author>Daniel A. Herrmann, Benjamin A. Levinstein</author><pubDate>Fri, 31 May 2024 18:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21030v1</guid></item><item><title>An Accelerated Gradient Method for Convex Smooth Simple Bilevel Optimization</title><link>http://arxiv.org/abs/2402.08097v2</link><description>In this paper, we focus on simple bilevel optimization problems, where weminimize a convex smooth objective function over the optimal solution set ofanother convex smooth constrained optimization problem. We present a novelbilevel optimization method that locally approximates the solution set of thelower-level problem using a cutting plane approach and employs an acceleratedgradient-based update to reduce the upper-level objective function over theapproximated solution set. We measure the performance of our method in terms ofsuboptimality and infeasibility errors and provide non-asymptotic convergenceguarantees for both error criteria. Specifically, when the feasible set iscompact, we show that our method requires at most$\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$ iterations to find asolution that is $\epsilon_f$-suboptimal and $\epsilon_g$-infeasible. Moreover,under the additional assumption that the lower-level objective satisfies the$r$-th H\"olderian error bound, we show that our method achieves an iterationcomplexity of$\mathcal{O}(\max\{\epsilon_{f}^{-\frac{2r-1}{2r}},\epsilon_{g}^{-\frac{2r-1}{2r}}\})$,which matches the optimal complexity of single-level convex constrainedoptimization when $r=1$.</description><author>Jincheng Cao, Ruichen Jiang, Erfan Yazdandoost Hamedani, Aryan Mokhtari</author><pubDate>Fri, 31 May 2024 18:20:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08097v2</guid></item><item><title>Collective Variable Free Transition Path Sampling with Generative Flow Network</title><link>http://arxiv.org/abs/2405.19961v2</link><description>Understanding transition paths between meta-stable states in molecularsystems is fundamental for material design and drug discovery. However,sampling these paths via molecular dynamics simulations is computationallyprohibitive due to the high-energy barriers between the meta-stable states.Recent machine learning approaches are often restricted to simple systems orrely on collective variables (CVs) extracted from expensive domain knowledge.In this work, we propose to leverage generative flow networks (GFlowNets) tosample transition paths without relying on CVs. We reformulate the problem asamortized energy-based sampling over molecular trajectories and train a biaspotential by minimizing the squared log-ratio between the target distributionand the generator, derived from the flow matching objective of GFlowNets. Ourevaluation on three proteins (Alanine Dipeptide, Polyproline, and Chignolin)demonstrates that our approach, called TPS-GFN, generates more realistic anddiverse transition paths than the previous CV-free machine learning approach.</description><author>Kiyoung Seong, Seonghyun Park, Seonghwan Kim, Woo Youn Kim, Sungsoo Ahn</author><pubDate>Fri, 31 May 2024 18:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19961v2</guid></item><item><title>LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models</title><link>http://arxiv.org/abs/2405.21028v1</link><description>When answering questions, LLMs can convey not only an answer, but a level ofconfidence about the answer being correct. This includes explicit confidencemarkers (e.g. giving a numeric score) as well as implicit markers, like anauthoritative tone or elaborating with additional knowledge. For LLMs to betrustworthy knowledge sources, the confidence they convey should match theiractual expertise; however, most current models tend towards overconfidence. Tocalibrate both implicit and explicit confidence markers, we introduce apragmatic, listener-aware finetuning method (LACIE) that models the listener,considering not only whether an answer is right, but whether it will beaccepted by a listener. We cast calibration as preference optimization,creating data via a two-agent game, where a speaker model's outputs are judgedby a simulated listener. We then finetune three LLMs (Mistral-7B, Llama3-8B,Llama3-70B) with LACIE, and show that the resulting models are bettercalibrated w.r.t. a simulated listener. Crucially, these trends transfer tohuman listeners, helping them correctly predict model correctness: we conduct ahuman evaluation where annotators accept or reject an LLM's answers, findingthat training with LACIE results in 47% fewer incorrect answers being acceptedwhile maintaining the same level of acceptance for correct answers.Furthermore, LACIE generalizes to another dataset, resulting in a largeincrease in truthfulness on TruthfulQA when trained on TriviaQA. Our analysisindicates that LACIE leads to a better confidence separation between correctand incorrect examples. Qualitatively, we find that a LACIE-trained modelhedges more and implicitly signals certainty when it is correct by using anauthoritative tone or including details. Finally, LACIE finetuning leads to anemergent increase in model abstention (e.g. saying "I don't know") for answersthat are likely wrong.</description><author>Elias Stengel-Eskin, Peter Hase, Mohit Bansal</author><pubDate>Fri, 31 May 2024 18:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21028v1</guid></item><item><title>Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles</title><link>http://arxiv.org/abs/2405.21027v1</link><description>For solving zero-sum games involving non-transitivity, a common approach isto maintain population policies to approximate the Nash Equilibrium (NE).Previous research has shown that the Policy Space Response Oracle (PSRO) is aneffective multi-agent reinforcement learning framework for these games.However, repeatedly training new policies from scratch to approximate the BestResponse (BR) to opponents' mixed policies at each iteration is inefficient andcostly. While some PSRO methods initialize a new BR policy by inheriting frompast BR policies, this approach limits the exploration of new policies,especially against challenging opponents.To address this issue, we proposeFusion-PSRO, which uses model fusion to initialize the policy for betterapproximation to BR. With Top-k probabilities from NE, we select high-qualitybase policies and fuse them into a new BR policy through model averaging. Thisapproach allows the initialized policy to incorporate multiple expert policies,making it easier to handle difficult opponents compared to inheriting orinitializing from scratch. Additionally, our method only modifies the policyinitialization, enabling its application to nearly all PSRO variants withoutadditional training overhead.Our experiments with non-transitive matrix games,Leduc poker, and the more complex Liars Dice demonstrate that Fusion-PSROenhances the performance of nearly all PSRO variants, achieving lowerexploitability.</description><author>Jiesong Lian, Yucong Huang, Mingzhi Wang, Chengdong Ma, Yixue Hao, Ying Wen, Yaodong Yang</author><pubDate>Fri, 31 May 2024 18:16:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21027v1</guid></item><item><title>Compact Optimality Verification for Optimization Proxies</title><link>http://arxiv.org/abs/2405.21023v1</link><description>Recent years have witnessed increasing interest in optimization proxies,i.e., machine learning models that approximate the input-output mapping ofparametric optimization problems and return near-optimal feasible solutions.Following recent work by (Nellikkath &amp; Chatzivasileiadis, 2021), this paperreconsiders the optimality verification problem for optimization proxies, i.e.,the determination of the worst-case optimality gap over the instancedistribution. The paper proposes a compact formulation for optimalityverification and a gradient-based primal heuristic that brings substantialcomputational benefits to the original formulation. The compact formulation isalso more general and applies to non-convex optimization problems. The benefitsof the compact formulation are demonstrated on large-scale DC Optimal PowerFlow and knapsack problems.</description><author>Wenbo Chen, Haoruo Zhao, Mathieu Tanneau, Pascal Van Hentenryck</author><pubDate>Fri, 31 May 2024 18:11:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21023v1</guid></item><item><title>You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet</title><link>http://arxiv.org/abs/2405.21022v1</link><description>Linear attention mechanisms have gained prominence in causal language modelsdue to their linear computational complexity and enhanced speed. However, theinherent decay mechanism in linear attention presents challenges when appliedto multi-dimensional sequence modeling tasks, such as image processing andmulti-modal learning. In these scenarios, the utilization of sequentialscanning to establish a global receptive field necessitates multiple scans formulti-dimensional data, thereby leading to inefficiencies. This paperidentifies the inefficiency caused by a multiplicative linear recurrence andproposes an efficient alternative additive linear recurrence to avoid theissue, as it can handle multi-dimensional data within a single scan. We furtherdevelop an efficient multi-dimensional sequential modeling framework calledLightNet based on the new recurrence. Moreover, we present two newmulti-dimensional linear relative positional encoding methods, MD-TPE andMD-LRPE to enhance the model's ability to discern positional information inmulti-dimensional scenarios. Our empirical evaluations across various tasks,including image classification, image generation, bidirectional languagemodeling, and autoregressive language modeling, demonstrate the efficacy ofLightNet, showcasing its potential as a versatile and efficient solution formulti-dimensional sequential modeling.</description><author>Zhen Qin, Yuxin Mao, Xuyang Shen, Dong Li, Jing Zhang, Yuchao Dai, Yiran Zhong</author><pubDate>Fri, 31 May 2024 18:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21022v1</guid></item><item><title>Beyond Conventional Parametric Modeling: Data-Driven Framework for Estimation and Prediction of Time Activity Curves in Dynamic PET Imaging</title><link>http://arxiv.org/abs/2405.21021v1</link><description>Dynamic Positron Emission Tomography (dPET) imaging and Time-Activity Curve(TAC) analyses are essential for understanding and quantifying thebiodistribution of radiopharmaceuticals over time and space. Traditionalcompartmental modeling, while foundational, commonly struggles to fully capturethe complexities of biological systems, including non-linear dynamics andvariability. This study introduces an innovative data-driven neuralnetwork-based framework, inspired by Reaction Diffusion systems, designed toaddress these limitations. Our approach, which adaptively fits TACs from dPET,enables the direct calibration of diffusion coefficients and reaction termsfrom observed data, offering significant improvements in predictive accuracyand robustness over traditional methods, especially in complex biologicalscenarios. By more accurately modeling the spatio-temporal dynamics ofradiopharmaceuticals, our method advances modeling of pharmacokinetic andpharmacodynamic processes, enabling new possibilities in quantitative nuclearmedicine.</description><author>Niloufar Zakariaei, Arman Rahmim, Eldad Haber</author><pubDate>Fri, 31 May 2024 18:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21021v1</guid></item><item><title>Improved Techniques for Optimization-Based Jailbreaking on Large Language Models</title><link>http://arxiv.org/abs/2405.21018v1</link><description>Large language models (LLMs) are being rapidly developed, and a key componentof their widespread deployment is their safety-related alignment. Manyred-teaming efforts aim to jailbreak LLMs, where among these efforts, theGreedy Coordinate Gradient (GCG) attack's success has led to a growing interestin the study of optimization-based jailbreaking techniques. Although GCG is asignificant milestone, its attacking efficiency remains unsatisfactory. In thispaper, we present several improved (empirical) techniques foroptimization-based jailbreaks like GCG. We first observe that the single targettemplate of "Sure" largely limits the attacking performance of GCG; given this,we propose to apply diverse target templates containing harmful self-suggestionand/or guidance to mislead LLMs. Besides, from the optimization aspects, wepropose an automatic multi-coordinate updating strategy in GCG (i.e.,adaptively deciding how many tokens to replace in each step) to accelerateconvergence, as well as tricks like easy-to-hard initialisation. Then, wecombine these improved technologies to develop an efficient jailbreak method,dubbed $\mathcal{I}$-GCG. In our experiments, we evaluate on a series ofbenchmarks (such as NeurIPS 2023 Red Teaming Track). The results demonstratethat our improved techniques can help GCG outperform state-of-the-artjailbreaking attacks and achieve nearly 100% attack success rate. The code isreleased at https://github.com/jiaxiaojunQAQ/I-GCG.</description><author>Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin</author><pubDate>Fri, 31 May 2024 18:07:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21018v1</guid></item><item><title>Stochastic Online Fisher Markets: Static Pricing Limits and Adaptive Enhancements</title><link>http://arxiv.org/abs/2205.00825v4</link><description>Fisher markets are one of the most fundamental models for resourceallocation. However, the problem of computing equilibrium prices in Fishermarkets typically relies on complete knowledge of users' budgets and utilityfunctions and requires transactions to happen in a static market where allusers are present simultaneously. Motivated by these practical considerations,we study an online variant of Fisher markets, wherein users with privatelyknown utility and budget parameters, drawn i.i.d. from a distribution, arrivesequentially. In this setting, we first study the limitations of static pricingalgorithms, which set uniform prices for all users, along two performancemetrics: (i) regret, i.e., the optimality gap in the objective of theEisenberg-Gale program between an online algorithm and an oracle with completeinformation, and (ii) capacity violations, i.e., the over-consumption of goodsrelative to their capacities. Given the limitations of static pricing, wedesign adaptive posted-pricing algorithms, one with knowledge of thedistribution of users' budget and utility parameters and another that adjustsprices solely based on past observations of user consumption, i.e., revealedpreference feedback, with improved performance guarantees. Finally, we presentnumerical experiments to compare our revealed preference algorithm'sperformance to several benchmarks.</description><author>Devansh Jalota, Yinyu Ye</author><pubDate>Fri, 31 May 2024 18:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.00825v4</guid></item><item><title>MpoxSLDNet: A Novel CNN Model for Detecting Monkeypox Lesions and Performance Comparison with Pre-trained Models</title><link>http://arxiv.org/abs/2405.21016v1</link><description>Monkeypox virus (MPXV) is a zoonotic virus that poses a significant threat topublic health, particularly in remote parts of Central and West Africa. Earlydetection of monkeypox lesions is crucial for effective treatment. However, dueto its similarity with other skin diseases, monkeypox lesion detection is achallenging task. To detect monkeypox, many researchers used variousdeep-learning models such as MobileNetv2, VGG16, ResNet50, InceptionV3,DenseNet121, EfficientNetB3, MobileNetV2, and Xception. However, these modelsoften require high storage space due to their large size. This study aims toimprove the existing challenges by introducing a CNN model named MpoxSLDNet(Monkeypox Skin Lesion Detector Network) to facilitate early detection andcategorization of Monkeypox lesions and Non-Monkeypox lesions in digitalimages. Our model represents a significant advancement in the field ofmonkeypox lesion detection by offering superior performance metrics, includingprecision, recall, F1-score, accuracy, and AUC, compared to traditionalpre-trained models such as VGG16, ResNet50, and DenseNet121. The key novelty ofour approach lies in MpoxSLDNet's ability to achieve high detection accuracywhile requiring significantly less storage space than existing models. Byaddressing the challenge of high storage requirements, MpoxSLDNet presents apractical solution for early detection and categorization of monkeypox lesionsin resource-constrained healthcare settings. In this study, we have used"Monkeypox Skin Lesion Dataset" comprising 1428 skin images of monkeypoxlesions and 1764 skin images of Non-Monkeypox lesions. Dataset's limitationscould potentially impact the model's ability to generalize to unseen cases.However, the MpoxSLDNet model achieved a validation accuracy of 94.56%,compared to 86.25%, 84.38%, and 67.19% for VGG16, DenseNet121, and ResNet50,respectively.</description><author>Fatema Jannat Dihan, Saydul Akbar Murad, Abu Jafar Md Muzahid, K. M. Aslam Uddin, Mohammed J. F. Alenazi, Anupam Kumar Bairagi, Sujit Biswas</author><pubDate>Fri, 31 May 2024 18:05:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21016v1</guid></item><item><title>Hierarchical World Models as Visual Whole-Body Humanoid Controllers</title><link>http://arxiv.org/abs/2405.18418v2</link><description>Whole-body control for humanoids is challenging due to the high-dimensionalnature of the problem, coupled with the inherent instability of a bipedalmorphology. Learning from visual observations further exacerbates thisdifficulty. In this work, we explore highly data-driven approaches to visualwhole-body humanoid control based on reinforcement learning, without anysimplifying assumptions, reward design, or skill primitives. Specifically, wepropose a hierarchical world model in which a high-level agent generatescommands based on visual observations for a low-level agent to execute, both ofwhich are trained with rewards. Our approach produces highly performant controlpolicies in 8 tasks with a simulated 56-DoF humanoid, while synthesizingmotions that are broadly preferred by humans. Code and videos:https://nicklashansen.com/rlpuppeteer</description><author>Nicklas Hansen, Jyothir S V, Vlad Sobal, Yann LeCun, Xiaolong Wang, Hao Su</author><pubDate>Fri, 31 May 2024 18:03:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18418v2</guid></item><item><title>Mastering Long-Tail Complexity on Graphs: Characterization, Learning, and Generalization</title><link>http://arxiv.org/abs/2305.09938v4</link><description>In the context of long-tail classification on graphs, the vast majority ofexisting work primarily revolves around the development of model debiasingstrategies, intending to mitigate class imbalances and enhance the overallperformance. Despite the notable success, there is very limited literature thatprovides a theoretical tool for characterizing the behaviors of long-tailclasses in graphs and gaining insight into generalization performance inreal-world scenarios. To bridge this gap, we propose a generalization bound forlong-tail classification on graphs by formulating the problem in the fashion ofmulti-task learning, i.e., each task corresponds to the prediction of oneparticular class. Our theoretical results show that the generalizationperformance of long-tail classification is dominated by the overall loss rangeand the task complexity. Building upon the theoretical findings, we propose anovel generic framework HierTail for long-tail classification on graphs. Inparticular, we start with a hierarchical task grouping module that allows us toassign related tasks into hypertasks and thus control the complexity of thetask space; then, we further design a balanced contrastive learning module toadaptively balance the gradients of both head and tail classes to control theloss range across all tasks in a unified fashion. Extensive experimentsdemonstrate the effectiveness of HierTail in characterizing long-tail classeson real graphs, which achieves up to 12.9% improvement over the leadingbaseline method in accuracy.</description><author>Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, Wei Cheng, Si Zhang, Yonghui Fan, Liqing Zhang, Dawei Zhou</author><pubDate>Fri, 31 May 2024 18:02:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09938v4</guid></item><item><title>TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models</title><link>http://arxiv.org/abs/2405.13401v3</link><description>Large language models (LLMs) have raised concerns about potential securitythreats despite performing significantly in Natural Language Processing (NLP).Backdoor attacks initially verified that LLM is doing substantial harm at allstages, but the cost and robustness have been criticized. Attacking LLMs isinherently risky in security review, while prohibitively expensive. Besides,the continuous iteration of LLMs will degrade the robustness of backdoors. Inthis paper, we propose TrojanRAG, which employs a joint backdoor attack in theRetrieval-Augmented Generation, thereby manipulating LLMs in universal attackscenarios. Specifically, the adversary constructs elaborate target contexts andtrigger sets. Multiple pairs of backdoor shortcuts are orthogonally optimizedby contrastive learning, thus constraining the triggering conditions to aparameter subspace to improve the matching. To improve the recall of the RAGfor the target contexts, we introduce a knowledge graph to construct structureddata to achieve hard matching at a fine-grained level. Moreover, we normalizethe backdoor scenarios in LLMs to analyze the real harm caused by backdoorsfrom both attackers' and users' perspectives and further verify whether thecontext is a favorable tool for jailbreaking models. Extensive experimentalresults on truthfulness, language understanding, and harmfulness show thatTrojanRAG exhibits versatility threats while maintaining retrieval capabilitieson normal queries.</description><author>Pengzhou Cheng, Yidong Ding, Tianjie Ju, Zongru Wu, Wei Du, Ping Yi, Zhuosheng Zhang, Gongshen Liu</author><pubDate>Fri, 31 May 2024 17:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13401v3</guid></item><item><title>Modeling User Preferences via Brain-Computer Interfacing</title><link>http://arxiv.org/abs/2405.09691v2</link><description>Present Brain-Computer Interfacing (BCI) technology allows inference anddetection of cognitive and affective states, but fairly little has been done tostudy scenarios in which such information can facilitate new applications thatrely on modeling human cognition. One state that can be quantified from variousphysiological signals is attention. Estimates of human attention can be used toreveal preferences and novel dimensions of user experience. Previous approacheshave tackled these incredibly challenging tasks using a variety of behavioralsignals, from dwell-time to click-through data, and computational models ofvisual correspondence to these behavioral signals. However, behavioral signalsare only rough estimations of the real underlying attention and affectivepreferences of the users. Indeed, users may attend to some content simplybecause it is salient, but not because it is really interesting, or simplybecause it is outrageous. With this paper, we put forward a research agenda andexample work using BCI to infer users' preferences, their attentionalcorrelates towards visual content, and their associations with affectiveexperience. Subsequently, we link these to relevant applications, such asinformation retrieval, personalized steering of generative models, andcrowdsourcing population estimates of affective experiences.</description><author>Luis A. Leiva, V. Javier Traver, Alexandra Kawala-Sterniuk, Tuukka Ruotsalo</author><pubDate>Fri, 31 May 2024 17:57:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09691v2</guid></item><item><title>GAD-Generative Learning for HD Map-Free Autonomous Driving</title><link>http://arxiv.org/abs/2405.00515v3</link><description>Deep-learning-based techniques have been widely adopted for autonomousdriving software stacks for mass production in recent years, focusing primarilyon perception modules, with some work extending this method to predictionmodules. However, the downstream planning and control modules are stilldesigned with hefty handcrafted rules, dominated by optimization-based methodssuch as quadratic programming or model predictive control. This results in aperformance bottleneck for autonomous driving systems in that corner casessimply cannot be solved by enumerating hand-crafted rules. We present adeep-learning-based approach that brings prediction, decision, and planningmodules together with the attempt to overcome the rule-based methods'deficiency in real-world applications of autonomous driving, especially forurban scenes. The DNN model we proposed is solely trained with 10 hours ofhuman driver data, and it supports all mass-production ADAS features availableon the market to date. This method is deployed onto a Jiyue test car with nomodification to its factory-ready sensor set and compute platform. thefeasibility, usability, and commercial potential are demonstrated in thisarticle.</description><author>Weijian Sun, Yanbo Jia, Qi Zeng, Zihao Liu, Jiang Liao, Yue Li, Xianfeng Li</author><pubDate>Fri, 31 May 2024 17:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00515v3</guid></item><item><title>StrucTexTv3: An Efficient Vision-Language Model for Text-rich Image Perception, Comprehension, and Beyond</title><link>http://arxiv.org/abs/2405.21013v1</link><description>Text-rich images have significant and extensive value, deeply integrated intovarious aspects of human life. Notably, both visual cues and linguistic symbolsin text-rich images play crucial roles in information transmission but areaccompanied by diverse challenges. Therefore, the efficient and effectiveunderstanding of text-rich images is a crucial litmus test for the capabilityof Vision-Language Models. We have crafted an efficient vision-language model,StrucTexTv3, tailored to tackle various intelligent tasks for text-rich images.The significant design of StrucTexTv3 is presented in the following aspects:Firstly, we adopt a combination of an effective multi-scale reduced visualtransformer and a multi-granularity token sampler (MG-Sampler) as a visualtoken generator, successfully solving the challenges of high-resolution inputand complex representation learning for text-rich images. Secondly, we enhancethe perception and comprehension abilities of StrucTexTv3 through instructionlearning, seamlessly integrating various text-oriented tasks into a unifiedframework. Thirdly, we have curated a comprehensive collection of high-qualitytext-rich images, abbreviated as TIM-30M, encompassing diverse scenarios likeincidental scenes, office documents, web pages, and screenshots, therebyimproving the robustness of our model. Our method achieved SOTA results intext-rich image perception tasks, and significantly improved performance incomprehension tasks. Among multimodal models with LLM decoder of approximately1.8B parameters, it stands out as a leader, which also makes the deployment ofedge devices feasible. In summary, the StrucTexTv3 model, featuring efficientstructural design, outstanding performance, and broad adaptability, offersrobust support for diverse intelligent application tasks involving text-richimages, thus exhibiting immense potential for widespread application.</description><author>Pengyuan Lyu, Yulin Li, Hao Zhou, Weihong Ma, Xingyu Wan, Qunyi Xie, Liang Wu, Chengquan Zhang, Kun Yao, Errui Ding, Jingdong Wang</author><pubDate>Fri, 31 May 2024 17:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21013v1</guid></item><item><title>G-Transformer for Conditional Average Potential Outcome Estimation over Time</title><link>http://arxiv.org/abs/2405.21012v1</link><description>Estimating potential outcomes for treatments over time based on observationaldata is important for personalized decision-making in medicine. Yet, existingneural methods for this task suffer from either (a) bias or (b) large variance.In order to address both limitations, we introduce the G-transformer (GT). OurGT is a novel, neural end-to-end model designed for unbiased, low-varianceestimation of conditional average potential outcomes (CAPOs) over time.Specifically, our GT is the first neural model to perform regression-basediterative G-computation for CAPOs in the time-varying setting. We evaluate theeffectiveness of our GT across various experiments. In sum, this workrepresents a significant step towards personalized decision-making fromelectronic health records.</description><author>Konstantin Hess, Dennis Frauen, Valentyn Melnychuk, Stefan Feuerriegel</author><pubDate>Fri, 31 May 2024 17:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21012v1</guid></item><item><title>Explaining Explanations in Probabilistic Logic Programming</title><link>http://arxiv.org/abs/2401.17045v3</link><description>The emergence of tools based on artificial intelligence has also led to theneed of producing explanations which are understandable by a human being. Inmost approaches, the system is considered a black box, making it difficult togenerate appropriate explanations. In this work, though, we consider a settingwhere models are transparent: probabilistic logic programming (PLP), a paradigmthat combines logic programming for knowledge representation and probability tomodel uncertainty. However, given a query, the usual notion of explanation isassociated with a set of choices, one for each random variable of the model.Unfortunately, such a set does not explain why the query is true and, in fact,it may contain choices that are actually irrelevant for the considered query.To improve this situation, we present in this paper an approach to explainingexplanations which is based on defining a new query-driven inference mechanismfor PLP where proofs are labeled with "choice expressions", a compact and easyto manipulate representation for sets of choices. The combination of prooftrees and choice expressions allows us to produce comprehensible queryjustifications with a causal structure.</description><author>Germn Vidal</author><pubDate>Fri, 31 May 2024 17:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17045v3</guid></item><item><title>Explaining Predictions by Characteristic Rules</title><link>http://arxiv.org/abs/2405.21003v1</link><description>Characteristic rules have been advocated for their ability to improveinterpretability over discriminative rules within the area of rule learning.However, the former type of rule has not yet been used by techniques forexplaining predictions. A novel explanation technique, called CEGA(Characteristic Explanatory General Association rules), is proposed, whichemploys association rule mining to aggregate multiple explanations generated byany standard local explanation technique into a set of characteristic rules. Anempirical investigation is presented, in which CEGA is compared to twostate-of-the-art methods, Anchors and GLocalX, for producing local andaggregated explanations in the form of discriminative rules. The resultssuggest that the proposed approach provides a better trade-off between fidelityand complexity compared to the two state-of-the-art approaches; CEGA andAnchors significantly outperform GLocalX with respect to fidelity, while CEGAand GLocalX significantly outperform Anchors with respect to the number ofgenerated rules. The effect of changing the format of the explanations of CEGAto discriminative rules and using LIME and SHAP as local explanation techniquesinstead of Anchors are also investigated. The results show that thecharacteristic explanatory rules still compete favorably with rules in thestandard discriminative format. The results also indicate that using CEGA incombination with either SHAP or Anchors consistently leads to a higher fidelitycompared to using LIME as the local explanation technique.</description><author>Amr Alkhatib, Henrik Bostrm, Michalis Vazirgiannis</author><pubDate>Fri, 31 May 2024 17:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21003v1</guid></item><item><title>URDFormer: A Pipeline for Constructing Articulated Simulation Environments from Real-World Images</title><link>http://arxiv.org/abs/2405.11656v3</link><description>Constructing simulation scenes that are both visually and physicallyrealistic is a problem of practical interest in domains ranging from roboticsto computer vision. This problem has become even more relevant as researcherswielding large data-hungry learning methods seek new sources of training datafor physical decision-making systems. However, building simulation models isoften still done by hand. A graphic designer and a simulation engineer workwith predefined assets to construct rich scenes with realistic dynamic andkinematic properties. While this may scale to small numbers of scenes, toachieve the generalization properties that are required for data-driven roboticcontrol, we require a pipeline that is able to synthesize large numbers ofrealistic scenes, complete with 'natural' kinematic and dynamic structures. Toattack this problem, we develop models for inferring structure and generatingsimulation scenes from natural images, allowing for scalable scene generationfrom web-scale datasets. To train these image-to-simulation models, we show howcontrollable text-to-image generative models can be used in generating pairedtraining data that allows for modeling of the inverse problem, mapping fromrealistic images back to complete scene models. We show how this paradigmallows us to build large datasets of scenes in simulation with semantic andphysical realism. We present an integrated end-to-end pipeline that generatessimulation scenes complete with articulated kinematic and dynamic structuresfrom real-world images and use these for training robotic control policies. Wethen robustly deploy in the real world for tasks like articulated objectmanipulation. In doing so, our work provides both a pipeline for large-scalegeneration of simulation environments and an integrated system for trainingrobust robotic control policies in the resulting environments.</description><author>Zoey Chen, Aaron Walsman, Marius Memmel, Kaichun Mo, Alex Fang, Karthikeya Vemuri, Alan Wu, Dieter Fox, Abhishek Gupta</author><pubDate>Fri, 31 May 2024 17:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11656v3</guid></item><item><title>Towards a Fluid computer</title><link>http://arxiv.org/abs/2405.20999v1</link><description>In 1991, Moore [20] raised a question about whether hydrodynamics is capableof performing computations. Similarly, in 2016, Tao [25] asked whether amechanical system, including a fluid flow, can simulate a universal Turingmachine. In this expository article, we review the construction in [8] of a"Fluid computer" in dimension 3 that combines techniques in symbolic dynamicswith the connection between steady Euler flows and contact geometry unveiled byEtnyre and Ghrist. In addition, we argue that the metric that renders thevector field Beltrami cannot be critical in the Chern-Hamilton sense [9]. Wealso sketch the completely different construction for the Euclidean metric in$\mathbb R^3$ as given in [7]. These results reveal the existence ofundecidable fluid particle paths. We conclude the article with a list of openproblems.</description><author>Robert Cardona, Eva Miranda, Daniel Peralta-Salas</author><pubDate>Fri, 31 May 2024 17:41:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20999v1</guid></item><item><title>Active Inference and Reinforcement Learning: A unified inference on continuous state and action spaces under partial observability</title><link>http://arxiv.org/abs/2212.07946v3</link><description>Reinforcement learning (RL) has garnered significant attention for developingdecision-making agents that aim to maximize rewards, specified by an externalsupervisor, within fully observable environments. However, many real-worldproblems involve partial observations, formulated as partially observableMarkov decision processes (POMDPs). Previous studies have tackled RL in POMDPsby either incorporating the memory of past actions and observations or byinferring the true state of the environment from observed data. However,aggregating observed data over time becomes impractical in continuous spaces.Moreover, inference-based RL approaches often require many samples to performwell, as they focus solely on reward maximization and neglect uncertainty inthe inferred state. Active inference (AIF) is a framework formulated in POMDPsand directs agents to select actions by minimizing a function called expectedfree energy (EFE). This supplies reward-maximizing (exploitative) behaviour, asin RL, with information-seeking (exploratory) behaviour. Despite thisexploratory behaviour of AIF, its usage is limited to discrete spaces due tothe computational challenges associated with EFE. In this paper, we propose aunified principle that establishes a theoretical connection between AIF and RL,enabling seamless integration of these two approaches and overcoming theiraforementioned limitations in continuous space POMDP settings. We substantiateour findings with theoretical analysis, providing novel perspectives forutilizing AIF in the design of artificial agents. Experimental resultsdemonstrate the superior learning capabilities of our method in solvingcontinuous space partially observable tasks. Notably, our approach harnessesinformation-seeking exploration, enabling it to effectively solve reward-freeproblems and rendering explicit task reward design by an external supervisoroptional.</description><author>Parvin Malekzadeh, Konstantinos N. Plataniotis</author><pubDate>Fri, 31 May 2024 17:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07946v3</guid></item><item><title>CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to Web Relevance Ranking</title><link>http://arxiv.org/abs/2405.20994v1</link><description>We present CWRCzech, Click Web Ranking dataset for Czech, a 100Mquery-document Czech click dataset for relevance ranking with user behaviordata collected from search engine logs of Seznam.cz. To the best of ourknowledge, CWRCzech is the largest click dataset with raw text published sofar. It provides document positions in the search results as well asinformation about user behavior: 27.6M clicked documents and 10.8M dwell times.In addition, we also publish a manually annotated Czech test for the relevancetask, containing nearly 50k query-document pairs, each annotated by at least 2annotators. Finally, we analyze how the user behavior data improve relevanceranking and show that models trained on data automatically harnessed atsufficient scale can surpass the performance of models trained on humanannotated data. CWRCzech is published under an academic non-commercial licenseand is available to the research community athttps://github.com/seznam/CWRCzech.</description><author>Josef Vonek, Milan Straka, Rostislav Kr, Lenka Lasoov, Ekaterina Egorova, Jana Strakov, Jakub Nplava</author><pubDate>Fri, 31 May 2024 17:38:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20994v1</guid></item><item><title>Information limits and Thouless-Anderson-Palmer equations for spiked matrix models with structured noise</title><link>http://arxiv.org/abs/2405.20993v1</link><description>We consider a prototypical problem of Bayesian inference for a structuredspiked model: a low-rank signal is corrupted by additive noise. While bothinformation-theoretic and algorithmic limits are well understood when the noiseis i.i.d. Gaussian, the more realistic case of structured noise still proves tobe challenging. To capture the structure while maintaining mathematicaltractability, a line of work has focused on rotationally invariant noise.However, existing studies either provide sub-optimal algorithms or they arelimited to a special class of noise ensembles. In this paper, we establish thefirst characterization of the information-theoretic limits for a noise matrixdrawn from a general trace ensemble. These limits are then achieved by anefficient algorithm inspired by the theory of adaptive Thouless-Anderson-Palmer(TAP) equations. Our approach leverages tools from statistical physics (replicamethod) and random matrix theory (generalized spherical integrals), and itunveils the equivalence between the rotationally invariant model and asurrogate Gaussian model.</description><author>Jean Barbier, Francesco Camilli, Marco Mondelli, Yizhou Xu</author><pubDate>Fri, 31 May 2024 17:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20993v1</guid></item><item><title>Calibrated Self-Rewarding Vision Language Models</title><link>http://arxiv.org/abs/2405.14622v3</link><description>Large Vision-Language Models (LVLMs) have made substantial progress byintegrating pre-trained large language models (LLMs) and vision models throughinstruction tuning. Despite these advancements, LVLMs often exhibit thehallucination phenomenon, where generated text responses appear linguisticallyplausible but contradict the input image, indicating a misalignment betweenimage and text pairs. This misalignment arises because the model tends toprioritize textual information over visual input, even when both the languagemodel and visual representations are of high quality. Existing methods leverageadditional models or human annotations to curate preference data and enhancemodality alignment through preference optimization. These approaches may noteffectively reflect the target LVLM's preferences, making the curatedpreferences easily distinguishable. Our work addresses these challenges byproposing the Calibrated Self-Rewarding (CSR) approach, which enables the modelto self-improve by iteratively generating candidate responses, evaluating thereward for each response, and curating preference data for fine-tuning. In thereward modeling, we employ a step-wise strategy and incorporate visualconstraints into the self-rewarding process to place greater emphasis on visualinput. Empirical results demonstrate that CSR enhances performance and reduceshallucinations across ten benchmarks and tasks, achieving substantialimprovements over existing methods by 7.62%. Our empirical results are furthersupported by rigorous theoretical analysis, under mild assumptions, verifyingthe effectiveness of introducing visual constraints into the self-rewardingparadigm. Additionally, CSR shows compatibility with different vision-languagemodels and the ability to incrementally improve performance through iterativefine-tuning. Our data and code are available athttps://github.com/YiyangZhou/CSR.</description><author>Yiyang Zhou, Zhiyuan Fan, Dongjie Cheng, Sihan Yang, Zhaorun Chen, Chenhang Cui, Xiyao Wang, Yun Li, Linjun Zhang, Huaxiu Yao</author><pubDate>Fri, 31 May 2024 17:37:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14622v3</guid></item><item><title>Hard Cases Detection in Motion Prediction by Vision-Language Foundation Models</title><link>http://arxiv.org/abs/2405.20991v1</link><description>Addressing hard cases in autonomous driving, such as anomalous road users,extreme weather conditions, and complex traffic interactions, presentssignificant challenges. To ensure safety, it is crucial to detect and managethese scenarios effectively for autonomous driving systems. However, the rarityand high-risk nature of these cases demand extensive, diverse datasets fortraining robust models. Vision-Language Foundation Models (VLMs) have shownremarkable zero-shot capabilities as being trained on extensive datasets. Thiswork explores the potential of VLMs in detecting hard cases in autonomousdriving. We demonstrate the capability of VLMs such as GPT-4v in detecting hardcases in traffic participant motion prediction on both agent and scenariolevels. We introduce a feasible pipeline where VLMs, fed with sequential imageframes with designed prompts, effectively identify challenging agents orscenarios, which are verified by existing prediction models. Moreover, bytaking advantage of this detection of hard cases by VLMs, we further improvethe training efficiency of the existing motion prediction pipeline byperforming data selection for the training samples suggested by GPT. We showthe effectiveness and feasibility of our pipeline incorporating VLMs withstate-of-the-art methods on NuScenes datasets. The code is accessible athttps://github.com/KTH-RPL/Detect_VLM.</description><author>Yi Yang, Qingwen Zhang, Kei Ikemura, Nazre Batool, John Folkesson</author><pubDate>Fri, 31 May 2024 17:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20991v1</guid></item><item><title>Locking Machine Learning Models into Hardware</title><link>http://arxiv.org/abs/2405.20990v1</link><description>Modern Machine Learning models are expensive IP and business competitivenessoften depends on keeping this IP confidential. This in turn restricts how thesemodels are deployed -- for example it is unclear how to deploy a modelon-device without inevitably leaking the underlying model. At the same time,confidential computing technologies such as Multi-Party Computation orHomomorphic encryption remain impractical for wide adoption. In this paper wetake a different approach and investigate feasibility of ML-specific mechanismsthat deter unauthorized model use by restricting the model to only be usable onspecific hardware, making adoption on unauthorized hardware inconvenient. Thatway, even if IP is compromised, it cannot be trivially used without specialisedhardware or major model adjustment. In a sense, we seek to enable cheap lockingof machine learning models into specific hardware. We demonstrate that lockingmechanisms are feasible by either targeting efficiency of modelrepresentations, such making models incompatible with quantisation, or tie themodel's operation on specific characteristics of hardware, such as number ofcycles for arithmetic operations. We demonstrate that locking comes withnegligible work and latency overheads, while significantly restrictingusability of the resultant model on unauthorized hardware.</description><author>Eleanor Clifford, Adhithya Saravanan, Harry Langford, Cheng Zhang, Yiren Zhao, Robert Mullins, Ilia Shumailov, Jamie Hayes</author><pubDate>Fri, 31 May 2024 17:35:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20990v1</guid></item><item><title>Communication-Efficient Distributed Deep Learning via Federated Dynamic Averaging</title><link>http://arxiv.org/abs/2405.20988v1</link><description>Driven by the ever-growing volume and decentralized nature of data, coupledwith the escalating size of modern models, distributed deep learning (DDL) hasbeen entrenched as the preferred paradigm for training. However, frequentsynchronization of DL models, encompassing millions to many billions ofparameters, creates a communication bottleneck, severely hindering scalability.Worse yet, DDL algorithms typically waste valuable bandwidth, and makethemselves less practical in bandwidth-constrained federated settings, byrelying on overly simplistic, periodic, and rigid synchronization schedules. Toaddress these shortcomings, we propose Federated Dynamic Averaging (FDA), acommunication-efficient DDL strategy that dynamically triggers synchronizationbased on the value of the model variance. Through extensive experiments acrossa wide range of learning tasks we demonstrate that FDA reduces communicationcost by orders of magnitude, compared to both traditional and cutting-edgecommunication-efficient algorithms. Remarkably, FDA achieves this withoutsacrificing convergence speed - in stark contrast to the trade-offs encounteredin the field. Additionally, we show that FDA maintains robust performanceacross diverse data heterogeneity settings.</description><author>Michail Theologitis, Georgios Frangias, Georgios Anestis, Vasilis Samoladas, Antonios Deligiannakis</author><pubDate>Fri, 31 May 2024 17:34:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20988v1</guid></item><item><title>Early Stopping Criteria for Training Generative Adversarial Networks in Biomedical Imaging</title><link>http://arxiv.org/abs/2405.20987v1</link><description>Generative Adversarial Networks (GANs) have high computational costs to traintheir complex architectures. Throughout the training process, GANs' output isanalyzed qualitatively based on the loss and synthetic images' diversity andquality. Based on this qualitative analysis, training is manually halted oncethe desired synthetic images are generated. By utilizing an early stoppingcriterion, the computational cost and dependence on manual oversight can bereduced yet impacted by training problems such as mode collapse,non-convergence, and instability. This is particularly prevalent in biomedicalimagery, where training problems degrade the diversity and quality of syntheticimages, and the high computational cost associated with training makes complexarchitectures increasingly inaccessible. This work proposes a novel earlystopping criteria to quantitatively detect training problems, halt training,and reduce the computational costs associated with synthesizing biomedicalimages. Firstly, the range of generator and discriminator loss values isinvestigated to assess whether mode collapse, non-convergence, and instabilityoccur sequentially, concurrently, or interchangeably throughout the training ofGANs. Secondly, utilizing these occurrences in conjunction with the MeanStructural Similarity Index (MS-SSIM) and Fr\'echet Inception Distance (FID)scores of synthetic images forms the basis of the proposed early stoppingcriteria. This work helps identify the occurrence of training problems in GANsusing low-resource computational cost and reduces training time to generatediversified and high-quality synthetic images.</description><author>Muhammad Muneeb Saad, Mubashir Husain Rehmani, Ruairi O'Reilly</author><pubDate>Fri, 31 May 2024 17:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20987v1</guid></item><item><title>Uncertainty Quantification for Bird's Eye View Semantic Segmentation: Methods and Benchmarks</title><link>http://arxiv.org/abs/2405.20986v1</link><description>The fusion of raw features from multiple sensors on an autonomous vehicle tocreate a Bird's Eye View (BEV) representation is crucial for planning andcontrol systems. There is growing interest in using deep learning models forBEV semantic segmentation. Anticipating segmentation errors and improving theexplainability of DNNs is essential for autonomous driving, yet it isunder-studied. This paper introduces a benchmark for predictive uncertaintyquantification in BEV segmentation. The benchmark assesses various approachesacross three popular datasets using two representative backbones and focuses onthe effectiveness of predicted uncertainty in identifying misclassified andout-of-distribution (OOD) pixels, as well as calibration. Empirical findingshighlight the challenges in uncertainty quantification. Our results find thatevidential deep learning based approaches show the most promise by efficientlyquantifying aleatoric and epistemic uncertainty. We propose theUncertainty-Focal-Cross-Entropy (UFCE) loss, designed for highly imbalanceddata, which consistently improves the segmentation quality and calibration.Additionally, we introduce a vacuity-scaled regularization term that enhancesthe model's focus on high uncertainty pixels, improving epistemic uncertaintyquantification.</description><author>Linlin Yu, Bowen Yang, Tianhao Wang, Kangshuo Li, Feng Chen</author><pubDate>Fri, 31 May 2024 17:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20986v1</guid></item><item><title>The Structure and Dynamics of Knowledge Graphs, with Superficiality</title><link>http://arxiv.org/abs/2305.08116v3</link><description>Large knowledge graphs combine human knowledge garnered from projects rangingfrom academia and institutions to enterprises and crowdsourcing. Within suchgraphs, each relationship between two nodes represents a basic fact involvingthese two entities. The diversity of the semantics of relationships constitutesthe richness of knowledge graphs, leading to the emergence of singulartopologies, sometimes chaotic in appearance. However, this complexcharacteristic can be modeled in a simple way by introducing the concept ofsuperficiality, which controls the overlap between relationships whose factsare generated independently. With this model, superficiality also regulates thebalance of the global distribution of knowledge by determining the proportionof misdescribed entities. This is the first model for the structure anddynamics of knowledge graphs. It leads to a better understanding of formalknowledge acquisition and organization.</description><author>Lock Lhote, Batrice Markhoff, Arnaud Soulet</author><pubDate>Fri, 31 May 2024 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08116v3</guid></item><item><title>DeCo: Decoupling Token Compression from Semantic Abstraction in Multimodal Large Language Models</title><link>http://arxiv.org/abs/2405.20985v1</link><description>The visual projector, which bridges the vision and language modalities andfacilitates cross-modal alignment, serves as a crucial component in MLLMs.However, measuring the effectiveness of projectors in vision-language alignmentremains under-explored, which currently can only be inferred from theperformance of MLLMs on downstream tasks. Motivated by the problem, this studyexamines the projector module by interpreting the vision-language semantic flowwithin MLLMs. Specifically, we trace back the semantic relevance flow fromgenerated language tokens to raw visual encoder patches and the intermediateoutputs produced by projectors. Our findings reveal that compressive projectors(e.g., QFormer), abstract visual patches into a limited set of semanticconcepts, such as objects or attributes, resulting in a 'double abstraction'phenomenon. This involves a first visual semantic abstraction by the projectorreferring to pre-defined query tokens, and a second extraction by the LLM basedon text instructions. The double abstraction is inefficient in training andwill result in cumulative vision semantics deficiency. To mitigate this issue,we propose the key insight of 'Decouple Compression from Abstraction (DeCo),that is compressing the visual token number at the patch level by projectorsand allowing the LLM to handle visual semantic abstraction entirely.Consequently, we adopt a simple compressor, i.e., 2D Adaptive Pooling, todownsample visual patches in a parameter-free manner. Empirical evaluationdemonstrates that DeCo surpasses traditional compressive projectors regardingboth performance and efficiency. It achieves performance gains of 0.9%, 7.1%,and 2.9% across the MLLM Benchmarks, Visual Localization, and Open-ended VQAtasks with fewer trainable parameters and faster convergence speed.</description><author>Linli Yao, Lei Li, Shuhuai Ren, Lean Wang, Yuanxin Liu, Xu Sun, Lu Hou</author><pubDate>Fri, 31 May 2024 17:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20985v1</guid></item><item><title>Spiketrum: An FPGA-based Implementation of a Neuromorphic Cochlea</title><link>http://arxiv.org/abs/2405.15923v3</link><description>This paper presents a novel FPGA-based neuromorphic cochlea, leveraging thegeneral-purpose spike-coding algorithm, Spiketrum. The focus of this study ison the development and characterization of this cochlea model, which excels intransforming audio vibrations into biologically realistic auditory spiketrains. These spike trains are designed to withstand neural fluctuations andspike losses while accurately encapsulating the spatial and precise temporalcharacteristics of audio, along with the intensity of incoming vibrations.Noteworthy features include the ability to generate real-time spike trains withminimal information loss and the capacity to reconstruct original signals. Thisfine-tuning capability allows users to optimize spike rates, achieving anoptimal balance between output quality and power consumption. Furthermore, theintegration of a feedback system into Spiketrum enables selective amplificationof specific features while attenuating others, facilitating adaptive powerconsumption based on application requirements. The hardware implementationsupports both spike-based and non-spike-based processors, making it versatilefor various computing systems. The cochlea's ability to encode diverse sensoryinformation, extending beyond sound waveforms, positions it as a promisingsensory input for current and future spike-based intelligent computing systems,offering compact and real-time spike train generation.</description><author>MHD Anas Alsakkal, Jayawan Wijekoon</author><pubDate>Fri, 31 May 2024 17:31:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15923v3</guid></item><item><title>Bayesian Design Principles for Offline-to-Online Reinforcement Learning</title><link>http://arxiv.org/abs/2405.20984v1</link><description>Offline reinforcement learning (RL) is crucial for real-world applicationswhere exploration can be costly or unsafe. However, offline learned policiesare often suboptimal, and further online fine-tuning is required. In thispaper, we tackle the fundamental dilemma of offline-to-online fine-tuning: ifthe agent remains pessimistic, it may fail to learn a better policy, while ifit becomes optimistic directly, performance may suffer from a sudden drop. Weshow that Bayesian design principles are crucial in solving such a dilemma.Instead of adopting optimistic or pessimistic policies, the agent should act ina way that matches its belief in optimal policies. Such a probability-matching agent can avoid a sudden performance drop whilestill being guaranteed to find the optimal policy. Based on our theoreticalfindings, we introduce a novel algorithm that outperforms existing methods onvarious benchmarks, demonstrating the efficacy of our approach. Overall, theproposed approach provides a new perspective on offline-to-online RL that hasthe potential to enable more effective learning from offline data.</description><author>Hao Hu, Yiqin Yang, Jianing Ye, Chengjie Wu, Ziqing Mai, Yujing Hu, Tangjie Lv, Changjie Fan, Qianchuan Zhao, Chongjie Zhang</author><pubDate>Fri, 31 May 2024 17:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20984v1</guid></item><item><title>Open Ad Hoc Teamwork with Cooperative Game Theory</title><link>http://arxiv.org/abs/2402.15259v3</link><description>Ad hoc teamwork poses a challenging problem, requiring the design of an agentto collaborate with teammates without prior coordination or joint training.Open ad hoc teamwork (OAHT) further complicates this challenge by consideringenvironments with a changing number of teammates, referred to as open teams.One promising solution in practice to this problem is leveraging thegeneralizability of graph neural networks to handle an unrestricted number ofagents, named graph-based policy learning (GPL). However, its joint Q-valuerepresentation over a coordination graph lacks convincing explanations. In thispaper, we establish a new theory to understand the joint Q-value representationfor OAHT, from the perspective of cooperative game theory, and validate itslearning paradigm. Building on our theory, we propose a novel algorithm namedCIAO, compatible with GPL framework, with additional provable implementationtricks that can facilitate learning. The demos of experimental results areavailable on https://sites.google.com/view/ciao2024, and the code ofexperiments is published on https://github.com/hsvgbkhgbv/CIAO.</description><author>Jianhong Wang, Yang Li, Yuan Zhang, Wei Pan, Samuel Kaski</author><pubDate>Fri, 31 May 2024 17:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15259v3</guid></item><item><title>Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers</title><link>http://arxiv.org/abs/2310.02905v2</link><description>Large language models (LLMs) have shown remarkable instruction-followingcapabilities and achieved impressive performances in various applications.However, the performances of LLMs depend heavily on the instructions given tothem, which are typically manually tuned with substantial human efforts. Recentwork has used the query-efficient Bayesian optimization (BO) algorithm toautomatically optimize the instructions given to black-box LLMs. However, BOusually falls short when optimizing highly sophisticated (e.g.,high-dimensional) objective functions, such as the functions mapping aninstruction to the performance of an LLM. This is mainly due to the limitedexpressive power of the Gaussian process (GP) which is used by BO as asurrogate to model the objective function. Meanwhile, it has been repeatedlyshown that neural networks (NNs), especially pre-trained transformers, possessstrong expressive power and can model highly complex functions. So, we adopt aneural bandit algorithm which replaces the GP in BO by an NN surrogate tooptimize instructions for black-box LLMs. More importantly, the neural banditalgorithm allows us to naturally couple the NN surrogate with the hiddenrepresentation learned by a pre-trained transformer (i.e., an open-source LLM),which significantly boosts its performance. These motivate us to propose ourINSTruction optimization usIng Neural bandits Coupled with Transformers(INSTINCT) algorithm. We perform instruction optimization for ChatGPT and useextensive experiments to show that INSTINCT consistently outperforms baselinesin different tasks, e.g., various instruction induction tasks and the task ofimproving zero-shot chain-of-thought instructions. Our code is available athttps://github.com/xqlin98/INSTINCT.</description><author>Xiaoqiang Lin, Zhaoxuan Wu, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low</author><pubDate>Fri, 31 May 2024 17:27:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02905v2</guid></item><item><title>Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits</title><link>http://arxiv.org/abs/2405.20981v1</link><description>Transthoracic Echocardiography (TTE) is a fundamental, non-invasivediagnostic tool in cardiovascular medicine, enabling detailed visualization ofcardiac structures crucial for diagnosing various heart conditions. Despite itswidespread use, TTE ultrasound imaging faces inherent limitations, notably thetrade-off between field of view (FoV) and resolution. This paper introduces anovel application of conditional Generative Adversarial Networks (cGANs),specifically designed to extend the FoV in TTE ultrasound imaging whilemaintaining high resolution. Our proposed cGAN architecture, termed echoGAN,demonstrates the capability to generate realistic anatomical structures throughoutpainting, effectively broadening the viewable area in medical imaging. Thisadvancement has the potential to enhance both automatic and manual ultrasoundnavigation, offering a more comprehensive view that could significantly reducethe learning curve associated with ultrasound imaging and aid in more accuratediagnoses. The results confirm that echoGAN reliably reproduce detailed cardiacfeatures, thereby promising a significant step forward in the field ofnon-invasive cardiac naviagation and diagnostics.</description><author>Matej Gazda, Samuel Kadoury, Jakub Gazda, Peter Drotar</author><pubDate>Fri, 31 May 2024 17:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20981v1</guid></item><item><title>Neural Gaussian Scale-Space Fields</title><link>http://arxiv.org/abs/2405.20980v1</link><description>Gaussian scale spaces are a cornerstone of signal representation andprocessing, with applications in filtering, multiscale analysis, anti-aliasing,and many more. However, obtaining such a scale space is costly and cumbersome,in particular for continuous representations such as neural fields. We presentan efficient and lightweight method to learn the fully continuous, anisotropicGaussian scale space of an arbitrary signal. Based on Fourier featuremodulation and Lipschitz bounding, our approach is trained self-supervised,i.e., training does not require any manual filtering. Our neural Gaussianscale-space fields faithfully capture multiscale representations across a broadrange of modalities, and support a diverse set of applications. These includeimages, geometry, light-stage data, texture anti-aliasing, and multiscaleoptimization.</description><author>Felix Mujkanovic, Ntumba Elie Nsampi, Christian Theobalt, Hans-Peter Seidel, Thomas Leimkhler</author><pubDate>Fri, 31 May 2024 17:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20980v1</guid></item><item><title>Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training</title><link>http://arxiv.org/abs/2405.20978v1</link><description>Large Language Models (LLMs) exhibit substantial capabilities yet encounterchallenges, including hallucination, outdated knowledge, and untraceablereasoning processes. Retrieval-augmented generation (RAG) has emerged as apromising solution, integrating knowledge from external databases to mitigatethese challenges. However, inappropriate retrieved passages can potentiallyhinder the LLMs' capacity to generate comprehensive and high-quality responses.Prior RAG studies on the robustness of retrieval noises often confinethemselves to a limited set of noise types, deviating from real-world retrievalenvironments and limiting practical applicability. In this study, we initiallyinvestigate retrieval noises and categorize them into three distinct types,reflecting real-world environments. We analyze the impact of these variousretrieval noises on the robustness of LLMs. Subsequently, we propose a novelRAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT).RAAT leverages adaptive adversarial training to dynamically adjust the model'straining process in response to retrieval noises. Concurrently, it employsmulti-task learning to ensure the model's capacity to internally recognizenoisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B modeltrained using RAAT exhibits significant improvements in F1 and EM scores underdiverse noise conditions. For reproducibility, we release our code and data at:https://github.com/calubkk/RAAT.</description><author>Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, Ruifeng Xu</author><pubDate>Fri, 31 May 2024 17:24:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20978v1</guid></item><item><title>Application based Evaluation of an Efficient Spike-Encoder, "Spiketrum"</title><link>http://arxiv.org/abs/2405.15927v3</link><description>Spike-based encoders represent information as sequences of spikes or pulses,which are transmitted between neurons. A prevailing consensus suggests thatspike-based approaches demonstrate exceptional capabilities in capturing thetemporal dynamics of neural activity and have the potential to provideenergy-efficient solutions for low-power applications. The Spiketrum encoderefficiently compresses input data using spike trains or code sets (fornon-spiking applications) and is adaptable to both hardware and softwareimplementations, with lossless signal reconstruction capability. The paperproposes and assesses Spiketrum's hardware, evaluating its output under varyingspike rates and its classification performance with popular spiking andnon-spiking classifiers, and also assessing the quality of informationcompression and hardware resource utilization. The paper extensively benchmarksboth Spiketrum hardware and its software counterpart against state-of-the-art,biologically-plausible encoders. The evaluations encompass benchmarkingcriteria, including classification accuracy, training speed, and sparsity whenusing encoder outputs in pattern recognition and classification with bothspiking and non-spiking classifiers. Additionally, they consider encoded outputentropy and hardware resource utilization and power consumption of the hardwareversion of the encoders. Results demonstrate Spiketrum's superiority in mostbenchmarking criteria, making it a promising choice for various applications.It efficiently utilizes hardware resources with low power consumption,achieving high classification accuracy. This work also emphasizes the potentialof encoders in spike-based processing to improve the efficiency and performanceof neural computing systems.</description><author>MHD Anas Alsakkal, Runze Wang, Jayawan Wijekoon, Huajin Tang</author><pubDate>Fri, 31 May 2024 17:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15927v3</guid></item><item><title>ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning</title><link>http://arxiv.org/abs/2405.20975v1</link><description>In Federated Learning (FL), a set of clients collaboratively train a machinelearning model (called global model) without sharing their local training data.The local training data of clients is typically non-i.i.d. and heterogeneous,resulting in varying contributions from individual clients to the finalperformance of the global model. In response, many contribution evaluationmethods were proposed, where the server could evaluate the contribution made byeach client and incentivize the high-contributing clients to sustain theirlong-term participation in FL. Existing studies mainly focus on developing newmetrics or algorithms to better measure the contribution of each client.However, the security of contribution evaluation methods of FL operating inadversarial environments is largely unexplored. In this paper, we propose thefirst model poisoning attack on contribution evaluation methods in FL, termedACE. Specifically, we show that any malicious client utilizing ACE couldmanipulate the parameters of its local model such that it is evaluated to havea high contribution by the server, even when its local training data is indeedof low quality. We perform both theoretical analysis and empirical evaluationsof ACE. Theoretically, we show our design of ACE can effectively boost themalicious client's perceived contribution when the server employs thewidely-used cosine distance metric to measure contribution. Empirically, ourresults show ACE effectively and efficiently deceive five state-of-the-artcontribution evaluation methods. In addition, ACE preserves the accuracy of thefinal global models on testing inputs. We also explore six countermeasures todefend ACE. Our results show they are inadequate to thwart ACE, highlightingthe urgent need for new defenses to safeguard the contribution evaluationmethods in FL.</description><author>Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran</author><pubDate>Fri, 31 May 2024 17:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20975v1</guid></item><item><title>SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</title><link>http://arxiv.org/abs/2405.20974v1</link><description>Large language models (LLMs) often generate inaccurate or fabricatedinformation and generally fail to indicate their confidence, which limits theirbroader applications. Previous work elicits confidence from LLMs by direct orself-consistency prompting, or constructing specific datasets for supervisedfinetuning. The prompting-based approaches have inferior performance, and thetraining-based approaches are limited to binary or inaccurate group-levelconfidence estimates. In this work, we present the advanced SaySelf, a trainingframework that teaches LLMs to express more accurate fine-grained confidenceestimates. In addition, beyond the confidence scores, SaySelf initiates theprocess of directing LLMs to produce self-reflective rationales that clearlyidentify gaps in their parametric knowledge and explain their uncertainty. Thisis achieved by using an LLM to automatically summarize the uncertainties inspecific knowledge via natural language. The summarization is based on theanalysis of the inconsistency in multiple sampled reasoning chains, and theresulting data is utilized for supervised fine-tuning. Moreover, we utilizereinforcement learning with a meticulously crafted reward function to calibratethe confidence estimates, motivating LLMs to deliver accurate, high-confidencepredictions and to penalize overconfidence in erroneous outputs. Experimentalresults in both in-distribution and out-of-distribution datasets demonstratethe effectiveness of SaySelf in reducing the confidence calibration error andmaintaining the task performance. We show that the generated self-reflectiverationales are reasonable and can further contribute to the calibration. Thecode is made public at \url{https://github.com/xu1868/SaySelf}.</description><author>Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao</author><pubDate>Fri, 31 May 2024 17:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20974v1</guid></item><item><title>LCQ: Low-Rank Codebook based Quantization for Large Language Models</title><link>http://arxiv.org/abs/2405.20973v1</link><description>Large language models~(LLMs) have recently demonstrated promising performancein many tasks. However, the high storage and computational cost of LLMs hasbecome a challenge for deploying LLMs. Weight quantization has been widely usedfor model compression, which can reduce both storage and computational cost.Most existing weight quantization methods for LLMs use a rank-one codebook forquantization, which results in substantial accuracy loss when the compressionratio is high. In this paper, we propose a novel weight quantization method,called low-rank codebook based quantization~(LCQ), for LLMs. LCQ adopts alow-rank codebook, the rank of which can be larger than one, for quantization.Experiments show that LCQ can achieve better accuracy than existing methodswith a negligibly extra storage cost.</description><author>Wen-Pu Cai, Wu-Jun Li</author><pubDate>Fri, 31 May 2024 17:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20973v1</guid></item><item><title>Amortizing intractable inference in diffusion models for vision, language, and control</title><link>http://arxiv.org/abs/2405.20971v1</link><description>Diffusion models have emerged as effective distribution estimators in vision,language, and reinforcement learning, but their use as priors in downstreamtasks poses an intractable posterior inference problem. This paper studiesamortized sampling of the posterior over data, $\mathbf{x}\sim p^{\rmpost}(\mathbf{x})\propto p(\mathbf{x})r(\mathbf{x})$, in a model that consistsof a diffusion generative model prior $p(\mathbf{x})$ and a black-boxconstraint or likelihood function $r(\mathbf{x})$. We state and prove theasymptotic correctness of a data-free learning objective, relative trajectorybalance, for training a diffusion model that samples from this posterior, aproblem that existing methods solve only approximately or in restricted cases.Relative trajectory balance arises from the generative flow network perspectiveon diffusion models, which allows the use of deep reinforcement learningtechniques to improve mode coverage. Experiments illustrate the broad potentialof unbiased inference of arbitrary posteriors under diffusion priors: in vision(classifier guidance), language (infilling under a discrete diffusion LLM), andmultimodal data (text-to-image generation). Beyond generative modeling, weapply relative trajectory balance to the problem of continuous control with ascore-based behavior prior, achieving state-of-the-art results on benchmarks inoffline reinforcement learning.</description><author>Siddarth Venkatraman, Moksh Jain, Luca Scimeca, Minsu Kim, Marcin Sendera, Mohsin Hasan, Luke Rowe, Sarthak Mittal, Pablo Lemos, Emmanuel Bengio, Alexandre Adam, Jarrid Rector-Brooks, Yoshua Bengio, Glen Berseth, Nikolay Malkin</author><pubDate>Fri, 31 May 2024 17:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20971v1</guid></item><item><title>PUAL: A Classifier on Trifurcate Positive-Unlabeled Data</title><link>http://arxiv.org/abs/2405.20970v1</link><description>Positive-unlabeled (PU) learning aims to train a classifier using the datacontaining only labeled-positive instances and unlabeled instances. However,existing PU learning methods are generally hard to achieve satisfactoryperformance on trifurcate data, where the positive instances distribute on bothsides of the negative instances. To address this issue, firstly we propose a PUclassifier with asymmetric loss (PUAL), by introducing a structure ofasymmetric loss on positive instances into the objective function of the globaland local learning classifier. Then we develop a kernel-based algorithm toenable PUAL to obtain non-linear decision boundary. We show that, throughexperiments on both simulated and real-world datasets, PUAL can achievesatisfactory classification on trifurcate data.</description><author>Xiaoke Wang, Xiaochen Yang, Rui Zhu, Jing-Hao Xue</author><pubDate>Fri, 31 May 2024 17:18:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20970v1</guid></item><item><title>Pre- to Post-Contrast Breast MRI Synthesis for Enhanced Tumour Segmentation</title><link>http://arxiv.org/abs/2311.10879v3</link><description>Despite its benefits for tumour detection and treatment, the administrationof contrast agents in dynamic contrast-enhanced MRI (DCE-MRI) is associatedwith a range of issues, including their invasiveness, bioaccumulation, and arisk of nephrogenic systemic fibrosis. This study explores the feasibility ofproducing synthetic contrast enhancements by translating pre-contrastT1-weighted fat-saturated breast MRI to their corresponding first DCE-MRIsequence leveraging the capabilities of a generative adversarial network (GAN).Additionally, we introduce a Scaled Aggregate Measure (SAMe) designed forquantitatively evaluating the quality of synthetic data in a principled mannerand serving as a basis for selecting the optimal generative model. We assessthe generated DCE-MRI data using quantitative image quality metrics and applythem to the downstream task of 3D breast tumour segmentation. Our resultshighlight the potential of post-contrast DCE-MRI synthesis in enhancing therobustness of breast tumour segmentation models via data augmentation. Our codeis available at https://github.com/RichardObi/pre_post_synthesis.</description><author>Richard Osuala, Smriti Joshi, Apostolia Tsirikoglou, Lidia Garrucho, Walter H. L. Pinaya, Oliver Diaz, Karim Lekadir</author><pubDate>Fri, 31 May 2024 17:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10879v3</guid></item><item><title>Superlatives in Context: Explicit and Implicit Domain Restrictions for Superlative Frames</title><link>http://arxiv.org/abs/2405.20967v1</link><description>Superlatives are used to single out elements with a maximal/minimal property.Semantically, superlatives perform a set comparison: something (or some things)has the min/max property out of a set. As such, superlatives provide an idealphenomenon for studying implicit phenomena and discourse restrictions. Whilethis comparison set is often not explicitly defined, its (implicit)restrictions can be inferred from the discourse context the expression appearsin. In this work we provide an extensive computational study on the semanticsof superlatives. We propose a unified account of superlative semantics whichallows us to derive a broad-coverage annotation schema. Using this unifiedschema we annotated a multi-domain dataset of superlatives and their semanticinterpretations. We specifically focus on interpreting implicit or ambiguoussuperlative expressions, by analyzing how the discourse context restricts theset of interpretations. In a set of experiments we then analyze how well modelsperform at variations of predicting superlative semantics, with and withoutcontext. We show that the fine-grained semantics of superlatives in context canbe challenging for contemporary models, including GPT-4.</description><author>Valentina Pyatkin, Bonnie Webber, Ido Dagan, Reut Tsarfaty</author><pubDate>Fri, 31 May 2024 17:14:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20967v1</guid></item><item><title>Primal Dual Continual Learning: Balancing Stability and Plasticity through Adaptive Memory Allocation</title><link>http://arxiv.org/abs/2310.00154v2</link><description>Continual learning is inherently a constrained learning problem. The goal isto learn a predictor under a no-forgetting requirement. Although several priorstudies formulate it as such, they do not solve the constrained problemexplicitly. In this work, we show that it is both possible and beneficial toundertake the constrained optimization problem directly. To do this, weleverage recent results in constrained learning through Lagrangian duality. Wefocus on memory-based methods, where a small subset of samples from previoustasks can be stored in a replay buffer. In this setting, we analyze twoversions of the continual learning problem: a coarse approach with constraintsat the task level and a fine approach with constraints at the sample level. Weshow that dual variables indicate the sensitivity of the optimal value of thecontinual learning problem with respect to constraint perturbations. We thenleverage this result to partition the buffer in the coarse approach, allocatingmore resources to harder tasks, and to populate the buffer in the fineapproach, including only impactful samples. We derive a deviation bound on dualvariables as sensitivity indicators, and empirically corroborate this result indiverse continual learning benchmarks. We also discuss the limitations of thesemethods with respect to the amount of memory available and the expressivenessof the parametrization.</description><author>Juan Elenter, Navid NaderiAlizadeh, Tara Javidi, Alejandro Ribeiro</author><pubDate>Fri, 31 May 2024 17:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00154v2</guid></item><item><title>Large Language Models are Zero-Shot Next Location Predictors</title><link>http://arxiv.org/abs/2405.20962v1</link><description>Predicting the locations an individual will visit in the future is crucialfor solving many societal issues like disease diffusion and reduction ofpollution among many others. The models designed to tackle next-locationprediction, however, require a significant amount of individual-levelinformation to be trained effectively. Such data may be scarce or evenunavailable in some geographic regions or peculiar scenarios (e.g., cold-startin recommendation systems). Moreover, the design of a next-location predictorable to generalize or geographically transfer knowledge is still an openresearch challenge. Recent advances in natural language processing have led toa rapid diffusion of Large Language Models (LLMs) which have shown goodgeneralization and reasoning capabilities. These insights, coupled with therecent findings that LLMs are rich in geographical knowledge, allowed us tobelieve that these models can act as zero-shot next-location predictors. Thispaper evaluates the capabilities of many popular LLMs in this role,specifically Llama, GPT-3.5 and Mistral 7B. After designing a proper prompt, wetested the models on three real-world mobility datasets. The results show thatLLMs can obtain accuracies up to 32.4%, a significant relative improvement ofover 600% when compared to sophisticated DL models specifically designed forhuman mobility. Moreover, we show that other LLMs are unable to perform thetask properly. To prevent positively biased results, we also propose aframework inspired by other studies to test data contamination. Finally, weexplored the possibility of using LLMs as text-based explainers fornext-location prediction showing that can effectively provide an explanationfor their decision. Notably, 7B models provide more generic, but stillreliable, explanations compared to larger counterparts. Code:github.com/ssai-trento/LLM-zero-shot-NL</description><author>Ciro Beneduce, Bruno Lepri, Massimiliano Luca</author><pubDate>Fri, 31 May 2024 17:07:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20962v1</guid></item><item><title>eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling</title><link>http://arxiv.org/abs/2403.01371v2</link><description>State-space graphical models and the variational autoencoder frameworkprovide a principled apparatus for learning dynamical systems from data.State-of-the-art probabilistic approaches are often able to scale to largeproblems at the cost of flexibility of the variational posterior orexpressivity of the dynamics model. However, those consolidations can bedetrimental if the ultimate goal is to learn a generative model capable ofexplaining the spatiotemporal structure of the data and making accurateforecasts. We introduce a low-rank structured variational autoencodingframework for nonlinear Gaussian state-space graphical models capable ofcapturing dense covariance structures that are important for learning dynamicalsystems with predictive capabilities. Our inference algorithm exploits thecovariance structures that arise naturally from sample based approximateGaussian message passing and low-rank amortized posterior updates --effectively performing approximate variational smoothing with time complexityscaling linearly in the state dimensionality. In comparisons with other deepstate-space model architectures our approach consistently demonstrates theability to learn a more predictive generative model. Furthermore, when appliedto neural physiological recordings, our approach is able to learn a dynamicalsystem capable of forecasting population spiking and behavioral correlates froma small portion of single trials.</description><author>Matthew Dowling, Yuan Zhao, Il Memming Park</author><pubDate>Fri, 31 May 2024 17:05:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01371v2</guid></item><item><title>Behind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation</title><link>http://arxiv.org/abs/2207.11860v5</link><description>In this paper, we address panoramic semantic segmentation which isunder-explored due to two critical challenges: (1) image distortions and objectdeformations on panoramas; (2) lack of semantic annotations in the 360{\deg}imagery. To tackle these problems, first, we propose the upgraded Transformerfor Panoramic Semantic Segmentation, i.e., Trans4PASS+, equipped withDeformable Patch Embedding (DPE) and Deformable MLP (DMLPv2) modules forhandling object deformations and image distortions whenever (before or afteradaptation) and wherever (shallow or deep levels). Second, we enhance theMutual Prototypical Adaptation (MPA) strategy via pseudo-label rectificationfor unsupervised domain adaptive panoramic segmentation. Third, aside fromPinhole-to-Panoramic (Pin2Pan) adaptation, we create a new dataset (SynPASS)with 9,080 panoramic images, facilitating Synthetic-to-Real (Syn2Real)adaptation scheme in 360{\deg} imagery. Extensive experiments are conducted,which cover indoor and outdoor scenarios, and each of them is investigated withPin2Pan and Syn2Real regimens. Trans4PASS+ achieves state-of-the-artperformances on four domain adaptive panoramic semantic segmentationbenchmarks. Code is available at https://github.com/jamycheung/Trans4PASS.</description><author>Jiaming Zhang, Kailun Yang, Hao Shi, Simon Rei, Kunyu Peng, Chaoxiang Ma, Haodong Fu, Philip H. S. Torr, Kaiwei Wang, Rainer Stiefelhagen</author><pubDate>Fri, 31 May 2024 17:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.11860v5</guid></item><item><title>Navigating Tabular Data Synthesis Research: Understanding User Needs and Tool Capabilities</title><link>http://arxiv.org/abs/2405.20959v1</link><description>In an era of rapidly advancing data-driven applications, there is a growingdemand for data in both research and practice. Synthetic data have emerged asan alternative when no real data is available (e.g., due to privacyregulations). Synthesizing tabular data presents unique and complex challenges,especially handling (i) missing values, (ii) dataset imbalance, (iii) diversecolumn types, and (iv) complex data distributions, as well as preserving (i)column correlations, (ii) temporal dependencies, and (iii) integrityconstraints (e.g., functional dependencies) present in the original dataset.While substantial progress has been made recently in the context ofgenerational models, there is no one-size-fits-all solution for tabular datatoday, and choosing the right tool for a given task is therefore no trivialtask. In this paper, we survey the state of the art in Tabular Data Synthesis(TDS), examine the needs of users by defining a set of functional andnon-functional requirements, and compile the challenges associated with meetingthose needs. In addition, we evaluate the reported performance of 36 popularresearch TDS tools about these requirements and develop a decision guide tohelp users find suitable TDS tools for their applications. The resultingdecision guide also identifies significant research gaps.</description><author>Maria F. Davila R., Sven Groen, Fabian Panse, Wolfram Wingerath</author><pubDate>Fri, 31 May 2024 17:00:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20959v1</guid></item><item><title>Towards Imbalanced Motion: Part-Decoupling Network for Video Portrait Segmentation</title><link>http://arxiv.org/abs/2307.16565v2</link><description>Video portrait segmentation (VPS), aiming at segmenting prominent foregroundportraits from video frames, has received much attention in recent years.However, simplicity of existing VPS datasets leads to a limitation on extensiveresearch of the task. In this work, we propose a new intricate large-scaleMulti-scene Video Portrait Segmentation dataset MVPS consisting of 101 videoclips in 7 scenario categories, in which 10,843 sampled frames are finelyannotated at pixel level. The dataset has diverse scenes and complicatedbackground environments, which is the most complex dataset in VPS to our bestknowledge. Through the observation of a large number of videos with portraitsduring dataset construction, we find that due to the joint structure of humanbody, motion of portraits is part-associated, which leads that different partsare relatively independent in motion. That is, motion of different parts of theportraits is imbalanced. Towards this imbalance, an intuitive and reasonableidea is that different motion states in portraits can be better exploited bydecoupling the portraits into parts. To achieve this, we propose aPart-Decoupling Network (PDNet) for video portrait segmentation. Specifically,an Inter-frame Part-Discriminated Attention (IPDA) module is proposed whichunsupervisedly segments portrait into parts and utilizes differentattentiveness on discriminative features specified to each different part. Inthis way, appropriate attention can be imposed to portrait parts withimbalanced motion to extract part-discriminated correlations, so that theportraits can be segmented more accurately. Experimental results demonstratethat our method achieves leading performance with the comparison tostate-of-the-art methods.</description><author>Tianshu Yu, Changqun Xia, Jia Li</author><pubDate>Fri, 31 May 2024 17:00:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16565v2</guid></item><item><title>Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow</title><link>http://arxiv.org/abs/2402.09894v2</link><description>Generative AI brings novel and impressive abilities to help people ineveryday tasks. There are many AI workflows that solve real and complexproblems by chaining AI outputs together with human interaction. Although thereis an undeniable lure of AI, it is uncertain how useful generative AI workflowsare after the novelty wears off. Additionally, workflows built with generativeAI have the potential to be easily customized to fit users' individual needs,but do users take advantage of this? We conducted a three-week longitudinalstudy with 12 users to understand the familiarization and customization ofgenerative AI tools for science communication. Our study revealed that thereexists a familiarization phase, during which users were exploring the novelcapabilities of the workflow and discovering which aspects they found useful.After this phase, users understood the workflow and were able to anticipate theoutputs. Surprisingly, after familiarization the perceived utility of thesystem was rated higher than before, indicating that the perceived utility ofAI is not just a novelty effect. The increase in benefits mainly comes fromend-users' ability to customize prompts, and thus potentially appropriate thesystem to their own needs. This points to a future where generative AI systemscan allow us to design for appropriation.</description><author>Tao Long, Katy Ilonka Gero, Lydia B. Chilton</author><pubDate>Fri, 31 May 2024 17:00:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09894v2</guid></item><item><title>Online Cascade Learning for Efficient Inference over Streams</title><link>http://arxiv.org/abs/2402.04513v2</link><description>Large Language Models (LLMs) have a natural role in answering complex queriesabout data streams, but the high computational cost of LLM inference makes theminfeasible in many such tasks. We propose online cascade learning, the firstapproach to address this challenge. The objective here is to learn a "cascade"of models, starting with lower-capacity models (such as logistic regression)and ending with a powerful LLM, along with a deferral policy that determinesthe model to be used on a given input. We formulate the task of learningcascades online as an imitation-learning problem, where smaller models areupdated over time imitating the collected LLM demonstrations, and give ano-regret algorithm for the problem. Experimental results across fourbenchmarks show that our method parallels LLMs in accuracy while cutting downinference costs by as much as 90% with strong robustness against inputdistribution shifts, underscoring its efficacy and adaptability in streamprocessing.</description><author>Lunyiu Nie, Zhimin Ding, Erdong Hu, Christopher Jermaine, Swarat Chaudhuri</author><pubDate>Fri, 31 May 2024 16:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04513v2</guid></item><item><title>The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data</title><link>http://arxiv.org/abs/2404.11265v2</link><description>Recently, backdoor attacks have posed a serious security threat to thetraining process of deep neural networks (DNNs). The attacked model behavesnormally on benign samples but outputs a specific result when the trigger ispresent. However, compared with the rocketing progress of backdoor attacks,existing defenses are difficult to deal with these threats effectively orrequire benign samples to work, which may be unavailable in real scenarios. Inthis paper, we find that the poisoned samples and benign samples can bedistinguished with prediction entropy. This inspires us to propose a noveldual-network training framework: The Victim and The Beneficiary (V&amp;B), whichexploits a poisoned model to train a clean model without extra benign samples.Firstly, we sacrifice the Victim network to be a powerful poisoned sampledetector by training on suspicious samples. Secondly, we train the Beneficiarynetwork on the credible samples selected by the Victim to inhibit backdoorinjection. Thirdly, a semi-supervised suppression strategy is adopted forerasing potential backdoors and improving model performance. Furthermore, tobetter inhibit missed poisoned samples, we propose a strong data augmentationmethod, AttentionMix, which works well with our proposed V&amp;B framework.Extensive experiments on two widely used datasets against 6 state-of-the-artattacks demonstrate that our framework is effective in preventing backdoorinjection and robust to various attacks while maintaining the performance onbenign samples. Our code is available at https://github.com/Zixuan-Zhu/VaB.</description><author>Zixuan Zhu, Rui Wang, Cong Zou, Lihua Jing</author><pubDate>Fri, 31 May 2024 16:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11265v2</guid></item><item><title>SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages</title><link>http://arxiv.org/abs/2402.08638v5</link><description>Exploring and quantifying semantic relatedness is central to representinglanguage and holds significant implications across various NLP tasks. Whileearlier NLP research primarily focused on semantic similarity, often within theEnglish language context, we instead investigate the broader phenomenon ofsemantic relatedness. In this paper, we present \textit{SemRel}, a new semanticrelatedness dataset collection annotated by native speakers across 13languages: \textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi,Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic,Spanish,} and \textit{Telugu}. These languages originate from five distinctlanguage families and are predominantly spoken in Africa and Asia -- regionscharacterised by a relatively limited availability of NLP resources. Eachinstance in the SemRel datasets is a sentence pair associated with a score thatrepresents the degree of semantic textual relatedness between the twosentences. The scores are obtained using a comparative annotation framework. Wedescribe the data collection and annotation processes, challenges when buildingthe datasets, baseline experiments, and their impact and utility in NLP.</description><author>Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine De Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Winata, Seid Muhie Yimam, Saif M. Mohammad</author><pubDate>Fri, 31 May 2024 16:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08638v5</guid></item><item><title>A Robot Walks into a Bar: Can Language Models Serve asCreativity Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with Comedians</title><link>http://arxiv.org/abs/2405.20956v1</link><description>We interviewed twenty professional comedians who perform live shows in frontof audiences and who use artificial intelligence in their artistic process aspart of 3-hour workshops on ``AI x Comedy'' conducted at the Edinburgh FestivalFringe in August 2023 and online. The workshop consisted of a comedy writingsession with large language models (LLMs), a human-computer interactionquestionnaire to assess the Creativity Support Index of AI as a writing tool,and a focus group interrogating the comedians' motivations for and processes ofusing AI, as well as their ethical concerns about bias, censorship andcopyright. Participants noted that existing moderation strategies used insafety filtering and instruction-tuned LLMs reinforced hegemonic viewpoints byerasing minority groups and their perspectives, and qualified this as a form ofcensorship. At the same time, most participants felt the LLMs did not succeedas a creativity support tool, by producing bland and biased comedy tropes, akinto ``cruise ship comedy material from the 1950s, but a bit less racist''. Ourwork extends scholarship about the subtle difference between, one the one hand,harmful speech, and on the other hand, ``offensive'' language as a practice ofresistance, satire and ``punching up''. We also interrogate the global valuealignment behind such language models, and discuss the importance ofcommunity-based value alignment and data ownership to build AI tools thatbetter suit artists' needs.</description><author>Piotr Wojciech Mirowski, Juliette Love, Kory W. Mathewson, Shakir Mohamed</author><pubDate>Fri, 31 May 2024 16:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20956v1</guid></item><item><title>Aligning Multiclass Neural Network Classifier Criterion with Task Performance via $F_$-Score</title><link>http://arxiv.org/abs/2405.20954v1</link><description>Multiclass neural network classifiers are typically trained usingcross-entropy loss. Following training, the performance of this same neuralnetwork is evaluated using an application-specific metric based on themulticlass confusion matrix, such as the Macro $F_\beta$-Score. It isquestionable whether the use of cross-entropy will yield a classifier thataligns with the intended application-specific performance criteria,particularly in scenarios where there is a need to emphasize one aspect ofclassifier performance. For example, if greater precision is preferred overrecall, the $\beta$ value in the $F_\beta$ evaluation metric can be adjustedaccordingly, but the cross-entropy objective remains unaware of this preferenceduring training. We propose a method that addresses this training-evaluationgap for multiclass neural network classifiers such that users can train thesemodels informed by the desired final $F_\beta$-Score. Following prior work inbinary classification, we utilize the concepts of the soft-set confusionmatrices and a piecewise-linear approximation of the Heaviside step function.Our method extends the $2 \times 2$ binary soft-set confusion matrix to amulticlass $d \times d$ confusion matrix and proposes dynamic adaptation of thethreshold value $\tau$, which parameterizes the piecewise-linear Heavisideapproximation during run-time. We present a theoretical analysis that showsthat our method can be used to optimize for a soft-set based approximation ofMacro-$F_\beta$ that is a consistent estimator of Macro-$F_\beta$, and ourextensive experiments show the practical effectiveness of our approach.</description><author>Nathan Tsoi, Deyuan Li, Taesoo Daniel Lee, Marynel Vzquez</author><pubDate>Fri, 31 May 2024 16:54:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20954v1</guid></item><item><title>Monte Carlo Tree Search Satellite Scheduling Under Cloud Cover Uncertainty</title><link>http://arxiv.org/abs/2405.20951v1</link><description>Efficient utilization of satellite resources in dynamic environments remainsa challenging problem in satellite scheduling. This paper addresses themulti-satellite collection scheduling problem (m-SatCSP), aiming to optimizetask scheduling over a constellation of satellites under uncertain conditionssuch as cloud cover. Leveraging Monte Carlo Tree Search (MCTS), a stochasticsearch algorithm, two versions of MCTS are explored to schedule satelliteseffectively. Hyperparameter tuning is conducted to optimize the algorithm'sperformance. Experimental results demonstrate the effectiveness of the MCTSapproach, outperforming existing methods in both solution quality andefficiency. Comparative analysis against other scheduling algorithms showcasescompetitive performance, positioning MCTS as a promising solution for satellitetask scheduling in dynamic environments.</description><author>Justin Norman, Francois Rivest</author><pubDate>Fri, 31 May 2024 16:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20951v1</guid></item><item><title>HQ-DiT: Efficient Diffusion Transformer with FP4 Hybrid Quantization</title><link>http://arxiv.org/abs/2405.19751v2</link><description>Diffusion Transformers (DiTs) have recently gained substantial attention inboth industrial and academic fields for their superior visual generationcapabilities, outperforming traditional diffusion models that use U-Net.However,the enhanced performance of DiTs also comes with high parameter countsand implementation costs, seriously restricting their use on resource-limiteddevices such as mobile phones. To address these challenges, we introduce theHybrid Floating-point Quantization for DiT(HQ-DiT), an efficient post-trainingquantization method that utilizes 4-bit floating-point (FP) precision on bothweights and activations for DiT inference. Compared to fixed-point quantization(e.g., INT8), FP quantization, complemented by our proposed clipping rangeselection mechanism, naturally aligns with the data distribution within DiT,resulting in a minimal quantization error. Furthermore, HQ-DiT also implementsa universal identity mathematical transform to mitigate the seriousquantization error caused by the outliers. The experimental results demonstratethat DiT can achieve extremely low-precision quantization (i.e., 4 bits) withnegligible impact on performance. Our approach marks the first instance whereboth weights and activations in DiTs are quantized to just 4 bits, with only a0.12 increase in sFID on ImageNet.</description><author>Wenxuan Liu, Sai Qian Zhang</author><pubDate>Fri, 31 May 2024 16:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19751v2</guid></item><item><title>Perimeter Control with Heterogeneous Metering Rates for Cordon Signals: A Physics-Regularized Multi-Agent Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2308.12985v2</link><description>Perimeter Control (PC) strategies have been proposed to address urban roadnetwork control in oversaturated situations by regulating the transfer flow ofthe Protected Network (PN) based on the Macroscopic Fundamental Diagram (MFD).The uniform metering rate for cordon signals in most existing studies overlooksthe variance of local traffic states at the intersection level, which may causesevere local traffic congestion and degradation of the network stability. PCstrategies with heterogeneous metering rates for cordon signals allow precisecontrol for the perimeter but the complexity of the problem increasesexponentially with the scale of the PN. This paper leverages a Multi-AgentReinforcement Learning (MARL)-based traffic signal control framework todecompose this PC problem, which considers heterogeneous metering rates forcordon signals, into multi-agent cooperation tasks. Each agent controls anindividual signal located in the cordon, decreasing the dimension of actionspace for the controller compared to centralized methods. A physicsregularization approach for the MARL framework is proposed to ensure thedistributed cordon signal controllers are aware of the global network state byencoding MFD-based knowledge into the action-value functions of the localagents. The proposed PC strategy is operated as a two-stage system, with afeedback PC strategy detecting the overall traffic state within the PN and thendistributing local instructions to cordon signals controllers in the MARLframework via the physics regularization. Through numerical tests withdifferent demand patterns in a microscopic traffic environment, the proposed PCstrategy shows promising robustness and transferability. It outperformsstate-of-the-art feedback PC strategies in increasing network throughput,decreasing distributed delay for gate links, and reducing carbon emissions.</description><author>Jiajie Yu, Pierre-Antoine Laharotte, Yu Han, Wei Ma, Ludovic Leclercq</author><pubDate>Fri, 31 May 2024 16:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12985v2</guid></item><item><title>OR-Bench: An Over-Refusal Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2405.20947v1</link><description>Large Language Models (LLMs) require careful safety alignment to preventmalicious outputs. While significant research focuses on mitigating harmfulcontent generation, the enhanced safety often come with the side effect ofover-refusal, where the LLMs may reject innocuous prompts and become lesshelpful. Although the issue of over-refusal has been empirically observed, asystematic measurement is challenging due to the difficulty of crafting promptsthat appear harmful but are benign. This study proposes a novel method forautomatically generating large-scale sets of ``seemingly toxic prompts''(benign prompts likely rejected by LLMs). Leveraging this technique, weintroduce OR-Bench, the first large-scale over-refusal benchmark. OR-Benchcomprises 80,000 seemingly toxic prompts across 10 common rejection categories,a subset of around 1,000 hard prompts that are challenging even forstate-of-the-art LLMs, and an additional 600 toxic prompts to preventindiscriminate responses. We then conduct a comprehensive study to measure theover-refusal of 25 popular LLMs across 8 model families. Our datasets areavailable at https://huggingface.co/datasets/bench-llm/OR-Bench and thecorresponding demo can be found athttps://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark canhelp the community develop better safety aligned models.</description><author>Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh</author><pubDate>Fri, 31 May 2024 16:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20947v1</guid></item><item><title>Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities</title><link>http://arxiv.org/abs/2405.18669v2</link><description>Integrating multiple generative foundation models, especially those trainedon different modalities, into something greater than the sum of its parts posessignificant challenges. Two key hurdles are the availability of aligned data(concepts that contain similar meaning but is expressed differently indifferent modalities), and effectively leveraging unimodal representations incross-domain generative tasks, without compromising their original unimodalcapabilities. We propose Zipper, a multi-tower decoder architecture that addresses theseconcerns by using cross-attention to flexibly compose multimodal generativemodels from independently pre-trained unimodal decoders. In our experimentsfusing speech and text modalities, we show the proposed architecture performsvery competitively in scenarios with limited aligned text-speech data. We alsoshowcase the flexibility of our model to selectively maintain unimodal (e.g.,text-to-text generation) generation performance by freezing the correspondingmodal tower (e.g. text). In cross-modal tasks such as automatic speechrecognition (ASR) where the output modality is text, we show that freezing thetext backbone results in negligible performance degradation. In cross-modaltasks such as text-to-speech generation (TTS) where the output modality isspeech, we show that using a pre-trained speech backbone results in superiorperformance to the baseline.</description><author>Vicky Zayats, Peter Chen, Melissa Ferrari, Dirk Padfield</author><pubDate>Fri, 31 May 2024 16:42:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18669v2</guid></item><item><title>TRAM: Benchmarking Temporal Reasoning for Large Language Models</title><link>http://arxiv.org/abs/2310.00835v3</link><description>Reasoning about time is essential for understanding the nuances of eventsdescribed in natural language. Previous research on this topic has been limitedin scope, characterized by a lack of standardized benchmarks that would allowfor consistent evaluations across different studies. In this paper, weintroduce TRAM, a temporal reasoning benchmark composed of ten datasets,encompassing various temporal aspects of events such as order, arithmetic,frequency, and duration, designed to facilitate a comprehensive evaluation ofthe TeR capabilities of large language models (LLMs). We evaluate popular LLMslike GPT-4 and Llama2 in zero-shot and few-shot scenarios, and establishbaselines with BERT-based and domain-specific models. Our findings indicatethat the best-performing model lags significantly behind human performance. Itis our aspiration that TRAM will spur further progress in enhancing the TeRcapabilities of LLMs.</description><author>Yuqing Wang, Yun Zhao</author><pubDate>Fri, 31 May 2024 16:36:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00835v3</guid></item><item><title>Effective Interplay between Sparsity and Quantization: From Theory to Practice</title><link>http://arxiv.org/abs/2405.20935v1</link><description>The increasing size of deep neural networks necessitates effective modelcompression to improve computational efficiency and reduce their memoryfootprint. Sparsity and quantization are two prominent compression methods thathave individually demonstrated significant reduction in computational andmemory footprints while preserving model accuracy. While effective, theinterplay between these two methods remains an open question. In this paper, weinvestigate the interaction between these two methods and assess whether theircombination impacts final model accuracy. We mathematically prove that applyingsparsity before quantization is the optimal sequence for these operations,minimizing error in computation. Our empirical studies across a wide range ofmodels, including OPT and Llama model families (125M-8B) and ViT corroboratethese theoretical findings. In addition, through rigorous analysis, wedemonstrate that sparsity and quantization are not orthogonal; theirinteraction can significantly harm model accuracy, with quantization errorplaying a dominant role in this degradation. Our findings extend to theefficient deployment of large models in resource-limited compute platforms andreduce serving cost, offering insights into best practices for applying thesecompression methods to maximize efficacy without compromising accuracy.</description><author>Simla Burcu Harma, Ayan Chakraborty, Elizaveta Kostenok, Danila Mishin, Dongho Ha, Babak Falsafi, Martin Jaggi, Ming Liu, Yunho Oh, Suvinay Subramanian, Amir Yazdanbakhsh</author><pubDate>Fri, 31 May 2024 16:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20935v1</guid></item><item><title>Concentration Bounds for Optimized Certainty Equivalent Risk Estimation</title><link>http://arxiv.org/abs/2405.20933v1</link><description>We consider the problem of estimating the Optimized Certainty Equivalent(OCE) risk from independent and identically distributed (i.i.d.) samples. Forthe classic sample average approximation (SAA) of OCE, we derive mean-squarederror as well as concentration bounds (assuming sub-Gaussianity). Further, weanalyze an efficient stochastic approximation-based OCE estimator, and derivefinite sample bounds for the same. To show the applicability of our bounds, weconsider a risk-aware bandit problem, with OCE as the risk. For this problem,we derive bound on the probability of mis-identification. Finally, we conductnumerical experiments to validate the theoretical findings.</description><author>Ayon Ghosh, L. A. Prashanth, Krishna Jagannathan</author><pubDate>Fri, 31 May 2024 16:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20933v1</guid></item><item><title>Learning to Model the World with Language</title><link>http://arxiv.org/abs/2308.01399v2</link><description>To interact with humans and act in the world, agents need to understand therange of language that people use and relate it to the visual world. Whilecurrent agents can learn to execute simple language instructions, we aim tobuild agents that leverage diverse language -- language like "this button turnson the TV" or "I put the bowls away" -- that conveys general knowledge,describes the state of the world, provides interactive feedback, and more. Ourkey idea is that agents should interpret such diverse language as a signal thathelps them predict the future: what they will observe, how the world willbehave, and which situations will be rewarded. This perspective unifieslanguage understanding with future prediction as a powerful self-supervisedlearning objective. We instantiate this in Dynalang, an agent that learns amultimodal world model to predict future text and image representations, andlearns to act from imagined model rollouts. While current methods that learnlanguage-conditioned policies degrade in performance with more diverse types oflanguage, we show that Dynalang learns to leverage environment descriptions,game rules, and instructions to excel on tasks ranging from game-playing tonavigating photorealistic home scans. Finally, we show that our method enablesadditional capabilities due to learning a generative model: Dynalang can bepretrained on text-only data, enabling learning from offline datasets, andgenerate language grounded in an environment.</description><author>Jessy Lin, Yuqing Du, Olivia Watkins, Danijar Hafner, Pieter Abbeel, Dan Klein, Anca Dragan</author><pubDate>Fri, 31 May 2024 16:32:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01399v2</guid></item><item><title>GUIDE: Guidance-based Incremental Learning with Diffusion Models</title><link>http://arxiv.org/abs/2403.03938v2</link><description>We introduce GUIDE, a novel continual learning approach that directsdiffusion models to rehearse samples at risk of being forgotten. Existinggenerative strategies combat catastrophic forgetting by randomly samplingrehearsal examples from a generative model. Such an approach contradictsbuffer-based approaches where sampling strategy plays an important role. Wepropose to bridge this gap by incorporating classifier guidance into thediffusion process to produce rehearsal examples specifically targetinginformation forgotten by a continuously trained model. This approach enablesthe generation of samples from preceding task distributions, which are morelikely to be misclassified in the context of recently encountered classes. Ourexperimental results show that GUIDE significantly reduces catastrophicforgetting, outperforming conventional random sampling approaches andsurpassing recent state-of-the-art methods in continual learning withgenerative replay.</description><author>Bartosz Cywiski, Kamil Deja, Tomasz Trzciski, Bartomiej Twardowski, ukasz Kuciski</author><pubDate>Fri, 31 May 2024 16:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03938v2</guid></item></channel></rss>