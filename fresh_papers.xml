<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 07 Oct 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2510.03232v1</link><description>Multimodal Large Language Models (MLLMs) have achieved strong performance ongeneral visual benchmarks but struggle with out-of-distribution (OOD) tasks inspecialized domains such as medical imaging, where labeled data is limited andexpensive. We introduce LEAML, a label-efficient adaptation framework thatleverages both scarce labeled VQA samples and abundant unlabeled images. Ourapproach generates domain-relevant pseudo question-answer pairs for unlabeleddata using a QA generator regularized by caption distillation. Importantly, weselectively update only those neurons most relevant to question-answering,enabling the QA Generator to efficiently acquire domain-specific knowledgeduring distillation. Experiments on gastrointestinal endoscopy and sports VQAdemonstrate that LEAML consistently outperforms standard fine-tuning underminimal supervision, highlighting the effectiveness of our proposed LEAMLframework.</description><author>Ci-Siang Lin, Min-Hung Chen, Yu-Yang Sheng, Yu-Chiang Frank Wang</author><pubDate>Fri, 03 Oct 2025 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03232v1</guid></item><item><title>Reward Models are Metrics in a Trench Coat</title><link>http://arxiv.org/abs/2510.03231v1</link><description>The emergence of reinforcement learning in post-training of large languagemodels has sparked significant interest in reward models. Reward models assessthe quality of sampled model outputs to generate training signals. This task isalso performed by evaluation metrics that monitor the performance of an AImodel. We find that the two research areas are mostly separate, leading toredundant terminology and repeated pitfalls. Common challenges includesusceptibility to spurious correlations, impact on downstream reward hacking,methods to improve data quality, and approaches to meta-evaluation. Ourposition paper argues that a closer collaboration between the fields can helpovercome these issues. To that end, we show how metrics outperform rewardmodels on specific tasks and provide an extensive survey of the two areas.Grounded in this survey, we point to multiple research topics in which closeralignment can improve reward models and metrics in areas such as preferenceelicitation methods, avoidance of spurious correlations and reward hacking, andcalibration-aware meta-evaluation.</description><author>Sebastian Gehrmann</author><pubDate>Fri, 03 Oct 2025 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03231v1</guid></item><item><title>Improving GUI Grounding with Explicit Position-to-Coordinate Mapping</title><link>http://arxiv.org/abs/2510.03230v1</link><description>GUI grounding, the task of mapping natural-language instructions to pixelcoordinates, is crucial for autonomous agents, yet remains difficult forcurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, whichbreaks when extrapolating to high-resolution displays unseen during training.Current approaches generate coordinates as text tokens directly from visualfeatures, forcing the model to infer complex position-to-pixel mappingsimplicitly; as a result, accuracy degrades and failures proliferate on newresolutions. We address this with two complementary innovations. First, RULERtokens serve as explicit coordinate markers, letting the model referencepositions similar to gridlines on a map and adjust rather than generatecoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatialencoding by ensuring that width and height dimensions are represented equally,addressing the asymmetry of standard positional schemes. Experiments onScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains ingrounding accuracy, with the largest improvements on high-resolutioninterfaces. By providing explicit spatial guidance rather than relying onimplicit learning, our approach enables more reliable GUI automation acrossdiverse resolutions and platforms.</description><author>Suyuchen Wang, Tianyu Zhang, Ahmed Masry, Christopher Pal, Spandana Gella, Bang Liu, Perouz Taslakian</author><pubDate>Fri, 03 Oct 2025 17:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03230v1</guid></item><item><title>Equivariant Splitting: Self-supervised learning from incomplete data</title><link>http://arxiv.org/abs/2510.00929v3</link><description>Self-supervised learning for inverse problems allows to train areconstruction network from noise and/or incomplete data alone. These methodshave the potential of enabling learning-based solutions when obtainingground-truth references for training is expensive or even impossible. In thispaper, we propose a new self-supervised learning strategy devised for thechallenging setting where measurements are observed via a single incompleteobservation model. We introduce a new definition of equivariance in the contextof reconstruction networks, and show that the combination of self-supervisedsplitting losses and equivariant reconstruction networks results in the sameminimizer in expectation as the one of a supervised loss. Through a series ofexperiments on image inpainting, accelerated magnetic resonance imaging, andcompressive sensing, we demonstrate that the proposed loss achievesstate-of-the-art performance in settings with highly rank-deficient forwardmodels.</description><author>Victor Sechaud, Jérémy Scanvic, Quentin Barthélemy, Patrice Abry, Julián Tachella</author><pubDate>Fri, 03 Oct 2025 17:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00929v3</guid></item><item><title>Generative Modeling of Weights: Generalization or Memorization?</title><link>http://arxiv.org/abs/2506.07998v2</link><description>Generative models have recently been explored for synthesizing neural networkweights. These approaches take neural network checkpoints as training data andaim to generate high-performing weights during inference. In this work, weexamine four representative, well-known methods on their ability to generatenovel model weights, i.e., weights that are different from the checkpoints seenduring training. Contrary to claims in prior work, we find that these methodssynthesize weights largely by memorization: they produce either replicas, or,at best, simple interpolations of the training checkpoints. Moreover, they failto outperform simple baselines, such as adding noise to the weights or taking asimple weight ensemble, in obtaining different and simultaneouslyhigh-performing models. Our further analysis suggests that this memorizationmight result from limited data, overparameterized models, and the underuse ofstructural priors specific to weight data. These findings highlight the needfor more careful design and rigorous evaluation of generative models whenapplied to new domains. Our code is available athttps://github.com/boyazeng/weight_memorization.</description><author>Boya Zeng, Yida Yin, Zhiqiu Xu, Zhuang Liu</author><pubDate>Fri, 03 Oct 2025 17:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.07998v2</guid></item><item><title>MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture Recognition</title><link>http://arxiv.org/abs/2510.03228v1</link><description>Randomized neural networks for representation learning have consistentlyachieved prominent results in texture recognition tasks, effectively combiningthe advantages of both traditional techniques and learning-based approaches.However, existing approaches have so far focused mainly on improvingcross-information prediction, without introducing significant advancements tothe overall randomized network architecture. In this paper, we propose Mixer, anovel randomized neural network for texture representation learning. At itscore, the method leverages hyperspherical random embeddings coupled with adual-branch learning module to capture both intra- and inter-channelrelationships, further enhanced by a newly formulated optimization problem forbuilding rich texture representations. Experimental results have shown theinteresting results of the proposed approach across several pure texturebenchmarks, each with distinct characteristics and challenges. The source codewill be available upon publication.</description><author>Ricardo T. Fares, Lucas C. Ribas</author><pubDate>Fri, 03 Oct 2025 17:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03228v1</guid></item><item><title>A fast non-reversible sampler for Bayesian finite mixture models</title><link>http://arxiv.org/abs/2510.03226v1</link><description>Finite mixtures are a cornerstone of Bayesian modelling, and it is well-knownthat sampling from the resulting posterior distribution can be a hard task. Inparticular, popular reversible Markov chain Monte Carlo schemes are often slowto converge when the number of observations $n$ is large. In this paper weintroduce a novel and simple non-reversible sampling scheme for Bayesian finitemixture models, which is shown to drastically outperform classical samplers inmany scenarios of interest, especially during convergence phase and whencomponents in the mixture have non-negligible overlap. At the theoreticallevel, we show that the performance of the proposed non-reversible schemecannot be worse than the standard one, in terms of asymptotic variance, by morethan a factor of four; and we provide a scaling limit analysis suggesting thatthe non-reversible sampler can reduce the convergence time from O$(n^2)$ toO$(n)$. We also discuss why the statistical features of mixture models makethem an ideal case for the use of non-reversible discrete samplers.</description><author>Filippo Ascolani, Giacomo Zanella</author><pubDate>Fri, 03 Oct 2025 17:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03226v1</guid></item><item><title>Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles</title><link>http://arxiv.org/abs/2510.03224v1</link><description>We propose a test-time defense mechanism against adversarial attacks:imperceptible image perturbations that significantly alter the predictions of amodel. Unlike existing methods that rely on feature filtering or smoothing,which can lead to information loss, we propose to "combat noise with noise" byleveraging stochastic resonance to enhance robustness while minimizinginformation loss. Our approach introduces small translational perturbations tothe input image, aligns the transformed feature embeddings, and aggregates thembefore mapping back to the original reference image. This can be expressed in aclosed-form formula, which can be deployed on diverse existing networkarchitectures without introducing additional network modules or fine-tuning forspecific attack types. The resulting method is entirely training-free,architecture-agnostic, and attack-agnostic. Empirical results showstate-of-the-art robustness on image classification and, for the first time,establish a generic test-time defense for dense prediction tasks, includingstereo matching and optical flow, highlighting the method's versatility andpracticality. Specifically, relative to clean (unperturbed) performance, ourmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%on stereo matching, and 29.2% on optical flow under various types ofadversarial attacks.</description><author>Dong Lao, Yuxiang Zhang, Haniyeh Ehsani Oskouie, Yangchao Wu, Alex Wong, Stefano Soatto</author><pubDate>Fri, 03 Oct 2025 17:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03224v1</guid></item><item><title>Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment</title><link>http://arxiv.org/abs/2510.03223v1</link><description>To solve complex reasoning tasks for Large Language Models (LLMs),prompting-based methods offer a lightweight alternative to fine-tuning andreinforcement learning. However, as reasoning chains extend, criticalintermediate steps and the original prompt will be buried in the context,receiving insufficient attention and leading to errors. In this paper, wepropose Self-Anchor, a novel pipeline that leverages the inherent structure ofreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectoriesinto structured plans and automatically aligns the model's attention to themost relevant inference steps, allowing the model to maintain focus throughoutgeneration. Our experiment shows that Self-Anchor outperforms SOTA promptingmethods across six benchmarks. Notably, Self-Anchor significantly reduces theperformance gap between ``non-reasoning'' models and specialized reasoningmodels, with the potential to enable most LLMs to tackle complex reasoningtasks without retraining.</description><author>Hongxiang Zhang, Yuan Tian, Tianyi Zhang</author><pubDate>Fri, 03 Oct 2025 17:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03223v1</guid></item><item><title>Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward</title><link>http://arxiv.org/abs/2510.03222v1</link><description>Reinforcement Learning with Verifiable Rewards (RLVR) has propelled LargeLanguage Models in complex reasoning, yet its scalability is often hindered bya training bottleneck where performance plateaus as policy entropy collapses,signaling a loss of exploration. Previous methods typically address this bymaintaining high policy entropy, yet the precise mechanisms that governmeaningful exploration have remained underexplored. Our analysis suggests thatan unselective focus on entropy risks amplifying irrelevant tokens anddestabilizing training. This paper investigates the exploration dynamics withinRLVR and identifies a key issue: the gradual elimination of valuablelow-probability exploratory tokens, which we term \textbf{\textit{reasoningsparks}}. We find that while abundant in pre-trained models, these sparks aresystematically extinguished during RLVR due to over-penalization, leading to adegeneracy in exploration. To address this, we introduce Low-probabilityRegularization (Lp-Reg). Its core mechanism regularizes the policy towards aheuristic proxy distribution. This proxy is constructed by filtering outpresumed noise tokens and re-normalizing the distribution over the remainingcandidates. The result is a less-noisy proxy where the probability of\textit{reasoning sparks} is amplified, which then serves as a softregularization target to shield these valuable tokens from elimination via KLdivergence. Experiments show that Lp-Reg enables stable on-policy training foraround 1,000 steps, a regime where baseline entropy-control methods collapse.This sustained exploration leads to state-of-the-art performance, achieving a$60.17\%$ average accuracy on five math benchmarks, an improvement of $2.66\%$over prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.</description><author>Guanhua Huang, Tingqiang Xu, Mingze Wang, Qi Yi, Xue Gong, Siheng Li, Ruibin Xiong, Kejiao Li, Yuhao Jiang, Bo Zhou</author><pubDate>Fri, 03 Oct 2025 17:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03222v1</guid></item><item><title>Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair</title><link>http://arxiv.org/abs/2510.03217v1</link><description>Agentic Automated Program Repair (APR) is increasingly tackling complex,repository-level bugs in industry, but ultimately agent-generated patches stillneed to be reviewed by a human before committing them to ensure they addressthe bug. Showing unlikely patches to developers can lead to substantial noise,wasting valuable developer time and eroding trust in automated code changes. Weintroduce two complementary LLM-based policies to reduce such noise: bugabstention and patch validation policies. Bug abstention excludes bugs that theagentic APR system is unlikely to fix. Patch validation rejects patches thatare unlikely to be a good fix for the given bug. We evaluate both policies onthree sets of bugs from Google's codebase, and their candidate patchesgenerated by an internal agentic APR system. On a set of 174 human-reportedbugs, removing bugs and patch trajectories rejected by our policies can raisesuccess rates by up to 13 percentage points and 15 percentage points,respectively, and by up to 39 percentage points in combination. On null pointerexceptions and sanitizer-reported bugs with machine-generated bug reports,patch validation also improves average single-sample success rates. Thistwo-policy approach provides a practical path to the reliable, industrial-scaledeployment of agentic APR systems.</description><author>José Cambronero, Michele Tufano, Sherry Shi, Renyao Wei, Grant Uy, Runxiang Cheng, Chin-Jung Liu, Shiying Pan, Satish Chandra, Pat Rondon</author><pubDate>Fri, 03 Oct 2025 17:53:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03217v1</guid></item><item><title>Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation</title><link>http://arxiv.org/abs/2510.03216v1</link><description>For equitable deployment of AI tools in hospitals and healthcare facilities,we need Deep Segmentation Networks that offer high performance and can betrained on cost-effective GPUs with limited memory and large batch sizes. Inthis work, we propose Wave-GMS, a lightweight and efficient multi-scalegenerative model for medical image segmentation. Wave-GMS has a substantiallysmaller number of trainable parameters, does not require loadingmemory-intensive pretrained vision foundation models, and supports trainingwith large batch sizes on GPUs with limited memory. We conducted extensiveexperiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument,and HAM10000), demonstrating that Wave-GMS achieves state-of-the-artsegmentation performance with superior cross-domain generalizability, whilerequiring only ~2.6M trainable parameters. Code is available athttps://github.com/ATPLab-LUMS/Wave-GMS.</description><author>Talha Ahmed, Nehal Ahmed Shaikh, Hassan Mohy-ud-Din</author><pubDate>Fri, 03 Oct 2025 17:53:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03216v1</guid></item><item><title>Cache-to-Cache: Direct Semantic Communication Between Large Language Models</title><link>http://arxiv.org/abs/2510.03215v1</link><description>Multi-LLM systems harness the complementary strengths of diverse LargeLanguage Models, achieving performance and efficiency gains unattainable by asingle model. In existing designs, LLMs communicate through text, forcinginternal representations to be transformed into output token sequences. Thisprocess both loses rich semantic information and incurs token-by-tokengeneration latency. Motivated by these limitations, we ask: Can LLMscommunicate beyond text? Oracle experiments show that enriching the KV-Cachesemantics can improve response quality without increasing cache size,supporting KV-Cache as an effective medium for inter-model communication. Thus,we propose Cache-to-Cache (C2C), a new paradigm for direct semanticcommunication between LLMs. C2C uses a neural network to project and fuse thesource model's KV-cache with that of the target model to enable direct semantictransfer. A learnable gating mechanism selects the target layers that benefitfrom cache communication. Compared with text communication, C2C utilizes thedeep, specialized semantics from both models, while avoiding explicitintermediate text generation. Experiments show that C2C achieves 8.5-10.5%higher average accuracy than individual models. It further outperforms the textcommunication paradigm by approximately 3.0-5.0%, while delivering an average2.0x speedup in latency. Our code is available athttps://github.com/thu-nics/C2C.</description><author>Tianyu Fu, Zihan Min, Hanling Zhang, Jichao Yan, Guohao Dai, Wanli Ouyang, Yu Wang</author><pubDate>Fri, 03 Oct 2025 17:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03215v1</guid></item><item><title>LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing</title><link>http://arxiv.org/abs/2406.07714v3</link><description>Greybox fuzzing has achieved success in revealing bugs and vulnerabilities inprograms. However, randomized mutation strategies have limited the fuzzer'sperformance on structured data. Specialized fuzzers can handle complexstructured data, but require additional efforts in grammar and suffer from lowthroughput. In this paper, we explore the potential of utilizing the Large Language Modelto enhance greybox fuzzing for structured data. We utilize the pre-trainedknowledge of LLM about data conversion and format to generate new valid inputs.We further fine-tuned it with paired mutation seeds to learn structured formatand mutation strategies effectively. Our LLM-based fuzzer, LLAMAFUZZ,integrates the power of LLM to understand and mutate structured data tofuzzing. We conduct experiments on the standard bug-based benchmark Magma and awide variety of real-world programs. LLAMAFUZZ outperforms our top competitorby 41 bugs on average. We also identified 47 unique bugs across all trials.Moreover, LLAMAFUZZ demonstrated consistent performance on both bug trigger andbug reached. Compared to AFL++, LLAMAFUZZ achieved 27.19% more branches inreal-world program sets on average. We also demonstrate a case study to explainhow LLMs enhance the fuzzing process in terms of code coverage.</description><author>Hongxiang Zhang, Yuyang Rong, Yifeng He, Hao Chen</author><pubDate>Fri, 03 Oct 2025 17:50:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07714v3</guid></item><item><title>Joint Bidding on Intraday and Frequency Containment Reserve Markets</title><link>http://arxiv.org/abs/2510.03209v1</link><description>As renewable energy integration increases supply variability, battery energystorage systems (BESS) present a viable solution for balancing supply anddemand. This paper proposes a novel approach for optimizing battery BESSparticipation in multiple electricity markets. We develop a joint biddingstrategy that combines participation in the primary frequency reserve marketwith continuous trading in the intraday market, addressing a gap in the extantliterature which typically considers these markets in isolation or simplifiesthe continuous nature of intraday trading. Our approach utilizes a mixedinteger linear programming implementation of the rolling intrinsic algorithmfor intraday decisions and state of charge recovery, alongside a learnedclassifier strategy (LCS) that determines optimal capacity allocation betweenmarkets. A comprehensive out-of-sample backtest over more than one year ofhistorical German market data validates our approach: The LCS increases overallprofits by over 4% compared to the best-performing static strategy and by morethan 3% over a naive dynamic benchmark. Crucially, our method closes the gap toa theoretical perfect foresight strategy to just 4%, demonstrating theeffectiveness of dynamic, learning-based allocation in a complex, multi-marketenvironment.</description><author>Yiming Zhang, Wolfgang Ridinger, David Wozabal</author><pubDate>Fri, 03 Oct 2025 17:48:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03209v1</guid></item><item><title>To Distill or Decide? Understanding the Algorithmic Trade-off in Partially Observable Reinforcement Learning</title><link>http://arxiv.org/abs/2510.03207v1</link><description>Partial observability is a notorious challenge in reinforcement learning(RL), due to the need to learn complex, history-dependent policies. Recentempirical successes have used privileged expert distillation--which leveragesavailability of latent state information during training (e.g., from asimulator) to learn and imitate the optimal latent, Markovian policy--todisentangle the task of "learning to see" from "learning to act". While expertdistillation is more computationally efficient than RL without latent stateinformation, it also has well-documented failure modes. In this paper--througha simple but instructive theoretical model called the perturbed Block MDP, andcontrolled experiments on challenging simulated locomotion tasks--weinvestigate the algorithmic trade-off between privileged expert distillationand standard RL without privileged information. Our main findings are: (1) Thetrade-off empirically hinges on the stochasticity of the latent dynamics, astheoretically predicted by contrasting approximate decodability with beliefcontraction in the perturbed Block MDP; and (2) The optimal latent policy isnot always the best latent policy to distill. Our results suggest newguidelines for effectively exploiting privileged information, potentiallyadvancing the efficiency of policy learning across many practical partiallyobservable domains.</description><author>Yuda Song, Dhruv Rohatgi, Aarti Singh, J. Andrew Bagnell</author><pubDate>Fri, 03 Oct 2025 17:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03207v1</guid></item><item><title>Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner</title><link>http://arxiv.org/abs/2510.03206v1</link><description>Diffusion language models, especially masked discrete diffusion models, haveachieved great success recently. While there are some theoretical and primaryempirical results showing the advantages of latent reasoning with loopedtransformers or continuous chain-of-thoughts, continuous diffusion modelstypically underperform their discrete counterparts. In this paper, we arguethat diffusion language models do not necessarily need to be in the discretespace. In particular, we prove that continuous diffusion models have strongerexpressivity than discrete diffusions and looped transformers. We attribute thecontradiction between the theoretical expressiveness and empirical performanceto their practical trainability: while continuous diffusion providesintermediate supervision that looped transformers lack, they introduceadditional difficulty decoding tokens into the discrete token space from thecontinuous representation space. We therefore propose Coevolutionary ContinuousDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion processon the union of a continuous representation space and a discrete token space,leveraging a single model to simultaneously denoise in the joint space. Bycombining two modalities, CCDD is expressive with rich semantics in the latentspace, as well as good trainability and sample quality with the help ofexplicit discrete tokens. We also propose effective architectures and advancedtraining/sampling techniques for CCDD, which reveals strong empiricalperformance in extensive language modeling experiments on real-world tasks.</description><author>Cai Zhou, Chenxiao Yang, Yi Hu, Chenyu Wang, Chubin Zhang, Muhan Zhang, Lester Mackey, Tommi Jaakkola, Stephen Bates, Dinghuai Zhang</author><pubDate>Fri, 03 Oct 2025 17:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03206v1</guid></item><item><title>MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs</title><link>http://arxiv.org/abs/2509.21634v2</link><description>The evolution toward 6G networks is being accelerated by the Open RadioAccess Network (O-RAN) paradigm -- an open, interoperable architecture thatenables intelligent, modular applications across public telecom and privateenterprise domains. While this openness creates unprecedented opportunities forinnovation, it also expands the attack surface, demanding resilient, low-cost,and autonomous security solutions. Legacy defenses remain largely reactive,labor-intensive, and inadequate for the scale and complexity of next-generationsystems. Current O-RAN applications focus mainly on network optimization orpassive threat detection, with limited capability for closed-loop, automatedresponse. To address this critical gap, we present an agentic AI framework for fullyautomated, end-to-end threat mitigation in 6G O-RAN environments. MobiLLMorchestrates security workflows through a modular multi-agent system powered byLarge Language Models (LLMs). The framework features a Threat Analysis Agentfor real-time data triage, a Threat Classification Agent that usesRetrieval-Augmented Generation (RAG) to map anomalies to specificcountermeasures, and a Threat Response Agent that safely operationalizesmitigation actions via O-RAN control interfaces. Grounded in trusted knowledgebases such as the MITRE FiGHT framework and 3GPP specifications, and equippedwith robust safety guardrails, MobiLLM provides a blueprint for trustworthyAI-driven network security. Initial evaluations demonstrate that MobiLLM caneffectively identify and orchestrate complex mitigation strategies,significantly reducing response latency and showcasing the feasibility ofautonomous security operations in 6G.</description><author>Prakhar Sharma, Haohuang Wen, Vinod Yegneswaran, Ashish Gehani, Phillip Porras, Zhiqiang Lin</author><pubDate>Fri, 03 Oct 2025 17:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21634v2</guid></item><item><title>Controlled Generation with Equivariant Variational Flow Matching</title><link>http://arxiv.org/abs/2506.18340v3</link><description>We derive a controlled generation objective within the framework ofVariational Flow Matching (VFM), which casts flow matching as a variationalinference problem. We demonstrate that controlled generation can be implementedtwo ways: (1) by way of end-to-end training of conditional generative models,or (2) as a Bayesian inference problem, enabling post hoc control ofunconditional models without retraining. Furthermore, we establish theconditions required for equivariant generation and provide an equivariantformulation of VFM tailored for molecular generation, ensuring invariance torotations, translations, and permutations. We evaluate our approach on bothuncontrolled and controlled molecular generation, achieving state-of-the-artperformance on uncontrolled generation and outperforming state-of-the-artmodels in controlled generation, both with end-to-end training and in theBayesian inference setting. This work strengthens the connection betweenflow-based generative modeling and Bayesian inference, offering a scalable andprincipled framework for constraint-driven and symmetry-aware generation.</description><author>Floor Eijkelboom, Heiko Zimmermann, Sharvaree Vadgama, Erik J Bekkers, Max Welling, Christian A. Naesseth, Jan-Willem van de Meent</author><pubDate>Fri, 03 Oct 2025 17:43:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.18340v3</guid></item><item><title>Automatic Generation of Digital Twins for Network Testing</title><link>http://arxiv.org/abs/2510.03205v1</link><description>The increased use of software in the operation and management oftelecommunication networks has moved the industry one step closer to realizingautonomous network operation. One consequence of this shift is thesignificantly increased need for testing and validation before such softwarecan be deployed. Complementing existing simulation or hardware-basedapproaches, digital twins present an environment to achieve this testing;however, they require significant time and human effort to configure andexecute. This paper explores the automatic generation of digital twins toprovide efficient and accurate validation tools, aligned to the ITU-Tautonomous network architecture's experimentation subsystem. We presentexperimental results for an initial use case, demonstrating that the approachis feasible in automatically creating efficient digital twins with sufficientaccuracy to be included as part of existing validation pipelines.</description><author>Shenjia Ding, David Flynn, Paul Harvey</author><pubDate>Fri, 03 Oct 2025 17:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03205v1</guid></item><item><title>MIRROR: Modular Internal Processing for Personalized Safety in LLM Dialogue</title><link>http://arxiv.org/abs/2506.00430v2</link><description>Large language models frequently generate harmful recommendations in personalmulti-turn dialogue by ignoring user-specific safety context, exhibitingsycophantic agreement, and compromising user safety for larger grouppreferences. We introduce MIRROR, a modular production-focused architecturethat prevents these failures through a persistent, bounded internal state thatpreserves personal conversational information across conversational turns. Ourdual-component design inspired by Dual Process Theory separates immediateresponse generation (Talker) from asynchronous deliberative processing(Thinker), which synthesizes parallel reasoning threads between turns withmarginal latency. On the CuRaTe personalized safety benchmark, MIRROR-augmentedmodels achieve a 21% relative improvement (69% to 84%) across seven diversefrontier models, with open-source Llama 4 and Mistral 3 variants surpassingboth GPT-4o and Claude 3.7 Sonnet at only \$0.0028 to \$0.0172 additional costper turn, narrowing the gap between affordable open-source models to frontiersystems in the safety space. The modular architecture enables flexibledeployment: full internal processing for affordable models or single-componentconfigurations for expensive systems, democratizing access to safer,personalized AI.</description><author>Nicole Hsing</author><pubDate>Fri, 03 Oct 2025 17:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.00430v2</guid></item><item><title>FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents</title><link>http://arxiv.org/abs/2510.03204v1</link><description>Web agents powered by large language models (LLMs) must process lengthy webpage observations to complete user goals; these pages often exceed tens ofthousands of tokens. This saturates context limits and increases computationalcost processing; moreover, processing full pages exposes agents to securityrisks such as prompt injection. Existing pruning strategies either discardrelevant content or retain irrelevant context, leading to suboptimal actionprediction. We introduce FocusAgent, a simple yet effective approach thatleverages a lightweight LLM retriever to extract the most relevant lines fromaccessibility tree (AxTree) observations, guided by task goals. By pruningnoisy and irrelevant content, FocusAgent enables efficient reasoning whilereducing vulnerability to injection attacks. Experiments on WorkArena andWebArena benchmarks show that FocusAgent matches the performance of strongbaselines, while reducing observation size by over 50%. Furthermore, a variantof FocusAgent significantly reduces the success rate of prompt-injectionattacks, including banner and pop-up attacks, while maintaining task successperformance in attack-free settings. Our results highlight that targetedLLM-based retrieval is a practical and robust strategy for building web agentsthat are efficient, effective, and secure.</description><author>Imene Kerboua, Sahar Omidi Shayegan, Megh Thakkar, Xing Han Lù, Léo Boisvert, Massimo Caccia, Jérémy Espinas, Alexandre Aussem, Véronique Eglin, Alexandre Lacoste</author><pubDate>Fri, 03 Oct 2025 17:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03204v1</guid></item><item><title>Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer</title><link>http://arxiv.org/abs/2510.03202v1</link><description>We present NN-Rank, an algorithm for ranking source languages forcross-lingual transfer, which leverages hidden representations frommultilingual models and unlabeled target-language data. We experiment with twopretrained multilingual models and two tasks: part-of-speech tagging (POS) andnamed entity recognition (NER). We consider 51 source languages and evaluate on56 and 72 target languages for POS and NER, respectively. When using in-domaindata, NN-Rank beats state-of-the-art baselines that leverage lexical andlinguistic features, with average improvements of up to 35.56 NDCG for POS and18.14 NDCG for NER. As prior approaches can fall back to language-levelfeatures if target language data is not available, we show that NN-Rank remainscompetitive using only the Bible, an out-of-domain corpus available for a largenumber of languages. Ablations on the amount of unlabeled target data showthat, for subsets consisting of as few as 25 examples, NN-Rank produceshigh-quality rankings which achieve 92.8% of the NDCG achieved using allavailable target data for ranking.</description><author>Abteen Ebrahimi, Adam Wiemerslage, Katharina von der Wense</author><pubDate>Fri, 03 Oct 2025 17:39:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03202v1</guid></item><item><title>MonSTeR: a Unified Model for Motion, Scene, Text Retrieval</title><link>http://arxiv.org/abs/2510.03200v1</link><description>Intention drives human movement in complex environments, but such movementcan only happen if the surrounding context supports it. Despite the intuitivenature of this mechanism, existing research has not yet provided tools toevaluate the alignment between skeletal movement (motion), intention (text),and the surrounding context (scene). In this work, we introduce MonSTeR, thefirst MOtioN-Scene-TExt Retrieval model. Inspired by the modeling ofhigher-order relations, MonSTeR constructs a unified latent space by leveragingunimodal and cross-modal representations. This allows MonSTeR to capture theintricate dependencies between modalities, enabling flexible but robustretrieval across various tasks. Our results show that MonSTeR outperformstrimodal models that rely solely on unimodal representations. Furthermore, wevalidate the alignment of our retrieval scores with human preferences through adedicated user study. We demonstrate the versatility of MonSTeR's latent spaceon zero-shot in-Scene Object Placement and Motion Captioning. Code andpre-trained models are available at github.com/colloroneluca/MonSTeR.</description><author>Luca Collorone, Matteo Gioia, Massimiliano Pappa, Paolo Leoni, Giovanni Ficarra, Or Litany, Indro Spinelli, Fabio Galasso</author><pubDate>Fri, 03 Oct 2025 17:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03200v1</guid></item><item><title>When Large Language Models are Reliable for Judging Empathic Communication</title><link>http://arxiv.org/abs/2506.10150v2</link><description>Large language models (LLMs) excel at generating empathic responses intext-based conversations. But, how reliably do they judge the nuances ofempathic communication? We investigate this question by comparing how experts,crowdworkers, and LLMs annotate empathic communication across four evaluativeframeworks drawn from psychology, natural language processing, andcommunications applied to 200 real-world conversations where one speaker sharesa personal problem and the other offers support. Drawing on 3,150 expertannotations, 2,844 crowd annotations, and 3,150 LLM annotations, we assessinter-rater reliability between these three annotator groups. We find thatexpert agreement is high but varies across the frameworks' sub-componentsdepending on their clarity, complexity, and subjectivity. We show that expertagreement offers a more informative benchmark for contextualizing LLMperformance than standard classification metrics. Across all four frameworks,LLMs consistently approach this expert level benchmark and exceed thereliability of crowdworkers. These results demonstrate how LLMs, when validatedon specific tasks with appropriate benchmarks, can support transparency andoversight in emotionally sensitive applications including their use asconversational companions.</description><author>Aakriti Kumar, Nalin Poungpeth, Diyi Yang, Erina Farrell, Bruce Lambert, Matthew Groh</author><pubDate>Fri, 03 Oct 2025 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.10150v2</guid></item><item><title>FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering</title><link>http://arxiv.org/abs/2508.14052v4</link><description>Accurate information retrieval (IR) is critical in the financial domain,where investors must identify relevant information from large collections ofdocuments. Traditional IR methods -- whether sparse or dense -- often fallshort in retrieval accuracy, as it requires not only capturing semanticsimilarity but also performing fine-grained reasoning over document structureand domain-specific knowledge. Recent advances in large language models (LLMs)have opened up new opportunities for retrieval with multi-step reasoning, wherethe model ranks passages through iterative reasoning about which information ismost relevant to a given query. However, there exists no benchmark to evaluatesuch capabilities in the financial domain. To address this gap, we introduceFinAgentBench, the first large-scale benchmark for evaluating retrieval withmulti-step reasoning in finance -- a setting we term agentic retrieval. Thebenchmark consists of 26K expert-annotated examples on S&amp;P-500 listed firms andassesses whether LLM agents can (1) identify the most relevant document typeamong candidates, and (2) pinpoint the key passage within the selecteddocument. Our evaluation framework explicitly separates these two reasoningsteps to address context limitations. This design enables to provide aquantitative basis for understanding retrieval-centric LLM behavior in finance.We evaluate a suite of state-of-the-art models and further demonstrated howtargeted fine-tuning can significantly improve agentic retrieval performance.Our benchmark provides a foundation for studying retrieval-centric LLM behaviorin complex, domain-specific tasks for finance.</description><author>Chanyeol Choi, Jihoon Kwon, Alejandro Lopez-Lira, Chaewoon Kim, Minjae Kim, Juneha Hwang, Jaeseon Ha, Hojun Choi, Suyeol Yun, Yongjin Kim, Yongjae Lee</author><pubDate>Fri, 03 Oct 2025 17:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.14052v4</guid></item><item><title>Best-of-Majority: Minimax-Optimal Strategy for Pass@$k$ Inference Scaling</title><link>http://arxiv.org/abs/2510.03199v1</link><description>LLM inference often generates a batch of candidates for a prompt and selectsone via strategies like majority voting or Best-of- N (BoN). For difficulttasks, this single-shot selection often underperforms. Consequently,evaluations commonly report Pass@$k$: the agent may submit up to $k$ responses,and only the best of them is used when computing regret. Motivated by this, westudy inference scaling in the more general Pass@$k$ inference setting, andprove that neither majority voting nor BoN exhibits the desirable scaling with$k$ and the sampling budget $N$. Combining the advantages of majority votingand BoN, we propose a new inference strategy called Best-of-Majority (BoM),with a pivotal step that restricts the candidates to the responses with highfrequency in the $N$ samples before selecting the top-$k$ rewards. We provethat when the sampling budget is $N=\tilde\Omega(C^*)$, the regret of BoM is$O(\epsilon_{\mathrm{opt}}+\sqrt{\epsilon_{\mathrm{RM}}^2C^*/k})$, where $C^*$is the coverage coefficient, $\epsilon_{\mathrm{RM}}$ is the estimation errorof the reward model, and $\epsilon_{\mathrm{opt}}$ is the estimation error ofreward at the optimal response. We further establish a matching lower bound,certifying that our algorithm is minimax optimal. Beyond optimality, BoM has akey advantage: unlike majority voting and BoN, its performance does not degradewhen increasing $N$. Experimental results of inference on math problems showBoM outperforming both majority voting and BoN.</description><author>Qiwei Di, Kaixuan Ji, Xuheng Li, Heyang Zhao, Quanquan Gu</author><pubDate>Fri, 03 Oct 2025 17:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03199v1</guid></item><item><title>Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft</title><link>http://arxiv.org/abs/2510.03198v1</link><description>Autoregressive video diffusion models have proved effective for worldmodeling and interactive scene generation, with Minecraft gameplay as arepresentative application. To faithfully simulate play, a model must generatenatural content while exploring new scenes and preserve spatial consistencywhen revisiting explored areas. Under limited computation budgets, it mustcompress and exploit historical cues within a finite context window, whichexposes a trade-off: Temporal-only memory lacks long-term spatial consistency,whereas adding spatial memory strengthens consistency but may degrade new scenegeneration quality when the model over-relies on insufficient spatial context.We present Memory Forcing, a learning framework that pairs training protocolswith a geometry-indexed spatial memory. Hybrid Training exposes distinctgameplay regimes, guiding the model to rely on temporal memory duringexploration and incorporate spatial memory for revisits. Chained ForwardTraining extends autoregressive training with model rollouts, where chainedpredictions create larger pose variations and encourage reliance on spatialmemory for maintaining consistency. Point-to-Frame Retrieval efficientlyretrieves history by mapping currently visible points to their source frames,while Incremental 3D Reconstruction maintains and updates an explicit 3D cache.Extensive experiments demonstrate that Memory Forcing achieves superiorlong-term spatial consistency and generative quality across diverseenvironments, while maintaining computational efficiency for extendedsequences.</description><author>Junchao Huang, Xinting Hu, Boyao Han, Shaoshuai Shi, Zhuotao Tian, Tianyu He, Li Jiang</author><pubDate>Fri, 03 Oct 2025 17:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03198v1</guid></item><item><title>Estimation of Resistance Training RPE using Inertial Sensors and Electromyography</title><link>http://arxiv.org/abs/2510.03197v1</link><description>Accurate estimation of rating of perceived exertion (RPE) can enhanceresistance training through personalized feedback and injury prevention. Thisstudy investigates the application of machine learning models to estimate RPEduring single-arm dumbbell bicep curls, using data from wearable inertial andelectromyography (EMG) sensors. A custom dataset of 69 sets and over 1000repetitions was collected, with statistical features extracted for modeltraining. Among the models evaluated, a random forest classifier achieved thehighest performance, with 41.4% exact accuracy and 85.9% $\pm1$ RPE accuracy.While the inclusion of EMG data slightly improved model accuracy over inertialsensors alone, its utility may have been limited by factors such as dataquality and placement sensitivity. Feature analysis highlighted eccentricrepetition time as the strongest RPE predictor. The results demonstrate thefeasibility of wearable-sensor-based RPE estimation and identify key challengesfor improving model generalizability.</description><author>James Thomas, Johan Wahlström</author><pubDate>Fri, 03 Oct 2025 17:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03197v1</guid></item><item><title>The Challenges of Hyperparameter Tuning for Accurate Causal Effect Estimation</title><link>http://arxiv.org/abs/2303.01412v2</link><description>ML is playing an increasingly crucial role in estimating causal effects oftreatments on outcomes from observational data. Many ML methods (`causalestimators') have been proposed for this task. All of these methods, as withany ML approach, require extensive hyperparameter tuning. For non-causalpredictive tasks, there is a consensus on the choice of tuning metrics (e.g.mean squared error), making it simple to compare models. However, for causalinference tasks, such a consensus is yet to be reached, making any comparisonof causal models difficult. On top of that, there is no ideal metric on whichto tune causal estimators, so one must rely on proxies. Furthermore, the factthat model selection in causal inference involves multiple components (causalestimator, ML regressor, hyperparameters, metric), complicates the issue evenfurther. In order to evaluate the importance of each component, we perform anextensive empirical study on their combination. Our experimental setup involvesmany commonly used causal estimators, regressors (`base learners' henceforth)and metrics applied to four well-known causal inference benchmark datasets. Ourresults show that hyperparameter tuning increased the probability of reachingstate-of-the-art performance in average ($65\% {\rightarrow} 81\%$) andindividualised ($50\% {\rightarrow} 57\%$) effect estimation with only commonlyused estimators. We also show that the performance of standard metrics can beinconsistent across different scenarios. Our findings highlight the need forfurther research to establish whether metrics uniformly capable ofstate-of-the-art performance in causal model evaluation can be found.</description><author>Damian Machlanski, Spyridon Samothrakis, Paul Clarke</author><pubDate>Fri, 03 Oct 2025 17:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01412v2</guid></item><item><title>Exponential Family Variational Flow Matching for Tabular Data Generation</title><link>http://arxiv.org/abs/2506.05940v4</link><description>While denoising diffusion and flow matching have driven major advances ingenerative modeling, their application to tabular data remains limited, despiteits ubiquity in real-world applications. To this end, we develop TabbyFlow, avariational Flow Matching (VFM) method for tabular data generation. To applyVFM to data with mixed continuous and discrete features, we introduceExponential Family Variational Flow Matching (EF-VFM), which representsheterogeneous data types using a general exponential family distribution. Wehereby obtain an efficient, data-driven objective based on moment matching,enabling principled learning of probability paths over mixed continuous anddiscrete variables. We also establish a connection between variational flowmatching and generalized flow matching objectives based on Bregman divergences.Evaluation on tabular data benchmarks demonstrates state-of-the-art performancecompared to baselines.</description><author>Andrés Guzmán-Cordero, Floor Eijkelboom, Jan-Willem van de Meent</author><pubDate>Fri, 03 Oct 2025 17:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05940v4</guid></item><item><title>CoDA: Agentic Systems for Collaborative Data Visualization</title><link>http://arxiv.org/abs/2510.03194v1</link><description>Deep research has revolutionized data analysis, yet data scientists stilldevote substantial time to manually crafting visualizations, highlighting theneed for robust automation from natural language queries. However, currentsystems struggle with complex datasets containing multiple files and iterativerefinement. Existing approaches, including simple single- or multi-agentsystems, often oversimplify the task, focusing on initial query parsing whilefailing to robustly manage data complexity, code errors, or final visualizationquality. In this paper, we reframe this challenge as a collaborativemulti-agent problem. We introduce CoDA, a multi-agent system that employsspecialized LLM agents for metadata analysis, task planning, code generation,and self-reflection. We formalize this pipeline, demonstrating howmetadata-focused analysis bypasses token limits and quality-driven refinementensures robustness. Extensive evaluations show CoDA achieves substantial gainsin the overall score, outperforming competitive baselines by up to 41.5%. Thiswork demonstrates that the future of visualization automation lies not inisolated code generation but in integrated, collaborative agentic workflows.</description><author>Zichen Chen, Jiefeng Chen, Sercan Ö. Arik, Misha Sra, Tomas Pfister, Jinsung Yoon</author><pubDate>Fri, 03 Oct 2025 17:30:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03194v1</guid></item><item><title>IntrusionX: A Hybrid Convolutional-LSTM Deep Learning Framework with Squirrel Search Optimization for Network Intrusion Detection</title><link>http://arxiv.org/abs/2510.00572v2</link><description>Intrusion Detection Systems (IDS) face persistent challenges due to evolvingcyberattacks, high-dimensional traffic data, and severe class imbalance inbenchmark datasets such as NSL-KDD. To address these issues, we proposeIntrusionX, a hybrid deep learning framework that integrates ConvolutionalNeural Networks (CNNs) for local feature extraction and Long Short-Term Memory(LSTM) networks for temporal modeling. The architecture is further optimizedusing the Squirrel Search Algorithm (SSA), enabling effective hyperparametertuning while maintaining computational efficiency. Our pipeline incorporatesrigorous preprocessing, stratified data splitting, and dynamic class weightingto enhance the detection of rare classes. Experimental evaluation on NSL-KDDdemonstrates that IntrusionX achieves 98% accuracy in binary classification and87% in 5-class classification, with significant improvements in minority classrecall (U2R: 71%, R2L: 93%). The novelty of IntrusionX lies in itsreproducible, imbalance-aware design with metaheuristic optimization.</description><author>Ahsan Farabi, Muhaiminul Rashid Shad, Israt Khandaker</author><pubDate>Fri, 03 Oct 2025 17:20:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00572v2</guid></item><item><title>Product-Quantised Image Representation for High-Quality Image Synthesis</title><link>http://arxiv.org/abs/2510.03191v1</link><description>Product quantisation (PQ) is a classical method for scalable vector encoding,yet it has seen limited usage for latent representations in high-fidelity imagegeneration. In this work, we introduce PQGAN, a quantised image autoencoderthat integrates PQ into the well-known vector quantisation (VQ) framework ofVQGAN. PQGAN achieves a noticeable improvement over state-of-the-art methods interms of reconstruction performance, including both quantisation methods andtheir continuous counterparts. We achieve a PSNR score of 37dB, where priorwork achieves 27dB, and are able to reduce the FID, LPIPS, and CMMD score by upto 96%. Our key to success is a thorough analysis of the interaction betweencodebook size, embedding dimensionality, and subspace factorisation, withvector and scalar quantisation as special cases. We obtain novel findings, suchthat the performance of VQ and PQ behaves in opposite ways when scaling theembedding dimension. Furthermore, our analysis shows performance trends for PQthat help guide optimal hyperparameter selection. Finally, we demonstrate thatPQGAN can be seamlessly integrated into pre-trained diffusion models. Thisenables either a significantly faster and more compute-efficient generation, ora doubling of the output resolution at no additional cost, positioning PQ as astrong extension for discrete latent representation in image synthesis.</description><author>Denis Zavadski, Nikita Philip Tatsch, Carsten Rother</author><pubDate>Fri, 03 Oct 2025 17:17:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03191v1</guid></item><item><title>Dynamic Prompt Generation for Interactive 3D Medical Image Segmentation Training</title><link>http://arxiv.org/abs/2510.03189v1</link><description>Interactive 3D biomedical image segmentation requires efficient models thatcan iteratively refine predictions based on user prompts. Current foundationmodels either lack volumetric awareness or suffer from limited interactivecapabilities. We propose a training strategy that combines dynamic volumetricprompt generation with content-aware adaptive cropping to optimize the use ofthe image encoder. Our method simulates realistic user interaction patternsduring training while addressing the computational challenges of learning fromsequential refinement feedback on a single GPU. For efficient training, weinitialize our network using the publicly available weights from thennInteractive segmentation model. Evaluation on the \textbf{Foundation Modelsfor Interactive 3D Biomedical Image Segmentation} competition demonstratesstrong performance with an average final Dice score of 0.6385, normalizedsurface distance of 0.6614, and area-under-the-curve metrics of 2.4799 (Dice)and 2.5671 (NSD).</description><author>Tidiane Camaret Ndir, Alexander Pfefferle, Robin Tibor Schirrmeister</author><pubDate>Fri, 03 Oct 2025 17:16:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03189v1</guid></item><item><title>Superposition disentanglement of neural representations reveals hidden alignment</title><link>http://arxiv.org/abs/2510.03186v1</link><description>The superposition hypothesis states that a single neuron within a populationmay participate in the representation of multiple features in order for thepopulation to represent more features than the number of neurons. Inneuroscience and AI, representational alignment metrics measure the extent towhich different deep neural networks (DNNs) or brains represent similarinformation. In this work, we explore a critical question: \textit{doessuperposition interact with alignment metrics in any undesirable way?} Wehypothesize that models which represent the same features in \textit{differentsuperposition arrangements}, i.e., their neurons have different linearcombinations of the features, will interfere with predictive mapping metrics(semi-matching, soft-matching, linear regression), producing lower alignmentthan expected. We first develop a theory for how the strict permutation metricsare dependent on superposition arrangements. This is tested by training sparseautoencoders (SAEs) to disentangle superposition in toy models, where alignmentscores are shown to typically increase when a model's base neurons are replacedwith its sparse overcomplete latent codes. We find similar increases forDNN\(\rightarrow\)DNN and DNN\(\rightarrow\)brain linear regression alignmentin the visual domain. Our results suggest that superposition disentanglement isnecessary for mapping metrics to uncover the true representational alignmentbetween neural codes.</description><author>André Longon, David Klindt, Meenakshi Khosla</author><pubDate>Fri, 03 Oct 2025 17:12:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03186v1</guid></item><item><title>Understanding How CodeLLMs (Mis)Predict Types with Activation Steering</title><link>http://arxiv.org/abs/2404.01903v3</link><description>Large Language Models (LLMs) are widely used by software engineers forprogramming tasks. However, research shows that LLMs often lack a deepunderstanding of program semantics. Even minor changes to syntax, such asrenaming variables, can significantly degrade performance across various tasks.In this work, we examine the task of type prediction: given a partially typedprogram, can a model predict a missing type annotations such that the resultingprogram is more typed? We construct a dataset of adversarial examples wheremodels initially predict the correct types, but begin to fail aftersemantically irrelevant edits. This is problematic, as models should ideallygeneralize across different syntactic forms of semantically equivalent code.This lack of robustness suggests that models may have a shallow understandingof code semantics. Despite this, we provide evidence that LLMs do, in fact,learn robust mechanisms for type prediction-though these mechanisms often failto activate in adversarial scenarios. By using activation steering, a methodthat manipulates a model's internal activations to guide it toward using latentknowledge, we restore accurate predictions on adversarial inputs. We show thatsteering successfully activates a type prediction mechanism that is shared byboth Python and TypeScript, and is more effective than prompting within-context examples. Across five different models, our comprehensive evaluationdemonstrates that LLMs can learn generalizable representations of codesemantics that transfer across programming languages.</description><author>Francesca Lucchetti, Arjun Guha</author><pubDate>Fri, 03 Oct 2025 17:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01903v3</guid></item><item><title>PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning</title><link>http://arxiv.org/abs/2510.03185v1</link><description>Benchmarks for competition-style reasoning have advanced evaluation inmathematics and programming, yet physics remains comparatively explored. Mostexisting physics benchmarks evaluate only final answers, which fail to capturereasoning processes, while recent stepwise methods rely on heuristicLLM-as-judge scoring or restrictive linear assumptions, limiting reliabilityand diagnostic validity. We introduce PRISM-Physics, a process-level evaluationframework and benchmark for complex physics reasoning problems. Solutions arerepresented as directed acyclic graphs (DAGs) of formulas, explicitly encodingcausal dependencies among intermediate steps to enable fine-grained,interpretable, and theoretically grounded scoring. We prove the optimality ofthe DAG representation and the corresponding scoring policy. Combining with afully rule-based method for symbolic formula equivalence matching that wedeveloped, we ensure consistent validation across diverse formulations withoutheuristic judgments. Results show that our evaluation framework is more alignedwith human experts' scoring. Experiments on state-of-the-art LLMs revealpersistent reasoning failures in physics, while step-level scoring offers bothdiagnostic insight and rich signals for later training. By combining structuralrigor, theoretical guarantees, and symbolic validation, PRISM-Physics providesa principled foundation for advancing process-level evaluation and guiding thedevelopment of models with deeper scientific reasoning capabilities.</description><author>Wanjia Zhao, Qinwei Ma, Jingzhe Shi, Shirley Wu, Jiaqi Han, Yijia Xiao, Si-Yuan Chen, Xiao Luo, Ludwig Schmidt, James Zou</author><pubDate>Fri, 03 Oct 2025 17:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03185v1</guid></item><item><title>Tuning LLM-based Code Optimization via Meta-Prompting: An Industrial Perspective</title><link>http://arxiv.org/abs/2508.01443v2</link><description>There is a growing interest in leveraging multiple large language models(LLMs) for automated code optimization. However, industrial platforms deployingmultiple LLMs face a critical challenge: prompts optimized for one LLM oftenfail with others, requiring expensive model-specific prompt engineering. Thiscross-model prompt engineering bottleneck severely limits the practicaldeployment of multi-LLM systems in production environments. We introduceMeta-Prompted Code Optimization (MPCO), a framework that automaticallygenerates high-quality, task-specific prompts across diverse LLMs whilemaintaining industrial efficiency requirements. MPCO leverages metaprompting todynamically synthesize context-aware optimization prompts by integratingproject metadata, task requirements, and LLM-specific contexts. It is anessential part of the ARTEMIS code optimization platform for automatedvalidation and scaling. Our comprehensive evaluation on five real-worldcodebases with 366 hours of runtime benchmarking demonstrates MPCO'seffectiveness: it achieves overall performance improvements up to 19.06% withthe best statistical rank across all systems compared to baseline methods.Analysis shows that 96% of the top-performing optimizations stem frommeaningful edits. Through systematic ablation studies and meta-promptersensitivity analysis, we identify that comprehensive context integration isessential for effective meta-prompting and that major LLMs can serveeffectively as meta-prompters, providing actionable insights for industrialpractitioners.</description><author>Jingzhi Gong, Rafail Giavrimis, Paul Brookes, Vardan Voskanyan, Fan Wu, Mari Ashiga, Matthew Truscott, Mike Basios, Leslie Kanthan, Jie Xu, Zheng Wang</author><pubDate>Fri, 03 Oct 2025 17:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.01443v2</guid></item><item><title>Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model</title><link>http://arxiv.org/abs/2505.16000v4</link><description>The rapid advancement of language models has demonstrated the potential ofartificial intelligence in the healthcare industry. However, small languagemodels struggle with specialized domains in low-resource languages likePersian. While numerous medical-domain websites exist in Persian, no curateddataset or corpus has been available making ours the first of its kind. Thisstudy introduces a newly curated dataset comprising 20k doctor-patient Q\&amp;Apairs and 60\% of a 90-million-token crawled corpus from medical magazines.Using a parameter-efficient fine-tuning approach, we enhanced the medicalknowledge of the baseline model, aya-expanse-8b. Benchmark evaluationsdemonstrate that the fine-tuned model achieves improved accuracy in medicalquestion answering and successfully passed the Iranian Basic Medical ScienceEntrance Exam (IBSEE) in September 2023, which the baseline model did not.Additionally, the fine-tuned model improved Persian-translated MMLU accuracy byan average of 2.67\%. This work highlights the potential of leveragingopen-access online data to enrich small language models in medical fields,providing a novel solution for Persian medical AI applications suitable forresource-constrained environments. Future research could explore multimodalinput to further enhance performance.</description><author>Mehrdad Ghassabi, Pedram Rostami, Hamidreza Baradaran Kashani, Amirhossein Poursina, Zahra Kazemi, Milad Tavakoli</author><pubDate>Fri, 03 Oct 2025 17:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.16000v4</guid></item><item><title>Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning</title><link>http://arxiv.org/abs/2510.03182v1</link><description>Vision Language Models (VLMs) show strong potential for visual planning butstruggle with precise spatial and long-horizon reasoning. In contrast, PlanningDomain Definition Language (PDDL) planners excel at long-horizon formalplanning, but cannot interpret visual inputs. Recent works combine thesecomplementary advantages by enabling VLMs to turn visual planning problems intoPDDL files for formal planning. However, while VLMs can generate PDDL problemfiles satisfactorily, they struggle to accurately generate the PDDL domainfiles, which describe all the planning rules. As a result, prior methods relyon human experts to predefine domain files or on constant environment accessfor refinement. We propose VLMFP, a Dual-VLM-guided framework that canautonomously generate both PDDL problem and domain files for formal visualplanning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: ASimVLM that simulates action consequences based on input rule descriptions, anda GenVLM that generates and iteratively refines PDDL files by comparing thePDDL and SimVLM execution results. VLMFP unleashes multiple levels ofgeneralizability: The same generated PDDL domain file works for all thedifferent instances under the same problem, and VLMs generalize to differentproblems with varied appearances and rules. We evaluate VLMFP with 6 grid-worlddomains and test its generalization to unseen instances, appearance, and gamerules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goalreaching for seen and unseen appearances, respectively. With the guidance ofSimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans forunseen instances in seen and unseen appearances, respectively. Project page:https://sites.google.com/view/vlmfp.</description><author>Yilun Hao, Yongchao Chen, Chuchu Fan, Yang Zhang</author><pubDate>Fri, 03 Oct 2025 16:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03182v1</guid></item><item><title>Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning</title><link>http://arxiv.org/abs/2510.03181v1</link><description>We study the Non-Stationary Reinforcement Learning (RL) under distributionshifts in both finite-horizon episodic and infinite-horizon discounted MarkovDecision Processes (MDPs). In the finite-horizon case, the transition functionsmay suddenly change at a particular episode. In the infinite-horizon setting,such changes can occur at an arbitrary time step during the agent's interactionwith the environment. While the Q-learning Upper Confidence Bound algorithm(QUCB) can discover a proper policy during learning, due to the distributionshifts, this policy can exploit sub-optimal rewards after the shift happens. Toaddress this issue, we propose Density-QUCB (DQUCB), a shift-awareQ-learning~UCB algorithm, which uses a transition density function to detectdistribution shifts, then leverages its likelihood to enhance the uncertaintyestimation quality of Q-learning~UCB, resulting in a balance betweenexploration and exploitation. Theoretically, we prove that our oracle DQUCBachieves a better regret guarantee than QUCB. Empirically, our DQUCB enjoys thecomputational efficiency of model-free RL and outperforms QUCB baselines byhaving a lower regret across RL tasks, as well as a real-world COVID-19 patienthospital allocation task using a Deep-Q-learning architecture.</description><author>Ha Manh Bui, Felix Parker, Kimia Ghobadi, Anqi Liu</author><pubDate>Fri, 03 Oct 2025 16:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03181v1</guid></item><item><title>When Names Disappear: Revealing What LLMs Actually Understand About Code</title><link>http://arxiv.org/abs/2510.03178v1</link><description>Large Language Models (LLMs) achieve strong results on code tasks, but howthey derive program meaning remains unclear. We argue that code communicatesthrough two channels: structural semantics, which define formal behavior, andhuman-interpretable naming, which conveys intent. Removing the naming channelseverely degrades intent-level tasks such as summarization, where modelsregress to line-by-line descriptions. Surprisingly, we also observe consistentreductions on execution tasks that should depend only on structure, revealingthat current benchmarks reward memorization of naming patterns rather thangenuine semantic reasoning. To disentangle these effects, we introduce a suiteof semantics-preserving obfuscations and show that they expose identifierleakage across both summarization and execution. Building on these insights, werelease ClassEval-Obf, an obfuscation-enhanced benchmark that systematicallysuppresses naming cues while preserving behavior. Our results demonstrate thatClassEval-Obf reduces inflated performance gaps, weakens memorizationshortcuts, and provides a more reliable basis for assessing LLMs' codeunderstanding and generalization.</description><author>Cuong Chi Le, Minh V. T. Pham, Cuong Duc Van, Hoang N. Phan, Huy N. Phan, Tien N. Nguyen</author><pubDate>Fri, 03 Oct 2025 16:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03178v1</guid></item><item><title>Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting?</title><link>http://arxiv.org/abs/2510.03174v1</link><description>Traditional topic models such as neural topic models rely on inference andgeneration networks to learn latent topic distributions. This paper explores anew paradigm for topic modeling in the era of large language models, framing TMas a long-form generation task whose definition is updated in this paradigm. Wepropose a simple but practical approach to implement LLM-based topic modeltasks out of the box (sample a data subset, generate topics and representativetext with our prompt, text assignment with keyword match). We then investigatewhether the long-form generation paradigm can beat NTMs via zero-shotprompting. We conduct a systematic comparison between NTMs and LLMs in terms oftopic quality and empirically examine the claim that "a majority of NTMs areoutdated."</description><author>Xuan Xu, Haolun Li, Zhongliang Yang, Beilin Chu, Jia Song, Moxuan Xu, Linna Zhou</author><pubDate>Fri, 03 Oct 2025 16:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03174v1</guid></item><item><title>Putnam-like dataset summary: LLMs as mathematical competition contestants</title><link>http://arxiv.org/abs/2509.24827v2</link><description>In this paper we summarize the results of the Putnam-like benchmark publishedby Google DeepMind. This dataset consists of 96 original problems in the spiritof the Putnam Competition and 576 solutions of LLMs. We analyse the performanceof models on this set of problems to verify their ability to solve problemsfrom mathematical contests.</description><author>Bartosz Bieganowski, Daniel Strzelecki, Robert Skiba, Mateusz Topolewski</author><pubDate>Fri, 03 Oct 2025 16:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24827v2</guid></item><item><title>Revisiting Reweighted Risk for Calibration: AURC, Focal, and Inverse Focal Loss</title><link>http://arxiv.org/abs/2505.23463v3</link><description>Several variants of reweighted risk functionals, such as focal loss, inversefocal loss, and the Area Under the Risk--Coverage Curve (AURC), have beenproposed for improving model calibration, yet their theoretical connections tocalibration errors remain unclear. In this paper, we revisit a broad class ofweighted risk functions commonly used in deep learning and establish aprincipled connection between calibration error and selective classification.We show that minimizing calibration error is closely linked to the selectiveclassification paradigm and demonstrate that optimizing selective risk inlow-confidence region naturally leads to improved calibration. This loss sharesa similar reweighting strategy with dual focal loss but offers greaterflexibility through the choice of confidence score functions (CSFs). Ourapproach uses a bin-based cumulative distribution function (CDF) approximation,enabling efficient gradient-based optimization without requiring expensivesorting and achieving $O(nK)$ complexity. Empirical evaluations demonstratethat our method achieves competitive calibration performance across a range ofdatasets and model architectures.</description><author>Han Zhou, Sebastian G. Gruber, Teodora Popordanoska, Matthew B. Blaschko</author><pubDate>Fri, 03 Oct 2025 16:41:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.23463v3</guid></item><item><title>Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism</title><link>http://arxiv.org/abs/2510.03167v1</link><description>A recent breakthrough in nonconvex optimization is the online-to-nonconvexconversion framework of \cite{cutkosky2023optimal}, which reformulates the taskof finding an $\varepsilon$-first-order stationary point as an online learningproblem. When both the gradient and the Hessian are Lipschitz continuous,instantiating this framework with two different online learners achieves acomplexity of $\mathcal{O}(\varepsilon^{-1.75}\log(1/\varepsilon))$ in thedeterministic case and a complexity of $\mathcal{O}(\varepsilon^{-3.5})$ in thestochastic case. However, this approach suffers from several limitations: (i)the deterministic method relies on a complex double-loop scheme that solves afixed-point equation to construct hint vectors for an optimistic onlinelearner, introducing an extra logarithmic factor; (ii) the stochastic methodassumes a bounded second-order moment of the stochastic gradient, which isstronger than standard variance bounds; and (iii) different online learningalgorithms are used in the two settings. In this paper, we address these issuesby introducing an online optimistic gradient method based on a novel\textit{doubly optimistic hint function}. Specifically, we use the gradient atan extrapolated point as the hint, motivated by two optimistic assumptions:that the difference between the hint and the target gradient remains nearconstant, and that consecutive update directions change slowly due tosmoothness. Our method eliminates the need for a double loop and removes thelogarithmic factor. Furthermore, by simply replacing full gradients withstochastic gradients and under the standard assumption that their variance isbounded by $\sigma^2$, we obtain a unified algorithm with complexity$\mathcal{O}(\varepsilon^{-1.75} + \sigma^2 \varepsilon^{-3.5})$, smoothlyinterpolating between the best-known deterministic rate and the optimalstochastic rate.</description><author>Francisco Patitucci, Ruichen Jiang, Aryan Mokhtari</author><pubDate>Fri, 03 Oct 2025 16:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03167v1</guid></item><item><title>FTTE: Federated Learning on Resource-Constrained Devices</title><link>http://arxiv.org/abs/2510.03165v1</link><description>Federated learning (FL) enables collaborative model training acrossdistributed devices while preserving data privacy, but deployment onresource-constrained edge nodes remains challenging due to limited memory,energy, and communication bandwidth. Traditional synchronous and asynchronousFL approaches further suffer from straggler induced delays and slow convergencein heterogeneous, large scale networks. We present FTTE (Federated TinyTraining Engine),a novel semi-asynchronous FL framework that uniquely employssparse parameter updates and a staleness-weighted aggregation based on both ageand variance of client updates. Extensive experiments across diverse models anddata distributions - including up to 500 clients and 90% stragglers -demonstrate that FTTE not only achieves 81% faster convergence, 80% loweron-device memory usage, and 69% communication payload reduction thansynchronous FL (eg.FedAVG), but also consistently reaches comparable or highertarget accuracy than semi-asynchronous (eg.FedBuff) in challenging regimes.These results establish FTTE as the first practical and scalable solution forreal-world FL deployments on heterogeneous and predominantlyresource-constrained edge devices.</description><author>Irene Tenison, Anna Murphy, Charles Beauville, Lalana Kagal</author><pubDate>Fri, 03 Oct 2025 16:36:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03165v1</guid></item><item><title>Why Do We Need Warm-up? A Theoretical Perspective</title><link>http://arxiv.org/abs/2510.03164v1</link><description>Learning rate warm-up - increasing the learning rate at the beginning oftraining - has become a ubiquitous heuristic in modern deep learning, yet itstheoretical foundations remain poorly understood. In this work, we provide aprincipled explanation for why warm-up improves training. We rely on ageneralization of the $(L_0, L_1)$-smoothness condition, which bounds localcurvature as a linear function of the loss sub-optimality and exhibitsdesirable closure properties. We demonstrate both theoretically and empiricallythat this condition holds for common neural architectures trained withmean-squared error and cross-entropy losses. Under this assumption, we provethat Gradient Descent with a warm-up schedule achieves faster convergence thanwith a fixed step-size, establishing upper and lower complexity bounds.Finally, we validate our theoretical insights through experiments on languageand vision models, confirming the practical benefits of warm-up schedules.</description><author>Foivos Alimisis, Rustem Islamov, Aurelien Lucchi</author><pubDate>Fri, 03 Oct 2025 16:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03164v1</guid></item><item><title>ROGR: Relightable 3D Objects using Generative Relighting</title><link>http://arxiv.org/abs/2510.03163v1</link><description>We introduce ROGR, a novel approach that reconstructs a relightable 3D modelof an object captured from multiple views, driven by a generative relightingmodel that simulates the effects of placing the object under novel environmentilluminations. Our method samples the appearance of the object under multiplelighting environments, creating a dataset that is used to train alighting-conditioned Neural Radiance Field (NeRF) that outputs the object'sappearance under any input environmental lighting. The lighting-conditionedNeRF uses a novel dual-branch architecture to encode the general lightingeffects and specularities separately. The optimized lighting-conditioned NeRFenables efficient feed-forward relighting under arbitrary environment mapswithout requiring per-illumination optimization or light transport simulation.We evaluate our approach on the established TensoIR and Stanford-ORB datasets,where it improves upon the state-of-the-art on most metrics, and showcase ourapproach on real-world object captures.</description><author>Jiapeng Tang, Matthew Lavine, Dor Verbin, Stephan J. Garbin, Matthias Nießner, Ricardo Martin Brualla, Pratul P. Srinivasan, Philipp Henzler</author><pubDate>Fri, 03 Oct 2025 16:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03163v1</guid></item><item><title>Calibrated Uncertainty Sampling for Active Learning</title><link>http://arxiv.org/abs/2510.03162v1</link><description>We study the problem of actively learning a classifier with a low calibrationerror. One of the most popular Acquisition Functions (AFs) in pool-based ActiveLearning (AL) is querying by the model's uncertainty. However, we recognizethat an uncalibrated uncertainty model on the unlabeled pool may significantlyaffect the AF effectiveness, leading to sub-optimal generalization and highcalibration error on unseen data. Deep Neural Networks (DNNs) make it evenworse as the model uncertainty from DNN is usually uncalibrated. Therefore, wepropose a new AF by estimating calibration errors and query samples with thehighest calibration error before leveraging DNN uncertainty. Specifically, weutilize a kernel calibration error estimator under the covariate shift andformally show that AL with this AF eventually leads to a bounded calibrationerror on the unlabeled pool and unseen test data. Empirically, our proposedmethod surpasses other AF baselines by having a lower calibration andgeneralization error across pool-based AL settings.</description><author>Ha Manh Bui, Iliana Maifeld-Carucci, Anqi Liu</author><pubDate>Fri, 03 Oct 2025 16:33:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03162v1</guid></item><item><title>UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization</title><link>http://arxiv.org/abs/2510.03161v1</link><description>With the rapid advancements in image generation, synthetic images have becomeincreasingly realistic, posing significant societal risks, such asmisinformation and fraud. Forgery Image Detection and Localization (FIDL) thusemerges as essential for maintaining information integrity and societalsecurity. Despite impressive performances by existing domain-specific detectionmethods, their practical applicability remains limited, primarily due to theirnarrow specialization, poor cross-domain generalization, and the absence of anintegrated adaptive framework. To address these issues, we propose UniShield,the novel multi-agent-based unified system capable of detecting and localizingimage forgeries across diverse domains, including image manipulation, documentmanipulation, DeepFake, and AI-generated images. UniShield innovativelyintegrates a perception agent with a detection agent. The perception agentintelligently analyzes image features to dynamically select suitable detectionmodels, while the detection agent consolidates various expert detectors into aunified framework and generates interpretable reports. Extensive experimentsshow that UniShield achieves state-of-the-art results, surpassing both existingunified approaches and domain-specific detectors, highlighting its superiorpracticality, adaptiveness, and scalability.</description><author>Qing Huang, Zhipei Xu, Xuanyu Zhang, Jian Zhang</author><pubDate>Fri, 03 Oct 2025 16:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03161v1</guid></item><item><title>SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus</title><link>http://arxiv.org/abs/2510.03160v1</link><description>Spine disorders affect 619 million people globally and are a leading cause ofdisability, yet AI-assisted diagnosis remains limited by the lack oflevel-aware, multimodal datasets. Clinical decision-making for spine disordersrequires sophisticated reasoning across X-ray, CT, and MRI at specificvertebral levels. However, progress has been constrained by the absence oftraceable, clinically-grounded instruction data and standardized,spine-specific benchmarks. To address this, we introduce SpineMed, an ecosystemco-designed with practicing spine surgeons. It features SpineMed-450k, thefirst large-scale dataset explicitly designed for vertebral-level reasoningacross imaging modalities with over 450,000 instruction instances, andSpineBench, a clinically-grounded evaluation framework. SpineMed-450k iscurated from diverse sources, including textbooks, guidelines, open datasets,and ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipelinewith a two-stage LLM generation method (draft and revision) to ensurehigh-quality, traceable data for question-answering, multi-turn consultations,and report generation. SpineBench evaluates models on clinically salient axes,including level identification, pathology assessment, and surgical planning.Our comprehensive evaluation of several recently advanced large vision-languagemodels (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained,level-specific reasoning. In contrast, our model fine-tuned on SpineMed-450kdemonstrates consistent and significant improvements across all tasks.Clinician assessments confirm the diagnostic clarity and practical utility ofour model's outputs.</description><author>Ming Zhao, Wenhui Dong, Yang Zhang, Xiang Zheng, Zhonghao Zhang, Zian Zhou, Yunzhi Guan, Liukun Xu, Wei Peng, Zhaoyang Gong, Zhicheng Zhang, Dachuan Li, Xiaosheng Ma, Yuli Ma, Jianing Ni, Changjiang Jiang, Lixia Tian, Qixin Chen, Kaishun Xia, Pingping Liu, Tongshun Zhang, Zhiqiang Liu, Zhongan Bi, Chenyang Si, Tiansheng Sun, Caifeng Shan</author><pubDate>Fri, 03 Oct 2025 16:32:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03160v1</guid></item><item><title>Neural Correlates of Language Models Are Specific to Human Language</title><link>http://arxiv.org/abs/2510.03156v1</link><description>Previous work has shown correlations between the hidden states of largelanguage models and fMRI brain responses, on language tasks. These correlationshave been taken as evidence of the representational similarity of these modelsand brain states. This study tests whether these previous results are robust toseveral possible concerns. Specifically this study shows: (i) that the previousresults are still found after dimensionality reduction, and thus are notattributable to the curse of dimensionality; (ii) that previous results areconfirmed when using new measures of similarity; (iii) that correlationsbetween brain representations and those from models are specific to modelstrained on human language; and (iv) that the results are dependent on thepresence of positional encoding in the models. These results confirm andstrengthen the results of previous research and contribute to the debate on thebiological plausibility and interpretability of state-of-the-art large languagemodels.</description><author>Iñigo Parra</author><pubDate>Fri, 03 Oct 2025 16:28:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03156v1</guid></item><item><title>Stimulus-Voltage-Based Prediction of Action Potential Onset Timing: Classical vs. Quantum-Inspired Approaches</title><link>http://arxiv.org/abs/2510.03155v1</link><description>Accurate modeling of neuronal action potential (AP) onset timing is crucialfor understanding neural coding of danger signals. Traditional leakyintegrate-and-fire (LIF) models, while widely used, exhibit high relative errorin predicting AP onset latency, especially under strong or rapidly changingstimuli. Inspired by recent experimental findings and quantum theory, wepresent a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treatsAP onset as a probabilistic event, represented by a Gaussian wave packet intime. This approach captures the biological variability and uncertaintyinherent in neuronal firing. We systematically compare the relative error of APonset predictions between the classical LIF and QI-LIF models using syntheticdata from hippocampal and sensory neurons subjected to varying stimulusamplitudes. Our results demonstrate that the QI-LIF model significantly reducesprediction error, particularly for high-intensity stimuli, aligning closelywith observed biological responses. This work highlights the potential ofquantum-inspired computational frameworks in advancing the accuracy of neuralmodeling and has implications for quantum engineering approaches tobrain-inspired computing.</description><author>Stevens Johnson, Varun Puram, Johnson Thomas, Acsah Konuparamban, Ashwin Kannan</author><pubDate>Fri, 03 Oct 2025 16:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03155v1</guid></item><item><title>RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives</title><link>http://arxiv.org/abs/2405.18406v4</link><description>Recent video generative models primarily rely on carefully written textprompts for specific tasks, like inpainting or style editing. They requirelabor-intensive textual descriptions for input videos, hindering theirflexibility to adapt personal/raw videos to user specifications. This paperproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-videogenerative framework that supports multiple video editing capabilities such asremoval, addition, and modification, through a unified pipeline. RACCooNconsists of two principal stages: Video-to-Paragraph (V2P) andParagraph-to-Video (P2V). In the V2P stage, we automatically describe videoscenes in well-structured natural language, capturing both the holistic contextand focused object details. Subsequently, in the P2V stage, users canoptionally refine these descriptions to guide the video diffusion model,enabling various modifications to the input video, such as removing, changingsubjects, and/or adding new objects. The proposed approach stands out fromother methods through several significant contributions: (1) RACCooN suggests amulti-granular spatiotemporal pooling strategy to generate well-structuredvideo descriptions, capturing both the broad context and object details withoutrequiring complex human annotations, simplifying precise video content editingbased on text for users. (2) Our video generative model incorporatesauto-generated narratives or instructions to enhance the quality and accuracyof the generated content. (3) RACCooN also plans to imagine new objects in agiven video, so users simply prompt the model to receive a detailed videoediting plan for complex video editing. The proposed framework demonstratesimpressive versatile capabilities in video-to-paragraph generation, videocontent editing, and can be incorporated into other SoTA video generativemodels for further enhancement.</description><author>Jaehong Yoon, Shoubin Yu, Mohit Bansal</author><pubDate>Fri, 03 Oct 2025 16:27:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18406v4</guid></item><item><title>EditLens: Quantifying the Extent of AI Editing in Text</title><link>http://arxiv.org/abs/2510.03154v1</link><description>A significant proportion of queries to large language models ask them to edituser-provided text, rather than generate new text from scratch. While previouswork focuses on detecting fully AI-generated text, we demonstrate thatAI-edited text is distinguishable from human-written and AI-generated text.First, we propose using lightweight similarity metrics to quantify themagnitude of AI editing present in a text given the original human-written textand validate these metrics with human annotators. Using these similaritymetrics as intermediate supervision, we then train EditLens, a regression modelthat predicts the amount of AI editing present within a text. Our modelachieves state-of-the-art performance on both binary (F1=94.7%) and ternary(F1=90.4%) classification tasks in distinguishing human, AI, and mixed writing.Not only do we show that AI-edited text can be detected, but also that thedegree of change made by AI to human writing can be detected, which hasimplications for authorship attribution, education, and policy. Finally, as acase study, we use our model to analyze the effects of AI-edits applied byGrammarly, a popular writing assistance tool. To encourage further research, wecommit to publicly releasing our models and dataset.</description><author>Katherine Thai, Bradley Emi, Elyas Masrour, Mohit Iyyer</author><pubDate>Fri, 03 Oct 2025 16:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03154v1</guid></item><item><title>Improving Cooperation in Collaborative Embodied AI</title><link>http://arxiv.org/abs/2510.03153v1</link><description>The integration of Large Language Models (LLMs) into multiagent systems hasopened new possibilities for collaborative reasoning and cooperation with AIagents. This paper explores different prompting methods and evaluates theireffectiveness in enhancing agent collaborative behaviour and decision-making.We enhance CoELA, a framework designed for building Collaborative EmbodiedAgents that leverage LLMs for multi-agent communication, reasoning, and taskcoordination in shared virtual spaces. Through systematic experimentation, weexamine different LLMs and prompt engineering strategies to identify optimisedcombinations that maximise collaboration performance. Furthermore, we extendour research by integrating speech capabilities, enabling seamlesscollaborative voice-based interactions. Our findings highlight theeffectiveness of prompt optimisation in enhancing collaborative agentperformance; for example, our best combination improved the efficiency of thesystem running with Gemma3 by 22% compared to the original CoELA system. Inaddition, the speech integration provides a more engaging user interface foriterative system development and demonstrations.</description><author>Hima Jacob Leven Suprabha, Laxmi Nag Laxminarayan Nagesh, Ajith Nair, Alvin Reuben Amal Selvaster, Ayan Khan, Raghuram Damarla, Sanju Hannah Samuel, Sreenithi Saravana Perumal, Titouan Puech, Venkataramireddy Marella, Vishal Sonar, Alessandro Suglia, Oliver Lemon</author><pubDate>Fri, 03 Oct 2025 16:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03153v1</guid></item><item><title>ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories</title><link>http://arxiv.org/abs/2510.03152v1</link><description>Accurately modeling human mobility is critical for urban planning,epidemiology, and traffic management. In this work, we introduce Markovian ReebGraphs, a novel framework for simulating spatiotemporal trajectories thatpreserve Patterns of Life (PoLs) learned from baseline data. By combiningindividual- and population-level mobility structures within a probabilistictopological model, our approach generates realistic future trajectories thatcapture both consistency and variability in daily life. Evaluations on theUrban Anomalies dataset (Atlanta and Berlin subsets) using the Jensen-ShannonDivergence (JSD) across population- and agent-level metrics demonstrate thatthe proposed method achieves strong fidelity while remaining data- andcompute-efficient. These results position Markovian Reeb Graphs as a scalableframework for trajectory simulation with broad applicability across diverseurban environments.</description><author>Anantajit Subrahmanya, Chandrakanth Gudavalli, Connor Levenson, Umang Garg, B. S. Manjunath</author><pubDate>Fri, 03 Oct 2025 16:25:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03152v1</guid></item><item><title>Mixture of Many Zero-Compute Experts: A High-Rate Quantization Theory Perspective</title><link>http://arxiv.org/abs/2510.03151v1</link><description>This paper uses classical high-rate quantization theory to provide newinsights into mixture-of-experts (MoE) models for regression tasks. Our MoE isdefined by a segmentation of the input space to regions, each with asingle-parameter expert that acts as a constant predictor with zero-compute atinference. Motivated by high-rate quantization theory assumptions, we assumethat the number of experts is sufficiently large to make their input-spaceregions very small. This lets us to study the approximation error of our MoEmodel class: (i) for one-dimensional inputs, we formulate the test error andits minimizing segmentation and experts; (ii) for multidimensional inputs, weformulate an upper bound for the test error and study its minimization.Moreover, we consider the learning of the expert parameters from a trainingdataset, given an input-space segmentation, and formulate their statisticallearning properties. This leads us to theoretically and empirically show howthe tradeoff between approximation and estimation errors in MoE learningdepends on the number of experts.</description><author>Yehuda Dar</author><pubDate>Fri, 03 Oct 2025 16:24:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03151v1</guid></item><item><title>Fixing That Free Lunch: When, Where, and Why Synthetic Data Fails in Model-Based Policy Optimization</title><link>http://arxiv.org/abs/2510.01457v2</link><description>Synthetic data is a core component of data-efficient Dyna-style model-basedreinforcement learning, yet it can also degrade performance. We study when ithelps, where it fails, and why, and we show that addressing the resultingfailure modes enables policy improvement that was previously unattainable. Wefocus on Model-Based Policy Optimization (MBPO), which performs actor andcritic updates using synthetic action counterfactuals. Despite reports ofstrong and generalizable sample-efficiency gains in OpenAI Gym, recent workshows that MBPO often underperforms its model-free counterpart, SoftActor-Critic (SAC), in the DeepMind Control Suite (DMC). Although both suitesinvolve continuous control with proprioceptive robots, this shift leads tosharp performance losses across seven challenging DMC tasks, with MBPO failingin cases where claims of generalization from Gym would imply success. Thisreveals how environment-specific assumptions can become implicitly encoded intoalgorithm design when evaluation is limited. We identify two coupled issuesbehind these failures: scale mismatches between dynamics and reward models thatinduce critic underestimation and hinder policy improvement during model-policycoevolution, and a poor choice of target representation that inflates modelvariance and produces error-prone rollouts. Addressing these failure modesenables policy improvement where none was previously possible, allowing MBPO tooutperform SAC in five of seven tasks while preserving the strong performancepreviously reported in OpenAI Gym. Rather than aiming only for incrementalaverage gains, we hope our findings motivate the community to developtaxonomies that tie MDP task- and environment-level structure to algorithmicfailure modes, pursue unified solutions where possible, and clarify howbenchmark choices ultimately shape the conditions under which algorithmsgeneralize.</description><author>Brett Barkley, David Fridovich-Keil</author><pubDate>Fri, 03 Oct 2025 16:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01457v2</guid></item><item><title>SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion</title><link>http://arxiv.org/abs/2510.01456v2</link><description>Out-of-distribution (OOD) detection is essential for reliable deployment ofmachine learning systems in vision, robotics, reinforcement learning, andbeyond. We introduce Score-Curvature Out-of-distribution Proximity Evaluatorfor Diffusion (SCOPED), a fast and general-purpose OOD detection method fordiffusion models that reduces the number of forward passes on the trained modelby an order of magnitude compared to prior methods, outperforming mostdiffusion-based baselines and closely approaching the accuracy of the strongestones. SCOPED is computed from a single diffusion model trained once on adiverse dataset, and combines the Jacobian trace and squared norm of themodel's score function into a single test statistic. Rather than thresholdingon a fixed value, we estimate the in-distribution density of SCOPED scoresusing kernel density estimation, enabling a flexible, unsupervised test that,in the simplest case, only requires a single forward pass and oneJacobian-vector product (JVP), made efficient by Hutchinson's trace estimator.On four vision benchmarks, SCOPED achieves competitive or state-of-the-artprecision-recall scores despite its low computational cost. The same methodgeneralizes to robotic control tasks with shared state and action spaces,identifying distribution shifts across reward functions and training regimes.These results position SCOPED as a practical foundation for fast and reliableOOD detection in real-world domains, including perceptual artifacts in vision,outlier detection in autoregressive models, exploration in reinforcementlearning, and dataset curation for unsupervised training.</description><author>Brett Barkley, Preston Culbertson, David Fridovich-Keil</author><pubDate>Fri, 03 Oct 2025 16:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01456v2</guid></item><item><title>Taming Imperfect Process Verifiers: A Sampling Perspective on Backtracking</title><link>http://arxiv.org/abs/2510.03149v1</link><description>Test-time algorithms that combine the generative power of language modelswith process verifiers that assess the quality of partial generations offer apromising lever for eliciting new reasoning capabilities, but the algorithmicdesign space and computational scaling properties of such approaches are stillopaque, and their benefits are far from apparent when one accounts for the costof learning a high-quality verifier. Our starting point is the observation thatseemingly benign errors in a learned verifier can lead to catastrophic failuresfor standard decoding techniques due to error amplification during the courseof generation. We then ask: can this be improved with more sophisticateddecoding strategies? We introduce a new process-guided test-time sampling algorithm, VGB, whichuses theoretically grounded backtracking to achieve provably better robustnessto verifier errors. VGB interprets autoregressive generation as a random walkon a tree of partial generations, with transition probabilities guided by theprocess verifier and base model; crucially, backtracking occursprobabilistically. This process generalizes the seminal Sinclair-Jerrum randomwalk (Sinclair &amp; Jerrum, 1989) from the literature on approximate counting andsampling in theoretical computer science, and a conceptual contribution of ourwork is to highlight parallels with this literature. Empirically, wedemonstrate on both synthetic and real language modeling tasks that VGBoutperforms baselines on a variety of metrics.</description><author>Dhruv Rohatgi, Abhishek Shetty, Donya Saless, Yuchen Li, Ankur Moitra, Andrej Risteski, Dylan J. Foster</author><pubDate>Fri, 03 Oct 2025 16:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03149v1</guid></item><item><title>The Computational Complexity of Almost Stable Clustering with Penalties</title><link>http://arxiv.org/abs/2510.03143v1</link><description>We investigate the complexity of stable (or perturbation-resilient) instancesof $\mathrm{k-M\small{EANS}}$ and $\mathrm{k-M\small{EDIAN}}$ clusteringproblems in metrics with small doubling dimension. While these problems havebeen extensively studied under multiplicative perturbation resilience inlow-dimensional Euclidean spaces (e.g., (Friggstad et al., 2019; Cohen-Addadand Schwiegelshohn, 2017)), we adopt a more general notion of stability, termed``almost stable'', which is closer to the notion of $(\alpha,\varepsilon)$-perturbation resilience introduced by Balcan and Liang (2016).Additionally, we extend our results to$\mathrm{k-M\small{EANS}}$/$\mathrm{k-M\small{EDIAN}}$ with penalties, whereeach data point is either assigned to a cluster centre or incurs a penalty. We show that certain special cases of almost stable$\mathrm{k-M\small{EANS}}$/$\mathrm{k-M\small{EDIAN}}$ (with penalties) aresolvable in polynomial time. To complement this, we also examine the hardnessof almost stable instances and $(1 + \frac{1}{poly(n)})$-stable instances of$\mathrm{k-M\small{EANS}}$/$\mathrm{k-M\small{EDIAN}}$ (with penalties),proving super-polynomial lower bounds on the runtime of any exact algorithmunder the widely believed Exponential Time Hypothesis (ETH).</description><author>Kamyar Khodamoradi, Farnam Mansouri, Sandra Zilles</author><pubDate>Fri, 03 Oct 2025 16:15:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03143v1</guid></item><item><title>MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning</title><link>http://arxiv.org/abs/2510.03142v1</link><description>Visual navigation policy is widely regarded as a promising direction, as itmimics humans by using egocentric visual observations for navigation. However,optical information of visual observations is difficult to be explicitlymodeled like LiDAR point clouds or depth maps, which subsequently requiresintelligent models and large-scale data. To this end, we propose to leveragethe intelligence of the Vision-Language-Action (VLA) model to learn diversenavigation capabilities from synthetic expert data in a teacher-student manner.Specifically, we implement the VLA model, MM-Nav, as a multi-view VLA (with 360observations) based on pretrained large language models and visual foundationmodels. For large-scale navigation data, we collect expert data from threereinforcement learning (RL) experts trained with privileged depth informationin three challenging tailor-made environments for different navigationcapabilities: reaching, squeezing, and avoiding. We iteratively train our VLAmodel using data collected online from RL experts, where the training ratio isdynamically balanced based on performance on individual capabilities. Throughextensive experiments in synthetic environments, we demonstrate that our modelachieves strong generalization capability. Moreover, we find that our studentVLA model outperforms the RL teachers, demonstrating the synergistic effect ofintegrating multiple capabilities. Extensive real-world experiments furtherconfirm the effectiveness of our method.</description><author>Tianyu Xu, Jiawei Chen, Jiazhao Zhang, Wenyao Zhang, Zekun Qi, Minghan Li, Zhizheng Zhang, He Wang</author><pubDate>Fri, 03 Oct 2025 16:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03142v1</guid></item><item><title>Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Experiments</title><link>http://arxiv.org/abs/2505.09901v2</link><description>Large language models (LLMs) are increasingly used to simulate or automatehuman behavior in complex sequential decision-making settings. A naturalquestion is then whether LLMs exhibit similar decision-making behavior tohumans, and can achieve comparable (or superior) performance. In this work, wefocus on the exploration-exploitation (E&amp;E) tradeoff, a fundamental aspect ofdynamic decision-making under uncertainty. We employ canonical multi-armedbandit (MAB) experiments introduced in the cognitive science and psychiatryliterature to conduct a comparative study of the E&amp;E strategies of LLMs,humans, and MAB algorithms. We use interpretable choice models to capture theE&amp;E strategies of the agents and investigate how enabling thinking traces,through both prompting strategies and thinking models, shapes LLMdecision-making. We find that enabling thinking in LLMs shifts their behaviortoward more human-like behavior, characterized by a mix of random and directedexploration. In a simple stationary setting, thinking-enabled LLMs exhibitsimilar levels of random and directed exploration compared to humans. However,in more complex, non-stationary environments, LLMs struggle to match humanadaptability, particularly in effective directed exploration, despite achievingsimilar regret in certain scenarios. Our findings highlight both the promiseand limits of LLMs as simulators of human behavior and tools for automateddecision-making and point to potential areas for improvement.</description><author>Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian</author><pubDate>Fri, 03 Oct 2025 16:12:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.09901v2</guid></item><item><title>Beyond the Final Layer: Intermediate Representations for Better Multilingual Calibration in Large Language Models</title><link>http://arxiv.org/abs/2510.03136v1</link><description>Confidence calibration, the alignment of a model's predicted confidence withits actual accuracy, is crucial for the reliable deployment of Large LanguageModels (LLMs). However, this critical property remains largely under-exploredin multilingual contexts. In this work, we conduct the first large-scale,systematic studies of multilingual calibration across six model families andover 100 languages, revealing that non-English languages suffer fromsystematically worse calibration. To diagnose this, we investigate the model'sinternal representations and find that the final layer, biased byEnglish-centric training, provides a poor signal for multilingual confidence.In contrast, our layer-wise analysis uncovers a key insight thatlate-intermediate layers consistently offer a more reliable andbetter-calibrated signal. Building on this, we introduce a suite oftraining-free methods, including Language-Aware Confidence Ensemble (LACE),which adaptively selects an optimal ensemble of layers for each specificlanguage. Our study highlights the hidden costs of English-centric alignmentand offer a new path toward building more globally equitable and trustworthyLLMs by looking beyond the final layer.</description><author>Ej Zhou, Caiqi Zhang, Tiancheng Hu, Chengzu Li, Nigel Collier, Ivan Vulić, Anna Korhonen</author><pubDate>Fri, 03 Oct 2025 16:07:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03136v1</guid></item><item><title>Batched Nonparametric Contextual Bandits</title><link>http://arxiv.org/abs/2402.17732v4</link><description>We study nonparametric contextual bandits under batch constraints, where theexpected reward for each action is modeled as a smooth function of covariates,and the policy updates are made at the end of each batch of observations. Weestablish a minimax regret lower bound for this setting and propose a novelbatch learning algorithm that achieves the optimal regret (up to logarithmicfactors). In essence, our procedure dynamically splits the covariate space intosmaller bins, carefully aligning their widths with the batch size. Ourtheoretical results suggest that for nonparametric contextual bandits, a nearlyconstant number of policy updates can attain optimal regret in the fully onlinesetting.</description><author>Rong Jiang, Cong Ma</author><pubDate>Fri, 03 Oct 2025 16:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17732v4</guid></item><item><title>Mask2IV: Interaction-Centric Video Generation via Mask Trajectories</title><link>http://arxiv.org/abs/2510.03135v1</link><description>Generating interaction-centric videos, such as those depicting humans orrobots interacting with objects, is crucial for embodied intelligence, as theyprovide rich and diverse visual priors for robot learning, manipulation policytraining, and affordance reasoning. However, existing methods often struggle tomodel such complex and dynamic interactions. While recent studies show thatmasks can serve as effective control signals and enhance generation quality,obtaining dense and precise mask annotations remains a major challenge forreal-world use. To overcome this limitation, we introduce Mask2IV, a novelframework specifically designed for interaction-centric video generation. Itadopts a decoupled two-stage pipeline that first predicts plausible motiontrajectories for both actor and object, then generates a video conditioned onthese trajectories. This design eliminates the need for dense mask inputs fromusers while preserving the flexibility to manipulate the interaction process.Furthermore, Mask2IV supports versatile and intuitive control, allowing usersto specify the target object of interaction and guide the motion trajectorythrough action descriptions or spatial position cues. To support systematictraining and evaluation, we curate two benchmarks covering diverse action andobject categories across both human-object interaction and robotic manipulationscenarios. Extensive experiments demonstrate that our method achieves superiorvisual realism and controllability compared to existing baselines.</description><author>Gen Li, Bo Zhao, Jianfei Yang, Laura Sevilla-Lara</author><pubDate>Fri, 03 Oct 2025 16:04:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03135v1</guid></item><item><title>Enhancing XAI Narratives through Multi-Narrative Refinement and Knowledge Distillation</title><link>http://arxiv.org/abs/2510.03134v1</link><description>Explainable Artificial Intelligence has become a crucial area of research,aiming to demystify the decision-making processes of deep learning models.Among various explainability techniques, counterfactual explanations have beenproven particularly promising, as they offer insights into model behavior byhighlighting minimal changes that would alter a prediction. Despite theirpotential, these explanations are often complex and technical, making themdifficult for non-experts to interpret. To address this challenge, we propose anovel pipeline that leverages Language Models, large and small, to composenarratives for counterfactual explanations. We employ knowledge distillationtechniques along with a refining mechanism to enable Small Language Models toperform comparably to their larger counterparts while maintaining robustreasoning abilities. In addition, we introduce a simple but effectiveevaluation method to assess natural language narratives, designed to verifywhether the models' responses are in line with the factual, counterfactualground truth. As a result, our proposed pipeline enhances both the reasoningcapabilities and practical performance of student models, making them moresuitable for real-world use cases.</description><author>Flavio Giorgi, Matteo Silvestri, Cesare Campagnano, Fabrizio Silvestri, Gabriele Tolomei</author><pubDate>Fri, 03 Oct 2025 16:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03134v1</guid></item><item><title>Pack and Force Your Memory: Long-form and Consistent Video Generation</title><link>http://arxiv.org/abs/2510.01784v2</link><description>Long-form video generation presents a dual challenge: models must capturelong-range dependencies while preventing the error accumulation inherent inautoregressive decoding. To address these challenges, we make twocontributions. First, for dynamic context modeling, we propose MemoryPack, alearnable context-retrieval mechanism that leverages both textual and imageinformation as global guidance to jointly model short- and long-termdependencies, achieving minute-level temporal consistency. This design scalesgracefully with video length, preserves computational efficiency, and maintainslinear complexity. Second, to mitigate error accumulation, we introduce DirectForcing, an efficient single-step approximating strategy that improvestraining-inference alignment and thereby curtails error propagation duringinference. Together, MemoryPack and Direct Forcing substantially enhance thecontext consistency and reliability of long-form video generation, advancingthe practical usability of autoregressive video models.</description><author>Xiaofei Wu, Guozhen Zhang, Zhiyong Xu, Yuan Zhou, Qinglin Lu, Xuming He</author><pubDate>Fri, 03 Oct 2025 16:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01784v2</guid></item><item><title>Post Reinforcement Learning Inference</title><link>http://arxiv.org/abs/2302.08854v5</link><description>We study estimation and inference using data collected by reinforcementlearning (RL) algorithms. These algorithms adaptively experiment by interactingwith individual units over multiple stages, updating their strategies based onpast outcomes. Our goal is to evaluate a counterfactual policy after datacollection and estimate structural parameters, such as dynamic treatmenteffects, that support credit assignment and quantify the impact of earlyactions on final outcomes. These parameters can often be defined as solutionsto moment equations, motivating moment-based estimation methods developed forstatic data. In RL settings, however, data are often collected adaptively undernonstationary behavior policies. As a result, standard estimators fail toachieve asymptotic normality due to time-varying variance. We propose aweighted generalized method of moments (GMM) approach that uses adaptiveweights to stabilize this variance. We characterize weighting schemes thatensure consistency and asymptotic normality of the weighted GMM estimators,enabling valid hypothesis testing and uniform confidence region construction.Key applications include dynamic treatment effect estimation and dynamicoff-policy evaluation.</description><author>Vasilis Syrgkanis, Ruohan Zhan</author><pubDate>Fri, 03 Oct 2025 16:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08854v5</guid></item><item><title>Total Robustness in Bayesian Nonlinear Regression for Measurement Error Problems under Model Misspecification</title><link>http://arxiv.org/abs/2510.03131v1</link><description>Modern regression analyses are often undermined by covariate measurementerror, misspecification of the regression model, and misspecification of themeasurement error distribution. We present, to the best of our knowledge, thefirst Bayesian nonparametric framework targeting total robustness that tacklesall three challenges in general nonlinear regression. The framework assigns aDirichlet process prior to the latent covariate-response distribution andupdates it with posterior pseudo-samples of the latent covariates, therebyproviding the Dirichlet process posterior with observation-informed latentinputs and yielding estimators that minimise the discrepancy between Dirichletprocess realisations and the model-induced joint law. This design allowspractitioners to (i) encode prior beliefs, (ii) choose between pseudo-samplinglatent covariates or working directly with error-prone observations, and (iii)tune the influence of prior and data. We establish generalisation bounds thattighten whenever the prior or pseudo-sample generator aligns with theunderlying data generating process, ensuring robustness without sacrificingconsistency. A gradient-based algorithm enables efficient computations;simulations and two real-world studies show lower estimation error and reducedestimation sensitivity to misspecification compared to Bayesian and frequentistcompetitors. The framework, therefore, offers a practical and interpretableparadigm for trustworthy regression when data and models are jointly imperfect.</description><author>Mengqi Chen, Charita Dellaporta, Thomas B. Berrett, Theodoros Damoulas</author><pubDate>Fri, 03 Oct 2025 15:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03131v1</guid></item><item><title>Signature-Informed Transformer for Asset Allocation</title><link>http://arxiv.org/abs/2510.03129v1</link><description>Robust asset allocation is a key challenge in quantitative finance, wheredeep-learning forecasters often fail due to objective mismatch and erroramplification. We introduce the Signature-Informed Transformer (SIT), a novelframework that learns end-to-end allocation policies by directly optimizing arisk-aware financial objective. SIT's core innovations include path signaturesfor a rich geometric representation of asset dynamics and a signature-augmentedattention mechanism embedding financial inductive biases, like lead-lageffects, into the model. Evaluated on daily S\&amp;P 100 equity data, SITdecisively outperforms traditional and deep-learning baselines, especially whencompared to predict-then-optimize models. These results indicate thatportfolio-aware objectives and geometry-aware inductive biases are essentialfor risk-aware capital allocation in machine-learning systems. The code isavailable at:https://github.com/Yoontae6719/Signature-Informed-Transformer-For-Asset-Allocation</description><author>Yoontae Hwang, Stefan Zohren</author><pubDate>Fri, 03 Oct 2025 15:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03129v1</guid></item><item><title>To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning</title><link>http://arxiv.org/abs/2504.07052v2</link><description>Recent advancements in large language models (LLMs) have significantlyimproved their reasoning abilities, particularly through techniques involvingsearch and backtracking. Backtracking naturally scales test-time compute byenabling sequential, linearized exploration via long chain-of-thought (CoT)generation. However, this is not the only strategy for scaling testtime-compute: parallel sampling with best-of-N selection provides analternative that generates diverse solutions simultaneously. Despite thegrowing adoption of sequential search, its advantages over parallelsampling-especially under a fixed compute budget-remain poorly understood. Inthis paper, we systematically compare these two approaches on two challengingreasoning tasks: CountDown and Sudoku. Surprisingly, we find that sequentialsearch underperforms parallel sampling on CountDown but outperforms it onSudoku, suggesting that backtracking is not universally beneficial. We identifytwo factors that can cause backtracking to degrade performance: (1) training onfixed search traces can lock models intro suboptimal strategies, and (2)explicit CoT supervision can discourage implicit (non verbalized) reasoning.Extending our analysis to reinforcement learning (RL), we show that models withbacktracking capabilities benefit significantly from RL fine-tuning, whilemodels without backtracking see limited, mixed gains. Together, these findingschallenge the assumption that backtracking universally enhances LLM reasoning,instead revealing a complex interaction between task structure, training data,model scale, and learning paradigm.</description><author>Tian Qin, David Alvarez-Melis, Samy Jelassi, Eran Malach</author><pubDate>Fri, 03 Oct 2025 15:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.07052v2</guid></item><item><title>A Study of Rule Omission in Raven's Progressive Matrices</title><link>http://arxiv.org/abs/2510.03127v1</link><description>Analogical reasoning lies at the core of human cognition and remains afundamental challenge for artificial intelligence. Raven's Progressive Matrices(RPM) serve as a widely used benchmark to assess abstract reasoning byrequiring the inference of underlying structural rules. While many vision-basedand language-based models have achieved success on RPM tasks, it remainsunclear whether their performance reflects genuine reasoning ability orreliance on statistical shortcuts. This study investigates the generalizationcapacity of modern AI systems under conditions of incomplete training bydeliberately omitting several structural rules during training. Bothsequence-to-sequence transformer models and vision-based architectures such asCoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN(I-RAVEN) dataset. Experiments reveal that although transformers demonstratestrong performance on familiar rules, their accuracy declines sharply whenfaced with novel or omitted rules. Moreover, the gap between token-levelaccuracy and complete answer accuracy highlights fundamental limitations incurrent approaches. These findings provide new insights into the reasoningmechanisms underlying deep learning models and underscore the need forarchitectures that move beyond pattern recognition toward robust abstractreasoning.</description><author>Binze Li</author><pubDate>Fri, 03 Oct 2025 15:53:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03127v1</guid></item><item><title>Highly Efficient and Effective LLMs with Multi-Boolean Architectures</title><link>http://arxiv.org/abs/2505.22811v2</link><description>Weight binarization has emerged as a promising strategy to reduce thecomplexity of large language models (LLMs). Existing approaches fall intopost-training binarization, which is simple but causes severe performance loss,and training-aware methods, which depend on full-precision latent weights,adding complexity and limiting efficiency. We propose a novel framework thatrepresents LLMs with multi-kernel Boolean parameters and, for the first time,enables direct finetuning LMMs in the Boolean domain, eliminating the need forlatent weights. This enhances representational capacity and dramaticallyreduces complexity during both finetuning and inference. Extensive experimentsacross diverse LLMs show our method outperforms recent ultra low-bitquantization and binarization techniques.</description><author>Ba-Hien Tran, Van Minh Nguyen</author><pubDate>Fri, 03 Oct 2025 15:53:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.22811v2</guid></item><item><title>EFC++: Elastic Feature Consolidation with Prototype Re-balancing for Cold Start Exemplar-free Incremental Learning</title><link>http://arxiv.org/abs/2503.10439v3</link><description>Exemplar-free Class Incremental Learning (EFCIL) aims to learn from asequence of tasks without having access to previous task data. In this paper,we consider the challenging Cold Start scenario in which insufficient data isavailable in the first task to learn a high-quality backbone. This isespecially challenging for EFCIL since it requires high plasticity, resultingin feature drift which is difficult to compensate for in the exemplar-freesetting. To address this problem, we propose an effective approach toconsolidate feature representations by regularizing drift in directions highlyrelevant to previous tasks while employing prototypes to reduce task-recencybias. Our approach, which we call Elastic Feature Consolidation++ (EFC++)exploits a tractable second-order approximation of feature drift based on aproposed Empirical Feature Matrix (EFM). The EFM induces a pseudo-metric infeature space which we use to regularize feature drift in important directionsand to update Gaussian prototypes. In addition, we introduce a post-trainingprototype re-balancing phase that updates classifiers to compensate for featuredrift. Experimental results on CIFAR-100, Tiny-ImageNet, ImageNet-Subset,ImageNet-1K and DomainNet demonstrate that EFC++ is better able to learn newtasks by maintaining model plasticity and significantly outperforms thestate-of-the-art.</description><author>Simone Magistri, Tomaso Trinci, Albin Soutif-Cormerais, Joost van de Weijer, Andrew D. Bagdanov</author><pubDate>Fri, 03 Oct 2025 15:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.10439v3</guid></item><item><title>HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion</title><link>http://arxiv.org/abs/2510.03122v1</link><description>The reconstruction of visual information from brain activity fostersinterdisciplinary integration between neuroscience and computer vision.However, existing methods still face challenges in accurately recovering highlycomplex visual stimuli. This difficulty stems from the characteristics ofnatural scenes: low-level features exhibit heterogeneity, while high-levelfeatures show semantic entanglement due to contextual overlaps. Inspired by thehierarchical representation theory of the visual cortex, we propose the HAVIRmodel, which separates the visual cortex into two hierarchical regions andextracts distinct features from each. Specifically, the Structural Generatorextracts structural information from spatial processing voxels and converts itinto latent diffusion priors, while the Semantic Extractor converts semanticprocessing voxels into CLIP embeddings. These components are integrated via theVersatile Diffusion model to synthesize the final image. Experimental resultsdemonstrate that HAVIR enhances both the structural and semantic quality ofreconstructions, even in complex scenes, and outperforms existing models.</description><author>Shiyi Zhang, Dong Liang, Hairong Zheng, Yihang Zhou</author><pubDate>Fri, 03 Oct 2025 15:50:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03122v1</guid></item><item><title>Real Time Headway Predictions in Urban Rail Systems and Implications for Service Control: A Deep Learning Approach</title><link>http://arxiv.org/abs/2510.03121v1</link><description>Efficient real-time dispatching in urban metro systems is essential forensuring service reliability, maximizing resource utilization, and improvingpassenger satisfaction. This study presents a novel deep learning frameworkcentered on a Convolutional Long Short-Term Memory (ConvLSTM) model designed topredict the complex spatiotemporal propagation of train headways across anentire metro line. By directly incorporating planned terminal headways as acritical input alongside historical headway data, the proposed model accuratelyforecasts future headway dynamics, effectively capturing both their temporalevolution and spatial dependencies across all stations. This capabilityempowers dispatchers to evaluate the impact of various terminal headway controldecisions without resorting to computationally intensive simulations. Weintroduce a flexible methodology to simulate diverse dispatcher strategies,ranging from maintaining even headways to implementing custom patterns derivedfrom observed terminal departures. In contrast to existing research primarilyfocused on passenger load predictioning or atypical disruption scenarios, ourapproach emphasizes proactive operational control. Evaluated on a large-scaledataset from an urban metro line, the proposed ConvLSTM model demonstratespromising headway predictions, offering actionable insights for real-timedecision-making. This framework provides rail operators with a powerful,computationally efficient tool to optimize dispatching strategies, therebysignificantly improving service consistency and passenger satisfaction.</description><author>Muhammad Usama, Haris Koutsopoulos</author><pubDate>Fri, 03 Oct 2025 15:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03121v1</guid></item><item><title>SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?</title><link>http://arxiv.org/abs/2510.03120v1</link><description>Academic survey writing, which distills vast literature into a coherent andinsightful narrative, remains a labor-intensive and intellectually demandingtask. While recent approaches, such as general DeepResearch agents andsurvey-specialized methods, can generate surveys automatically (a.k.a.LLM4Survey), their outputs often fall short of human standards and there lacksa rigorous, reader-aligned benchmark for thoroughly revealing theirdeficiencies. To fill the gap, we propose a fine-grained, quiz-drivenevaluation framework SurveyBench, featuring (1) typical survey topics sourcefrom recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys;(2) a multifaceted metric hierarchy that assesses the outline quality (e.g.,coverage breadth, logical coherence), content quality (e.g., synthesisgranularity, clarity of insights), and non-textual richness; and (3) adual-mode evaluation protocol that includes content-based and quiz-basedanswerability tests, explicitly aligned with readers' informational needs.Results show SurveyBench effectively challenges existing LLM4Survey approaches(e.g., on average 21% lower than human in content-based evaluation).</description><author>Zhaojun Sun, Xuzhou Zhu, Xuanhe Zhou, Xin Tong, Shuo Wang, Jie Fu, Guoliang Li, Zhiyuan Liu, Fan Wu</author><pubDate>Fri, 03 Oct 2025 15:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03120v1</guid></item><item><title>C2AL: Cohort-Contrastive Auxiliary Learning for Large-scale Recommendation Systems</title><link>http://arxiv.org/abs/2510.02215v2</link><description>Training large-scale recommendation models under a single global objectiveimplicitly assumes homogeneity across user populations. However, real-worlddata are composites of heterogeneous cohorts with distinct conditionaldistributions. As models increase in scale and complexity and as more data isused for training, they become dominated by central distribution patterns,neglecting head and tail regions. This imbalance limits the model's learningability and can result in inactive attention weights or dead neurons. In thispaper, we reveal how the attention mechanism can play a key role infactorization machines for shared embedding selection, and propose to addressthis challenge by analyzing the substructures in the dataset and exposing thosewith strong distributional contrast through auxiliary learning. Unlike previousresearch, which heuristically applies weighted labels or multi-task heads tomitigate such biases, we leverage partially conflicting auxiliary labels toregularize the shared representation. This approach customizes the learningprocess of attention layers to preserve mutual information with minoritycohorts while improving global performance. We evaluated C2AL on massiveproduction datasets with billions of data points each for six SOTA models.Experiments show that the factorization machine is able to capture fine-graineduser-ad interactions using the proposed method, achieving up to a 0.16%reduction in normalized entropy overall and delivering gains exceeding 0.30% ontargeted minority cohorts.</description><author>Mertcan Cokbas, Ziteng Liu, Zeyi Tao, Elder Veliz, Qin Huang, Ellie Wen, Huayu Li, Qiang Jin, Murat Duman, Benjamin Au, Guy Lebanon, Sagar Chordia, Chengkai Zhang</author><pubDate>Fri, 03 Oct 2025 15:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02215v2</guid></item><item><title>Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction</title><link>http://arxiv.org/abs/2510.03117v1</link><description>This study focuses on a challenging yet promising task,Text-to-Sounding-Video (T2SV) generation, which aims to generate a video withsynchronized audio from text conditions, meanwhile ensuring both modalities arealigned with text. Despite progress in joint audio-video training, two criticalchallenges still remain unaddressed: (1) a single, shared text caption wherethe text for video is equal to the text for audio often creates modalinterference, confusing the pretrained backbones, and (2) the optimal mechanismfor cross-modal feature interaction remains unclear. To address thesechallenges, we first propose the Hierarchical Visual-Grounded Captioning (HVGC)framework that generates pairs of disentangled captions, a video caption, andan audio caption, eliminating interference at the conditioning stage. Based onHVGC, we further introduce BridgeDiT, a novel dual-tower diffusion transformer,which employs a Dual CrossAttention (DCA) mechanism that acts as a robust``bridge" to enable a symmetric, bidirectional exchange of information,achieving both semantic and temporal synchronization. Extensive experiments onthree benchmark datasets, supported by human evaluations, demonstrate that ourmethod achieves state-of-the-art results on most metrics. Comprehensiveablation studies further validate the effectiveness of our contributions,offering key insights for the future T2SV task. All the codes and checkpointswill be publicly released.</description><author>Kaisi Guan, Xihua Wang, Zhengfeng Lai, Xin Cheng, Peng Zhang, XiaoJiang Liu, Ruihua Song, Meng Cao</author><pubDate>Fri, 03 Oct 2025 15:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03117v1</guid></item><item><title>Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation</title><link>http://arxiv.org/abs/2510.03115v1</link><description>Speech-to-Text Translation (S2TT) systems built from Automatic SpeechRecognition (ASR) and Text-to-Text Translation (T2TT) modules face two majorlimitations: error propagation and the inability to exploit prosodic or otheracoustic cues. Chain-of-Thought (CoT) prompting has recently been introduced,with the expectation that jointly accessing speech and transcription willovercome these issues. Analyzing CoT through attribution methods, robustnessevaluations with corrupted transcripts, and prosody-awareness, we find that itlargely mirrors cascaded behavior, relying mainly on transcripts while barelyleveraging speech. Simple training interventions, such as adding Direct S2TTdata or noisy transcript injection, enhance robustness and increase speechattribution. These findings challenge the assumed advantages of CoT andhighlight the need for architectures that explicitly integrate acousticinformation into translation.</description><author>Jacobo Romero-Díaz, Gerard I. Gállego, Oriol Pareras, Federico Costa, Javier Hernando, Cristina España-Bonet</author><pubDate>Fri, 03 Oct 2025 15:42:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03115v1</guid></item><item><title>jina-reranker-v3: Last but Not Late Interaction for Listwise Document Reranking</title><link>http://arxiv.org/abs/2509.25085v3</link><description>jina-reranker-v3 is a 0.6B-parameter multilingual listwise reranker thatintroduces a novel "last but not late" interaction. Unlike late interactionmodels like ColBERT that encode documents separately before multi-vectormatching, our approach applies causal attention between the query and allcandidate documents in the same context window, enabling rich interactionsbefore extracting contextual embeddings from each document's final token. Thenew model achieves state-of-the-art BEIR performance with 61.94 nDCG@10 whilebeing significantly smaller than other models with comparable performance.</description><author>Feng Wang, Yuqing Li, Han Xiao</author><pubDate>Fri, 03 Oct 2025 15:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25085v3</guid></item><item><title>GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion</title><link>http://arxiv.org/abs/2510.03110v1</link><description>Reference-driven image completion, which restores missing regions in a targetview using additional images, is particularly challenging when the target viewdiffers significantly from the references. Existing generative methods relysolely on diffusion priors and, without geometric cues such as camera pose ordepth, often produce misaligned or implausible content. We propose GeoComplete,a novel framework that incorporates explicit 3D structural guidance to enforcegeometric consistency in the completed regions, setting it apart from priorimage-only approaches. GeoComplete introduces two key ideas: conditioning thediffusion process on projected point clouds to infuse geometric information,and applying target-aware masking to guide the model toward relevant referencecues. The framework features a dual-branch diffusion architecture. One branchsynthesizes the missing regions from the masked target, while the otherextracts geometric features from the projected point cloud. Jointself-attention across branches ensures coherent and accurate completion. Toaddress regions visible in references but absent in the target, we project thetarget view into each reference to detect occluded areas, which are then maskedduring training. This target-aware masking directs the model to focus on usefulcues, enhancing performance in difficult scenarios. By integrating ageometry-aware dual-branch diffusion architecture with a target-aware maskingstrategy, GeoComplete offers a unified and robust solution forgeometry-conditioned image completion. Experiments show that GeoCompleteachieves a 17.1 PSNR improvement over state-of-the-art methods, significantlyboosting geometric accuracy while maintaining high visual quality.</description><author>Beibei Lin, Tingting Chen, Robby T. Tan</author><pubDate>Fri, 03 Oct 2025 15:38:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03110v1</guid></item><item><title>Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs</title><link>http://arxiv.org/abs/2502.14837v2</link><description>Multi-head Latent Attention (MLA) is an innovative architecture proposed byDeepSeek, designed to ensure efficient and economical inference bysignificantly compressing the Key-Value (KV) cache into a latent vector.Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and itsvariants such as Grouped-Query Attention (GQA) exhibit significant costdisadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLAwithout pre-training from scratch is both meaningful and challenging. Thispaper proposes the first data-efficient fine-tuning method for transitioningfrom MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,we remove RoPE from dimensions of queries and keys that contribute less to theattention scores, for low-rank approximation, we introduce joint SVDapproximations based on the pre-trained parameters of keys and values. Thesecarefully designed strategies enable MHA2MLA to recover performance using onlya small fraction (0.3% to 0.6%) of the data, significantly reducing inferencecosts while seamlessly integrating with compression techniques such as KV cachequantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,with only a 0.5% drop in LongBench performance.</description><author>Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Lixing Shen, Zhan Chen, Xipeng Qiu, Qi Zhang, Tao Gui</author><pubDate>Fri, 03 Oct 2025 15:37:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.14837v2</guid></item><item><title>Rates of Convergence of Generalised Variational Inference Posteriors under Prior Misspecification</title><link>http://arxiv.org/abs/2510.03109v1</link><description>We prove rates of convergence and robustness to prior misspecification withina Generalised Variational Inference (GVI) framework with bounded divergences.This addresses a significant open challenge for GVI and Federated GVI thatemploy a different divergence to the Kullback--Leibler under priormisspecification, operate within a subset of possible probability measures, andresult in intractable posteriors. Our theoretical contributions cover severeprior misspecification while relying on our ability to restrict the space ofpossible GVI posterior measures, and infer properties based on this space. Inparticular, we are able to establish sufficient conditions for existence anduniqueness of GVI posteriors on arbitrary Polish spaces, prove that the GVIposterior measure concentrates on a neighbourhood of loss minimisers, andextend this to rates of convergence regardless of the prior measure.</description><author>Terje Mildner, Paris Giampouras, Theodoros Damoulas</author><pubDate>Fri, 03 Oct 2025 15:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03109v1</guid></item><item><title>Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction</title><link>http://arxiv.org/abs/2510.01407v2</link><description>Image compression and reconstruction are crucial for various digitalapplications. While contemporary neural compression methods achieve impressivecompression rates, the adoption of such technology has been largely hindered bythe complexity and large computational costs of the convolution-based decodersduring data reconstruction. To address the decoder bottleneck in neuralcompression, we develop a new compression-reconstruction framework based onincorporating low-rank representation in an autoencoder with vectorquantization. We demonstrated that performing a series of computationallyefficient low-rank operations on the learned latent representation of imagescan efficiently reconstruct the data with high quality. Our approachdramatically reduces the computational overhead in the decoding phase of neuralcompression/reconstruction, essentially eliminating the decoder computebottleneck while maintaining high fidelity of image outputs.</description><author>Ethan G. Rogers, Cheng Wang</author><pubDate>Fri, 03 Oct 2025 15:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01407v2</guid></item><item><title>Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields</title><link>http://arxiv.org/abs/2510.03104v1</link><description>Semantic distillation in radiance fields has spurred significant advances inopen-vocabulary robot policies, e.g., in manipulation and navigation, foundedon pretrained semantics from large vision models. While prior work hasdemonstrated the effectiveness of visual-only semantic features (e.g., DINO andCLIP) in Gaussian Splatting and neural radiance fields, the potential benefitof geometry-grounding in distilled fields remains an open question. Inprinciple, visual-geometry features seem very promising for spatial tasks suchas pose estimation, prompting the question: Do geometry-grounded semanticfeatures offer an edge in distilled fields? Specifically, we ask three criticalquestions: First, does spatial-grounding produce higher-fidelity geometry-awaresemantic features? We find that image features from geometry-grounded backbonescontain finer structural details compared to their counterparts. Secondly, doesgeometry-grounding improve semantic object localization? We observe nosignificant difference in this task. Thirdly, does geometry-grounding enablehigher-accuracy radiance field inversion? Given the limitations of prior workand their lack of semantics integration, we propose a novel framework SPINE forinverting radiance fields without an initial guess, consisting of two corecomponents: coarse inversion using distilled semantics, and fine inversionusing photometric-based optimization. Surprisingly, we find that the poseestimation accuracy decreases with geometry-grounded features. Our resultssuggest that visual-only features offer greater versatility for a broader rangeof downstream tasks, although geometry-grounded features contain more geometricdetail. Notably, our findings underscore the necessity of future research oneffective strategies for geometry-grounding that augment the versatility andperformance of pretrained semantic features.</description><author>Zhiting Mei, Ola Shorinwa, Anirudha Majumdar</author><pubDate>Fri, 03 Oct 2025 15:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03104v1</guid></item><item><title>Morphlux: Transforming Torus Fabrics for Efficient Multi-tenant ML</title><link>http://arxiv.org/abs/2508.03674v3</link><description>We develop Morphlux, a server-scale programmable photonic fabric tointerconnect accelerators within servers. We show that augmentingstate-of-the-art torus-based ML data-centers with Morphlux can improve thebandwidth of tenant compute allocations by up to 66%, reduce computefragmentation by up to 70%, and minimize the blast radius of chip failures. Wedevelop a novel end-to-end hardware prototype of Morphlux to demonstrate theseperformance benefits which translate to 1.72X improvement in trainingthroughput of ML models. By rapidly programming the server-scale fabric in ourhardware testbed, Morphlux can replace a failed accelerator chip with a healthyone in 1.2 seconds.</description><author>Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh</author><pubDate>Fri, 03 Oct 2025 15:31:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.03674v3</guid></item><item><title>Semantic Similarity in Radiology Reports via LLMs and NER</title><link>http://arxiv.org/abs/2510.03102v1</link><description>Radiology report evaluation is a crucial part of radiologists' training andplays a key role in ensuring diagnostic accuracy. As part of the standardreporting workflow, a junior radiologist typically prepares a preliminaryreport, which is then reviewed and edited by a senior radiologist to producethe final report. Identifying semantic differences between preliminary andfinal reports is essential for junior doctors, both as a training tool and tohelp uncover gaps in clinical knowledge. While AI in radiology is a rapidlygrowing field, the application of large language models (LLMs) remainschallenging due to the need for specialised domain knowledge. In this paper, weexplore the ability of LLMs to provide explainable and accurate comparisons ofreports in the radiology domain. We begin by comparing the performance ofseveral LLMs in comparing radiology reports. We then assess a more traditionalapproach based on Named-Entity-Recognition (NER). However, both approachesexhibit limitations in delivering accurate feedback on semantic similarity. Toaddress this, we propose Llama-EntScore, a semantic similarity scoring methodusing a combination of Llama 3.1 and NER with tunable weights to emphasise orde-emphasise specific types of differences. Our approach generates aquantitative similarity score for tracking progress and also gives aninterpretation of the score that aims to offer valuable guidance in reviewingand refining their reporting. We find our method achieves 67% exact-matchaccuracy and 93% accuracy within +/- 1 when compared to radiologist-providedground truth scores - outperforming both LLMs and NER used independently. Codeis available at:\href{https://github.com/otmive/llama_reports}{github.com/otmive/llama\_reports}</description><author>Beth Pearson, Ahmed Adnan, Zahraa Abdallah</author><pubDate>Fri, 03 Oct 2025 15:31:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03102v1</guid></item><item><title>AdaBet: Gradient-free Layer Selection for Efficient Training of Deep Neural Networks</title><link>http://arxiv.org/abs/2510.03101v1</link><description>To utilize pre-trained neural networks on edge and mobile devices, we oftenrequire efficient adaptation to user-specific runtime data distributions whileoperating under limited compute and memory resources. On-device retraining witha target dataset can facilitate such adaptations; however, it remainsimpractical due to the increasing depth of modern neural nets, as well as thecomputational overhead associated with gradient-based optimization across alllayers. Current approaches reduce training cost by selecting a subset of layersfor retraining, however, they rely on labeled data, at least one full-modelbackpropagation, or server-side meta-training; limiting their suitability forconstrained devices. We introduce AdaBet, a gradient-free layer selectionapproach to rank important layers by analyzing topological features of theiractivation spaces through Betti Numbers and using forward passes alone. AdaBetallows selecting layers with high learning capacity, which are important forretraining and adaptation, without requiring labels or gradients. EvaluatingAdaBet on sixteen pairs of benchmark models and datasets, shows AdaBet achievesan average gain of 5% more classification accuracy over gradient-basedbaselines while reducing average peak memory consumption by 40%.</description><author>Irene Tenison, Soumyajit Chatterjee, Fahim Kawsar, Mohammad Malekzadeh</author><pubDate>Fri, 03 Oct 2025 15:30:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03101v1</guid></item><item><title>Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving</title><link>http://arxiv.org/abs/2510.00060v2</link><description>In this work, we reconceptualize autonomous driving as a generalized languageand formulate the trajectory planning task as next waypoint prediction. Weintroduce Max-V1, a novel framework for one-stage end-to-end autonomousdriving. Our framework presents a single-pass generation paradigm that alignswith the inherent sequentiality of driving. This approach leverages thegenerative capacity of the VLM (Vision-Language Model) to enable end-to-endtrajectory prediction directly from front-view camera input. The efficacy ofthis method is underpinned by a principled supervision strategy derived fromstatistical modeling. This provides a well-defined learning objective, whichmakes the framework highly amenable to master complex driving policies throughimitation learning from large-scale expert demonstrations. Empirically, ourmethod achieves the state-of-the-art performance on the nuScenes dataset,delivers an overall improvement of over 30% compared to prior baselines.Furthermore, it exhibits superior generalization performance on cross-domaindatasets acquired from diverse vehicles, demonstrating notable potential forcross-vehicle robustness and adaptability. Due to these empirical strengths,this work introduces a model enabling fundamental driving behaviors, laying thefoundation for the development of more capable self-driving agents. Code willbe available upon publication.</description><author>Sheng Yang, Tong Zhan, Guancheng Chen, Yanfeng Lu, Jian Wang</author><pubDate>Fri, 03 Oct 2025 15:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00060v2</guid></item><item><title>Adaptive Node Feature Selection For Graph Neural Networks</title><link>http://arxiv.org/abs/2510.03096v1</link><description>We propose an adaptive node feature selection approach for graph neuralnetworks (GNNs) that identifies and removes unnecessary features duringtraining. The ability to measure how features contribute to model output is keyfor interpreting decisions, reducing dimensionality, and even improvingperformance by eliminating unhelpful variables. However, graph-structured dataintroduces complex dependencies that may not be amenable to classical featureimportance metrics. Inspired by this challenge, we present a model- andtask-agnostic method that determines relevant features during training based onchanges in validation performance upon permuting feature values. Wetheoretically motivate our intervention-based approach by characterizing howGNN performance depends on the relationships between node data and graphstructure. Not only do we return feature importance scores once trainingconcludes, we also track how relevance evolves as features are successivelydropped. We can therefore monitor if features are eliminated effectively andalso evaluate other metrics with this technique. Our empirical results verifythe flexibility of our approach to different graph architectures as well as itsadaptability to more challenging graph learning settings.</description><author>Ali Azizpour, Madeline Navarro, Santiago Segarra</author><pubDate>Fri, 03 Oct 2025 15:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03096v1</guid></item><item><title>Distilled Protein Backbone Generation</title><link>http://arxiv.org/abs/2510.03095v1</link><description>Diffusion- and flow-based generative models have recently demonstrated strongperformance in protein backbone generation tasks, offering unprecedentedcapabilities for de novo protein design. However, while achieving notableperformance in generation quality, these models are limited by their generatingspeed, often requiring hundreds of iterative steps in the reverse-diffusionprocess. This computational bottleneck limits their practical utility inlarge-scale protein discovery, where thousands to millions of candidatestructures are needed. To address this challenge, we explore the techniques ofscore distillation, which has shown great success in reducing the number ofsampling steps in the vision domain while maintaining high generation quality.However, a straightforward adaptation of these methods results in unacceptablylow designability. Through extensive study, we have identified how toappropriately adapt Score identity Distillation (SiD), a state-of-the-art scoredistillation strategy, to train few-step protein backbone generators whichsignificantly reduce sampling time, while maintaining comparable performance totheir pretrained teacher model. In particular, multistep generation combinedwith inference time noise modulation is key to the success. We demonstrate thatour distilled few-step generators achieve more than a 20-fold improvement insampling speed, while achieving similar levels of designability, diversity, andnovelty as the Proteina teacher model. This reduction in inference cost enableslarge-scale in silico protein design, thereby bringing diffusion-based modelscloser to real-world protein engineering applications.</description><author>Liyang Xie, Haoran Zhang, Zhendong Wang, Wesley Tansey, Mingyuan Zhou</author><pubDate>Fri, 03 Oct 2025 15:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03095v1</guid></item><item><title>Revisiting Direct Speech-to-Text Translation with Speech LLMs: Better Scaling than CoT Prompting?</title><link>http://arxiv.org/abs/2510.03093v1</link><description>Recent work on Speech-to-Text Translation (S2TT) has focused on LLM-basedmodels, introducing the increasingly adopted Chain-of-Thought (CoT) prompting,where the model is guided to first transcribe the speech and then translate it.CoT typically outperforms direct prompting primarily because it can exploitabundant Automatic Speech Recognition (ASR) and Text-to-Text Translation (T2TT)datasets to explicitly model its steps. In this paper, we systematicallycompare CoT and Direct prompting under increasing amounts of S2TT data. To thisend, we pseudo-label an ASR corpus by translating its transcriptions into sixEuropean languages, and train LLM-based S2TT systems with both promptingstrategies at different data scales. Our results show that Direct improves moreconsistently as the amount of data increases, suggesting that it may become amore effective approach as larger S2TT resources are created.</description><author>Oriol Pareras, Gerard I. Gállego, Federico Costa, Cristina España-Bonet, Javier Hernando</author><pubDate>Fri, 03 Oct 2025 15:23:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03093v1</guid></item><item><title>Risk-Sensitive Agent Compositions</title><link>http://arxiv.org/abs/2506.04632v2</link><description>From software development to robot control, modern agentic systems decomposecomplex objectives into a sequence of subtasks and choose a set of specializedAI agents to complete them. We formalize agentic workflows as directed acyclicgraphs, called agent graphs, where edges represent AI agents and pathscorrespond to feasible compositions of agents. Real-world deployment requiresselecting agent compositions that not only maximize task success but alsominimize violations of safety, fairness, and privacy requirements which demandsa careful analysis of the low-probability (tail) behaviors of compositions ofagents. In this work, we consider risk minimization over the set of feasibleagent compositions and seek to minimize the value-at-risk of the lossdistribution of the agent composition where the loss quantifies violations ofthese requirements. We introduce an efficient algorithm which traverses theagent graph and finds a near-optimal composition of agents. It uses a dynamicprogramming approach to approximate the value-at-risk of agent compositions byexploiting a union bound. Furthermore, we prove that the approximation isnear-optimal asymptotically for a broad class of practical loss functions. Toevaluate our framework, we consider a suite of video game-like controlbenchmarks that require composing several agents trained with reinforcementlearning and demonstrate our algorithm's effectiveness in approximating thevalue-at-risk and identifying the optimal agent composition.</description><author>Guruprerana Shabadi, Rajeev Alur</author><pubDate>Fri, 03 Oct 2025 15:20:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.04632v2</guid></item><item><title>Latent Diffusion Unlearning: Protecting Against Unauthorized Personalization Through Trajectory Shifted Perturbations</title><link>http://arxiv.org/abs/2510.03089v1</link><description>Text-to-image diffusion models have demonstrated remarkable effectiveness inrapid and high-fidelity personalization, even when provided with only a fewuser images. However, the effectiveness of personalization techniques has leadto concerns regarding data privacy, intellectual property protection, andunauthorized usage. To mitigate such unauthorized usage and model replication,the idea of generating ``unlearnable'' training samples utilizing imagepoisoning techniques has emerged. Existing methods for this have limitedimperceptibility as they operate in the pixel space which results in imageswith noise and artifacts. In this work, we propose a novel model-basedperturbation strategy that operates within the latent space of diffusionmodels. Our method alternates between denoising and inversion while modifyingthe starting point of the denoising trajectory: of diffusion models. Thistrajectory-shifted sampling ensures that the perturbed images maintain highvisual fidelity to the original inputs while being resistant to inversion andpersonalization by downstream generative models. This approach integratesunlearnability into the framework of Latent Diffusion Models (LDMs), enabling apractical and imperceptible defense against unauthorized model adaptation. Wevalidate our approach on four benchmark datasets to demonstrate robustnessagainst state-of-the-art inversion attacks. Results demonstrate that our methodachieves significant improvements in imperceptibility ($\sim 8 \% -10\%$ onperceptual metrics including PSNR, SSIM, and FID) and robustness ( $\sim 10\%$on average across five adversarial settings), highlighting its effectiveness insafeguarding sensitive data.</description><author>Naresh Kumar Devulapally, Shruti Agarwal, Tejas Gokhale, Vishnu Suresh Lokhande</author><pubDate>Fri, 03 Oct 2025 15:18:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03089v1</guid></item><item><title>Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection</title><link>http://arxiv.org/abs/2509.12990v2</link><description>In this report, we address the problem of determining whether a user performsan action incorrectly from egocentric video data. To handle the challengesposed by subtle and infrequent mistakes, we propose a Dual-Stage ReweightedMixture-of-Experts (DR-MoE) framework. In the first stage, features areextracted using a frozen ViViT model and a LoRA-tuned ViViT model, which arecombined through a feature-level expert module. In the second stage, threeclassifiers are trained with different objectives: reweighted cross-entropy tomitigate class imbalance, AUC loss to improve ranking under skeweddistributions, and label-aware loss with sharpness-aware minimization toenhance calibration and generalization. Their predictions are fused using aclassification-level expert module. The proposed method achieves strongperformance, particularly in identifying rare and ambiguous mistake instances.The code is available at https://github.com/boyuh/DR-MoE.</description><author>Boyu Han, Qianqian Xu, Shilong Bao, Zhiyong Yang, Sicong Li, Qingming Huang</author><pubDate>Fri, 03 Oct 2025 15:18:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.12990v2</guid></item></channel></rss>