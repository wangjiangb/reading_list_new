<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 26 Sep 2025 01:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SIM-CoT: Supervised Implicit Chain-of-Thought</title><link>http://arxiv.org/abs/2509.20317v2</link><description>Implicit Chain-of-Thought (CoT) methods offer a token-efficient alternativeto explicit CoT reasoning in Large Language Models (LLMs), but a persistentperformance gap has limited their adoption. We identify a core latentinstability issue when scaling the computational budget of implicit CoT: as thenumber of reasoning tokens increases, training often becomes unstable andcollapses. Our analysis shows that this instability arises from latentrepresentations becoming homogeneous and losing semantic diversity, caused byinsufficient step-level supervision in current implicit CoT methods. To addressthis, we propose SIM-CoT, a plug-and-play training module that introducesstep-level supervision to stabilize and enrich the latent reasoning space.SIM-CoT employs an auxiliary decoder during training to align each implicittoken with its corresponding explicit reasoning step, ensuring latent statescapture distinct and meaningful information. The auxiliary decoder is removedat inference, preserving the efficiency of implicit CoT with no added overhead.It also provides interpretability by projecting each latent token onto anexplicit reasoning vocabulary, enabling per-step visualization and diagnosis.SIM-CoT significantly improves both in-domain accuracy and out-of-domainstability of implicit CoT methods, boosting Coconut by +8.2\% on GPT-2 and CODIby +3.0\% on LLaMA-3.1 8B. It further surpasses the explicit CoT baseline onGPT-2 by 2.1\% with 2.3$\times$ greater token efficiency, while closing theperformance gap on larger models like LLaMA-3.1 8B. Code:https://github.com/InternLM/SIM-CoT</description><author>Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi Wang, Xipeng Qiu, Dahua Lin</author><pubDate>Thu, 25 Sep 2025 12:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20317v2</guid></item><item><title>Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation</title><link>http://arxiv.org/abs/2509.20269v2</link><description>As deep neural networks are increasingly deployed in dynamic, real-worldenvironments, relying on a single static model is often insufficient. Changesin input data distributions caused by sensor drift or lighting variationsnecessitate continual model adaptation. In this paper, we propose a hybridtraining methodology that enables efficient on-device domain adaptation bycombining the strengths of Backpropagation and Predictive Coding. The methodbegins with a deep neural network trained offline using Backpropagation toachieve high initial performance. Subsequently, Predictive Coding is employedfor online adaptation, allowing the model to recover accuracy lost due toshifts in the input data distribution. This approach leverages the robustnessof Backpropagation for initial representation learning and the computationalefficiency of Predictive Coding for continual learning, making it particularlywell-suited for resource-constrained edge devices or future neuromorphicaccelerators. Experimental results on the MNIST and CIFAR-10 datasetsdemonstrate that this hybrid strategy enables effective adaptation with areduced computational overhead, offering a promising solution for maintainingmodel performance in dynamic environments.</description><author>Matteo Cardoni, Sam Leroux</author><pubDate>Thu, 25 Sep 2025 09:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20269v2</guid></item><item><title>EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning</title><link>http://arxiv.org/abs/2509.20360v1</link><description>Recent advances in foundation models highlight a clear trend towardunification and scaling, showing emergent capabilities across diverse domains.While image generation and editing have rapidly transitioned from task-specificto unified frameworks, video generation and editing remain fragmented due toarchitectural limitations and data scarcity. In this work, we introduceEditVerse, a unified framework for image and video generation and editingwithin a single model. By representing all modalities, i.e., text, image, andvideo, as a unified token sequence, EditVerse leverages self-attention toachieve robust in-context learning, natural cross-modal knowledge transfer, andflexible handling of inputs and outputs with arbitrary resolutions anddurations. To address the lack of video editing training data, we design ascalable data pipeline that curates 232K video editing samples and combinesthem with large-scale image and video datasets for joint training. Furthermore,we present EditVerseBench, the first benchmark for instruction-based videoediting covering diverse tasks and resolutions. Extensive experiments and userstudies demonstrate that EditVerse achieves state-of-the-art performance,surpassing existing open-source and commercial models, while exhibitingemergent editing and generation abilities across modalities.</description><author>Xuan Ju, Tianyu Wang, Yuqian Zhou, He Zhang, Qing Liu, Nanxuan Zhao, Zhifei Zhang, Yijun Li, Yuanhao Cai, Shaoteng Liu, Daniil Pakhomov, Zhe Lin, Soo Ye Kim, Qiang Xu</author><pubDate>Wed, 24 Sep 2025 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20360v1</guid></item><item><title>PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation</title><link>http://arxiv.org/abs/2509.20358v1</link><description>Existing video generation models excel at producing photo-realistic videosfrom text or images, but often lack physical plausibility and 3Dcontrollability. To overcome these limitations, we introduce PhysCtrl, a novelframework for physics-grounded image-to-video generation with physicalparameters and force control. At its core is a generative physics network thatlearns the distribution of physical dynamics across four materials (elastic,sand, plasticine, and rigid) via a diffusion model conditioned on physicsparameters and applied forces. We represent physical dynamics as 3D pointtrajectories and train on a large-scale synthetic dataset of 550K animationsgenerated by physics simulators. We enhance the diffusion model with a novelspatiotemporal attention block that emulates particle interactions andincorporates physics-based constraints during training to enforce physicalplausibility. Experiments show that PhysCtrl generates realistic,physics-grounded motion trajectories which, when used to drive image-to-videomodels, yield high-fidelity, controllable videos that outperform existingmethods in both visual quality and physical plausibility. Project Page:https://cwchenwang.github.io/physctrl</description><author>Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao Gu, Lingjie Liu</author><pubDate>Wed, 24 Sep 2025 17:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20358v1</guid></item><item><title>Language Models that Think, Chat Better</title><link>http://arxiv.org/abs/2509.20357v1</link><description>Reinforcement learning with verifiable rewards (RLVR) improves language modelreasoning by using rule-based rewards in verifiable domains such as mathematicsand code. However, RLVR leads to limited generalization for open-ended tasks --such as writing outline essays or making meal plans -- where humans reasonroutinely. This paper shows that the RLVR paradigm is effective beyondverifiable domains, and introduces **RL** with **M**odel-rewarded **T**hinking(**RLMT**) for general-purpose chat capabilities. Using diverse real-worldprompts, RLMT requires LMs to generate long CoT reasoning before response, andoptimizes them with online RL against a preference-based reward model used inRLHF. Across 40 training runs on Llama-3.1-8B and Qwen-2.5-7B (both base andinstruct) and multiple optimization algorithms (DPO, PPO, and GRPO), RLMTconsistently outperforms standard RLHF pipelines. This includes substantialgains of 3-7 points on three chat benchmarks (AlpacaEval2, WildBench, andArenaHardV2), along with 1-3 point improvements on other tasks like creativewriting and general knowledge. Our best 8B model surpasses GPT-4o in chat andcreative writing and rivals Claude-3.7-Sonnet (Thinking). RLMT can also beapplied directly to base models without an SFT stage, akin to R1-Zero training.Remarkably, with only 7K prompts, Llama-3.1-8B base trained with our RLMTrecipe outperforms Llama-3.1-8B-Instruct post-trained with a complexmulti-staged pipeline with 25M+ examples. We close with qualitative andquantitative analyses of how trained models plan their responses. Our resultsrethink the post-training pipeline and call upon future work to understand andemploy thinking more broadly.</description><author>Adithya Bhaskar, Xi Ye, Danqi Chen</author><pubDate>Wed, 24 Sep 2025 17:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20357v1</guid></item><item><title>EmbeddingGemma: Powerful and Lightweight Text Representations</title><link>http://arxiv.org/abs/2509.20354v1</link><description>We introduce EmbeddingGemma, a new lightweight, open text embedding modelbased on the Gemma 3 language model family. Our innovative training recipestrategically captures knowledge from larger models via encoder-decoderinitialization and geometric embedding distillation. We improve modelrobustness and expressiveness with a spread-out regularizer, and ensuregeneralizability by merging checkpoints from varied, optimized mixtures.Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual,English, and code domains, EmbeddingGemma (300M) achieves state-of-the-artresults. Notably, it outperforms prior top models, both proprietary and open,with fewer than 500M parameters, and provides performance comparable to modelsdouble its size, offering an exceptional performance-to-cost ratio. Remarkably,this lead persists when quantizing model weights or truncating embeddingoutputs. This makes EmbeddingGemma particularly well-suited for low-latency andhigh-throughput use cases such as on-device applications. We provide ablationstudies exploring our key design choices. We release EmbeddingGemma to thecommunity to promote further research.</description><author>Henrique Schechter Vera, Sahil Dua, Biao Zhang, Daniel Salz, Ryan Mullins, Sindhu Raghuram Panyam, Sara Smoot, Iftekhar Naim, Joe Zou, Feiyang Chen, Daniel Cer, Alice Lisak, Min Choi, Lucas Gonzalez, Omar Sanseviero, Glenn Cameron, Ian Ballantyne, Kat Black, Kaifeng Chen, Weiyi Wang, Zhe Li, Gus Martins, Jinhyuk Lee, Mark Sherwood, Juyeong Ji, Renjie Wu, Jingxiao Zheng, Jyotinder Singh, Abheesht Sharma, Divya Sreepat, Aashi Jain, Adham Elarabawy, AJ Co, Andreas Doumanoglou, Babak Samari, Ben Hora, Brian Potetz, Dahun Kim, Enrique Alfonseca, Fedor Moiseev, Feng Han, Frank Palma Gomez, Gustavo Hernández Ábrego, Hesen Zhang, Hui Hui, Jay Han, Karan Gill, Ke Chen, Koert Chen, Madhuri Shanbhogue, Michael Boratko, Paul Suganthan, Sai Meher Karthik Duddu, Sandeep Mariserla, Setareh Ariafar, Shanf</author><pubDate>Wed, 24 Sep 2025 17:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20354v1</guid></item><item><title>Efficiently learning depth-3 circuits via quantum agnostic boosting</title><link>http://arxiv.org/abs/2509.14461v2</link><description>We initiate the study of quantum agnostic learning of phase states withrespect to a function class $\mathsf{C}\subseteq \{c:\{0,1\}^n\rightarrow\{0,1\}\}$: given copies of an unknown $n$-qubit state $|\psi\rangle$ which hasfidelity $\textsf{opt}$ with a phase state$|\phi_c\rangle=\frac{1}{\sqrt{2^n}}\sum_{x\in \{0,1\}^n}(-1)^{c(x)}|x\rangle$for some $c\in \mathsf{C}$, output $|\phi\rangle$ which has fidelity $|\langle\phi | \psi \rangle|^2 \geq \textsf{opt}-\varepsilon$. To this end, we giveagnostic learning protocols for the following classes: (i) Size-$t$ decisiontrees which runs in time $\textsf{poly}(n,t,1/\varepsilon)$. This also implies$k$-juntas can be agnostically learned in time$\textsf{poly}(n,2^k,1/\varepsilon)$. (ii) $s$-term DNF formulas in time$\textsf{poly}(n,(s/\varepsilon)^{\log \log (s/\varepsilon) \cdot\log(1/\varepsilon)})$. Our main technical contribution is a quantum agnostic boosting protocol whichconverts a weak agnostic learner, which outputs a parity state $|\phi\rangle$such that $|\langle \phi|\psi\rangle|^2\geq \textsf{opt}/\textsf{poly}(n)$,into a strong learner which outputs a superposition of parity states$|\phi'\rangle$ such that $|\langle \phi'|\psi\rangle|^2\geq \textsf{opt} -\varepsilon$. Using quantum agnostic boosting, we obtain a $n^{O(\log \log n \cdot\log(1/\varepsilon))}$-time algorithm for learning $\textsf{poly}(n)$-sizeddepth-$3$ circuits (consisting of $\textsf{AND}$, $\textsf{OR}$, $\textsf{NOT}$gates) in the uniform $\textsf{PAC}$ model given quantum examples, which isnear-polynomial time for constant $\varepsilon$. Classically, obtaining analgorithm with a similar complexity has been an open question in the$\textsf{PAC}$ model and our work answers this given quantum examples.</description><author>Srinivasan Arunachalam, Arkopal Dutt, Alexandru Gheorghiu, Michael de Oliveira</author><pubDate>Wed, 24 Sep 2025 17:54:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.14461v2</guid></item><item><title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</title><link>http://arxiv.org/abs/2401.10371v7</link><description>Machine unlearning has raised significant interest with the adoption of lawsensuring the ``right to be forgotten''. Researchers have provided aprobabilistic notion of approximate unlearning under a similar definition ofDifferential Privacy (DP), where privacy is defined as statisticalindistinguishability to retraining from scratch. We propose Langevinunlearning, an unlearning framework based on noisy gradient descent withprivacy guarantees for approximate unlearning problems. Langevin unlearningunifies the DP learning process and the privacy-certified unlearning processwith many algorithmic benefits. These include approximate certified unlearningfor non-convex problems, complexity saving compared to retraining, sequentialand batch unlearning for multiple unlearning requests.</description><author>Eli Chien, Haoyu Wang, Ziang Chen, Pan Li</author><pubDate>Wed, 24 Sep 2025 17:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10371v7</guid></item><item><title>Exploring Graph-Transformer Out-of-Distribution Generalization Abilities</title><link>http://arxiv.org/abs/2506.20575v2</link><description>Deep learning on graphs has shown remarkable success across numerousapplications, including social networks, bio-physics, traffic networks, andrecommendation systems. Regardless of their successes, current methodsfrequently depend on the assumption that training and testing data share thesame distribution, a condition rarely met in real-world scenarios. Whilegraph-transformer (GT) backbones have recently outperformed traditionalmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)benchmarks, their effectiveness under distribution shifts remains largelyunexplored. In this work, we address the challenge of out-of-distribution (OOD)generalization for graph neural networks, with a special focus on the impact ofbackbone architecture. We systematically evaluate GT and hybrid backbones inOOD settings and compare them to MPNNs. To do so, we adapt several leadingdomain generalization (DG) algorithms to work with GTs and assess theirperformance on a benchmark designed to test a variety of distribution shifts.Our results reveal that GT and hybrid GT-MPNN backbones demonstrate strongergeneralization ability compared to MPNNs, even without specialized DGalgorithms (on four out of six benchmarks). Additionally, we propose a novelpost-training analysis approach that compares the clustering structure of theentire ID and OOD test datasets, specifically examining domain alignment andclass separation. Highlighting its model-agnostic design, the method yieldedvaluable insights into both GT and MPNN backbones and appears well suited forbroader DG applications beyond graph learning, offering a deeper perspective ongeneralization abilities that goes beyond standard accuracy metrics. Together,our findings highlight the promise of graph-transformers for robust, real-worldgraph learning and set a new direction for future research in OODgeneralization.</description><author>Itay Niv, Neta Rabin</author><pubDate>Wed, 24 Sep 2025 17:48:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.20575v2</guid></item><item><title>LEDiT: Your Length-Extrapolatable Diffusion Transformer without Positional Encoding</title><link>http://arxiv.org/abs/2503.04344v3</link><description>Diffusion transformers (DiTs) struggle to generate images at resolutionshigher than their training resolutions. The primary obstacle is that theexplicit positional encodings(PE), such as RoPE, need extrapolating to unseenpositions which degrades performance when the inference resolution differs fromtraining. In this paper, We propose a Length-Extrapolatable DiffusionTransformer~(LEDiT) to overcome this limitation. LEDiT needs no explicit PEs,thereby avoiding PE extrapolation. The key innovation of LEDiT lies in the useof causal attention. We demonstrate that causal attention can implicitly encodeglobal positional information and show that such information facilitatesextrapolation. We further introduce a locality enhancement module, whichcaptures fine-grained local information to complement the global coarse-grainedposition information encoded by causal attention. Experimental results on bothconditional and text-to-image generation tasks demonstrate that LEDiT supportsup to 4x resolution scaling (e.g., from 256x256 to 512x512), achieving betterimage quality compared to the state-of-the-art length extrapolation methods. Webelieve that LEDiT marks a departure from the standard RoPE-based methods andoffers a promising insight into length extrapolation. Project page:https://shenzhang2145.github.io/ledit/</description><author>Shen Zhang, Siyuan Liang, Yaning Tan, Zhaowei Chen, Linze Li, Ge Wu, Yuhao Chen, Shuheng Li, Zhenyu Zhao, Caihua Chen, Jiajun Liang, Yao Tang</author><pubDate>Wed, 24 Sep 2025 17:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.04344v3</guid></item><item><title>Fair Clustering with Minimum Representation Constraints</title><link>http://arxiv.org/abs/2409.02963v2</link><description>Clustering is a well-studied unsupervised learning task that aims topartition data points into a number of clusters. In many applications, theseclusters correspond to real-world constructs (e.g., electoral districts,playlists, TV channels), where a group (e.g., social or demographic) benefitsonly if it reaches a minimum level of representation in the cluster (e.g., 50%to elect their preferred candidate). In this paper, we study the k-means andk-medians clustering problems under the additional fairness constraint thateach group must attain a minimum level of representation in at least aspecified number of clusters. We formulate this problem as a mixed-integer(nonlinear) optimization problem and propose an alternating minimizationalgorithm, called MiniReL, to solve it. Although incorporating fairnessconstraints results in an NP-hard assignment problem within the MiniReLalgorithm, we present several heuristic strategies that make the approachpractical even for large datasets. Numerical results demonstrate that ourmethod yields fair clusters without increasing clustering cost across standardbenchmark datasets.</description><author>Connor Lawless, Oktay Gunluk</author><pubDate>Wed, 24 Sep 2025 17:47:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02963v2</guid></item><item><title>Process-Informed Forecasting of Complex Thermal Dynamics in Pharmaceutical Manufacturing</title><link>http://arxiv.org/abs/2509.20349v1</link><description>Accurate time-series forecasting for complex physical systems is the backboneof modern industrial monitoring and control. While deep learning models excelat capturing complex dynamics, currently, their deployment is limited due tophysical inconsistency and robustness, hence constraining their reliability inregulated environments. We introduce process-informed forecasting (PIF) modelsfor temperature in pharmaceutical lyophilization. We investigate a wide rangeof models, from classical ones such as Autoregressive Integrated Moving AverageModel (ARIMA) and Exponential Smoothing Model (ETS), to modern deep learningarchitectures, including Kolmogorov-Arnold Networks (KANs). We compare threedifferent loss function formulations that integrate a process-informedtrajectory prior: a fixed-weight loss, a dynamic uncertainty-based loss, and aResidual-Based Attention (RBA) mechanism. We evaluate all models not only foraccuracy and physical consistency but also for robustness to sensor noise.Furthermore, we test the practical generalizability of the best model in atransfer learning scenario on a new process. Our results show that PIF modelsoutperform their data-driven counterparts in terms of accuracy, physicalplausibility and noise resilience. This work provides a roadmap for developingreliable and generalizable forecasting solutions for critical applications inthe pharmaceutical manufacturing landscape.</description><author>Ramona Rubini, Siavash Khodakarami, Aniruddha Bora, George Em Karniadakis, Michele Dassisti</author><pubDate>Wed, 24 Sep 2025 17:42:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20349v1</guid></item><item><title>Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees</title><link>http://arxiv.org/abs/2509.20345v1</link><description>The rapid proliferation of high-quality synthetic data -- generated byadvanced AI models or collected as auxiliary data from related tasks --presents both opportunities and challenges for statistical inference. Thispaper introduces a GEneral Synthetic-Powered Inference (GESPI) framework thatwraps around any statistical inference procedure to safely enhance sampleefficiency by combining synthetic and real data. Our framework leverageshigh-quality synthetic data to boost statistical power, yet adaptively defaultsto the standard inference method using only real data when synthetic data is oflow quality. The error of our method remains below a user-specified boundwithout any distributional assumptions on the synthetic data, and decreases asthe quality of the synthetic data improves. This flexibility enables seamlessintegration with conformal prediction, risk control, hypothesis testing, andmultiple testing procedures, all without modifying the base inference method.We demonstrate the benefits of our method on challenging tasks with limitedlabeled data, including AlphaFold protein structure prediction, and comparinglarge reasoning models on complex math problems.</description><author>Meshi Bashari, Yonghoon Lee, Roy Maor Lotan, Edgar Dobriban, Yaniv Romano</author><pubDate>Wed, 24 Sep 2025 17:37:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20345v1</guid></item><item><title>Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On</title><link>http://arxiv.org/abs/2509.20343v1</link><description>As online shopping continues to grow, the demand for Virtual Try-On (VTON)technology has surged, allowing customers to visualize products on themselvesby overlaying product images onto their own photos. An essential yetchallenging condition for effective VTON is pose control, which ensuresaccurate alignment of products with the user's body while supporting diverseorientations for a more immersive experience. However, incorporating poseconditions into VTON models presents several challenges, including selectingthe optimal pose representation, integrating poses without additionalparameters, and balancing pose preservation with flexible pose control. In this work, we build upon a baseline VTON model that concatenates thereference image condition without external encoder, control network, or complexattention layers. We investigate methods to incorporate pose control into thispure concatenation paradigm by spatially concatenating pose data, comparingperformance using pose maps and skeletons, without adding any additionalparameters or module to the baseline model. Our experiments reveal that posestitching with pose maps yields the best results, enhancing both posepreservation and output realism. Additionally, we introduce a mixed-masktraining strategy using fine-grained and bounding box masks, allowing the modelto support flexible product integration across varied poses and conditions.</description><author>Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane</author><pubDate>Wed, 24 Sep 2025 17:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20343v1</guid></item><item><title>Morphological Synthesizer for Ge'ez Language: Addressing Morphological Complexity and Resource Limitations</title><link>http://arxiv.org/abs/2509.20341v1</link><description>Ge'ez is an ancient Semitic language renowned for its unique alphabet. Itserves as the script for numerous languages, including Tigrinya and Amharic,and played a pivotal role in Ethiopia's cultural and religious developmentduring the Aksumite kingdom era. Ge'ez remains significant as a liturgicallanguage in Ethiopia and Eritrea, with much of the national identitydocumentation recorded in Ge'ez. These written materials are invaluable primarysources for studying Ethiopian and Eritrean philosophy, creativity, knowledge,and civilization. Ge'ez has a complex morphological structure with richinflectional and derivational morphology, and no usable NLP has been developedand published until now due to the scarcity of annotated linguistic data,corpora, labeled datasets, and lexicons. Therefore, we propose a rule-basedGe'ez morphological synthesizer to generate surface words from root wordsaccording to the morphological structures of the language. We used 1,102 sampleverbs, representing all verb morphological structures, to test and evaluate thesystem. The system achieves a performance of 97.4%, outperforming the baselinemodel and suggesting that future work should build a comprehensive systemconsidering morphological variations of the language. Keywords: Ge'ez, NLP, morphology, morphological synthesizer, rule-based</description><author>Gebrearegawi Gebremariam, Hailay Teklehaymanot, Gebregewergs Mezgebe</author><pubDate>Wed, 24 Sep 2025 17:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20341v1</guid></item><item><title>Spatio-Temporal Directed Graph Learning for Account Takeover Fraud Detection</title><link>http://arxiv.org/abs/2509.20339v1</link><description>Account Takeover (ATO) fraud poses a significant challenge in consumerbanking, requiring high recall under strict latency while minimizing frictionfor legitimate users. Production systems typically rely on tabulargradient-boosted decision trees (e.g., XGBoost) that score sessionsindependently, overlooking the relational and temporal structure of onlineactivity that characterizes coordinated attacks and "fraud rings." We introduceATLAS (Account Takeover Learning Across Spatio-Temporal Directed Graph), aframework that reformulates ATO detection as spatio-temporal nodeclassification on a time-respecting directed session graph. ATLAS linksentities via shared identifiers (account, device, IP) and regulatesconnectivity with time-window and recency constraints, enabling causal,time-respecting message passing and latency-aware label propagation that usesonly labels available at scoring time, non-anticipative and leakage-free. Weoperationalize ATLAS with inductive GraphSAGE variants trained via neighborsampling, at scale on a sessions graph with more than 100M nodes and around 1Bedges. On a high-risk digital product at Capital One, ATLAS delivers 6.38percent AUC improvement and more than 50 percent reduction in customerfriction, improving fraud capture while reducing user friction.</description><author>Mohsen Nayebi Kerdabadi, William Andrew Byron, Xin Sun, Amirfarrokh Iranitalab</author><pubDate>Wed, 24 Sep 2025 17:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20339v1</guid></item><item><title>Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2509.20338v1</link><description>Conventional multi-agent reinforcement learning (MARL) methods rely ontime-triggered execution, where agents sample and communicate actions at fixedintervals. This approach is often computationally expensive andcommunication-intensive. To address this limitation, we propose ET-MAPG(Event-Triggered Multi-Agent Policy Gradient reinforcement learning), aframework that jointly learns an agent's control policy and itsevent-triggering policy. Unlike prior work that decouples these mechanisms,ET-MAPG integrates them into a unified learning process, enabling agents tolearn not only what action to take but also when to execute it. For scenarioswith inter-agent communication, we introduce AET-MAPG, an attention-basedvariant that leverages a self-attention mechanism to learn selectivecommunication patterns. AET-MAPG empowers agents to determine not only when totrigger an action but also with whom to communicate and what information toexchange, thereby optimizing coordination. Both methods can be integrated withany policy gradient MARL algorithm. Extensive experiments across diverse MARLbenchmarks demonstrate that our approaches achieve performance comparable tostate-of-the-art, time-triggered baselines while significantly reducing bothcomputational load and communication overhead.</description><author>Umer Siddique, Abhinav Sinha, Yongcan Cao</author><pubDate>Wed, 24 Sep 2025 17:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20338v1</guid></item><item><title>DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data</title><link>http://arxiv.org/abs/2505.15074v3</link><description>Large Language Models (LLMs) are increasingly aligned with human preferencesthrough Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods,Group Relative Policy Optimization (GRPO) has gained attention for itssimplicity and strong performance, notably eliminating the need for a learnedvalue function. However, GRPO implicitly assumes a balanced domain distributionand uniform semantic alignment across groups, assumptions that rarely hold inreal-world datasets. When applied to multi-domain, imbalanced data, GRPOdisproportionately optimizes for dominant domains, neglecting underrepresentedones and resulting in poor generalization and fairness. We proposeDomain-Informed Self-Consistency Policy Optimization (DISCO), a principledextension to GRPO that addresses inter-group imbalance with two keyinnovations. Domain-aware reward scaling counteracts frequency bias byreweighting optimization based on domain prevalence. Difficulty-aware rewardscaling leverages prompt-level self-consistency to identify and prioritizeuncertain prompts that offer greater learning value. Together, these strategiespromote more equitable and effective policy learning across domains. Extensiveexperiments across multiple LLMs and skewed training distributions show thatDISCO improves generalization, outperforms existing GRPO variants by 5% onQwen3 models, and sets new state-of-the-art results on multi-domain alignmentbenchmarks. Our code and data are available athttps://github.com/Tonyzhou98/disco_grpo.</description><author>Yuhang Zhou, Jing Zhu, Shengyi Qian, Zhuokai Zhao, Xiyao Wang, Xiaoyu Liu, Ming Li, Paiheng Xu, Wei Ai, Furong Huang</author><pubDate>Wed, 24 Sep 2025 17:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15074v3</guid></item><item><title>Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing</title><link>http://arxiv.org/abs/2509.20336v1</link><description>Transformer-based LLMs demonstrate strong performance on graph reasoningtasks, yet their internal mechanisms remain underexplored. To uncover thesereasoning process mechanisms in a fundamental and unified view, we set thebasic decoder-only transformers and explain them using the circuit-tracerframework. Through this lens, we visualize reasoning traces and identify twocore mechanisms in graph reasoning: token merging and structural memorization,which underlie both path reasoning and substructure extraction tasks. Wefurther quantify these behaviors and analyze how they are influenced by graphdensity and model size. Our study provides a unified interpretability frameworkfor understanding structural reasoning in decoder-only Transformers.</description><author>Xinnan Dai, Chung-Hsiang Lo, Kai Guo, Shenglai Zeng, Dongsheng Luo, Jiliang Tang</author><pubDate>Wed, 24 Sep 2025 17:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20336v1</guid></item><item><title>Feature Dynamics as Implicit Data Augmentation: A Depth-Decomposed View on Deep Neural Network Generalization</title><link>http://arxiv.org/abs/2509.20334v1</link><description>Why do deep networks generalize well? In contrast to classical generalizationtheory, we approach this fundamental question by examining not only inputs andoutputs, but the evolution of internal features. Our study suggests aphenomenon of temporal consistency that predictions remain stable when shallowfeatures from earlier checkpoints combine with deeper features from later ones.This stability is not a trivial convergence artifact. It acts as a form ofimplicit, structured augmentation that supports generalization. We show thattemporal consistency extends to unseen and corrupted data, but collapses whensemantic structure is destroyed (e.g., random labels). Statistical testsfurther reveal that SGD injects anisotropic noise aligned with a few principaldirections, reinforcing its role as a source of structured variability.Together, these findings suggest a conceptual perspective that links featuredynamics to generalization, pointing toward future work on practical surrogatesfor measuring temporal feature evolution.</description><author>Tianyu Ruan, Kuo Gai, Shihua Zhang</author><pubDate>Wed, 24 Sep 2025 17:23:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20334v1</guid></item><item><title>Multimodal Reference Visual Grounding</title><link>http://arxiv.org/abs/2504.02876v2</link><description>Visual grounding focuses on detecting objects from images based on languageexpressions. Recent Large Vision-Language Models (LVLMs) have significantlyadvanced visual grounding performance by training large models with large-scaledatasets. However, the problem remains challenging, especially when similarobjects appear in the input image. For example, an LVLM may not be able todifferentiate Diet Coke and regular Coke in an image. In this case, ifadditional reference images of Diet Coke and regular Coke are available, it canhelp the visual grounding of similar objects. In this work, we introduce a new task named Multimodal Reference VisualGrounding (MRVG). In this task, a model has access to a set of reference imagesof objects in a database. Based on these reference images and a languageexpression, the model is required to detect a target object from a query image.We first introduce a new dataset to study the MRVG problem. Then we introduce anovel method, named MRVG-Net, to solve this visual grounding problem. We showthat by efficiently using reference images with few-shot object detection andusing Large Language Models (LLMs) for object matching, our method achievessuperior visual grounding performance compared to the state-of-the-art LVLMssuch as Qwen2.5-VL-72B. Our approach bridges the gap between few-shot detectionand visual grounding, unlocking new capabilities for visual understanding,which has wide applications in robotics. Project page with our video, code, anddataset: https://irvlutd.github.io/MultiGrounding</description><author>Yangxiao Lu, Ruosen Li, Liqiang Jing, Jikai Wang, Xinya Du, Yunhui Guo, Nicholas Ruozzi, Yu Xiang</author><pubDate>Wed, 24 Sep 2025 17:23:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.02876v2</guid></item><item><title>Video models are zero-shot learners and reasoners</title><link>http://arxiv.org/abs/2509.20328v1</link><description>The remarkable zero-shot capabilities of Large Language Models (LLMs) havepropelled natural language processing from task-specific models to unified,generalist foundation models. This transformation emerged from simpleprimitives: large, generative models trained on web-scale data. Curiously, thesame primitives apply to today's generative video models. Could video models beon a trajectory towards general-purpose vision understanding, much like LLMsdeveloped general-purpose language understanding? We demonstrate that Veo 3 cansolve a broad variety of tasks it wasn't explicitly trained for: segmentingobjects, detecting edges, editing images, understanding physical properties,recognizing object affordances, simulating tool use, and more. These abilitiesto perceive, model, and manipulate the visual world enable early forms ofvisual reasoning like maze and symmetry solving. Veo's emergent zero-shotcapabilities indicate that video models are on a path to becoming unified,generalist vision foundation models.</description><author>Thaddäus Wiedemer, Yuxuan Li, Paul Vicol, Shixiang Shane Gu, Nick Matarese, Kevin Swersky, Been Kim, Priyank Jaini, Robert Geirhos</author><pubDate>Wed, 24 Sep 2025 17:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20328v1</guid></item><item><title>RAG Security and Privacy: Formalizing the Threat Model and Attack Surface</title><link>http://arxiv.org/abs/2509.20324v1</link><description>Retrieval-Augmented Generation (RAG) is an emerging approach in naturallanguage processing that combines large language models (LLMs) with externaldocument retrieval to produce more accurate and grounded responses. While RAGhas shown strong potential in reducing hallucinations and improving factualconsistency, it also introduces new privacy and security challenges that differfrom those faced by traditional LLMs. Existing research has demonstrated thatLLMs can leak sensitive information through training data memorization oradversarial prompts, and RAG systems inherit many of these vulnerabilities. Atthe same time, reliance of RAG on an external knowledge base opens new attacksurfaces, including the potential for leaking information about the presence orcontent of retrieved documents, or for injecting malicious content tomanipulate model behavior. Despite these risks, there is currently no formalframework that defines the threat landscape for RAG systems. In this paper, weaddress a critical gap in the literature by proposing, to the best of ourknowledge, the first formal threat model for retrieval-RAG systems. Weintroduce a structured taxonomy of adversary types based on their access tomodel components and data, and we formally define key threat vectors such asdocument-level membership inference and data poisoning, which pose seriousprivacy and integrity risks in real-world deployments. By establishing formaldefinitions and attack models, our work lays the foundation for a more rigorousand principled understanding of privacy and security in RAG systems.</description><author>Atousa Arzanipour, Rouzbeh Behnia, Reza Ebrahimi, Kaushik Dutta</author><pubDate>Wed, 24 Sep 2025 17:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20324v1</guid></item><item><title>A Recovery Guarantee for Sparse Neural Networks</title><link>http://arxiv.org/abs/2509.20323v1</link><description>We prove the first guarantees of sparse recovery for ReLU neural networks,where the sparse network weights constitute the signal to be recovered.Specifically, we study structural properties of the sparse network weights fortwo-layer, scalar-output networks under which a simple iterative hardthresholding algorithm recovers these weights exactly, using memory that growslinearly in the number of nonzero weights. We validate this theoretical resultwith simple experiments on recovery of sparse planted MLPs, MNISTclassification, and implicit neural representations. Experimentally, we findperformance that is competitive with, and often exceeds, a high-performing butmemory-inefficient baseline based on iterative magnitude pruning.</description><author>Sara Fridovich-Keil, Mert Pilanci</author><pubDate>Wed, 24 Sep 2025 17:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20323v1</guid></item><item><title>VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation</title><link>http://arxiv.org/abs/2509.20322v1</link><description>Humanoid loco-manipulation in unstructured environments demands tightintegration of egocentric perception and whole-body control. However, existingapproaches either depend on external motion capture systems or fail togeneralize across diverse tasks. We introduce VisualMimic, a visual sim-to-realframework that unifies egocentric vision with hierarchical whole-body controlfor humanoid robots. VisualMimic combines a task-agnostic low-level keypointtracker -- trained from human motion data via a teacher-student scheme -- witha task-specific high-level policy that generates keypoint commands from visualand proprioceptive input. To ensure stable training, we inject noise into thelow-level policy and clip high-level actions using human motion statistics.VisualMimic enables zero-shot transfer of visuomotor policies trained insimulation to real humanoid robots, accomplishing a wide range ofloco-manipulation tasks such as box lifting, pushing, football dribbling, andkicking. Beyond controlled laboratory settings, our policies also generalizerobustly to outdoor environments. Videos are available at:https://visualmimic.github.io .</description><author>Shaofeng Yin, Yanjie Ze, Hong-Xing Yu, C. Karen Liu, Jiajun Wu</author><pubDate>Wed, 24 Sep 2025 17:10:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20322v1</guid></item><item><title>DRES: Benchmarking LLMs for Disfluency Removal</title><link>http://arxiv.org/abs/2509.20321v1</link><description>Disfluencies -- such as "um," "uh," interjections, parentheticals, and editedstatements -- remain a persistent challenge for speech-driven systems,degrading accuracy in command interpretation, summarization, and conversationalagents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlledtext-level benchmark that establishes a reproducible semantic upper bound forthis task. DRES builds on human-annotated Switchboard transcripts, isolatingdisfluency removal from ASR errors and acoustic variability. We systematicallyevaluate proprietary and open-source LLMs across scales, prompting strategies,and architectures. Our results reveal that (i) simple segmentation consistentlyimproves performance, even for long-context models; (ii) reasoning-orientedmodels tend to over-delete fluent tokens; and (iii) fine-tuning achieves nearstate-of-the-art precision and recall but harms generalization abilities. Wefurther present a set of LLM-specific error modes and offer nine practicalrecommendations (R1-R9) for deploying disfluency removal in speech-drivenpipelines. DRES provides a reproducible, model-agnostic foundation foradvancing robust spoken-language systems.</description><author>Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee</author><pubDate>Wed, 24 Sep 2025 17:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20321v1</guid></item><item><title>Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector</title><link>http://arxiv.org/abs/2508.13739v2</link><description>The growing deployment of Large Vision-Language Models (VLMs) raises safetyconcerns, as adversaries may exploit model vulnerabilities to induce harmfuloutputs, with targeted black-box adversarial attacks posing a particularlysevere threat. However, existing methods primarily maximize encoder-levelglobal similarity, which lacks the granularity for stealthy and practicalfine-grained attacks, where only specific target should be altered (e.g.,modifying a car while preserving its background). Moreover, they largelyneglect the projector, a key semantic bridge in VLMs for multimodal alignment.To address these limitations, we propose a novel black-box targeted attackframework that leverages the projector. Specifically, we utilize the widelyadopted Querying Transformer (Q-Former) which transforms global imageembeddings into fine-grained query outputs, to enhance attack effectiveness andgranularity. For standard global targeted attack scenarios, we propose theIntermediate Projector Guided Attack (IPGA), which aligns Q-Former fine-grainedquery outputs with the target to enhance attack strength and exploits theintermediate pretrained Q-Former that is not fine-tuned for any specific LargeLanguage Model (LLM) to improve attack transferability. For fine-grained attackscenarios, we augment IPGA with the Residual Query Alignment (RQA) module,which preserves unrelated content by constraining non-target query outputs toenhance attack granularity. Extensive experiments demonstrate that IPGAsignificantly outperforms baselines in global targeted attacks, and IPGA withRQA (IPGA-R) attains superior success rates and unrelated content preservationover baselines in fine-grained attacks. Our method also transfers effectivelyto commercial VLMs such as Google Gemini and OpenAI GPT.</description><author>Yiming Cao, Yanjie Li, Kaisheng Liang, Bin Xiao</author><pubDate>Wed, 24 Sep 2025 17:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13739v2</guid></item><item><title>Z-Scores: A Metric for Linguistically Assessing Disfluency Removal</title><link>http://arxiv.org/abs/2509.20319v1</link><description>Evaluating disfluency removal in speech requires more than aggregatetoken-level scores. Traditional word-based metrics such as precision, recall,and F1 (E-Scores) capture overall performance but cannot reveal why modelssucceed or fail. We introduce Z-Scores, a span-level linguistically-groundedevaluation metric that categorizes system behavior across distinct disfluencytypes (EDITED, INTJ, PRN). Our deterministic alignment module enables robustmapping between generated text and disfluent transcripts, allowing Z-Scores toexpose systematic weaknesses that word-level metrics obscure. By providingcategory-specific diagnostics, Z-Scores enable researchers to identify modelfailure modes and design targeted interventions -- such as tailored prompts ordata augmentation -- yielding measurable performance improvements. A case studywith LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencieshidden in aggregate F1, directly informing model refinement strategies.</description><author>Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee</author><pubDate>Wed, 24 Sep 2025 17:02:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20319v1</guid></item><item><title>A Comprehensive Evaluation of YOLO-based Deer Detection Performance on Edge Devices</title><link>http://arxiv.org/abs/2509.20318v1</link><description>The escalating economic losses in agriculture due to deer intrusion,estimated to be in the hundreds of millions of dollars annually in the U.S.,highlight the inadequacy of traditional mitigation strategies since thesemethods are often labor-intensive, costly, and ineffective for modern farmingsystems. To overcome this, there is a critical need for intelligent, autonomoussolutions which require accurate and efficient deer detection. But the progressin this field is impeded by a significant gap in the literature, mainly thelack of a domain-specific, practical dataset and limited study on the on-fielddeployability of deer detection systems. Addressing this gap, this studypresents a comprehensive evaluation of state-of-the-art deep learning modelsfor deer detection in challenging real-world scenarios. The contributions ofthis work are threefold. First, we introduce a curated, publicly availabledataset of 3,095 annotated images with bounding-box annotations of deer,derived from the Idaho Cameratraps project. Second, we provide an extensivecomparative analysis of 12 model variants across four recent YOLOarchitectures(v8, v9, v10, and v11). Finally, we benchmarked performance on ahigh-end NVIDIA RTX 5090 GPU and evaluated on two representative edge computingplatforms: Raspberry Pi 5 and NVIDIA Jetson AGX Xavier. Results show that thereal-time detection is not feasible in Raspberry Pi without hardware-specificmodel optimization, while NVIDIA Jetson provides greater than 30 FPS withGPU-accelerated inference on 's' and 'n' series models. This study also revealsthat smaller, architecturally advanced models such as YOLOv11n, YOLOv8s, andYOLOv9s offer the optimal balance of high accuracy (AP@.5 &gt; 0.85) andcomputational efficiency (FPS &gt; 30). To support further research, both thesource code and datasets are publicly available athttps://github.com/WinnerBishal/track-the-deer.</description><author>Bishal Adhikari, Jiajia Li, Eric S. Michel, Jacob Dykes, Te-Ming Paul Tseng, Mary Love Tagert, Dong Chen</author><pubDate>Wed, 24 Sep 2025 17:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20318v1</guid></item><item><title>SIM-CoT: Supervised Implicit Chain-of-Thought</title><link>http://arxiv.org/abs/2509.20317v1</link><description>Implicit Chain-of-Thought (CoT) methods present a promising, token-efficientalternative to explicit CoT reasoning in Large Language Models (LLMs), but apersistent performance gap has limited the application of implicit CoT. Weidentify a core latent instability issue by scaling the computational budget ofimplicit CoT approaches: as we increase the number of implicit reasoning tokensto enhance performance, the training process often becomes unstable andcollapses. Our analysis reveals that this instability arises from the latentrepresentations becoming homogeneous and losing their semantic diversity, afailure caused by insufficient step-level supervision in existing implicit CoTapproaches. To address this issue, we propose SIM-CoT, a plug-and-play trainingmodule that introduces step-level supervision to stabilize and enrich thelatent reasoning space. Specifically, SIM-CoT employs an auxiliary decoderduring training to align each implicit token with its corresponding explicitreasoning step, ensuring that latent states capture distinct and meaningfulinformation. The proposed auxiliary decoder is removed during inference,preserving the computational efficiency of implicit CoT methods with no addedoverhead. In addition, the auxiliary decoder affords interpretability ofimplicit reasoning by projecting each latent token onto an explicit reasoningvocabulary, enabling per-step visualization of semantic roles and diagnosis.SIM-CoT significantly enhances both the in-domain accuracy and out-of-domainstability of various implicit CoT methods, boosting baselines like Coconut by+8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strongscalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1%with 2.3\times greater token efficiency, while substantially closing theperformance gap on larger models like LLaMA-3.1 8B.</description><author>Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi Wang, Xipeng Qiu, Dahua Lin</author><pubDate>Wed, 24 Sep 2025 17:01:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20317v1</guid></item><item><title>A GEN AI Framework for Medical Note Generation</title><link>http://arxiv.org/abs/2410.01841v2</link><description>The increasing administrative burden of medical documentation, particularlythrough Electronic Health Records (EHR), significantly reduces the timeavailable for direct patient care and contributes to physician burnout. Toaddress this issue, we propose MediNotes, an advanced generative AI frameworkdesigned to automate the creation of SOAP (Subjective, Objective, Assessment,Plan) notes from medical conversations. MediNotes integrates Large LanguageModels (LLMs), Retrieval-Augmented Generation (RAG), and Automatic SpeechRecognition (ASR) to capture and process both text and voice inputs in realtime or from recorded audio, generating structured and contextually accuratemedical notes. The framework also incorporates advanced techniques likeQuantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning(PEFT) for efficient model fine-tuning in resource-constrained environments.Additionally, MediNotes offers a query-based retrieval system, allowinghealthcare providers and patients to access relevant medical informationquickly and accurately. Evaluations using the ACI-BENCH dataset demonstratethat MediNotes significantly improves the accuracy, efficiency, and usabilityof automated medical documentation, offering a robust solution to reduce theadministrative burden on healthcare professionals while improving the qualityof clinical workflows.</description><author>Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz</author><pubDate>Wed, 24 Sep 2025 17:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01841v2</guid></item><item><title>Interdisciplinary Research in Conversation: A Case Study in Computational Morphology for Language Documentation</title><link>http://arxiv.org/abs/2509.10644v2</link><description>Computational morphology has the potential to support language documentationthrough tasks like morphological segmentation and the generation of InterlinearGlossed Text (IGT). However, our research outputs have seen limited use inreal-world language documentation settings. This position paper situates thedisconnect between computational morphology and language documentation within abroader misalignment between research and practice in NLP and argues that thefield risks becoming decontextualized and ineffectual without systematicintegration of User-Centered Design (UCD). To demonstrate how principles fromUCD can reshape the research agenda, we present a case study of GlossLM, astate-of-the-art multilingual IGT generation model. Through a small-scale userstudy with three documentary linguists, we find that despite strong metricbased performance, the system fails to meet core usability needs in realdocumentation contexts. These insights raise new research questions aroundmodel constraints, label standardization, segmentation, and personalization. Weargue that centering users not only produces more effective tools, but surfacesricher, more relevant research directions</description><author>Enora Rice, Katharina von der Wense, Alexis Palmer</author><pubDate>Wed, 24 Sep 2025 16:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.10644v2</guid></item><item><title>Efficient Fine-Tuning of Large Language Models for Automated Medical Documentation</title><link>http://arxiv.org/abs/2409.09324v3</link><description>Scientific research indicates that for every hour spent in direct patientcare, physicians spend nearly two additional hours on administrative tasks,particularly on electronic health records (EHRs) and desk work. This excessiveadministrative burden not only reduces the time available for patient care butalso contributes to physician burnout and inefficiencies in healthcaredelivery. To address these challenges, this study introduces MediGen, afine-tuned large language model (LLM) designed to automate the generation ofmedical reports from medical dialogues. By leveraging state-of-the-artmethodologies for fine-tuning open-source pretrained models, includingLLaMA3-8B, MediGen achieves high accuracy in transcribing and summarizingclinical interactions. The fine-tuned LLaMA3-8B model demonstrated promisingresults, achieving a ROUGE score of 58% and a BERTScore-F1 of 72%, indicatingits effectiveness in generating accurate and clinically relevant medicalreports. These findings suggest that MediGen has the potential to significantlyreduce the administrative workload on physicians, improving both healthcareefficiency and physician well-being.</description><author>Hui Yi Leong, Yi Fan Gao, Ji Shuai, Yang Zhang, Uktu Pamuksuz</author><pubDate>Wed, 24 Sep 2025 16:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09324v3</guid></item><item><title>UNComp: Can Matrix Entropy Uncover Sparsity? -- A Compressor Design from an Uncertainty-Aware Perspective</title><link>http://arxiv.org/abs/2410.03090v2</link><description>Deploying large language models (LLMs) for long-context inference remainschallenging due to their substantial memory and computational demands. Whiletechniques such as Key-Value (KV) cache compression are designed to reducememory usage, they often neglect the structured sparsity inherent in therelationship between hidden states and their corresponding KV cache. In thiswork, we explore the role of uncertainty as a potential indicator of sparsitywithin LLMs. We propose UNComp, an uncertainty-aware framework that leveragestruncated matrix entropy to identify areas of low information content, therebyrevealing sparsity patterns that can be used for adaptive compression. Unliketraditional methods that apply uniform compression, UNComp dynamically adjustsits approach to compression, guided by uncertainty measures that reflect theimportance of various model components. Our analysis shows that sparsitypatterns, when derived from uncertainty estimates, can be exploited to revealspecial long-range dependencies, such as retrieval heads and retrieval layers.This perspective not only enhances our understanding of how compression can beoptimized but also provides new insights into the inherent sparsity of LLMsduring long-context inference. By focusing on uncertainty to analyze thesparsity pattern in detail, UNComp reduces the KV cache size to 4.74% of theoriginal, achieves a 6% prefill speedup, and improves throughput by 6.4x - notonly delivering strong lossless compression performance, but also validatingthe effectiveness of the underlying theoretical tool. We release the code athttps://github.com/menik1126/UNComp.</description><author>Jing Xiong, Jianghan Shen, Fanghua Ye, Chaofan Tao, Zhongwei Wan, Jianqiao Lu, Xun Wu, Chuanyang Zheng, Zhijiang Guo, Min Yang, Lingpeng Kong, Ngai Wong</author><pubDate>Wed, 24 Sep 2025 16:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03090v2</guid></item><item><title>Multilingual Hope Speech Detection: A Comparative Study of Logistic Regression, mBERT, and XLM-RoBERTa with Active Learning</title><link>http://arxiv.org/abs/2509.20315v1</link><description>Hope speech language that fosters encouragement and optimism plays a vitalrole in promoting positive discourse online. However, its detection remainschallenging, especially in multilingual and low-resource settings. This paperpresents a multilingual framework for hope speech detection using an activelearning approach and transformer-based models, including mBERT andXLM-RoBERTa. Experiments were conducted on datasets in English, Spanish,German, and Urdu, including benchmark test sets from recent shared tasks. Ourresults show that transformer models significantly outperform traditionalbaselines, with XLM-RoBERTa achieving the highest overall accuracy.Furthermore, our active learning strategy maintained strong performance evenwith small annotated datasets. This study highlights the effectiveness ofcombining multilingual transformers with data-efficient training strategies forhope speech detection.</description><author>T. O. Abiola, K. D. Abiodun, O. E. Olumide, O. O. Adebanji, O. Hiram Calvo, Grigori Sidorov</author><pubDate>Wed, 24 Sep 2025 16:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20315v1</guid></item><item><title>White-Basilisk: A Hybrid Model for Code Vulnerability Detection</title><link>http://arxiv.org/abs/2507.08540v3</link><description>The proliferation of software vulnerabilities presents a significantchallenge to cybersecurity, necessitating more effective detectionmethodologies. We introduce White-Basilisk, a novel approach to vulnerabilitydetection that demonstrates superior performance while challenging prevailingassumptions in AI model scaling. Utilizing an innovative architecture thatintegrates Mamba layers, linear self-attention, and a Mixture of Expertsframework, White-Basilisk achieves state-of-the-art results in vulnerabilitydetection tasks with a parameter count of only 200M. The model's capacity toprocess sequences of unprecedented length enables comprehensive analysis ofextensive codebases in a single pass, surpassing the context limitations ofcurrent Large Language Models (LLMs). White-Basilisk exhibits robustperformance on imbalanced, real-world datasets, while maintaining computationalefficiency that facilitates deployment across diverse organizational scales.This research not only establishes new benchmarks in code security but alsoprovides empirical evidence that compact, efficiently designed models canoutperform larger counterparts in specialized tasks, potentially redefiningoptimization strategies in AI development for domain-specific applications.</description><author>Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris Ioannidis</author><pubDate>Wed, 24 Sep 2025 16:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.08540v3</guid></item><item><title>Advancing Expert Specialization for Better MoE</title><link>http://arxiv.org/abs/2505.22323v2</link><description>Mixture-of-Experts (MoE) models enable efficient scaling of large languagemodels (LLMs) by activating only a subset of experts per input. However, weobserve that the commonly used auxiliary load balancing loss often leads toexpert overlap and overly uniform routing, which hinders expert specializationand degrades overall performance during post-training. To address this, wepropose a simple yet effective solution that introduces two complementaryobjectives: (1) an orthogonality loss to encourage experts to process distincttypes of tokens, and (2) a variance loss to encourage more discriminativerouting decisions. Gradient-level analysis demonstrates that these objectivesare compatible with the existing auxiliary loss and contribute to optimizingthe training process. Experimental results over various model architectures andacross multiple benchmarks show that our method significantly enhances expertspecialization. Notably, our method improves classic MoE baselines withauxiliary loss by up to 23.79%, while also maintaining load balancing indownstream tasks, without any architectural modifications or additionalcomponents. We will release our code to contribute to the community.</description><author>Hongcan Guo, Haolang Lu, Guoshun Nan, Bolun Chu, Jialin Zhuang, Yuan Yang, Wenhao Che, Sicong Leng, Qimei Cui, Xudong Jiang</author><pubDate>Wed, 24 Sep 2025 16:48:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.22323v2</guid></item><item><title>Graph Variate Neural Networks</title><link>http://arxiv.org/abs/2509.20311v1</link><description>Modelling dynamically evolving spatio-temporal signals is a prominentchallenge in the Graph Neural Network (GNN) literature. Notably, GNNs assume anexisting underlying graph structure. While this underlying structure may notalways exist or is derived independently from the signal, a temporally evolvingfunctional network can always be constructed from multi-channel data. GraphVariate Signal Analysis (GVSA) defines a unified framework consisting of anetwork tensor of instantaneous connectivity profiles against a stable supportusually constructed from the signal itself. Building on GVSA and tools fromgraph signal processing, we introduce Graph-Variate Neural Networks (GVNNs):layers that convolve spatio-temporal signals with a signal-dependentconnectivity tensor combining a stable long-term support with instantaneous,data-driven interactions. This design captures dynamic statisticalinterdependencies at each time step without ad hoc sliding windows and admitsan efficient implementation with linear complexity in sequence length. Acrossforecasting benchmarks, GVNNs consistently outperform strong graph-basedbaselines and are competitive with widely used sequence models such as LSTMsand Transformers. On EEG motor-imagery classification, GVNNs achieve strongaccuracy highlighting their potential for brain-computer interfaceapplications.</description><author>Om Roy, Yashar Moshfeghi, Keith Smith</author><pubDate>Wed, 24 Sep 2025 16:44:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20311v1</guid></item><item><title>Deep learning for exoplanet detection and characterization by direct imaging at high contrast</title><link>http://arxiv.org/abs/2509.20310v1</link><description>Exoplanet imaging is a major challenge in astrophysics due to the need forhigh angular resolution and high contrast. We present a multi-scale statisticalmodel for the nuisance component corrupting multivariate image series at highcontrast. Integrated into a learnable architecture, it leverages the physics ofthe problem and enables the fusion of multiple observations of the same star ina way that is optimal in terms of detection signal-to-noise ratio. Applied todata from the VLT/SPHERE instrument, the method significantly improves thedetection sensitivity and the accuracy of astrometric and photometricestimation.</description><author>Théo Bodrito, Olivier Flasseur, Julien Mairal, Jean Ponce, Maud Langlois, Anne-Marie Lagrange</author><pubDate>Wed, 24 Sep 2025 16:43:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20310v1</guid></item><item><title>Enhancing RAG Efficiency with Adaptive Context Compression</title><link>http://arxiv.org/abs/2507.22931v3</link><description>Retrieval-augmented generation (RAG) enhances large language models (LLMs)with external knowledge but incurs significant inference costs due to lengthyretrieved contexts. While context compression mitigates this issue, existingmethods apply fixed compression rates, over-compressing simple queries orunder-compressing complex ones. We propose Adaptive Context Compression for RAG(ACC-RAG), a framework that dynamically adjusts compression rates based oninput complexity, optimizing inference efficiency without sacrificing accuracy.ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) witha context selector to retain minimal sufficient information, akin to humanskimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperformsfixed-rate methods and matches/unlocks over 4 times faster inference versusstandard RAG while maintaining or improving accuracy.</description><author>Shuyu Guo, Shuo Zhang, Zhaochun Ren</author><pubDate>Wed, 24 Sep 2025 16:41:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.22931v3</guid></item><item><title>Structure As Search: Unsupervised Permutation Learning for Combinatorial Optimization</title><link>http://arxiv.org/abs/2507.04164v3</link><description>We propose a non-autoregressive framework for the Travelling Salesman Problemwhere solutions emerge directly from learned permutations, without requiringexplicit search. By applying a similarity transformation to Hamiltonian cycles,the model learns to approximate permutation matrices via continuousrelaxations. Our unsupervised approach achieves competitive performance againstclassical heuristics, demonstrating that the inherent structure of the problemcan effectively guide combinatorial optimization without sequentialdecision-making. Our method offers concrete evidence that neural networks candirectly capture and exploit combinatorial structure.</description><author>Yimeng Min, Carla P. Gomes</author><pubDate>Wed, 24 Sep 2025 16:36:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.04164v3</guid></item><item><title>Ads that Stick: Near-Optimal Ad Optimization through Psychological Behavior Models</title><link>http://arxiv.org/abs/2509.20304v1</link><description>Optimizing the timing and frequency of ads is a central problem in digitaladvertising, with significant economic consequences. Existing schedulingpolicies rely on simple heuristics, such as uniform spacing and frequency caps,that overlook long-term user interest. However, it is well-known that users'long-term interest and engagement result from the interplay of severalpsychological effects (Curmei, Haupt, Recht, Hadfield-Menell, ACM CRS, 2022). In this work, we model change in user interest upon showing ads based onthree key psychological principles: mere exposure, hedonic adaptation, andoperant conditioning. The first two effects are modeled using a concavefunction of user interest with repeated exposure, while the third effect ismodeled using a temporal decay function, which explains the decline in userinterest due to overexposure. Under our psychological behavior model, we askthe following question: Given a continuous time interval $T$, how many adsshould be shown, and at what times, to maximize the user interest towards theads? Towards answering this question, we first show that, if the number ofdisplayed ads is fixed, then the optimal ad-schedule only depends on theoperant conditioning function. Our main result is a quasi-linear time algorithmthat outputs a near-optimal ad-schedule, i.e., the difference in theperformance of our schedule and the optimal schedule is exponentially small.Our algorithm leads to significant insights about optimal ad placement andshows that simple heuristics such as uniform spacing are sub-optimal under manynatural settings. The optimal number of ads to display, which also depends onthe mere exposure and hedonistic adaptation functions, can be found through asimple linear search given the above algorithm. We further support our findingswith experimental results, demonstrating that our strategy outperforms variousbaselines.</description><author>Kailash Gopal Darmasubramanian, Akash Pareek, Arindam Khan, Arpit Agarwal</author><pubDate>Wed, 24 Sep 2025 16:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20304v1</guid></item><item><title>The 2020 United States Decennial Census Is More Private Than You (Might) Think</title><link>http://arxiv.org/abs/2410.09296v3</link><description>The U.S. Decennial Census serves as the foundation for many high-profilepolicy decision-making processes, including federal funding allocation andredistricting. In 2020, the Census Bureau adopted differential privacy toprotect the confidentiality of individual responses through a disclosureavoidance system that injects noise into census data tabulations. The Bureausubsequently posed an open question: Could stronger privacy guarantees beobtained for the 2020 U.S. Census compared to their published guarantees, orequivalently, had the privacy budgets been fully utilized? In this paper, we address this question affirmatively by demonstrating thatthe 2020 U.S. Census provides significantly stronger privacy protections thanits nominal guarantees suggest at each of the eight geographical levels, fromthe national level down to the block level. This finding is enabled by ourprecise tracking of privacy losses using $f$-differential privacy, applied tothe composition of private queries across these geographical levels. Ouranalysis reveals that the Census Bureau introduced unnecessarily high levels ofnoise to meet the specified privacy guarantees for the 2020 Census.Consequently, we show that noise variances could be reduced by $15.08\%$ to$24.82\%$ while maintaining nearly the same level of privacy protection foreach geographical level, thereby improving the accuracy of privatized censusstatistics. We empirically demonstrate that reducing noise injection intocensus statistics mitigates distortion caused by privacy constraints indownstream applications of private census data, illustrated through a studyexamining the relationship between earnings and education.</description><author>Buxin Su, Weijie J. Su, Chendi Wang</author><pubDate>Wed, 24 Sep 2025 16:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09296v3</guid></item><item><title>FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory for Segmentation-oriented Anomaly Synthesis</title><link>http://arxiv.org/abs/2509.20295v1</link><description>Industrial anomaly segmentation relies heavily on pixel-level annotations,yet real-world anomalies are often scarce, diverse, and costly to label.Segmentation-oriented industrial anomaly synthesis (SIAS) has emerged as apromising alternative; however, existing methods struggle to balance samplingefficiency and generation quality. Moreover, most approaches treat all spatialregions uniformly, overlooking the distinct statistical differences betweenanomaly and background areas. This uniform treatment hinders the synthesis ofcontrollable, structure-specific anomalies tailored for segmentation tasks. Inthis paper, we propose FAST, a foreground-aware diffusion framework featuringtwo novel modules: the Anomaly-Informed Accelerated Sampling (AIAS) and theForeground-Aware Reconstruction Module (FARM). AIAS is a training-free samplingalgorithm specifically designed for segmentation-oriented industrial anomalysynthesis, which accelerates the reverse process through coarse-to-fineaggregation and enables the synthesis of state-of-the-art segmentation-orientedanomalies in as few as 10 steps. Meanwhile, FARM adaptively adjusts theanomaly-aware noise within the masked foreground regions at each sampling step,preserving localized anomaly signals throughout the denoising trajectory.Extensive experiments on multiple industrial benchmarks demonstrate that FASTconsistently outperforms existing anomaly synthesis methods in downstreamsegmentation tasks. We release the code at:https://anonymous.4open.science/r/NeurIPS-938.</description><author>Xichen Xu, Yanshu Wang, Jinbao Wang, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu</author><pubDate>Wed, 24 Sep 2025 16:28:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20295v1</guid></item><item><title>Alignment-Sensitive Minimax Rates for Spectral Algorithms with Learned Kernels</title><link>http://arxiv.org/abs/2509.20294v1</link><description>We study spectral algorithms in the setting where kernels are learned fromdata. We introduce the effective span dimension (ESD), an alignment-sensitivecomplexity measure that depends jointly on the signal, spectrum, and noiselevel $\sigma^2$. The ESD is well-defined for arbitrary kernels and signalswithout requiring eigen-decay conditions or source conditions. We prove thatfor sequence models whose ESD is at most $K$, the minimax excess risk scales as$\sigma^2 K$. Furthermore, we analyze over-parameterized gradient flow andprove that it can reduce the ESD. This finding establishes a connection betweenadaptive feature learning and provable improvements in generalization ofspectral algorithms. We demonstrate the generality of the ESD framework byextending it to linear models and RKHS regression, and we support the theorywith numerical experiments. This framework provides a novel perspective ongeneralization beyond traditional fixed-kernel theories.</description><author>Dongming Huang, Zhifan Li, Yicheng Li, Qian Lin</author><pubDate>Wed, 24 Sep 2025 16:28:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20294v1</guid></item><item><title>When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity</title><link>http://arxiv.org/abs/2509.20293v1</link><description>LLM-judged benchmarks are increasingly used to evaluate complex modelbehaviors, yet their design introduces failure modes absent in conventionalground-truth based benchmarks. We argue that without tight objectives andverifiable constructions, benchmark rankings can produce high-confidencerankings that are in fact largely noise. We introduce two mechanisms todiagnose these issues. Schematic adherence quantifies how much of a judge'soverall verdict is explained by the explicit evaluation schema, revealingunexplained variance when judges deviate from their own rubric. Psychometricvalidity aggregates internal consistency and discriminant validity signals toquantify irreducible uncertainty in any benchmarking run. Applying these toolsto Arena-Hard Auto, we find severe schema incoherence and factor collapseacross popular judges: for example, unexplained variance exceeding 90 percentfor DeepSeek-R1-32B and factor correlations above 0.93 for most criteria. Wealso show that the ELO-style aggregation used by Arena-Hard Auto collapses andmasks genuine ranking uncertainty. Our results highlight design failures thatundermine validity and offer actionable principles for building better-scoped,reliability-aware LLM-judged benchmarks. We release our code athttps://anonymous.4open.science/r/judgment-to-noise-947D/README.md</description><author>Benjamin Feuer, Chiung-Yi Tseng, Astitwa Sarthak Lathe, Oussama Elachqar, John P Dickerson</author><pubDate>Wed, 24 Sep 2025 16:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20293v1</guid></item><item><title>Beyond the Pre-Service Horizon: Infusing In-Service Behavior for Improved Financial Risk Forecasting</title><link>http://arxiv.org/abs/2509.06385v3</link><description>Typical financial risk management involves distinct phases for pre-servicerisk assessment and in-service default detection, often modeled separately.This paper proposes a novel framework, Multi-Granularity Knowledge Distillation(abbreviated as MGKD), aimed at improving pre-service risk prediction throughthe integration of in-service user behavior data. MGKD follows the idea ofknowledge distillation, where the teacher model, trained on historicalin-service data, guides the student model, which is trained on pre-servicedata. By using soft labels derived from in-service data, the teacher modelhelps the student model improve its risk prediction prior to serviceactivation. Meanwhile, a multi-granularity distillation strategy is introduced,including coarse-grained, fine-grained, and self-distillation, to align therepresentations and predictions of the teacher and student models. Thisapproach not only reinforces the representation of default cases but alsoenables the transfer of key behavioral patterns associated with defaulters fromthe teacher to the student model, thereby improving the overall performance ofpre-service risk assessment. Moreover, we adopt a re-weighting strategy tomitigate the model's bias towards the minority class. Experimental results onlarge-scale real-world datasets from Tencent Mobile Payment demonstrate theeffectiveness of our proposed approach in both offline and online scenarios.</description><author>Senhao Liu, Zhiyu Guo, Zhiyuan Ji, Yueguo Chen, Yateng Tang, Yunhai Wang, Xuehao Zheng, Xiang Ao</author><pubDate>Wed, 24 Sep 2025 16:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.06385v3</guid></item><item><title>PGCLODA: Prompt-Guided Graph Contrastive Learning for Oligopeptide-Infectious Disease Association Prediction</title><link>http://arxiv.org/abs/2509.20290v1</link><description>Infectious diseases continue to pose a serious threat to public health,underscoring the urgent need for effective computational approaches to screennovel anti-infective agents. Oligopeptides have emerged as promising candidatesin antimicrobial research due to their structural simplicity, highbioavailability, and low susceptibility to resistance. Despite their potential,computational models specifically designed to predict associations betweenoligopeptides and infectious diseases remain scarce. This study introduces aprompt-guided graph-based contrastive learning framework (PGCLODA) to uncoverpotential associations. A tripartite graph is constructed with oligopeptides,microbes, and diseases as nodes, incorporating both structural and semanticinformation. To preserve critical regions during contrastive learning, aprompt-guided graph augmentation strategy is employed to generate meaningfulpaired views. A dual encoder architecture, integrating Graph ConvolutionalNetwork (GCN) and Transformer, is used to jointly capture local and globalfeatures. The fused embeddings are subsequently input into a multilayerperceptron (MLP) classifier for final prediction. Experimental results on abenchmark dataset indicate that PGCLODA consistently outperformsstate-of-the-art models in AUROC, AUPRC, and accuracy. Ablation andhyperparameter studies confirm the contribution of each module. Case studiesfurther validate the generalization ability of PGCLODA and its potential touncover novel, biologically relevant associations. These findings offervaluable insights for mechanism-driven discovery and oligopeptide-based drugdevelopment. The source code of PGCLODA is available online athttps://github.com/jjnlcode/PGCLODA.</description><author>Dayu Tan, Jing Chen, Xiaoping Zhou, Yansen Su, Chunhou Zheng</author><pubDate>Wed, 24 Sep 2025 16:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20290v1</guid></item><item><title>Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation</title><link>http://arxiv.org/abs/2509.20287v1</link><description>We investigate the tradeoff between adequacy and fluency in machinetranslation. We show the severity of this tradeoff at the evaluation level andanalyze where popular metrics fall within it. Essentially, current metricsgenerally lean toward adequacy, meaning that their scores correlate morestrongly with the adequacy of translations than with fluency. More importantly,we find that this tradeoff also persists at the meta-evaluation level, and thatthe standard WMT meta-evaluation favors adequacy-oriented metrics overfluency-oriented ones. We show that this bias is partially attributed to thecomposition of the systems included in the meta-evaluation datasets. To controlthis bias, we propose a method that synthesizes translation systems inmeta-evaluation. Our findings highlight the importance of understanding thistradeoff in meta-evaluation and its impact on metric rankings.</description><author>Behzad Shayegh, Jan-Thorsten Peter, David Vilar, Tobias Domhan, Juraj Juraska, Markus Freitag, Lili Mou</author><pubDate>Wed, 24 Sep 2025 16:21:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20287v1</guid></item><item><title>Biologically Plausible Learning via Bidirectional Spike-Based Distillation</title><link>http://arxiv.org/abs/2509.20284v1</link><description>Developing biologically plausible learning algorithms that can achieveperformance comparable to error backpropagation remains a longstandingchallenge. Existing approaches often compromise biological plausibility byentirely avoiding the use of spikes for error propagation or relying on bothpositive and negative learning signals, while the question of how spikes canrepresent negative values remains unresolved. To address these limitations, weintroduce Bidirectional Spike-based Distillation (BSD), a novel learningalgorithm that jointly trains a feedforward and a backward spiking network. Weformulate learning as a transformation between two spiking representations(i.e., stimulus encoding and concept encoding) so that the feedforward networkimplements perception and decision-making by mapping stimuli to actions, whilethe backward network supports memory recall by reconstructing stimuli fromconcept representations. Extensive experiments on diverse benchmarks, includingimage recognition, image generation, and sequential regression, show that BSDachieves performance comparable to networks trained with classical errorbackpropagation. These findings represent a significant step towardbiologically grounded, spike-driven learning in neural networks.</description><author>Changze Lv, Yifei Wang, Yanxun Zhang, Yiyang Lu, Jingwen Xu, Di Yu, Xin Du, Xuanjing Huang, Xiaoqing Zheng</author><pubDate>Wed, 24 Sep 2025 16:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20284v1</guid></item><item><title>PerFace: Metric Learning in Perceptual Facial Similarity for Enhanced Face Anonymization</title><link>http://arxiv.org/abs/2509.20281v1</link><description>In response to rising societal awareness of privacy concerns, faceanonymization techniques have advanced, including the emergence offace-swapping methods that replace one identity with another. Achieving abalance between anonymity and naturalness in face swapping requires carefulselection of identities: overly similar faces compromise anonymity, whiledissimilar ones reduce naturalness. Existing models, however, focus on binaryidentity classification "the same person or not", making it difficult tomeasure nuanced similarities such as "completely different" versus "highlysimilar but different." This paper proposes a human-perception-based facesimilarity metric, creating a dataset of 6,400 triplet annotations and metriclearning to predict the similarity. Experimental results demonstratesignificant improvements in both face similarity prediction and attribute-basedface classification tasks over existing methods.</description><author>Haruka Kumagai, Leslie Wöhler, Satoshi Ikehata, Kiyoharu Aizawa</author><pubDate>Wed, 24 Sep 2025 16:15:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20281v1</guid></item><item><title>HiPerformer: A High-Performance Global-Local Segmentation Model with Modular Hierarchical Fusion Strategy</title><link>http://arxiv.org/abs/2509.20280v1</link><description>Both local details and global context are crucial in medical imagesegmentation, and effectively integrating them is essential for achieving highaccuracy. However, existing mainstream methods based on CNN-Transformer hybridarchitectures typically employ simple feature fusion techniques such as serialstacking, endpoint concatenation, or pointwise addition, which struggle toaddress the inconsistencies between features and are prone to informationconflict and loss. To address the aforementioned challenges, we innovativelypropose HiPerformer. The encoder of HiPerformer employs a novel modularhierarchical architecture that dynamically fuses multi-source features inparallel, enabling layer-wise deep integration of heterogeneous information.The modular hierarchical design not only retains the independent modelingcapability of each branch in the encoder, but also ensures sufficientinformation transfer between layers, effectively avoiding the degradation offeatures and information loss that come with traditional stacking methods.Furthermore, we design a Local-Global Feature Fusion (LGFF) module to achieveprecise and efficient integration of local details and global semanticinformation, effectively alleviating the feature inconsistency problem andresulting in a more comprehensive feature representation. To further enhancemulti-scale feature representation capabilities and suppress noiseinterference, we also propose a Progressive Pyramid Aggregation (PPA) module toreplace traditional skip connections. Experiments on eleven public datasetsdemonstrate that the proposed method outperforms existing segmentationtechniques, demonstrating higher segmentation accuracy and robustness. The codeis available at https://github.com/xzphappy/HiPerformer.</description><author>Dayu Tan, Zhenpeng Xu, Yansen Su, Xin Peng, Chunhou Zheng, Weimin Zhong</author><pubDate>Wed, 24 Sep 2025 16:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20280v1</guid></item><item><title>A co-evolving agentic AI system for medical imaging analysis</title><link>http://arxiv.org/abs/2509.20279v1</link><description>Agentic AI is rapidly advancing in healthcare and biomedical research.However, in medical image analysis, their performance and adoption remainlimited due to the lack of a robust ecosystem, insufficient toolsets, and theabsence of real-time interactive expert feedback. Here we present "TissueLab",a co-evolving agentic AI system that allows researchers to ask directquestions, automatically plan and generate explainable workflows, and conductreal-time analyses where experts can visualize intermediate results and refinethem. TissueLab integrates tool factories across pathology, radiology, andspatial omics domains. By standardizing inputs, outputs, and capabilities ofdiverse tools, the system determines when and how to invoke them to addressresearch and clinical questions. Across diverse tasks with clinicallymeaningful quantifications that inform staging, prognosis, and treatmentplanning, TissueLab achieves state-of-the-art performance compared withend-to-end vision-language models (VLMs) and other agentic AI systems such asGPT-5. Moreover, TissueLab continuously learns from clinicians, evolving towardimproved classifiers and more effective decision strategies. With activelearning, it delivers accurate results in unseen disease contexts withinminutes, without requiring massive datasets or prolonged retraining. Releasedas a sustainable open-source ecosystem, TissueLab aims to acceleratecomputational research and translational adoption in medical imaging whileestablishing a foundation for the next generation of medical AI.</description><author>Songhao Li, Jonathan Xu, Tiancheng Bao, Yuxuan Liu, Yuchen Liu, Yihang Liu, Lilin Wang, Wenhui Lei, Sheng Wang, Yinuo Xu, Yan Cui, Jialu Yao, Shunsuke Koga, Zhi Huang</author><pubDate>Wed, 24 Sep 2025 16:15:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20279v1</guid></item><item><title>Instruction Boundary: Quantifying Biases in LLM Reasoning under Various Coverage</title><link>http://arxiv.org/abs/2509.20278v1</link><description>Large-language-model (LLM) reasoning has long been regarded as a powerfultool for problem solving across domains, providing non-experts with valuableadvice. However, their limitations - especially those stemming from promptdesign - remain underexplored. Because users may supply biased or incompleteprompts - often unintentionally - LLMs can be misled, undermining reliabilityand creating risks. We refer to this vulnerability as the Instruction Boundary.To investigate the phenomenon, we distill it into eight concrete facets andintroduce BiasDetector, a framework that measures biases arising from threeinstruction types: complete, redundant, and insufficient. We evaluate severalmainstream LLMs and find that, despite high headline accuracy, substantialbiases persist in many downstream tasks as a direct consequence of promptcoverage. Our empirical study confirms that LLM reasoning reliability can stillbe significantly improved. We analyze the practical impact of these biases andoutline mitigation strategies. Our findings underscore the need for developersto tackle biases and for users to craft options carefully.</description><author>Zipeng Ling, Yuehao Tang, Chen Huang, Shuliang Liu, Gaoyang Jiang, Shenghong Fu, Junqi Yang, Yao Wan, Jiawan Zhang, Kejia Huang, Xuming Hu</author><pubDate>Wed, 24 Sep 2025 16:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20278v1</guid></item><item><title>Investigating Security Implications of Automatically Generated Code on the Software Supply Chain</title><link>http://arxiv.org/abs/2509.20277v1</link><description>In recent years, various software supply chain (SSC) attacks have posedsignificant risks to the global community. Severe consequences may arise ifdevelopers integrate insecure code snippets that are vulnerable to SSC attacksinto their products. Particularly, code generation techniques, such as largelanguage models (LLMs), have been widely utilized in the developer community.However, LLMs are known to suffer from inherent issues when generating code,including fabrication, misinformation, and reliance on outdated training data,all of which can result in serious software supply chain threats. In thispaper, we investigate the security threats to the SSC that arise from theseinherent issues. We examine three categories of threats, including elevenpotential SSC-related threats, related to external components in source code,and continuous integration configuration files. We find some threats inLLM-generated code could enable attackers to hijack software and workflows,while some others might cause potential hidden threats that compromise thesecurity of the software over time. To understand these security impacts andseverity, we design a tool, SSCGuard, to generate 439,138 prompts based onSSC-related questions collected online, and analyze the responses of fourpopular LLMs from GPT and Llama. Our results show that all identifiedSSC-related threats persistently exist. To mitigate these risks, we propose anovel prompt-based defense mechanism, namely Chain-of-Confirmation, to reducefabrication, and a middleware-based defense that informs users of various SSCthreats.</description><author>Xiaofan Li, Xing Gao</author><pubDate>Wed, 24 Sep 2025 16:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20277v1</guid></item><item><title>Deciphering Functions of Neurons in Vision-Language Models</title><link>http://arxiv.org/abs/2502.18485v4</link><description>The burgeoning growth of open-sourced vision-language models (VLMs) hascatalyzed a plethora of applications across diverse domains. Ensuring thetransparency and interpretability of these models is critical for fosteringtrustworthy and responsible AI systems. In this study, our objective is todelve into the internals of VLMs to interpret the functions of individualneurons. We observe the activations of neurons with respects to the inputvisual tokens and text tokens, and reveal some interesting findings.Particularly, we found that there are neurons responsible for only visual ortext information, or both, respectively, which we refer to them as visualneurons, text neurons, and multi-modal neurons, respectively. We build aframework that automates the explanation of neurons with the assistant ofGPT-4o. Meanwhile, for visual neurons, we propose an activation simulator toassess the reliability of the explanations for visual neurons. Systemstatistical analyses on top of one representative VLM of LLaVA, uncover thebehaviors/characteristics of different categories of neurons.</description><author>Jiaqi Xu, Cuiling Lan, Yan Lu</author><pubDate>Wed, 24 Sep 2025 16:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.18485v4</guid></item><item><title>Extended Low-Rank Approximation Accelerates Learning of Elastic Response in Heterogeneous Materials</title><link>http://arxiv.org/abs/2509.20276v1</link><description>Predicting how the microstructure governs the mechanical response ofheterogeneous materials is essential for optimizing design and performance. Yetthis task remains difficult due to the complex, high dimensional nature ofmicrostructural features. Relying on physics based simulations to probe themicrostructural space is computationally prohibitive. This motivates thedevelopment of computational tools to efficiently learn structure propertylinkages governing mechanical behavior. While contemporary data drivenapproaches offer new possibilities, they often require large datasets. Toaddress this challenge, this work presents the Extended Low Rank Approximation(xLRA), a framework that employs canonical polyadic tensor decomposition. Itefficiently maps high dimensional microstructural information to the localelastic response by adaptively incorporating higher rank terms. xLRA accuratelypredicts the local elastic strain fields in porous microstructures, requiring amaximum rank of only 4. The compact formulation of xLRA achieves accuratepredictions when trained on just 5% of the dataset, demonstrating significantdata efficiency. Moreover, xLRA proves transferability by delivering resultsacross representative material systems, including two phase composites andsingle and dual phase polycrystals. Despite being compact, xLRA retainsessential microstructural details, enabling accurate predictions on unseenmicrostructures. Benchmarking shows that xLRA outperforms contemporary methodsin predictive accuracy, generalizability, and computational efficiency, whilerequiring 6 orders of magnitude fewer floating point operations. In summary,xLRA provides an efficient framework for predicting the elastic response frommicrostructures, enabling scalable mapping of structure property linkages.</description><author>Prabhat Karmakar, Sayan Gupta, Ilaksh Adlakha</author><pubDate>Wed, 24 Sep 2025 16:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20276v1</guid></item><item><title>Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader</title><link>http://arxiv.org/abs/2509.03148v2</link><description>The Romansh language, spoken in Switzerland, has limited resources formachine translation evaluation. In this paper, we present a benchmark for sixvarieties of Romansh: Rumantsch Grischun, a supra-regional variety, and fiveregional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Ourreference translations were created by human translators based on the WMT24++benchmark, which ensures parallelism with more than 55 other languages. Anautomatic evaluation of existing MT systems and LLMs shows that translation outof Romansh into German is handled relatively well for all the varieties, buttranslation into Romansh is still challenging.</description><author>Jannis Vamvas, Ignacio Pérez Prat, Not Battesta Soliva, Sandra Baltermia-Guetg, Andrina Beeli, Simona Beeli, Madlaina Capeder, Laura Decurtins, Gian Peder Gregori, Flavia Hobi, Gabriela Holderegger, Arina Lazzarini, Viviana Lazzarini, Walter Rosselli, Bettina Vital, Anna Rutkiewicz, Rico Sennrich</author><pubDate>Wed, 24 Sep 2025 16:07:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.03148v2</guid></item><item><title>A Versatile Foundation Model for AI-enabled Mammogram Interpretation</title><link>http://arxiv.org/abs/2509.20271v1</link><description>Breast cancer is the most commonly diagnosed cancer and the leading cause ofcancer-related mortality in women globally. Mammography is essential for theearly detection and diagnosis of breast lesions. Despite recent progress infoundation models (FMs) for mammogram analysis, their clinical translationremains constrained by several fundamental limitations, including insufficientdiversity in training data, limited model generalizability, and a lack ofcomprehensive evaluation across clinically relevant tasks. Here, we introduceVersaMammo, a versatile foundation model for mammograms, designed to overcomethese limitations. We curated the largest multi-institutional mammogram datasetto date, comprising 706,239 images from 21 sources. To improve generalization,we propose a two-stage pre-training strategy to develop VersaMammo, a mammogramfoundation model. First, a teacher model is trained via self-supervisedlearning to extract transferable features from unlabeled mammograms. Then,supervised learning combined with knowledge distillation transfers bothfeatures and clinical knowledge into VersaMammo. To ensure a comprehensiveevaluation, we established a benchmark comprising 92 specific tasks, including68 internal tasks and 24 external validation tasks, spanning 5 major clinicaltask categories: lesion detection, segmentation, classification, imageretrieval, and visual question answering. VersaMammo achieves state-of-the-artperformance, ranking first in 50 out of 68 specific internal tasks and 20 outof 24 external validation tasks, with average ranks of 1.5 and 1.2,respectively. These results demonstrate its superior generalization andclinical utility, offering a substantial advancement toward reliable andscalable breast cancer screening and diagnosis.</description><author>Fuxiang Huang, Jiayi Zhu, Yunfang Yu, Yu Xie, Yuan Guo, Qingcong Kong, Mingxiang Wu, Xinrui Jiang, Shu Yang, Jiabo Ma, Ziyi Liu, Zhe Xu, Zhixuan Chen, Yujie Tan, Zifan He, Luhui Mao, Xi Wang, Junlin Hou, Lei Zhang, Qiong Luo, Zhenhui Li, Herui Yao, Hao Chen</author><pubDate>Wed, 24 Sep 2025 16:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20271v1</guid></item><item><title>Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent</title><link>http://arxiv.org/abs/2509.20270v1</link><description>Managing scan protocols in Computed Tomography (CT), which includes adjustingacquisition parameters or configuring reconstructions, as well as selectingpostprocessing tools in a patient-specific manner, is time-consuming andrequires clinical as well as technical expertise. At the same time, we observean increasing shortage of skilled workforce in radiology. To address thisissue, a Large Language Model (LLM)-based agent framework is proposed to assistwith the interpretation and execution of protocol configuration requests givenin natural language or a structured, device-independent format, aiming toimprove the workflow efficiency and reduce technologists' workload. The agentcombines in-context-learning, instruction-following, and structured toolcallingabilities to identify relevant protocol elements and apply accuratemodifications. In a systematic evaluation, experimental results indicate thatthe agent can effectively retrieve protocol components, generate devicecompatible protocol definition files, and faithfully implement user requests.Despite demonstrating feasibility in principle, the approach faces limitationsregarding syntactic and semantic validity due to lack of a unified device API,and challenges with ambiguous or complex requests. In summary, the findingsshow a clear path towards LLM-based agents for supporting scan protocolmanagement in CT imaging.</description><author>Xingjian Kang, Linda Vorberg, Andreas Maier, Alexander Katzmann, Oliver Taubmann</author><pubDate>Wed, 24 Sep 2025 16:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20270v1</guid></item><item><title>Assay2Mol: large language model-based drug design using BioAssay context</title><link>http://arxiv.org/abs/2507.12574v2</link><description>Scientific databases aggregate vast amounts of quantitative data alongsidedescriptive text. In biochemistry, molecule screening assays evaluate candidatemolecules' functional responses against disease targets. Unstructured text thatdescribes the biological mechanisms through which these targets operate,experimental screening protocols, and other attributes of assays offer richinformation for drug discovery campaigns but has been untapped because of thatunstructured format. We present Assay2Mol, a large language model-basedworkflow that can capitalize on the vast existing biochemical screening assaysfor early-stage drug discovery. Assay2Mol retrieves existing assay recordsinvolving targets similar to the new target and generates candidate moleculesusing in-context learning with the retrieved assay screening data. Assay2Moloutperforms recent machine learning approaches that generate candidate ligandmolecules for target protein structures, while also promoting moresynthesizable molecule generation.</description><author>Yifan Deng, Spencer S. Ericksen, Anthony Gitter</author><pubDate>Wed, 24 Sep 2025 16:03:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.12574v2</guid></item><item><title>Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation</title><link>http://arxiv.org/abs/2509.20269v1</link><description>As deep neural networks are increasingly deployed in dynamic, real-worldenvironments, relying on a single static model is often insufficient. Changesin input data distributions caused by sensor drift or lighting variationsnecessitate continual model adaptation. In this paper, we propose a hybridtraining methodology that enables efficient on-device domain adaptation bycombining the strengths of Backpropagation and Predictive Coding. The methodbegins with a deep neural network trained offline using Backpropagation toachieve high initial performance. Subsequently, Predictive Coding is employedfor online adaptation, allowing the model to recover accuracy lost due toshifts in the input data distribution. This approach leverages the robustnessof Backpropagation for initial representation learning and the computationalefficiency of Predictive Coding for continual learning, making it particularlywell-suited for resource-constrained edge devices or future neuromorphicaccelerators. Experimental results on the MNIST and CIFAR-10 datasetsdemonstrate that this hybrid strategy enables effective adaptation with areduced computational overhead, offering a promising solution for maintainingmodel performance in dynamic environments.</description><author>Matteo Cardoni, Sam Leroux</author><pubDate>Wed, 24 Sep 2025 16:03:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20269v1</guid></item><item><title>Imaging Biomarkers for Neurodegenerative Diseases from Detailed Segmentation of Medial Temporal Lobe Subregions on in vivo Brain MRI Using Upsampling Strategy Guided by High-resolution ex vivo MRI</title><link>http://arxiv.org/abs/2504.18442v2</link><description>The medial temporal lobe (MTL) is a region impacted extensively andnon-uniformly in early stages of Alzheimer's disease (AD). Regional MTLmorphometric measures extracted from magnetic resonance imaging (MRI) aresupportive features for the diagnosis of AD and related disorders (ADRD).Different MRI modalities have distinct advantages for MTL morphometry.Anisotropic T2-weighted (T2w) MRI is preferred for hippocampal subfields due toits higher contrast between hippocampal layers. Isotropic T1-weighted (T1w) MRIis beneficial for thickness calculation of extra-hippocampal subregions due toits stable image quality and isotropic resolution. We propose a multi-modalityMTL segmentation algorithm that bridges the T1w and T2w modalities by bringingboth to a nearly isotropic voxel space. Guided by high-resolution ex vivo 9.4TMRI, an upsampling model was designed for the ground truth segmentations.Combined with non-local means upsampling, this model was used to construct anearly iso-tropic T1w and T2w MTL subregion segmentation training set, whichwas used to train a nnUNet model. Morphometric biomarkers extracted by thismodel were compared to those extracted using conventional models operating inanisotropic spaces on downstream tasks. Biomarkers extracted using the proposedmodel had greater ability to discriminate between individuals with mildcognitive impairment and cognitively unimpaired; and had great-er longitudinalstability. These findings suggest that the biomarkers derived from T1w and T2wMRI unsampled to nearly isotropic resolution have sig-nificant potential forimproving disease diagnosis and monitoring disease progression in ADRD.</description><author>Yue Li, Pulkit Khandelwal, Long Xie, Laura E. M. Wisse, Amanda E. Denning, Christopher A. Brown, Emily McGrew, Sydney A. Lim, Niyousha Sadeghpour, Sadhana Ravikumar, Ranjit Ittyerah, Eunice Chung, Daniel T. Ohm, Nidhi S. Mundada, María Mercedes Íñiguez de Onzoño Martín, María del Mar Arroyo Jiménez, Monica Mũnoz, Maria del Pilar Marcos Rabal, David J. Irwin, Edward B. Lee, Ricardo Insausti, Sandhitsu R. Das, David A. Wolk, Paul A. Yushkevich</author><pubDate>Wed, 24 Sep 2025 15:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.18442v2</guid></item><item><title>To Fold or Not to Fold: Graph Regularized Tensor Train for Visual Data Completion</title><link>http://arxiv.org/abs/2306.11123v2</link><description>Tensor train (TT) representation has achieved tremendous success in visualdata completion tasks, especially when it is combined with tensor folding.However, folding an image or video tensor breaks the original data structure,leading to local information loss as nearby pixels may be assigned intodifferent dimensions and become far away from each other. In this paper, tofully preserve the local information of the original visual data, we explorenot folding the data tensor, and at the same time adopt graph information toregularize local similarity between nearby entries. To overcome the highcomputational complexity introduced by the graph-based regularization in the TTcompletion problem, we propose to break the original problem into multiplesub-problems with respect to each TT core fiber, instead of each TT core as intraditional methods. Furthermore, to avoid heavy parameter tuning, a sparsitypromoting probabilistic model is built based on the generalized inverseGaussian (GIG) prior, and an inference algorithm is derived under themean-field approximation. Experiments on both synthetic data and real-worldvisual data show the superiority of the proposed methods.</description><author>Le Xu, Lei Cheng, Ngai Wong, Yik-Chung Wu</author><pubDate>Wed, 24 Sep 2025 15:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11123v2</guid></item><item><title>Failure Modes of Maximum Entropy RLHF</title><link>http://arxiv.org/abs/2509.20265v1</link><description>In this paper, we show that Simple Preference Optimization (SimPO) can bederived as Maximum Entropy Reinforcement Learning with length-normalizedtemperature, providing a theoretical foundation for this reference-free method.Motivated by SimPO's strong performance in offline preference optimization, weinvestigate whether Maximum Entropy RL can achieve similar results in onlineRLHF settings. Our experiments find that Maximum Entropy RL consistentlyexhibits overoptimization and unstable KL dynamics, even at very low learningrates. Unlike KL-constrained methods that maintain stable training, entropyregularization fails to prevent reward hacking and appears to correlate withoveroptimization. Lastly, we discuss possible explanations for why SimPOsucceeds in offline settings while Maximum Entropy RL struggles in onlinescenarios. Our findings suggest that reference-free approaches may facedistinct challenges when applied to online or offline preference learning.</description><author>Ömer Veysel Çağatan, Barış Akgün</author><pubDate>Wed, 24 Sep 2025 15:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20265v1</guid></item><item><title>Beyond Simple Graphs: Neural Multi-Objective Routing on Multigraphs</title><link>http://arxiv.org/abs/2506.22095v3</link><description>Learning-based methods for routing have gained significant attention inrecent years, both in single-objective and multi-objective contexts. Yet,existing methods are unsuitable for routing on multigraphs, which featuremultiple edges with distinct attributes between node pairs, despite theirstrong relevance in real-world scenarios. In this paper, we propose two graphneural network-based methods to address multi-objective routing on multigraphs.Our first approach operates directly on the multigraph by autoregressivelyselecting edges until a tour is completed. The second model, which is morescalable, first simplifies the multigraph via a learned pruning strategy andthen performs autoregressive routing on the resulting simple graph. We evaluateboth models empirically, across a wide range of problems and graphdistributions, and demonstrate their competitive performance compared to strongheuristics and neural baselines.</description><author>Filip Rydin, Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár</author><pubDate>Wed, 24 Sep 2025 15:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.22095v3</guid></item><item><title>AAPO: Enhancing the Reasoning Capabilities of LLMs with Advantage Momentum</title><link>http://arxiv.org/abs/2505.14264v2</link><description>Reinforcement learning (RL) has emerged as an effective approach forenhancing the reasoning capabilities of large language models (LLMs),especially in scenarios where supervised fine-tuning (SFT) falls short due tolimited chain-of-thought (CoT) data. Among RL-based post-training methods,group relative advantage estimation, as exemplified by Group Relative PolicyOptimization (GRPO), has attracted considerable attention for eliminating thedependency on the value model, thereby simplifying training compared totraditional approaches like Proximal Policy Optimization (PPO). However, weobserve that exsiting group relative advantage estimation method still suffersfrom training inefficiencies, particularly when the estimated advantageapproaches zero. To address this limitation, we propose Advantage-AugmentedPolicy Optimization (AAPO), a novel RL algorithm that optimizes thecross-entropy (CE) loss using advantages enhanced through a momentum-basedestimation scheme. This approach effectively mitigates the inefficienciesassociated with group relative advantage estimation. Experimental results onmultiple mathematical reasoning benchmarks demonstrate the superior performanceof AAPO.</description><author>Jian Xiong, Jingbo Zhou, Jingyong Ye, Qiang Huang, Dejing Dou</author><pubDate>Wed, 24 Sep 2025 15:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.14264v2</guid></item><item><title>DreamMix: Decoupling Object Attributes for Enhanced Editability in Customized Image Inpainting</title><link>http://arxiv.org/abs/2411.17223v2</link><description>Subject-driven image inpainting has recently gained prominence in imageediting with the rapid advancement of diffusion models. Beyond image guidance,recent studies have explored incorporating text guidance to achieveidentity-preserved yet locally editable object inpainting. However, thesemethods still suffer from identity overfitting, where original attributesremain entangled with target textual instructions. To overcome this limitation,we propose DreamMix, a diffusion-based framework adept at inserting targetobjects into user-specified regions while concurrently enabling arbitrarytext-driven attribute modifications. DreamMix introduces three key components:(i) an Attribute Decoupling Mechanism (ADM) that synthesizes diverseattribute-augmented image-text pairs to mitigate overfitting; (ii) a TextualAttribute Substitution (TAS) module that isolates target attributes viaorthogonal decomposition, and (iii) a Disentangled Inpainting Framework (DIF)that seperates local generation from global harmonization. Extensiveexperiments across multiple inpainting backbones demonstrate that DreamMixachieves a superior balance between identity preservation and attributeeditability across diverse applications, including object insertion, attributeediting, and small object inpainting.</description><author>Yicheng Yang, Pengxiang Li, Lu Zhang, Liqian Ma, Ping Hu, Siyu Du, Yunzhi Zhuge, Xu Jia, Huchuan Lu</author><pubDate>Wed, 24 Sep 2025 15:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.17223v2</guid></item><item><title>AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory Anchors for End-to-End Driving</title><link>http://arxiv.org/abs/2509.20253v1</link><description>End-to-end multi-modal planning has become a transformative paradigm inautonomous driving, effectively addressing behavioral multi-modality and thegeneralization challenge in long-tail scenarios. We propose AnchDrive, aframework for end-to-end driving that effectively bootstraps a diffusion policyto mitigate the high computational cost of traditional generative models.Rather than denoising from pure noise, AnchDrive initializes its planner with arich set of hybrid trajectory anchors. These anchors are derived from twocomplementary sources: a static vocabulary of general driving priors and a setof dynamic, context-aware trajectories. The dynamic trajectories are decoded inreal-time by a Transformer that processes dense and sparse perceptual features.The diffusion model then learns to refine these anchors by predicting adistribution of trajectory offsets, enabling fine-grained refinement. Thisanchor-based bootstrapping design allows for efficient generation of diverse,high-quality trajectories. Experiments on the NAVSIM benchmark confirm thatAnchDrive sets a new state-of-the-art and shows strong gen?eralizability</description><author>Jinhao Chai, Anqing Jiang, Hao Jiang, Shiyi Mu, Zichong Gu, Shugong Xu</author><pubDate>Wed, 24 Sep 2025 15:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20253v1</guid></item><item><title>CANDLE: A Cross-Modal Agentic Knowledge Distillation Framework for Interpretable Sarcopenia Diagnosis</title><link>http://arxiv.org/abs/2507.21179v2</link><description>Background and Aims: Large language models (LLMs) have shown remarkablegeneralization and transfer capabilities by learning from vast corpora of textand web data. Their semantic representations allow cross-task knowledgetransfer and reasoning, offering promising opportunities for data-scarce andheterogeneous domains such as clinical medicine. Yet, in diagnostic tasks likesarcopenia, major challenges remain: interpretability, transparency, anddeployment efficiency. Traditional machine learning (TML) models provide stableperformance and feature-level attribution, ensuring traceable and auditabledecision logic, but lack semantic breadth. Conversely, LLMs enable flexibleinference but often function as opaque predictors. Existing integrationstrategies remain shallow, rarely embedding the structured reasoning of TMLinto LLM inference. Methods: Using sarcopenia diagnosis as a case study,SHapley Additive exPlanations (SHAP) were extracted from a baseline XGBoostmodel and transformed into structured, LLM-compatible representations. Anactor-critic reinforcement learning (RL) strategy guided the LLM to reason overthese SHAP-based inputs, producing calibrated rationales and refined decisionrules. The distilled reasoning was consolidated into a structured knowledgerepository and deployed via retrieval-augmented generation (RAG) for case-basedinference. Results: (Omitted here.) Conclusion: By coupling SHAP-derivedstatistical evidence with reinforcement-trained LLM reasoning, CANDLE mitigatesthe interpretability-performance trade-off, enhances predictive accuracy, andpreserves high decision consistency. The framework offers a scalable approachto knowledge assetization of TML models, enabling interpretable, reproducible,and clinically aligned decision support in sarcopenia and potentially broadermedical domains.</description><author>Yuqi Jin, Zhenhao Shuai, Zihan Hu, Weiteng Zhang, Weihao Xie, Jianwei Shuai, Xian Shen, Zhen Feng</author><pubDate>Wed, 24 Sep 2025 15:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.21179v2</guid></item><item><title>4D Driving Scene Generation With Stereo Forcing</title><link>http://arxiv.org/abs/2509.20251v1</link><description>Current generative models struggle to synthesize dynamic 4D driving scenesthat simultaneously support temporal extrapolation and spatial novel viewsynthesis (NVS) without per-scene optimization. Bridging generation and novelview synthesis remains a major challenge. We present PhiGenesis, a unifiedframework for 4D scene generation that extends video generation techniques withgeometric and temporal consistency. Given multi-view image sequences and cameraparameters, PhiGenesis produces temporally continuous 4D Gaussian splattingrepresentations along target 3D trajectories. In its first stage, PhiGenesisleverages a pre-trained video VAE with a novel range-view adapter to enablefeed-forward 4D reconstruction from multi-view images. This architecturesupports single-frame or video inputs and outputs complete 4D scenes includinggeometry, semantics, and motion. In the second stage, PhiGenesis introduces ageometric-guided video diffusion model, using rendered historical 4D scenes aspriors to generate future views conditioned on trajectories. To addressgeometric exposure bias in novel views, we propose Stereo Forcing, a novelconditioning strategy that integrates geometric uncertainty during denoising.This method enhances temporal coherence by dynamically adjusting generativeinfluence based on uncertainty-aware perturbations. Our experimental resultsdemonstrate that our method achieves state-of-the-art performance in bothappearance and geometric reconstruction, temporal generation and novel viewsynthesis (NVS) tasks, while simultaneously delivering competitive performancein downstream evaluations. Homepage is at\href{https://jiangxb98.github.io/PhiGensis}{PhiGensis}.</description><author>Hao Lu, Zhuang Ma, Guangfeng Jiang, Wenhang Ge, Bohan Li, Yuzhan Cai, Wenzhao Zheng, Yunpeng Zhang, Yingcong Chen</author><pubDate>Wed, 24 Sep 2025 15:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20251v1</guid></item><item><title>Dynamic Lagging for Time-Series Forecasting in E-Commerce Finance: Mitigating Information Loss with A Hybrid ML Architecture</title><link>http://arxiv.org/abs/2509.20244v1</link><description>Accurate forecasting in the e-commerce finance domain is particularlychallenging due to irregular invoice schedules, payment deferrals, anduser-specific behavioral variability. These factors, combined with sparsedatasets and short historical windows, limit the effectiveness of conventionaltime-series methods. While deep learning and Transformer-based models haveshown promise in other domains, their performance deteriorates under partialobservability and limited historical data. To address these challenges, wepropose a hybrid forecasting framework that integrates dynamic lagged featureengineering and adaptive rolling-window representations with classicalstatistical models and ensemble learners. Our approach explicitly incorporatesinvoice-level behavioral modeling, structured lag of support data, and customstability-aware loss functions, enabling robust forecasts in sparse andirregular financial settings. Empirical results demonstrate an approximate 5%reduction in MAPE compared to baseline models, translating into substantialfinancial savings. Furthermore, the framework enhances forecast stability overquarterly horizons and strengthens feature target correlation by capturing bothshort- and long-term patterns, leveraging user profile attributes, andsimulating upcoming invoice behaviors. These findings underscore the value ofcombining structured lagging, invoice-level closure modeling, and behavioralinsights to advance predictive accuracy in sparse financial time-seriesforecasting.</description><author>Abhishek Sharma, Anat Parush, Sumit Wadhwa, Amihai Savir, Anne Guinard, Prateek Srivastava</author><pubDate>Wed, 24 Sep 2025 15:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20244v1</guid></item><item><title>An Anisotropic Cross-View Texture Transfer with Multi-Reference Non-Local Attention for CT Slice Interpolation</title><link>http://arxiv.org/abs/2509.20242v1</link><description>Computed tomography (CT) is one of the most widely used non-invasive imagingmodalities for medical diagnosis. In clinical practice, CT images are usuallyacquired with large slice thicknesses due to the high cost of memory storageand operation time, resulting in an anisotropic CT volume with much lowerinter-slice resolution than in-plane resolution. Since such inconsistentresolution may lead to difficulties in disease diagnosis, deep learning-basedvolumetric super-resolution methods have been developed to improve inter-sliceresolution. Most existing methods conduct single-image super-resolution on thethrough-plane or synthesize intermediate slices from adjacent slices; however,the anisotropic characteristic of 3D CT volume has not been well explored. Inthis paper, we propose a novel cross-view texture transfer approach for CTslice interpolation by fully utilizing the anisotropic nature of 3D CT volume.Specifically, we design a unique framework that takes high-resolution in-planetexture details as a reference and transfers them to low-resolutionthrough-plane images. To this end, we introduce a multi-reference non-localattention module that extracts meaningful features for reconstructingthrough-plane high-frequency details from multiple in-plane images. Throughextensive experiments, we demonstrate that our method performs significantlybetter in CT slice interpolation than existing competing methods on public CTdatasets including a real-paired benchmark, verifying the effectiveness of theproposed framework. The source code of this work is available athttps://github.com/khuhm/ACVTT.</description><author>Kwang-Hyun Uhm, Hyunjun Cho, Sung-Hoo Hong, Seung-Won Jung</author><pubDate>Wed, 24 Sep 2025 15:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20242v1</guid></item><item><title>Energy Use of AI Inference: Efficiency Pathways and Test-Time Compute</title><link>http://arxiv.org/abs/2509.20241v1</link><description>As AI inference scales to billions of queries and emerging reasoning andagentic workflows increase token demand, reliable estimates of per-query energyuse are increasingly important for capacity planning, emissions accounting, andefficiency prioritization. Many public estimates are inconsistent and overstateenergy use, because they extrapolate from limited benchmarks and fail toreflect efficiency gains achievable at scale. In this perspective, we introducea bottom-up methodology to estimate the per-query energy of large-scale LLMsystems based on token throughput. For models running on an H100 node underrealistic workloads, GPU utilization and PUE constraints, we estimate a medianenergy per query of 0.34 Wh (IQR: 0.18-0.67) for frontier-scale models (&gt;200billion parameters). These results are consistent with measurements usingproduction-scale configurations and show that non-production estimates andassumptions can overstate energy use by 4-20x. Extending to test-time scalingscenarios with 15x more tokens per typical query, the median energy rises 13xto 4.32 Wh, indicating that targeting efficiency in this regime will deliverthe largest fleet-wide savings. We quantify achievable efficiency gains at themodel, serving platform, and hardware levels, finding individual medianreductions of 1.5-3.5x in energy per query, while combined advances canplausibly deliver 8-20x reductions. To illustrate the system-level impact, weestimate the baseline daily energy use of a deployment serving 1 billionqueries to be 0.8 GWh/day. If 10% are long queries, demand could grow to 1.8GWh/day. With targeted efficiency interventions, it falls to 0.9 GWh/day,similar to the energy footprint of web search at that scale. This echoes howdata centers historically tempered energy growth through efficiency gainsduring the internet and cloud build-up.</description><author>Felipe Oviedo, Fiodar Kazhamiaka, Esha Choukse, Allen Kim, Amy Luers, Melanie Nakagawa, Ricardo Bianchini, Juan M. Lavista Ferres</author><pubDate>Wed, 24 Sep 2025 15:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20241v1</guid></item><item><title>A HyperGraphMamba-Based Multichannel Adaptive Model for ncRNA Classification</title><link>http://arxiv.org/abs/2509.20240v1</link><description>Non-coding RNAs (ncRNAs) play pivotal roles in gene expression regulation andthe pathogenesis of various diseases. Accurate classification of ncRNAs isessential for functional annotation and disease diagnosis. To address existinglimitations in feature extraction depth and multimodal fusion, we proposeHGMamba-ncRNA, a HyperGraphMamba-based multichannel adaptive model, whichintegrates sequence, secondary structure, and optionally available expressionfeatures of ncRNAs to enhance classification performance. Specifically, thesequence of ncRNA is modeled using a parallel Multi-scale Convolution and LSTMarchitecture (MKC-L) to capture both local patterns and long-range dependenciesof nucleotides. The structure modality employs a multi-scale graph transformer(MSGraphTransformer) to represent the multi-level topological characteristicsof ncRNA secondary structures. The expression modality utilizes a ChebyshevPolynomial-based Kolmogorov-Arnold Network (CPKAN) to effectively model andinterpret high-dimensional expression profiles. Finally, by incorporatingvirtual nodes to facilitate efficient and comprehensive multimodal interaction,HyperGraphMamba is proposed to adaptively align and integrate multichannelheterogeneous modality features. Experiments conducted on three public datasetsdemonstrate that HGMamba-ncRNA consistently outperforms state-of-the-artmethods in terms of accuracy and other metrics. Extensive empirical studiesfurther confirm the model's robustness, effectiveness, and strongtransferability, offering a novel and reliable strategy for complex ncRNAfunctional classification. Code and datasets are available athttps://anonymous.4open.science/r/HGMamba-ncRNA-94D0.</description><author>Xin An, Ruijie Li, Qiao Ning, Hui Li, Qian Ma, Shikai Guo</author><pubDate>Wed, 24 Sep 2025 15:31:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20240v1</guid></item><item><title>Error Propagation in Dynamic Programming: From Stochastic Control to Option Pricing</title><link>http://arxiv.org/abs/2509.20239v1</link><description>This paper investigates theoretical and methodological foundations forstochastic optimal control (SOC) in discrete time. We start formulating thecontrol problem in a general dynamic programming framework, introducing themathematical structure needed for a detailed convergence analysis. Theassociate value function is estimated through a sequence of approximationscombining nonparametric regression methods and Monte Carlo subsampling. Theregression step is performed within reproducing kernel Hilbert spaces (RKHSs),exploiting the classical KRR algorithm, while Monte Carlo sampling methods areintroduced to estimate the continuation value. To assess the accuracy of ourvalue function estimator, we propose a natural error decomposition andrigorously control the resulting error terms at each time step. We then analyzehow this error propagates backward in time-from maturity to the initial stage-arelatively underexplored aspect of the SOC literature. Finally, we illustratehow our analysis naturally applies to a key financial application: the pricingof American options.</description><author>Andrea Della Vecchia, Damir Filipović</author><pubDate>Wed, 24 Sep 2025 15:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20239v1</guid></item><item><title>FORGE: Foundational Optimization Representations from Graph Embeddings</title><link>http://arxiv.org/abs/2508.20330v4</link><description>Combinatorial optimization problems are ubiquitous in science andengineering. Still, learning-based approaches to accelerate combinatorialoptimization often require solving a large number of difficult instances tocollect training data, incurring significant computational cost. Existinglearning-based methods require training dedicated models for each problemdistribution, for each downstream task, severely limiting their scalability andgeneralization. We introduce Forge: Foundational Optimization Representationsfrom Graph Embeddings, a framework that pre-trains a vector-quantized graphautoencoder on a large, diverse collection of mixed-integer programming (MIP)instances in an unsupervised manner, without relying on optimization solvers oroptimal solutions. Vector quantization produces discrete code assignments thatserve as a vocabulary for representing optimization instances. We evaluateForge in both unsupervised and supervised settings. In the unsupervisedsetting, Forge embeddings effectively cluster unseen instances across problemdomains and sizes. In the supervised setting, we fine-tune Forge embeddings andshow that a single pre-trained model helps predicting both the integrality gapfor cut-generation and variable hints for search guidance across multipleproblem and size distributions. In both tasks, we improve the performance of acommercial optimization solver and outperform state-of-the-art learning-basedmethods. Finally, we open-source our training code, pre-trained Forge weights,and embeddings for multiple MIP distributions to foster further research inrepresentation learning for optimization problems.</description><author>Zohair Shafi, Serdar Kadioglu</author><pubDate>Wed, 24 Sep 2025 15:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.20330v4</guid></item><item><title>Context-Masked Meta-Prompting for Privacy-Preserving LLM Adaptation in Finance</title><link>http://arxiv.org/abs/2407.18920v2</link><description>The increasing reliance on Large Language Models (LLMs) in sensitive domainslike finance necessitates robust methods for privacy preservation andregulatory compliance. This paper presents an iterative meta-promptingmethodology designed to optimise hard prompts without exposing proprietary orconfidential context to the LLM. Through a novel regeneration process involvingfeeder and propagation methods, we demonstrate significant improvements inprompt efficacy. Evaluated on public datasets serving as proxies for financialtasks such as SQuAD for extractive financial Q&amp;A, CNN/DailyMail for newssummarisation, and SAMSum for client interaction summarisation, our approach,utilising GPT-3.5 Turbo, achieved a 103.87% improvement in ROUGE-L F1 forquestion answering. This work highlights a practical, low-cost strategy foradapting LLMs to financial applications while upholding critical privacy andauditability standards, offering a compelling case for its relevance in theevolving landscape of generative AI in finance.</description><author>Sayash Raaj Hiraou</author><pubDate>Wed, 24 Sep 2025 15:30:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18920v2</guid></item><item><title>Investigating the Representation of Backchannels and Fillers in Fine-tuned Language Models</title><link>http://arxiv.org/abs/2509.20237v1</link><description>Backchannels and fillers are important linguistic expressions in dialogue,but are under-represented in modern transformer-based language models (LMs).Our work studies the representation of them in language models using threefine-tuning strategies. The models are trained on three dialogue corpora inEnglish and Japanese, where backchannels and fillers are preserved andannotated, to investigate how fine-tuning can help LMs learn theirrepresentations. We first apply clustering analysis to the learntrepresentation of backchannels and fillers, and have found increased silhouettescores in representations from fine-tuned models, which suggests thatfine-tuning enables LMs to distinguish the nuanced semantic variation indifferent backchannel and filler use. We also use natural language generation(NLG) metrics to confirm that the utterances generated by fine-tuned languagemodels resemble human-produced utterances more closely. Our findings suggestthe potentials of transforming general LMs into conversational LMs that aremore capable of producing human-like languages adequately.</description><author>Yu Wang, Leyi Lao, Langchu Huang, Gabriel Skantze, Yang Xu, Hendrik Buschmeier</author><pubDate>Wed, 24 Sep 2025 15:27:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20237v1</guid></item><item><title>Long Video Understanding with Learnable Retrieval in Video-Language Models</title><link>http://arxiv.org/abs/2312.04931v3</link><description>The remarkable natural language understanding, reasoning, and generationcapabilities of large language models (LLMs) have made them attractive forapplication to video understanding, utilizing video tokens as contextual input.However, employing LLMs for long video understanding presents significantchallenges. The extensive number of video tokens leads to considerablecomputational costs for LLMs while using aggregated tokens results in loss ofvision details. Moreover, the presence of abundant question-irrelevant tokensintroduces noise to the video reasoning process. To address these issues, weintroduce a simple yet effective learnable retrieval-based video-language model(R-VLM) for efficient long video understanding. Specifically, given a question(query) and a long video, our model identifies and selects the most relevant Kvideo chunks and uses their associated visual tokens to serve as context forthe LLM inference. This effectively reduces the number of video tokens,eliminates noise interference, and enhances system performance. We achieve thisby incorporating a learnable lightweight MLP block to facilitate the efficientretrieval of question-relevant chunks, through the end-to-end training of ourvideo-language model with a proposed soft matching loss. Our experimentalresults on multiple zero-shot video question answering datasets validate theeffectiveness of our framework for comprehending long videos.</description><author>Jiaqi Xu, Cuiling Lan, Wenxuan Xie, Xuejin Chen, Yan Lu</author><pubDate>Wed, 24 Sep 2025 15:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04931v3</guid></item><item><title>ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression</title><link>http://arxiv.org/abs/2509.20234v1</link><description>The hypothesis that Convolutional Neural Networks (CNNs) are inherentlytexture-biased has shaped much of the discourse on feature use in deeplearning. We revisit this hypothesis by examining limitations in thecue-conflict experiment by Geirhos et al. To address these limitations, wepropose a domain-agnostic framework that quantifies feature reliance throughsystematic suppression of shape, texture, and color cues, avoiding theconfounds of forced-choice conflicts. By evaluating humans and neural networksunder controlled suppression conditions, we find that CNNs are not inherentlytexture-biased but predominantly rely on local shape features. Nonetheless,this reliance can be substantially mitigated through modern training strategiesor architectures (ConvNeXt, ViTs). We further extend the analysis acrosscomputer vision, medical imaging, and remote sensing, revealing that reliancepatterns differ systematically: computer vision models prioritize shape,medical imaging models emphasize color, and remote sensing models exhibit astronger reliance towards texture. Code is available athttps://github.com/tomburgert/feature-reliance.</description><author>Tom Burgert, Oliver Stoll, Paolo Rota, Begüm Demir</author><pubDate>Wed, 24 Sep 2025 15:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20234v1</guid></item><item><title>Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization</title><link>http://arxiv.org/abs/2509.20230v1</link><description>Current LLM unlearning methods face a critical security vulnerability thatundermines their fundamental purpose: while they appear to successfully removesensitive or harmful knowledge, this ``forgotten" information remainsprecariously recoverable through relearning attacks. We identify that the rootcause is that conventional methods optimizing the forgetting loss at individualdata points will drive model parameters toward sharp minima in the losslandscape. In these unstable regions, even minimal parameter perturbations candrastically alter the model's behaviors. Consequently, relearning attacksexploit this vulnerability by using just a few fine-tuning samples to navigatethe steep gradients surrounding these unstable regions, thereby rapidlyrecovering knowledge that was supposedly erased. This exposes a criticalrobustness gap between apparent unlearning and actual knowledge removal. Toaddress this issue, we propose StableUN, a bi-level feedback-guidedoptimization framework that explicitly seeks more stable parameter regions vianeighborhood-aware optimization. It integrates forgetting feedback, which usesadversarial perturbations to probe parameter neighborhoods, with rememberingfeedback to preserve model utility, aligning the two objectives throughgradient projection. Experiments on WMDP and MUSE benchmarks demonstrate thatour method is significantly more robust against both relearning andjailbreaking attacks while maintaining competitive utility performance.</description><author>Wenhan Wu, Zheyuan Liu, Chongyang Gao, Ren Wang, Kaize Ding</author><pubDate>Wed, 24 Sep 2025 15:23:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20230v1</guid></item><item><title>Muse-it: A Tool for Analyzing Music Discourse on Reddit</title><link>http://arxiv.org/abs/2509.20228v1</link><description>Music engagement spans diverse interactions with music, from selection andemotional response to its impact on behavior, identity, and social connections.Social media platforms provide spaces where such engagement can be observed innatural, unprompted conversations. Advances in natural language processing(NLP) and big data analytics make it possible to analyze these discussions atscale, extending music research to broader contexts. Reddit, in particular,offers anonymity that encourages diverse participation and yields richdiscourse on music in ecological settings. Yet the scale of this data requirestools to extract, process, and analyze it effectively. We present Muse-it, aplatform that retrieves comprehensive Reddit data centered on user-definedqueries. It aggregates posts from across subreddits, supports topic modeling,temporal trend analysis, and clustering, and enables efficient study oflarge-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,Spotify), retrieves track-level metadata such as artist, album, release date,genre, popularity, and lyrics, and links these to the discussions. Aninteractive interface provides dynamic visualizations of the collected data.Muse-it thus offers an accessible way for music researchers to gather andanalyze big data, opening new avenues for understanding music engagement as itnaturally unfolds online.</description><author>Jatin Agarwala, George Paul, Nemani Harsha Vardhan, Vinoo Alluri</author><pubDate>Wed, 24 Sep 2025 15:22:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20228v1</guid></item><item><title>Latent Wavelet Diffusion For Ultra-High-Resolution Image Synthesis</title><link>http://arxiv.org/abs/2506.00433v3</link><description>High-resolution image synthesis remains a core challenge in generativemodeling, particularly in balancing computational efficiency with thepreservation of fine-grained visual detail. We present Latent Wavelet Diffusion(LWD), a lightweight training framework that significantly improves detail andtexture fidelity in ultra-high-resolution (2K-4K) image synthesis. LWDintroduces a novel, frequency-aware masking strategy derived from waveletenergy maps, which dynamically focuses the training process on detail-richregions of the latent space. This is complemented by a scale-consistent VAEobjective to ensure high spectral fidelity. The primary advantage of ourapproach is its efficiency: LWD requires no architectural modifications andadds zero additional cost during inference, making it a practical solution forscaling existing models. Across multiple strong baselines, LWD consistentlyimproves perceptual quality and FID scores, demonstrating the power ofsignal-driven supervision as a principled and efficient path towardhigh-resolution generative modeling.</description><author>Luigi Sigillo, Shengfeng He, Danilo Comminiello</author><pubDate>Wed, 24 Sep 2025 15:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.00433v3</guid></item><item><title>Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation</title><link>http://arxiv.org/abs/2509.20225v1</link><description>Multimodal data has significantly advanced recommendation systems byintegrating diverse information sources to model user preferences and itemcharacteristics. However, these systems often struggle with redundant andirrelevant information, which can degrade performance. Most existing methodseither fuse multimodal information directly or use rigid architecturalseparation for disentanglement, failing to adequately filter noise and modelthe complex interplay between modalities. To address these challenges, wepropose a novel framework, the Multimodal Representation-disentangledInformation Bottleneck (MRdIB). Concretely, we first employ a MultimodalInformation Bottleneck to compress the input representations, effectivelyfiltering out task-irrelevant noise while preserving rich semantic information.Then, we decompose the information based on its relationship with therecommendation target into unique, redundant, and synergistic components. Weachieve this decomposition with a series of constraints: a unique informationlearning objective to preserve modality-unique signals, a redundant informationlearning objective to minimize overlap, and a synergistic information learningobjective to capture emergent information. By optimizing these objectives,MRdIB guides a model to learn more powerful and disentangled representations.Extensive experiments on several competitive models and three benchmarkdatasets demonstrate the effectiveness and versatility of our MRdIB inenhancing multimodal recommendation.</description><author>Hui Wang, Jinghui Qin, Wushao Wen, Qingling Li, Shanshan Zhong, Zhongzhan Huang</author><pubDate>Wed, 24 Sep 2025 15:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20225v1</guid></item><item><title>Design Insights and Comparative Evaluation of a Hardware-Based Cooperative Perception Architecture for Lane Change Prediction</title><link>http://arxiv.org/abs/2509.20218v1</link><description>Research on lane change prediction has gained attention in the last fewyears. Most existing works in this area have been conducted in simulationenvironments or with pre-recorded datasets, these works often rely onsimplified assumptions about sensing, communication, and traffic behavior thatdo not always hold in practice. Real-world deployments of lane-changeprediction systems are relatively rare, and when they are reported, thepractical challenges, limitations, and lessons learned are oftenunder-documented. This study explores cooperative lane-change predictionthrough a real hardware deployment in mixed traffic and shares the insightsthat emerged during implementation and testing. We highlight the practicalchallenges we faced, including bottlenecks, reliability issues, and operationalconstraints that shaped the behavior of the system. By documenting theseexperiences, the study provides guidance for others working on similarpipelines.</description><author>Mohamed Manzour, Catherine M. Elias, Omar M. Shehata, Rubén Izquierdo, Miguel Ángel Sotelo</author><pubDate>Wed, 24 Sep 2025 15:15:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20218v1</guid></item><item><title>Machine-Learning Interatomic Potentials for Long-Range Systems</title><link>http://arxiv.org/abs/2502.04668v3</link><description>Machine-learning interatomic potentials have emerged as a revolutionary classof force-field models in molecular simulations, delivering quantum-mechanicalaccuracy at a fraction of the computational cost and enabling the simulation oflarge-scale systems over extended timescales. However, they often focus onmodeling local environments, neglecting crucial long-range interactions. Wepropose a Sum-of-Gaussians Neural Network (SOG-Net), a lightweight andversatile framework for integrating long-range interactions into machinelearning force field. The SOG-Net employs a latent-variable learning networkthat seamlessly bridges short-range and long-range components, coupled with anefficient Fourier convolution layer that incorporates long-range effects. Bylearning sum-of-Gaussians multipliers across different convolution layers, theSOG-Net adaptively captures diverse long-range decay behaviors whilemaintaining close-to-linear computational complexity during training andsimulation via non-uniform fast Fourier transforms. The method is demonstratedeffective for a broad range of long-range systems.</description><author>Yajie Ji, Jiuyang Liang, Zhenli Xu</author><pubDate>Wed, 24 Sep 2025 15:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04668v3</guid></item><item><title>The Cream Rises to the Top: Efficient Reranking Method for Verilog Code Generation</title><link>http://arxiv.org/abs/2509.20215v1</link><description>LLMs face significant challenges in Verilog generation due to limiteddomain-specific knowledge. While sampling techniques improve pass@k metrics,hardware engineers need one trustworthy solution rather than uncertaincandidates. To bridge this gap, we formulate it as a semantic alignment problembetween requirements and Verilog implementations, and propose VCD-RNK, adiscriminator model tailored for efficient Verilog code reranking.Specifically, VCD-RNKincorporates Verilog-specific reasoning by distillingexpert knowledge across three dimensions: code semantic analysis, test casegeneration, and functional correctness assessment. By explicitly simulating theabove reasoning processes during inference, VCD-RNK effectively avoidscomputationally intensive test execution in existing methods.</description><author>Guang Yang, Wei Zheng, Xiang Chen, Yifan Sun, Fengji Zhang, Terry Yue Zhuo</author><pubDate>Wed, 24 Sep 2025 15:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20215v1</guid></item><item><title>Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for Efficient LLM Deployment</title><link>http://arxiv.org/abs/2509.20214v1</link><description>We study weight-only post-training quantization (PTQ), which quantizes theweights of a large language model (LLM) without retraining, using little or nocalibration data. Weight-only PTQ is crucial for reducing the memory footprintand latency of LLM inference, especially in memory-bound, small-batch inferencescenarios, such as personalized inference on edge devices. Despite itsimportance, irregular weight distributions with heavy-tailed outliers in LLMscomplicate quantization, recently motivating rotation-based methods thattransform weights into near-Gaussian distributions, which are more regular withfewer outliers, thereby reducing quantization error. In this work, we firstderive the information-theoretically optimal bit allocation for Gaussianizedweights under given bit budgets, revealing that fine-grained fractional-bitquantizers approaching the Gaussian distortion-rate bound are essential toachieve near-optimal quantization performance. To bridge this theoreticalinsight and practical implementation, we introduce Q-Palette, a versatilecollection of fractional-bit quantizers that range from trellis-codedquantizers offering near-optimal distortion to simpler vector and scalarquantizers optimized for faster inference, all efficiently implemented withoptimized CUDA kernels across various bitwidths. Furthermore, leveragingQ-Palette as a foundational component, we propose a novel mixed-schemequantization framework, jointly optimizing quantizer choices and layer fusiondecisions given resource constraints. The code is available athttps://github.com/snu-mllab/Q-Palette.</description><author>Deokjae Lee, Hyun Oh Song</author><pubDate>Wed, 24 Sep 2025 15:10:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20214v1</guid></item><item><title>UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning</title><link>http://arxiv.org/abs/2509.11543v2</link><description>Graphical User Interface (GUI) agents have demonstrated remarkable progressin automating complex user interface interactions through reinforcementlearning. However, current approaches face a fundamental dilemma: offline RLenables stable training on pre-collected trajectories, but struggles withmulti-step task execution for lack of trajectory-level reward signals; onlineRL captures these signals through environment interaction, but suffers fromsparse rewards and prohibitive deployment costs. To address it, we presentSemi-online Reinforcement Learning, a novel paradigm that simulates online RLon offline trajectories. During each rollout process, we preserve the originalmodel output within the multi-turn dialogue, where a Patch Module adaptivelyrecovers the divergence between rollout and expert trajectories. To capturelong-term training signals, Semi-online RL introduces discounted future returnsinto the reward computation and optimizes the policy with weighted step-leveland episode-level advantages. We further introduce Semi-Online Performance(SOP), a metric that aligns better with true online performance, serving as apractical and effective proxy for real-world evaluation. Experiments show thatours Semi-online RL achieves SOTA performance among 7B models across fourdynamic benchmarks, with significant gains over the base model (e.g., +12.0% onAndroidWorld, +23.8% on AITW), demonstrating significant progress in bridgingthe gap between offline training efficiency and online multi-turn reasoning.The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1.</description><author>Zhengxi Lu, Jiabo Ye, Fei Tang, Yongliang Shen, Haiyang Xu, Ziwei Zheng, Weiming Lu, Ming Yan, Fei Huang, Jun Xiao, Yueting Zhuang</author><pubDate>Wed, 24 Sep 2025 15:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.11543v2</guid></item><item><title>Wrapped Gaussian on the manifold of Symmetric Positive Definite Matrices</title><link>http://arxiv.org/abs/2502.01512v4</link><description>Circular and non-flat data distributions are prevalent across diverse domainsof data science, yet their specific geometric structures often remainunderutilized in machine learning frameworks. A principled approach toaccounting for the underlying geometry of such data is pivotal, particularlywhen extending statistical models, like the pervasive Gaussian distribution. Inthis work, we tackle those issue by focusing on the manifold of symmetricpositive definite (SPD) matrices, a key focus in information geometry. Weintroduce a non-isotropic wrapped Gaussian by leveraging the exponential map,we derive theoretical properties of this distribution and propose a maximumlikelihood framework for parameter estimation. Furthermore, we reinterpretestablished classifiers on SPD through a probabilistic lens and introduce newclassifiers based on the wrapped Gaussian model. Experiments on synthetic andreal-world datasets demonstrate the robustness and flexibility of thisgeometry-aware distribution, underscoring its potential to advancemanifold-based data analysis. This work lays the groundwork for extendingclassical machine learning and statistical methods to more complex andstructured data.</description><author>Thibault de Surrel, Fabien Lotte, Sylvain Chevallier, Florian Yger</author><pubDate>Wed, 24 Sep 2025 15:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01512v4</guid></item><item><title>Time-adaptive HénonNets for separable Hamiltonian systems</title><link>http://arxiv.org/abs/2509.20212v1</link><description>Measurement data is often sampled irregularly, i.e., not on equidistant timegrids. This is also true for Hamiltonian systems. However, existing machinelearning methods, which learn symplectic integrators, such as SympNets [1] andH\'enonNets [2] still require training data generated by fixed step sizes. Tolearn time-adaptive symplectic integrators, an extension to SympNets calledTSympNets is introduced in [3]. The aim of this work is to do a similarextension for H\'enonNets. We propose a novel neural network architecturecalled T-H\'enonNets, which is symplectic by design and can handle adaptivetime steps. We also extend the T-H\'enonNet architecture to non-autonomousHamiltonian systems. Additionally, we provide universal approximation theoremsfor both new architectures for separable Hamiltonian systems and discuss why itis difficult to handle non-separable Hamiltonian systems with the proposedmethods. To investigate these theoretical approximation capabilities, weperform different numerical experiments.</description><author>Konrad Janik, Peter Benner</author><pubDate>Wed, 24 Sep 2025 15:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20212v1</guid></item><item><title>Practical do-Shapley Explanations with Estimand-Agnostic Causal Inference</title><link>http://arxiv.org/abs/2509.20211v1</link><description>Among explainability techniques, SHAP stands out as one of the most popular,but often overlooks the causal structure of the problem. In response, do-SHAPemploys interventional queries, but its reliance on estimands hinders itspractical application. To address this problem, we propose the use ofestimand-agnostic approaches, which allow for the estimation of anyidentifiable query from a single model, making do-SHAP feasible on complexgraphs. We also develop a novel algorithm to significantly accelerate itscomputation at a negligible cost, as well as a method to explain inaccessibleData Generating Processes. We demonstrate the estimation and computationalperformance of our approach, and validate it on two real-world datasets,highlighting its potential in obtaining reliable explanations.</description><author>Álvaro Parafita, Tomas Garriga, Axel Brando, Francisco J. Cazorla</author><pubDate>Wed, 24 Sep 2025 15:04:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20211v1</guid></item><item><title>Low-Resource English-Tigrinya MT: Leveraging Multilingual Models, Custom Tokenizers, and Clean Evaluation Benchmarks</title><link>http://arxiv.org/abs/2509.20209v1</link><description>Despite advances in Neural Machine Translation (NMT), low-resource languageslike Tigrinya remain underserved due to persistent challenges, includinglimited corpora, inadequate tokenization strategies, and the lack ofstandardized evaluation benchmarks. This paper investigates transfer learningtechniques using multilingual pretrained models to enhance translation qualityfor morphologically rich, low-resource languages. We propose a refined approachthat integrates language-specific tokenization, informed embeddinginitialization, and domain-adaptive fine-tuning. To enable rigorous assessment,we construct a high-quality, human-aligned English-Tigrinya evaluation datasetcovering diverse domains. Experimental results demonstrate that transferlearning with a custom tokenizer substantially outperforms zero-shot baselines,with gains validated by BLEU, chrF, and qualitative human evaluation.Bonferroni correction is applied to ensure statistical significance acrossconfigurations. Error analysis reveals key limitations and informs targetedrefinements. This study underscores the importance of linguistically awaremodeling and reproducible benchmarks in bridging the performance gap forunderrepresented languages. Resources are available athttps://github.com/hailaykidu/MachineT_TigEng and https://huggingface.co/Hailay/MachineT_TigEng</description><author>Hailay Kidu Teklehaymanot, Gebrearegawi Gidey, Wolfgang Nejdl</author><pubDate>Wed, 24 Sep 2025 15:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20209v1</guid></item><item><title>Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs</title><link>http://arxiv.org/abs/2509.20208v1</link><description>Integrating LLM powered operators in declarative query languages allows forthe combination of cheap and interpretable functions with powerful,generalizable language model reasoning. However, in order to benefit from theoptimized execution of a database query language like SQL, generated outputsmust align with the rules enforced by both type checkers and database contents.Current approaches address this challenge with orchestrations consisting ofmany LLM-based post-processing calls to ensure alignment between generatedoutputs and database values, introducing performance bottlenecks. We perform astudy on the ability of various sized open-source language models to both parseand execute functions within a query language based on SQL, showing that smalllanguage models can excel as function executors over hybrid data sources. Then,we propose an efficient solution to enforce the well-typedness of LLMfunctions, demonstrating 7% accuracy improvement on a multi-hop questionanswering dataset with 53% improvement in latency over comparable solutions. Wemake our implementation available at https://github.com/parkervg/blendsql</description><author>Parker Glenn, Alfy Samuel, Daben Liu</author><pubDate>Wed, 24 Sep 2025 15:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20208v1</guid></item><item><title>PU-Gaussian: Point Cloud Upsampling using 3D Gaussian Representation</title><link>http://arxiv.org/abs/2509.20207v1</link><description>Point clouds produced by 3D sensors are often sparse and noisy, posingchallenges for tasks requiring dense and high-fidelity 3D representations.Prior work has explored both implicit feature-based upsampling anddistance-function learning to address this, but often at the expense ofgeometric interpretability or robustness to input sparsity. To overcome theselimitations, we propose PU-Gaussian, a novel upsampling network that models thelocal neighborhood around each point using anisotropic 3D Gaussiandistributions. These Gaussians capture the underlying geometric structure,allowing us to perform upsampling explicitly in the local geometric domain bydirect point sampling. The sampling process generates a dense, but coarse,point cloud. A subsequent refinement network adjusts the coarse output toproduce a more uniform distribution and sharper edges. We perform extensivetesting on the PU1K and PUGAN datasets, demonstrating that PU-Gaussian achievesstate-of-the-art performance. We make code and model weights publicly availableat https://github.com/mvg-inatech/PU-Gaussian.git.</description><author>Mahmoud Khater, Mona Strauss, Philipp von Olshausen, Alexander Reiterer</author><pubDate>Wed, 24 Sep 2025 15:02:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20207v1</guid></item><item><title>CLIP Can Understand Depth</title><link>http://arxiv.org/abs/2402.03251v2</link><description>In this paper, we demonstrate that CLIP can also be adapted to downstreamtasks where its vision-language alignment is suboptimally learned duringpre-training on web-crawled data, all without requiring fine-tuning. We explorethe case of monocular depth estimation, where CLIP's contrastive priorstruggles to generalize, compared to its success in domains such as generativemodeling and semantic segmentation. Since CLIP fails to consistently capturesimilarities between image patches and natural language prompts describingdistance, we eliminate the use of its pre-trained natural language tokenembeddings and distill the semantic prior of its frozen text encoder into asingle learnable embedding matrix called "mirror". The main design goal ofmirror is to derive a non-human language prompt that approximates an optimalnatural language prompt: "How far is this location from the camera?" Using thisapproach, we jointly train two lightweight modules, a mirror and a compactdecoder, on top of a frozen CLIP for dense depth prediction. Compared toconventional depth models, our framework is significantly more efficient interms of parameters and computation. The resulting model exhibits impressiveperformance, matching several state-of-the-art vision models on the NYU Depthv2 and KITTI benchmark datasets, while outperforming all vision-language depthmodels based on a frozen CLIP prior. Experiments demonstrate that thesuboptimal depth understanding of CLIP in terms of spatial and temporalconsistency can be significantly corrected without either fine-tuning it orconcatenating mirror with its pre-trained subword token embeddings.Furthermore, an ablation study on the convergence status of mirror shows thatit is implicitly trained to capture objects, such as humans and windows, wheresemantic cues play an important role in detection.</description><author>Sohee Kim, Jisu Kang, Dunam Kim, Seokju Lee</author><pubDate>Wed, 24 Sep 2025 14:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03251v2</guid></item><item><title>Staying on the Manifold: Geometry-Aware Noise Injection</title><link>http://arxiv.org/abs/2509.20201v1</link><description>It has been shown that perturbing the input during training implicitlyregularises the gradient of the learnt function, leading to smoother models andenhancing generalisation. However, previous research mostly considered theaddition of ambient noise in the input space, without considering theunderlying structure of the data. In this work, we propose several methods ofadding geometry-aware input noise that accounts for the lower dimensionalmanifold the input space inhabits. We start by projecting ambient Gaussiannoise onto the tangent space of the manifold. In a second step, the noisesample is mapped on the manifold via the associated geodesic curve. We alsoconsider Brownian motion noise, which moves in random steps along the manifold.We show that geometry-aware noise leads to improved generalization androbustness to hyperparameter selection on highly curved manifolds, whileperforming at least as well as training without noise on simpler manifolds. Ourproposed framework extends to learned data manifolds.</description><author>Albert Kjøller Jacobsen, Johanna Marie Gegenfurtner, Georgios Arvanitidis</author><pubDate>Wed, 24 Sep 2025 14:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20201v1</guid></item><item><title>LLMs Reproduce Stereotypes of Sexual and Gender Minorities</title><link>http://arxiv.org/abs/2501.05926v3</link><description>A large body of research has found substantial gender bias in NLP systems.Most of this research takes a binary, essentialist view of gender: limiting itsvariation to the categories _men_ and _women_, conflating gender with sex, andignoring different sexual identities. But gender and sexuality exist on aspectrum, so in this paper we study the biases of large language models (LLMs)towards sexual and gender minorities beyond binary categories. Grounding ourstudy in a widely used social psychology model -- the Stereotype Content Model-- we demonstrate that English-language survey questions about socialperceptions elicit more negative stereotypes of sexual and gender minoritiesfrom both humans and LLMs. We then extend this framework to a more realisticuse case: text generation. Our analysis shows that LLMs generate stereotypedrepresentations of sexual and gender minorities in this setting, showing thatthey amplify representational harms in creative writing, a widely advertiseduse for LLMs.</description><author>Ruby Ostrow, Adam Lopez</author><pubDate>Wed, 24 Sep 2025 14:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05926v3</guid></item><item><title>Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion</title><link>http://arxiv.org/abs/2410.13674v3</link><description>Low-quality or scarce data has posed significant challenges for training deepneural networks in practice. While classical data augmentation cannotcontribute very different new data, diffusion models opens up a new door tobuild self-evolving AI by generating high-quality and diverse synthetic datathrough text-guided prompts. However, text-only guidance cannot controlsynthetic images' proximity to the original images, resulting inout-of-distribution data detrimental to the model performance. To overcome thelimitation, we study image guidance to achieve a spectrum of interpolationsbetween synthetic and real images. With stronger image guidance, the generatedimages are similar to the training data but hard to learn. While with weakerimage guidance, the synthetic images will be easier for model but contribute toa larger distribution gap with the original data. The generated full spectrumof data enables us to build a novel "Diffusion Curriculum (DisCL)". DisCLadjusts the image guidance level of image synthesis for each training stage: Itidentifies and focuses on hard samples for the model and assesses the mosteffective guidance level of synthetic images to improve hard data learning. Weapply DisCL to two challenging tasks: long-tail (LT) classification andlearning from low-quality data. It focuses on lower-guidance images ofhigh-quality to learn prototypical features as a warm-up of learninghigher-guidance images that might be weak on diversity or quality. Extensiveexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy whenapplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the basemodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%improvement in all-class accuracy.</description><author>Yijun Liang, Shweta Bhardwaj, Tianyi Zhou</author><pubDate>Wed, 24 Sep 2025 14:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13674v3</guid></item></channel></rss>