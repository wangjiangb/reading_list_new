<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 05 Nov 2025 05:19:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything</title><link>http://arxiv.org/abs/2511.02834v1</link><description>Multimodal large language models (MLLMs) have shown strong capabilities butremain limited to fixed modality pairs and require costly fine-tuning withlarge aligned datasets. Building fully omni-capable models that can integratetext, images, audio, and video remains impractical and lacks robust reasoningsupport. In this paper, we propose an Agent-Omni framework that coordinatesexisting foundation models through a master-agent system, enabling flexiblemultimodal reasoning without retraining. The master agent interprets userintent, delegates subtasks to modality-specific agents, and integrates theiroutputs into coherent responses. Extensive experiments across text, image,audio, video, and omni benchmarks show that Agent-Omni consistently achievesstate-of-the-art performance, particularly on tasks requiring complexcross-modal reasoning. Its agent-based design enables seamless integration ofspecialized foundation models, ensuring adaptability to diverse inputs whilemaintaining transparency and interpretability. In addition, the framework ismodular and easily extensible, allowing future improvements as stronger modelsbecome available. %We release an open-source implementation to supportcontinued research on scalable and reliable omni-modal reasoning.</description><author>Huawei Lin, Yunzhi Shi, Tong Geng, Weijie Zhao, Wei Wang, Ravender Pal Singh</author><pubDate>Tue, 04 Nov 2025 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02834v1</guid></item><item><title>Why and When Deep is Better than Shallow: An Implementation-Agnostic State-Transition View of Depth Supremacy</title><link>http://arxiv.org/abs/2505.15064v3</link><description>Why and when is deep better than shallow? We answer this question in aframework that is agnostic to network implementation. We formulate a deep modelas an abstract state-transition semigroup acting on a general metric space, andseparate the implementation (e.g., ReLU nets, transformers, andchain-of-thought) from the abstract state transition. We prove a bias-variancedecomposition in which the variance depends only on the abstract depth-$k$network and not on the implementation (Theorem 1). We further split the boundsinto output and hidden parts to tie the depth dependence of the variance to themetric entropy of the state-transition semigroup (Theorem 2). We theninvestigate implementation-free conditions under which the variance growpolynomially or logarithmically with depth (Section 4). Combining these withexponential or polynomial bias decay identifies four canonical bias-variancetrade-off regimes (EL/EP/PL/PP) and produces explicit optimal depths $k^\ast$.Across regimes, $k^\ast&gt;1$ typically holds, giving a rigorous form of depthsupremacy. The lowest generalization error bound is achieved under the ELregime (exp-decay bias + log-growth variance), explaining why and when deep isbetter, especially for iterative or hierarchical concept classes such as neuralODEs, diffusion/score-matching models, and chain-of-thought reasoning.</description><author>Sho Sonoda, Yuka Hashimoto, Isao Ishikawa, Masahiro Ikeda</author><pubDate>Tue, 04 Nov 2025 18:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15064v3</guid></item><item><title>In Good GRACEs: Principled Teacher Selection for Knowledge Distillation</title><link>http://arxiv.org/abs/2511.02833v1</link><description>Knowledge distillation is an efficient strategy to use data generated bylarge "teacher" language models to train smaller capable "student" models, butselecting the optimal teacher for a specific student-task combination requiresexpensive trial-and-error. We propose a lightweight score called GRACE toquantify how effective a teacher will be for post-training a student model.GRACE measures distributional properties of the student's gradients withoutaccess to a verifier, teacher logits, teacher internals, or test data. From aninformation-theoretic perspective, GRACE connects to leave-one-out stability ofgradient-based algorithms, which controls the generalization performance of thedistilled students. On GSM8K and MATH, GRACE correlates strongly (up to 86%Spearman correlation) with the performance of the distilled LLaMA and OLMostudents. In particular, training a student using the GRACE-selected teachercan improve the performance by up to 7.4% over naively using thebest-performing teacher. Further, GRACE can provide guidance on crucial designchoices in distillation, including (1) the best temperature to use whengenerating from the teacher, (2) the best teacher to use given a sizeconstraint, and (3) the best teacher to use within a specific model family.Altogether, our findings demonstrate that GRACE can efficiently and effectivelyidentify a strongly compatible teacher for a given student and providefine-grained guidance on how to perform distillation.</description><author>Abhishek Panigrahi, Bingbin Liu, Sadhika Malladi, Sham Kakade, Surbhi Goel</author><pubDate>Tue, 04 Nov 2025 18:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02833v1</guid></item><item><title>TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System</title><link>http://arxiv.org/abs/2511.02832v1</link><description>Large-scale data has driven breakthroughs in robotics, from language modelsto vision-language-action models in bimanual manipulation. However, humanoidrobotics lacks equally effective data collection frameworks. Existing humanoidteleoperation systems either use decoupled control or depend on expensivemotion capture setups. We introduce TWIST2, a portable, mocap-free humanoidteleoperation and data collection system that preserves full whole-body controlwhile advancing scalability. Our system leverages PICO4U VR for obtainingreal-time whole-body human motions, with a custom 2-DoF robot neck (cost around$250) for egocentric vision, enabling holistic human-to-humanoid control. Wedemonstrate long-horizon dexterous and mobile humanoid skills and we cancollect 100 demonstrations in 15 minutes with an almost 100% success rate.Building on this pipeline, we propose a hierarchical visuomotor policyframework that autonomously controls the full humanoid body based on egocentricvision. Our visuomotor policy successfully demonstrates whole-body dexterousmanipulation and dynamic kicking tasks. The entire system is fully reproducibleand open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is alsoopen-sourced at https://twist-data.github.io .</description><author>Yanjie Ze, Siheng Zhao, Weizhuo Wang, Angjoo Kanazawa, Rocky Duan, Pieter Abbeel, Guanya Shi, Jiajun Wu, C. Karen Liu</author><pubDate>Tue, 04 Nov 2025 18:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02832v1</guid></item><item><title>GeoCrossBench: Cross-Band Generalization for Remote Sensing</title><link>http://arxiv.org/abs/2511.02831v1</link><description>The number and diversity of remote sensing satellites grows over time, whilethe vast majority of labeled data comes from older satellites. As thefoundation models for Earth observation scale up, the cost of (re-)training tosupport new satellites grows too, so the generalization capabilities of themodels towards new satellites become increasingly important. In this work weintroduce GeoCrossBench, an extension of the popular GeoBench benchmark with anew evaluation protocol: it tests the in-distribution performance;generalization to satellites with no band overlap; and generalization tosatellites with additional bands with respect to the training set. We alsodevelop a self-supervised extension of ChannelViT, ChiViT, to improve itscross-satellite performance. First, we show that even the best foundationmodels for remote sensing (DOFA, TerraFM) do not outperform general purposemodels like DINOv3 in the in-distribution setting. Second, when generalizing tonew satellites with no band overlap, all models suffer 2-4x drop inperformance, and ChiViT significantly outperforms the runner-up DINOv3. Third,the performance of all tested models drops on average by 5-25\% when givenadditional bands during test time. Finally, we show that fine-tuning just thelast linear layer of these models using oracle labels from all bands can getrelatively consistent performance across all satellites, highlighting that thebenchmark is far from being saturated. We publicly release the code and thedatasets to encourage the development of more future-proof remote sensingmodels with stronger cross-satellite generalization.</description><author>Hakob Tamazyan, Ani Vanyan, Alvard Barseghyan, Anna Khosrovyan, Evan Shelhamer, Hrant Khachatrian</author><pubDate>Tue, 04 Nov 2025 18:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02831v1</guid></item><item><title>Densemarks: Learning Canonical Embeddings for Human Heads Images via Point Tracks</title><link>http://arxiv.org/abs/2511.02830v1</link><description>We propose DenseMarks - a new learned representation for human heads,enabling high-quality dense correspondences of human head images. For a 2Dimage of a human head, a Vision Transformer network predicts a 3D embedding foreach pixel, which corresponds to a location in a 3D canonical unit cube. Inorder to train our network, we collect a dataset of pairwise point matches,estimated by a state-of-the-art point tracker over a collection of diversein-the-wild talking heads videos, and guide the mapping via a contrastive loss,encouraging matched points to have close embeddings. We further employmulti-task learning with face landmarks and segmentation constraints, as wellas imposing spatial continuity of embeddings through latent cube features,which results in an interpretable and queryable canonical space. Therepresentation can be used for finding common semantic parts, face/headtracking, and stereo reconstruction. Due to the strong supervision, our methodis robust to pose variations and covers the entire head, including hair.Additionally, the canonical space bottleneck makes sure the obtainedrepresentations are consistent across diverse poses and individuals. Wedemonstrate state-of-the-art results in geometry-aware point matching andmonocular head tracking with 3D Morphable Models. The code and the modelcheckpoint will be made available to the public.</description><author>Dmitrii Pozdeev, Alexey Artemov, Ananta R. Bhattarai, Artem Sevastopolsky</author><pubDate>Tue, 04 Nov 2025 18:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02830v1</guid></item><item><title>Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning</title><link>http://arxiv.org/abs/2505.17830v3</link><description>Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomouslyacquire diverse behaviors, but faces major challenges in visual environmentsdue to high-dimensional, semantically sparse observations. In the onlinesetting, where agents learn representations while exploring, the latent spaceevolves with the agent's policy, to capture newly discovered areas of theenvironment. However, without incentivization to maximize state coverage in therepresentation, classical approaches based on auto-encoders may converge tolatent spaces that over-represent a restricted set of states frequently visitedby the agent. This is exacerbated in an intrinsic motivation setting, where theagent uses the distribution encoded in the latent space to sample the goals itlearns to master. To address this issue, we propose to progressively enforcedistributional shifts towards a uniform distribution over the full state space,to ensure a full coverage of skills that can be learned in the environment. Weintroduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method thatcombines the $\beta$-VAE framework with Distributionally Robust Optimization.DRAG leverages an adversarial neural weighter of training states of the VAE, toaccount for the mismatch between the current data distribution and unseen partsof the environment. This allows the agent to construct semantically meaningfullatent spaces beyond its immediate experience. Our approach improves statespace coverage and downstream control performance on hard explorationenvironments such as mazes and robotic control involving walls to bypass,without pre-training nor prior environment knowledge.</description><author>Nicolas Castanet, Olivier Sigaud, Sylvain Lamprier</author><pubDate>Tue, 04 Nov 2025 18:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17830v3</guid></item><item><title>PLUTO-4: Frontier Pathology Foundation Models</title><link>http://arxiv.org/abs/2511.02826v1</link><description>Foundation models trained on large-scale pathology image corpora havedemonstrated strong transfer capabilities across diverse histopathology tasks.Building on this progress, we introduce PLUTO-4, our next generation ofpathology foundation models that extend the Pathology-Universal Transformer(PLUTO) to frontier scale. We share two complementary Vision Transformerarchitectures in the PLUTO-4 family: a compact and efficient PLUTO-4S modeloptimized for multi-scale deployment using a FlexiViT setup with 2D-RoPEembeddings, and a frontier-scale PLUTO-4G model trained with a single patchsize to maximize representation capacity and stability. Both models arepretrained using a self-supervised objective derived from DINOv2 on a largemulti-institutional corpus containing 551,164 WSIs from 137,144 patients acrossover 50 institutions, spanning over 60 disease types and over 100 stains.Comprehensive evaluation across public and internal benchmarks demonstratesthat PLUTO-4 achieves state-of-the-art performance on tasks requiring varyingspatial and biological context, including patch-level classification,segmentation, and slide-level diagnosis. The compact PLUTO-4S provideshigh-throughput and robust performance for practical deployment, while PLUTO-4Gestablishes new performance frontiers across multiple pathology benchmarks,including an 11% improvement in dermatopathology diagnosis. These diverseimprovements underscore PLUTO-4's potential to transform real-worldapplications as a backbone for translational research and diagnostic use cases.</description><author>Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti, Ryun Han, Andrew Walker, Judy Shen, Chintan Shah, Blake Martin, Aashish Sood, Elliot Miller, Ben Glass, Andy Beck, Harsha Pokkalla, Syed Ashar Javed</author><pubDate>Tue, 04 Nov 2025 18:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02826v1</guid></item><item><title>Neurosymbolic Deep Learning Semantics</title><link>http://arxiv.org/abs/2511.02825v1</link><description>Artificial Intelligence (AI) is a powerful new language of science asevidenced by recent Nobel Prizes in chemistry and physics that recognizedcontributions to AI applied to those areas. Yet, this new language lackssemantics, which makes AI's scientific discoveries unsatisfactory at best. Withthe purpose of uncovering new facts but also improving our understanding of theworld, AI-based science requires formalization through a framework capable oftranslating insight into comprehensible scientific knowledge. In this paper, weargue that logic offers an adequate framework. In particular, we use logic in aneurosymbolic framework to offer a much needed semantics for deep learning, theneural network-based technology of current AI. Deep learning and neurosymbolicAI lack a general set of conditions to ensure that desirable properties aresatisfied. Instead, there is a plethora of encoding and knowledge extractionapproaches designed for particular cases. To rectify this, we introduced aframework for semantic encoding, making explicit the mapping between neuralnetworks and logic, and characterizing the common ingredients of the variousexisting approaches. In this paper, we describe succinctly and exemplify howlogical semantics and neural networks are linked through this framework, wereview some of the most prominent approaches and techniques developed forneural encoding and knowledge extraction, provide a formal definition of ourframework, and discuss some of the difficulties of identifying a semanticencoding in practice in light of analogous problems in the philosophy of mind.</description><author>Artur d'Avila Garcez, Simon Odense</author><pubDate>Tue, 04 Nov 2025 18:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02825v1</guid></item><item><title>Kosmos: An AI Scientist for Autonomous Discovery</title><link>http://arxiv.org/abs/2511.02824v1</link><description>Data-driven scientific discovery requires iterative cycles of literaturesearch, hypothesis generation, and data analysis. Substantial progress has beenmade towards AI agents that can automate scientific research, but all suchagents remain limited in the number of actions they can take before losingcoherence, thus limiting the depth of their findings. Here we present Kosmos,an AI scientist that automates data-driven discovery. Given an open-endedobjective and a dataset, Kosmos runs for up to 12 hours performing cycles ofparallel data analysis, literature search, and hypothesis generation beforesynthesizing discoveries into scientific reports. Unlike prior systems, Kosmosuses a structured world model to share information between a data analysisagent and a literature search agent. The world model enables Kosmos tocoherently pursue the specified objective over 200 agent rollouts, collectivelyexecuting an average of 42,000 lines of code and reading 1,500 papers per run.Kosmos cites all statements in its reports with code or primary literature,ensuring its reasoning is traceable. Independent scientists found 79.4% ofstatements in Kosmos reports to be accurate, and collaborators reported that asingle 20-cycle Kosmos run performed the equivalent of 6 months of their ownresearch time on average. Furthermore, collaborators reported that the numberof valuable scientific findings generated scales linearly with Kosmos cycles(tested up to 20 cycles). We highlight seven discoveries made by Kosmos thatspan metabolomics, materials science, neuroscience, and statistical genetics.Three discoveries independently reproduce findings from preprinted orunpublished manuscripts that were not accessed by Kosmos at runtime, while fourmake novel contributions to the scientific literature.</description><author>Ludovico Mitchener, Angela Yiu, Benjamin Chang, Mathieu Bourdenx, Tyler Nadolski, Arvis Sulovari, Eric C. Landsness, Daniel L. Barabasi, Siddharth Narayanan, Nicky Evans, Shriya Reddy, Martha Foiani, Aizad Kamal, Leah P. Shriver, Fang Cao, Asmamaw T. Wassie, Jon M. Laurent, Edwin Melville-Green, Mayk Caldas, Albert Bou, Kaleigh F. Roberts, Sladjana Zagorac, Timothy C. Orr, Miranda E. Orr, Kevin J. Zwezdaryk, Ali E. Ghareeb, Laurie McCoy, Bruna Gomes, Euan A. Ashley, Karen E. Duff, Tonio Buonassisi, Tom Rainforth, Randall J. Bateman, Michael Skarlinski, Samuel G. Rodriques, Michaela M. Hinks, Andrew D. White</author><pubDate>Tue, 04 Nov 2025 18:50:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02824v1</guid></item><item><title>Gene Regulatory Network Inference in the Presence of Selection Bias and Latent Confounders</title><link>http://arxiv.org/abs/2501.10124v2</link><description>Gene regulatory network inference (GRNI) aims to discover how genes causallyregulate each other from gene expression data. It is well-known thatstatistical dependencies in observed data do not necessarily imply causation,as spurious dependencies may arise from latent confounders, such as non-codingRNAs. Numerous GRNI methods have thus been proposed to address this confoundingissue. However, dependencies may also result from selection--only cellssatisfying certain survival or inclusion criteria are observed--while theseselection-induced spurious dependencies are frequently overlooked in geneexpression data analyses. In this work, we show that such selection isubiquitous and, when ignored or conflated with true regulations, can lead toflawed causal interpretation and misguided intervention recommendations. Toaddress this challenge, a fundamental question arises: can we distinguishdependencies due to regulation, confounding, and crucially, selection? We showthat gene perturbations offer a simple yet effective answer: selection-induceddependencies are symmetric under perturbation, while those from regulation orconfounding are not. Building on this motivation, we propose GISL (Generegulatory network Inference in the presence of Selection bias and Latentconfounders), a principled algorithm that leverages perturbation data touncover both true gene regulatory relations and non-regulatory mechanisms ofselection and confounding up to the equivalence class. Experiments on syntheticand real-world gene expression data demonstrate the effectiveness of ourmethod.</description><author>Gongxu Luo, Haoyue Dai, Loka Li, Chengqian Gao, Boyang Sun, Kun Zhang</author><pubDate>Tue, 04 Nov 2025 18:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10124v2</guid></item><item><title>Optimizing AI Agent Attacks With Synthetic Data</title><link>http://arxiv.org/abs/2511.02823v1</link><description>As AI deployments become more complex and high-stakes, it becomesincreasingly important to be able to estimate their risk. AI control is oneframework for doing so. However, good control evaluations require elicitingstrong attack policies. This can be challenging in complex agentic environmentswhere compute constraints leave us data-poor. In this work, we show how tooptimize attack policies in SHADE-Arena, a dataset of diverse realistic controlenvironments. We do this by decomposing attack capability into five constituentskills -- suspicion modeling, attack selection, plan synthesis, execution andsubtlety -- and optimizing each component individually. To get around theconstraint of limited data, we develop a probabilistic model of attackdynamics, optimize our attack hyperparameters using this simulation, and thenshow that the results transfer to SHADE-Arena. This results in a substantialimprovement in attack strength, reducing safety score from a baseline of 0.87to 0.41 using our scaffold.</description><author>Chloe Loughridge, Paul Colognese, Avery Griffin, Tyler Tracy, Jon Kutasov, Joe Benton</author><pubDate>Tue, 04 Nov 2025 18:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02823v1</guid></item><item><title>Accelerated Frank-Wolfe Algorithms: Complementarity Conditions and Sparsity</title><link>http://arxiv.org/abs/2511.02821v1</link><description>We develop new accelerated first-order algorithms in the Frank-Wolfe (FW)family for minimizing smooth convex functions over compact convex sets, with afocus on two prominent constraint classes: (1) polytopes and (2) matrix domainsgiven by the spectrahedron and the unit nuclear-norm ball. A key technicalingredient is a complementarity condition that captures solution sparsity --face dimension for polytopes and rank for matrices. We present two algorithms:(1) a purely linear optimization oracle (LOO) method for polytopes that hasoptimal worst-case first-order (FO) oracle complexity and, aside of a finite\emph{burn-in} phase and up to a logarithmic factor, has LOO complexity thatscales with $r/\sqrt{\epsilon}$, where $\epsilon$ is the target accuracy and$r$ is the solution sparsity $r$ (independently of the ambient dimension), and(2) a hybrid scheme that combines FW with a sparse projection oracle (e.g.,low-rank SVDs for matrix domains with low-rank solutions), which also hasoptimal FO oracle complexity, and after a finite burn-in phase, only requires$O(1/\sqrt{\epsilon})$ sparse projections and LOO calls (independently of boththe ambient dimension and the rank of optimal solutions). Our results close agap on how to accelerate recent advancements in linearly-converging FWalgorithms for strongly convex optimization, without paying the price of thedimension.</description><author>Dan Garber</author><pubDate>Tue, 04 Nov 2025 18:47:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02821v1</guid></item><item><title>ValueCompass: A Framework for Measuring Contextual Value Alignment Between Human and LLMs</title><link>http://arxiv.org/abs/2409.09586v3</link><description>As AI systems become more advanced, ensuring their alignment with a diverserange of individuals and societal values becomes increasingly critical. But howcan we capture fundamental human values and assess the degree to which AIsystems align with them? We introduce ValueCompass, a framework of fundamentalvalues, grounded in psychological theory and a systematic review, to identifyand evaluate human-AI alignment. We apply ValueCompass to measure the valuealignment of humans and large language models (LLMs) across four real-worldscenarios: collaborative writing, education, public sectors, and healthcare.Our findings reveal concerning misalignments between humans and LLMs, such ashumans frequently endorse values like "National Security" which were largelyrejected by LLMs. We also observe that values differ across scenarios,highlighting the need for context-aware AI alignment strategies. This workprovides valuable insights into the design space of human-AI alignment, layingthe foundations for developing AI systems that responsibly reflect societalvalues and ethics.</description><author>Hua Shen, Tiffany Knearem, Reshmi Ghosh, Yu-Ju Yang, Nicholas Clark, Tanushree Mitra, Yun Huang</author><pubDate>Tue, 04 Nov 2025 18:44:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09586v3</guid></item><item><title>Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning</title><link>http://arxiv.org/abs/2511.02818v1</link><description>Tabular data remain the predominant format for real-world applications. Yet,developing effective neural models for tabular data remains challenging due toheterogeneous feature types and complex interactions occurring at multiplescales. Recent advances in tabular in-context learning (ICL), such as TabPFNand TabICL, have achieved state-of-the-art performance comparable togradient-boosted trees (GBTs) without task-specific fine-tuning. However,current architectures exhibit key limitations: (1) single-scale featureprocessing that overlooks hierarchical dependencies, (2) dense attention withquadratic scaling in table width, and (3) strictly sequential componentprocessing that prevents iterative representation refinement andcross-component communication. To address these challenges, we introduceOrion-MSP, a tabular ICL architecture featuring three key innovations: (1)multi-scale processing to capture hierarchical feature interactions; (2)block-sparse attention combining windowed, global, and random patterns forscalable efficiency and long-range connectivity; and (3) a Perceiver-stylememory enabling safe bidirectional information flow across components. Acrossdiverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performancewhile scaling effectively to high-dimensional tables, establishing a newstandard for efficient tabular in-context learning. The model is publiclyavailable at https://github.com/Lexsi-Labs/Orion-MSP .</description><author>Mohamed Bouadi, Pratinav Seth, Aditya Tanna, Vinay Kumar Sankarapu</author><pubDate>Tue, 04 Nov 2025 18:43:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02818v1</guid></item><item><title>Hybrid Quantum-Classical Recurrent Neural Networks</title><link>http://arxiv.org/abs/2510.25557v2</link><description>We present a hybrid quantum-classical recurrent neural network (QRNN)architecture in which the recurrent core is realized as a parametrized quantumcircuit (PQC) controlled by a classical feedforward network. The hidden stateis the quantum state of an $n$-qubit PQC in an exponentially large Hilbertspace $\mathbb{C}^{2^n}$, which serves as a coherent recurrent quantum memory.The PQC is unitary by construction, making the hidden-state evolutionnorm-preserving without external constraints. At each timestep, mid-circuitPauli expectation-value readouts are combined with the input embedding andprocessed by the feedforward network, which provides explicit classicalnonlinearity. The outputs parametrize the PQC, which updates the hidden statevia unitary dynamics. The QRNN is compact and physically consistent, and itunifies (i) unitary recurrence as a high-capacity memory, (ii) partialobservation via mid-circuit readouts, and (iii) nonlinear classical control forinput-conditioned parametrization. We evaluate the model in simulation with upto 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, andlanguage modeling. For sequence-to-sequence learning, we further devise a softattention mechanism over the mid-circuit readouts and show its effectivenessfor machine translation. To our knowledge, this is the first model (RNN orotherwise) grounded in quantum operations to achieve competitive performanceagainst strong classical baselines across a broad class of sequence-learningtasks.</description><author>Wenduan Xu</author><pubDate>Tue, 04 Nov 2025 18:43:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.25557v2</guid></item><item><title>Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities</title><link>http://arxiv.org/abs/2511.02817v1</link><description>As model context lengths continue to grow, concerns about whether modelseffectively use the full context length have persisted. While several carefullydesigned long-context evaluations have recently been released, theseevaluations tend to rely on retrieval from one or more sections of the context,which allows nearly all of the context tokens to be disregarded as noise. Thisrepresents only one type of task that might be performed with long context. Weintroduce Oolong, a benchmark of long-context reasoning tasks that requireanalyzing individual chunks of text on an atomic level, and then aggregatingthese analyses to answer distributional questions. Oolong is separated into twotask sets: Oolong-synth, a set of naturalistic synthetic tasks, where we caneasily ablate components of the reasoning problem; and Oolong-real, adownstream setting which requires reasoning over real-world conversationaldata. Oolong requires models to reason over large quantities of examples, toperform both classification and counting in-context, and to reason overtemporal and user relations. Even frontier models struggle on Oolong, withGPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracyon both splits at 128K. We release the data and evaluation harness for Oolongto enable further development of models that can reason over large quantitiesof text.</description><author>Amanda Bertsch, Adithya Pratapa, Teruko Mitamura, Graham Neubig, Matthew R. Gormley</author><pubDate>Tue, 04 Nov 2025 18:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02817v1</guid></item><item><title>Assessing win strength in MLB win prediction models</title><link>http://arxiv.org/abs/2511.02815v1</link><description>In Major League Baseball, strategy and planning are major factors indetermining the outcome of a game. Previous studies have aided this by buildingmachine learning models for predicting the winning team of any given game. Weextend this work by training a comprehensive set of machine learning modelsusing a common dataset. In addition, we relate the win probabilities producedby these models to win strength as measured by score differential. In doing sowe show that the most common machine learning models do indeed demonstrate arelationship between predicted win probability and the strength of the win.Finally, we analyze the results of using predicted win probabilities as adecision making mechanism on run-line betting. We demonstrate positive returnswhen utilizing appropriate betting strategies, and show that naive use ofmachine learning models for betting lead to significant loses.</description><author>Morgan Allen, Paul Savala</author><pubDate>Tue, 04 Nov 2025 18:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02815v1</guid></item><item><title>MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning</title><link>http://arxiv.org/abs/2511.02805v1</link><description>Typical search agents concatenate the entire interaction history into the LLMcontext, preserving information integrity but producing long, noisy contexts,resulting in high computation and memory costs. In contrast, using only thecurrent turn avoids this overhead but discards essential information. Thistrade-off limits the scalability of search agents. To address this challenge,we propose MemSearcher, an agent workflow that iteratively maintains a compactmemory and combines the current turn with it. At each turn, MemSearcher fusesthe user's question with the memory to generate reasoning traces, performsearch actions, and update memory to retain only information essential forsolving the task. This design stabilizes context length across multi-turninteractions, improving efficiency without sacrificing accuracy. To optimizethis workflow, we introduce multi-context GRPO, an end-to-end RL framework thatjointly optimize reasoning, search strategies, and memory management ofMemSearcher Agents. Specifically, multi-context GRPO samples groups oftrajectories under different contexts and propagates trajectory-leveladvantages across all conversations within them. Trained on the same dataset asSearch-R1, MemSearcher achieves significant improvements over strong baselineson seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% onQwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearchereven outperforms 7B-based baselines, demonstrating that striking a balancebetween information integrity and efficiency yields both higher accuracy andlower computational overhead. The code and models will be publicly available athttps://github.com/icip-cas/MemSearcher</description><author>Qianhao Yuan, Jie Lou, Zichao Li, Jiawei Chen, Yaojie Lu, Hongyu Lin, Le Sun, Debing Zhang, Xianpei Han</author><pubDate>Tue, 04 Nov 2025 18:27:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02805v1</guid></item><item><title>TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models</title><link>http://arxiv.org/abs/2511.02802v1</link><description>Tabular foundation models represent a growing paradigm in structured datalearning, extending the benefits of large-scale pretraining to tabular domains.However, their adoption remains limited due to heterogeneous preprocessingpipelines, fragmented APIs, inconsistent fine-tuning procedures, and theabsence of standardized evaluation for deployment-oriented metrics such ascalibration and fairness. We present TabTune, a unified library thatstandardizes the complete workflow for tabular foundation models through asingle interface. TabTune provides consistent access to seven state-of-the-artmodels supporting multiple adaptation strategies, including zero-shotinference, meta-learning, supervised fine-tuning (SFT), and parameter-efficientfine-tuning (PEFT). The framework automates model-aware preprocessing, managesarchitectural heterogeneity internally, and integrates evaluation modules forperformance, calibration, and fairness. Designed for extensibility andreproducibility, TabTune enables consistent benchmarking of adaptationstrategies of tabular foundation models. The library is open source andavailable at https://github.com/Lexsi-Labs/TabTune .</description><author>Aditya Tanna, Pratinav Seth, Mohamed Bouadi, Utsav Avaiya, Vinay Kumar Sankarapu</author><pubDate>Tue, 04 Nov 2025 18:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02802v1</guid></item><item><title>GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality</title><link>http://arxiv.org/abs/2510.11878v2</link><description>As the demand for immersive 3D content grows, the need for intuitive andefficient interaction methods becomes paramount. Current techniques forphysically manipulating 3D content within Virtual Reality (VR) often facesignificant limitations, including reliance on engineering-intensive processesand simplified geometric representations, such as tetrahedral cages, which cancompromise visual fidelity and physical accuracy. In this paper, we introduceGS-Verse (Gaussian Splatting for Virtual Environment Rendering and SceneEditing), a novel method designed to overcome these challenges by directlyintegrating an object's mesh with a Gaussian Splatting (GS) representation. Ourapproach enables more precise surface approximation, leading to highlyrealistic deformations and interactions. By leveraging existing 3D mesh assets,GS-Verse facilitates seamless content reuse and simplifies the developmentworkflow. Moreover, our system is designed to be physics-engine-agnostic,granting developers robust deployment flexibility. This versatile architecturedelivers a highly realistic, adaptable, and intuitive approach to interactive3D manipulation. We rigorously validate our method against the currentstate-of-the-art technique that couples VR with GS in a comparative user studyinvolving 18 participants. Specifically, we demonstrate that our approach isstatistically significantly better for physics-aware stretching manipulationand is also more consistent in other physics-based manipulations like twistingand shaking. Further evaluation across various interactions and scenes confirmsthat our method consistently delivers high and reliable performance, showingits potential as a plausible alternative to existing methods.</description><author>Anastasiya Pechko, Piotr Borycki, Joanna Waczyńska, Daniel Barczyk, Agata Szymańska, Sławomir Tadeja, Przemysław Spurek</author><pubDate>Tue, 04 Nov 2025 18:24:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.11878v2</guid></item><item><title>Program Synthesis Dialog Agents for Interactive Decision-Making</title><link>http://arxiv.org/abs/2502.19610v3</link><description>Many real-world eligibility problems, ranging from medical diagnosis to taxplanning, can be mapped to decision problems expressed in natural language,wherein a model must make a binary choice based on user features. Large-scaledomains such as legal codes or frequently updated funding opportunities renderhuman annotation (e.g., web forms or decision trees) impractical, highlightingthe need for agents that can automatically assist in decision-making. Sincerelevant information is often only known to the user, it is crucial that theseagents ask the right questions. As agents determine when to terminate aconversation, they face a trade-off between accuracy and the number ofquestions asked, a key metric for both user experience and cost. To evaluatethis task, we propose BeNYfits, a new benchmark for determining usereligibility for multiple overlapping social benefits opportunities throughinteractive decision-making. Our experiments show that current language modelsstruggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using aReAct-style chain-of-thought. To address this, we introduce ProADA, a novelapproach that leverages program synthesis to assist in decision-making bymapping dialog planning to a code generation problem and using gaps instructured data to determine the best next action. Our agent, ProADA, improvesthe F1 score to 55.6 while maintaining nearly the same number of dialog turns.</description><author>Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu</author><pubDate>Tue, 04 Nov 2025 18:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.19610v3</guid></item><item><title>Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning</title><link>http://arxiv.org/abs/2511.02797v1</link><description>Federated Learning (FL) is a distributed training paradigm whereinparticipants collaborate to build a global model while ensuring the privacy ofthe involved data, which remains stored on participant devices. However,proposals aiming to ensure such privacy also make it challenging to protectagainst potential attackers seeking to compromise the training outcome. In thiscontext, we present Fast, Private, and Protected (FPP), a novel approach thataims to safeguard federated training while enabling secure aggregation topreserve data privacy. This is accomplished by evaluating rounds usingparticipants' assessments and enabling training recovery after an attack. FPPalso employs a reputation-based mechanism to mitigate the participation ofattackers. We created a dockerized environment to validate the performance ofFPP compared to other approaches in the literature (FedAvg, Power-of-Choice,and aggregation via Trimmed Mean and Median). Our experiments demonstrate thatFPP achieves a rapid convergence rate and can converge even in the presence ofmalicious participants performing model poisoning attacks.</description><author>Nicolas Riccieri Gardin Assumpcao, Leandro Villas</author><pubDate>Tue, 04 Nov 2025 18:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02797v1</guid></item><item><title>Can LLMs subtract numbers?</title><link>http://arxiv.org/abs/2511.02795v1</link><description>We present a systematic study of subtraction in large language models (LLMs).While prior benchmarks emphasize addition and multiplication, subtraction hasreceived comparatively little attention despite being structurally distinct asa non-commutative operation. We evaluate eight pretrained LLMs spanning fourfamilies on addition and subtraction problems. Our experiments reveal thatsubtraction accuracy lags behind addition by a wide margin. We find that theerrors for ($a-b$) are concentrated in cases where ($a&lt;b$). In such cases, LLMsfrequently produce the correct magnitude but omit the negative sign. Probinganalyses show that LLMs internally encode whether results should be negative,yet this information is often not reflected in generated outputs. We furthertest well-known techniques such as few-shot learning and instruction-tuning tosee if they can improve the LLMs' performance. Our results suggest that whilefew-shot prompting yields modest gains, the instruction-tuned models achievenear-perfect accuracies in generating the negative sign. Together, thesefindings provide a clearer characterization of the limitations andrecoverability of LLMs' arithmetic capabilities in subtraction.</description><author>Mayank Jobanputra, Nils Philipp Walter, Maitrey Mehta, Blerta Veseli, Evan Parker Kelly Chapple, Yifan Wang, Sneha Chetani, Ellie Pavlick, Antonio Vergari, Vera Demberg</author><pubDate>Tue, 04 Nov 2025 18:20:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02795v1</guid></item><item><title>When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning</title><link>http://arxiv.org/abs/2511.02794v1</link><description>Despite rapid growth in multimodal large language models (MLLMs), theirreasoning traces remain opaque: it is often unclear which modality drives aprediction, how conflicts are resolved, or when one stream dominates. In thispaper, we introduce modality sabotage, a diagnostic failure mode in which ahigh-confidence unimodal error overrides other evidence and misleads the fusedresult. To analyze such dynamics, we propose a lightweight, model-agnosticevaluation layer that treats each modality as an agent, producing candidatelabels and a brief self-assessment used for auditing. A simple fusion mechanismaggregates these outputs, exposing contributors (modalities supporting correctoutcomes) and saboteurs (modalities that mislead). Applying our diagnosticlayer in a case study on multimodal emotion recognition benchmarks withfoundation models revealed systematic reliability profiles, providing insightinto whether failures may arise from dataset artifacts or model limitations.More broadly, our framework offers a diagnostic scaffold for multimodalreasoning, supporting principled auditing of fusion dynamics and informingpossible interventions.</description><author>Chenyu Zhang, Minsol Kim, Shohreh Ghorbani, Jingyao Wu, Rosalind Picard, Patricia Maes, Paul Pu Liang</author><pubDate>Tue, 04 Nov 2025 18:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02794v1</guid></item><item><title>Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark</title><link>http://arxiv.org/abs/2510.26802v1</link><description>Recent video generation models can produce high-fidelity, temporally coherentvideos, indicating that they may encode substantial world knowledge. Beyondrealistic synthesis, they also exhibit emerging behaviors indicative of visualperception, modeling, and manipulation. Yet, an important question stillremains: Are video models ready to serve as zero-shot reasoners in challengingvisual reasoning scenarios? In this work, we conduct an empirical study tocomprehensively investigate this question, focusing on the leading and popularVeo-3. We evaluate its reasoning behavior across 12 dimensions, includingspatial, geometric, physical, temporal, and embodied logic, systematicallycharacterizing both its strengths and failure modes. To standardize this study,we curate the evaluation data into MME-CoF, a compact benchmark that enablesin-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Ourfindings reveal that while current video models demonstrate promising reasoningpatterns on short-horizon spatial coherence, fine-grained grounding, andlocally consistent dynamics, they remain limited in long-horizon causalreasoning, strict geometric constraints, and abstract logic. Overall, they arenot yet reliable as standalone zero-shot reasoners, but exhibit encouragingsigns as complementary visual engines alongside dedicated reasoning models.Project page: https://video-cof.github.io</description><author>Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng</author><pubDate>Thu, 30 Oct 2025 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26802v1</guid></item><item><title>OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes</title><link>http://arxiv.org/abs/2510.26800v1</link><description>There are two prevalent ways to constructing 3D scenes: procedural generationand 2D lifting. Among them, panorama-based 2D lifting has emerged as apromising technique, leveraging powerful 2D generative priors to produceimmersive, realistic, and diverse 3D environments. In this work, we advancethis technique to generate graphics-ready 3D scenes suitable for physicallybased rendering (PBR), relighting, and simulation. Our key insight is torepurpose 2D generative models for panoramic perception of geometry, textures,and PBR materials. Unlike existing 2D lifting approaches that emphasizeappearance generation and ignore the perception of intrinsic properties, wepresent OmniX, a versatile and unified framework. Based on a lightweight andefficient cross-modal adapter structure, OmniX reuses 2D generative priors fora broad range of panoramic vision tasks, including panoramic perception,generation, and completion. Furthermore, we construct a large-scale syntheticpanorama dataset containing high-quality multimodal panoramas from diverseindoor and outdoor scenes. Extensive experiments demonstrate the effectivenessof our model in panoramic visual perception and graphics-ready 3D scenegeneration, opening new possibilities for immersive and physically realisticvirtual world generation.</description><author>Yukun Huang, Jiwen Yu, Yanning Zhou, Jianan Wang, Xintao Wang, Pengfei Wan, Xihui Liu</author><pubDate>Thu, 30 Oct 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26800v1</guid></item><item><title>UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection</title><link>http://arxiv.org/abs/2506.03237v2</link><description>The detection of ligand binding sites for proteins is a fundamental step inStructure-Based Drug Design. Despite notable advances in recent years, existingmethods, datasets, and evaluation metrics are confronted with several keychallenges: (1) current datasets and methods are centered on individualprotein-ligand complexes and neglect that diverse binding sites may existacross multiple complexes of the same protein, introducing significantstatistical bias; (2) ligand binding site detection is typically modeled as adiscontinuous workflow, employing binary segmentation and subsequent clusteringalgorithms; (3) traditional evaluation metrics do not adequately reflect theactual performance of different binding site prediction methods. To addressthese issues, we first introduce UniSite-DS, the first UniProt (UniqueProtein)-centric ligand binding site dataset, which contains 4.81 times moremulti-site data and 2.08 times more overall data compared to the previouslymost widely used datasets. We then propose UniSite, the first end-to-end ligandbinding site detection framework supervised by set prediction loss withbijective matching. In addition, we introduce Average Precision based onIntersection over Union (IoU) as a more accurate evaluation metric for ligandbinding site prediction. Extensive experiments on UniSite-DS and severalrepresentative benchmark datasets demonstrate that IoU-based Average Precisionprovides a more accurate reflection of prediction quality, and that UniSiteoutperforms current state-of-the-art methods in ligand binding site detection.The dataset and codes will be made publicly available athttps://github.com/quanlin-wu/unisite.</description><author>Jigang Fan, Quanlin Wu, Shengjie Luo, Liwei Wang</author><pubDate>Thu, 30 Oct 2025 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.03237v2</guid></item><item><title>Masked Diffusion Captioning for Visual Feature Learning</title><link>http://arxiv.org/abs/2510.26799v1</link><description>We learn visual features by captioning images with an image-conditionedmasked diffusion language model, a formulation we call masked diffusioncaptioning (MDC). During training, text tokens in each image-caption pair aremasked at a randomly chosen ratio, and a decoder conditioned on visual featuresis trained to reconstruct the original text. After training, the learned visualfeatures can be applied to downstream vision tasks. Unlike autoregressivecaptioning, the strength of the visual learning signal in MDC does not dependon each token's position in the sequence, reducing the need for auxiliaryobjectives. Linear probing experiments across a variety of academic-scalemodels and datasets show that the learned visual features are competitive withthose produced by autoregressive and contrastive approaches.</description><author>Chao Feng, Zihao Wei, Andrew Owens</author><pubDate>Thu, 30 Oct 2025 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26799v1</guid></item><item><title>SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting</title><link>http://arxiv.org/abs/2510.26796v1</link><description>Immersive applications call for synthesizing spatiotemporal 4D content fromcasual videos without costly 3D supervision. Existing video-to-4D methodstypically rely on manually annotated camera poses, which are labor-intensiveand brittle for in-the-wild footage. Recent warp-then-inpaint approachesmitigate the need for pose labels by warping input frames along a novel cameratrajectory and using an inpainting model to fill missing regions, therebydepicting the 4D scene from diverse viewpoints. However, thistrajectory-to-trajectory formulation often entangles camera motion with scenedynamics and complicates both modeling and inference. We introduce SEE4D, apose-free, trajectory-to-camera framework that replaces explicit trajectoryprediction with rendering to a bank of fixed virtual cameras, therebyseparating camera control from scene modeling. A view-conditional videoinpainting model is trained to learn a robust geometry prior by denoisingrealistically synthesized warped images and to inpaint occluded or missingregions across virtual viewpoints, eliminating the need for explicit 3Dannotations. Building on this inpainting core, we design a spatiotemporalautoregressive inference pipeline that traverses virtual-camera splines andextends videos with overlapping windows, enabling coherent generation atbounded per-step complexity. We validate See4D on cross-view video generationand sparse reconstruction benchmarks. Across quantitative metrics andqualitative assessments, our method achieves superior generalization andimproved performance relative to pose- or trajectory-conditioned baselines,advancing practical 4D world modeling from casual videos.</description><author>Dongyue Lu, Ao Liang, Tianxin Huang, Xiao Fu, Yuyang Zhao, Baorui Ma, Liang Pan, Wei Yin, Lingdong Kong, Wei Tsang Ooi, Ziwei Liu</author><pubDate>Thu, 30 Oct 2025 17:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26796v1</guid></item><item><title>Scaling Image Geo-Localization to Continent Level</title><link>http://arxiv.org/abs/2510.26795v1</link><description>Determining the precise geographic location of an image at a global scaleremains an unsolved challenge. Standard image retrieval techniques areinefficient due to the sheer volume of images (&gt;100M) and fail when coverage isinsufficient. Scalable solutions, however, involve a trade-off: globalclassification typically yields coarse results (10+ kilometers), whilecross-view retrieval between ground and aerial imagery suffers from a domaingap and has been primarily studied on smaller regions. This paper introduces ahybrid approach that achieves fine-grained geo-localization across a largegeographic expanse the size of a continent. We leverage a proxy classificationtask during training to learn rich feature representations that implicitlyencode precise location information. We combine these learned prototypes withembeddings of aerial imagery to increase robustness to the sparsity ofground-level data. This enables direct, fine-grained retrieval over areasspanning multiple countries. Our extensive evaluation demonstrates that ourapproach can localize within 200m more than 68\% of queries of a datasetcovering a large part of Europe. The code is publicly available athttps://scaling-geoloc.github.io.</description><author>Philipp Lindenberger, Paul-Edouard Sarlin, Jan Hosang, Matteo Balice, Marc Pollefeys, Simon Lynen, Eduard Trulls</author><pubDate>Thu, 30 Oct 2025 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26795v1</guid></item><item><title>The Quest for Generalizable Motion Generation: Data, Model, and Evaluation</title><link>http://arxiv.org/abs/2510.26794v1</link><description>Despite recent advances in 3D human motion generation (MoGen) on standardbenchmarks, existing models still face a fundamental bottleneck in theirgeneralization capability. In contrast, adjacent generative fields, mostnotably video generation (ViGen), have demonstrated remarkable generalizationin modeling human behaviors, highlighting transferable insights that MoGen canleverage. Motivated by this observation, we present a comprehensive frameworkthat systematically transfers knowledge from ViGen to MoGen across three keypillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, alarge-scale dataset comprising 228,000 high-quality motion samples thatintegrates high-fidelity optical MoCap data with semantically annotated motionsfrom web videos and synthesized samples generated by state-of-the-art ViGenmodels. The dataset includes both text-motion pairs and text-video-motiontriplets, substantially expanding semantic diversity. Second, we proposeViMoGen, a flow-matching-based diffusion transformer that unifies priors fromMoCap data and ViGen models through gated multimodal conditioning. To enhanceefficiency, we further develop ViMoGen-light, a distilled variant thateliminates video generation dependencies while preserving stronggeneralization. Finally, we present MBench, a hierarchical benchmark designedfor fine-grained evaluation across motion quality, prompt fidelity, andgeneralization ability. Extensive experiments show that our frameworksignificantly outperforms existing approaches in both automatic and humanevaluations. The code, data, and benchmark will be made publicly available.</description><author>Jing Lin, Ruisi Wang, Junzhe Lu, Ziqi Huang, Guorui Song, Ailing Zeng, Xian Liu, Chen Wei, Wanqi Yin, Qingping Sun, Zhongang Cai, Lei Yang, Ziwei Liu</author><pubDate>Thu, 30 Oct 2025 17:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26794v1</guid></item><item><title>Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability</title><link>http://arxiv.org/abs/2510.26792v1</link><description>We study the ability of Transformer models to learn sequences generated byPermuted Congruential Generators (PCGs), a widely used family of pseudo-randomnumber generators (PRNGs). PCGs introduce substantial additional difficultyover linear congruential generators (LCGs) by applying a series of bit-wiseshifts, XORs, rotations and truncations to the hidden state. We show thatTransformers can nevertheless successfully perform in-context prediction onunseen sequences from diverse PCG variants, in tasks that are beyond publishedclassical attacks. In our experiments we scale moduli up to $2^{22}$ using upto $50$ million model parameters and datasets with up to $5$ billion tokens.Surprisingly, we find even when the output is truncated to a single bit, it canbe reliably predicted by the model. When multiple distinct PRNGs are presentedtogether during training, the model can jointly learn them, identifyingstructures from different permutations. We demonstrate a scaling law withmodulus $m$: the number of in-context sequence elements required fornear-perfect prediction grows as $\sqrt{m}$. For larger moduli, optimizationenters extended stagnation phases; in our experiments, learning moduli $m \geq2^{20}$ requires incorporating training data from smaller moduli, demonstratinga critical necessity for curriculum learning. Finally, we analyze embeddinglayers and uncover a novel clustering phenomenon: the model spontaneouslygroups the integer inputs into bitwise rotationally-invariant clusters,revealing how representations can transfer from smaller to larger moduli.</description><author>Tao Tao, Maissam Barkeshli</author><pubDate>Thu, 30 Oct 2025 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26792v1</guid></item><item><title>Gistify! Codebase-Level Understanding via Runtime Execution</title><link>http://arxiv.org/abs/2510.26790v1</link><description>As coding agents are increasingly deployed in large codebases, the need toautomatically design challenging, codebase-level evaluation is central. Wepropose Gistify, a task where a coding LLM must create a single, minimal,self-contained file that can reproduce a specific functionality of a codebase.The coding LLM is given full access to a codebase along with a specificentrypoint (e.g., a python command), and the generated file must replicate theoutput of the same command ran under the full codebase, while containing onlythe essential components necessary to execute the provided command. Success onGistify requires both structural understanding of the codebase, accuratemodeling of its execution flow as well as the ability to produce potentiallylarge code patches. Our findings show that current state-of-the-art modelsstruggle to reliably solve Gistify tasks, especially ones with long executionstraces.</description><author>Hyunji Lee, Minseon Kim, Chinmay Singh, Matheus Pereira, Atharv Sonwane, Isadora White, Elias Stengel-Eskin, Mohit Bansal, Zhengyan Shi, Alessandro Sordoni, Marc-Alexandre Côté, Xingdi Yuan, Lucas Caccia</author><pubDate>Thu, 30 Oct 2025 17:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26790v1</guid></item><item><title>Defeating the Training-Inference Mismatch via FP16</title><link>http://arxiv.org/abs/2510.26788v1</link><description>Reinforcement learning (RL) fine-tuning of large language models (LLMs) oftensuffers from instability due to the numerical mismatch between the training andinference policies. While prior work has attempted to mitigate this issuethrough algorithmic corrections or engineering alignments, we show that itsroot cause lies in the floating point precision itself. The widely adoptedBF16, despite its large dynamic range, introduces large rounding errors thatbreaks the consistency between training and inference. In this work, wedemonstrate that simply reverting to \textbf{FP16} effectively eliminates thismismatch. The change is simple, fully supported by modern frameworks with onlya few lines of code change, and requires no modification to the modelarchitecture or learning algorithm. Our results suggest that using FP16uniformly yields more stable optimization, faster convergence, and strongerperformance across diverse tasks, algorithms and frameworks. We hope thesefindings motivate a broader reconsideration of precision trade-offs in RLfine-tuning.</description><author>Penghui Qi, Zichen Liu, Xiangxin Zhou, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin</author><pubDate>Thu, 30 Oct 2025 17:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26788v1</guid></item><item><title>Remote Labor Index: Measuring AI Automation of Remote Work</title><link>http://arxiv.org/abs/2510.26787v1</link><description>AIs have made rapid progress on research-oriented benchmarks of knowledge andreasoning, but it remains unclear how these gains translate into economic valueand automation. To measure this, we introduce the Remote Labor Index (RLI), abroadly multi-sector benchmark comprising real-world, economically valuableprojects designed to evaluate end-to-end agent performance in practicalsettings. AI agents perform near the floor on RLI, with the highest-performingagent achieving an automation rate of 2.5%. These results help grounddiscussions of AI automation in empirical evidence, setting a common basis fortracking AI impacts and enabling stakeholders to proactively navigate AI-drivenlabor automation.</description><author>Mantas Mazeika, Alice Gatti, Cristina Menghini, Udari Madhushani Sehwag, Shivam Singhal, Yury Orlovskiy, Steven Basart, Manasi Sharma, Denis Peskoff, Elaine Lau, Jaehyuk Lim, Lachlan Carroll, Alice Blair, Vinaya Sivakumar, Sumana Basu, Brad Kenstler, Yuntao Ma, Julian Michael, Xiaoke Li, Oliver Ingebretsen, Aditya Mehta, Jean Mottola, John Teichmann, Kevin Yu, Zaina Shaik, Adam Khoja, Richard Ren, Jason Hausenloy, Long Phan, Ye Htet, Ankit Aich, Tahseen Rabbani, Vivswan Shah, Andriy Novykov, Felix Binder, Kirill Chugunov, Luis Ramirez, Matias Geralnik, Hernán Mesura, Dean Lee, Ed-Yeremai Hernandez Cardona, Annette Diamond, Summer Yue, Alexandr Wang, Bing Liu, Ernesto Hernandez, Dan Hendrycks</author><pubDate>Thu, 30 Oct 2025 17:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26787v1</guid></item><item><title>HEIR: Learning Graph-Based Motion Hierarchies</title><link>http://arxiv.org/abs/2510.26786v1</link><description>Hierarchical structures of motion exist across research fields, includingcomputer vision, graphics, and robotics, where complex dynamics typically arisefrom coordinated interactions among simpler motion components. Existing methodsto model such dynamics typically rely on manually-defined or heuristichierarchies with fixed motion primitives, limiting their generalizabilityacross different tasks. In this work, we propose a general hierarchical motionmodeling method that learns structured, interpretable motion relationshipsdirectly from data. Our method represents observed motions using graph-basedhierarchies, explicitly decomposing global absolute motions intoparent-inherited patterns and local motion residuals. We formulate hierarchyinference as a differentiable graph learning problem, where vertices representelemental motions and directed edges capture learned parent-child dependenciesthrough graph neural networks. We evaluate our hierarchical reconstructionapproach on three examples: 1D translational motion, 2D rotational motion, anddynamic 3D scene deformation via Gaussian splatting. Experimental results showthat our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,and produces more realistic and interpretable deformations compared to thebaseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,data-driven hierarchical modeling paradigm, our method offers a formulationapplicable to a broad range of motion-centric tasks. Project Page:https://light.princeton.edu/HEIR/</description><author>Cheng Zheng, William Koch, Baiang Li, Felix Heide</author><pubDate>Thu, 30 Oct 2025 17:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26786v1</guid></item><item><title>LLMs Process Lists With General Filter Heads</title><link>http://arxiv.org/abs/2510.26784v1</link><description>We investigate the mechanisms underlying a range of list-processing tasks inLLMs, and we find that LLMs have learned to encode a compact, causalrepresentation of a general filtering operation that mirrors the generic"filter" function of functional programming. Using causal mediation analysis ona diverse set of list-processing tasks, we find that a small number ofattention heads, which we dub filter heads, encode a compact representation ofthe filtering predicate in their query states at certain tokens. We demonstratethat this predicate representation is general and portable: it can be extractedand reapplied to execute the same filtering operation on different collections,presented in different formats, languages, or even in tasks. However, we alsoidentify situations where transformer LMs can exploit a different strategy forfiltering: eagerly evaluating if an item satisfies the predicate and storingthis intermediate result as a flag directly in the item representations. Ourresults reveal that transformer LMs can develop human-interpretableimplementations of abstract computational operations that generalize in waysthat are surprisingly similar to strategies used in traditional functionalprogramming patterns.</description><author>Arnab Sen Sharma, Giordano Rogers, Natalie Shapira, David Bau</author><pubDate>Thu, 30 Oct 2025 17:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26784v1</guid></item><item><title>TinyTim: A Family of Language Models for Divergent Generation</title><link>http://arxiv.org/abs/2508.11607v2</link><description>In the search for artificial general intelligence, model development andtraining has focused primarily on vast datasets of known problems and theiraccepted solutions. This process necessarily produces convergent systems whichare fundamentally incapable of the conceptual reframing that is required forgenuine creative breakthroughs. Inspired by the divergent cognitive processesthat allow humans to make such creative leaps, our work introduces a family oflanguage models, TinyTim, to serve as sources of divergent generation withinbroader systems. These models have been created by fine-tuning on theanti-parsimonious text of James Joyce's `Finnegans Wake'. Quantitative analysisof both an unsupervised fine-tuned model (TinyTim-V1) and a newinstruction-tuned variant (TinyTim-V2) demonstrates a profound capacity forlexical invention; the foundational V1 model exhibits a Yule's K score forlexical richness over twenty times greater than that of convergent baselines.This trait is a stable property of the family, as the instruction-tuned V2maintains a statistically distinct profile and resists factual convergence,sacrificing benchmark performance to preserve its core generative style. Thiswork establishes a methodology for engineering specialized divergent modelsthat, when paired with convergent systems, can reframe problems and forcebreakthroughs beyond the reach of statistical optimization alone.</description><author>Christopher J. Agostino</author><pubDate>Thu, 30 Oct 2025 17:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11607v2</guid></item><item><title>A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</title><link>http://arxiv.org/abs/2510.26783v1</link><description>This note introduces a unified theory for causal inference that integratesRiesz regression, covariate balancing, density-ratio estimation (DRE), targetedmaximum likelihood estimation (TMLE), and the matching estimator in averagetreatment effect (ATE) estimation. In ATE estimation, the balancing weights andthe regression functions of the outcome play important roles, where thebalancing weights are referred to as the Riesz representer, bias-correctionterm, and clever covariates, depending on the context. Riesz regression,covariate balancing, DRE, and the matching estimator are methods for estimatingthe balancing weights, where Riesz regression is essentially equivalent to DREin the ATE context, the matching estimator is a special case of DRE, and DRE isin a dual relationship with covariate balancing. TMLE is a method forconstructing regression function estimators such that the leading bias termbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares DensityRatio Estimation and Riesz Regression.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26783v1</guid></item><item><title>Clone Deterministic 3D Worlds with Geometrically-Regularized World Models</title><link>http://arxiv.org/abs/2510.26782v1</link><description>A world model is an internal model that simulates how the world evolves.Given past observations and actions, it predicts the future of both theembodied agent and its environment. Accurate world models are essential forenabling agents to think, plan, and reason effectively in complex, dynamicsettings. Despite rapid progress, current world models remain brittle anddegrade over long horizons. We argue that a central cause is representationquality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy orentangled latents make dynamics learning unnecessarily hard. We therefore askwhether improving representation learning alone can substantially improveworld-model performance. In this work, we take a step toward building a trulyaccurate world model by addressing a fundamental yet open problem: constructinga model that can fully clone and overfit to a deterministic 3D world. Wepropose Geometrically-Regularized World Models (GRWM), which enforces thatconsecutive points along a natural sensory trajectory remain close in latentrepresentation space. This approach yields significantly improved latentrepresentations that align closely with the true topology of the environment.GRWM is plug-and-play, requires only minimal architectural modification, scaleswith trajectory length, and is compatible with diverse latent generativebackbones. Across deterministic 3D settings and long-horizon prediction tasks,GRWM significantly increases rollout fidelity and stability. Analyses show thatits benefits stem from learning a latent manifold with superior geometricstructure. These findings support a clear takeaway: improving representationlearning is a direct and useful path to robust world models, deliveringreliable long-horizon predictions without enlarging the dynamics module.</description><author>Zaishuo Xia, Yukuan Lu, Xinyi Li, Yifan Xu, Yubei Chen</author><pubDate>Thu, 30 Oct 2025 17:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26782v1</guid></item><item><title>ChartAB: A Benchmark for Chart Grounding &amp; Dense Alignment</title><link>http://arxiv.org/abs/2510.26781v1</link><description>Charts play an important role in visualization, reasoning, data analysis, andthe exchange of ideas among humans. However, existing vision-language models(VLMs) still lack accurate perception of details and struggle to extractfine-grained structures from charts. Such limitations in chart grounding alsohinder their ability to compare multiple charts and reason over them. In thispaper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide acomprehensive evaluation of VLMs in chart grounding tasks, i.e., extractingtabular data, localizing visualization elements, and recognizing variousattributes from charts of diverse types and complexities. We design a JSONtemplate to facilitate the calculation of evaluation metrics specificallytailored for each grounding task. By incorporating a novel two-stage inferenceworkflow, the benchmark can further evaluate VLMs' capability to align andcompare elements/attributes across two charts. Our analysis of evaluations onseveral recent VLMs reveals new insights into their perception biases,weaknesses, robustness, and hallucinations in chart understanding. Thesefindings highlight the fine-grained discrepancies among VLMs in chartunderstanding tasks and point to specific skills that need to be strengthenedin current models.</description><author>Aniruddh Bansal, Davit Soselia, Dang Nguyen, Tianyi Zhou</author><pubDate>Thu, 30 Oct 2025 17:56:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26781v1</guid></item><item><title>S-CFE: Simple Counterfactual Explanations</title><link>http://arxiv.org/abs/2410.15723v7</link><description>We study the problem of finding optimal sparse, manifold-alignedcounterfactual explanations for classifiers. Canonically, this can beformulated as an optimization problem with multiple non-convex components,including classifier loss functions and manifold alignment (or\emph{plausibility}) metrics. The added complexity of enforcing\emph{sparsity}, or shorter explanations, complicates the problem further.Existing methods often focus on specific models and plausibility measures,relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, wetackle the canonical formulation using the accelerated proximal gradient (APG)method, a simple yet efficient first-order procedure capable of handling smoothnon-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$)regularizers. This enables our approach to seamlessly incorporate variousclassifiers and plausibility measures while producing sparser solutions. Ouralgorithm only requires differentiable data-manifold regularizers and supportsbox constraints for bounded feature ranges, ensuring the generatedcounterfactuals remain \emph{actionable}. Finally, experiments on real-worlddatasets demonstrate that our approach effectively produces sparse,manifold-aligned counterfactual explanations while maintaining proximity to thefactual data and computational efficiency.</description><author>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</author><pubDate>Thu, 30 Oct 2025 17:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15723v7</guid></item><item><title>Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance</title><link>http://arxiv.org/abs/2510.26778v1</link><description>Age-related macular degeneration (AMD) is one of the leading causes ofirreversible vision impairment in people over the age of 60. This researchfocuses on semantic segmentation for AMD lesion detection in RGB fundus images,a non-invasive and cost-effective imaging technique. The results of the ADAMchallenge - the most comprehensive AMD detection from RGB fundus imagesresearch competition and open dataset to date - serve as a benchmark for ourevaluation. Taking the U-Net connectivity as a base of our framework, weevaluate and compare several approaches to improve the segmentation model'sarchitecture and training pipeline, including pre-processing techniques,encoder (backbone) deep network types of varying complexity, and specializedloss functions to mitigate class imbalances on image and pixel levels. The mainoutcome of this research is the final configuration of the AMD detectionframework, which outperforms all the prior ADAM challenge submissions on themulti-class segmentation of different AMD lesion types in non-invasive RGBfundus images. The source code used to conduct the experiments presented inthis paper is made freely available.</description><author>Valentyna Starodub, Mantas Lukoševičius</author><pubDate>Thu, 30 Oct 2025 17:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26778v1</guid></item><item><title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title><link>http://arxiv.org/abs/2510.23534v2</link><description>We develop a direct debiased machine learning framework comprising Neymantargeted estimation and generalized Riesz regression. Our framework unifiesRiesz regression for automatic debiased machine learning, covariate balancing,targeted maximum likelihood estimation (TMLE), and density-ratio estimation. Inmany problems involving causal effects or structural models, the parameters ofinterest depend on regression functions. Plugging regression functionsestimated by machine learning methods into the identifying equations can yieldpoor performance because of first-stage bias. To reduce such bias, debiasedmachine learning employs Neyman orthogonal estimating equations. Debiasedmachine learning typically requires estimation of the Riesz representer and theregression function. For this problem, we develop a direct debiased machinelearning framework with an end-to-end algorithm. We formulate estimation of thenuisance parameters, the regression function and the Riesz representer, asminimizing the discrepancy between Neyman orthogonal scores computed with knownand unknown nuisance parameters, which we refer to as Neyman targetedestimation. Neyman targeted estimation includes Riesz representer estimation,and we measure discrepancies using the Bregman divergence. The Bregmandivergence encompasses various loss functions as special cases, where thesquared loss yields Riesz regression and the Kullback-Leibler divergence yieldsentropy balancing. We refer to this Riesz representer estimation as generalizedRiesz regression. Neyman targeted estimation also yields TMLE as a special casefor regression function estimation. Furthermore, for specific pairs of modelsand Riesz representer estimation methods, we can automatically obtain thecovariate balancing property without explicitly solving the covariate balancingobjective.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.23534v2</guid></item><item><title>Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification</title><link>http://arxiv.org/abs/2510.26777v1</link><description>Recent research on time series foundation models has primarily focused onforecasting, leaving it unclear how generalizable their learned representationsare. In this study, we examine whether frozen pre-trained forecasting modelscan provide effective representations for classification. To this end, wecompare different representation extraction strategies and introduce twomodel-agnostic embedding augmentations. Our experiments show that the bestforecasting models achieve classification accuracy that matches or evensurpasses that of state-of-the-art models pre-trained specifically forclassification. Moreover, we observe a positive correlation between forecastingand classification performance. These findings challenge the assumption thattask-specific pre-training is necessary, and suggest that learning to forecastmay provide a powerful route toward constructing general-purpose time seriesfoundation models.</description><author>Andreas Auer, Daniel Klotz, Sebastinan Böck, Sepp Hochreiter</author><pubDate>Thu, 30 Oct 2025 17:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26777v1</guid></item><item><title>Faithful and Fast Influence Function via Advanced Sampling</title><link>http://arxiv.org/abs/2510.26776v1</link><description>How can we explain the influence of training data on black-box models?Influence functions (IFs) offer a post-hoc solution by utilizing gradients andHessians. However, computing the Hessian for an entire dataset isresource-intensive, necessitating a feasible alternative. A common approachinvolves randomly sampling a small subset of the training data, but this methodoften results in highly inconsistent IF estimates due to the high variance insample configurations. To address this, we propose two advanced samplingtechniques based on features and logits. These samplers select a small yetrepresentative subset of the entire dataset by considering the stochasticdistribution of features or logits, thereby enhancing the accuracy of IFestimations. We validate our approach through class removal experiments, atypical application of IFs, using the F1-score to measure how effectively themodel forgets the removed class while maintaining inference consistency on theremaining classes. Our method reduces computation time by 30.1% and memoryusage by 42.2%, or improves the F1-score by 2.5% compared to the baseline.</description><author>Jungyeon Koh, Hyeonsu Lyu, Jonggyu Jang, Hyun Jong Yang</author><pubDate>Thu, 30 Oct 2025 17:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26776v1</guid></item><item><title>Completion $\neq$ Collaboration: Scaling Collaborative Effort with Agents</title><link>http://arxiv.org/abs/2510.25744v2</link><description>Current evaluations of agents remain centered around one-shot taskcompletion, failing to account for the inherently iterative and collaborativenature of many real-world problems, where human goals are often underspecifiedand evolve. We argue for a shift from building and assessing task completionagents to developing collaborative agents, assessed not only by the quality oftheir final outputs but by how well they engage with and enhance human effortthroughout the problem-solving process. To support this shift, we introducecollaborative effort scaling, a framework that captures how an agent's utilitygrows with increasing user involvement. Through case studies and simulatedevaluations, we show that state-of-the-art agents often underperform inmulti-turn, real-world scenarios, revealing a missing ingredient in agentdesign: the ability to sustain engagement and scaffold user understanding.Collaborative effort scaling offers a lens for diagnosing agent behavior andguiding development toward more effective interactions.</description><author>Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma, Jillian Ross, Alex Gu, Chenglei Si, Wayne Chi, Andi Peng, Jocelyn J Shen, Ameet Talwalkar, Tongshuang Wu, David Sontag</author><pubDate>Thu, 30 Oct 2025 17:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.25744v2</guid></item><item><title>STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization</title><link>http://arxiv.org/abs/2510.26771v1</link><description>Quantization is the key method for reducing inference latency, power andmemory footprint of generative AI models. However, accuracy often degradessharply when activations are quantized below eight bits. Recent work suggeststhat invertible linear transformations (e.g. rotations) can aid quantization,by reparameterizing feature channels and weights. In this paper, we propose\textit{Sequence Transformation and Mixed Precision} (STaMP) quantization, anovel strategy that applies linear transformations along the \textit{sequence}dimension to exploit the strong local correlation in language and visual data.By keeping a small number of tokens in each intermediate activation at higherprecision, we can maintain model accuracy at lower (average) activationsbit-widths. We evaluate STaMP on recent LVM and LLM architectures,demonstrating that it significantly improves low bit width activationquantization and complements established activation and weight quantizationmethods including recent feature transformations.</description><author>Marco Federici, Riccardo Del Chiaro, Boris van Breugel, Paul Whatmough, Markus Nagel</author><pubDate>Thu, 30 Oct 2025 17:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26771v1</guid></item><item><title>SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models</title><link>http://arxiv.org/abs/2510.26769v1</link><description>This work introduces SteerVLM, a lightweight steering module designed toguide Vision-Language Models (VLMs) towards outputs that better adhere todesired instructions. Our approach learns from the latent embeddings of pairedprompts encoding target and converse behaviors to dynamically adjustactivations connecting the language modality with image context. This allowsfor fine-grained, inference-time control over complex output semantics withoutmodifying model weights while preserving performance on off-target tasks. Oursteering module requires learning parameters equal to 0.14% of the originalVLM's size. Our steering module gains model control through dimension-wiseactivation modulation and adaptive steering across layers without requiringpre-extracted static vectors or manual tuning of intervention points.Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), amultimodal dataset specifically created to facilitate the development andevaluation of VLM steering techniques. Our method outperforms existingintervention techniques on steering and hallucination mitigation benchmarks forVLMs and proposes a robust solution for multimodal model control throughactivation engineering.</description><author>Anushka Sivakumar, Andrew Zhang, Zaber Hakim, Chris Thomas</author><pubDate>Thu, 30 Oct 2025 17:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26769v1</guid></item><item><title>AMO-Bench: Large Language Models Still Struggle in High School Math Competitions</title><link>http://arxiv.org/abs/2510.26768v1</link><description>We present AMO-Bench, an Advanced Mathematical reasoning benchmark withOlympiad level or even higher difficulty, comprising 50 human-crafted problems.Existing benchmarks have widely leveraged high school math competitions forevaluating mathematical reasoning capabilities of large language models (LLMs).However, many existing math competitions are becoming less effective forassessing top-tier LLMs due to performance saturation (e.g., AIME24/25). Toaddress this, AMO-Bench introduces more rigorous challenges by ensuring all 50problems are (1) cross-validated by experts to meet at least the InternationalMathematical Olympiad (IMO) difficulty standards, and (2) entirely originalproblems to prevent potential performance leakages from data memorization.Moreover, each problem in AMO-Bench requires only a final answer rather than aproof, enabling automatic and robust grading for evaluation. Experimentalresults across 26 LLMs on AMO-Bench show that even the best-performing modelachieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.Beyond these poor performances, our further analysis reveals a promisingscaling trend with increasing test-time compute on AMO-Bench. These resultshighlight the significant room for improving the mathematical reasoning incurrent LLMs. We release AMO-Bench to facilitate further research intoadvancing the reasoning abilities of language models.https://amo-bench.github.io/</description><author>Shengnan An, Xunliang Cai, Xuezhi Cao, Xiaoyu Li, Yehao Lin, Junlin Liu, Xinxuan Lv, Dan Ma, Xuanlin Wang, Ziwen Wang, Shuang Zhou</author><pubDate>Thu, 30 Oct 2025 17:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26768v1</guid></item><item><title>Adversarial generalization of unfolding (model-based) networks</title><link>http://arxiv.org/abs/2509.15370v3</link><description>Unfolding networks are interpretable networks emerging from iterativealgorithms, incorporate prior knowledge of data structure, and are designed tosolve inverse problems like compressed sensing, which deals with recoveringdata from noisy, missing observations. Compressed sensing finds applications incritical domains, from medical imaging to cryptography, where adversarialrobustness is crucial to prevent catastrophic failures. However, a solidtheoretical understanding of the performance of unfolding networks in thepresence of adversarial attacks is still in its infancy. In this paper, westudy the adversarial generalization of unfolding networks when perturbed with$l_2$-norm constrained attacks, generated by the fast gradient sign method.Particularly, we choose a family of state-of-the-art overaparameterizedunfolding networks and deploy a new framework to estimate their adversarialRademacher complexity. Given this estimate, we provide adversarialgeneralization error bounds for the networks under study, which are tight withrespect to the attack level. To our knowledge, this is the first theoreticalanalysis on the adversarial generalization of unfolding networks. We furtherpresent a series of experiments on real-world data, with results corroboratingour derived theory, consistently for all data. Finally, we observe that thefamily's overparameterization can be exploited to promote adversarialrobustness, shedding light on how to efficiently robustify neural networks.</description><author>Vicky Kouni</author><pubDate>Thu, 30 Oct 2025 17:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.15370v3</guid></item><item><title>MORE: Multi-Organ Medical Image REconstruction Dataset</title><link>http://arxiv.org/abs/2510.26759v1</link><description>CT reconstruction provides radiologists with images for diagnosis andtreatment, yet current deep learning methods are typically limited to specificanatomies and datasets, hindering generalization ability to unseen anatomiesand lesions. To address this, we introduce the Multi-Organ medical imageREconstruction (MORE) dataset, comprising CT scans across 9 diverse anatomieswith 15 lesion types. This dataset serves two key purposes: (1) enabling robusttraining of deep learning models on extensive, heterogeneous data, and (2)facilitating rigorous evaluation of model generalization for CT reconstruction.We further establish a strong baseline solution that outperforms priorapproaches under these challenging conditions. Our results demonstrate that:(1) a comprehensive dataset helps improve the generalization capability ofmodels, and (2) optimization-based methods offer enhanced robustness for unseenanatomies. The MORE dataset is freely accessible under CC-BY-NC 4.0 at ourproject page https://more-med.github.io/</description><author>Shaokai Wu, Yapan Guo, Yanbiao Ji, Jing Tong, Yuxiang Lu, Mei Li, Suizhi Huang, Yue Ding, Hongtao Lu</author><pubDate>Thu, 30 Oct 2025 17:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26759v1</guid></item><item><title>The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy</title><link>http://arxiv.org/abs/2510.26752v1</link><description>As increasingly capable agents are deployed, a central safety question is howto retain meaningful human control without modifying the underlying system. Westudy a minimal control interface where an agent chooses whether to actautonomously (play) or defer (ask), while a human simultaneously chooseswhether to be permissive (trust) or to engage in oversight (oversee). If theagent defers, the human's choice determines the outcome, potentially leading toa corrective action or a system shutdown. We model this interaction as atwo-player Markov Game. Our analysis focuses on cases where this game qualifiesas a Markov Potential Game (MPG), a class of games where we can provide analignment guarantee: under a structural assumption on the human's valuefunction, any decision by the agent to act more autonomously that benefitsitself cannot harm the human's value. We also analyze extensions to this MPGframework. Theoretically, this perspective provides conditions for a specificform of intrinsic alignment. If the reward structures of the human-agent gamemeet these conditions, we have a formal guarantee that the agent improving itsown outcome will not harm the human's. Practically, this model motivates atransparent control layer with predictable incentives where the agent learns todefer when risky and act when safe, while its pretrained policy and theenvironment's reward structure remain untouched. Our gridworld simulation showsthat through independent learning, the agent and human discover their optimaloversight roles. The agent learns to ask when uncertain and the human learnswhen to oversee, leading to an emergent collaboration that avoids safetyviolations introduced post-training. This demonstrates a practical method formaking misaligned models safer after deployment.</description><author>William Overman, Mohsen Bayati</author><pubDate>Thu, 30 Oct 2025 17:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26752v1</guid></item><item><title>Smoothing Slot Attention Iterations and Recurrences</title><link>http://arxiv.org/abs/2508.05417v2</link><description>Slot Attention (SA) and its variants lie at the heart of mainstreamObject-Centric Learning (OCL). Objects in an image can be aggregated intorespective slot vectors, by \textit{iteratively} refining cold-start queryvectors, typically three times, via SA on image features. For video, suchaggregation is \textit{recurrently} shared across frames, with queriescold-started on the first frame while transitioned from the previous frame'sslots on non-first frames. However, the cold-start queries lack sample-specificcues thus hinder precise aggregation on the image or video's first frame; Also,non-first frames' queries are already sample-specific thus require transformsdifferent from the first frame's aggregation. We address these issues for thefirst time with our \textit{SmoothSA}: (1) To smooth SA iterations on the imageor video's first frame, we \textit{preheat} the cold-start queries with richinformation of input features, via a tiny module self-distilled inside OCL; (2)To smooth SA recurrences across all video frames, we \textit{differentiate} thehomogeneous transforms on the first and non-first frames, by using full andsingle iterations respectively. Comprehensive experiments on object discovery,recognition and downstream benchmarks validate our method's effectiveness.Further analyses intuitively illuminate how our method smooths SA iterationsand recurrences. Our source code, model checkpoints and training logs areavailable on https://github.com/Genera1Z/SmoothSA.</description><author>Rongzhen Zhao, Wenyan Yang, Juho Kannala, Joni Pajarinen</author><pubDate>Thu, 30 Oct 2025 17:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.05417v2</guid></item><item><title>Predicting Video Slot Attention Queries from Random Slot-Feature Pairs</title><link>http://arxiv.org/abs/2508.01345v3</link><description>Unsupervised video Object-Centric Learning (OCL) is promising as it enablesobject-level scene representation and dynamics modeling as we humans do.Mainstream video OCL methods adopt a recurrent architecture: An aggregatoraggregates current video frame into object features, termed slots, under somequeries; A transitioner transits current slots to queries for the next frame.This is an effective architecture but all existing implementations both(\textit{i1}) neglect to incorporate next frame features, the most informativesource for query prediction, and (\textit{i2}) fail to learn transitiondynamics, the knowledge essential for query prediction. To address theseissues, we propose Random Slot-Feature pair for learning Query prediction(RandSF.Q): (\textit{t1}) We design a new transitioner to incorporate bothslots and features, which provides more information for query prediction;(\textit{t2}) We train the transitioner to predict queries from slot-featurepairs randomly sampled from available recurrences, which drives it to learntransition dynamics. Experiments on scene representation demonstrate that ourmethod surpass existing video OCL methods significantly, e.g., up to 10 pointson object discovery, setting new state-of-the-art. Such superiority alsobenefits downstream tasks like dynamics modeling. Our core source code, modelcheckpoints and training logs are available onhttps://github.com/Genera1Z/RandSF.Q.</description><author>Rongzhen Zhao, Jian Li, Juho Kannala, Joni Pajarinen</author><pubDate>Thu, 30 Oct 2025 17:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.01345v3</guid></item><item><title>Comparing human and LLM politeness strategies in free production</title><link>http://arxiv.org/abs/2506.09391v2</link><description>Polite speech poses a fundamental alignment challenge for large languagemodels (LLMs). Humans deploy a rich repertoire of linguistic strategies tobalance informational and social goals -- from positive approaches that buildrapport (compliments, expressions of interest) to negative strategies thatminimize imposition (hedging, indirectness). We investigate whether LLMs employa similarly context-sensitive repertoire by comparing human and LLM responsesin both constrained and open-ended production tasks. We find that larger models($\ge$70B parameters) successfully replicate key preferences from thecomputational pragmatics literature, and human evaluators surprisingly preferLLM-generated responses in open-ended contexts. However, further linguisticanalyses reveal that models disproportionately rely on negative politenessstrategies even in positive contexts, potentially leading tomisinterpretations. While modern LLMs demonstrate an impressive handle onpoliteness strategies, these subtle differences raise important questions aboutpragmatic alignment in AI systems.</description><author>Haoran Zhao, Robert D. Hawkins</author><pubDate>Thu, 30 Oct 2025 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.09391v2</guid></item><item><title>Locality in Image Diffusion Models Emerges from Data Statistics</title><link>http://arxiv.org/abs/2509.09672v2</link><description>Recent work has shown that the generalization ability of image diffusionmodels arises from the locality properties of the trained neural network. Inparticular, when denoising a particular pixel, the model relies on a limitedneighborhood of the input image around that pixel, which, according to theprevious work, is tightly related to the ability of these models to producenovel images. Since locality is central to generalization, it is crucial tounderstand why diffusion models learn local behavior in the first place, aswell as the factors that govern the properties of locality patterns. In thiswork, we present evidence that the locality in deep diffusion models emerges asa statistical property of the image dataset and is not due to the inductivebias of convolutional neural networks, as suggested in previous work.Specifically, we demonstrate that an optimal parametric linear denoiserexhibits similar locality properties to deep neural denoisers. We show, boththeoretically and experimentally, that this locality arises directly from pixelcorrelations present in the image datasets. Moreover, locality patterns aredrastically different on specialized datasets, approximating principalcomponents of the data's covariance. We use these insights to craft ananalytical denoiser that better matches scores predicted by a deep diffusionmodel than prior expert-crafted alternatives. Our key takeaway is that whileneural network architectures influence generation quality, their primary roleis to capture locality patterns inherent in the data.</description><author>Artem Lukoianov, Chenyang Yuan, Justin Solomon, Vincent Sitzmann</author><pubDate>Thu, 30 Oct 2025 17:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.09672v2</guid></item><item><title>Deep sequence models tend to memorize geometrically; it is unclear why</title><link>http://arxiv.org/abs/2510.26745v1</link><description>In sequence modeling, the parametric memory of atomic facts has beenpredominantly abstracted as a brute-force lookup of co-occurrences betweenentities. We contrast this associative view against a geometric view of howmemory is stored. We begin by isolating a clean and analyzable instance ofTransformer reasoning that is incompatible with memory as strictly a storage ofthe local co-occurrences specified during training. Instead, the model musthave somehow synthesized its own geometry of atomic facts, encoding globalrelationships between all entities, including non-co-occurring ones. This inturn has simplified a hard reasoning task involving an $\ell$-fold compositioninto an easy-to-learn 1-step geometric task. From this phenomenon, we extract fundamental aspects of neural embeddinggeometries that are hard to explain. We argue that the rise of such a geometry,despite optimizing over mere local associations, cannot be straightforwardlyattributed to typical architectural or optimizational pressures.Counterintuitively, an elegant geometry is learned even when it is not moresuccinct than a brute-force lookup of associations. Then, by analyzing a connection to Node2Vec, we demonstrate how the geometrystems from a spectral bias that -- in contrast to prevailing theories -- indeedarises naturally despite the lack of various pressures. This analysis alsopoints to practitioners a visible headroom to make Transformer memory morestrongly geometric. We hope the geometric view of parametric memory encouragesrevisiting the default intuitions that guide researchers in areas likeknowledge acquisition, capacity, discovery and unlearning.</description><author>Shahriar Noroozizadeh, Vaishnavh Nagarajan, Elan Rosenfeld, Sanjiv Kumar</author><pubDate>Thu, 30 Oct 2025 17:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26745v1</guid></item><item><title>Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model</title><link>http://arxiv.org/abs/2503.09205v3</link><description>Integrating audio and visual data for training multimodal foundational modelsremains a challenge. The Audio-Video Vector Alignment (AVVA) frameworkaddresses this by considering AV scene alignment beyond mere temporalsynchronization, and leveraging Large Language Models (LLMs) for data curation.AVVA implements a scoring mechanism for selecting aligned training datasegments. It integrates Whisper, a speech-based foundation model, for audio andDINOv2 for video analysis in a dual-encoder structure with contrastive learningon AV pairs. Evaluations on AudioCaps, VALOR, and VGGSound demonstrate theeffectiveness of the proposed model architecture and data curation approach.AVVA achieves a significant improvement in top-k accuracies for video-to-audioretrieval on all datasets compared to DenseAV, while using only 192 hrs ofcurated training data. Furthermore, an ablation study indicates that the datacuration process effectively trades data quality for data quantity, yieldingincreases in top-k retrieval accuracies on AudioCaps, VALOR, and VGGSound,compared to training on the full spectrum of uncurated data.</description><author>Ali Vosoughi, Dimitra Emmanouilidou, Hannes Gamper</author><pubDate>Thu, 30 Oct 2025 17:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.09205v3</guid></item><item><title>A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation</title><link>http://arxiv.org/abs/2510.26740v1</link><description>We introduce the General Incentives-based Framework for Fairness (GIFF), anovel approach for fair multi-agent resource allocation that infers fairdecision-making from standard value functions. In resource-constrainedsettings, agents optimizing for efficiency often create inequitable outcomes.Our approach leverages the action-value (Q-)function to balance efficiency andfairness without requiring additional training. Specifically, our methodcomputes a local fairness gain for each action and introduces a counterfactualadvantage correction term to discourage over-allocation to already well-offagents. This approach is formalized within a centralized control setting, wherean arbitrator uses the GIFF-modified Q-values to solve an allocation problem. Empirical evaluations across diverse domains, including dynamic ridesharing,homelessness prevention, and a complex job allocation task-demonstrate that ourframework consistently outperforms strong baselines and can discoverfar-sighted, equitable policies. The framework's effectiveness is supported bya theoretical foundation; we prove its fairness surrogate is a principled lowerbound on the true fairness improvement and that its trade-off parameter offersmonotonic tuning. Our findings establish GIFF as a robust and principledframework for leveraging standard reinforcement learning components to achievemore equitable outcomes in complex multi-agent systems.</description><author>Ashwin Kumar, William Yeoh</author><pubDate>Thu, 30 Oct 2025 17:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26740v1</guid></item><item><title>ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models</title><link>http://arxiv.org/abs/2507.06078v2</link><description>Despite the success of deep learning across various domains, it remainsvulnerable to adversarial attacks. Although many existing adversarial attackmethods achieve high success rates, they typically rely on $\ell_{p}$-normperturbation constraints, which do not align with human perceptualcapabilities. Consequently, researchers have shifted their focus towardgenerating natural, unrestricted adversarial examples (UAEs). GAN-basedapproaches suffer from inherent limitations, such as poor image quality due toinstability and mode collapse. Meanwhile, diffusion models have been employedfor UAE generation, but they still rely on iterative PGD perturbationinjection, without fully leveraging their central denoising capabilities. Inthis paper, we introduce a novel approach for generating UAEs based ondiffusion models, named ScoreAdv. This method incorporates an interpretableadversarial guidance mechanism to gradually shift the sampling distributiontowards the adversarial distribution, while using an interpretable saliency mapto inject the visual information of a reference image into the generatedsamples. Notably, our method is capable of generating an unlimited number ofnatural adversarial examples and can attack not only classification models butalso retrieval models. We conduct extensive experiments on ImageNet and CelebAdatasets, validating the performance of ScoreAdv across ten target models inboth black-box and white-box settings. Our results demonstrate that ScoreAdvachieves state-of-the-art attack success rates and image quality, whilemaintaining inference efficiency. Furthermore, the dynamic balance betweendenoising and adversarial perturbation enables ScoreAdv to remain robust evenunder defensive measures.</description><author>Chihan Huang, Hao Tang</author><pubDate>Thu, 30 Oct 2025 17:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.06078v2</guid></item><item><title>Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality</title><link>http://arxiv.org/abs/2506.14681v2</link><description>Supervised fine-tuning (SFT) is a critical step in aligning large languagemodels (LLMs) with human instructions and values, yet many aspects of SFTremain poorly understood. We trained a wide range of base models on a varietyof datasets including code generation, mathematical reasoning, andgeneral-domain tasks, resulting in 1,000+ SFT models under controlledconditions. We then identified the dataset properties that matter most andexamined the layer-wise modifications introduced by SFT. Our findings revealthat some training-task synergies persist across all models while others varysubstantially, emphasizing the importance of model-specific strategies.Moreover, we demonstrate that perplexity consistently predicts SFTeffectiveness, often surpassing superficial similarity between the trainingdata and the benchmark, and that mid-layer weight changes correlate moststrongly with performance gains. We release these 1,000+ SFT models andbenchmark results to accelerate further research. All resources are availableat https://github.com/llm-jp/massive-sft.</description><author>Yuto Harada, Yusuke Yamauchi, Yusuke Oda, Yohei Oseki, Yusuke Miyao, Yu Takagi</author><pubDate>Thu, 30 Oct 2025 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.14681v2</guid></item><item><title>Advancing Local Clustering on Graphs via Compressive Sensing: Semi-supervised and Unsupervised Methods</title><link>http://arxiv.org/abs/2504.19419v2</link><description>Local clustering aims to identify specific substructures within a large graphwithout any additional structural information of the graph. These substructuresare typically small compared to the overall graph, enabling the problem to beapproached by finding a sparse solution to a linear system associated with thegraph Laplacian. In this work, we first propose a method for identifyingspecific local clusters when very few labeled data are given, which we termsemi-supervised local clustering. We then extend this approach to theunsupervised setting when no prior information on labels is available. Theproposed methods involve randomly sampling the graph, applying diffusionthrough local cluster extraction, then examining the overlap among the resultsto find each cluster. We establish the co-membership conditions for any pair ofnodes, and rigorously prove the correctness of our methods. Additionally, weconduct extensive experiments to demonstrate that the proposed methods achievestate of the art results in the low-label rates regime.</description><author>Zhaiming Shen, Sung Ha Kang</author><pubDate>Thu, 30 Oct 2025 17:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.19419v2</guid></item><item><title>Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming</title><link>http://arxiv.org/abs/2506.05567v2</link><description>Neural Networks (NN) with ReLU activation functions are used to modelmultiparametric quadratic optimization problems (mp-QP) in diverse engineeringapplications. Researchers have suggested leveraging the piecewise affineproperty of deep NN models to solve mp-QP with linear constraints, which alsoexhibit piecewise affine behaviour. However, traditional deep NN applicationsto mp-QP fall short of providing optimal and feasible predictions, even whentrained on large datasets. This study proposes a partially-supervised NN (PSNN)architecture that directly represents the mathematical structure of the globalsolution function. In contrast to generic NN training approaches, the proposedPSNN method derives a large proportion of model weights directly from themathematical properties of the optimization problem, producing more accuratesolutions despite significantly smaller training data sets. Many energymanagement problems are formulated as QP, so we apply the proposed approach toenergy systems (specifically DC optimal power flow) to demonstrate proof ofconcept. Model performance in terms of solution accuracy and speed ofpredictions was compared against a commercial solver and a generic Deep NNmodel based on classical training. Results show KKT sufficient conditions forPSNN consistently outperform generic NN architectures with classical trainingusing far less data, including when tested on extreme, out-of-trainingdistribution test data. Given its speed advantages over traditional solvers,the PSNN model can quickly produce optimal and feasible solutions within asecond for millions of input parameters sampled from a distribution ofstochastic demands and renewable generator dispatches, which can be used forsimulations and long term planning.</description><author>Fuat Can Beylunioglu, Mehrdad Pirnia, P. Robert Duimering</author><pubDate>Thu, 30 Oct 2025 17:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05567v2</guid></item><item><title>Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models</title><link>http://arxiv.org/abs/2510.26732v1</link><description>This paper presents a comprehensive cross-platform evaluation of reasoningcapabilities in contemporary foundation models, establishing aninfrastructure-agnostic benchmark across three computational paradigms: HPCsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), anduniversity clusters (a node with eight H200 GPUs). We evaluate 15 foundation models across 79 problems spanning eight academicdomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,Calculus, and Optimization) through three experimental phases: (1) Baselineestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishingmethodology and reference performance; (2) Infrastructure validation: The19-problem benchmark repeated on university cluster (seven models includingFalcon-Mamba state-space architecture) and Nebius AI Studio (ninestate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen330B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnosticreproducibility; (3) Extended evaluation: Full 79-problem assessment on bothuniversity cluster and Nebius platforms, probing generalization at scale acrossarchitectural diversity. The findings challenge conventional scaling assumptions, establish trainingdata quality as more critical than model size, and provide actionableguidelines for model selection across educational, production, and researchcontexts. The tri-infrastructure methodology and 79-problem benchmark enablelongitudinal tracking of reasoning capabilities as foundation models evolve.</description><author>J. de Curtò, I. de Zarzà, Pablo García, Jordi Cabot</author><pubDate>Thu, 30 Oct 2025 17:31:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26732v1</guid></item><item><title>ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</title><link>http://arxiv.org/abs/2510.26730v1</link><description>The expansion of large language models is increasingly limited by theconstrained memory capacity of modern GPUs. To mitigate this,Mixture-of-Experts (MoE) architectures activate only a small portion ofparameters during inference, significantly lowering both memory demand andcomputational overhead. However, conventional MoE inference approaches, whichselect active experts independently at each layer, often introduce considerablelatency because of frequent parameter transfers between host and GPU memory. Inaddition, current cross-layer prediction strategies, which are typically basedon fixed steps, lack adaptability across different hardware platforms andworkloads, thereby reducing their robustness and effectiveness. To address these challenges, we present ExpertFlow, a runtime system for MoEinference that combines adaptive expert prefetching and cache-aware routing.ExpertFlow continuously adjusts its prediction horizon for expert activation byleveraging runtime statistics such as transfer bandwidth, parameterdimensionality, and model feedback signals. Furthermore, it incorporates ahybrid cross-layer prediction scheme that fuses pregating information withintermediate computational states to anticipate future expert needs. Byadaptively refining prefetching decisions and aligning them with actual usagebehavior, ExpertFlow effectively decreases cache misses and removes latencycaused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reducesmodel stall time to less than 0.1% of the baseline, highlighting its capabilityto optimize MoE inference under stringent memory constraints.</description><author>Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu, Wei Zhang</author><pubDate>Thu, 30 Oct 2025 17:29:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26730v1</guid></item><item><title>Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training</title><link>http://arxiv.org/abs/2510.20059v2</link><description>Enhancing reasoning capabilities in small language models is critical forspecialized applications such as medical question answering, particularly inunderrepresented languages like Persian. In this study, we employ ReinforcementLearning with AI Feedback (RLAIF) and Direct preference optimization (DPO) toimprove the reasoning skills of a general-purpose Persian language model. Toachieve this, we translated a multiple-choice medical question-answeringdataset into Persian and used RLAIF to generate rejected-preferred answerpairs, which are essential for DPO training. By prompting both teacher andstudent models to produce Chain-of-Thought (CoT) reasoning responses, wecompiled a dataset containing correct and incorrect reasoning trajectories.This dataset, comprising 2 million tokens in preferred answers and 2.5 milliontokens in rejected ones, was used to train a baseline model, significantlyenhancing its medical reasoning capabilities in Persian. Remarkably, theresulting model outperformed its predecessor, gaokerena-V, which was trained onapproximately 57 million tokens, despite leveraging a much smaller dataset.These results highlight the efficiency and effectiveness of reasoning-focusedtraining approaches in developing domain-specific language models with limiteddata availability.</description><author>Mehrdad Ghassabi, Sadra Hakim, Hamidreza Baradaran Kashani, Pedram Rostami</author><pubDate>Thu, 30 Oct 2025 17:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.20059v2</guid></item><item><title>Integrating Protein Sequence and Expression Level to Analysis Molecular Characterization of Breast Cancer Subtypes</title><link>http://arxiv.org/abs/2410.01755v3</link><description>Breast cancer's complexity and variability pose significant challenges inunderstanding its progression and guiding effective treatment. This study aimsto integrate protein sequence data with expression levels to improve themolecular characterization of breast cancer subtypes and predict clinicaloutcomes. Using ProtGPT2, a language model specifically designed for proteinsequences, we generated embeddings that capture the functional and structuralproperties of proteins. These embeddings were integrated with proteinexpression levels to form enriched biological representations, which wereanalyzed using machine learning methods, such as ensemble K-means forclustering and XGBoost for classification. Our approach enabled the successfulclustering of patients into biologically distinct groups and accuratelypredicted clinical outcomes such as survival and biomarker status, achievinghigh performance metrics, notably an F1 score of 0.88 for survival and 0.87 forbiomarker status prediction. Feature importance analysis identified KMT2C,CLASP2, and MYO1B as key proteins involved in hormone signaling, cytoskeletalremodeling, and therapy resistance in hormone receptor-positive andtriple-negative breast cancer, with potential influence on breast cancersubtype behavior and progression. Furthermore, protein-protein interactionnetworks and correlation analyses revealed functional interdependencies amongproteins that may influence the behavior and progression of breast cancersubtypes. These findings suggest that integrating protein sequence andexpression data provides valuable insights into tumor biology and hassignificant potential to enhance personalized treatment strategies in breastcancer care.</description><author>Hossein Sholehrasa, Majid Jaberi-Douraki</author><pubDate>Thu, 30 Oct 2025 17:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01755v3</guid></item><item><title>Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</title><link>http://arxiv.org/abs/2510.26723v1</link><description>The goal of policy learning is to train a policy function that recommends atreatment given covariates to maximize population welfare. There are two majorapproaches in policy learning: the empirical welfare maximization (EWM)approach and the plug-in approach. The EWM approach is analogous to aclassification problem, where one first builds an estimator of the populationwelfare, which is a functional of policy functions, and then trains a policy bymaximizing the estimated welfare. In contrast, the plug-in approach is based onregression, where one first estimates the conditional average treatment effect(CATE) and then recommends the treatment with the highest estimated outcome.This study bridges the gap between the two approaches by showing that both arebased on essentially the same optimization problem. In particular, we prove anexact equivalence between EWM and least squares over a reparameterization ofthe policy class. As a consequence, the two approaches are interchangeable inseveral respects and share the same theoretical guarantees under commonconditions. Leveraging this equivalence, we propose a novel regularizationmethod for policy learning. Our findings yield a convex and computationallyefficient training procedure that avoids the NP-hard combinatorial steptypically required in EWM.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:23:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26723v1</guid></item><item><title>Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</title><link>http://arxiv.org/abs/2510.26722v1</link><description>Over-the-air (OTA) federated learning (FL) has been well recognized as ascalable paradigm that exploits the waveform superposition of the wirelessmultiple-access channel to aggregate model updates in a single use. ExistingOTA-FL designs largely enforce zero-bias model updates by either assuming\emph{homogeneous} wireless conditions (equal path loss across devices) orforcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous}wireless scenarios, however, such designs are constrained by the weakest deviceand inflate the update variance. Moreover, prior analyses of biased OTA-FLlargely address convex objectives, while most modern AI models are highlynon-convex. Motivated by these gaps, we study OTA-FL with stochastic gradientdescent (SGD) for general smooth non-convex objectives under wirelessheterogeneity. We develop novel OTA-FL SGD updates that allow a structured,time-invariant model bias while facilitating reduced variance updates. Wederive a finite-time stationarity bound (expected time average squared gradientnorm) that explicitly reveals a bias-variance trade-off. To optimize thistrade-off, we pose a non-convex joint OTA power-control design and develop anefficient successive convex approximation (SCA) algorithm that requires onlystatistical CSI at the base station. Experiments on a non-convex imageclassification task validate the approach: the SCA-based design acceleratesconvergence via an optimized bias and improves generalization over prior OTA-FLbaselines.</description><author>Muhammad Faraz Ul Abrar, Nicolò Michelusi</author><pubDate>Thu, 30 Oct 2025 17:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26722v1</guid></item><item><title>Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis</title><link>http://arxiv.org/abs/2510.26721v1</link><description>Multimodal large language models (MLLMs) exhibit a pronounced preference fortextual inputs when processing vision-language data, limiting their ability toreason effectively from visual evidence. Unlike prior studies that attributethis text bias to external factors such as data imbalance or instructiontuning, we propose that the bias originates from the model's internalarchitecture. Specifically, we hypothesize that visual key vectors (VisualKeys) are out-of-distribution (OOD) relative to the text key space learnedduring language-only pretraining. Consequently, these visual keys receivesystematically lower similarity scores during attention computation, leading totheir under-utilization in the context representation. To validate thishypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze theirdistributional structures using qualitative (t-SNE) and quantitative(Jensen-Shannon divergence) methods. The results provide direct evidence thatvisual and textual keys occupy markedly distinct subspaces within the attentionspace. The inter-modal divergence is statistically significant, exceedingintra-modal variation by several orders of magnitude. These findings revealthat text bias arises from an intrinsic misalignment within the attention keyspace rather than solely from external data factors.</description><author>Xinhan Zheng, Huyu Wu, Xueting Wang, Haiyun Jiang</author><pubDate>Thu, 30 Oct 2025 17:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26721v1</guid></item><item><title>Reducing base drag on road vehicles using pulsed jets optimized by hybrid genetic algorithms</title><link>http://arxiv.org/abs/2510.26718v1</link><description>Aerodynamic drag on flat-backed vehicles like vans and trucks is dominated bya low-pressure wake, whose control is critical for reducing fuel consumption.This paper presents an experimental study at $Re_W\approx 78,300$ on activeflow control using four pulsed jets at the rear edges of a bluff body model. Ahybrid genetic algorithm, combining a global search with a local gradient-basedoptimizer, was used to determine the optimal jet actuation parameters in anexperiment-in-the-loop setup. The cost function was designed to achieve a netenergy saving by simultaneously minimizing aerodynamic drag and penalizing theactuation's energy consumption. The optimization campaign successfullyidentified a control strategy that yields a drag reduction of approximately10%. The optimal control law features a strong, low-frequency actuation fromthe bottom jet, which targets the main vortex shedding, while the top andlateral jets address higher-frequency, less energetic phenomena. Particle ImageVelocimetry analysis reveals a significant upward shift and stabilization ofthe wake, leading to substantial pressure recovery on the model's lower base.Ultimately, this work demonstrates that a model-free optimization approach cansuccessfully identify non-intuitive, multi-faceted actuation strategies thatyield significant and energetically efficient drag reduction.</description><author>Isaac Robledo, Juan Alfaro, Víctor Duro, Alberto Solera-Rico, Rodrigo Castellanos, Carlos Sanmiguel Vila</author><pubDate>Thu, 30 Oct 2025 17:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26718v1</guid></item><item><title>On Purely Private Covariance Estimation</title><link>http://arxiv.org/abs/2510.26717v1</link><description>We present a simple perturbation mechanism for the release of $d$-dimensionalcovariance matrices $\Sigma$ under pure differential privacy. For largedatasets with at least $n\geq d^2/\varepsilon$ elements, our mechanism recoversthe provably optimal Frobenius norm error guarantees of\cite{nikolov2023private}, while simultaneously achieving best known error forall other $p$-Schatten norms, with $p\in [1,\infty]$. Our error isinformation-theoretically optimal for all $p\ge 2$, in particular, ourmechanism is the first purely private covariance estimator that achievesoptimal error in spectral norm. For small datasets $n&lt; d^2/\varepsilon$, we further show that by projectingthe output onto the nuclear norm ball of appropriate radius, our algorithmachieves the optimal Frobenius norm error $O(\sqrt{d\;\text{Tr}(\Sigma) /n})$,improving over the known bounds of $O(\sqrt{d/n})$ of \cite{nikolov2023private}and ${O}\big(d^{3/4}\sqrt{\text{Tr}(\Sigma)/n}\big)$ of\cite{dong2022differentially}.</description><author>Tommaso d'Orsi, Gleb Novikov</author><pubDate>Thu, 30 Oct 2025 17:18:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26717v1</guid></item><item><title>When Kernels Multiply, Clusters Unify: Fusing Embeddings with the Kronecker Product</title><link>http://arxiv.org/abs/2506.08645v2</link><description>State-of-the-art embeddings often capture distinct yet complementarydiscriminative features: For instance, one image embedding model may excel atdistinguishing fine-grained textures, while another focuses on object-levelstructure. Motivated by this observation, we propose a principled approach tofuse such complementary representations through kernel multiplication.Multiplying the kernel similarity functions of two embeddings allows theirdiscriminative structures to interact, producing a fused representation whosekernel encodes the union of the clusters identified by each parent embedding.This formulation also provides a natural way to construct joint kernels forpaired multi-modal data (e.g., image-text tuples), where the product ofmodality-specific kernels inherits structure from both domains. We highlightthat this kernel product is mathematically realized via the Kronecker productof the embedding feature maps, yielding our proposed KrossFuse framework forembedding fusion. To address the computational cost of the resultinghigh-dimensional Kronecker space, we further develop RP-KrossFuse, a scalablevariant that leverages random projections for efficient approximation. As a keyapplication, we use this framework to bridge the performance gap betweencross-modal embeddings (e.g., CLIP, BLIP) and unimodal experts (e.g., DINOv2,E5). Experiments show that RP-KrossFuse effectively integrates these models,enhancing modality-specific performance while preserving cross-modal alignment.The project code is available at https://github.com/yokiwuuu/KrossFuse.</description><author>Youqi Wu, Jingwei Zhang, Farzan Farnia</author><pubDate>Thu, 30 Oct 2025 17:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08645v2</guid></item><item><title>LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</title><link>http://arxiv.org/abs/2510.26715v1</link><description>A vast majority of mass spectrometry data remains uncharacterized, leavingmuch of its biological and chemical information untapped. Recent advances inmachine learning have begun to address this gap, particularly for tasks such asspectral identification in tandem mass spectrometry data. Here, we present thelatest generation of LSM-MS2, a large-scale deep learning foundation modeltrained on millions of spectra to learn a semantic chemical space. LSM-MS2achieves state-of-the-art performance in spectral identification, improving onexisting methods by 30% in accuracy of identifying challenging isomericcompounds, yielding 42% more correct identifications in complex biologicalsamples, and maintaining robustness under low-concentration conditions.Furthermore, LSM-MS2 produces rich spectral embeddings that enable directbiological interpretation from minimal downstream data, successfullydifferentiating disease states and predicting clinical outcomes across diversetranslational applications.</description><author>Gabriel Asher, Devesh Shah, Amy A. Caudy, Luke Ferro, Lea Amar, Ana S. H. Costa, Thomas Patton, Niall O'Connor, Jennifer M. Campbell, Jack Geremia</author><pubDate>Thu, 30 Oct 2025 17:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26715v1</guid></item><item><title>On the limitation of evaluating machine unlearning using only a single training seed</title><link>http://arxiv.org/abs/2510.26714v1</link><description>Machine unlearning (MU) aims to remove the influence of certain data pointsfrom a trained model without costly retraining. Most practical MU algorithmsare only approximate and their performance can only be assessed empirically.Care must therefore be taken to make empirical comparisons as representative aspossible. A common practice is to run the MU algorithm multiple timesindependently starting from the same trained model. In this work, wedemonstrate that this practice can give highly non-representative resultsbecause -- even for the same architecture and same dataset -- some MU methodscan be highly sensitive to the choice of random number seed used for modeltraining. We therefore recommend that empiricalcomphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms shouldalso reflect the variability across different model training seeds.</description><author>Jamie Lanyon, Axel Finke, Petros Andreou, Georgina Cosma</author><pubDate>Thu, 30 Oct 2025 17:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26714v1</guid></item><item><title>Controlling Thinking Speed in Reasoning Models</title><link>http://arxiv.org/abs/2507.03704v2</link><description>Human cognition is theorized to operate in two modes: fast, intuitive System1 thinking and slow, deliberate System 2 thinking. While current LargeReasoning Models (LRMs) excel at System 2 thinking, their inability to performfast thinking leads to high computational overhead and latency. In this work,we enable LRMs to approximate human intelligence through dynamic thinking speedadjustment, optimizing accuracy-efficiency trade-offs. Our approach addressestwo key questions: (1) how to control thinking speed in LRMs, and (2) when toadjust it for optimal performance. For the first question, we identify thesteering vector that governs slow-fast thinking transitions in LRMs'representation space. Using this vector, we achieve the first representationediting-based test-time scaling effect, outperforming existing prompt-basedscaling methods. For the second question, we apply real-time difficultyestimation to signal reasoning segments of varying complexity. Combining thesetechniques, we propose the first reasoning strategy that enables fastprocessing of easy steps and deeper analysis for complex reasoning. Without anytraining or additional cost, our plug-in module delivers an average +1.3%accuracy with -8.6% token usage across leading LRMs and advanced reasoningbenchmarks. All of our algorithms are implemented based on vLLM and areexpected to support broader applications and inspire future research.</description><author>Zhengkai Lin, Zhihang Fu, Ze Chen, Chao Chen, Liang Xie, Wenxiao Wang, Deng Cai, Zheng Wang, Jieping Ye</author><pubDate>Thu, 30 Oct 2025 17:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.03704v2</guid></item><item><title>An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</title><link>http://arxiv.org/abs/2510.26709v1</link><description>Communication remains a central bottleneck in large-scale distributed machinelearning, and gradient sparsification has emerged as a promising strategy toalleviate this challenge. However, existing gradient compressors face notablelimitations: Rand-$K$\ discards structural information and performs poorly inpractice, while Top-$K$\ preserves informative entries but loses thecontraction property and requires costly All-Gather operations. In this paper,we propose ARC-Top-$K$, an {All-Reduce}-Compatible Top-$K$ compressor thataligns sparsity patterns across nodes using a lightweight sketch of thegradient, enabling index-free All-Reduce while preserving globally significantinformation. ARC-Top-$K$\ is provably contractive and, when combined withmomentum error feedback (EF21M), achieves linear speedup and sharperconvergence rates than the original EF21M under standard assumptions.Empirically, ARC-Top-$K$\ matches the accuracy of Top-$K$\ while reducingwall-clock training time by up to 60.7\%, offering an efficient and scalablesolution that combines the robustness of Rand-$K$\ with the strong performanceof Top-$K$.</description><author>Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong, Kun Yuan</author><pubDate>Thu, 30 Oct 2025 17:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26709v1</guid></item><item><title>RLBFF: Binary Flexible Feedback to bridge between Human Feedback &amp; Verifiable Rewards</title><link>http://arxiv.org/abs/2509.21319v2</link><description>Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learningwith Verifiable Rewards (RLVR) are the main RL paradigms used in LLMpost-training, each offering distinct advantages. However, RLHF struggles withinterpretability and reward hacking because it relies on human judgments thatusually lack explicit criteria, whereas RLVR is limited in scope by its focuson correctness-based verifiers. We propose Reinforcement Learning with BinaryFlexible Feedback (RLBFF), which combines the versatility of human-drivenpreferences with the precision of rule-based verification, enabling rewardmodels to capture nuanced aspects of response quality beyond mere correctness.RLBFF extracts principles that can be answered in a binary fashion (e.g.accuracy of information: yes, or code readability: no) from natural languagefeedback. Such principles can then be used to ground Reward Model training asan entailment task (response satisfies or does not satisfy an arbitraryprinciple). We show that Reward Models trained in this manner can outperformBradley-Terry models when matched for data and achieve top performance onRM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,2025). Additionally, users can specify principles of interest at inference timeto customize the focus of our reward models, in contrast to Bradley-Terrymodels. Finally, we present a fully open source recipe (including data) toalign Qwen3-32B using RLBFF and our Reward Model, to match or exceed theperformance of o3-mini and DeepSeek R1 on general alignment benchmarks ofMT-Bench, WildBench, and Arena Hard v2 (at &lt;5% of the inference cost). Models:https://huggingface.co/collections/nvidia/reward-models-10-2025</description><author>Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Ellie Evans, Daniel Egert, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev</author><pubDate>Thu, 30 Oct 2025 17:09:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21319v2</guid></item><item><title>Value Drifts: Tracing Value Alignment During LLM Post-Training</title><link>http://arxiv.org/abs/2510.26707v1</link><description>As LLMs occupy an increasingly important role in society, they are more andmore confronted with questions that require them not only to draw on theirgeneral knowledge but also to align with certain human value systems.Therefore, studying the alignment of LLMs with human values has become acrucial field of inquiry. Prior work, however, mostly focuses on evaluating thealignment of fully trained models, overlooking the training dynamics by whichmodels learn to express human values. In this work, we investigate how and atwhich stage value alignment arises during the course of a model'spost-training. Our analysis disentangles the effects of post-trainingalgorithms and datasets, measuring both the magnitude and time of value driftsduring training. Experimenting with Llama-3 and Qwen-3 models of differentsizes and popular supervised fine-tuning (SFT) and preference optimizationdatasets and algorithms, we find that the SFT phase generally establishes amodel's values, and subsequent preference optimization rarely re-aligns thesevalues. Furthermore, using a synthetic preference dataset that enablescontrolled manipulation of values, we find that different preferenceoptimization algorithms lead to different value alignment outcomes, even whenpreference data is held constant. Our findings provide actionable insights intohow values are learned during post-training and help to inform data curation,as well as the selection of models and algorithms for preference optimizationto improve model alignment to human values.</description><author>Mehar Bhatia, Shravan Nayak, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Vered Shwartz, Siva Reddy</author><pubDate>Thu, 30 Oct 2025 17:09:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26707v1</guid></item><item><title>Budgeted Multiple-Expert Deferral</title><link>http://arxiv.org/abs/2510.26706v1</link><description>Learning to defer uncertain predictions to costly experts offers a powerfulstrategy for improving the accuracy and efficiency of machine learning systems.However, standard training procedures for deferral algorithms typically requirequerying all experts for every training instance, an approach that becomesprohibitively expensive when expert queries incur significant computational orresource costs. This undermines the core goal of deferral: to limit unnecessaryexpert usage. To overcome this challenge, we introduce the budgeted deferralframework, which aims to train effective deferral algorithms while minimizingexpert query costs during training. We propose new algorithms for bothtwo-stage and single-stage multiple-expert deferral settings that selectivelyquery only a subset of experts per training example. While inspired by activelearning, our setting is fundamentally different: labels are already known, andthe core challenge is to decide which experts to query in order to balance costand predictive performance. We establish theoretical guarantees for both of ouralgorithms, including generalization bounds and label complexity analyses.Empirical results across several domains show that our algorithms substantiallyreduce training costs without sacrificing prediction accuracy, demonstratingthe practical value of our budget-aware deferral algorithms.</description><author>Giulia DeSalvo, Clara Mohri, Mehryar Mohri, Yutao Zhong</author><pubDate>Thu, 30 Oct 2025 17:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26706v1</guid></item><item><title>How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators</title><link>http://arxiv.org/abs/2510.26704v1</link><description>Can regularization terms in the training of invertible neural networks leadto known Bayesian point estimators in reconstruction? Invertible networks areattractive for inverse problems due to their inherent stability andinterpretability. Recently, optimization strategies for invertible neuralnetworks that approximate either a reconstruction map or the forward operatorhave been studied from a Bayesian perspective, but each has limitations. Toaddress this, we introduce and analyze two regularization terms for the networktraining that, upon inversion of the network, recover properties of classicalBayesian point estimators: while the first can be connected to the posteriormean, the second resembles the MAP estimator. Our theoretical analysischaracterizes how each loss shapes both the learned forward operator and itsinverse reconstruction map. Numerical experiments support our findings anddemonstrate how these loss-term regularizers introduce data-dependence in astable and interpretable way.</description><author>Nick Heilenkötter</author><pubDate>Thu, 30 Oct 2025 17:07:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26704v1</guid></item><item><title>ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</title><link>http://arxiv.org/abs/2510.26703v1</link><description>Purpose: Medical foundation models (FMs) offer a path to buildhigh-performance diagnostic systems. However, their application to prostatecancer (PCa) detection from micro-ultrasound ({\mu}US) remains untested inclinical settings. We present ProstNFound+, an adaptation of FMs for PCadetection from {\mu}US, along with its first prospective validation. Methods:ProstNFound+ incorporates a medical FM, adapter tuning, and a custom promptencoder that embeds PCa-specific clinical biomarkers. The model generates acancer heatmap and a risk score for clinically significant PCa. Followingtraining on multi-center retrospective data, the model is prospectivelyevaluated on data acquired five years later from a new clinical site. Modelpredictions are benchmarked against standard clinical scoring protocols(PRI-MUS and PI-RADS). Results: ProstNFound+ shows strong generalization to theprospective data, with no performance degradation compared to retrospectiveevaluation. It aligns closely with clinical scores and produces interpretableheatmaps consistent with biopsy-confirmed lesions. Conclusion: The resultshighlight its potential for clinical deployment, offering a scalable andinterpretable alternative to expert-driven protocols.</description><author>Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To, Amoon Jamzad, Tarek Elghareb, Zhuoxin Guo, Adam Kinnaird, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</author><pubDate>Thu, 30 Oct 2025 17:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26703v1</guid></item><item><title>Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching</title><link>http://arxiv.org/abs/2510.26702v1</link><description>Authorizing Large Language Model driven agents to dynamically invoke toolsand access protected resources introduces significant risks, since currentmethods for delegating authorization grant overly broad permissions and giveaccess to tools allowing agents to operate beyond the intended task scope. Weintroduce and assess a delegated authorization model enabling authorizationservers to semantically inspect access requests to protected resources, andissue access tokens constrained to the minimal set of scopes necessary for theagents' assigned tasks. Given the unavailability of datasets centered ondelegated authorization flows, particularly including both semanticallyappropriate and inappropriate scope requests for a given task, we introduceASTRA, a dataset and data generation pipeline for benchmarking semanticmatching between tasks and scopes. Our experiments show both the potential andcurrent limitations of model-based matching, particularly as the number ofscopes needed for task completion increases. Our results highlight the need forfurther research into semantic matching techniques enabling intent-awareauthorization for multi-agent and tool-augmented applications, includingfine-grained control, such as Task-Based Access Control (TBAC).</description><author>Majed El Helou, Chiara Troiani, Benjamin Ryder, Jean Diaconu, Hervé Muyal, Marcelo Yannuzzi</author><pubDate>Thu, 30 Oct 2025 17:07:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26702v1</guid></item><item><title>Curriculum Abductive Learning</title><link>http://arxiv.org/abs/2505.12275v2</link><description>Abductive Learning (ABL) integrates machine learning with logical reasoningin a loop: a learning model predicts symbolic concept labels from raw inputs,which are revised through abduction using domain knowledge and then fed backfor retraining. However, due to the nondeterminism of abduction, the trainingprocess often suffers from instability, especially when the knowledge base islarge and complex, resulting in a prohibitively large abduction space. Whileprior works focus on improving candidate selection within this space, theytypically treat the knowledge base as a static black box. In this work, wepropose Curriculum Abductive Learning (C-ABL), a method that explicitlyleverages the internal structure of the knowledge base to address the ABLtraining challenges. C-ABL partitions the knowledge base into a sequence ofsub-bases, progressively introduced during training. This reduces the abductionspace throughout training and enables the model to incorporate logic in astepwise, smooth way. Experiments across multiple tasks show that C-ABLoutperforms previous ABL implementations, significantly improves trainingstability, convergence speed, and final accuracy, especially under complexknowledge setting.</description><author>Wen-Chao Hu, Qi-Jie Li, Lin-Han Jia, Cunjing Ge, Yu-Feng Li, Yuan Jiang, Zhi-Hua Zhou</author><pubDate>Thu, 30 Oct 2025 17:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12275v2</guid></item><item><title>Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</title><link>http://arxiv.org/abs/2510.26700v1</link><description>Observational studies developing causal machine learning (ML) models for theprediction of individualized treatment effects (ITEs) seldom conduct empiricalevaluations to assess the conditional exchangeability assumption. We aimed toevaluate the performance of these models under conditional exchangeabilityviolations and the utility of negative control outcomes (NCOs) as a diagnostic.We conducted a simulation study to examine confounding bias in ITE estimatesgenerated by causal forest and X-learner models under varying conditions,including the presence or absence of true heterogeneity. We simulated data toreflect real-world scenarios with differing levels of confounding, sample size,and NCO confounding structures. We then estimated and compared subgroup-leveltreatment effects on the primary outcome and NCOs across settings with andwithout unmeasured confounding. When conditional exchangeability was violated,causal forest and X-learner models failed to recover true treatment effectheterogeneity and, in some cases, falsely indicated heterogeneity when therewas none. NCOs successfully identified subgroups affected by unmeasuredconfounding. Even when NCOs did not perfectly satisfy its ideal assumptions, itremained informative, flagging potential bias in subgroup level estimates,though not always pinpointing the subgroup with the largest confounding.Violations of conditional exchangeability substantially limit the validity ofITE estimates from causal ML models in routinely collected observational data.NCOs serve a useful empirical diagnostic tool for detecting subgroup-specificunmeasured confounding and should be incorporated into causal ML workflows tosupport the credibility of individualized inference.</description><author>Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss, Rishi J. Desai</author><pubDate>Thu, 30 Oct 2025 17:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26700v1</guid></item><item><title>Guided Model Merging for Hybrid Data Learning: Leveraging Centralized Data to Refine Decentralized Models</title><link>http://arxiv.org/abs/2503.20138v2</link><description>Current network training paradigms primarily focus on either centralized ordecentralized data regimes. However, in practice, data availability oftenexhibits a hybrid nature, where both regimes coexist. This hybrid settingpresents new opportunities for model training, as the two regimes offercomplementary trade-offs: decentralized data is abundant but subject toheterogeneity and communication constraints, while centralized data, thoughlimited in volume and potentially unrepresentative, enables better curation andhigh-throughput access. Despite its potential, effectively combining theseparadigms remains challenging, and few frameworks are tailored to hybrid dataregimes. To address this, we propose a novel framework that constructs a modelatlas from decentralized models and leverages centralized data to refine aglobal model within this structured space. The refined model is then used toreinitialize the decentralized models. Our method synergizes federated learning(to exploit decentralized data) and model merging (to utilize centralizeddata), enabling effective training under hybrid data availability.Theoretically, we show that our approach achieves faster convergence thanmethods relying solely on decentralized data, due to variance reduction in themerging process. Extensive experiments demonstrate that our frameworkconsistently outperforms purely centralized, purely decentralized, and existinghybrid-adaptable methods. Notably, our method remains robust even when thecentralized and decentralized data domains differ or when decentralized datacontains noise, significantly broadening its applicability.</description><author>Junyi Zhu, Ruicong Yao, Taha Ceritli, Savas Ozkan, Matthew B. Blaschko, Eunchung Noh, Jeongwon Min, Cho Jung Min, Mete Ozay</author><pubDate>Thu, 30 Oct 2025 17:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.20138v2</guid></item><item><title>The End of Manual Decoding: Towards Truly End-to-End Language Models</title><link>http://arxiv.org/abs/2510.26697v1</link><description>The "end-to-end" label for LLMs is a misnomer. In practice, they depend on anon-differentiable decoding process that requires laborious, hand-tuning ofhyperparameters like temperature and top-p. This paper introduces AutoDeco, anovel architecture that enables truly "end-to-end" generation by learning tocontrol its own decoding strategy. We augment the standard transformer withlightweight heads that, at each step, dynamically predict context-specifictemperature and top-p values alongside the next-token logits. This approachtransforms decoding into a parametric, token-level process, allowing the modelto self-regulate its sampling strategy within a single forward pass. Through extensive experiments on eight benchmarks, we demonstrate thatAutoDeco not only significantly outperforms default decoding strategies butalso achieves performance comparable to an oracle-tuned baseline derived from"hacking the test set"-a practical upper bound for any static method.Crucially, we uncover an emergent capability for instruction-based decodingcontrol: the model learns to interpret natural language commands (e.g.,"generate with low randomness") and adjusts its predicted temperature and top-pon a token-by-token basis, opening a new paradigm for steerable and interactiveLLM decoding.</description><author>Zhichao Wang, Dongyang Ma, Xinting Huang, Deng Cai, Tian Lan, Jiahao Xu, Haitao Mi, Xiaoying Tang, Yan Wang</author><pubDate>Thu, 30 Oct 2025 17:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26697v1</guid></item><item><title>The Impact and Outlook of 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2510.26694v1</link><description>Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformedthe landscape of 3D scene representations, inspiring an extensive body ofassociated research. Follow-up work includes analyses and contributions thatenhance the efficiency, scalability, and real-world applicability of 3DGS. Inthis summary, we present an overview of several key directions that haveemerged in the wake of 3DGS. We highlight advances enabling resource-efficienttraining and rendering, the evolution toward dynamic (or four-dimensional,4DGS) representations, and deeper exploration of the mathematical foundationsunderlying its appearance modeling and rendering process. Furthermore, weexamine efforts to bring 3DGS to mobile and virtual reality platforms, itsextension to massive-scale environments, and recent progress towardnear-instant radiance field reconstruction via feed-forward or distributedcomputation. Collectively, these developments illustrate how 3DGS has evolvedfrom a breakthrough representation into a versatile and foundational tool for3D vision and graphics.</description><author>Bernhard Kerbl</author><pubDate>Thu, 30 Oct 2025 17:01:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26694v1</guid></item><item><title>Kimi Linear: An Expressive, Efficient Attention Architecture</title><link>http://arxiv.org/abs/2510.26692v1</link><description>We introduce Kimi Linear, a hybrid linear attention architecture that, forthe first time, outperforms full attention under fair comparisons acrossvarious scenarios -- including short-context, long-context, and reinforcementlearning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), anexpressive linear attention module that extends Gated DeltaNet with afiner-grained gating mechanism, enabling more effective use of limitedfinite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardwareefficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)transition matrices, which substantially reduces computation compared to thegeneral DPLR formulation while remaining more consistent with the classicaldelta rule. We pretrain a Kimi Linear model with 3B activated parameters and 48B totalparameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention(MLA). Our experiments show that with an identical training recipe, Kimi Linearoutperforms full MLA with a sizeable margin across all evaluated tasks, whilereducing KV cache usage by up to 75% and achieving up to 6 times decodingthroughput for a 1M context. These results demonstrate that Kimi Linear can bea drop-in replacement for full attention architectures with superiorperformance and efficiency, including tasks with longer input and outputlengths. To support further research, we open-source the KDA kernel and vLLMimplementations, and release the pre-trained and instruction-tuned modelcheckpoints.</description><author>Kimi Team, Yu Zhang, Zongyu Lin, Xingcheng Yao, Jiaxi Hu, Fanqing Meng, Chengyin Liu, Xin Men, Songlin Yang, Zhiyuan Li, Wentao Li, Enzhe Lu, Weizhou Liu, Yanru Chen, Weixin Xu, Longhui Yu, Yejie Wang, Yu Fan, Longguang Zhong, Enming Yuan, Dehao Zhang, Yizhi Zhang, T. Y. Liu, Haiming Wang, Shengjun Fang, Weiran He, Shaowei Liu, Yiwei Li, Jianlin Su, Jiezhong Qiu, Bo Pang, Junjie Yan, Zhejun Jiang, Weixiao Huang, Bohong Yin, Jiacheng You, Chu Wei, Zhengtao Wang, Chao Hong, Yutian Chen, Guanduo Chen, Yucheng Wang, Huabin Zheng, Feng Wang, Yibo Liu, Mengnan Dong, Zheng Zhang, Siyuan Pan, Wenhao Wu, Yuhao Wu, Longyu Guan, Jiawen Tao, Guohong Fu, Xinran Xu, Yuzhi Wang, Guokun Lai, Yuxin Wu, Xinyu Zhou, Zhilin Yang, Yulun Du</author><pubDate>Thu, 30 Oct 2025 16:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26692v1</guid></item><item><title>LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits</title><link>http://arxiv.org/abs/2510.26690v1</link><description>Low-Rank Adaptation (LoRA) has become a popular technique forparameter-efficient fine-tuning of large language models (LLMs). In manyreal-world scenarios, multiple adapters are loaded simultaneously to enable LLMcustomization for personalized user experiences or to support a diverse rangeof tasks. Although each adapter is lightweight in isolation, their aggregatecost becomes substantial at scale. To address this, we propose LoRAQuant, amixed-precision post-training quantization method tailored to LoRA.Specifically, LoRAQuant reparameterizes each adapter by singular valuedecomposition (SVD) to concentrate the most important information into specificrows and columns. This makes it possible to quantize the important componentsto higher precision, while quantizing the rest to ultra-low bitwidth. Weconduct comprehensive experiments with LLaMA 2-7B, LLaMA 2-13B, and Mistral 7Bmodels on mathematical reasoning, coding, and summarization tasks. Results showthat our LoRAQuant uses significantly lower bits than other quantizationmethods, but achieves comparable or even higher performance.</description><author>Amir Reza Mirzaei, Yuqiao Wen, Yanshuai Cao, Lili Mou</author><pubDate>Thu, 30 Oct 2025 16:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26690v1</guid></item><item><title>FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design</title><link>http://arxiv.org/abs/2510.26688v1</link><description>Designing efficient quantum circuits is a central bottleneck to exploring thepotential of quantum computing, particularly for noisy intermediate-scalequantum (NISQ) devices, where circuit efficiency and resilience to errors areparamount. The search space of gate sequences grows combinatorially, andhandcrafted templates often waste scarce qubit and depth budgets. We introduce\textsc{FlowQ-Net} (Flow-based Quantum design Network), a generative frameworkfor automated quantum circuit synthesis based on Generative Flow Networks(GFlowNets). This framework learns a stochastic policy to construct circuitssequentially, sampling them in proportion to a flexible, user-defined rewardfunction that can encode multiple design objectives such as performance, depth,and gate count. This approach uniquely enables the generation of a diverseensemble of high-quality circuits, moving beyond single-solution optimization.We demonstrate the efficacy of \textsc{FlowQ-Net} through an extensive set ofsimulations. We apply our method to Variational Quantum Algorithm (VQA) ansatzdesign for molecular ground state estimation, Max-Cut, and imageclassification, key challenges in near-term quantum computing. Circuitsdesigned by \textsc{FlowQ-Net} achieve significant improvements, yieldingcircuits that are 10$\times$-30$\times$ more compact in terms of parameters,gates, and depth compared to commonly used unitary baselines, withoutcompromising accuracy. This trend holds even when subjected to error profilesfrom real-world quantum devices. Our results underline the potential ofgenerative models as a general-purpose methodology for automated quantumcircuit design, offering a promising path towards more efficient quantumalgorithms and accelerating scientific discovery in the quantum domain.</description><author>Jun Dai, Michael Rizvi-Martel, Guillaume Rabusseau</author><pubDate>Thu, 30 Oct 2025 16:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26688v1</guid></item><item><title>Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill</title><link>http://arxiv.org/abs/2510.26684v1</link><description>We present a long-term deployment study of a machine vision-based anomalydetection system for failure prediction in a steel rolling mill. The systemintegrates industrial cameras to monitor equipment operation, alignment, andhot bar motion in real time along the process line. Live video streams areprocessed on a centralized video server using deep learning models, enablingearly prediction of equipment failures and process interruptions, therebyreducing unplanned breakdown costs. Server-based inference minimizes thecomputational load on industrial process control systems (PLCs), supportingscalable deployment across production lines with minimal additional resources.By jointly analyzing sensor data from data acquisition systems and visualinputs, the system identifies the location and probable root causes offailures, providing actionable insights for proactive maintenance. Thisintegrated approach enhances operational reliability, productivity, andprofitability in industrial manufacturing environments.</description><author>Vaibhav Kurrey, Sivakalyan Pujari, Gagan Raj Gupta</author><pubDate>Thu, 30 Oct 2025 16:54:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26684v1</guid></item><item><title>Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</title><link>http://arxiv.org/abs/2510.26683v1</link><description>Large language models (LLMs) have demonstrated exceptional capabilitiesacross multiple domains by leveraging massive pre-training and curatedfine-tuning data. However, in data-sensitive fields such as healthcare, thelack of high-quality, domain-specific training corpus hinders LLMs' adaptationfor specialized applications. Meanwhile, domain experts have distilled domainwisdom into ontology rules, which formalize relationships among concepts andensure the integrity of knowledge management repositories. Viewing LLMs asimplicit repositories of human knowledge, we propose Evontree, a novelframework that leverages a small set of high-quality ontology rules tosystematically extract, validate, and enhance domain knowledge within LLMs,without requiring extensive external datasets. Specifically, Evontree extractsdomain ontology from raw models, detects inconsistencies using two coreontology rules, and reinforces the refined knowledge via self-distilledfine-tuning. Extensive experiments on medical QA benchmarks withLlama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over bothunmodified models and leading supervised baselines, achieving up to a 3.7%improvement in accuracy. These results confirm the effectiveness, efficiency,and robustness of our approach for low-resource domain adaptation of LLMs.</description><author>Mingchen Tu, Zhiqiang Liu, Juan Li, Liangyurui Liu, Junjie Wang, Lei Liang, Wen Zhang</author><pubDate>Thu, 30 Oct 2025 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26683v1</guid></item><item><title>Improving Classification of Occluded Objects through Scene Context</title><link>http://arxiv.org/abs/2510.26681v1</link><description>The presence of occlusions has provided substantial challenges totypically-powerful object recognition algorithms. Additional sources ofinformation can be extremely valuable to reduce errors caused by occlusions.Scene context is known to aid in object recognition in biological vision. Inthis work, we attempt to add robustness into existing Region ProposalNetwork-Deep Convolutional Neural Network (RPN-DCNN) object detection networksthrough two distinct scene-based information fusion techniques. We present onealgorithm under each methodology: the first operates prior to prediction,selecting a custom object network to use based on the identified backgroundscene, and the second operates after detection, fusing scene knowledge intoinitial object scores output by the RPN. We demonstrate our algorithms onchallenging datasets featuring partial occlusions, which show overallimprovement in both recall and precision against baseline methods. In addition,our experiments contrast multiple training methodologies for occlusionhandling, finding that training on a combination of both occluded andunoccluded images demonstrates an improvement over the others. Our method isinterpretable and can easily be adapted to other datasets, offering many futuredirections for research and practical applications.</description><author>Courtney M. King, Daniel D. Leeds, Damian Lyons, George Kalaitzis</author><pubDate>Thu, 30 Oct 2025 16:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26681v1</guid></item><item><title>GSE: Group-wise Sparse and Explainable Adversarial Attacks</title><link>http://arxiv.org/abs/2311.17434v5</link><description>Sparse adversarial attacks fool deep neural networks (DNNs) through minimalpixel perturbations, often regularized by the $\ell_0$ norm. Recent effortshave replaced this norm with a structural sparsity regularizer, such as thenuclear group norm, to craft group-wise sparse adversarial attacks. Theresulting perturbations are thus explainable and hold significant practicalrelevance, shedding light on an even greater vulnerability of DNNs. However,crafting such attacks poses an optimization challenge, as it involves computingnorms for groups of pixels within a non-convex objective. We address this bypresenting a two-phase algorithm that generates group-wise sparse attackswithin semantically meaningful areas of an image. Initially, we optimize aquasinorm adversarial loss using the $1/2-$quasinorm proximal operator tailoredfor non-convex programming. Subsequently, the algorithm transitions to aprojected Nesterov's accelerated gradient descent with $2-$norm regularizationapplied to perturbation magnitudes. Rigorous evaluations on CIFAR-10 andImageNet datasets demonstrate a remarkable increase in group-wise sparsity,e.g., $50.9\%$ on CIFAR-10 and $38.4\%$ on ImageNet (average case, targetedattack). This performance improvement is accompanied by significantly fastercomputation times, improved explainability, and a $100\%$ attack success rate.</description><author>Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta</author><pubDate>Thu, 30 Oct 2025 16:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17434v5</guid></item><item><title>Tight Differentially Private PCA via Matrix Coherence</title><link>http://arxiv.org/abs/2510.26679v1</link><description>We revisit the task of computing the span of the top $r$ singular vectors$u_1, \ldots, u_r$ of a matrix under differential privacy. We show that asimple and efficient algorithm -- based on singular value decomposition andstandard perturbation mechanisms -- returns a private rank-$r$ approximationwhose error depends only on the \emph{rank-$r$ coherence} of $u_1, \ldots, u_r$and the spectral gap $\sigma_r - \sigma_{r+1}$. This resolves a question posedby Hardt and Roth~\cite{hardt2013beyond}. Our estimator outperforms the stateof the art -- significantly so in some regimes. In particular, we show that inthe dense setting, it achieves the same guarantees for single-spike PCA in theWishart model as those attained by optimal non-private algorithms, whereasprior private algorithms failed to do so. In addition, we prove that (rank-$r$) coherence does not increase underGaussian perturbations. This implies that any estimator based on the Gaussianmechanism -- including ours -- preserves the coherence of the input. Weconjecture that similar behavior holds for other structured models, includingplanted problems in graphs. We also explore applications of coherence to graph problems. In particular,we present a differentially private algorithm for Max-Cut and other constraintsatisfaction problems under low coherence assumptions.</description><author>Tommaso d'Orsi, Gleb Novikov</author><pubDate>Thu, 30 Oct 2025 16:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26679v1</guid></item><item><title>Neural active manifolds: nonlinear dimensionality reduction for uncertainty quantification</title><link>http://arxiv.org/abs/2408.03534v2</link><description>We present a new approach for nonlinear dimensionality reduction,specifically designed for computationally expensive mathematical models. Weleverage autoencoders to discover a one-dimensional neural active manifold(NeurAM) capturing the model output variability, through the aid of asimultaneously learnt surrogate model with inputs on this manifold. Our methodonly relies on model evaluations and does not require the knowledge ofgradients. The proposed dimensionality reduction framework can then be appliedto assist outer loop many-query tasks in scientific computing, like sensitivityanalysis and multifidelity uncertainty propagation. In particular, we prove,both theoretically under idealized conditions, and numerically in challengingtest cases, how NeurAM can be used to obtain multifidelity sampling estimatorswith reduced variance by sampling the models on the discovered low-dimensionaland shared manifold among models. Several numerical examples illustrate themain features of the proposed dimensionality reduction strategy and highlightits advantages with respect to existing approaches in the literature.</description><author>Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Alison L. Marsden, Daniele E. Schiavazzi</author><pubDate>Thu, 30 Oct 2025 16:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03534v2</guid></item><item><title>Resource Efficient Multi-stain Kidney Glomeruli Segmentation via Self-supervision</title><link>http://arxiv.org/abs/2412.15389v3</link><description>Semantic segmentation under domain shift remains a fundamental challenge incomputer vision, particularly when labelled training data is scarce. Thischallenge is particularly exemplified in histopathology image analysis, wherethe same tissue structures must be segmented across images captured underdifferent imaging conditions (stains), each representing a distinct visualdomain. Traditional deep learning methods like UNet require extensive labels,which is both costly and time-consuming, particularly when dealing withmultiple domains (or stains). To mitigate this, various unsupervised domainadaptation based methods such as UDAGAN have been proposed, which reduce theneed for labels by requiring only one (source) stain to be labelled.Nonetheless, obtaining source stain labels can still be challenging. Thisarticle shows that through self-supervised pre-training -- including SimCLR,BYOL, and a novel approach, HR-CS-CO -- the performance of these segmentationmethods (UNet, and UDAGAN) can be retained even with 95% fewer labels. Notably,with self-supervised pre-training and using only 5% labels, the performancedrops are minimal: 5.9% for UNet and 6.2% for UDAGAN, averaged over all stains,compared to their respective fully supervised counterparts (withoutpre-training, using 100% labels). Furthermore, these findings are shown togeneralise beyond their training distribution to public benchmark datasets.Implementations and pre-trained models are publicly available\href{https://github.com/zeeshannisar/resource-effecient-multi-stain-kidney-glomeruli-segmentation.git}{online}.</description><author>Zeeshan Nisar, Friedrich Feuerhake, Thomas Lampert</author><pubDate>Thu, 30 Oct 2025 16:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15389v3</guid></item></channel></rss>