<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 24 Oct 2024 01:00:22 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Robust Variable Selection for High-dimensional Regression with Missing Data and Measurement Errors</title><link>http://arxiv.org/abs/2410.16722v2</link><description>In our paper,we focus on robust variable selection for missing data andmeasurement error.Missing data and measurement errors can lead to confusingdata distribution.We propose an exponential loss function with tuning parameterto apply to Missing and measurement errors data.By adjusting the parameter,theloss functioncan be better and more robust under various different datadistributions.We use inverse probability weighting and additivityerrormodels toaddress missing data and measurement errors.Also,we find that the Atanpunishment method works better.We used Monte Carlo simulations to assess thevalidity of robust variable selection and validated our findings with thebreast cancer dataset</description><author>Zhenhao Zhang</author><pubDate>Wed, 23 Oct 2024 16:10:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16722v2</guid></item><item><title>GeoCode-GPT: A Large Language Model for Geospatial Code Generation Tasks</title><link>http://arxiv.org/abs/2410.17031v2</link><description>The increasing demand for spatiotemporal data and modeling tasks ingeosciences has made geospatial code generation technology a critical factor inenhancing productivity. Although large language models (LLMs) have demonstratedpotential in code generation tasks, they often encounter issues such as refusalto code or hallucination in geospatial code generation due to a lack ofdomain-specific knowledge and code corpora. To address these challenges, thispaper presents and open-sources the GeoCode-PT and GeoCode-SFT corpora, alongwith the GeoCode-Eval evaluation dataset. Additionally, by leveraging QLoRA andLoRA for pretraining and fine-tuning, we introduce GeoCode-GPT-7B, the firstLLM focused on geospatial code generation, fine-tuned from Code Llama-7B.Furthermore, we establish a comprehensive geospatial code evaluation framework,incorporating option matching, expert validation, and prompt engineeringscoring for LLMs, and systematically evaluate GeoCode-GPT-7B using theGeoCode-Eval dataset. Experimental results show that GeoCode-GPT outperformsother models in multiple-choice accuracy by 9.1% to 32.1%, in codesummarization ability by 1.7% to 25.4%, and in code generation capability by1.2% to 25.1%. This paper provides a solution and empirical validation forenhancing LLMs' performance in geospatial code generation, extends theboundaries of domain-specific model applications, and offers valuable insightsinto unlocking their potential in geospatial code generation.</description><author>Shuyang Hou, Zhangxiao Shen, Anqi Zhao, Jianyuan Liang, Zhipeng Gui, Xuefeng Guan, Rui Li, Huayi Wu</author><pubDate>Wed, 23 Oct 2024 13:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17031v2</guid></item><item><title>Optimal Design for Reward Modeling in RLHF</title><link>http://arxiv.org/abs/2410.17055v2</link><description>Reinforcement Learning from Human Feedback (RLHF) has become a popularapproach to align language models (LMs) with human preferences. This methodinvolves collecting a large dataset of human pairwise preferences acrossvarious text generations and using it to infer (implicitly or explicitly) areward model. Numerous methods have been proposed to learn the reward model andalign a LM with it. However, the costly process of collecting human preferenceshas received little attention and could benefit from theoretical insights. Thispaper addresses this issue and aims to formalize the reward training model inRLHF. We frame the selection of an effective dataset as a simple regretminimization task, using a linear contextual dueling bandit method. Given thepotentially large number of arms, this approach is more coherent than thebest-arm identification setting. We then propose an offline framework forsolving this problem. Under appropriate assumptions - linearity of the rewardmodel in the embedding space, and boundedness of the reward parameter - wederive bounds on the simple regret. Finally, we provide a lower bound thatmatches our upper bound up to constant and logarithmic terms. To our knowledge,this is the first theoretical contribution in this area to provide an offlineapproach as well as worst-case guarantees.</description><author>Antoine Scheid, Etienne Boursier, Alain Durmus, Michael I. Jordan, Pierre Ménard, Eric Moulines, Michal Valko</author><pubDate>Wed, 23 Oct 2024 12:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17055v2</guid></item><item><title>Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models</title><link>http://arxiv.org/abs/2405.15574v4</link><description>The rapid development of large language and vision models (LLVMs) has beendriven by advances in visual instruction tuning. Recently, open-source LLVMshave curated high-quality visual instruction tuning datasets and utilizedadditional vision encoders or multiple computer vision models in order tonarrow the performance gap with powerful closed-source LLVMs. Theseadvancements are attributed to multifaceted information required for diversecapabilities, including fundamental image understanding, real-world knowledgeabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,signs, and math problems), and step-by-step procedures for solving complexquestions. Drawing from the multifaceted information, we present a newefficient LLVM, Mamba-based traversal of rationales (Meteor), which leveragesmultifaceted rationale to enhance understanding and answering capabilities. Toembed lengthy rationales containing abundant information, we employ the Mambaarchitecture, capable of processing sequential data with linear timecomplexity. We introduce a new concept of traversal of rationale thatfacilitates efficient embedding of rationale. Subsequently, the backbonemultimodal language model (MLM) is trained to generate answers with the aid ofrationale. Through these steps, Meteor achieves significant improvements invision language performances across multiple evaluation benchmarks requiringdiverse capabilities, without scaling up the model size or employing additionalvision encoders and computer vision models.</description><author>Byung-Kwan Lee, Chae Won Kim, Beomchan Park, Yong Man Ro</author><pubDate>Wed, 23 Oct 2024 10:54:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15574v4</guid></item><item><title>xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories</title><link>http://arxiv.org/abs/2410.16928v2</link><description>Time series data is prevalent across numerous fields, necessitating thedevelopment of robust and accurate forecasting models. Capturing patterns bothwithin and between temporal and multivariate components is crucial for reliablepredictions. We introduce xLSTM-Mixer, a model designed to effectivelyintegrate temporal sequences, joint time-variate information, and multipleperspectives for robust forecasting. Our approach begins with a linear forecastshared across variates, which is then refined by xLSTM blocks. These blocksserve as key elements for modeling the complex dynamics of challenging timeseries data. xLSTM-Mixer ultimately reconciles two distinct views to producethe final forecast. Our extensive evaluations demonstrate xLSTM-Mixer'ssuperior long-term forecasting performance compared to recent state-of-the-artmethods. A thorough model analysis provides further insights into its keycomponents and confirms its robustness and effectiveness. This work contributesto the resurgence of recurrent models in time series forecasting.</description><author>Maurice Kraus, Felix Divo, Devendra Singh Dhami, Kristian Kersting</author><pubDate>Wed, 23 Oct 2024 08:13:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16928v2</guid></item><item><title>Non-myopic Generation of Language Model for Reasoning and Planning</title><link>http://arxiv.org/abs/2410.17195v2</link><description>Large Language Models have demonstrated remarkable abilities in reasoning andplanning by breaking down complex problems into sequential steps. Despite theirsuccess in various domains like mathematical problem-solving and coding, LLMsface challenges in ensuring reliable and optimal planning due to their inherentmyopic nature of autoregressive decoding. This paper revisits LLM reasoningfrom an optimal-control perspective, proposing a novel method,Predictive-Decoding, that leverages Model Predictive Control to enhanceplanning accuracy. By re-weighting LLM distributions based on foresighttrajectories, Predictive-Decoding aims to mitigate early errors and promotenon-myopic planning. Our experiments show significant improvements in a widerange of tasks for math, coding, and agents. Furthermore, Predictive-Decodingdemonstrates computational efficiency, outperforming search baselines withreduced computational resources. This study provides insights into optimizingLLM planning capabilities.</description><author>Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong</author><pubDate>Wed, 23 Oct 2024 07:02:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17195v2</guid></item><item><title>Understanding Transfer Learning via Mean-field Analysis</title><link>http://arxiv.org/abs/2410.17128v2</link><description>We propose a novel framework for exploring generalization errors of transferlearning through the lens of differential calculus on the space of probabilitymeasures. In particular, we consider two main transfer learning scenarios,$\alpha$-ERM and fine-tuning with the KL-regularized empirical riskminimization and establish generic conditions under which the generalizationerror and the population risk convergence rates for these scenarios arestudied. Based on our theoretical results, we show the benefits of transferlearning with a one-hidden-layer neural network in the mean-field regime undersome suitable integrability and regularity assumptions on the loss andactivation functions.</description><author>Gholamali Aminian, Łukasz Szpruch, Samuel N. Cohen</author><pubDate>Wed, 23 Oct 2024 06:51:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17128v2</guid></item><item><title>Toward Fairer Face Recognition Datasets</title><link>http://arxiv.org/abs/2406.16592v3</link><description>Face recognition and verification are two computer vision tasks whoseperformance has progressed with the introduction of deep representations.However, ethical, legal, and technical challenges due to the sensitivecharacter of face data and biases in real training datasets hinder theirdevelopment. Generative AI addresses privacy by creating fictitious identities,but fairness problems persist. We promote fairness by introducing a demographicattributes balancing mechanism in generated training datasets. We experimentwith an existing real dataset, three generated training datasets, and thebalanced versions of a diffusion-based dataset. We propose a comprehensiveevaluation that considers accuracy and fairness equally and includes a rigorousregression-based statistical analysis of attributes. The analysis shows thatbalancing reduces demographic unfairness. Also, a performance gap persistsdespite generation becoming more accurate with time. The proposed balancingmethod and comprehensive verification evaluation promote fairer and transparentface recognition and verification.</description><author>Alexandre Fournier-Montgieux, Michael Soumm, Adrian Popescu, Bertrand Luvison, Hervé Le Borgne</author><pubDate>Wed, 23 Oct 2024 06:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16592v3</guid></item><item><title>Masked Clinical Modelling: A Framework for Synthetic and Augmented Survival Data Generation</title><link>http://arxiv.org/abs/2410.16811v2</link><description>Access to real clinical data is often restricted due to privacy obligations,creating significant barriers for healthcare research. Synthetic datasetsprovide a promising solution, enabling secure data sharing and modeldevelopment. However, most existing approaches focus on data realism ratherthan utility -- ensuring that models trained on synthetic data yield clinicallymeaningful insights comparable to those trained on real data. In this paper, wepresent Masked Clinical Modelling (MCM), a framework inspired by maskedlanguage modelling, designed for both data synthesis and conditional dataaugmentation. We evaluate this prototype on the WHAS500 dataset using CoxProportional Hazards models, focusing on the preservation of hazard ratios askey clinical metrics. Our results show that data generated using the MCMframework improves both discrimination and calibration in survival analysis,outperforming existing methods. MCM demonstrates strong potential to supportsurvival data analysis and broader healthcare applications.</description><author>Nicholas I-Hsien Kuo, Blanca Gallego, Louisa Jorm</author><pubDate>Wed, 23 Oct 2024 05:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16811v2</guid></item><item><title>LLMScan: Causal Scan for LLM Misbehavior Detection</title><link>http://arxiv.org/abs/2410.16638v2</link><description>Despite the success of Large Language Models (LLMs) across various fields,their potential to generate untruthful, biased and harmful responses posessignificant risks, particularly in critical applications. This highlights theurgent need for systematic methods to detect and prevent such misbehavior.While existing approaches target specific issues such as harmful responses,this work introduces LLMScan, an innovative LLM monitoring technique based oncausality analysis, offering a comprehensive solution. LLMScan systematicallymonitors the inner workings of an LLM through the lens of causal inference,operating on the premise that the LLM's `brain' behaves differently whenmisbehaving. By analyzing the causal contributions of the LLM's input tokensand transformer layers, LLMScan effectively detects misbehavior. Extensiveexperiments across various tasks and models reveal clear distinctions in thecausal distributions between normal behavior and misbehavior, enabling thedevelopment of accurate, lightweight detectors for a variety of misbehaviordetection tasks.</description><author>Mengdi Zhang, Kai Kiat Goh, Peixin Zhang, Jun Sun</author><pubDate>Wed, 23 Oct 2024 03:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16638v2</guid></item><item><title>AskBeacon -- Performing genomic data exchange and analytics with natural language</title><link>http://arxiv.org/abs/2410.16700v2</link><description>Enabling clinicians and researchers to directly interact with global genomicdata resources by removing technological barriers is vital for medicalgenomics. AskBeacon enables Large Language Models to be applied to securelyshared cohorts via the GA4GH Beacon protocol. By simply "asking" Beacon,actionable insights can be gained, analyzed and made publication-ready.</description><author>Anuradha Wickramarachchi, Shakila Tonni, Sonali Majumdar, Sarvnaz Karimi, Sulev Kõks, Brendan Hosking, Jordi Rambla, Natalie A. Twine, Yatish Jain, Denis C. Bauer</author><pubDate>Wed, 23 Oct 2024 02:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16700v2</guid></item><item><title>Altogether: Image Captioning via Re-aligning Alt-text</title><link>http://arxiv.org/abs/2410.17251v1</link><description>This paper focuses on creating synthetic data to improve the quality of imagecaptions. Existing works typically have two shortcomings. First, they captionimages from scratch, ignoring existing alt-text metadata, and second, lacktransparency if the captioners' training data (e.g. GPT) is unknown. In thispaper, we study a principled approach Altogether based on the key idea to editand re-align existing alt-texts associated with the images. To generatetraining data, we perform human annotation where annotators start with theexisting alt-text and re-align it to the image content in multiple rounds,consequently constructing captions with rich visual concepts. This differs fromprior work that carries out human annotation as a one-time description tasksolely based on images and annotator knowledge. We train a captioner on thisdata that generalizes the process of re-aligning alt-texts at scale. Ourresults show our Altogether approach leads to richer image captions that alsoimprove text-to-image generation and zero-shot image classification tasks.</description><author>Hu Xu, Po-Yao Huang, Xiaoqing Ellen Tan, Ching-Feng Yeh, Jacob Kahn, Christine Jou, Gargi Ghosh, Omer Levy, Luke Zettlemoyer, Wen-tau Yih, Shang-Wen Li, Saining Xie, Christoph Feichtenhofer</author><pubDate>Tue, 22 Oct 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17251v1</guid></item><item><title>JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation</title><link>http://arxiv.org/abs/2410.17250v1</link><description>Accelerating research on Large Multimodal Models (LMMs) in non-Englishlanguages is crucial for enhancing user experiences across broader populations.In this paper, we introduce JMMMU (Japanese MMMU), the first large-scaleJapanese benchmark designed to evaluate LMMs on expert-level tasks based on theJapanese cultural context. To facilitate comprehensive culture-awareevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)subset, where the culture-independent subjects (e.g., Math) are selected andtranslated into Japanese, enabling one-to-one comparison with its Englishcounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newlycrafted subjects that reflect Japanese cultural context. Using the CA subset,we observe performance drop in many LMMs when evaluated in Japanese, which ispurely attributable to language variation. Using the CS subset, we reveal theirinadequate Japanese cultural understanding. Further, by combining both subsets,we identify that some LMMs perform well on the CA subset but not on the CSsubset, exposing a shallow understanding of the Japanese language that lacksdepth in cultural understanding. We hope this work will not only help advanceLMM performance in Japanese but also serve as a guideline to createhigh-standard, culturally diverse benchmarks for multilingual LMM development.The project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.</description><author>Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Kazuki Egashira, Jeonghun Baek, Xiang Yue, Graham Neubig, Kiyoharu Aizawa</author><pubDate>Tue, 22 Oct 2024 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17250v1</guid></item><item><title>SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes</title><link>http://arxiv.org/abs/2410.17249v1</link><description>We present SpectroMotion, a novel approach that combines 3D GaussianSplatting (3DGS) with physically-based rendering (PBR) and deformation fieldsto reconstruct dynamic specular scenes. Previous methods extending 3DGS tomodel dynamic scenes have struggled to accurately represent specular surfaces.Our method addresses this limitation by introducing a residual correctiontechnique for accurate surface normal computation during deformation,complemented by a deformable environment map that adapts to time-varyinglighting conditions. We implement a coarse-to-fine training strategy thatsignificantly enhances both scene geometry and specular color prediction. Wedemonstrate that our model outperforms prior methods for view synthesis ofscenes containing dynamic specular objects and that it is the only existing3DGS method capable of synthesizing photorealistic real-world dynamic specularscenes, outperforming state-of-the-art methods in rendering complex, dynamic,and specular scenes.</description><author>Cheng-De Fan, Chen-Wei Chang, Yi-Ruei Liu, Jie-Ying Lee, Jiun-Long Huang, Yu-Chee Tseng, Yu-Lun Liu</author><pubDate>Tue, 22 Oct 2024 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17249v1</guid></item><item><title>HyperspectralViTs: Fast and Accurate methane detection on-board satellites</title><link>http://arxiv.org/abs/2410.17248v1</link><description>On-board processing of hyperspectral data with machine learning models wouldenable unprecedented amount of autonomy for a wide range of tasks, for examplemethane detection or mineral identification. Methane is the second mostimportant greenhouse gas contributor to climate change, and it's automateddetection on-board of satellites using machine learning models would allow forearly warning system and could enable new capabilities such as automatedscheduling inside constellations of satellites. Classical methods for methanedetection suffer from high false positive rates and previous deep learningmodels exhibit prohibitive computational requirements. We propose fast andaccurate machine learning architectures which support end-to-end training withdata of high spectral dimension. We evaluate our models on two tasks related tohyperspectral data processing - methane leak detection and mineralidentification. With our proposed general architectures, we improve the F1score of the previous methane detection state-of-the-art models by more than27% on a newly created synthetic dataset and by almost 13% on the previouslyreleased large benchmark dataset. We also demonstrate that training models onthe synthetic dataset improves performance of models finetuned on the datasetof real events by 6.9% in F1 score in contrast with training from scratch. On anewly created dataset for mineral identification, our models provide 3.5%improvement in the F1 score in contrast to the default versions of the models.With our proposed models we improve the inference speed by 85.19% in contrastto previous classical and deep learning approaches by removing the dependencyon classically computed features. Namely, one capture from the EMIT sensor canbe processed in only 30 seconds on a realistic proxy hardware used on theION-SCV 004 satellite.</description><author>Vít Růžička, Andrew Markham</author><pubDate>Tue, 22 Oct 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17248v1</guid></item><item><title>PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction</title><link>http://arxiv.org/abs/2410.17247v1</link><description>In large vision-language models (LVLMs), images serve as inputs that carry awealth of information. As the idiom "A picture is worth a thousand words"implies, representing a single image in current LVLMs can require hundreds oreven thousands of tokens. This results in significant computational costs,which grow quadratically as input image resolution increases, thereby severelyimpacting the efficiency of both training and inference. Previous approacheshave attempted to reduce the number of image tokens either before or within theearly layers of LVLMs. However, these strategies inevitably result in the lossof crucial image information, ultimately diminishing model performance. Toaddress this challenge, we conduct an empirical study revealing that all visualtokens are necessary for LVLMs in the shallow layers, and token redundancyprogressively increases in the deeper layers of the model. To this end, wepropose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boosttheir efficiency in both training and inference with neglectable performanceloss. Specifically, we partition the LVLM into several stages and drop part ofthe image tokens at the end of each stage with a pre-defined ratio, creatingpyramid-like visual tokens across model layers. The dropping is based on alightweight similarity calculation with a negligible time overhead. Extensiveexperiments demonstrate that PyramidDrop can achieve a 40% training time and55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.Besides, the PyramidDrop could also serve as a plug-and-play strategy forinference acceleration without training, with better performance and lowerinference cost than counterparts. We hope that the insights and approachintroduced by PyramidDrop will inspire future research to further investigatethe role of image tokens in LVLMs.</description><author>Long Xing, Qidong Huang, Xiaoyi Dong, Jiajie Lu, Pan Zhang, Yuhang Zang, Yuhang Cao, Conghui He, Jiaqi Wang, Feng Wu, Dahua Lin</author><pubDate>Tue, 22 Oct 2024 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17247v1</guid></item><item><title>Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins</title><link>http://arxiv.org/abs/2410.17246v1</link><description>While visuomotor policy learning has advanced robotic manipulation, preciselyexecuting contact-rich tasks remains challenging due to the limitations ofvision in reasoning about physical interactions. To address this, recent workhas sought to integrate tactile sensing into policy learning. However, manyexisting approaches rely on optical tactile sensors that are either restrictedto recognition tasks or require complex dimensionality reduction steps forpolicy learning. In this work, we explore learning policies with magnetic skinsensors, which are inherently low-dimensional, highly sensitive, andinexpensive to integrate with robotic platforms. To leverage these sensorseffectively, we present the Visuo-Skin (ViSk) framework, a simple approach thatuses a transformer-based policy and treats skin sensor data as additionaltokens alongside visual information. Evaluated on four complex real-world tasksinvolving credit card swiping, plug insertion, USB insertion, and bookshelfretrieval, ViSk significantly outperforms both vision-only and optical tactilesensing based policies. Further analysis reveals that combining tactile andvisual modalities enhances policy performance and spatial generalization,achieving an average improvement of 27.5% across tasks.https://visuoskin.github.io/</description><author>Venkatesh Pattabiraman, Yifeng Cao, Siddhant Haldar, Lerrel Pinto, Raunaq Bhirangi</author><pubDate>Tue, 22 Oct 2024 17:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17246v1</guid></item><item><title>Towards Reliable Evaluation of Behavior Steering Interventions in LLMs</title><link>http://arxiv.org/abs/2410.17245v1</link><description>Representation engineering methods have recently shown promise for enablingefficient steering of model behavior. However, evaluation pipelines for thesemethods have primarily relied on subjective demonstrations, instead ofquantitative, objective metrics. We aim to take a step towards addressing thisissue by advocating for four properties missing from current evaluations: (i)contexts sufficiently similar to downstream tasks should be used for assessingintervention quality; (ii) model likelihoods should be accounted for; (iii)evaluations should allow for standardized comparisons across different targetbehaviors; and (iv) baseline comparisons should be offered. We introduce anevaluation pipeline grounded in these criteria, offering both a quantitativeand visual analysis of how effectively a given method works. We use thispipeline to evaluate two representation engineering methods on how effectivelythey can steer behaviors such as truthfulness and corrigibility, finding thatsome interventions are less effective than previously reported.</description><author>Itamar Pres, Laura Ruis, Ekdeep Singh Lubana, David Krueger</author><pubDate>Tue, 22 Oct 2024 17:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17245v1</guid></item><item><title>Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss</title><link>http://arxiv.org/abs/2410.17243v1</link><description>Contrastive loss is a powerful approach for representation learning, wherelarger batch sizes enhance performance by providing more negative samples tobetter distinguish between similar and dissimilar data. However, scaling batchsizes is constrained by the quadratic growth in GPU memory consumption,primarily due to the full instantiation of the similarity matrix. To addressthis, we propose a tile-based computation strategy that partitions thecontrastive loss calculation into arbitrary small blocks, avoiding fullmaterialization of the similarity matrix. Furthermore, we introduce amulti-level tiling strategy to leverage the hierarchical structure ofdistributed systems, employing ring-based communication at the GPU level tooptimize synchronization and fused kernels at the CUDA core level to reduce I/Ooverhead. Experimental results show that the proposed method scales batch sizesto unprecedented levels. For instance, it enables contrastive training of aCLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GBwithout sacrificing any accuracy. Compared to SOTA memory-efficient solutions,it achieves a two-order-of-magnitude reduction in memory while maintainingcomparable speed. The code will be made publicly available.</description><author>Zesen Cheng, Hang Zhang, Kehan Li, Sicong Leng, Zhiqiang Hu, Fei Wu, Deli Zhao, Xin Li, Lidong Bing</author><pubDate>Tue, 22 Oct 2024 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17243v1</guid></item><item><title>LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</title><link>http://arxiv.org/abs/2410.17242v1</link><description>We propose the Large View Synthesis Model (LVSM), a novel transformer-basedapproach for scalable and generalizable novel view synthesis from sparse-viewinputs. We introduce two architectures: (1) an encoder-decoder LVSM, whichencodes input image tokens into a fixed number of 1D latent tokens, functioningas a fully learned scene representation, and decodes novel-view images fromthem; and (2) a decoder-only LVSM, which directly maps input images tonovel-view outputs, completely eliminating intermediate scene representations.Both models bypass the 3D inductive biases used in previous methods -- from 3Drepresentations (e.g., NeRF, 3DGS) to network designs (e.g., epipolarprojections, plane sweeps) -- addressing novel view synthesis with a fullydata-driven approach. While the encoder-decoder model offers faster inferencedue to its independent latent representation, the decoder-only LVSM achievessuperior quality, scalability, and zero-shot generalization, outperformingprevious state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensiveevaluations across multiple datasets demonstrate that both LVSM variantsachieve state-of-the-art novel view synthesis quality. Notably, our modelssurpass all previous methods even with reduced computational resources (1-2GPUs). Please see our website for more details:https://haian-jin.github.io/projects/LVSM/ .</description><author>Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi, Tianyuan Zhang, Fujun Luan, Noah Snavely, Zexiang Xu</author><pubDate>Tue, 22 Oct 2024 17:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17242v1</guid></item><item><title>Frontiers in Intelligent Colonoscopy</title><link>http://arxiv.org/abs/2410.17241v1</link><description>Colonoscopy is currently one of the most sensitive screening methods forcolorectal cancer. This study investigates the frontiers of intelligentcolonoscopy techniques and their prospective implications for multimodalmedical applications. With this goal, we begin by assessing the currentdata-centric and model-centric landscapes through four tasks for colonoscopicscene perception, including classification, detection, segmentation, andvision-language understanding. This assessment enables us to identifydomain-specific challenges and reveals that multimodal research in colonoscopyremains open for further exploration. To embrace the coming multimodal era, weestablish three foundational initiatives: a large-scale multimodal instructiontuning dataset ColonINST, a colonoscopy-designed multimodal language modelColonGPT, and a multimodal benchmark. To facilitate ongoing monitoring of thisrapidly evolving field, we provide a public website for the latest updates:https://github.com/ai4colonoscopy/IntelliScope.</description><author>Ge-Peng Ji, Jingyi Liu, Peng Xu, Nick Barnes, Fahad Shahbaz Khan, Salman Khan, Deng-Ping Fan</author><pubDate>Tue, 22 Oct 2024 17:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17241v1</guid></item><item><title>SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</title><link>http://arxiv.org/abs/2410.17238v1</link><description>Automated Machine Learning (AutoML) approaches encompass traditional methodsthat optimize fixed pipelines for model selection and ensembling, as well asnewer LLM-based frameworks that autonomously build pipelines. While LLM-basedagents have shown promise in automating machine learning tasks, they oftengenerate low-diversity and suboptimal code, even after multiple iterations. Toovercome these limitations, we introduce Tree-Search Enhanced LLM Agents(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search(MCTS) to optimize the AutoML process. By representing pipeline configurationsas trees, our framework enables agents to conduct experiments intelligently anditeratively refine their strategies, facilitating a more effective explorationof the machine learning solution space. This novel approach allows SELA todiscover optimal pathways based on experimental feedback, improving the overallquality of the solutions. In an extensive evaluation across 20 machine learningdatasets, we compare the performance of traditional and agent-based AutoMLmethods, demonstrating that SELA achieves a win rate of 65% to 80% against eachbaseline across all datasets. These results underscore the significantpotential of agent-based strategies in AutoML, offering a fresh perspective ontackling complex machine learning challenges.</description><author>Yizhou Chi, Yizhang Lin, Sirui Hong, Duyi Pan, Yaying Fei, Guanghao Mei, Bangbang Liu, Tianqi Pang, Jacky Kwok, Ceyao Zhang, Bang Liu, Chenglin Wu</author><pubDate>Tue, 22 Oct 2024 17:56:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17238v1</guid></item><item><title>Large Language Models Empowered Personalized Web Agents</title><link>http://arxiv.org/abs/2410.17236v1</link><description>Web agents have emerged as a promising direction to automate Web taskcompletion based on user instructions, significantly enhancing user experience.Recently, Web agents have evolved from traditional agents to Large LanguageModels (LLMs)-based Web agents. Despite their success, existing LLM-based Webagents overlook the importance of personalized data (e.g., user profiles andhistorical Web behaviors) in assisting the understanding of users' personalizedinstructions and executing customized actions. To overcome the limitation, wefirst formulate the task of LLM-empowered personalized Web agents, whichintegrate personalized data and user instructions to personalize instructioncomprehension and action execution. To address the absence of a comprehensiveevaluation benchmark, we construct a Personalized Web Agent Benchmark(PersonalWAB), featuring user instructions, personalized user data, Webfunctions, and two evaluation paradigms across three personalized Web tasks.Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)framework to adapt LLMs to the personalized Web agent task. PUMA utilizes amemory bank with a task-specific retrieval strategy to filter relevanthistorical Web behaviors. Based on the behaviors, PUMA then aligns LLMs forpersonalized action execution through fine-tuning and direct preferenceoptimization. Extensive experiments validate the superiority of PUMA overexisting Web agents on PersonalWAB.</description><author>Hongru Cai, Yongqi Li, Wenjie Wang, Fengbin Zhu, Xiaoyu Shen, Wenjie Li, Tat-Seng Chua</author><pubDate>Tue, 22 Oct 2024 17:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17236v1</guid></item><item><title>Automated Spinal MRI Labelling from Reports Using a Large Language Model</title><link>http://arxiv.org/abs/2410.17235v1</link><description>We propose a general pipeline to automate the extraction of labels fromradiology reports using large language models, which we validate on spinal MRIreports. The efficacy of our labelling method is measured on five distinctconditions: spinal cancer, stenosis, spondylolisthesis, cauda equinacompression and herniation. Using open-source models, our method equals orsurpasses GPT-4 on a held-out set of reports. Furthermore, we show that theextracted labels can be used to train imaging models to classify the identifiedconditions in the accompanying MR scans. All classifiers trained usingautomated labels achieve comparable performance to models trained using scansmanually annotated by clinicians. Code can be found athttps://github.com/robinyjpark/AutoLabelClassifier.</description><author>Robin Y. Park, Rhydian Windsor, Amir Jamaludin, Andrew Zisserman</author><pubDate>Tue, 22 Oct 2024 17:54:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17235v1</guid></item><item><title>Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy</title><link>http://arxiv.org/abs/2410.17234v1</link><description>Large Language Models (LLMs) are known to hallucinate, whereby they generateplausible but inaccurate text. This phenomenon poses significant risks incritical applications, such as medicine or law, necessitating robusthallucination mitigation strategies. While recent works have proposedfine-tuning methods to teach LLMs to abstain from answering questions beyondtheir knowledge or capabilities, these methods rely on the existence ofground-truth labels or are limited to short-form responses. To address theselimitations, we propose fine-tuning using semantic entropy, an uncertaintymeasure derived from introspection into the model which does not requireexternal labels. We demonstrate that our approach matches or outperforms modelsfine-tuned using prior work and achieves strong performance for both short andlong-form generations on a range of datasets.</description><author>Benedict Aaron Tjandra, Muhammed Razzak, Jannik Kossen, Kunal Handa, Yarin Gal</author><pubDate>Tue, 22 Oct 2024 17:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17234v1</guid></item><item><title>Few-shot In-Context Preference Learning Using Large Language Models</title><link>http://arxiv.org/abs/2410.17233v1</link><description>Designing reward functions is a core component of reinforcement learning butcan be challenging for truly complex behavior. Reinforcement Learning fromHuman Feedback (RLHF) has been used to alleviate this challenge by replacing ahand-coded reward function with a reward function learned from preferences.However, it can be exceedingly inefficient to learn these rewards as they areoften learned tabula rasa. We investigate whether Large Language Models (LLMs)can reduce this query inefficiency by converting an iterative series of humanpreferences into code representing the rewards. We propose In-ContextPreference Learning (ICPL), a method that uses the grounding of an LLM toaccelerate learning reward functions from preferences. ICPL takes theenvironment context and task description, synthesizes a set of rewardfunctions, and then repeatedly updates the reward functions using humanrankings of videos of the resultant policies. Using synthetic preferences, wedemonstrate that ICPL is orders of magnitude more efficient than RLHF and iseven competitive with methods that use ground-truth reward functions instead ofpreferences. Finally, we perform a series of human preference-learning trialsand observe that ICPL extends beyond synthetic settings and can workeffectively with humans-in-the-loop. Additional information and videos areprovided at https://sites.google.com/view/few-shot-icpl/home.</description><author>Chao Yu, Hong Lu, Jiaxuan Gao, Qixin Tan, Xinting Yang, Yu Wang, Yi Wu, Eugene Vinitsky</author><pubDate>Tue, 22 Oct 2024 17:53:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17233v1</guid></item><item><title>Optimal Robust Estimation under Local and Global Corruptions: Stronger Adversary and Smaller Error</title><link>http://arxiv.org/abs/2410.17230v1</link><description>Algorithmic robust statistics has traditionally focused on the contaminationmodel where a small fraction of the samples are arbitrarily corrupted. Weconsider a recent contamination model that combines two kinds of corruptions:(i) small fraction of arbitrary outliers, as in classical robust statistics,and (ii) local perturbations, where samples may undergo bounded shifts onaverage. While each noise model is well understood individually, the combinedcontamination model poses new algorithmic challenges, with only partial resultsknown. Existing efficient algorithms are limited in two ways: (i) they workonly for a weak notion of local perturbations, and (ii) they obtain suboptimalerror for isotropic subgaussian distributions (among others). The latterlimitation led [NGS24, COLT'24] to hypothesize that improving the error might,in fact, be computationally hard. Perhaps surprisingly, we show thatinformation theoretically optimal error can indeed be achieved in polynomialtime, under an even \emph{stronger} local perturbation model (thesliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, ouranalysis reveals that the entire family of stability-based robust meanestimators continues to work optimally in a black-box manner for the combinedcontamination model. This generalization is particularly useful in real-worldscenarios where the specific form of data corruption is not known in advance.We also present efficient algorithms for distribution learning and principalcomponent analysis in the combined contamination model.</description><author>Thanasis Pittas, Ankit Pensia</author><pubDate>Tue, 22 Oct 2024 17:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17230v1</guid></item><item><title>Responsibility in a Multi-Value Strategic Setting</title><link>http://arxiv.org/abs/2410.17229v1</link><description>Responsibility is a key notion in multi-agent systems and in creating safe,reliable and ethical AI. However, most previous work on responsibility has onlyconsidered responsibility for single outcomes. In this paper we present a modelfor responsibility attribution in a multi-agent, multi-value setting. We alsoexpand our model to cover responsibility anticipation, demonstrating howconsiderations of responsibility can help an agent to select strategies thatare in line with its values. In particular we show that non-dominatedregret-minimising strategies reliably minimise an agent's expected degree ofresponsibility.</description><author>Timothy Parker, Umberto Grandi, Emiliano Lorini</author><pubDate>Tue, 22 Oct 2024 17:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17229v1</guid></item><item><title>BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval</title><link>http://arxiv.org/abs/2407.12883v2</link><description>Existing retrieval benchmarks primarily consist of information-seekingqueries (e.g., aggregated questions from search engines) where keyword orsemantic-based retrieval is usually sufficient. However, many complexreal-world queries require in-depth reasoning to identify relevant documentsthat go beyond surface form matching. For example, finding documentation for acoding question requires understanding the logic and syntax of the functionsinvolved. To better benchmark retrieval on such challenging queries, weintroduce BRIGHT, the first text retrieval benchmark that requires intensivereasoning to retrieve relevant documents. Our dataset consists of 1,384real-world queries spanning diverse domains, such as economics, psychology,mathematics, and coding. These queries are drawn from naturally occurring andcarefully curated human data. Extensive evaluation reveals that evenstate-of-the-art retrieval models perform poorly on BRIGHT. The leading modelon the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show thatincorporating explicit reasoning about the query improves retrieval performanceby up to 12.2 points. Moreover, incorporating retrieved documents from thetop-performing retriever boosts question-answering performance by over 6.6points. We believe that BRIGHT paves the way for future research on retrievalsystems in more realistic and challenging settings.</description><author>Hongjin Su, Howard Yen, Mengzhou Xia, Weijia Shi, Niklas Muennighoff, Han-yu Wang, Haisu Liu, Quan Shi, Zachary S. Siegel, Michael Tang, Ruoxi Sun, Jinsung Yoon, Sercan O. Arik, Danqi Chen, Tao Yu</author><pubDate>Tue, 22 Oct 2024 17:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12883v2</guid></item><item><title>The Persian Rug: solving toy models of superposition using large-scale symmetries</title><link>http://arxiv.org/abs/2410.12101v2</link><description>We present a complete mechanistic description of the algorithm learned by aminimal non-linear sparse data autoencoder in the limit of large inputdimension. The model, originally presented in arXiv:2209.10652, compressessparse data vectors through a linear layer and decompresses using anotherlinear layer followed by a ReLU activation. We notice that when the data ispermutation symmetric (no input feature is privileged) large models reliablylearn an algorithm that is sensitive to individual weights only through theirlarge-scale statistics. For these models, the loss function becomesanalytically tractable. Using this understanding, we give the explicit scalingsof the loss at high sparsity, and show that the model is near-optimal amongrecently proposed architectures. In particular, changing or adding to theactivation function any elementwise or filtering operation can at best improvethe model's performance by a constant factor. Finally, we forward-engineer amodel with the requisite symmetries and show that its loss precisely matchesthat of the trained models. Unlike the trained model weights, the lowrandomness in the artificial weights results in miraculous fractal structuresresembling a Persian rug, to which the algorithm is oblivious. Our workcontributes to neural network interpretability by introducing techniques forunderstanding the structure of autoencoders. Code to reproduce our results canbe found at https://github.com/KfirD/PersianRug .</description><author>Aditya Cowsik, Kfir Dolev, Alex Infanger</author><pubDate>Tue, 22 Oct 2024 17:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12101v2</guid></item><item><title>Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing</title><link>http://arxiv.org/abs/2410.17225v1</link><description>Climate change poses critical challenges globally, disproportionatelyaffecting low-income countries that often lack resources and linguisticrepresentation on the international stage. Despite Bangladesh's status as oneof the most vulnerable nations to climate impacts, research gaps persist inBengali-language studies related to climate change and NLP. To address thisdisparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change andenvironmental news dataset, comprising a 2300 annotated Bangla news articles,offering multiple perspectives such as political influence,scientific/statistical data, authenticity, stance detection, and stakeholderinvolvement. Furthermore, we present an in-depth exploratory analysis ofDhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model familyfor climate and environmental opinion detection in Bangla, fine-tuned on ourdataset. This research contributes significantly to enhancing accessibility andanalysis of climate discourse in Bengali (Bangla), addressing crucialcommunication and research gaps in climate-impacted regions like Bangladeshwith 180 million people.</description><author>Azmine Toushik Wasi, Wahid Faisal, Taj Ahmad, Abdur Rahman, Mst Rafia Islam</author><pubDate>Tue, 22 Oct 2024 17:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17225v1</guid></item><item><title>Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods</title><link>http://arxiv.org/abs/2410.17222v1</link><description>Fine-tuning Large Language Models (LLMs) typically involves updating at leasta few billions of parameters. A more parameter-efficient approach is PromptTuning (PT), which updates only a few learnable tokens, and differently,In-Context Learning (ICL) adapts the model to a new task by simply includingexamples in the input without any training. When applying optimization-basedmethods, such as fine-tuning and PT for few-shot learning, the model isspecifically adapted to the small set of training examples, whereas ICL leavesthe model unchanged. This distinction makes traditional learning methods moreprone to overfitting; in contrast, ICL is less sensitive to the few-shotscenario. While ICL is not prone to overfitting, it does not fully extract theinformation that exists in the training examples. This work introducesContext-aware Prompt Tuning (CPT), a method inspired by ICL, PT, andadversarial attacks. We build on the ICL strategy of concatenating examplesbefore the input, but we extend this by PT-like learning, refining the contextembedding through iterative optimization to extract deeper insights from thetraining examples. We carefully modify specific context tokens, considering theunique structure of input and output formats. Inspired by adversarial attacks,we adjust the input based on the labels present in the context, focusing onminimizing, rather than maximizing, the loss. Moreover, we apply a projectedgradient descent algorithm to keep token embeddings close to their originalvalues, under the assumption that the user-provided data is inherentlyvaluable. Our method has been shown to achieve superior accuracy acrossmultiple classification tasks using various LLM models.</description><author>Tsachi Blau, Moshe Kimhi, Yonatan Belinkov, Alexander Bronstein, Chaim Baskin</author><pubDate>Tue, 22 Oct 2024 17:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17222v1</guid></item><item><title>Scalable spectral representations for network multiagent control</title><link>http://arxiv.org/abs/2410.17221v1</link><description>Network Markov Decision Processes (MDPs), a popular model for multi-agentcontrol, pose a significant challenge to efficient learning due to theexponential growth of the global state-action space with the number of agents.In this work, utilizing the exponential decay property of network dynamics, wefirst derive scalable spectral local representations for network MDPs, whichinduces a network linear subspace for the local $Q$-function of each agent.Building on these local spectral representations, we design a scalablealgorithmic framework for continuous state-action network MDPs, and provideend-to-end guarantees for the convergence of our algorithm. Empirically, wevalidate the effectiveness of our scalable representation-based approach on twobenchmark problems, and demonstrate the advantages of our approach over genericfunction approximation approaches to representing the local $Q$-functions.</description><author>Zhaolin Ren, Runyu, Zhang, Bo Dai, Na Li</author><pubDate>Tue, 22 Oct 2024 17:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17221v1</guid></item><item><title>Creativity in AI: Progresses and Challenges</title><link>http://arxiv.org/abs/2410.17218v1</link><description>Creativity is the ability to produce novel, useful, and surprising ideas, andhas been widely studied as a crucial aspect of human cognition. Machinecreativity on the other hand has been a long-standing challenge. With the riseof advanced generative AI, there has been renewed interest and debate regardingAI's creative capabilities. Therefore, it is imperative to revisit the state ofcreativity in AI and identify key progresses and remaining challenges. In thiswork, we survey leading works studying the creative capabilities of AI systems,focusing on creative problem-solving, linguistic, artistic, and scientificcreativity. Our review suggests that while the latest AI models are largelycapable of producing linguistically and artistically creative outputs such aspoems, images, and musical pieces, they struggle with tasks that requirecreative problem-solving, abstract thinking and compositionality and theirgenerations suffer from a lack of diversity, originality, long-rangeincoherence and hallucinations. We also discuss key questions concerningcopyright and authorship issues with generative models. Furthermore, wehighlight the need for a comprehensive evaluation of creativity that isprocess-driven and considers several dimensions of creativity. Finally, wepropose future research directions to improve the creativity of AI outputs,drawing inspiration from cognitive science and psychology.</description><author>Mete Ismayilzada, Debjit Paul, Antoine Bosselut, Lonneke van der Plas</author><pubDate>Tue, 22 Oct 2024 17:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17218v1</guid></item><item><title>Hierarchical Upper Confidence Bounds for Constrained Online Learning</title><link>http://arxiv.org/abs/2410.17216v1</link><description>The multi-armed bandit (MAB) problem is a foundational framework insequential decision-making under uncertainty, extensively studied for itsapplications in areas such as clinical trials, online advertising, and resourceallocation. Traditional MAB formulations, however, do not adequately capturescenarios where decisions are structured hierarchically, involve multi-levelconstraints, or feature context-dependent action spaces. In this paper, weintroduce the hierarchical constrained bandits (HCB) framework, which extendsthe contextual bandit problem to incorporate hierarchical decision structuresand multi-level constraints. We propose the hierarchical constrained upperconfidence bound (HC-UCB) algorithm, designed to address the complexities ofthe HCB problem by leveraging confidence bounds within a hierarchical setting.Our theoretical analysis establishes sublinear regret bounds for HC-UCB andprovides high-probability guarantees for constraint satisfaction at allhierarchical levels. Furthermore, we derive a minimax lower bound on the regretfor the HCB problem, demonstrating the near-optimality of our algorithm. Theresults are significant for real-world applications where decision-makingprocesses are inherently hierarchical and constrained, offering a robust andefficient solution that balances exploration and exploitation across multiplelevels of decision-making.</description><author>Ali Baheri</author><pubDate>Tue, 22 Oct 2024 17:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17216v1</guid></item><item><title>MiniPLM: Knowledge Distillation for Pre-Training Language Models</title><link>http://arxiv.org/abs/2410.17215v1</link><description>Knowledge distillation (KD) is widely used to train small, high-performingstudent language models (LMs) using large teacher LMs. While effective infine-tuning, KD during pre-training faces challenges in efficiency,flexibility, and effectiveness. Existing methods either incur highcomputational costs due to online teacher inference, require tokenizationmatching between teacher and student LMs, or risk losing the difficulty anddiversity of the teacher-generated training data. To address these issues, wepropose MiniPLM, a KD framework for pre-training LMs by refining the trainingdata distribution with the teacher's knowledge. For efficiency, MiniPLMperforms offline teacher LM inference, allowing KD for multiple student LMswithout adding training-time costs. For flexibility, MiniPLM operates solely onthe training corpus, enabling KD across model families. For effectiveness,MiniPLM leverages the differences between large and small LMs to enhance thedifficulty and diversity of the training data, helping student LMs acquireversatile and sophisticated knowledge. Extensive experiments demonstrate thatMiniPLM boosts the student LMs' performance on 9 widely used downstream tasks,improves the language modeling capabilities, and reduces pre-trainingcomputation. The benefit of MiniPLM extends to large pre-training scales,evidenced by the extrapolation of the scaling curves. Further analysis revealsthat MiniPLM supports KD across model families and enhances the utilization ofpre-training data. Our model, code, and data are available athttps://github.com/thu-coai/MiniPLM.</description><author>Yuxian Gu, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang</author><pubDate>Tue, 22 Oct 2024 17:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17215v1</guid></item><item><title>On high-dimensional modifications of the nearest neighbor classifier</title><link>http://arxiv.org/abs/2407.05145v2</link><description>Nearest neighbor classifier is arguably the most simple and popularnonparametric classifier available in the literature. However, due to theconcentration of pairwise distances and the violation of the neighborhoodstructure, this classifier often suffers in high-dimension, low-sample size(HDLSS) situations, especially when the scale difference between the competingclasses dominates their location difference. Several attempts have been made inthe literature to take care of this problem. In this article, we discuss someof these existing methods and propose some new ones. We carry out sometheoretical investigations in this regard and analyze several simulated andbenchmark datasets to compare the empirical performances of proposed methodswith some of the existing ones.</description><author>Annesha Ghosh, Bilol Banerjee, Anil K. Ghosh</author><pubDate>Tue, 22 Oct 2024 17:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05145v2</guid></item><item><title>Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading</title><link>http://arxiv.org/abs/2410.17212v1</link><description>Stock return forecasting is a major component of numerous financeapplications. Predicted stock returns can be incorporated into portfoliotrading algorithms to make informed buy or sell decisions which can optimizereturns. In such portfolio trading applications, the predictive performance ofa time series forecasting model is crucial. In this work, we propose the use ofthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm toprogressively evolve recurrent neural networks (RNNs) for stock returnpredictions. RNNs are evolved independently for each stocks and portfoliotrading decisions are made based on the predicted stock returns. The portfolioused for testing consists of the 30 companies in the Dow-Jones Index (DJI) witheach stock have the same weight. Results show that using these evolved RNNs anda simple daily long-short strategy can generate higher returns than both theDJI index and the S&amp;P 500 Index for both 2022 (bear market) and 2023 (bullmarket).</description><author>Zimeng Lyu, Amulya Saxena, Rohaan Nadeem, Hao Zhang, Travis Desell</author><pubDate>Tue, 22 Oct 2024 17:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17212v1</guid></item><item><title>Typography Leads Semantic Diversifying: Amplifying Adversarial Transferability across Multimodal Large Language Models</title><link>http://arxiv.org/abs/2405.20090v3</link><description>Recently, Multimodal Large Language Models (MLLMs) achieve remarkableperformance in numerous zero-shot tasks due to their outstanding cross-modalinteraction and comprehension abilities. However, MLLMs are found to still bevulnerable to human-imperceptible adversarial examples. In the exploration ofsecurity vulnerabilities in real-world scenarios, transferability, which canachieve cross-model impact, is considered the greatest threat posed byadversarial examples. However, there is currently no systematic research on thethreat of cross-MLLMs adversarial transferability. Therefore, this paper as thefirst step to provide a comprehensive evaluation of the transferability ofadversarial examples generated by various MLLMs. Furthermore, leveraging twokey factors that influence transferability performance: 1) The strength ofinformation diversity involved in the adversarial generation process; 2)Editing across vision-language modality information. We propose a boostingmethod called Typography Augment Transferability Method (TATM) to investigatethe adversarial transferability performance across MLLMs further. Throughextensive experimental validation, our TATM demonstrates exceptionalperformance in real-world applications of "Harmful Word Insertion" and"Important Information Protection".</description><author>Hao Cheng, Erjia Xiao, Jiayan Yang, Jiahang Cao, Qiang Zhang, Le Yang, Jize Zhang, Kaidi Xu, Jindong Gu, Renjing Xu</author><pubDate>Tue, 22 Oct 2024 17:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20090v3</guid></item><item><title>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</title><link>http://arxiv.org/abs/2410.10796v2</link><description>A standard practice when using large language models is for users tosupplement their instruction with an input context containing new informationfor the model to process. However, models struggle to reliably follow the inputcontext, especially when it conflicts with their parametric knowledge frompretraining. In-principle, one would expect models to adapt to the user contextbetter after instruction finetuning, particularly when handling knowledgeconflicts. However, we observe a surprising failure mode: during instructiontuning, the context reliance under knowledge conflicts initially increases asexpected, but then gradually decreases as instruction finetuning progresses.This happens while the performance on standard benchmarks keeps on increasingfar after this drop. We call this phenomenon context-parametric inversion andobserve it across multiple general purpose instruction tuning datasets such asTULU, Alpaca and Ultrachat, across different model families like Llama,Mistral, and Pythia. We perform various controlled studies and theoreticalanalysis to show that context-parametric inversion occurs due to examples inthe instruction finetuning data where the input context provides informationthat aligns with model's parametric knowledge. Our analysis suggests somenatural mitigation strategies with limited but insightful gains, and serves asa useful starting point in addressing this deficiency in instructionfinetuning.</description><author>Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan</author><pubDate>Tue, 22 Oct 2024 17:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10796v2</guid></item><item><title>Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling</title><link>http://arxiv.org/abs/2410.17210v1</link><description>Purpose: Bangladesh's legal system struggles with major challenges likedelays, complexity, high costs, and millions of unresolved cases, which determany from pursuing legal action due to lack of knowledge or financialconstraints. This research seeks to develop a specialized Large Language Model(LLM) to assist in the Bangladeshi legal system. Methods: We createdUKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting andscraping data on various legal acts. We fine-tuned the GPT-2 model on thisdataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistancein English. Results: The model was rigorously evaluated using semanticassessments, including case studies supported by expert opinions. Theevaluation provided promising results, demonstrating the potential for themodel to assist in legal matters within Bangladesh. Conclusion: Our workrepresents the first structured effort toward building an AI-based legalassistant for Bangladesh. While the results are encouraging, furtherrefinements are necessary to improve the model's accuracy, credibility, andsafety. This is a significant step toward creating a legal AI capable ofserving the needs of a population of 180 million.</description><author>Azmine Toushik Wasi, Wahid Faisal, Mst Rafia Islam, Mahathir Mohammad Bappy</author><pubDate>Tue, 22 Oct 2024 17:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17210v1</guid></item><item><title>Pessimistic asynchronous sampling in high-cost Bayesian optimization</title><link>http://arxiv.org/abs/2406.15291v2</link><description>Asynchronous Bayesian optimization is a recently implemented technique thatallows for parallel operation of experimental systems and disjointed workflows.Contrasting with serial Bayesian optimization which individually selectsexperiments one at a time after conducting a measurement for each experiment,asynchronous policies sequentially assign multiple experiments beforemeasurements can be taken and evaluate new measurements continuously as theyare made available. This technique allows for faster data generation andtherefore faster optimization of an experimental space. This work extends thecapabilities of asynchronous optimization methods beyond prior studies byevaluating four additional policies that incorporate pessimistic predictions inthe training data set. Combined with a conventional policy that uses modelpredictions, the five total policies were evaluated in a simulated environmentand benchmarked with serial sampling. Under some conditions and parameter spacedimensionalities, the pessimistic prediction asynchronous policy reachedoptimum experimental conditions in significantly fewer experiments thanequivalent serial policies and proved to be less susceptible to convergenceonto local optima at higher dimensions. Without accounting for the fastersampling rate, the pessimistic asynchronous algorithm presented in this workcould result in more efficient algorithm driven optimization of high-costexperimental spaces. Accounting for sampling rate, the presented asynchronousalgorithm could allow for faster optimization in experimental spaces wheremultiple experiments can be run before results are collected.</description><author>Amanda A. Volk, Kristofer G. Reyes, Jeffrey G. Ethier, Luke A. Baldwin</author><pubDate>Tue, 22 Oct 2024 17:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15291v2</guid></item><item><title>Audio-to-Score Conversion Model Based on Whisper methodology</title><link>http://arxiv.org/abs/2410.17209v1</link><description>This thesis develops a Transformer model based on Whisper, which extractsmelodies and chords from music audio and records them into ABC notation. Acomprehensive data processing workflow is customized for ABC notation,including data cleansing, formatting, and conversion, and a mutation mechanismis implemented to increase the diversity and quality of training data. Thisthesis innovatively introduces the "Orpheus' Score", a custom notation systemthat converts music information into tokens, designs a custom vocabularylibrary, and trains a corresponding custom tokenizer. Experiments show thatcompared to traditional algorithms, the model has significantly improvedaccuracy and performance. While providing a convenient audio-to-score tool formusic enthusiasts, this work also provides new ideas and tools for research inmusic information processing.</description><author>Hongyao Zhang, Bohang Sun</author><pubDate>Tue, 22 Oct 2024 17:31:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17209v1</guid></item><item><title>SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents</title><link>http://arxiv.org/abs/2308.02594v4</link><description>Deep Reinforcement Learning (DRL) has made significant advancements invarious fields, such as autonomous driving, healthcare, and robotics, byenabling agents to learn optimal policies through interactions with theirenvironments. However, the application of DRL in safety-critical domainspresents challenges, particularly concerning the safety of the learnedpolicies. DRL agents, which are focused on maximizing rewards, may selectunsafe actions, leading to safety violations. Runtime safety monitoring is thusessential to ensure the safe operation of these agents, especially inunpredictable and dynamic environments. This paper introduces SMARLA, ablack-box safety monitoring approach specifically designed for DRL agents.SMARLA utilizes machine learning to predict safety violations by observing theagent's behavior during execution. The approach is based on Q-values, whichreflect the expected reward for taking actions in specific states. SMARLAemploys state abstraction to reduce the complexity of the state space,enhancing the predictive capabilities of the monitoring model. Such abstractionenables the early detection of unsafe states, allowing for the implementationof corrective and preventive measures before incidents occur. We quantitativelyand qualitatively validated SMARLA on three well-known case studies widely usedin DRL research. Empirical results reveal that SMARLA is accurate at predictingsafety violations, with a low false positive rate, and can predict violationsat an early stage, approximately halfway through the execution of the agent,before violations occur. We also discuss different decision criteria, based onconfidence intervals of the predicted violation probabilities, to triggersafety mechanisms aiming at a trade-off between early detection and low falsepositive rates.</description><author>Amirhossein Zolfagharian, Manel Abdellatif, Lionel C. Briand, Ramesh S</author><pubDate>Tue, 22 Oct 2024 17:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02594v4</guid></item><item><title>Universal approximation property of Banach space-valued random feature models including random neural networks</title><link>http://arxiv.org/abs/2312.08410v3</link><description>We introduce a Banach space-valued extension of random feature learning, adata-driven supervised machine learning technique for large-scale kernelapproximation. By randomly initializing the feature maps, only the linearreadout needs to be trained, which reduces the computational complexitysubstantially. Viewing random feature models as Banach space-valued randomvariables, we prove a universal approximation result in the correspondingBochner space. Moreover, we derive approximation rates and an explicitalgorithm to learn an element of the given Banach space by such models. Theframework of this paper includes random trigonometric/Fourier regression and inparticular random neural networks which are single-hidden-layer feedforwardneural networks whose weights and biases are randomly initialized, whence onlythe linear readout needs to be trained. For the latter, we can then lift theuniversal approximation property of deterministic neural networks to randomneural networks, even within function spaces over non-compact domains, e.g.,weighted spaces, $L^p$-spaces, and (weighted) Sobolev spaces, where the latterincludes the approximation of the (weak) derivatives. In addition, we analyzewhen the training costs for approximating a given function grow polynomially inboth the input/output dimension and the reciprocal of a pre-specified toleratedapproximation error. Furthermore, we demonstrate in a numerical example theempirical advantages of random feature models over their deterministiccounterparts.</description><author>Ariel Neufeld, Philipp Schmocker</author><pubDate>Tue, 22 Oct 2024 17:29:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08410v3</guid></item><item><title>EPContrast: Effective Point-level Contrastive Learning for Large-scale Point Cloud Understanding</title><link>http://arxiv.org/abs/2410.17207v1</link><description>The acquisition of inductive bias through point-level contrastive learningholds paramount significance in point cloud pre-training. However, the squaregrowth in computational requirements with the scale of the point cloud poses asubstantial impediment to the practical deployment and execution. To addressthis challenge, this paper proposes an Effective Point-level ContrastiveLearning method for large-scale point cloud understanding dubbed\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. Inpractice, AGContrast constructs positive and negative pairs based on asymmetricgranularity embedding, while ChannelContrast imposes contrastive supervisionbetween channel feature maps. EPContrast offers point-level contrastive losswhile concurrently mitigating the computational resource burden. The efficacyof EPContrast is substantiated through comprehensive validation on S3DIS andScanNetV2, encompassing tasks such as semantic segmentation, instancesegmentation, and object detection. In addition, rich ablation experimentsdemonstrate remarkable bias induction capabilities under label-efficient andone-epoch training settings.</description><author>Zhiyi Pan, Guoqing Liu, Wei Gao, Thomas H. Li</author><pubDate>Tue, 22 Oct 2024 17:27:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17207v1</guid></item><item><title>Data-driven rainfall prediction at a regional scale: a case study with Ghana</title><link>http://arxiv.org/abs/2410.14062v2</link><description>With a warming planet, tropical regions are expected to experience the bruntof climate change, with more intense and more volatile rainfall events.Currently, state-of-the-art numerical weather prediction (NWP) models are knownto struggle to produce skillful rainfall forecasts in tropical regions ofAfrica. There is thus a pressing need for improved rainfall forecasting inthese regions. Over the last decade or so, the increased availability oflarge-scale meteorological datasets and the development of powerful machinelearning models have opened up new opportunities for data-driven weatherforecasting. Focusing on Ghana in this study, we use these tools to develop twoU-Net convolutional neural network (CNN) models, to predict 24h rainfall at 12hand 30h lead-time. The models were trained using data from the ERA5 reanalysisdataset, and the GPM-IMERG dataset. A special attention was paid tointerpretability. We developed a novel statistical methodology that allowed usto probe the relative importance of the meteorological variables input in ourmodel, offering useful insights into the factors that drive precipitation inthe Ghana region. Empirically, we found that our 12h lead-time model hasperformances that match, and in some accounts are better than the 18h lead-timeforecasts produced by the ECMWF (as available in the TIGGE dataset). We alsofound that combining our data-driven model with classical NWP further improvesforecast accuracy.</description><author>Indrajit Kalita, Lucia Vilallonga, Yves Atchade</author><pubDate>Tue, 22 Oct 2024 17:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14062v2</guid></item><item><title>Sample Compression Unleashed: New Generalization Bounds for Real Valued Losses</title><link>http://arxiv.org/abs/2409.17932v2</link><description>The sample compression theory provides generalization guarantees forpredictors that can be fully defined using a subset of the training dataset anda (short) message string, generally defined as a binary sequence. Previousworks provided generalization bounds for the zero-one loss, which isrestrictive notably when applied to deep learning approaches. In this paper, wepresent a general framework for deriving new sample compression bounds thathold for real-valued unbounded losses. Using the Pick-To-Learn (P2L)meta-algorithm, which transforms the training method of any machine-learningpredictor to yield sample-compressed predictors, we empirically demonstrate thetightness of the bounds and their versatility by evaluating them on randomforests and multiple types of neural networks.</description><author>Mathieu Bazinet, Valentina Zantedeschi, Pascal Germain</author><pubDate>Tue, 22 Oct 2024 17:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17932v2</guid></item><item><title>ACPBench: Reasoning about Action, Change, and Planning</title><link>http://arxiv.org/abs/2410.05669v2</link><description>There is an increasing body of work using Large Language Models (LLMs) asagents for orchestrating workflows and making decisions in domains that requireplanning and multi-step reasoning. As a result, it is imperative to evaluateLLMs on core skills required for planning. In this work, we present ACPBench, abenchmark for evaluating the reasoning tasks in the field of planning. Thebenchmark consists of 7 reasoning tasks over 13 planning domains. Thecollection is constructed from planning domains described in a formal language.This allows us to synthesize problems with provably correct solutions acrossmany tasks and domains. Further, it allows us the luxury of scale withoutadditional human effort, i.e., many additional problems can be createdautomatically. Our extensive evaluation of 22 LLMs and OpenAI o1 reasoningmodels highlights the significant gap in the reasoning capability of the LLMs.Our findings with OpenAI o1, a multi-turn reasoning model, reveal significantgains in performance on multiple-choice questions, yet surprisingly, no notableprogress is made on boolean questions. The ACPBench collection is available at https://ibm.github.io/ACPBench.</description><author>Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi</author><pubDate>Tue, 22 Oct 2024 17:16:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05669v2</guid></item><item><title>VoiceBench: Benchmarking LLM-Based Voice Assistants</title><link>http://arxiv.org/abs/2410.17196v1</link><description>Building on the success of large language models (LLMs), recent advancementssuch as GPT-4o have enabled real-time speech interactions through LLM-basedvoice assistants, offering a significantly improved user experience compared totraditional text-based interactions. However, the absence of benchmarksdesigned to evaluate these speech interaction capabilities has hinderedprogress of LLM-based voice assistants development. Current evaluations focusprimarily on automatic speech recognition (ASR) or general knowledge evaluationwith clean speeches, neglecting the more intricate, real-world scenarios thatinvolve diverse speaker characteristics, environmental and content factors. Toaddress this, we introduce VoiceBench, the first benchmark designed to providea multi-faceted evaluation of LLM-based voice assistants. VoiceBench alsoincludes both real and synthetic spoken instructions that incorporate the abovethree key real-world variations. Extensive experiments reveal the limitationsof current LLM-based voice assistant models and offer valuable insights forfuture research and development in this field.</description><author>Yiming Chen, Xianghu Yue, Chen Zhang, Xiaoxue Gao, Robby T. Tan, Haizhou Li</author><pubDate>Tue, 22 Oct 2024 17:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17196v1</guid></item><item><title>Language Model Non-myopic Generation for Reasoning and Planning</title><link>http://arxiv.org/abs/2410.17195v1</link><description>Large Language Models have demonstrated remarkable abilities in reasoning andplanning by breaking down complex problems into sequential steps. Despite theirsuccess in various domains like mathematical problem-solving and coding, LLMsface challenges in ensuring reliable and optimal planning due to their inherentmyopic nature of autoregressive decoding. This paper revisits LLM reasoningfrom an optimal-control perspective, proposing a novel method,Predictive-Decoding, that leverages Model Predictive Control to enhanceplanning accuracy. By re-weighting LLM distributions based on foresighttrajectories, Predictive-Decoding aims to mitigate early errors and promotenon-myopic planning. Our experiments show significant improvements in a widerange of tasks for math, coding, and agents. Furthermore, Predictive-Decodingdemonstrates computational efficiency, outperforming search baselines withreduced computational resources. This study provides insights into optimizingLLM planning capabilities.</description><author>Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong</author><pubDate>Tue, 22 Oct 2024 17:13:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17195v1</guid></item><item><title>Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing</title><link>http://arxiv.org/abs/2410.17194v1</link><description>Knowledge Editing (KE) algorithms alter models' internal weights to performtargeted updates to incorrect, outdated, or otherwise unwanted factualassociations. In order to better define the possibilities and limitations ofthese approaches, recent work has shown that applying KE can adversely affectmodels' factual recall accuracy and diminish their general reasoning abilities.While these studies give broad insights into the potential harms of KEalgorithms, e.g., via performance evaluations on benchmarks, we argue little isunderstood as to why such destructive failures occur. Is it possible KE methodsdistort representations of concepts beyond the targeted fact, hence hamperingabilities at broad? If so, what is the extent of this distortion? To take astep towards addressing such questions, we define a novel synthetic taskwherein a Transformer is trained from scratch to internalize a ``structured''knowledge graph. The structure enforces relationships between entities of thegraph, such that editing a factual association has "trickling effects" on otherentities in the graph (e.g., altering X's parent is Y to Z affects who X'ssiblings' parent is). Through evaluations of edited models and analysis ofextracted representations, we show that KE inadvertently affectsrepresentations of entities beyond the targeted one, distorting relevantstructures that allow a model to infer unseen knowledge about an entity. Wecall this phenomenon representation shattering and demonstrate that it resultsin degradation of factual recall and reasoning performance more broadly. Tocorroborate our findings in a more naturalistic setup, we perform preliminaryexperiments with a pretrained GPT-2-XL model and reproduce the representationshattering effect therein as well. Overall, our work yields a precisemechanistic hypothesis to explain why KE has adverse effects on modelcapabilities.</description><author>Kento Nishi, Maya Okawa, Rahul Ramesh, Mikail Khona, Ekdeep Singh Lubana, Hidenori Tanaka</author><pubDate>Tue, 22 Oct 2024 17:13:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17194v1</guid></item><item><title>Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios</title><link>http://arxiv.org/abs/2410.17193v1</link><description>Dataset distillation has demonstrated strong performance on simple datasetslike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results inmore complex scenarios. In this paper, we propose EDF (emphasizes thediscriminative features), a dataset distillation method that enhances keydiscriminative regions in synthetic images using Grad-CAM activation maps. Ourapproach is inspired by a key observation: in simple datasets, high-activationareas typically occupy most of the image, whereas in complex scenarios, thesize of these areas is much smaller. Unlike previous methods that treat allpixels equally when synthesizing images, EDF uses Grad-CAM activation maps toenhance high-activation areas. From a supervision perspective, we downplaysupervision signals that have lower losses, as they contain common patterns.Additionally, to help the DD community better explore complex scenarios, webuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulouslyselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. Inparticular, EDF consistently outperforms SOTA results in complex scenarios,such as ImageNet-1K subsets. Hopefully, more researchers will be inspired andencouraged to improve the practicality and efficacy of DD. Our code andbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.</description><author>Kai Wang, Zekai Li, Zhi-Qi Cheng, Samir Khaki, Ahmad Sajedi, Ramakrishna Vedantam, Konstantinos N Plataniotis, Alexander Hauptmann, Yang You</author><pubDate>Tue, 22 Oct 2024 17:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17193v1</guid></item><item><title>On Functional Dimension and Persistent Pseudodimension</title><link>http://arxiv.org/abs/2410.17191v1</link><description>For any fixed feedforward ReLU neural network architecture, it is well-knownthat many different parameter settings can determine the same function. It isless well-known that the degree of this redundancy is inhomogeneous acrossparameter space. In this work, we discuss two locally applicable complexitymeasures for ReLU network classes and what we know about the relationshipbetween them: (1) the local functional dimension [14, 18], and (2) a localversion of VC dimension that we call persistent pseudodimension. The former iseasy to compute on finite batches of points; the latter should give localbounds on the generalization gap, which would inform an understanding of themechanics of the double descent phenomenon [7].</description><author>J. Elisenda Grigsby, Kathryn Lindsey</author><pubDate>Tue, 22 Oct 2024 17:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17191v1</guid></item><item><title>DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative Path Planning</title><link>http://arxiv.org/abs/2410.17186v1</link><description>Informative path planning (IPP) is an important planning paradigm for variousreal-world robotic applications such as environment monitoring. IPP involvesplanning a path that can learn an accurate belief of the quantity of interest,while adhering to planning constraints. Traditional IPP methods typicallyrequire high computation time during execution, giving rise to reinforcementlearning (RL) based IPP methods. However, the existing RL-based methods do notconsider spatio-temporal environments which involve their own challenges due tovariations in environment characteristics. In this paper, we propose DyPNIPP, arobust RL-based IPP framework, designed to operate effectively acrossspatio-temporal environments with varying dynamics. To achieve this, DyPNIPPincorporates domain randomization to train the agent across diverseenvironments and introduces a dynamics prediction model to capture and adaptthe agent actions to specific environment dynamics. Our extensive experimentsin a wildfire environment demonstrate that DyPNIPP outperforms existingRL-based IPP algorithms by significantly improving robustness and performingacross diverse environment conditions.</description><author>Srujan Deolasee, Siva Kailas, Wenhao Luo, Katia Sycara, Woojun Kim</author><pubDate>Tue, 22 Oct 2024 17:07:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17186v1</guid></item><item><title>Can Large Language Models Identify Authorship?</title><link>http://arxiv.org/abs/2403.08213v2</link><description>The ability to accurately identify authorship is crucial for verifyingcontent authenticity and mitigating misinformation. Large Language Models(LLMs) have demonstrated an exceptional capacity for reasoning andproblem-solving. However, their potential in authorship analysis remainsunder-explored. Traditional studies have depended on hand-crafted stylisticfeatures, whereas state-of-the-art approaches leverage text embeddings frompre-trained language models. These methods, which typically require fine-tuningon labeled data, often suffer from performance degradation in cross-domainapplications and provide limited explainability. This work seeks to addressthree research questions: (1) Can LLMs perform zero-shot, end-to-end authorshipverification effectively? (2) Are LLMs capable of accurately attributingauthorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMsprovide explainability in authorship analysis, particularly through the role oflinguistic features? Moreover, we investigate the integration of explicitlinguistic features to guide LLMs in their reasoning processes. Our assessmentdemonstrates LLMs' proficiency in both tasks without the need fordomain-specific fine-tuning, providing explanations into their decision makingvia a detailed analysis of linguistic features. This establishes a newbenchmark for future research on LLM-based authorship analysis.</description><author>Baixiang Huang, Canyu Chen, Kai Shu</author><pubDate>Tue, 22 Oct 2024 17:07:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08213v2</guid></item><item><title>The Impact of Large Language Models in Academia: from Writing to Speaking</title><link>http://arxiv.org/abs/2409.13686v2</link><description>Large language models (LLMs) are increasingly impacting human society,particularly in textual information. Based on more than 30,000 papers and 1,000presentations from machine learning conferences, we examined and compared thewords used in writing and speaking, representing the first large-scale study ofhow LLMs influence the two main modes of verbal communication and expressionwithin the same group of people. Our empirical results show that LLM-stylewords such as "significant" have been used more frequently in abstracts andoral presentations. The impact on speaking is beginning to emerge and is likelyto grow in the future, calling attention to the implicit influence and rippleeffect of LLMs on human society.</description><author>Mingmeng Geng, Caixi Chen, Yanru Wu, Dongping Chen, Yao Wan, Pan Zhou</author><pubDate>Tue, 22 Oct 2024 17:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13686v2</guid></item><item><title>Levels of AI Agents: from Rules to Large Language Models</title><link>http://arxiv.org/abs/2405.06643v2</link><description>AI agents are defined as artificial entities to perceive the environment,make decisions and take actions. Inspired by the 6 levels of autonomous drivingby Society of Automotive Engineers, the AI agents are also categorized based onutilities and strongness, as the following levels: L0, no AI, with tools takinginto account perception plus actions; L1, using rule-based AI; L2, makingrule-based AI replaced by IL/RL-based AI, with additional reasoning &amp; decisionmaking; L3, applying LLM-based AI instead of IL/RL-based AI, additionallysetting up memory &amp; reflection; L4, based on L3, facilitating autonomouslearning &amp; generalization; L5, based on L4, appending personality of emotionand character and collaborative behavior with multi-agents.</description><author>Yu Huang</author><pubDate>Tue, 22 Oct 2024 17:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06643v2</guid></item><item><title>LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains</title><link>http://arxiv.org/abs/2407.14344v2</link><description>This research investigates whether OpenAI's GPT-4, a state-of-the-art largelanguage model, can accurately classify the political bias of news sourcesbased solely on their URLs. Given the subjective nature of political labels,third-party bias ratings like those from Ad Fontes Media, AllSides, and MediaBias/Fact Check (MBFC) are often used in research to analyze news sourcediversity. This study aims to determine if GPT-4 can replicate these humanratings on a seven-degree scale ("far-left" to "far-right"). The analysiscompares GPT-4's classifications against MBFC's, and controls for websitepopularity using Open PageRank scores. Findings reveal a high correlation($\text{Spearman's } \rho = .89$, $n = 5,877$, $p &lt; 0.001$) between GPT-4's andMBFC's ratings, indicating the model's potential reliability. However, GPT-4abstained from classifying approximately $\frac{2}{3}$ of the dataset. It ismore likely to abstain from rating unpopular websites, which also suffer fromless accurate assessments. The LLM tends to avoid classifying sources that MBFCconsiders to be centrist, resulting in more polarized outputs. Finally, thisanalysis shows a slight leftward skew in GPT's classifications compared toMBFC's. Therefore, while this paper suggests that while GPT-4 can be ascalable, cost-effective tool for political bias classification of newswebsites, its use should be as a complement to human judgment to mitigatebiases.</description><author>Raphael Hernandes, Giulio Corsi</author><pubDate>Tue, 22 Oct 2024 16:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14344v2</guid></item><item><title>EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution</title><link>http://arxiv.org/abs/2408.17379v2</link><description>Task planning for robots in real-life settings presents significantchallenges. These challenges stem from three primary issues: the difficulty inidentifying grounded sequences of steps to achieve a goal; the lack of astandardized mapping between high-level actions and low-level commands; and thechallenge of maintaining low computational overhead given the limited resourcesof robotic hardware. We introduce EMPOWER, a framework designed foropen-vocabulary online grounding and planning for embodied agents aimed ataddressing these issues. By leveraging efficient pre-trained foundation modelsand a multi-role mechanism, EMPOWER demonstrates notable improvements ingrounded planning and execution. Quantitative results highlight theeffectiveness of our approach, achieving an average success rate of 0.73 acrosssix different real-life scenarios using a TIAGo robot.</description><author>Francesco Argenziano, Michele Brienza, Vincenzo Suriani, Daniele Nardi, Domenico D. Bloisi</author><pubDate>Tue, 22 Oct 2024 16:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17379v2</guid></item><item><title>AIM 2024 Challenge on Compressed Video Quality Assessment: Methods and Results</title><link>http://arxiv.org/abs/2408.11982v3</link><description>Video quality assessment (VQA) is a crucial task in the development of videocompression standards, as it directly impacts the viewer experience. This paperpresents the results of the Compressed Video Quality Assessment challenge, heldin conjunction with the Advances in Image Manipulation (AIM) workshop at ECCV2024. The challenge aimed to evaluate the performance of VQA methods on adiverse dataset of 459 videos, encoded with 14 codecs of various compressionstandards (AVC/H.264, HEVC/H.265, AV1, and VVC/H.266) and containing acomprehensive collection of compression artifacts. To measure the methodsperformance, we employed traditional correlation coefficients between theirpredictions and subjective scores, which were collected via large-scalecrowdsourced pairwise human comparisons. For training purposes, participantswere provided with the Compressed Video Quality Assessment Dataset (CVQAD), apreviously developed dataset of 1022 videos. Up to 30 participating teamsregistered for the challenge, while we report the results of 6 teams, whichsubmitted valid final solutions and code for reproducing the results. Moreover,we calculated and present the performance of state-of-the-art VQA methods onthe developed dataset, providing a comprehensive benchmark for future research.The dataset, results, and online leaderboard are publicly available athttps://challenges.videoprocessing.ai/challenges/compressedvideo-quality-assessment.html.</description><author>Maksim Smirnov, Aleksandr Gushchin, Anastasia Antsiferova, Dmitry Vatolin, Radu Timofte, Ziheng Jia, Zicheng Zhang, Wei Sun, Jiaying Qian, Yuqin Cao, Yinan Sun, Yuxin Zhu, Xiongkuo Min, Guangtao Zhai, Kanjar De, Qing Luo, Ao-Xiang Zhang, Peng Zhang, Haibo Lei, Linyan Jiang, Yaqing Li, Wenhui Meng, Zhenzhong Chen, Zhengxue Cheng, Jiahao Xiao, Jun Xu, Chenlong He, Qi Zheng, Ruoxi Zhu, Min Li, Yibo Fan, Zhengzhong Tu</author><pubDate>Tue, 22 Oct 2024 16:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11982v3</guid></item><item><title>A Bayesian Framework for Clustered Federated Learning</title><link>http://arxiv.org/abs/2410.15473v2</link><description>One of the main challenges of federated learning (FL) is handlingnon-independent and identically distributed (non-IID) client data, which mayoccur in practice due to unbalanced datasets and use of different data sourcesacross clients. Knowledge sharing and model personalization are key strategiesfor addressing this issue. Clustered federated learning is a class of FLmethods that groups clients that observe similarly distributed data intoclusters, such that every client is typically associated with one datadistribution and participates in training a model for that distribution alongtheir cluster peers. In this paper, we present a unified Bayesian framework forclustered FL which associates clients to clusters. Then we propose severalpractical algorithms to handle the, otherwise growing, data associations in away that trades off performance and computational complexity. This workprovides insights on client-cluster associations and enables client knowledgesharing in new ways. The proposed framework circumvents the need for uniqueclient-cluster associations, which is seen to increase the performance of theresulting models in a variety of experiments.</description><author>Peng Wu, Tales Imbiriba, Pau Closas</author><pubDate>Tue, 22 Oct 2024 16:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15473v2</guid></item><item><title>Remote Timing Attacks on Efficient Language Model Inference</title><link>http://arxiv.org/abs/2410.17175v1</link><description>Scaling up language models has significantly increased their capabilities.But larger models are slower models, and so there is now an extensive body ofwork (e.g., speculative sampling or parallel decoding) that improves the(average case) efficiency of language model generation. But these techniquesintroduce data-dependent timing characteristics. We show it is possible toexploit these timing differences to mount a timing attack. By monitoring the(encrypted) network traffic between a victim user and a remote language model,we can learn information about the content of messages by noting when responsesare faster or slower. With complete black-box access, on open source systems weshow how it is possible to learn the topic of a user's conversation (e.g.,medical advice vs. coding assistance) with 90%+ precision, and on productionsystems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish betweenspecific messages or infer the user's language. We further show that an activeadversary can leverage a boosting attack to recover PII placed in messages(e.g., phone numbers or credit card numbers) for open source systems. Weconclude with potential defenses and directions for future work.</description><author>Nicholas Carlini, Milad Nasr</author><pubDate>Tue, 22 Oct 2024 16:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17175v1</guid></item><item><title>From Attention to Activation: Unravelling the Enigmas of Large Language Models</title><link>http://arxiv.org/abs/2410.17174v1</link><description>We study two strange phenomena in auto-regressive Transformers: (1) thedominance of the first token in attention heads; (2) the occurrence of largeoutlier activations in the hidden states. We find that popular large languagemodels, such as Llama attend maximally to the first token in 98% of attentionheads, a behaviour we attribute to the softmax function. To mitigate thisissue, we propose a reformulation of softmax to softmax-1. Furthermore, weidentify adaptive optimisers, e.g. Adam, as the primary contributor to thelarge outlier activations and introduce OrthoAdam, a novel optimiser thatutilises orthogonal matrices to transform gradients, to address this issue.Finally, not only do our methods prevent these phenomena from occurring, butadditionally, they enable Transformers to sustain their performance whenquantised using basic algorithms, something that standard methods are unable todo. In summary, our methods reduce the attention proportion on the first tokenfrom 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3.</description><author>Prannay Kaul, Chengcheng Ma, Ismail Elezi, Jiankang Deng</author><pubDate>Tue, 22 Oct 2024 16:51:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17174v1</guid></item><item><title>KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional Elements</title><link>http://arxiv.org/abs/2410.17172v1</link><description>We introduce KANICE (Kolmogorov-Arnold Networks with InteractiveConvolutional Elements), a novel neural architecture that combinesConvolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN)principles. KANICE integrates Interactive Convolutional Blocks (ICBs) and KANlinear layers into a CNN framework. This leverages KANs' universalapproximation capabilities and ICBs' adaptive feature learning. KANICE capturescomplex, non-linear data relationships while enabling dynamic,context-dependent feature extraction based on the Kolmogorov-Arnoldrepresentation theorem. We evaluated KANICE on four datasets: MNIST,Fashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KANhybrids, and ICB variants. KANICE consistently outperformed baseline models,achieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset. Furthermore, we introduce KANICE-mini, a compact variant designed forefficiency. A comprehensive ablation study demonstrates that KANICE-miniachieves comparable performance to KANICE with significantly fewer parameters.KANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, comparedto KANICE's 25,432,000. This study highlights the potential of KAN-basedarchitectures in balancing performance and computational efficiency in imageclassification tasks. Our work contributes to research in adaptive neuralnetworks, integrates mathematical theorems into deep learning architectures,and explores the trade-offs between model complexity and performance, advancingcomputer vision and pattern recognition. The source code for this paper ispublicly accessible through our GitHub repository(https://github.com/m-ferdaus/kanice).</description><author>Md Meftahul Ferdaus, Mahdi Abdelguerfi, Elias Ioup, David Dobson, Kendall N. Niles, Ken Pathak, Steven Sloan</author><pubDate>Tue, 22 Oct 2024 16:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17172v1</guid></item><item><title>Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding</title><link>http://arxiv.org/abs/2410.17173v1</link><description>Protein inverse folding-that is, predicting an amino acid sequence that willfold into the desired 3D structure-is an important problem for structure-basedprotein design. Machine learning based methods for inverse folding typicallyuse recovery of the original sequence as the optimization objective. However,inverse folding is a one-to-many problem where several sequences can fold tothe same structure. Moreover, for many practical applications, it is oftendesirable to have multiple, diverse sequences that fold into the targetstructure since it allows for more candidate sequences for downstreamoptimizations. Here, we demonstrate that although recent inverse foldingmethods show increased sequence recovery, their "foldable diversity"-i.e. theirability to generate multiple non-similar sequences that fold into thestructures consistent with the target-does not increase. To address this, wepresent RL-DIF, a categorical diffusion model for inverse folding that ispre-trained on sequence recovery and tuned via reinforcement learning onstructural consistency. We find that RL-DIF achieves comparable sequencerecovery and structural consistency to benchmark models but shows greaterfoldable diversity: experiments show RL-DIF can achieve an foldable diversityof 29% on CATH 4.2, compared to 23% from models trained on the same dataset.The PyTorch model weights and sampling code are available on GitHub.</description><author>Yasha Ektefaie, Olivia Viessmann, Siddharth Narayanan, Drew Dresser, J. Mark Kim, Armen Mkrtchyan</author><pubDate>Tue, 22 Oct 2024 16:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17173v1</guid></item><item><title>Self-calibration for Language Model Quantization and Pruning</title><link>http://arxiv.org/abs/2410.17170v1</link><description>Quantization and pruning are fundamental approaches for model compression,enabling efficient inference for language models. In a post-training setting,state-of-the-art quantization and pruning methods require calibration data, asmall set of unlabeled examples. Conventionally, randomly sampled web text isused, aiming to reflect the model training data. However, this poses two keyproblems: (1) unrepresentative calibration examples can harm model performance,and (2) organizations increasingly avoid releasing model training data. In thispaper, we propose self-calibration as a solution. Our approach requires noexternal data, instead leveraging the model itself to generate syntheticcalibration data as a better approximation of the pre-training datadistribution. We extensively compare the performance of self-calibration withseveral baselines, across a variety of models, compression methods, and tasks.Our approach proves consistently competitive in maximizing downstream taskperformance, frequently outperforming even using real data.</description><author>Miles Williams, George Chrysostomou, Nikolaos Aletras</author><pubDate>Tue, 22 Oct 2024 16:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17170v1</guid></item><item><title>FDINet: Protecting against DNN Model Extraction via Feature Distortion Index</title><link>http://arxiv.org/abs/2306.11338v3</link><description>Machine Learning as a Service (MLaaS) platforms have gained popularity due totheir accessibility, cost-efficiency, scalability, and rapid developmentcapabilities. However, recent research has highlighted the vulnerability ofcloud-based models in MLaaS to model extraction attacks. In this paper, weintroduce FDINET, a novel defense mechanism that leverages the featuredistribution of deep neural network (DNN) models. Concretely, by analyzing thefeature distribution from the adversary's queries, we reveal that the featuredistribution of these queries deviates from that of the model's training set.Based on this key observation, we propose Feature Distortion Index (FDI), ametric designed to quantitatively measure the feature distribution deviation ofreceived queries. The proposed FDINET utilizes FDI to train a binary detectorand exploits FDI similarity to identify colluding adversaries from distributedextraction attacks. We conduct extensive experiments to evaluate FDINET againstsix state-of-the-art extraction attacks on four benchmark datasets and fourpopular model architectures. Empirical results demonstrate the followingfindings FDINET proves to be highly effective in detecting model extraction,achieving a 100% detection accuracy on DFME and DaST. FDINET is highlyefficient, using just 50 queries to raise an extraction alarm with an averageconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identifycolluding adversaries with an accuracy exceeding 91%. Additionally, itdemonstrates the ability to detect two types of adaptive attacks.</description><author>Hongwei Yao, Zheng Li, Haiqin Weng, Feng Xue, Zhan Qin, Kui Ren</author><pubDate>Tue, 22 Oct 2024 16:39:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11338v3</guid></item><item><title>Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence</title><link>http://arxiv.org/abs/2410.17161v1</link><description>We propose a novel approach for learning interchangeable tokens in languagemodels to obtain an extendable vocabulary that can generalize to new tokens.Our method is designed to address alpha-equivalence, the principle thatrenaming bound variables in a syntactic expression preserves semantics. Thisproperty arises in many formal languages such as temporal logics, in which allproposition symbols represent the same concept but are distinguishable fromeach other. To handle such tokens, we develop a dual-part embedding approach.The first part is shared across all interchangeable tokens, thereby enforcingthat they represent the same core concept. The second part is randomlygenerated for each token, which enables distinguishability. We evaluate ourmethod in a Transformer encoder-decoder model on two tasks: solving lineartemporal logic formulae and copying with extendable vocabulary. Our methoddemonstrates promising generalization capabilities in addition to introducing afavorable inductive bias for alpha-equivalence.</description><author>İlker Işık, Ramazan Gokberk Cinbis, Ebru Aydin Gol</author><pubDate>Tue, 22 Oct 2024 16:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17161v1</guid></item><item><title>Layered LA-MAPF: a decomposition of large agent MAPF instance to accelerate solving without compromising solvability</title><link>http://arxiv.org/abs/2410.17160v1</link><description>Multi-Agent Path Finding (MAPF) has been widely studied in recent years.However, most existing MAPF algorithms assume that an agent occupies only asingle grid in a grid-based map. This assumption limits their applicability inmany real-world domains where agents have geometric shapes, rather than beingpoint-like. Such agents, which can occupy multiple cells simultaneously, arereferred to as ``large'' agents. When considering the shape and size of agentsin MAPF, the computational complexity increases significantly as the number ofagents grows, primarily due to the increased overhead in conflict detectionbetween geometric agents. In this paper, we propose two types of subproblemsfor the LA-MAPF (Large-Agent MAPF) problem: \textbf{cluster} (which has noconstraints on the order of solution) and \textbf{level} (which imposesconstraints on the solution order). We introduce \textbf{Layered LA-MAPF}, amethod that decomposes a MAPF instance involving geometric agents intoclusters, and then further decomposes each cluster into levels. This approachaims to reduce time complexity when solving LA-MAPF problems. Our resultsdemonstrate the performance of our method as the number of agents increasesacross various maps, and how it accelerates LA-MAPF methods, such as LA-CBS andLA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition\textbf{halves the time cost (reducing from an average of 40s to 20s) andtriples the success rate (from an average of 0.27 to 0.80)} in finding asolution within 60 seconds. To facilitate further research, we have made thesource code for Layered LA-MAPF publicly available at\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.</description><author>Zhuo Yao</author><pubDate>Tue, 22 Oct 2024 16:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17160v1</guid></item><item><title>LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting</title><link>http://arxiv.org/abs/2410.17159v1</link><description>Forecasting models are pivotal in a data-driven world with vast volumes oftime series data that appear as a compound of vast Linear and Nonlinearpatterns. Recent deep time series forecasting models struggle to utilizeseasonal and trend decomposition to separate the entangled components. Such astrategy only explicitly extracts simple linear patterns like trends, leavingthe other linear modes and vast unexplored nonlinear patterns to the residual.Their flawed linear and nonlinear feature extraction models and shallow-leveldecomposition limit their adaptation to the diverse patterns present inreal-world scenarios. Given this, we innovate Recursive Residual Decompositionby introducing explicit extraction of both linear and nonlinear patterns. Thisdeeper-level decomposition framework, which is named LiNo, captures linearpatterns using a Li block which can be a moving average kernel, and modelsnonlinear patterns using a No block which can be a Transformer encoder. Theextraction of these two patterns is performed alternatively and recursively. Toachieve the full potential of LiNo, we develop the current simple linearpattern extractor to a general learnable autoregressive model, and design anovel No block that can handle all essential nonlinear patterns. Remarkably,the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarksunder univariate and multivariate forecasting scenarios. Experiments show thatcurrent forecasting models can deliver more robust and precise results throughthis advanced Recursive Residual Decomposition. We hope this work could offerinsight into designing more effective forecasting models. Code is available atthis Repository: https://github.com/Levi-Ackman/LiNo.</description><author>Guoqi Yu, Yaoming Li, Xiaoyu Guo, Dayu Wang, Zirui Liu, Shujun Wang, Tong Yang</author><pubDate>Tue, 22 Oct 2024 16:33:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17159v1</guid></item><item><title>Improving Pinterest Search Relevance Using Large Language Models</title><link>http://arxiv.org/abs/2410.17152v1</link><description>To improve relevance scoring on Pinterest Search, we integrate Large LanguageModels (LLMs) into our search relevance model, leveraging carefully designedtext representations to predict the relevance of Pins effectively. Our approachuses search queries alongside content representations that include captionsextracted from a generative visual language model. These are further enrichedwith link-based text data, historically high-quality engaged queries,user-curated boards, Pin titles and Pin descriptions, creating robust modelsfor predicting search relevance. We use a semi-supervised learning approach toefficiently scale up the amount of training data, expanding beyond theexpensive human labeled data available. By utilizing multilingual LLMs, oursystem extends training data to include unseen languages and domains, despiteinitial data and annotator expertise being confined to English. Furthermore, wedistill from the LLM-based model into real-time servable model architecturesand features. We provide comprehensive offline experimental validation for ourproposed techniques and demonstrate the gains achieved through the finaldeployed system at scale.</description><author>Han Wang, Mukuntha Narayanan Sundararaman, Onur Gungor, Yu Xu, Krishna Kamath, Rakesh Chalasani, Kurchi Subhra Hazra, Jinfeng Rao</author><pubDate>Tue, 22 Oct 2024 16:29:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17152v1</guid></item><item><title>Are Visual-Language Models Effective in Action Recognition? A Comparative Study</title><link>http://arxiv.org/abs/2410.17149v1</link><description>Current vision-language foundation models, such as CLIP, have recently shownsignificant improvement in performance across various downstream tasks.However, whether such foundation models significantly improve more complexfine-grained action recognition tasks is still an open question. To answer thisquestion and better find out the future research direction on human behavioranalysis in-the-wild, this paper provides a large-scale study and insight oncurrent state-of-the-art vision foundation models by comparing their transferability onto zero-shot and frame-wise action recognition tasks. Extensiveexperiments are conducted on recent fine-grained, human-centric actionrecognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU,Charades) including action classification and segmentation.</description><author>Mahmoud Ali, Di Yang, François Brémond</author><pubDate>Tue, 22 Oct 2024 16:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17149v1</guid></item><item><title>Covariance estimation using Markov chain Monte Carlo</title><link>http://arxiv.org/abs/2410.17147v1</link><description>We investigate the complexity of covariance matrix estimation for Gibbsdistributions based on dependent samples from a Markov chain. We show that when$\pi$ satisfies a Poincar\'e inequality and the chain possesses a spectral gap,we can achieve similar sample complexity using MCMC as compared to an estimatorconstructed using i.i.d. samples, with potentially much better querycomplexity. As an application of our methods, we show improvements for thequery complexity in both constrained and unconstrained settings for concreteinstances of MCMC. In particular, we provide guarantees regarding isotropicrounding procedures for sampling uniformly on convex bodies.</description><author>Yunbum Kook, Matthew S. Zhang</author><pubDate>Tue, 22 Oct 2024 16:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17147v1</guid></item><item><title>Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases</title><link>http://arxiv.org/abs/2410.14594v2</link><description>Recent advancements in tool-equipped Agents (LLMs) have enabled complex taskslike secure database interactions and multi-agent code development. However,scaling tool capacity beyond agent reasoning or model limits remains achallenge. In this paper, we address these challenges by introducing ToolshedKnowledge Bases, a tool knowledge base (vector database) designed to storeenhanced tool representations and optimize tool selection for large-scaletool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, anovel ensemble of tool-applied advanced retrieval-augmented generation (RAG)techniques across the pre-retrieval, intra-retrieval, and post-retrievalphases, without requiring model fine-tuning. During pre-retrieval, tooldocuments are enhanced with key information and stored in the ToolshedKnowledge Base. Intra-retrieval focuses on query planning and transformation toincrease retrieval accuracy. Post-retrieval refines the retrieved tooldocuments and enables self-reflection. Furthermore, by varying both the totalnumber of tools (tool-M) an Agent has access to and the tool selectionthreshold (top-k), we address trade-offs between retrieval accuracy, agentperformance, and token cost. Our approach achieves 46%, 56%, and 47% absoluteimprovements on the ToolE single-tool, ToolE multi-tool and Seal-Toolsbenchmark datasets, respectively (Recall@5).</description><author>Elias Lumer, Vamse Kumar Subbiah, James A. Burke, Pradeep Honaganahalli Basavaraju, Austin Huber</author><pubDate>Tue, 22 Oct 2024 16:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14594v2</guid></item><item><title>ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control With Decoupled Codec</title><link>http://arxiv.org/abs/2406.01205v2</link><description>In this paper, we present ControlSpeech, a text-to-speech (TTS) systemcapable of fully cloning the speaker's voice and enabling arbitrary control andadjustment of speaking style, merely based on a few seconds of audio prompt anda simple textual style description prompt. Prior zero-shot TTS models andcontrollable TTS models either could only mimic the speaker's voice withoutfurther control and adjustment capabilities or were unrelated tospeaker-specific voice generation. Therefore, ControlSpeech focuses on a morechallenging new task-a TTS system with controllable timbre, content, and styleat the same time. ControlSpeech takes speech prompts, content prompts, andstyle prompts as inputs and utilizes bidirectional attention and mask-basedparallel decoding to capture corresponding codec representations in a discretedecoupling codec space. Moreover, we discovered the issue of text stylecontrollability in a many-to-many mapping fashion and proposed the StyleMixture Semantic Density (SMSD) model to resolve this problem. SMSD modulewhich is based on Gaussian mixture density networks, is designed to enhance thefine-grained partitioning and sampling capabilities of style semanticinformation and generate speech with more diverse styles. In terms ofexperiments, we make available a controllable model toolkit calledControlToolkit with a new style controllable dataset, some replicated baselinemodels and propose new metrics to evaluate both the control capability and thequality of generated audio in ControlSpeech. The relevant ablation studiesvalidate the necessity of each component in ControlSpeech is necessary. We hopethat ControlSpeech can establish the next foundation paradigm of controllablespeech synthesis. The relevant code and demo are available athttps://github.com/jishengpeng/ControlSpeech .</description><author>Shengpeng Ji, Jialong Zuo, Wen Wang, Minghui Fang, Siqi Zheng, Qian Chen, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Zhou Zhao</author><pubDate>Tue, 22 Oct 2024 16:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01205v2</guid></item><item><title>Boosting Sample Efficiency and Generalization in Multi-agent Reinforcement Learning via Equivariance</title><link>http://arxiv.org/abs/2410.02581v3</link><description>Multi-Agent Reinforcement Learning (MARL) struggles with sample inefficiencyand poor generalization [1]. These challenges are partially due to a lack ofstructure or inductive bias in the neural networks typically used in learningthe policy. One such form of structure that is commonly observed in multi-agentscenarios is symmetry. The field of Geometric Deep Learning has developedEquivariant Graph Neural Networks (EGNN) that are equivariant (or symmetric) torotations, translations, and reflections of nodes. Incorporating equivariancehas been shown to improve learning efficiency and decrease error [ 2 ]. In thispaper, we demonstrate that EGNNs improve the sample efficiency andgeneralization in MARL. However, we also show that a naive application of EGNNsto MARL results in poor early exploration due to a bias in the EGNN structure.To mitigate this bias, we present Exploration-enhanced Equivariant Graph NeuralNetworks or E2GN2. We compare E2GN2 to other common function approximatorsusing common MARL benchmarks MPE and SMACv2. E2GN2 demonstrates a significantimprovement in sample efficiency, greater final reward convergence, and a 2x-5xgain in over standard GNNs in our generalization tests. These results pave theway for more reliable and effective solutions in complex multi-agent systems.</description><author>Joshua McClellan, Naveed Haghani, John Winder, Furong Huang, Pratap Tokekar</author><pubDate>Tue, 22 Oct 2024 16:26:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02581v3</guid></item><item><title>LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging</title><link>http://arxiv.org/abs/2410.17146v1</link><description>Large pre-trained models exhibit impressive zero-shot performance acrossdiverse tasks, but fine-tuning often leads to catastrophic forgetting, whereimprovements on a target domain degrade generalization on other tasks. Toaddress this challenge, we introduce LiNeS, Layer-increasing Network Scaling, apost-training editing technique designed to preserve pre-trained generalizationwhile enhancing fine-tuned task performance. LiNeS scales parameter updateslinearly based on their layer depth within the network, maintaining shallowlayers close to their pre-trained values to preserve general features whileallowing deeper layers to retain task-specific representations. We furtherextend this approach to multi-task model merging scenarios, where layer-wisescaling of merged parameters reduces negative task interference. LiNeSdemonstrates significant improvements in both single-task and multi-tasksettings across various benchmarks in vision and natural language processing.It mitigates forgetting, enhances out-of-distribution generalization,integrates seamlessly with existing multi-task model merging baselinesimproving their performance across benchmarks and model sizes, and can boostgeneralization when merging LLM policies aligned with different rewards viaRLHF. Importantly, our method is simple to implement and complementary to manyexisting techniques.</description><author>Ke Wang, Nikolaos Dimitriadis, Alessandro Favero, Guillermo Ortiz-Jimenez, Francois Fleuret, Pascal Frossard</author><pubDate>Tue, 22 Oct 2024 16:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17146v1</guid></item><item><title>Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?</title><link>http://arxiv.org/abs/2410.17145v1</link><description>Large language models (LLMs) perform well on common tasks but struggle withgeneralization in low-resource and low-computation settings. We examine thislimitation by testing various LLMs and specialized translation models onEnglish-Thai machine translation and code-switching datasets. Our findingsreveal that under more strict computational constraints, such as 4-bitquantization, LLMs fail to translate effectively. In contrast, specializedmodels, with comparable or lower computational requirements, consistentlyoutperform LLMs. This underscores the importance of specialized models formaintaining performance under resource constraints.</description><author>Jirat Chiaranaipanich, Naiyarat Hanmatheekuna, Jitkapat Sawatphol, Krittamate Tiankanon, Jiramet Kinchagawat, Amrest Chinkamol, Parinthapat Pengpun, Piyalitt Ittichaiwong, Peerat Limkonchotiwat</author><pubDate>Tue, 22 Oct 2024 16:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17145v1</guid></item><item><title>YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using Optimized Receptive Fields and Anchor-Free Fusion</title><link>http://arxiv.org/abs/2410.17144v1</link><description>Ensuring safety in both autonomous driving and advanced driver-assistancesystems (ADAS) depends critically on the efficient deployment of traffic signrecognition technology. While current methods show effectiveness, they oftencompromise between speed and accuracy. To address this issue, we present anovel real-time and efficient road sign detection network, YOLO-TS. Thisnetwork significantly improves performance by optimizing the receptive fieldsof multi-scale feature maps to align more closely with the size distribution oftraffic signs in various datasets. Moreover, our innovative feature-fusionstrategy, leveraging the flexibility of Anchor-Free methods, allows formulti-scale object detection on a high-resolution feature map abundant incontextual information, achieving remarkable enhancements in both accuracy andspeed. To mitigate the adverse effects of the grid pattern caused by dilatedconvolutions on the detection of smaller objects, we have devised a uniquemodule that not only mitigates this grid effect but also widens the receptivefield to encompass an extensive range of spatial contextual information, thusboosting the efficiency of information usage. Evaluation on challenging publicdatasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existingstate-of-the-art methods in terms of both accuracy and speed. The code for ourmethod will be available.</description><author>Junzhou Chen, Heqiang Huang, Ronghui Zhang, Nengchao Lyu, Yanyong Guo, Hong-Ning Dai, Hong Yan</author><pubDate>Tue, 22 Oct 2024 16:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17144v1</guid></item><item><title>Coniferest: a complete active anomaly detection framework</title><link>http://arxiv.org/abs/2410.17142v1</link><description>We present coniferest, an open source generic purpose active anomalydetection framework written in Python. The package design and implementedalgorithms are described. Currently, static outlier detection analysis issupported via the Isolation forest algorithm. Moreover, Active AnomalyDiscovery (AAD) and Pineforest algorithms are available to tackle activeanomaly detection problems. The algorithms and package performance areevaluated on a series of synthetic datasets. We also describe a few successcases which resulted from applying the package to real astronomical data inactive anomaly detection tasks within the SNAD project.</description><author>M. V. Kornilov, V. S. Korolev, K. L. Malanchev, A. D. Lavrukhina, E. Russeil, T. A. Semenikhin, E. Gangler, E. E. O. Ishida, M. V. Pruzhinskaya, A. A. Volnova, S. Sreejith</author><pubDate>Tue, 22 Oct 2024 16:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17142v1</guid></item><item><title>Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements</title><link>http://arxiv.org/abs/2410.17141v1</link><description>Hacking poses a significant threat to cybersecurity, inflicting billions ofdollars in damages annually. To mitigate these risks, ethical hacking, orpenetration testing, is employed to identify vulnerabilities in systems andnetworks. Recent advancements in large language models (LLMs) have shownpotential across various domains, including cybersecurity. However, there iscurrently no comprehensive, open, end-to-end automated penetration testingbenchmark to drive progress and evaluate the capabilities of these models insecurity contexts. This paper introduces a novel open benchmark for LLM-basedautomated penetration testing, addressing this critical gap. We first evaluatethe performance of LLMs, including GPT-4o and Llama 3.1-405B, using thestate-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1demonstrates an edge over GPT-4o, both models currently fall short ofperforming fully automated, end-to-end penetration testing. Next, we advancethe state-of-the-art and present ablation studies that provide insights intoimproving the PentestGPT tool. Our research illuminates the challenges LLMsface in each aspect of Pentesting, e.g. enumeration, exploitation, andprivilege escalation. This work contributes to the growing body of knowledge onAI-assisted cybersecurity and lays the foundation for future research inautomated penetration testing using large language models.</description><author>Isamu Isozaki, Manil Shrestha, Rick Console, Edward Kim</author><pubDate>Tue, 22 Oct 2024 16:18:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17141v1</guid></item><item><title>Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary Resolution</title><link>http://arxiv.org/abs/2409.12961v2</link><description>Visual data comes in various forms, ranging from small icons of just a fewpixels to long videos spanning hours. Existing multi-modal LLMs usuallystandardize these diverse visual inputs to a fixed resolution for visualencoders and yield similar numbers of tokens for LLMs. This approach isnon-optimal for multimodal understanding and inefficient for processing inputswith long and short visual contents. To solve the problem, we propose Oryx, aunified multimodal architecture for the spatial-temporal understanding ofimages, videos, and multi-view 3D scenes. Oryx offers an on-demand solution toseamlessly and efficiently process visual inputs with arbitrary spatial sizesand temporal lengths through two core innovations: 1) a pre-trained OryxViTmodel that can encode images at any resolution into LLM-friendly visualrepresentations; 2) a dynamic compressor module that supports 1x to 16xcompression on visual tokens by request. These design features enable Oryx toaccommodate extremely long visual contexts, such as videos, with lowerresolution and high compression while maintaining high recognition precisionfor tasks like document understanding with native resolution and nocompression. Beyond the architectural improvements, enhanced data curation andspecialized training on long-context retrieval and spatial-aware data help Oryxachieve strong capabilities in image, video, and 3D multimodal understandingsimultaneously. Our work is open-sourced at https://github.com/Oryx-mllm/Oryx.</description><author>Zuyan Liu, Yuhao Dong, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao</author><pubDate>Tue, 22 Oct 2024 16:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.12961v2</guid></item><item><title>Trustworthy XAI and Application</title><link>http://arxiv.org/abs/2410.17139v1</link><description>One of today's most significant and transformative technologies is therapidly developing field of artificial intelligence (AI). Deined as a computersystem that simulates human cognitive processes, AI is present in many aspectsof our daily lives, from the self-driving cars on the road to the intelligence(AI) because some AI systems are so complex and opaque. With millions ofparameters and layers, these system-deep neural networks in particular-make itdifficult for humans to comprehend accountability, prejudice, and justice areraised by the opaqueness of its decision-making process. AI has a lot ofpotential, but it also comes with a lot of difficulties and moral dilemmas. Inthe context of explainable artificial intelligence (XAI), trust is crucial asit ensures that AI systems behave consistently, fairly, and ethically. In thepresent article, we explore XAI, reliable XAI, and several practical uses forreliable XAI. Once more, we go over the three main components-transparency,explainability, and trustworthiness of XAI-that we determined are pertinent inthis situation. We present an overview of recent scientific studies that employtrustworthy XAI in various application fields. In the end, trustworthiness iscrucial for establishing and maintaining trust between humans and AI systems,facilitating the integration of AI systems into various applications anddomains for the benefit of society.</description><author>MD Abdullah Al Nasim, Parag Biswas, Abdur Rashid, Angona Biswas, Kishor Datta Gupta</author><pubDate>Tue, 22 Oct 2024 16:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17139v1</guid></item><item><title>AlphaChimp: Tracking and Behavior Recognition of Chimpanzees</title><link>http://arxiv.org/abs/2410.17136v1</link><description>Understanding non-human primate behavior is crucial for improving animalwelfare, modeling social behavior, and gaining insights into both distinctlyhuman and shared behaviors. Despite recent advances in computer vision,automated analysis of primate behavior remains challenging due to thecomplexity of their social interactions and the lack of specialized algorithms.Existing methods often struggle with the nuanced behaviors and frequentocclusions characteristic of primate social dynamics. This study aims todevelop an effective method for automated detection, tracking, and recognitionof chimpanzee behaviors in video footage. Here we show that our proposedmethod, AlphaChimp, an end-to-end approach that simultaneously detectschimpanzee positions and estimates behavior categories from videos,significantly outperforms existing methods in behavior recognition. AlphaChimpachieves approximately 10% higher tracking accuracy and a 20% improvement inbehavior recognition compared to state-of-the-art methods, particularlyexcelling in the recognition of social behaviors. This superior performancestems from AlphaChimp's innovative architecture, which integrates temporalfeature fusion with a Transformer-based self-attention mechanism, enabling moreeffective capture and interpretation of complex social interactions amongchimpanzees. Our approach bridges the gap between computer vision andprimatology, enhancing technical capabilities and deepening our understandingof primate communication and sociality. We release our code and models and hopethis will facilitate future research in animal social dynamics. This workcontributes to ethology, cognitive science, and artificial intelligence,offering new perspectives on social intelligence.</description><author>Xiaoxuan Ma, Yutang Lin, Yuan Xu, Stephan P. Kaufhold, Jack Terwilliger, Andres Meza, Yixin Zhu, Federico Rossano, Yizhou Wang</author><pubDate>Tue, 22 Oct 2024 16:08:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17136v1</guid></item><item><title>Reinforcement Learning for Data-Driven Workflows in Radio Interferometry. I. Principal Demonstration in Calibration</title><link>http://arxiv.org/abs/2410.17135v1</link><description>Radio interferometry is an observational technique used to studyastrophysical phenomena. Data gathered by an interferometer requiressubstantial processing before astronomers can extract the scientificinformation from it. Data processing consists of a sequence of calibration andanalysis procedures where choices must be made about the sequence of proceduresas well as the specific configuration of the procedure itself. These choicesare typically based on a combination of measurable data characteristics, anunderstanding of the instrument itself, an appreciation of the trade-offsbetween compute cost and accuracy, and a learned understanding of what isconsidered "best practice". A metric of absolute correctness is not alwaysavailable and validity is often subject to human judgment. The underlyingprinciples and software configurations to discern a reasonable workflow for agiven dataset is the subject of training workshops for students and scientists.Our goal is to use objective metrics that quantify best practice, andnumerically map out the decision space with respect to our metrics. With theseobjective metrics we demonstrate an automated, data-driven, decision systemthat is capable of sequencing the optimal action(s) for processinginterferometric data. This paper introduces a simplified description of theprinciples behind interferometry and the procedures required for dataprocessing. We highlight the issues with current automation approaches andpropose our ideas for solving these bottlenecks. A prototype is demonstratedand the results are discussed.</description><author>Brian M. Kirk, Urvashi Rau, Ramyaa Ramyaa</author><pubDate>Tue, 22 Oct 2024 16:07:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17135v1</guid></item><item><title>NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples</title><link>http://arxiv.org/abs/2410.14669v2</link><description>Vision-language models (VLMs) have made significant progress in recentvisual-question-answering (VQA) benchmarks that evaluate complexvisio-linguistic reasoning. However, are these models truly effective? In thiswork, we show that VLMs still struggle with natural images and questions thathumans can easily answer, which we term natural adversarial samples. We alsofind it surprisingly easy to generate these VQA samples from natural image-textcorpora using off-the-shelf models like CLIP and ChatGPT. We propose asemi-automated approach to collect a new benchmark, NaturalBench, for reliablyevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a$\textbf{vision-centric}$ design by pairing each question with two images thatyield different answers, preventing blind solutions from answering withoutusing the images. This makes NaturalBench more challenging than previousbenchmarks that can be solved with commonsense priors. We evaluate 53state-of-the-art VLMs on NaturalBench, showing that models likeLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4olag 50%-70% behind human performance (over 90%). We analyze why NaturalBench ishard from two angles: (1) Compositionality: Solving NaturalBench requiresdiverse visio-linguistic skills, including understanding attribute bindings,object relationships, and advanced reasoning like logic and counting. To thisend, unlike prior work that uses a single tag per sample, we tag eachNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)Biases: NaturalBench exposes severe biases in VLMs, as models often choose thesame answer regardless of the image. Lastly, we apply our benchmark curationmethod to diverse data sources, including long captions (over 100 words) andnon-English languages like Chinese and Hindi, highlighting its potential fordynamic evaluations of VLMs.</description><author>Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan</author><pubDate>Tue, 22 Oct 2024 16:07:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14669v2</guid></item><item><title>Aligning Large Language Models via Self-Steering Optimization</title><link>http://arxiv.org/abs/2410.17131v1</link><description>Automated alignment develops alignment systems with minimal humanintervention. The key to automated alignment lies in providing learnable andaccurate preference signals for preference learning without human annotation.In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithmthat autonomously generates high-quality preference signals based on predefinedprinciples during iterative training, eliminating the need for manualannotation. $SSO$ maintains the accuracy of signals by ensuring a consistentgap between chosen and rejected responses while keeping them both on-policy tosuit the current policy model's learning capacity. $SSO$ can benefit the onlineand offline training of the policy model, as well as enhance the training ofreward models. We validate the effectiveness of $SSO$ with two foundationmodels, Qwen2 and Llama3.1, indicating that it provides accurate, on-policypreference signals throughout iterative training. Without any manual annotationor external models, $SSO$ leads to significant performance improvements acrosssix subjective or objective benchmarks. Besides, the preference data generatedby $SSO$ significantly enhanced the performance of the reward model onRewardbench. Our work presents a scalable approach to preference optimization,paving the way for more efficient and effective automated alignment.</description><author>Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun, Jingren Zhou, Junyang Lin</author><pubDate>Tue, 22 Oct 2024 16:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17131v1</guid></item><item><title>Understanding Transfer Learning via Mean-field Analysis</title><link>http://arxiv.org/abs/2410.17128v1</link><description>We propose a novel framework for exploring generalization errors of transferlearning through the lens of differential calculus on the space of probabilitymeasures. In particular, we consider two main transfer learning scenarios,$\alpha$-ERM and fine-tuning with the KL-regularized empirical riskminimization and establish generic conditions under which the generalizationerror and the population risk convergence rates for these scenarios arestudied. Based on our theoretical results, we show the benefits of transferlearning with a one-hidden-layer neural network in the mean-field regime undersome suitable integrability and regularity assumptions on the loss andactivation functions.</description><author>Gholamali Aminian, Samuel N. Cohen, Łukasz Szpruch</author><pubDate>Tue, 22 Oct 2024 16:00:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17128v1</guid></item><item><title>PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles</title><link>http://arxiv.org/abs/2410.17127v1</link><description>Users can divulge sensitive information to proprietary LLM providers, raisingsignificant privacy concerns. While open-source models, hosted locally on theuser's machine, alleviate some concerns, models that users can host locally areoften less capable than proprietary frontier models. Toward preserving userprivacy while retaining the best quality, we propose Privacy-ConsciousDelegation, a novel task for chaining API-based and local models. We utilizerecent public collections of user-LLM interactions to construct a naturalbenchmark called PUPA, which contains personally identifiable information(PII). To study potential approaches, we devise PAPILLON, a multi-stage LLMpipeline that uses prompt optimization to address a simpler version of ourtask. Our best pipeline maintains high response quality for 85.5% of userqueries while restricting privacy leakage to only 7.5%. We still leave a largemargin to the generation quality of proprietary LLMs for future work. Our dataand code will be available at https://github.com/siyan-sylvia-li/PAPILLON.</description><author>Li Siyan, Vethavikashini Chithrra Raghuram, Omar Khattab, Julia Hirschberg, Zhou Yu</author><pubDate>Tue, 22 Oct 2024 16:00:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17127v1</guid></item><item><title>Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards</title><link>http://arxiv.org/abs/2410.17126v1</link><description>Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learningfrom Human Feedback to align large language models (LLMs) with downstreamtasks. This paper investigates the feasibility of using PPO for directreinforcement learning (RL) from explicitly programmed reward signals, asopposed to indirect learning from human feedback via an intermediary rewardmodel. We focus on tasks expressed through formal languages, such asmathematics and programming, where explicit reward functions can be programmedto automatically assess the quality of generated outputs. We apply thisapproach to a sentiment alignment task, a simple arithmetic task, and a morecomplex game synthesis task. The sentiment alignment task replicates priorresearch and serves to validate our experimental setup. Our results show thatpure RL-based training for the two formal language tasks is challenging, withsuccess being limited even for the simple arithmetic task. We propose a novelbatch-entropy regularization term to aid exploration, although training is notyet entirely stable. Our findings suggest that direct RL training of LLMs maybe more suitable for relatively minor changes, such as alignment, than forlearning new tasks altogether, even if an informative reward signal can beexpressed programmatically.</description><author>Alexander G. Padula, Dennis J. N. J. Soemers</author><pubDate>Tue, 22 Oct 2024 15:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17126v1</guid></item><item><title>Automated neuroradiological support systems for multiple cerebrovascular disease markers -- A systematic review and meta-analysis</title><link>http://arxiv.org/abs/2410.17124v1</link><description>Cerebrovascular diseases (CVD) can lead to stroke and dementia. Stroke is thesecond leading cause of death world wide and dementia incidence is increasingby the year. There are several markers of CVD that are visible on brainimaging, including: white matter hyperintensities (WMH), acute and chronicischaemic stroke lesions (ISL), lacunes, enlarged perivascular spaces (PVS),acute and chronic haemorrhagic lesions, and cerebral microbleeds (CMB). Brainatrophy also occurs in CVD. These markers are important for patient managementand intervention, since they indicate elevated risk of future stroke anddementia. We systematically reviewed automated systems designed to supportradiologists reporting on these CVD imaging findings. We consideredcommercially available software and research publications which identify atleast two CVD markers. In total, we included 29 commercial products and 13research publications. Two distinct types of commercial support system wereavailable: those which identify acute stroke lesions (haemorrhagic andischaemic) from computed tomography (CT) scans, mainly for the purpose ofpatient triage; and those which measure WMH and atrophy regionally andlongitudinally. In research, WMH and ISL were the markers most frequentlyanalysed together, from magnetic resonance imaging (MRI) scans; lacunes and PVSwere each targeted only twice and CMB only once. For stroke, commerciallyavailable systems largely support the emergency setting, whilst researchsystems consider also follow-up and routine scans. The systems to quantify WMHand atrophy are focused on neurodegenerative disease support, where these CVDmarkers are also of significance. There are currently no openly validatedsystems, commercially, or in research, performing a comprehensive jointanalysis of all CVD markers (WMH, ISL, lacunes, PVS, haemorrhagic lesions, CMB,and atrophy).</description><author>Jesse Phitidis, Alison Q. O'Neil, William N. Whiteley, Beatrice Alex, Joanna M. Wardlaw, Miguel O. Bernabeu, Maria Valdés Hernández</author><pubDate>Tue, 22 Oct 2024 15:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17124v1</guid></item><item><title>The Complexity of Optimizing Atomic Congestion</title><link>http://arxiv.org/abs/2312.10219v2</link><description>Atomic congestion games are a classic topic in network design, routing, andalgorithmic game theory, and are capable of modeling congestion and flowoptimization tasks in various application areas. While both the price ofanarchy for such games as well as the computational complexity of computingtheir Nash equilibria are by now well-understood, the computational complexityof computing a system-optimal set of strategies -- that is, a centrally plannedrouting that minimizes the average cost of agents -- is severely understudiedin the literature. We close this gap by identifying the exact boundaries oftractability for the problem through the lens of the parameterized complexityparadigm. After showing that the problem remains highly intractable even onextremely simple networks, we obtain a set of results which demonstrate thatthe structural parameters which control the computational (in)tractability ofthe problem are not vertex-separator based in nature (such as, e.g.,treewidth), but rather based on edge separators. We conclude by extending ouranalysis towards the (even more challenging) min-max variant of the problem.</description><author>Cornelius Brand, Robert Ganian, Subrahmanyam Kalyanasundaram, Fionn Mc Inerney</author><pubDate>Tue, 22 Oct 2024 15:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10219v2</guid></item><item><title>Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks</title><link>http://arxiv.org/abs/2410.17118v1</link><description>Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are apromising paradigm of heterogeneous network (HetNet), attributed to thecomplementary physical properties of optical spectra and radio frequency.However, the current development of such HetNets is mostly bottlenecked by theexisting transmission control protocol (TCP), which restricts the userequipment (UE) to connecting one access point (AP) at a time. While the ongoinginvestigation on multipath TCP (MPTCP) can bring significant benefits, itcomplicates the network topology of HetNets, making the existing load balancing(LB) learning models less effective. Driven by this, we propose a graph neuralnetwork (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,which results in a partial mesh topology. Such a topology can be modeled as agraph, with the channel state information and data rate requirement embedded asnode features, while the LB solutions are deemed as edge labels. Compared tothe conventional deep neural network (DNN), the proposed GNN-based modelexhibits two key strengths: i) it can better interpret a complex networktopology; and ii) it can handle various numbers of APs and UEs with a singletrained model. Simulation results show that against the traditionaloptimisation method, the proposed learning model can achieve near-optimalthroughput within a gap of 11.5%, while reducing the inference time by 4 ordersof magnitude. In contrast to the DNN model, the new method can improve thenetwork throughput by up to 21.7%, at a similar inference time level.</description><author>Han Ji, Xiping Wu, Zhihong Zeng, Chen Chen</author><pubDate>Tue, 22 Oct 2024 15:49:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17118v1</guid></item><item><title>PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving</title><link>http://arxiv.org/abs/2404.01596v3</link><description>Motion prediction is critical for autonomous off-road driving, however, itpresents significantly more challenges than on-road driving because of thecomplex interaction between the vehicle and the terrain. Traditionalphysics-based approaches encounter difficulties in accurately modeling dynamicsystems and external disturbance. In contrast, data-driven neural networksrequire extensive datasets and struggle with explicitly capturing thefundamental physical laws, which can easily lead to poor generalization. Bymerging the advantages of both methods, neuro-symbolic approaches present apromising direction. These methods embed physical laws into neural models,potentially significantly improving generalization capabilities. However, noprior works were evaluated in real-world settings for off-road driving. Tobridge this gap, we present PhysORD, a neural-symbolic approach integrating theconservation law, i.e., the Euler-Lagrange equation, into data-driven neuralmodels for motion prediction in off-road driving. Our experiments showed thatPhysORD can accurately predict vehicle motion and tolerate external disturbanceby modeling uncertainties. The learned dynamics model achieves 46.7% higheraccuracy using only 3.1% of the parameters compared to data-driven methods,demonstrating the data efficiency and superior generalization ability of ourneural-symbolic method.</description><author>Zhipeng Zhao, Bowen Li, Yi Du, Taimeng Fu, Chen Wang</author><pubDate>Tue, 22 Oct 2024 15:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01596v3</guid></item><item><title>Enhancing Answer Attribution for Faithful Text Generation with Large Language Models</title><link>http://arxiv.org/abs/2410.17112v1</link><description>The increasing popularity of Large Language Models (LLMs) in recent years haschanged the way users interact with and pose questions to AI-basedconversational systems. An essential aspect for increasing the trustworthinessof generated LLM answers is the ability to trace the individual claims fromresponses back to relevant sources that support them, the process known asanswer attribution. While recent work has started exploring the task of answerattribution in LLMs, some challenges still remain. In this work, we firstperform a case study analyzing the effectiveness of existing answer attributionmethods, with a focus on subtasks of answer segmentation and evidenceretrieval. Based on the observed shortcomings, we propose new methods forproducing more independent and contextualized claims for better retrieval andattribution. The new methods are evaluated and shown to improve the performanceof answer attribution components. We end with a discussion and outline offuture directions for the task.</description><author>Juraj Vladika, Luca Mülln, Florian Matthes</author><pubDate>Tue, 22 Oct 2024 15:37:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17112v1</guid></item><item><title>Credal Bayesian Deep Learning</title><link>http://arxiv.org/abs/2302.09656v5</link><description>Uncertainty quantification and robustness to distribution shifts areimportant goals in machine learning and artificial intelligence. AlthoughBayesian Neural Networks (BNNs) allow for uncertainty in the predictions to beassessed, different sources of predictive uncertainty cannot be distinguishedproperly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDLallows to train an (uncountably) infinite ensemble of BNNs, using only finitelymany elements. This is possible thanks to prior and likelihood finitelygenerated credal sets (FGCSs), a concept from the imprecise probabilityliterature. Intuitively, convex combinations of a finite collection ofprior-likelihood pairs are able to represent infinitely many such pairs. Aftertraining, CBDL outputs a set of posteriors on the parameters of the neuralnetwork. At inference time, such posterior set is used to derive a set ofpredictive distributions that is in turn utilized to distinguish between(predictive) aleatoric and epistemic uncertainties, and to quantify them. Thepredictive set also produces either (i) a collection of outputs enjoyingdesirable probabilistic guarantees, or (ii) the single output that is deemedthe best, that is, the one having the highest predictive lower probability --another imprecise-probabilistic concept. CBDL is more robust than single BNNsto prior and likelihood misspecification, and to distribution shift. We showthat CBDL is better at quantifying and disentangling different types of(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,we apply CBDL to two case studies to demonstrate its downstream taskscapabilities: one, for motion prediction in autonomous driving scenarios, andtwo, to model blood glucose and insulin dynamics for artificial pancreascontrol. We show that CBDL performs better when compared to an ensemble of BNNsbaseline.</description><author>Michele Caprio, Souradeep Dutta, Kuk Jin Jang, Vivian Lin, Radoslav Ivanov, Oleg Sokolsky, Insup Lee</author><pubDate>Tue, 22 Oct 2024 15:36:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09656v5</guid></item><item><title>Permutation Picture of Graph Combinatorial Optimization Problems</title><link>http://arxiv.org/abs/2410.17111v1</link><description>This paper proposes a framework that formulates a wide range of graphcombinatorial optimization problems using permutation-based representations.These problems include the travelling salesman problem, maximum independentset, maximum cut, and various other related problems. This work potentiallyopens up new avenues for algorithm design in neural combinatorial optimization,bridging the gap between discrete and continuous optimization techniques.</description><author>Yimeng Min</author><pubDate>Tue, 22 Oct 2024 15:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17111v1</guid></item><item><title>CLAP: Concave Linear APproximation for Quadratic Graph Matching</title><link>http://arxiv.org/abs/2410.17101v1</link><description>Solving point-wise feature correspondence in visual data is a fundamentalproblem in computer vision. A powerful model that addresses this challenge isto formulate it as graph matching, which entails solving a Quadratic AssignmentProblem (QAP) with node-wise and edge-wise constraints. However, solving such aQAP can be both expensive and difficult due to numerous local extreme points.In this work, we introduce a novel linear model and solver designed toaccelerate the computation of graph matching. Specifically, we employ apositive semi-definite matrix approximation to establish the structuralattribute constraint.We then transform the original QAP into a linear modelthat is concave for maximization. This model can subsequently be solved usingthe Sinkhorn optimal transport algorithm, known for its enhanced efficiency andnumerical stability compared to existing approaches. Experimental results onthe widely used benchmark PascalVOC showcase that our algorithm achievesstate-of-the-art performance with significantly improved efficiency. Sourcecode: https://github.com/xmlyqing00/clap</description><author>Yongqing Liang, Huijun Han, Xin Li</author><pubDate>Tue, 22 Oct 2024 15:28:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17101v1</guid></item><item><title>Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations</title><link>http://arxiv.org/abs/2410.17099v1</link><description>The quality is a crucial issue for crowd annotations. Answer aggregation isan important type of solution. The aggregated answers estimated from multiplecrowd answers to the same instance are the eventually collected annotations,rather than the individual crowd answers themselves. Recently, the capabilityof Large Language Models (LLMs) on data annotation tasks has attracted interestfrom researchers. Most of the existing studies mainly focus on the averageperformance of individual crowd workers; several recent works studied thescenarios of aggregation on categorical labels and LLMs used as label creators.However, the scenario of aggregation on text answers and the role of LLMs asaggregators are not yet well-studied. In this paper, we investigate thecapability of LLMs as aggregators in the scenario of close-ended crowd textanswer aggregation. We propose a human-LLM hybrid text answer aggregationmethod with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. Wemake the experiments based on public crowdsourcing datasets. The results showthe effectiveness of our approach based on the collaboration of crowd workersand LLMs.</description><author>Jiyi Li</author><pubDate>Tue, 22 Oct 2024 15:22:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17099v1</guid></item></channel></rss>