<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 15 May 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance</title><link>http://arxiv.org/abs/2304.06715v2</link><description>Interpretability methods are valuable only if their explanations faithfullydescribe the explained model. In this work, we consider neural networks whosepredictions are invariant under a specific symmetry group. This includespopular architectures, ranging from convolutional to graph neural networks. Anyexplanation that faithfully explains this type of model needs to be inagreement with this invariance property. We formalize this intuition throughthe notion of explanation invariance and equivariance by leveraging theformalism from geometric deep learning. Through this rigorous formalism, wederive (1) two metrics to measure the robustness of any interpretability methodwith respect to the model symmetry group; (2) theoretical robustness guaranteesfor some popular interpretability methods and (3) a systematic approach toincrease the invariance of any interpretability method with respect to asymmetry group. By empirically measuring our metrics for explanations of modelsassociated with various modalities and symmetry groups, we derive a set of 5guidelines to allow users and developers of interpretability methods to producerobust explanations.</description><author>Jonathan Crabbé, Mihaela van der Schaar</author><pubDate>Fri, 12 May 2023 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06715v2</guid></item><item><title>A Critical View Of Vision-Based Long-Term Dynamics Prediction Under Environment Misalignment</title><link>http://arxiv.org/abs/2305.07648v1</link><description>Dynamics prediction, which is the problem of predicting future states ofscene objects based on current and prior states, is drawing increasingattention as an instance of learning physics. To solve this problem, RegionProposal Convolutional Interaction Network (RPCIN), a vision-based model, wasproposed and achieved state-of-the-art performance in long-term prediction.RPCIN only takes raw images and simple object descriptions, such as thebounding box and segmentation mask of each object, as input. However, despiteits success, the model's capability can be compromised under conditions ofenvironment misalignment. In this paper, we investigate two challengingconditions for environment misalignment: Cross-Domain and Cross-Context byproposing four datasets that are designed for these challenges: SimB-Border,SimB-Split, BlenB-Border, and BlenB-Split. The datasets cover two domains andtwo contexts. Using RPCIN as a probe, experiments conducted on the combinationsof the proposed datasets reveal potential weaknesses of the vision-basedlong-term dynamics prediction model. Furthermore, we propose a promisingdirection to mitigate the Cross-Domain challenge and provide concrete evidencesupporting such a direction, which provides dramatic alleviation of thechallenge on the proposed datasets.</description><author>Hanchen Xie, Jiageng Zhu, Mahyar Khayatkhoei, Jiazhi Li, Mohamed E. Hussein, Wael AbdAlmgaeed</author><pubDate>Fri, 12 May 2023 18:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07648v1</guid></item><item><title>Beware of diffusion models for synthesizing medical images -- A comparison with GANs in terms of memorizing brain tumor images</title><link>http://arxiv.org/abs/2305.07644v1</link><description>Diffusion models were initially developed for text-to-image generation andare now being utilized to generate high quality synthetic images. Preceded byGANs, diffusion models have shown impressive results using various evaluationmetrics. However, commonly used metrics such as FID and IS are not suitable fordetermining whether diffusion models are simply reproducing the trainingimages. Here we train StyleGAN and diffusion models, using BRATS20 and BRATS21datasets, to synthesize brain tumor images, and measure the correlation betweenthe synthetic images and all training images. Our results show that diffusionmodels are much more likely to memorize the training images, especially forsmall datasets. Researchers should be careful when using diffusion models formedical imaging, if the final goal is to share the synthetic images.</description><author>Muhammad Usman Akbar, Wuhao Wang, Anders Eklund</author><pubDate>Fri, 12 May 2023 18:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07644v1</guid></item><item><title>The ASNR-MICCAI Brain Tumor Segmentation (BraTS) Challenge 2023: Intracranial Meningioma</title><link>http://arxiv.org/abs/2305.07642v1</link><description>Meningiomas are the most common primary intracranial tumor in adults and canbe associated with significant morbidity and mortality. Radiologists,neurosurgeons, neuro-oncologists, and radiation oncologists rely onmultiparametric MRI (mpMRI) for diagnosis, treatment planning, and longitudinaltreatment monitoring; yet automated, objective, and quantitative tools fornon-invasive assessment of meningiomas on mpMRI are lacking. The BraTSmeningioma 2023 challenge will provide a community standard and benchmark forstate-of-the-art automated intracranial meningioma segmentation models based onthe largest expert annotated multilabel meningioma mpMRI dataset to date.Challenge competitors will develop automated segmentation models to predictthree distinct meningioma sub-regions on MRI including enhancing tumor,non-enhancing tumor core, and surrounding nonenhancing T2/FLAIR hyperintensity.Models will be evaluated on separate validation and held-out test datasetsusing standardized metrics utilized across the BraTS 2023 series of challengesincluding the Dice similarity coefficient and Hausdorff distance. The modelsdeveloped during the course of this challenge will aid in incorporation ofautomated meningioma MRI segmentation into clinical practice, which willultimately improve care of patients with meningioma.</description><author>Dominic LaBella, Maruf Adewole, Michelle Alonso-Basanta, Talissa Altes, Syed Muhammad Anwar, Ujjwal Baid, Timothy Bergquist, Radhika Bhalerao, Sully Chen, Verena Chung, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Devon Godfrey, Fathi Hilal, Ariana Familiar, Keyvan Farahani, Juan Eugenio Iglesias, Zhifan Jiang, Elaine Johanson, Anahita Fathi Kazerooni, Collin Kent, John Kirkpatrick, Florian Kofler, Koen Van Leemput, Hongwei Bran Li, Xinyang Liu, Aria Mahtabfar, Shan McBurney-Lin, Ryan McLean, Zeke Meier, Ahmed W Moawad, John Mongan, Pierre Nedelec, Maxence Pajot, Marie Piraud, Arif Rashid, Zachary Reitman, Russell Takeshi Shinohara, Yury Velichko, Chunhao Wang, Pranav Warman, Walter Wiggins, Mariam Aboian, Jake Albrecht, Udunna Anazodo, Spyridon Bakas, Adam Flanders, Anastasia Ja</author><pubDate>Fri, 12 May 2023 18:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07642v1</guid></item><item><title>Efficient Neural Network based Classification and Outlier Detection for Image Moderation using Compressed Sensing and Group Testing</title><link>http://arxiv.org/abs/2305.07639v1</link><description>Popular social media platforms employ neural network based image moderationengines to classify images uploaded on them as having potentially objectionablecontent. Such moderation engines must answer a large number of queries withheavy computational cost, even though the actual number of images withobjectionable content is usually a tiny fraction. Inspired by recent work onNeural Group Testing, we propose an approach which exploits this fact to reducethe overall computational cost of such engines using the technique ofCompressed Sensing (CS). We present the quantitative matrix-pooled neuralnetwork (QMPNN), which takes as input $n$ images, and a $m \times n$ binarypooling matrix with $m &lt; n$, whose rows indicate $m$ pools of images i.e.selections of $r$ images out of $n$. The QMPNN efficiently outputs the productof this matrix with the unknown sparse binary vector indicating whether eachimage is objectionable or not, i.e. it outputs the number of objectionableimages in each pool. For suitable matrices, this is decoded using CS decodingalgorithms to predict which images were objectionable. The computational costof running the QMPNN and the CS algorithms is significantly lower than the costof using a neural network with the same number of parameters separately on eachimage to classify the images, which we demonstrate via extensive experiments.Our technique is inherently resilient to moderate levels of errors in theprediction from the QMPNN. Furthermore, we present pooled deep outlierdetection, which brings CS and group testing techniques to deep outlierdetection, to provide for the case when the objectionable images do not belongto a set of pre-defined classes. This technique enables efficient automatedmoderation of off-topic images shared on topical forums dedicated to sharingimages of a certain single class, many of which are currently human-moderated.</description><author>Sabyasachi Ghosh, Sanyam Saxena, Ajit Rajwade</author><pubDate>Fri, 12 May 2023 18:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07639v1</guid></item><item><title>On the Partial Convexification for Low-Rank Spectral Optimization: Rank Bounds and Algorithms</title><link>http://arxiv.org/abs/2305.07638v1</link><description>A Low-rank Spectral Optimization Problem (LSOP) minimizes a linear objectivesubject to multiple two-sided linear matrix inequalities intersected with alow-rank and spectral constrained domain set. Although solving LSOP is, ingeneral, NP-hard, its partial convexification (i.e., replacing the domain setby its convex hull) termed "LSOP-R," is often tractable and yields ahigh-quality solution. This motivates us to study the strength of LSOP-R.Specifically, we derive rank bounds for any extreme point of the feasible setof LSOP-R and prove their tightness for the domain sets with different matrixspaces. The proposed rank bounds recover two well-known results in theliterature from a fresh angle and also allow us to derive sufficient conditionsunder which the relaxation LSOP-R is equivalent to the original LSOP. Toeffectively solve LSOP-R, we develop a column generation algorithm with avector-based convex pricing oracle, coupled with a rank-reduction algorithm,which ensures the output solution satisfies the theoretical rank bound.Finally, we numerically verify the strength of the LSOP-R and the efficacy ofthe proposed algorithms.</description><author>Yongchun Li, Weijun Xie</author><pubDate>Fri, 12 May 2023 18:46:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07638v1</guid></item><item><title>Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery</title><link>http://arxiv.org/abs/2305.07637v1</link><description>The Imaging Data Commons (IDC) is a cloud-based database that providesresearchers with open access to cancer imaging data and tools for analysis,with the goal of facilitating collaboration in medical imaging research.However, querying the IDC database for cohort discovery and access to imagingdata has a significant learning curve for researchers due to its complex andtechnical nature. We developed Text2Cohort, a large language model (LLM) basedtoolkit to facilitate natural language cohort discovery by translating userinput into IDC database queries through prompt engineering and returning thequery's response to the user. Furthermore, autocorrection is implemented toresolve syntax and semantic errors in queries by passing the errors back to themodel for interpretation and correction. We evaluate Text2Cohort on 50 naturallanguage user inputs ranging from information extraction to cohort discovery.The resulting queries and outputs were verified by two computer scientists tomeasure Text2Cohort's accuracy and F1 score. Text2Cohort successfully generatedqueries and their responses with an 88% accuracy and F1 score of 0.94. However,it failed to generate queries for six user inputs due to syntax and semanticerrors. Our results indicate that Text2Cohort succeeded at generating querieswith correct responses, but occasionally failed due to a poor understanding ofthe data schema. Despite these shortcomings, Text2Cohort demonstrates theutility of LLMs to enable researchers to discover and curate cohorts using datahosted on IDC with incredible accuracy using natural language in a moreintuitive and user-friendly way, thus democratizing access to the IDC.</description><author>Pranav Kulkarni, Adway Kanhere, Paul H. Yi, Vishwa S. Parekh</author><pubDate>Fri, 12 May 2023 18:46:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07637v1</guid></item><item><title>Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training</title><link>http://arxiv.org/abs/2305.07633v1</link><description>Existing recommender systems face difficulties with zero-shot items, i.e.items that have no historical interactions with users during the trainingstage. Though recent works extract universal item representation viapre-trained language models (PLMs), they ignore the crucial item relationships.This paper presents a novel paradigm for the Zero-Shot Item-basedRecommendation (ZSIR) task, which pre-trains a model on product knowledge graph(PKG) to refine the item features from PLMs. We identify three challenges forpre-training PKG, which are multi-type relations in PKG, semantic divergencebetween item generic information and relations and domain discrepancy from PKGto downstream ZSIR task. We address the challenges by proposing fourpre-training tasks and novel task-oriented adaptation (ToA) layers. Moreover,this paper discusses how to fine-tune the model on new recommendation task suchthat the ToA layers are adapted to ZSIR task. Comprehensive experiments on 18markets dataset are conducted to verify the effectiveness of the proposed modelin both knowledge prediction and ZSIR task.</description><author>Ziwei Fan, Zhiwei Liu, Shelby Heinecke, Jianguo Zhang, Huan Wang, Caiming Xiong, Philip S. Yu</author><pubDate>Fri, 12 May 2023 18:38:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07633v1</guid></item><item><title>Design, Development, and Evaluation of an Interactive Personalized Social Robot to Monitor and Coach Post-Stroke Rehabilitation Exercises</title><link>http://arxiv.org/abs/2305.07632v1</link><description>Socially assistive robots are increasingly being explored to improve theengagement of older adults and people with disability in health andwell-being-related exercises. However, even if people have various physicalconditions, most prior work on social robot exercise coaching systems hasutilized generic, predefined feedback. The deployment of these systems stillremains a challenge. In this paper, we present our work of iteratively engagingtherapists and post-stroke survivors to design, develop, and evaluate a socialrobot exercise coaching system for personalized rehabilitation. Throughinterviews with therapists, we designed how this system interacts with the userand then developed an interactive social robot exercise coaching system. Thissystem integrates a neural network model with a rule-based model toautomatically monitor and assess patients' rehabilitation exercises and can betuned with individual patient's data to generate real-time, personalizedcorrective feedback for improvement. With the dataset of rehabilitationexercises from 15 post-stroke survivors, we demonstrated our systemsignificantly improves its performance to assess patients' exercises whiletuning with held-out patient's data. In addition, our real-world evaluationstudy showed that our system can adapt to new participants and achieved 0.81average performance to assess their exercises, which is comparable to theexperts' agreement level. We further discuss the potential benefits andlimitations of our system in practice.</description><author>Min Hun Lee, Daniel P. Siewiorek, Asim Smailagic, Alexandre Bernardino, Sergi Bermúdez i Badia</author><pubDate>Fri, 12 May 2023 18:37:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07632v1</guid></item><item><title>Feature-compatible Progressive Learning for Video Copy Detection</title><link>http://arxiv.org/abs/2304.10305v2</link><description>Video Copy Detection (VCD) has been developed to identify instances ofunauthorized or duplicated video content. This paper presents our second placesolutions to the Meta AI Video Similarity Challenge (VSC22), CVPR 2023. Inorder to compete in this challenge, we propose Feature-Compatible ProgressiveLearning (FCPL) for VCD. FCPL trains various models that producemutually-compatible features, meaning that the features derived from multipledistinct models can be directly compared with one another. We find this mutualcompatibility enables feature ensemble. By implementing progressive learningand utilizing labeled ground truth pairs, we effectively gradually enhanceperformance. Experimental results demonstrate the superiority of the proposedFCPL over other competitors. Our code is available athttps://github.com/WangWenhao0716/VSC-DescriptorTrack-Submission andhttps://github.com/WangWenhao0716/VSC-MatchingTrack-Submission.</description><author>Wenhao Wang, Yifan Sun, Yi Yang</author><pubDate>Fri, 12 May 2023 18:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10305v2</guid></item><item><title>Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn</title><link>http://arxiv.org/abs/2305.07625v1</link><description>Meta-learning and other approaches to few-shot learning are widely studiedfor image recognition, and are increasingly applied to other vision tasks suchas pose estimation and dense prediction. This naturally raises the question ofwhether there is any few-shot meta-learning algorithm capable of generalizingacross these diverse task types? To support the community in answering thisquestion, we introduce Meta Omnium, a dataset-of-datasets spanning multiplevision tasks including recognition, keypoint localization, semanticsegmentation and regression. We experiment with popular few-shot meta-learningbaselines and analyze their ability to generalize across tasks and to transferknowledge between them. Meta Omnium enables meta-learning researchers toevaluate model generalization to a much wider array of tasks than previouslypossible, and provides a single framework for evaluating meta-learners across awide suite of vision applications in a consistent manner.</description><author>Ondrej Bohdal, Yinbing Tian, Yongshuo Zong, Ruchika Chavhan, Da Li, Henry Gouk, Li Guo, Timothy Hospedales</author><pubDate>Fri, 12 May 2023 18:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07625v1</guid></item><item><title>Agile gesture recognition for capacitive sensing devices: adapting on-the-job</title><link>http://arxiv.org/abs/2305.07624v1</link><description>Automated hand gesture recognition has been a focus of the AI community fordecades. Traditionally, work in this domain revolved largely around scenariosassuming the availability of the flow of images of the user hands. This haspartly been due to the prevalence of camera-based devices and the wideavailability of image data. However, there is growing demand for gesturerecognition technology that can be implemented on low-power devices usinglimited sensor data instead of high-dimensional inputs like hand images. Inthis work, we demonstrate a hand gesture recognition system and method thatuses signals from capacitive sensors embedded into the etee hand controller.The controller generates real-time signals from each of the wearer fivefingers. We use a machine learning technique to analyse the time series signalsand identify three features that can represent 5 fingers within 500 ms. Theanalysis is composed of a two stage training strategy, including dimensionreduction through principal component analysis and classification with Knearest neighbour. Remarkably, we found that this combination showed a level ofperformance which was comparable to more advanced methods such as supervisedvariational autoencoder. The base system can also be equipped with thecapability to learn from occasional errors by providing it with an additionaladaptive error correction mechanism. The results showed that the errorcorrector improve the classification performance in the base system withoutcompromising its performance. The system requires no more than 1 ms ofcomputing time per input sample, and is smaller than deep neural networks,demonstrating the feasibility of agile gesture recognition systems based onthis technology.</description><author>Ying Liu, Liucheng Guo, Valeri A. Makarov, Yuxiang Huang, Alexander Gorban, Evgeny Mirkes, Ivan Y. Tyukin</author><pubDate>Fri, 12 May 2023 18:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07624v1</guid></item><item><title>PALR: Personalization Aware LLMs for Recommendation</title><link>http://arxiv.org/abs/2305.07622v1</link><description>Large language models (LLMs) have recently received significant attention fortheir exceptional capabilities. Despite extensive efforts in developinggeneral-purpose LLMs that can be utilized in various natural languageprocessing (NLP) tasks, there has been less research exploring their potentialin recommender systems. In this paper, we propose a novel framework, namedPALR, which aiming to combine user history behaviors (such as clicks,purchases, ratings, etc.) with LLMs to generate user preferred items.Specifically, we first use user/item interactions as guidance for candidateretrieval. Then we adopt a LLM-based ranking model to generate recommendeditems. Unlike existing approaches that typically adopt general-purpose LLMs forzero/few-shot recommendation testing or training on small-sized language models(with less than 1 billion parameters), which cannot fully elicit LLMs'reasoning abilities and leverage rich item side parametric knowledge, wefine-tune a 7 billion parameters LLM for the ranking purpose. This model takesretrieval candidates in natural language format as input, with instructionwhich explicitly asking to select results from input candidates duringinference. Our experimental results demonstrate that our solution outperformsstate-of-the-art models on various sequential recommendation tasks.</description><author>Zheng Chen</author><pubDate>Fri, 12 May 2023 18:21:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07622v1</guid></item><item><title>Uncertainty Estimation for Deep Learning Image Reconstruction using a Local Lipschitz Metric</title><link>http://arxiv.org/abs/2305.07618v1</link><description>The use of deep learning approaches for image reconstruction is ofcontemporary interest in radiology, especially for approaches that solveinverse problems associated with imaging. In deployment, these models may beexposed to input distributions that are widely shifted from training data, duein part to data biases or drifts. We propose a metric based on local Lipschitzdetermined from a single trained model that can be used to estimate the modeluncertainty for image reconstructions. We demonstrate a monotonic relationshipbetween the local Lipschitz value and Mean Absolute Error and show that thismethod can be used to provide a threshold that determines whether a given DLreconstruction approach was well suited to the task. Our uncertainty estimationmethod can be used to identify out-of-distribution test samples, relateinformation regarding epistemic uncertainties, and guide proper dataaugmentation. Quantifying uncertainty of learned reconstruction approaches isespecially pertinent to the medical domain where reconstructed images mustremain diagnostically accurate.</description><author>Danyal F. Bhutto, Bo Zhu, Jeremiah Z. Liu, Neha Koonjoo, Bruce R. Rosen, Matthew S. Rosen</author><pubDate>Fri, 12 May 2023 18:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07618v1</guid></item><item><title>Neural Étendue Expander for Ultra-Wide-Angle High-Fidelity Holographic Display</title><link>http://arxiv.org/abs/2109.08123v2</link><description>Holographic displays can generate light fields by dynamically modulating thewavefront of a coherent beam of light using a spatial light modulator,promising rich virtual and augmented reality applications. However, the limitedspatial resolution of existing dynamic spatial light modulators imposes a tightbound on the diffraction angle. As a result, modern holographic displayspossess low \'{e}tendue, which is the product of the display area and themaximum solid angle of diffracted light. The low \'{e}tendue forces a sacrificeof either the field of view (FOV) or the display size. In this work, we liftthis limitation by presenting neural \'{e}tendue expanders. This new breed ofoptical elements, which is learned from a natural image dataset, enables higherdiffraction angles for ultra-wide FOV while maintaining both a compact formfactor and the fidelity of displayed contents to human viewers. With neural\'{e}tendue expanders, we achieve 64$\times$ \'{e}tendue expansion of naturalimages with reconstruction quality (measured in PSNR) over 29 dB onretinal-resolution images. As a result, the proposed approach with expansionfactor 64$\times$ enables high-fidelity ultra-wide-angle holographic projectionof natural images using an 8K-pixel SLM, resulting in 126$^\circ$ FOV and an18.5 mm eyebox size, covering more than 85% of the human FOV.</description><author>Ethan Tseng, Seung-Hwan Baek, Grace Kuo, Nathan Matsuda, Andrew Maimone, Praneeth Chakravarthula, Qiang Fu, Wolfgang Heidrich, Douglas Lanman, Felix Heide</author><pubDate>Fri, 12 May 2023 18:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.08123v2</guid></item><item><title>Scalable Coupling of Deep Learning with Logical Reasoning</title><link>http://arxiv.org/abs/2305.07617v1</link><description>In the ongoing quest for hybridizing discrete reasoning with neural nets,there is an increasing interest in neural architectures that can learn how tosolve discrete reasoning or optimization problems from natural inputs. In thispaper, we introduce a scalable neural architecture and loss function dedicatedto learning the constraints and criteria of NP-hard reasoning problemsexpressed as discrete Graphical Models. Our loss function solves one of themain limitations of Besag's pseudo-loglikelihood, enabling learning of highenergies. We empirically show it is able to efficiently learn how to solveNP-hard reasoning problems from natural inputs as the symbolic, visual ormany-solutions Sudoku problems as well as the energy optimization formulationof the protein design problem, providing data efficiency, interpretability, and\textit{a posteriori} control over predictions.</description><author>Marianne Defresne, Sophie Barbe, Thomas Schiex</author><pubDate>Fri, 12 May 2023 18:09:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07617v1</guid></item><item><title>What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization</title><link>http://arxiv.org/abs/2305.07615v1</link><description>Summarization models often generate text that is poorly calibrated to qualitymetrics because they are trained to maximize the likelihood of a singlereference (MLE). To address this, recent work has added a calibration step,which exposes a model to its own ranked outputs to improve relevance or, in aseparate line of work, contrasts positive and negative sets to improvefaithfulness. While effective, much of this work has focused on how to generateand optimize these sets. Less is known about why one setup is more effectivethan another. In this work, we uncover the underlying characteristics ofeffective sets. For each training instance, we form a large, diverse pool ofcandidates and systematically vary the subsets used for calibrationfine-tuning. Each selection strategy targets distinct aspects of the sets, suchas lexical diversity or the size of the gap between positive and negatives. Onthree diverse scientific long-form summarization datasets (spanning biomedical,clinical, and chemical domains), we find, among others, that faithfulnesscalibration is optimal when the negative sets are extractive and more likely tobe generated, whereas for relevance calibration, the metric margin betweencandidates should be maximized and surprise--the disagreement between model andmetric defined candidate rankings--minimized. Code to create, select, andoptimize calibration sets is available athttps://github.com/griff4692/calibrating-summaries</description><author>Griffin Adams, Bichlien H Nguyen, Jake Smith, Yingce Xia, Shufang Xie, Anna Ostropolets, Budhaditya Deb, Yuan-Jyue Chen, Tristan Naumann, Noémie Elhadad</author><pubDate>Fri, 12 May 2023 18:08:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07615v1</guid></item><item><title>Linear Classifiers Under Infinite Imbalance</title><link>http://arxiv.org/abs/2106.05797v2</link><description>We study the behavior of linear discriminant functions for binaryclassification in the infinite-imbalance limit, where the sample size of oneclass grows without bound while the sample size of the other remains fixed. Thecoefficients of the classifier minimize an empirical loss specified through aweight function. We show that for a broad class of weight functions, theintercept diverges but the rest of the coefficient vector has a finite almostsure limit under infinite imbalance, extending prior work on logisticregression. The limit depends on the left-tail growth rate of the weightfunction, for which we distinguish two cases: subexponential and exponential.The limiting coefficient vectors reflect robustness or conservatism propertiesin the sense that they optimize against certain worst-case alternatives. In thesubexponential case, the limit is equivalent to an implicit choice ofupsampling distribution for the minority class. We apply these ideas in acredit risk setting, with particular emphasis on performance in thehigh-sensitivity and high-specificity regions.</description><author>Paul Glasserman, Mike Li</author><pubDate>Fri, 12 May 2023 18:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.05797v2</guid></item><item><title>NevIR: Negation in Neural Information Retrieval</title><link>http://arxiv.org/abs/2305.07614v1</link><description>Negation is a common everyday phenomena and has been a consistent area ofweakness for language models (LMs). Although the Information Retrieval (IR)community has adopted LMs as the backbone of modern IR architectures, there hasbeen little to no research in understanding how negation impacts neural IR. Wetherefore construct a straightforward benchmark on this theme: asking IR modelsto rank two documents that differ only by negation. We show that the resultsvary widely according to the type of IR architecture: cross-encoders performbest, followed by late-interaction models, and in last place are bi-encoder andsparse neural architectures. We find that most current information retrievalmodels do not consider negation, performing similarly or worse than randomlyranking. We show that although the obvious approach of continued fine-tuning ona dataset of contrastive documents containing negations increases performance(as does model size), there is still a large gap between machine and humanperformance.</description><author>Orion Weller, Dawn Lawrie, Benjamin Van Durme</author><pubDate>Fri, 12 May 2023 18:05:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07614v1</guid></item><item><title>Sparse Bayesian Lasso via a Variable-Coefficient $\ell_1$ Penalty</title><link>http://arxiv.org/abs/2211.05089v3</link><description>Modern statistical learning algorithms are capable of amazing flexibility,but struggle with interpretability. One possible solution is sparsity: makinginference such that many of the parameters are estimated as being identically0, which may be imposed through the use of nonsmooth penalties such as the$\ell_1$ penalty. However, the $\ell_1$ penalty introduces significant biaswhen high sparsity is desired. In this article, we retain the $\ell_1$ penalty,but define learnable penalty weights $\lambda_p$ endowed with hyperpriors. Westart the article by investigating the optimization problem this poses,developing a proximal operator associated with the $\ell_1$ norm. We then studythe theoretical properties of this variable-coefficient $\ell_1$ penalty in thecontext of penalized likelihood. Next, we investigate application of thispenalty to Variational Bayes, developing a model we call the Sparse BayesianLasso which allows for behavior qualitatively like Lasso regression to beapplied to arbitrary variational models. In simulation studies, this gives usthe Uncertainty Quantification and low bias properties of simulation-basedapproaches with an order of magnitude less computation. Finally, we apply ourmethodology to a Bayesian lagged spatiotemporal regression model of internaldisplacement that occurred during the Iraqi Civil War of 2013-2017.</description><author>Nathan Wycoff, Ali Arab, Katharine M. Donato, Lisa O. Singh</author><pubDate>Fri, 12 May 2023 18:04:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05089v3</guid></item><item><title>Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training</title><link>http://arxiv.org/abs/2305.07613v1</link><description>Training Generative adversarial networks (GANs) stably is a challenging task.The generator in GANs transform noise vectors, typically Gaussian distributed,into realistic data such as images. In this paper, we propose a novel approachfor training GANs with images as inputs, but without enforcing any pairwiseconstraints. The intuition is that images are more structured than noise, whichthe generator can leverage to learn a more robust transformation. The processcan be made efficient by identifying closely related datasets, or a ``friendlyneighborhood'' of the target distribution, inspiring the moniker, Spider GAN.To define friendly neighborhoods leveraging proximity between datasets, wepropose a new measure called the signed inception distance (SID), inspired bythe polyharmonic kernel. We show that the Spider GAN formulation results infaster convergence, as the generator can discover correspondence even betweenseemingly unrelated datasets, for instance, between Tiny-ImageNet and CelebAfaces. Further, we demonstrate cascading Spider GAN, where the outputdistribution from a pre-trained GAN generator is used as the input to thesubsequent network. Effectively, transporting one distribution to another in acascaded fashion until the target is learnt -- a new flavor of transferlearning. We demonstrate the efficacy of the Spider approach on DCGAN,conditional GAN, PGGAN, StyleGAN2 and StyleGAN3. The proposed approach achievesstate-of-the-art Frechet inception distance (FID) values, with one-fifth of thetraining iterations, in comparison to their baseline counterparts onhigh-resolution small datasets such as MetFaces, Ukiyo-E Faces and AFHQ-Cats.</description><author>Siddarth Asokan, Chandra Sekhar Seelamantula</author><pubDate>Fri, 12 May 2023 18:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07613v1</guid></item><item><title>Lower Bounds and Accelerated Algorithms in Distributed Stochastic Optimization with Communication Compression</title><link>http://arxiv.org/abs/2305.07612v1</link><description>Communication compression is an essential strategy for alleviatingcommunication overhead by reducing the volume of information exchanged betweencomputing nodes in large-scale distributed stochastic optimization. Althoughnumerous algorithms with convergence guarantees have been obtained, the optimalperformance limit under communication compression remains unclear. In this paper, we investigate the performance limit of distributed stochasticoptimization algorithms employing communication compression. We focus on twomain types of compressors, unbiased and contractive, and address thebest-possible convergence rates one can obtain with these compressors. Weestablish the lower bounds for the convergence rates of distributed stochasticoptimization in six different settings, combining strongly-convex,generally-convex, or non-convex functions with unbiased or contractivecompressor types. To bridge the gap between lower bounds and existingalgorithms' rates, we propose NEOLITHIC, a nearly optimal algorithm withcompression that achieves the established lower bounds up to logarithmicfactors under mild conditions. Extensive experimental results support ourtheoretical findings. This work provides insights into the theoreticallimitations of existing compressors and motivates further research intofundamentally new compressor properties.</description><author>Yutong He, Xinmeng Huang, Yiming Chen, Wotao Yin, Kun Yuan</author><pubDate>Fri, 12 May 2023 18:02:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07612v1</guid></item><item><title>Should Bank Stress Tests Be Fair?</title><link>http://arxiv.org/abs/2207.13319v2</link><description>Regulatory stress tests have become one of the main tools for setting capitalrequirements at the largest U.S. banks. The Federal Reserve uses confidentialmodels to evaluate bank-specific outcomes for bank-specific portfolios inshared stress scenarios. As a matter of policy, the same models are used forall banks, despite considerable heterogeneity across institutions; individualbanks have contended that some models are not suited to their businesses.Motivated by this debate, we ask, what is a fair aggregation of individuallytailored models into a common model? We argue that simply pooling data acrossbanks treats banks equally but is subject to two deficiencies: it may distortthe impact of legitimate portfolio features, and it is vulnerable to implicitmisdirection of legitimate information to infer bank identity. We comparevarious notions of regression fairness to address these deficiencies,considering both forecast accuracy and equal treatment. In the setting oflinear models, we argue for estimating and then discarding centered bank fixedeffects as preferable to simply ignoring differences across banks. We presentevidence that the overall impact can be material. We also discuss extensions tononlinear models.</description><author>Paul Glasserman, Mike Li</author><pubDate>Fri, 12 May 2023 18:02:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.13319v2</guid></item><item><title>Multimodal Sentiment Analysis: A Survey</title><link>http://arxiv.org/abs/2305.07611v1</link><description>Multimodal sentiment analysis has become an important research area in thefield of artificial intelligence. With the latest advances in deep learning,this technology has reached new heights. It has great potential for bothapplication and research, making it a popular research topic. This reviewprovides an overview of the definition, background, and development ofmultimodal sentiment analysis. It also covers recent datasets and advancedmodels, emphasizing the challenges and future prospects of this technology.Finally, it looks ahead to future research directions. It should be noted thatthis review provides constructive suggestions for promising research directionsand building better performing multimodal sentiment analysis models, which canhelp researchers in this field.</description><author>Songning Lai, Haoxuan Xu, Xifeng Hu, Zhaoxia Ren, Zhi Liu</author><pubDate>Fri, 12 May 2023 17:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07611v1</guid></item><item><title>Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation</title><link>http://arxiv.org/abs/2305.07609v1</link><description>The remarkable achievements of Large Language Models (LLMs) have led to theemergence of a novel recommendation paradigm -- Recommendation via LLM(RecLLM). Nevertheless, it is important to note that LLMs may contain socialprejudices, and therefore, the fairness of recommendations made by RecLLMrequires further investigation. To avoid the potential risks of RecLLM, it isimperative to evaluate the fairness of RecLLM with respect to various sensitiveattributes on the user side. Due to the differences between the RecLLM paradigmand the traditional recommendation paradigm, it is problematic to directly usethe fairness benchmark of traditional recommendation. To address the dilemma,we propose a novel benchmark called Fairness of Recommendation via LLM(FaiRLLM). This benchmark comprises carefully crafted metrics and a datasetthat accounts for eight sensitive attributes1 in two recommendation scenarios:music and movies. By utilizing our FaiRLLM benchmark, we conducted anevaluation of ChatGPT and discovered that it still exhibits unfairness to somesensitive attributes when generating recommendations. Our code and dataset canbe found at https://github.com/jizhi-zhang/FaiRLLM.</description><author>Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, Xiangnan He</author><pubDate>Fri, 12 May 2023 17:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07609v1</guid></item><item><title>Generative AI: Implications and Applications for Education</title><link>http://arxiv.org/abs/2305.07605v1</link><description>The launch of ChatGPT in November 2022 precipitated a panic among someeducators while prompting qualified enthusiasm from others. Under the umbrellaterm Generative AI, ChatGPT is an example of a range of technologies for thedelivery of computer-generated text, image, and other digitized media. Thispaper examines the implications for education of one generative AI technology,chatbots responding from large language models, or C-LLM. It reports on anapplication of a C-LLM to AI review and assessment of complex student work. Ina concluding discussion, the paper explores the intrinsic limits of generativeAI, bound as it is to language corpora and their textual representation throughbinary notation. Within these limits, we suggest the range of emerging andpotential applications of Generative AI in education.</description><author>Anastasia Olga, Tzirides, Akash Saini, Gabriela Zapata, Duane Searsmith, Bill Cope, Mary Kalantzis, Vania Castro, Theodora Kourkoulou, John Jones, Rodrigo Abrantes da Silva, Jen Whiting, Nikoleta Polyxeni Kastani</author><pubDate>Fri, 12 May 2023 17:52:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07605v1</guid></item><item><title>ViT Unified: Joint Fingerprint Recognition and Presentation Attack Detection</title><link>http://arxiv.org/abs/2305.07602v1</link><description>A secure fingerprint recognition system must contain both a presentationattack (i.e., spoof) detection and recognition module in order to protect usersagainst unwanted access by malicious users. Traditionally, these tasks would becarried out by two independent systems; however, recent studies havedemonstrated the potential to have one unified system architecture in order toreduce the computational burdens on the system, while maintaining highaccuracy. In this work, we leverage a vision transformer architecture for jointspoof detection and matching and report competitive results withstate-of-the-art (SOTA) models for both a sequential system (two ViT modelsoperating independently) and a unified architecture (a single ViT model forboth tasks). ViT models are particularly well suited for this task as the ViT'sglobal embedding encodes features useful for recognition, whereas theindividual, local embeddings are useful for spoof detection. We demonstrate thecapability of our unified model to achieve an average integrated matching (IM)accuracy of 98.87% across LivDet 2013 and 2015 CrossMatch sensors. This iscomparable to IM accuracy of 98.95% of our sequential dual-ViT system, but with~50% of the parameters and ~58% of the latency.</description><author>Steven A. Grosz, Kanishka P. Wijewardena, Anil K. Jain</author><pubDate>Fri, 12 May 2023 17:51:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07602v1</guid></item><item><title>Hierarchical Bayesian Modelling for Knowledge Transfer Across Engineering Fleets via Multitask Learning</title><link>http://arxiv.org/abs/2204.12404v4</link><description>A population-level analysis is proposed to address data sparsity whenbuilding predictive models for engineering infrastructure. Utilising aninterpretable hierarchical Bayesian approach and operational fleet data, domainexpertise is naturally encoded (and appropriately shared) between differentsub-groups, representing (i) use-type, (ii) component, or (iii) operatingcondition. Specifically, domain expertise is exploited to constrain the modelvia assumptions (and prior distributions) allowing the methodology toautomatically share information between similar assets, improving the survivalanalysis of a truck fleet and power prediction in a wind farm. In each assetmanagement example, a set of correlated functions is learnt over the fleet, ina combined inference, to learn a population model. Parameter estimation isimproved when sub-fleets share correlated information at different levels ofthe hierarchy. In turn, groups with incomplete data automatically borrowstatistical strength from those that are data-rich. The statisticalcorrelations enable knowledge transfer via Bayesian transfer learning, and thecorrelations can be inspected to inform which assets share information forwhich effect (i.e. parameter). Both case studies demonstrate the wideapplicability to practical infrastructure monitoring, since the approach isnaturally adapted between interpretable fleet models of different in situexamples.</description><author>L. A. Bull, D. Di Francesco, M. Dhada, O. Steinert, T. Lindgren, A. K. Parlikad, A. B. Duncan, M. Girolami</author><pubDate>Fri, 12 May 2023 17:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.12404v4</guid></item><item><title>RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for Oriented Object Detection</title><link>http://arxiv.org/abs/2305.07598v1</link><description>With the publication of DINO, a variant of the Detection Transformer (DETR),Detection Transformers are breaking the record in the object detectionbenchmark with the merits of their end-to-end design and scalability. However,the extension of DETR to oriented object detection has not been thoroughlystudied although more benefits from its end-to-end architecture are expectedsuch as removing NMS and anchor-related costs. In this paper, we propose afirst strong DINO-based baseline for oriented object detection. We found thatstraightforward employment of DETRs for oriented object detection does notguarantee non-duplicate prediction, and propose a simple cost to mitigate this.Furthermore, we introduce a novel denoising strategy that uses Hungarianmatching to filter redundant noised queries and query alignment to preservematching consistency between Transformer decoder layers. Our proposed modeloutperforms previous rotated DETRs and other counterparts, achievingstate-of-the-art performance in DOTA-v1.0/v1.5/v2.0, and DIOR-R benchmarks.</description><author>Hakjin Lee, Minki Song, Jamyoung Koo, Junghoon Seo</author><pubDate>Fri, 12 May 2023 17:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07598v1</guid></item><item><title>Opti Code Pro: A Heuristic Search-based Approach to Code Refactoring</title><link>http://arxiv.org/abs/2305.07594v1</link><description>This paper presents an approach that evaluates best-first search methods tocode refactoring. The motivation for code refactoring could be to improve thedesign, structure, or implementation of an existing program without changingits functionality. To solve a very specific problem of coupling and cohesion,we propose using heuristic search-based techniques on an approximation of thefull code refactoring problem, to guide the refactoring process towardsolutions that have high cohesion and low coupling. We evaluated our approachby providing demonstrative examples of the effectiveness of this approach onrandom state problems and created a tool to implement the algorithm on Javaprojects.</description><author>Sourena Khanzadeh, Samad Alias Nyein Chan, Richard Valenzano, Manar Alalfi</author><pubDate>Fri, 12 May 2023 17:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07594v1</guid></item><item><title>Knowledge distillation with Segment Anything (SAM) model for Planetary Geological Mapping</title><link>http://arxiv.org/abs/2305.07586v1</link><description>Planetary science research involves analysing vast amounts of remote sensingdata, which are often costly and time-consuming to annotate and process. One ofthe essential tasks in this field is geological mapping, which requiresidentifying and outlining regions of interest in planetary images, includinggeological features and landforms. However, manually labelling these images isa complex and challenging task that requires significant domain expertise andeffort. To expedite this endeavour, we propose the use of knowledgedistillation using the recently introduced cutting-edge Segment Anything (SAM)model. We demonstrate the effectiveness of this prompt-based foundation modelfor rapid annotation and quick adaptability to a prime use case of mappingplanetary skylights. Our work reveals that with a small set of annotationsobtained with the right prompts from the model and subsequently training aspecialised domain decoder, we can achieve satisfactory semantic segmentationon this task. Key results indicate that the use of knowledge distillation cansignificantly reduce the effort required by domain experts for manualannotation and improve the efficiency of image segmentation tasks. Thisapproach has the potential to accelerate extra-terrestrial discovery byautomatically detecting and segmenting Martian landforms.</description><author>Sahib Julka, Michael Granitzer</author><pubDate>Fri, 12 May 2023 17:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07586v1</guid></item><item><title>MoMo: Momentum Models for Adaptive Learning Rates</title><link>http://arxiv.org/abs/2305.07583v1</link><description>We present new adaptive learning rates that can be used with any momentummethod. To showcase our new learning rates we develop MoMo and MoMo-Adam, whichare SGD with momentum (SGDM) and Adam together with our new adaptive learningrates. Our MoMo methods are motivated through model-based stochasticoptimization, wherein we use momentum estimates of the batch losses andgradients sampled at each iteration to build a model of the loss function. Ourmodel also makes use of any known lower bound of the loss function by usingtruncation. Indeed most losses are bounded below by zero. We then approximatelyminimize this model at each iteration to compute the next step. For losses withunknown lower bounds, we develop new on-the-fly estimates of the lower boundthat we use in our model. Numerical experiments show that our MoMo methodsimprove over SGDM and Adam in terms of accuracy and robustness tohyperparameter tuning for training image classifiers on MNIST, CIFAR10,CIFAR100, Imagenet32, DLRM on the Criteo dataset, and a transformer model onthe translation task IWSLT14.</description><author>Fabian Schaipp, Ruben Ohana, Michael Eickenberg, Aaron Defazio, Robert M. Gower</author><pubDate>Fri, 12 May 2023 17:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07583v1</guid></item><item><title>GAMIVAL: Video Quality Prediction on Mobile Cloud Gaming Content</title><link>http://arxiv.org/abs/2305.02422v2</link><description>The mobile cloud gaming industry has been rapidly growing over the lastdecade. When streaming gaming videos are transmitted to customers' clientdevices from cloud servers, algorithms that can monitor distorted video qualitywithout having any reference video available are desirable tools. However,creating No-Reference Video Quality Assessment (NR VQA) models that canaccurately predict the quality of streaming gaming videos rendered by computergraphics engines is a challenging problem, since gaming content generallydiffers statistically from naturalistic videos, often lacks detail, andcontains many smooth regions. Until recently, the problem has been furthercomplicated by the lack of adequate subjective quality databases of mobilegaming content. We have created a new gaming-specific NR VQA model called theGaming Video Quality Evaluator (GAMIVAL), which combines and leverages theadvantages of spatial and temporal gaming distorted scene statistics models, aneural noise model, and deep semantic features. Using a support vectorregression (SVR) as a regressor, GAMIVAL achieves superior performance on thenew LIVE-Meta Mobile Cloud Gaming (LIVE-Meta MCG) video quality database.</description><author>Yu-Chih Chen, Avinab Saha, Chase Davis, Bo Qiu, Xiaoming Wang, Rahul Gowda, Ioannis Katsavounidis, Alan C. Bovik</author><pubDate>Fri, 12 May 2023 17:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02422v2</guid></item><item><title>AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners</title><link>http://arxiv.org/abs/2302.01877v2</link><description>Diffusion models have demonstrated their powerful generative capability inmany tasks, with great potential to serve as a paradigm for offlinereinforcement learning. However, the quality of the diffusion model is limitedby the insufficient diversity of training data, which hinders the performanceof planning and the generalizability to new tasks. This paper introducesAdaptDiffuser, an evolutionary planning method with diffusion that canself-evolve to improve the diffusion model hence a better planner, not only forseen tasks but can also adapt to unseen tasks. AdaptDiffuser enables thegeneration of rich synthetic expert data for goal-conditioned tasks usingguidance from reward gradients. It then selects high-quality data via adiscriminator to finetune the diffusion model, which improves thegeneralization ability to unseen tasks. Empirical experiments on two benchmarkenvironments and two carefully designed unseen tasks in KUKA industrial robotarm and Maze2D environments demonstrate the effectiveness of AdaptDiffuser. Forexample, AdaptDiffuser not only outperforms the previous art Diffuser by 20.8%on Maze2D and 7.5% on MuJoCo locomotion, but also adapts better to new tasks,e.g., KUKA pick-and-place, by 27.9% without requiring additional expert data.More visualization results and demo videos could be found on our project page.</description><author>Zhixuan Liang, Yao Mu, Mingyu Ding, Fei Ni, Masayoshi Tomizuka, Ping Luo</author><pubDate>Fri, 12 May 2023 17:23:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01877v2</guid></item><item><title>Fisher Information Embedding for Node and Graph Learning</title><link>http://arxiv.org/abs/2305.07580v1</link><description>Attention-based graph neural networks (GNNs), such as graph attentionnetworks (GATs), have become popular neural architectures for processinggraph-structured data and learning node embeddings. Despite their empiricalsuccess, these models rely on labeled data and the theoretical properties ofthese models have yet to be fully understood. In this work, we propose a novelattention-based node embedding framework for graphs. Our framework builds upona hierarchical kernel for multisets of subgraphs around nodes (e.g.neighborhoods) and each kernel leverages the geometry of a smooth statisticalmanifold to compare pairs of multisets, by "projecting" the multisets onto themanifold. By explicitly computing node embeddings with a manifold of Gaussianmixtures, our method leads to a new attention mechanism for neighborhoodaggregation. We provide theoretical insights into genralizability andexpressivity of our embeddings, contributing to a deeper understanding ofattention-based GNNs. We propose efficient unsupervised and supervised methodsfor learning the embeddings, with the unsupervised method not requiring anylabeled data. Through experiments on several node classification benchmarks, wedemonstrate that our proposed method outperforms existing attention-based graphmodels like GATs. Our code is available athttps://github.com/BorgwardtLab/fisher_information_embedding.</description><author>Dexiong Chen, Paolo Pellizzoni, Karsten Borgwardt</author><pubDate>Fri, 12 May 2023 17:15:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07580v1</guid></item><item><title>A Comprehensive Survey on Model Quantization for Deep Neural Networks</title><link>http://arxiv.org/abs/2205.07877v2</link><description>Recent advances in machine learning by deep neural networks are significant.But using these networks has been accompanied by a huge number of parametersfor storage and computations that leads to an increase in the hardware cost andposing challenges. Therefore, compression approaches have been proposed todesign efficient accelerators. One important approach for deep neural networkcompression is quantization that full-precision values are stored in lowbit-width. In this way, in addition to memory saving, the operations will bereplaced by simple ones with low cost. Many methods are suggested for DNNsQuantization in recent years, because of flexibility and influence in designingefficient hardware. Therefore, an integrated report is essential for betterunderstanding, analysis, and comparison. In this paper, we provide acomprehensive survey. We describe the quantization concepts and categorize themethods from different perspectives. We discuss using the scale factor to matchthe quantization levels with the distribution of the full-precision values anddescribe the clustering-based methods. For the first time, we review thetraining of a quantized deep neural network and using Straight-ThroughEstimator comprehensively. Also, we describe the simplicity of operations inquantized deep convolutional neural networks and explain the sensitivity of thedifferent layers in quantization. Finally, we discuss the evaluation of thequantization methods and compare the accuracy of previous methods with variousbit-width for weights and activations on CIFAR-10 and the large-scale dataset,ImageNet.</description><author>Babak Rokh, Ali Azarpeyvand, Alireza Khanteymoori</author><pubDate>Fri, 12 May 2023 17:08:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.07877v2</guid></item><item><title>Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts</title><link>http://arxiv.org/abs/2305.07572v1</link><description>Originally introduced as a neural network for ensemble learning, mixture ofexperts (MoE) has recently become a fundamental building block of highlysuccessful modern deep neural networks for heterogeneous data analysis inseveral applications, including those in machine learning, statistics,bioinformatics, economics, and medicine. Despite its popularity in practice, asatisfactory level of understanding of the convergence behavior ofGaussian-gated MoE parameter estimation is far from complete. The underlyingreason for this challenge is the inclusion of covariates in the Gaussian gatingand expert networks, which leads to their intrinsically complex interactionsvia partial differential equations with respect to their parameters. We addressthese issues by designing novel Voronoi loss functions to accurately captureheterogeneity in the maximum likelihood estimator (MLE) for resolving parameterestimation in these models. Our results reveal distinct behaviors of the MLEunder two settings: the first setting is when all the location parameters inthe Gaussian gating are non-zeros while the second setting is when there existsat least one zero-valued location parameter. Notably, these behaviors can becharacterized by the solvability of two different systems of polynomialequations. Finally, we conduct a simulation study to verify our theoreticalresults.</description><author>Huy Nguyen, TrungTin Nguyen, Khai Nguyen, Nhat Ho</author><pubDate>Fri, 12 May 2023 17:02:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07572v1</guid></item><item><title>GPS++: Reviving the Art of Message Passing for Molecular Property Prediction</title><link>http://arxiv.org/abs/2302.02947v2</link><description>We present GPS++, a hybrid Message Passing Neural Network / Graph Transformermodel for molecular property prediction. Our model integrates a well-tunedlocal message passing component and biased global attention with other keyideas from prior literature to achieve state-of-the-art results on large-scalemolecular dataset PCQM4Mv2. Through a thorough ablation study we highlight theimpact of individual components and find that nearly all of the model'sperformance can be maintained without any use of global self-attention, showingthat message passing is still a competitive approach for 3D molecular propertyprediction despite the recent dominance of graph transformers. We also findthat our approach is significantly more accurate than prior art when 3Dpositional information is not available.</description><author>Dominic Masters, Josef Dean, Kerstin Klaser, Zhiyi Li, Sam Maddrell-Mander, Adam Sanders, Hatem Helal, Deniz Beker, Andrew Fitzgibbon, Shenyang Huang, Ladislav Rampášek, Dominique Beaini</author><pubDate>Fri, 12 May 2023 16:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02947v2</guid></item><item><title>Overlooked factors in concept-based explanations: Dataset choice, concept learnability, and human capability</title><link>http://arxiv.org/abs/2207.09615v2</link><description>Concept-based interpretability methods aim to explain deep neural networkmodel predictions using a predefined set of semantic concepts. These methodsevaluate a trained model on a new, "probe" dataset and correlate modelpredictions with the visual concepts labeled in that dataset. Despite theirpopularity, they suffer from limitations that are not well-understood andarticulated by the literature. In this work, we analyze three commonlyoverlooked factors in concept-based explanations. First, the choice of theprobe dataset has a profound impact on the generated explanations. Our analysisreveals that different probe datasets may lead to very different explanations,and suggests that the explanations are not generalizable outside the probedataset. Second, we find that concepts in the probe dataset are often lesssalient and harder to learn than the classes they claim to explain, callinginto question the correctness of the explanations. We argue that only visuallysalient concepts should be used in concept-based explanations. Finally, whileexisting methods use hundreds or even thousands of concepts, our human studiesreveal a much stricter upper bound of 32 concepts or less, beyond which theexplanations are much less practically useful. We make suggestions for futuredevelopment and analysis of concept-based interpretability methods. Code forour analysis and user interface can be found at\url{https://github.com/princetonvisualai/OverlookedFactors}</description><author>Vikram V. Ramaswamy, Sunnie S. Y. Kim, Ruth Fong, Olga Russakovsky</author><pubDate>Fri, 12 May 2023 16:48:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09615v2</guid></item><item><title>A Memory Model for Question Answering from Streaming Data Supported by Rehearsal and Anticipation of Coreference Information</title><link>http://arxiv.org/abs/2305.07565v1</link><description>Existing question answering methods often assume that the input content(e.g., documents or videos) is always accessible to solve the task.Alternatively, memory networks were introduced to mimic the human process ofincremental comprehension and compression of the information in afixed-capacity memory. However, these models only learn how to maintain memoryby backpropagating errors in the answers through the entire network. Instead,it has been suggested that humans have effective mechanisms to boost theirmemorization capacities, such as rehearsal and anticipation. Drawinginspiration from these, we propose a memory model that performs rehearsal andanticipation while processing inputs to memorize important information forsolving question answering tasks from streaming data. The proposed mechanismsare applied self-supervised during training through masked modeling tasksfocused on coreference information. We validate our model on a short-sequence(bAbI) dataset as well as large-sequence textual (NarrativeQA) and video(ActivityNet-QA) question answering datasets, where it achieves substantialimprovements over previous memory network approaches. Furthermore, our ablationstudy confirms the proposed mechanisms' importance for memory models.</description><author>Vladimir Araujo, Alvaro Soto, Marie-Francine Moens</author><pubDate>Fri, 12 May 2023 16:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07565v1</guid></item><item><title>Measuring Progress in Fine-grained Vision-and-Language Understanding</title><link>http://arxiv.org/abs/2305.07558v1</link><description>While pretraining on large-scale image-text data from the Web has facilitatedrapid progress on many vision-and-language (V&amp;L) tasks, recent work hasdemonstrated that pretrained models lack "fine-grained" understanding, such asthe ability to recognise relationships, verbs, and numbers in images. This hasresulted in an increased interest in the community to either develop newbenchmarks or models for such capabilities. To better understand and quantifyprogress in this direction, we investigate four competitive V&amp;L models on fourfine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al.,2022) consistently outperforms other baselines, and that modelling innovationscan impact performance more than scaling Web data, which even degradesperformance sometimes. Through a deeper investigation of X-VLM, we highlightthe importance of both novel losses and rich data sources for learningfine-grained skills. Finally, we inspect training dynamics, and discover thatfor some tasks, performance peaks early in training or significantlyfluctuates, never converging.</description><author>Emanuele Bugliarello, Laurent Sartran, Aishwarya Agrawal, Lisa Anne Hendricks, Aida Nematzadeh</author><pubDate>Fri, 12 May 2023 16:34:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07558v1</guid></item><item><title>Dish detection in food platters: A framework for automated diet logging and nutrition management</title><link>http://arxiv.org/abs/2305.07552v1</link><description>Diet is central to the epidemic of lifestyle disorders. Accurate andeffortless diet logging is one of the significant bottlenecks for effectivediet management and calorie restriction. Dish detection from food platters is achallenging problem due to a visually complex food layout. We present anend-to-end computational framework for diet management, from data compilation,annotation, and state-of-the-art model identification to its mobile appimplementation. As a case study, we implement the framework in the context ofIndian food platters known for their complex presentation that poses achallenge for the automated detection of dishes. Starting with the 61 mostpopular Indian dishes, we identify the state-of-the-art model through acomparative analysis of deep-learning-based object detection architectures.Rooted in a meticulous compilation of 68,005 platter images with 134,814 manualdish annotations, we first compare ten architectures for multi-labelclassification to identify ResNet152 (mAP=84.51%) as the best model. YOLOv8x(mAP=87.70%) emerged as the best model architecture for dish detection amongthe eight deep-learning models implemented after a thorough performanceevaluation. By comparing with the state-of-the-art model for the IndianFood10dataset, we demonstrate the superior object detection performance of YOLOv8xfor this subset and establish Resnet152 as the best architecture formulti-label classification. The models thus trained on richly annotated datacan be extended to include dishes from across global cuisines. The proposedframework is demonstrated through a proof-of-concept mobile application withdiverse applications for diet logging, food recommendation systems, nutritionalinterventions, and mitigation of lifestyle disorders.</description><author>Mansi Goel, Shashank Dargar, Shounak Ghatak, Nidhi Verma, Pratik Chauhan, Anushka Gupta, Nikhila Vishnumolakala, Hareesh Amuru, Ekta Gambhir, Ronak Chhajed, Meenal Jain, Astha Jain, Samiksha Garg, Nitesh Narwade, Nikhilesh Verhwani, Abhuday Tiwari, Kirti Vashishtha, Ganesh Bagler</author><pubDate>Fri, 12 May 2023 16:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07552v1</guid></item><item><title>Understanding Automatic Differentiation Pitfalls</title><link>http://arxiv.org/abs/2305.07546v1</link><description>Automatic differentiation, also known as backpropagation, AD, autodiff, oralgorithmic differentiation, is a popular technique for computing derivativesof computer programs accurately and efficiently. Sometimes, however, thederivatives computed by AD could be interpreted as incorrect. These pitfallsoccur systematically across tools and approaches. In this paper we broadlycategorize problematic usages of AD and illustrate each category with examplessuch as chaos, time-averaged oscillations, discretizations, fixed-point loops,lookup tables, and linear solvers. We also review debugging techniques andtheir effectiveness in these situations. With this article we hope to helpreaders avoid unexpected behavior, detect problems more easily when they occur,and have more realistic expectations from AD tools.</description><author>Jan Hückelheim, Harshitha Menon, William Moses, Bruce Christianson, Paul Hovland, Laurent Hascoët</author><pubDate>Fri, 12 May 2023 16:17:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07546v1</guid></item><item><title>Bilaterally Slimmable Transformer for Elastic and Efficient Visual Question Answering</title><link>http://arxiv.org/abs/2203.12814v2</link><description>Recent advances in Transformer architectures [1] have brought remarkableimprovements to visual question answering (VQA). Nevertheless,Transformer-based VQA models are usually deep and wide to guarantee goodperformance, so they can only run on powerful GPU servers and cannot run oncapacity-restricted platforms such as mobile phones. Therefore, it is desirableto learn an elastic VQA model that supports adaptive pruning at runtime to meetthe efficiency constraints of different platforms. To this end, we present thebilaterally slimmable Transformer (BST), a general framework that can beseamlessly integrated into arbitrary Transformer-based VQA models to train asingle model once and obtain various slimmed submodels of different widths anddepths. To verify the effectiveness and generality of this method, we integratethe proposed BST framework with three typical Transformer-based VQA approaches,namely MCAN [2], UNITER [3], and CLIP-ViL [4], and conduct extensiveexperiments on two commonly-used benchmark datasets. In particular, one slimmedMCAN-BST submodel achieves comparable accuracy on VQA-v2, while being 0.38xsmaller in model size and having 0.27x fewer FLOPs than the reference MCANmodel. The smallest MCAN-BST submodel only has 9M parameters and 0.16G FLOPsduring inference, making it possible to deploy it on a mobile device with lessthan 60 ms latency.</description><author>Zhou Yu, Zitian Jin, Jun Yu, Mingliang Xu, Hongbo Wang, Jianping Fan</author><pubDate>Fri, 12 May 2023 16:15:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.12814v2</guid></item><item><title>Content-based jewellery item retrieval using the local region-based histograms</title><link>http://arxiv.org/abs/2305.07540v1</link><description>Jewellery item retrieval is regularly used to find what people want on onlinemarketplaces using a sample query reference image. Considering recentdevelopments, due to the simultaneous nature of various jewelry items, variousjewelry goods' occlusion in images or visual streams, as well as shapedeformation, content-based jewellery item retrieval (CBJIR) still haslimitations whenever it pertains to visual searching in the actual world. Thisarticle proposed a content-based jewellery item retrieval method using thelocal region-based histograms in HSV color space. Using five local regions, ournovel jewellery classification module extracts the specific feature vectorsfrom the query image. The jewellery classification module is also applied tothe jewellery database to extract feature vectors. Finally, the similarityscore is matched between the database and query features vectors to retrievethe jewellery items from the database. The proposed method performance istested on publicly available jewellery item retrieval datasets, i.e. ringFIRand Fashion Product Images dataset. The experimental results demonstrate thedominance of the proposed method over the baseline methods for retrievingdesired jewellery products.</description><author>Amin Muhammad Shoib, Summaira Jabeen, Changbo Wang, Tassawar Ali</author><pubDate>Fri, 12 May 2023 16:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07540v1</guid></item><item><title>Discourse Analysis via Questions and Answers: Parsing Dependency Structures of Questions Under Discussion</title><link>http://arxiv.org/abs/2210.05905v2</link><description>Automatic discourse processing is bottlenecked by data: current discourseformalisms pose highly demanding annotation tasks involving large taxonomies ofdiscourse relations, making them inaccessible to lay annotators. This workinstead adopts the linguistic framework of Questions Under Discussion (QUD) fordiscourse analysis and seeks to derive QUD structures automatically. QUD viewseach sentence as an answer to a question triggered in prior context; thus, wecharacterize relationships between sentences as free-form questions, incontrast to exhaustive fine-grained taxonomies. We develop thefirst-of-its-kind QUD parser that derives a dependency structure of questionsover full documents, trained using a large, crowdsourced question-answeringdataset DCQA (Ko et al., 2022). Human evaluation results show that QUDdependency parsing is possible for language models trained with thiscrowdsourced, generalizable annotation scheme. We illustrate how our QUDstructure is distinct from RST trees, and demonstrate the utility of QUDanalysis in the context of document simplification. Our findings show that QUDparsing is an appealing alternative for automatic discourse processing.</description><author>Wei-Jen Ko, Yating Wu, Cutter Dalton, Dananjay Srinivas, Greg Durrett, Junyi Jessy Li</author><pubDate>Fri, 12 May 2023 16:01:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.05905v2</guid></item><item><title>Saturated Non-Monotonic Activation Functions</title><link>http://arxiv.org/abs/2305.07537v1</link><description>Activation functions are essential to deep learning networks. Popular andversatile activation functions are mostly monotonic functions, somenon-monotonic activation functions are being explored and show promisingperformance. But by introducing non-monotonicity, they also alter the positiveinput, which is proved to be unnecessary by the success of ReLU and itsvariants. In this paper, we double down on the non-monotonic activationfunctions' development and propose the Saturated Gaussian Error Linear Units bycombining the characteristics of ReLU and non-monotonic activation functions.We present three new activation functions built with our proposed method:SGELU, SSiLU, and SMish, which are composed of the negative portion of GELU,SiLU, and Mish, respectively, and ReLU's positive portion. The results of imageclassification experiments on CIFAR-100 indicate that our proposed activationfunctions are highly effective and outperform state-of-the-art baselines acrossmultiple deep learning architectures.</description><author>Junjia Chen, Zhibin Pan</author><pubDate>Fri, 12 May 2023 16:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07537v1</guid></item><item><title>PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs</title><link>http://arxiv.org/abs/2304.09015v3</link><description>Temporal facts, the facts for characterizing events that hold in specifictime periods, are attracting rising attention in the knowledge graph (KG)research communities. In terms of quality management, the introduction of timerestrictions brings new challenges to maintaining the temporal consistency ofKGs and detecting potential temporal conflicts. Previous studies rely onmanually enumerated temporal constraints to detect conflicts, which arelabor-intensive and may have granularity issues. We start from the commonpattern of temporal facts and constraints and propose a pattern-based temporalconstraint mining method, PaTeCon. PaTeCon uses automatically determined graphpatterns and their relevant statistical information over the given KG insteadof human experts to generate time constraints. Specifically, PaTeCondynamically attaches class restriction to candidate constraints according totheir measuring scores.We evaluate PaTeCon on two large-scale datasets based onWikidata and Freebase respectively. The experimental results show thatpattern-based automatic constraint mining is powerful in generating valuabletemporal constraints.</description><author>Jianhao Chen, Junyang Ren, Wentao Ding, Yuzhong Qu</author><pubDate>Fri, 12 May 2023 15:48:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09015v3</guid></item><item><title>WEDGE: A multi-weather autonomous driving dataset built from generative vision-language models</title><link>http://arxiv.org/abs/2305.07528v1</link><description>The open road poses many challenges to autonomous perception, including poorvisibility from extreme weather conditions. Models trained on good-weatherdatasets frequently fail at detection in these out-of-distribution settings. Toaid adversarial robustness in perception, we introduce WEDGE (WEather images byDALL-E GEneration): a synthetic dataset generated with a vision-languagegenerative model via prompting. WEDGE consists of 3360 images in 16 extremeweather conditions manually annotated with 16513 bounding boxes, supportingresearch in the tasks of weather classification and 2D object detection. Wehave analyzed WEDGE from research standpoints, verifying its effectiveness forextreme-weather autonomous perception. We establish baseline performance forclassification and detection with 53.87% test accuracy and 45.41 mAP. Mostimportantly, WEDGE can be used to fine-tune state-of-the-art detectors,improving SOTA performance on real-world weather benchmarks (such as DAWN) by4.48 AP for well-generated classes like trucks. WEDGE has been collected underOpenAI's terms of use and is released for public use under the CC BY-NC-SA 4.0license. The repository for this work and dataset is available athttps://infernolia.github.io/WEDGE.</description><author>Aboli Marathe, Deva Ramanan, Rahee Walambe, Ketan Kotecha</author><pubDate>Fri, 12 May 2023 15:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07528v1</guid></item><item><title>Joint MR sequence optimization beats pure neural network approaches for spin-echo MRI super-resolution</title><link>http://arxiv.org/abs/2305.07524v1</link><description>Current MRI super-resolution (SR) methods only use existing contrastsacquired from typical clinical sequences as input for the neural network (NN).In turbo spin echo sequences (TSE) the sequence parameters can have a stronginfluence on the actual resolution of the acquired image and have consequentlya considera-ble impact on the performance of the NN. We propose aknown-operator learning approach to perform an end-to-end optimization of MRsequence and neural net-work parameters for SR-TSE. This MR-physics-informedtraining procedure jointly optimizes the radiofrequency pulse train of a protondensity- (PD-) and T2-weighted TSE and a subsequently applied convolutionalneural network to predict the corresponding PDw and T2w super-resolution TSEimages. The found radiofrequency pulse train designs generate an optimal signalfor the NN to perform the SR task. Our method generalizes from thesimulation-based optimi-zation to in vivo measurements and the acquiredphysics-informed SR images show higher correlation with a time-consumingsegmented high-resolution TSE sequence compared to a pure network trainingapproach.</description><author>Hoai Nam Dang, Vladimir Golkov, Thomas Wimmer, Daniel Cremers, Andreas Maier, Moritz Zaiss</author><pubDate>Fri, 12 May 2023 15:40:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07524v1</guid></item><item><title>PillarAcc: Sparse PointPillars Accelerator for Real-Time Point Cloud 3D Object Detection on Edge Devices</title><link>http://arxiv.org/abs/2305.07522v1</link><description>3D object detection using point cloud (PC) data is vital for autonomousdriving perception pipelines, where efficient encoding is key to meetingstringent resource and latency requirements. PointPillars, a widely adoptedbird's-eye view (BEV) encoding, aggregates 3D point cloud data into 2D pillarsfor high-accuracy 3D object detection. However, most state-of-the-art methodsemploying PointPillar overlook the inherent sparsity of pillar encoding,missing opportunities for significant computational reduction. In this study,we propose a groundbreaking algorithm-hardware co-design that acceleratessparse convolution processing and maximizes sparsity utilization inpillar-based 3D object detection networks. We investigate sparsificationopportunities using an advanced pillar-pruning method, achieving an optimalbalance between accuracy and sparsity. We introduce PillarAcc, astate-of-the-art sparsity support mechanism that enhances sparse pillarconvolution through linear complexity input-output mapping generation andconflict-free gather-scatter memory access. Additionally, we propose dataflowoptimization techniques, dynamically adjusting the pillar processing schedulefor optimal hardware utilization under diverse sparsity operations. We evaluatePillarAcc on various cutting-edge 3D object detection networks and benchmarks,achieving remarkable speedup and energy savings compared to representative edgeplatforms, demonstrating record-breaking PointPillars speed of 500FPS withminimal compromise in accuracy.</description><author>Minjae Lee, Hyungmin Kim, Seongmin Park, Minyong Yoon, Janghwan Lee, Junwon Choi, Mingu Kang, Jungwook Choi</author><pubDate>Fri, 12 May 2023 15:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07522v1</guid></item><item><title>AGFormer: Efficient Graph Representation with Anchor-Graph Transformer</title><link>http://arxiv.org/abs/2305.07521v1</link><description>To alleviate the local receptive issue of GCN, Transformers have beenexploited to capture the long range dependences of nodes for graph datarepresentation and learning. However, existing graph Transformers generallyemploy regular self-attention module for all node-to-node message passing whichneeds to learn the affinities/relationships between all node's pairs, leadingto high computational cost issue. Also, they are usually sensitive to graphnoises. To overcome this issue, we propose a novel graph Transformerarchitecture, termed Anchor Graph Transformer (AGFormer), by leveraging ananchor graph model. To be specific, AGFormer first obtains some representativeanchors and then converts node-to-node message passing into anchor-to-anchorand anchor-to-node message passing process. Thus, AGFormer performs much moreefficiently and also robustly than regular node-to-node Transformers. Extensiveexperiments on several benchmark datasets demonstrate the effectiveness andbenefits of proposed AGFormer.</description><author>Bo Jiang, Fei Xu, Ziyan Zhang, Jin Tang, Feiping Nie</author><pubDate>Fri, 12 May 2023 15:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07521v1</guid></item><item><title>HFLIC: Human Friendly Perceptual Learned Image Compression with Reinforced Transform</title><link>http://arxiv.org/abs/2305.07519v1</link><description>In recent years, there has been rapid development in learned imagecompression techniques that prioritize ratedistortion-perceptual compression,preserving fine details even at lower bit-rates. However, currentlearning-based image compression methods often sacrifice human-friendlycompression and require long decoding times. In this paper, we proposeenhancements to the backbone network and loss function of existing imagecompression model, focusing on improving human perception and efficiency. Ourproposed approach achieves competitive subjective results compared tostate-of-the-art end-to-end learned image compression methods and classicmethods, while requiring less decoding time and offering human-friendlycompression. Through empirical evaluation, we demonstrate the effectiveness ofour proposed method in achieving outstanding performance, with more than 25%bit-rate saving at the same subjective quality.</description><author>Peirong Ning, Wei Jiang, Ronggang Wang</author><pubDate>Fri, 12 May 2023 15:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07519v1</guid></item><item><title>BlendFields: Few-Shot Example-Driven Facial Modeling</title><link>http://arxiv.org/abs/2305.07514v1</link><description>Generating faithful visualizations of human faces requires capturing bothcoarse and fine-level details of the face geometry and appearance. Existingmethods are either data-driven, requiring an extensive corpus of data notpublicly accessible to the research community, or fail to capture fine detailsbecause they rely on geometric face models that cannot represent fine-graineddetails in texture with a mesh discretization and linear deformation designedto model only a coarse face geometry. We introduce a method that bridges thisgap by drawing inspiration from traditional computer graphics techniques.Unseen expressions are modeled by blending appearance from a sparse set ofextreme poses. This blending is performed by measuring local volumetric changesin those expressions and locally reproducing their appearance whenever asimilar expression is performed at test time. We show that our methodgeneralizes to unseen expressions, adding fine-grained effects on top of smoothvolumetric deformations of a face, and demonstrate how it generalizes beyondfaces.</description><author>Kacper Kania, Stephan J. Garbin, Andrea Tagliasacchi, Virginia Estellers, Kwang Moo Yi, Julien Valentin, Tomasz Trzciński, Marek Kowalski</author><pubDate>Fri, 12 May 2023 15:30:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07514v1</guid></item><item><title>Learn to Unlearn: A Survey on Machine Unlearning</title><link>http://arxiv.org/abs/2305.07512v1</link><description>Machine Learning (ML) models contain private information, and implementingthe right to be forgotten is a challenging privacy issue in many dataapplications. Machine unlearning has emerged as an alternative to removesensitive data from a trained model, but completely retraining ML models isoften not feasible. This survey provides a concise appraisal of MachineUnlearning techniques, encompassing both exact and approximate methods,probable attacks, and verification approaches. The survey compares the meritsand limitations each method and evaluates their performance using the Deltagradexact machine unlearning method. The survey also highlights challenges like thepressing need for a robust model for non-IID deletion to mitigate fairnessissues. Overall, the survey provides a thorough synopsis of machine unlearningtechniques and applications, noting future research directions in this evolvingfield. The survey aims to be a valuable resource for researchers andpractitioners seeking to provide privacy and equity in ML systems.</description><author>Youyang Qu, Xin Yuan, Ming Ding, Wei Ni, Thierry Rakotoarivelo, David Smith</author><pubDate>Fri, 12 May 2023 15:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07512v1</guid></item><item><title>Learning Coherent Clusters in Weakly-Connected Network Systems</title><link>http://arxiv.org/abs/2211.15301v2</link><description>We propose a structure-preserving model-reduction methodology for large-scaledynamic networks with tightly-connected components. First, the coherent groupsare identified by a spectral clustering algorithm on the graph Laplacian matrixthat models the network feedback. Then, a reduced network is built, where eachnode represents the aggregate dynamics of each coherent group, and the reducednetwork captures the dynamic coupling between the groups. We provide an upperbound on the approximation error when the network graph is randomly generatedfrom a weight stochastic block model. Finally, numerical experiments align withand validate our theoretical findings.</description><author>Hancheng Min, Enrique Mallada</author><pubDate>Fri, 12 May 2023 15:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15301v2</guid></item><item><title>Robust and Scalable Bayesian Online Changepoint Detection</title><link>http://arxiv.org/abs/2302.04759v2</link><description>This paper proposes an online, provably robust, and scalable Bayesianapproach for changepoint detection. The resulting algorithm has key advantagesover previous work: it provides provable robustness by leveraging thegeneralised Bayesian perspective, and also addresses the scalability issues ofprevious attempts. Specifically, the proposed generalised Bayesian formalismleads to conjugate posteriors whose parameters are available in closed form byleveraging diffusion score matching. The resulting algorithm is exact, can beupdated through simple algebra, and is more than 10 times faster than itsclosest competitor.</description><author>Matias Altamirano, François-Xavier Briol, Jeremias Knoblauch</author><pubDate>Fri, 12 May 2023 15:26:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04759v2</guid></item><item><title>eXplainable Artificial Intelligence on Medical Images: A Survey</title><link>http://arxiv.org/abs/2305.07511v1</link><description>Over the last few years, the number of works about deep learning applied tothe medical field has increased enormously. The necessity of a rigorousassessment of these models is required to explain these results to all peopleinvolved in medical exams. A recent field in the machine learning area isexplainable artificial intelligence, also known as XAI, which targets toexplain the results of such black box models to permit the desired assessment.This survey analyses several recent studies in the XAI field applied to medicaldiagnosis research, allowing some explainability of the machine learningresults in several different diseases, such as cancers and COVID-19.</description><author>Matteus Vargas Simão da Silva, Rodrigo Reis Arrais, Jhessica Victoria Santos da Silva, Felipe Souza Tânios, Mateus Antonio Chinelatto, Natalia Backhaus Pereira, Renata De Paris, Lucas Cesar Ferreira Domingos, Rodrigo Dória Villaça, Vitor Lopes Fabris, Nayara Rossi Brito da Silva, Ana Claudia Akemi Matsuki de Faria, Jose Victor Nogueira Alves da Silva, Fabiana Cristina Queiroz de Oliveira Marucci, Francisco Alves de Souza Neto, Danilo Xavier Silva, Vitor Yukio Kondo, Claudio Filipi Gonçalves dos Santos</author><pubDate>Fri, 12 May 2023 15:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07511v1</guid></item><item><title>LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development</title><link>http://arxiv.org/abs/2305.07507v1</link><description>In this work, we conduct a detailed analysis on the performance oflegal-oriented pre-trained language models (PLMs). We examine the interplaybetween their original objective, acquired knowledge, and legal languageunderstanding capacities which we define as the upstream, probing, anddownstream performance, respectively. We consider not only the models' size butalso the pre-training corpora used as important dimensions in our study. Tothis end, we release a multinational English legal corpus (LeXFiles) and alegal knowledge probing benchmark (LegalLAMA) to facilitate training anddetailed analysis of legal-oriented PLMs. We release two new legal PLMs trainedon LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. Wefind that probing performance strongly correlates with upstream performance inrelated legal topics. On the other hand, downstream performance is mainlydriven by the model's size and prior legal knowledge which can be estimated byupstream and probing performance. Based on these findings, we can conclude thatboth dimensions are important for those seeking the development ofdomain-specific PLMs.</description><author>Ilias Chalkidis, Nicolas Garneau, Catalina Goanta, Daniel Martin Katz, Anders Søgaard</author><pubDate>Fri, 12 May 2023 15:21:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07507v1</guid></item><item><title>Calibration-Aware Bayesian Learning</title><link>http://arxiv.org/abs/2305.07504v1</link><description>Deep learning models, including modern systems like large language models,are well known to offer unreliable estimates of the uncertainty of theirdecisions. In order to improve the quality of the confidence levels, also knownas calibration, of a model, common approaches entail the addition of eitherdata-dependent or data-independent regularization terms to the training loss.Data-dependent regularizers have been recently introduced in the context ofconventional frequentist learning to penalize deviations between confidence andaccuracy. In contrast, data-independent regularizers are at the core ofBayesian learning, enforcing adherence of the variational distribution in themodel parameter space to a prior density. The former approach is unable toquantify epistemic uncertainty, while the latter is severely affected by modelmisspecification. In light of the limitations of both methods, this paperproposes an integrated framework, referred to as calibration-aware Bayesianneural networks (CA-BNNs), that applies both regularizers while optimizing overa variational distribution as in Bayesian learning. Numerical results validatethe advantages of the proposed approach in terms of expected calibration error(ECE) and reliability diagrams.</description><author>Jiayi Huang, Sangwoo Park, Osvaldo Simeone</author><pubDate>Fri, 12 May 2023 15:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07504v1</guid></item><item><title>Culture-to-Culture Image Translation and User Evaluation</title><link>http://arxiv.org/abs/2201.01565v6</link><description>The article introduces the concept of image "culturization," which we defineas the process of altering the ``brushstroke of cultural features" that makeobjects perceived as belonging to a given culture while preserving theirfunctionalities. First, we defined a pipeline for translating objects' imagesfrom a source to a target cultural domain based on state-of-the-art GenerativeAdversarial Networks. Then, we gathered data through an online questionnaire totest four hypotheses concerning the impact of images belonging to differentcultural domains on Italian participants. As expected, results depend onindividual tastes and preferences: however, they align with our conjecture thatsome people, during the interaction with an intelligent system, will prefer tobe shown images modified to match their cultural background. The study has twomain limitations. First, we focussed on the culturization of individual objectsinstead of complete scenes. However, objects play a crucial role in conveyingcultural meanings and can strongly influence how an image is perceived within aspecific cultural context. Understanding and addressing object-leveltranslation is a vital step toward achieving more comprehensive scene-leveltranslation in future research. Second, we performed experiments with Italianparticipants only. We think that there are unique aspects of Italian culturethat make it an interesting and relevant case study for exploring the impact ofimage culturization. Italy is a very culturally conservative society, andItalians have specific sensitivities and expectations regarding the accuraterepresentation of their cultural identity and traditions, which can shapeindividuals' preferences and inclinations toward certain visual styles,aesthetics, and design choices. As a consequence, we think they are an idealcandidate for a preliminary investigation of image culturization.</description><author>Giulia Zaino, Carmine Tommaso Recchiuto, Antonio Sgorbissa</author><pubDate>Fri, 12 May 2023 15:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.01565v6</guid></item><item><title>Beyond invariant representation learning: linearly alignable latent spaces for efficient closed-form domain adaptation</title><link>http://arxiv.org/abs/2305.07500v1</link><description>Optimal transport (OT) is a powerful geometric tool used to compare and alignprobability measures following the least effort principle. Among manysuccessful applications of OT in machine learning (ML), domain adaptation (DA)-- a field of study where the goal is to transfer a classifier from onelabelled domain to another similar, yet different unlabelled or scarcelylabelled domain -- has been historically among the most investigated ones. Thissuccess is due to the ability of OT to provide both a meaningful discrepancymeasure to assess the similarity of two domains' distributions and a mappingthat can project source domain data onto the target one. In this paper, wepropose a principally new OT-based approach applied to DA that uses theclosed-form solution of the OT problem given by an affine mapping and learns anembedding space for which this solution is optimal and computationally lesscomplex. We show that our approach works in both homogeneous and heterogeneousDA settings and outperforms or is on par with other famous baselines based onboth traditional OT and OT in incomparable spaces. Furthermore, we show thatour proposed method vastly reduces computational complexity.</description><author>Oliver Struckmeier, Ievgen Redko, Anton Mallasto, Karol Arndt, Markus Heinonen, Ville Kyrki</author><pubDate>Fri, 12 May 2023 15:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07500v1</guid></item><item><title>A Nonparametric Approach with Marginals for Modeling Consumer Choice</title><link>http://arxiv.org/abs/2208.06115v2</link><description>Given data on choices made by consumers for different assortments, a keychallenge is to develop parsimonious models that describe and predict consumerchoice behavior. One such choice model is the marginal distribution model whichrequires only the specification of the marginal distributions of the randomutilities of the alternatives to explain choice data. In this paper, we developan exact characterisation of the set of choice probabilities which arerepresentable by the marginal distribution model consistently across anycollection of assortments. Allowing for the possibility of alternatives to begrouped based on the marginal distribution of their utilities, we show (a)verifying consistency of choice probability data with this model is possible inpolynomial time and (b) finding the closest fit reduces to solving a mixedinteger convex program. Our results show that the marginal distribution modelprovides much better representational power as compared to multinomial logitand much better computational performance as compared to the random utilitymodel.</description><author>Yanqiu Ruan, Xiaobo Li, Karthyek Murthy, Karthik Natarajan</author><pubDate>Fri, 12 May 2023 15:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.06115v2</guid></item><item><title>Device-Robust Acoustic Scene Classification via Impulse Response Augmentation</title><link>http://arxiv.org/abs/2305.07499v1</link><description>The ability to generalize to a wide range of recording devices is a crucialperformance factor for audio classification models. The characteristics ofdifferent types of microphones introduce distributional shifts in the digitizedaudio signals due to their varying frequency responses. If this domain shift isnot taken into account during training, the model's performance could degradeseverely when it is applied to signals recorded by unseen devices. Inparticular, training a model on audio signals recorded with a small number ofdifferent microphones can make generalization to unseen devices difficult. Totackle this problem, we convolve audio signals in the training set withpre-recorded device impulse responses (DIRs) to artificially increase thediversity of recording devices. We systematically study the effect of DIRaugmentation on the task of Acoustic Scene Classification using CNNs and AudioSpectrogram Transformers. The results show that DIR augmentation in isolationperforms similarly to the state-of-the-art method Freq-MixStyle. However, wealso show that DIR augmentation and Freq-MixStyle are complementary, achievinga new state-of-the-art performance on signals recorded by devices unseen duringtraining.</description><author>Tobias Morocutti, Florian Schmid, Khaled Koutini, Gerhard Widmer</author><pubDate>Fri, 12 May 2023 15:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07499v1</guid></item><item><title>Visual Information Extraction in the Wild: Practical Dataset and End-to-end Solution</title><link>http://arxiv.org/abs/2305.07498v1</link><description>Visual information extraction (VIE), which aims to simultaneously perform OCRand information extraction in a unified framework, has drawn increasingattention due to its essential role in various applications like understandingreceipts, goods, and traffic signs. However, as existing benchmark datasets forVIE mainly consist of document images without the adequate diversity of layoutstructures, background disturbs, and entity categories, they cannot fullyreveal the challenges of real-world applications. In this paper, we propose alarge-scale dataset consisting of camera images for VIE, which contains notonly the larger variance of layout, backgrounds, and fonts but also much moretypes of entities. Besides, we propose a novel framework for end-to-end VIEthat combines the stages of OCR and information extraction in an end-to-endlearning fashion. Different from the previous end-to-end approaches thatdirectly adopt OCR features as the input of an information extraction module,we propose to use contrastive learning to narrow the semantic gap caused by thedifference between the tasks of OCR and information extraction. We evaluate theexisting end-to-end methods for VIE on the proposed dataset and observe thatthe performance of these methods has a distinguishable drop from SROIE (awidely used English dataset) to our proposed dataset due to the larger varianceof layout and entities. These results demonstrate our dataset is more practicalfor promoting advanced VIE algorithms. In addition, experiments demonstratethat the proposed VIE method consistently achieves the obvious performancegains on the proposed and SROIE datasets.</description><author>Jianfeng Kuang, Wei Hua, Dingkang Liang, Mingkun Yang, Deqiang Jiang, Bo Ren, Yu Zhou, Xiang Bai</author><pubDate>Fri, 12 May 2023 15:11:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07498v1</guid></item><item><title>Dynamically Conservative Self-Driving Planner for Long-Tail Cases</title><link>http://arxiv.org/abs/2305.07497v1</link><description>Self-driving vehicles (SDVs) are becoming reality but still suffer from"long-tail" challenges during natural driving: the SDVs will continuallyencounter rare, safety-critical cases that may not be included in the datasetthey were trained. Some safety-assurance planners solve this problem by beingconservative in all possible cases, which may significantly affect drivingmobility. To this end, this work proposes a method to automatically adjust theconservative level according to each case's "long-tail" rate, named dynamicallyconservative planner (DCP). We first define the "long-tail" rate as an SDV'sconfidence to pass a driving case. The rate indicates the probability ofsafe-critical events and is estimated using the statistics bootstrapped methodwith historical data. Then, a reinforcement learning-based planner is designedto contain candidate policies with different conservative levels. The finalpolicy is optimized based on the estimated "long-tail" rate. In this way, theDCP is designed to automatically adjust to be more conservative inlow-confidence "long-tail" cases while keeping efficient otherwise. The DCP isevaluated in the CARLA simulator using driving cases with "long-tail"distributed training data. The results show that the DCP can accuratelyestimate the "long-tail" rate to identify potential risks. Based on the rate,the DCP automatically avoids potential collisions in "long-tail" cases usingconservative decisions while not affecting the average velocity in othertypical cases. Thus, the DCP is safer and more efficient than the baselineswith fixed conservative levels, e.g., an always conservative planner. This workprovides a technique to guarantee SDV's performance in unexpected driving caseswithout resorting to a global conservative setting, which contributes tosolving the "long-tail" problem practically.</description><author>Weitao Zhou, Zhong Cao, Nanshan Deng, Xiaoyu Liu, Kun Jiang, Diange Yang</author><pubDate>Fri, 12 May 2023 15:11:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07497v1</guid></item><item><title>Gallery Sampling for Robust and Fast Face Identification</title><link>http://arxiv.org/abs/2305.07495v1</link><description>Deep learning methods have been achieved brilliant results in facerecognition. One of the important tasks to improve the performance is tocollect and label images as many as possible. However, labeling identities andchecking qualities of large image data are difficult task and mistakes cannotbe avoided in processing large data. Previous works have been trying to dealwith the problem only in training domain, however it can cause much seriousproblem if the mistakes are in gallery data of face identification. We proposedgallery data sampling methods which are robust to outliers including wronglabeled, low quality, and less-informative images and reduce searching time.The proposed sampling-by-pruning and sampling-by-generating methodssignificantly improved face identification performance on our 5.4M web imagedataset of celebrities. The proposed method achieved 0.0975 in terms of FNIR atFPIR=0.01, while conventional method showed 0.3891. The average number offeature vectors for each individual gallery was reduced to 17.1 from 115.9 andit can provide much faster search. We also made experiments on public datasetsand our method achieved 0.1314 and 0.0668 FNIRs at FPIR=0.01 on theCASIA-WebFace and MS1MV2, while the convectional method did 0.5446, and 0.1327,respectively.</description><author>Myung-cheol Roh, Pyoung-gang Lim, Jongju Shin</author><pubDate>Fri, 12 May 2023 15:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07495v1</guid></item><item><title>Temporal Network Creation Games</title><link>http://arxiv.org/abs/2305.07494v1</link><description>Most networks are not static objects, but instead they change over time. Thisobservation has sparked rigorous research on temporal graphs within the lastyears. In temporal graphs, we have a fixed set of nodes and the connectionsbetween them are only available at certain time steps. This gives rise to aplethora of algorithmic problems on such graphs, most prominently the problemof finding temporal spanners, i.e., the computation of subgraphs that guaranteeall pairs reachability via temporal paths. To the best of our knowledge, onlycentralized approaches for the solution of this problem are known. However,many real-world networks are not shaped by a central designer but instead theyemerge and evolve by the interaction of many strategic agents. This observationis the driving force of the recent intensive research on game-theoretic networkformation models. In this work we bring together these two recent research directions: temporalgraphs and game-theoretic network formation. As a first step into this newrealm, we focus on a simplified setting where a complete temporal host graph isgiven and the agents, corresponding to its nodes, selfishly create incidentedges to ensure that they can reach all other nodes via temporal paths in thecreated network. This yields temporal spanners as equilibria of our game. Weprove results on the convergence to and the existence of equilibrium networks,on the complexity of finding best agent strategies, and on the quality of theequilibria. By taking these first important steps, we uncover challenging openproblems that call for an in-depth exploration of the creation of temporalgraphs by strategic agents.</description><author>Davide Bilò, Sarel Cohen, Tobias Friedrich, Hans Gawendowicz, Nicolas Klodt, Pascal Lenzner, George Skretas</author><pubDate>Fri, 12 May 2023 15:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07494v1</guid></item><item><title>A Comprehensive Analysis of Adapter Efficiency</title><link>http://arxiv.org/abs/2305.07491v1</link><description>Adapters have been positioned as a parameter-efficient fine-tuning (PEFT)approach, whereby a minimal number of parameters are added to the model andfine-tuned. However, adapters have not been sufficiently analyzed to understandif PEFT translates to benefits in training/deployment efficiency andmaintainability/extensibility. Through extensive experiments on many adapters,tasks, and languages in supervised and cross-lingual zero-shot settings, weclearly show that for Natural Language Understanding (NLU) tasks, the parameterefficiency in adapters does not translate to efficiency gains compared to fullfine-tuning of models. More precisely, adapters are relatively expensive totrain and have slightly higher deployment latency. Furthermore, themaintainability/extensibility benefits of adapters can be achieved with simplerapproaches like multi-task training via full fine-tuning, which also providerelatively faster training times. We, therefore, recommend that for moderatelysized models for NLU tasks, practitioners should rely on full fine-tuning ormulti-task training rather than using adapters. Our code is available athttps://github.com/AI4Bharat/adapter-efficiency.</description><author>Nandini Mundra, Sumanth Doddapaneni, Raj Dabre, Anoop Kunchukuttan, Ratish Puduppully, Mitesh M. Khapra</author><pubDate>Fri, 12 May 2023 15:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07491v1</guid></item><item><title>ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4</title><link>http://arxiv.org/abs/2305.07490v1</link><description>In recent years, large language models (LLMs) have made significant progressin natural language processing (NLP), with models like ChatGPT and GPT-4achieving impressive capabilities in various linguistic tasks. However,training models on such a large scale is challenging, and finding datasets thatmatch the model's scale is often difficult. Fine-tuning and training modelswith fewer parameters using novel methods have emerged as promising approachesto overcome these challenges. One such model is MiniGPT-4, which achievescomparable vision-language understanding to GPT-4 by leveraging novelpre-training models and innovative training strategies. However, the modelstill faces some challenges in image understanding, particularly in artisticpictures. A novel multimodal model called ArtGPT-4 has been proposed to addressthese limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100device in just 2 hours, using only about 200 GB of data. The model can depictimages with an artistic flair and generate visual code, including aestheticallypleasing HTML/CSS web pages. Furthermore, the article proposes novel benchmarksfor evaluating the performance of vision-language models. In the subsequentevaluation methods, ArtGPT-4 scored more than 1 point higher than the current\textbf{state-of-the-art} model and was only 0.25 points lower than artists ona 6-point scale. Our code and pre-trained model are available at\url{https://huggingface.co/Tyrannosaurus/ArtGPT-4}.</description><author>Zhengqing Yuan, Huiwen Xue, Xinyi Wang, Yongming Liu, Zhuanzhe Zhao, Kun Wang</author><pubDate>Fri, 12 May 2023 15:04:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07490v1</guid></item><item><title>Deep Perceptual Similarity is Adaptable to Ambiguous Contexts</title><link>http://arxiv.org/abs/2304.02265v2</link><description>The concept of image similarity is ambiguous, and images can be similar inone context and not in another. This ambiguity motivates the creation ofmetrics for specific contexts. This work explores the ability of deepperceptual similarity (DPS) metrics to adapt to a given context. DPS metricsuse the deep features of neural networks for comparing images. These metricshave been successful on datasets that leverage the average human perception inlimited settings. But the question remains if they could be adapted to specificsimilarity contexts. No single metric can suit all similarity contexts, andprevious rule-based metrics are labor-intensive to rewrite for new contexts. Onthe other hand, DPS metrics use neural networks that might be retrained foreach context. However, retraining networks takes resources and might ruinperformance on previous tasks. This work examines the adaptability of DPSmetrics by training ImageNet pretrained CNNs to measure similarity according togiven contexts. Contexts are created by randomly ranking six image distortions.Distortions later in the ranking are considered more disruptive to similaritywhen applied to an image for that context. This also gives insight into whetherthe pretrained features capture different similarity contexts. The adaptedmetrics are evaluated on a perceptual similarity dataset to evaluate ifadapting to a ranking affects their prior performance. The findings show thatDPS metrics can be adapted with high performance. While the adapted metricshave difficulties with the same contexts as baselines, performance is improvedin 99% of cases. Finally, it is shown that the adaption is not significantlydetrimental to prior performance on perceptual similarity. The implementationof this work is available online:https://github.com/LTU-Machine-Learning/Analysis-of-Deep-Perceptual-Loss-Networks</description><author>Gustav Grund Pihlgren, Fredrik Sandin, Marcus Liwicki</author><pubDate>Fri, 12 May 2023 15:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02265v2</guid></item><item><title>Benchmarks and leaderboards for sound demixing tasks</title><link>http://arxiv.org/abs/2305.07489v1</link><description>Music demixing is the task of separating different tracks from the givensingle audio signal into components, such as drums, bass, and vocals from therest of the accompaniment. Separation of sources is useful for a range ofareas, including entertainment and hearing aids. In this paper, we introducetwo new benchmarks for the sound source separation tasks and compare popularmodels for sound demixing, as well as their ensembles, on these benchmarks. Forthe models' assessments, we provide the leaderboard athttps://mvsep.com/quality_checker/, giving a comparison for a range of models.The new benchmark datasets are available for download. We also develop a novelapproach for audio separation, based on the ensembling of different models thatare suited best for the particular stem. The proposed solution was evaluated inthe context of the Music Demixing Challenge 2023 and achieved top results indifferent tracks of the challenge. The code and the approach are open-sourcedon GitHub.</description><author>Roman Solovyev, Alexander Stempkovskiy, Tatiana Habruseva</author><pubDate>Fri, 12 May 2023 15:00:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07489v1</guid></item><item><title>Identify, Estimate and Bound the Uncertainty of Reinforcement Learning for Autonomous Driving</title><link>http://arxiv.org/abs/2305.07487v1</link><description>Deep reinforcement learning (DRL) has emerged as a promising approach fordeveloping more intelligent autonomous vehicles (AVs). A typical DRLapplication on AVs is to train a neural network-based driving policy. However,the black-box nature of neural networks can result in unpredictable decisionfailures, making such AVs unreliable. To this end, this work proposes a methodto identify and protect unreliable decisions of a DRL driving policy. The basicidea is to estimate and constrain the policy's performance uncertainty, whichquantifies potential performance drop due to insufficient training data ornetwork fitting errors. By constraining the uncertainty, the DRL model'sperformance is always greater than that of a baseline policy. The uncertaintycaused by insufficient data is estimated by the bootstrapped method. Then, theuncertainty caused by the network fitting error is estimated using an ensemblenetwork. Finally, a baseline policy is added as the performance lower bound toavoid potential decision failures. The overall framework is calleduncertainty-bound reinforcement learning (UBRL). The proposed UBRL is evaluatedon DRL policies with different amounts of training data, taking an unprotectedleft-turn driving case as an example. The result shows that the UBRL method canidentify potentially unreliable decisions of DRL policy. The UBRL guarantees tooutperform baseline policy even when the DRL policy is not well-trained and hashigh uncertainty. Meanwhile, the performance of UBRL improves with moretraining data. Such a method is valuable for the DRL application on real-roaddriving and provides a metric to evaluate a DRL policy.</description><author>Weitao Zhou, Zhong Cao, Nanshan Deng, Kun Jiang, Diange Yang</author><pubDate>Fri, 12 May 2023 14:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07487v1</guid></item><item><title>Reduced Label Complexity For Tight $\ell_2$ Regression</title><link>http://arxiv.org/abs/2305.07486v1</link><description>Given data ${\rm X}\in\mathbb{R}^{n\times d}$ and labels$\mathbf{y}\in\mathbb{R}^{n}$ the goal is find $\mathbf{w}\in\mathbb{R}^d$ tominimize $\Vert{\rm X}\mathbf{w}-\mathbf{y}\Vert^2$. We give a polynomialalgorithm that, \emph{oblivious to $\mathbf{y}$}, throws out $n/(d+\sqrt{n})$data points and is a $(1+d/n)$-approximation to optimal in expectation. Themotivation is tight approximation with reduced label complexity (number oflabels revealed). We reduce label complexity by $\Omega(\sqrt{n})$. Openquestion: Can label complexity be reduced by $\Omega(n)$ with tight$(1+d/n)$-approximation?</description><author>Alex Gittens, Malik Magdon-Ismail</author><pubDate>Fri, 12 May 2023 14:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07486v1</guid></item><item><title>Online Learning Under A Separable Stochastic Approximation Framework</title><link>http://arxiv.org/abs/2305.07484v1</link><description>We propose an online learning algorithm for a class of machine learningmodels under a separable stochastic approximation framework. The essence of ouridea lies in the observation that certain parameters in the models are easierto optimize than others. In this paper, we focus on models where someparameters have a linear nature, which is common in machine learning. In oneroutine of the proposed algorithm, the linear parameters are updated by therecursive least squares (RLS) algorithm, which is equivalent to a stochasticNewton method; then, based on the updated linear parameters, the nonlinearparameters are updated by the stochastic gradient method (SGD). The proposedalgorithm can be understood as a stochastic approximation version of blockcoordinate gradient descent approach in which one part of the parameters isupdated by a second-order SGD method while the other part is updated by afirst-order SGD. Global convergence of the proposed online algorithm fornon-convex cases is established in terms of the expected violation of afirst-order optimality condition. Numerical experiments have shown that theproposed method accelerates convergence significantly and produces more robusttraining and test performance when compared to other popular learningalgorithms. Moreover, our algorithm is less sensitive to the learning rate andoutperforms the recently proposed slimTrain algorithm. The code has beenuploaded to GitHub for validation.</description><author>Min Gan, Xiang-xiang Su, Guang-yong Chen</author><pubDate>Fri, 12 May 2023 14:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07484v1</guid></item><item><title>Comprehensive Solution Program Centric Pretraining for Table-and-Text Hybrid Numerical Reasoning</title><link>http://arxiv.org/abs/2305.07475v1</link><description>Numerical reasoning over table-and-text hybrid passages, such as financialreports, poses significant challenges and has numerous potential applications.Noise and irrelevant variables in the model input have been a hindrance to itsperformance. Additionally, coarse-grained supervision of the whole solutionprogram has impeded the model's ability to learn the underlying numericalreasoning process. In this paper, we propose three pretraining tasks thatoperate at both the whole program and sub-program level: Variable IntegrityRanking, which guides the model to focus on useful variables; Variable OperatorPrediction, which decomposes the supervision into fine-grained single operatorprediction; and Variable Keyphrase Masking, which encourages the model toidentify key evidence that sub-programs are derived from. Experimental resultsdemonstrate the effectiveness of our proposed methods, surpassingtransformer-based model baselines.</description><author>Qianying Liu, Dongsheng Yang, Wenjie Zhong, Fei Cheng, Sadao Kurohashi</author><pubDate>Fri, 12 May 2023 14:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07475v1</guid></item><item><title>GPT-NER: Named Entity Recognition via Large Language Models</title><link>http://arxiv.org/abs/2304.10428v3</link><description>Despite the fact that large-scale Language Models (LLM) have achieved SOTAperformances on a variety of NLP tasks, its performance on NER is stillsignificantly below supervised baselines. This is due to the gap between thetwo tasks the NER and LLMs: the former is a sequence labeling task in naturewhile the latter is a text-generation model. In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges thegap by transforming the sequence labeling task to a generation task that can beeasily adapted by LLMs e.g., the task of finding location entities in the inputtext "Columbus is a city" is transformed to generate the text sequence"@@Columbus## is a city", where special tokens @@## marks the entity toextract. To efficiently address the "hallucination" issue of LLMs, where LLMshave a strong inclination to over-confidently label NULL inputs as entities, wepropose a self-verification strategy by prompting LLMs to ask itself whetherthe extracted entities belong to a labeled entity tag. We conduct experiments on five widely adopted NER datasets, and GPT-NERachieves comparable performances to fully supervised baselines, which is thefirst time as far as we are concerned. More importantly, we find that GPT-NERexhibits a greater ability in the low-resource and few-shot setups, when theamount of training data is extremely scarce, GPT-NER performs significantlybetter than supervised models. This demonstrates the capabilities of GPT-NER inreal-world NER applications where the number of labeled examples is limited.</description><author>Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, Guoyin Wang</author><pubDate>Fri, 12 May 2023 14:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10428v3</guid></item><item><title>Connection Sensitivity Matters for Training-free DARTS: From Architecture-Level Scoring to Operation-Level Sensitivity Analysis</title><link>http://arxiv.org/abs/2106.11542v4</link><description>The recently proposed training-free NAS methods abandon the training phaseand design various zero-cost proxies as scores to identify excellentarchitectures, arousing extreme computational efficiency for neuralarchitecture search. In this paper, we raise an interesting problem: can weproperly measure the operation importance in DARTS through a training-free way,with avoiding the parameter-intensive bias? We investigate this questionthrough the lens of edge connectivity, and provide an affirmative answer bydefining a connectivity concept, ZERo-cost Operation Sensitivity (ZEROS), toscore the importance of candidate operations in DARTS at initialization. Bydevising an iterative and data-agnostic manner in utilizing ZEROS for NAS, ournovel trial leads to a framework called training free differentiablearchitecture search (FreeDARTS). Based on the theory of Neural Tangent Kernel(NTK), we show the proposed connectivity score provably negatively correlatedwith the generalization bound of DARTS supernet after convergence undergradient descent training. In addition, we theoretically explain how ZEROSimplicitly avoids parameter-intensive bias in selecting architectures, andempirically show the searched architectures by FreeDARTS are of comparablesize. Extensive experiments have been conducted on a series of search spaces,and results have demonstrated that FreeDARTS is a reliable and efficientbaseline for neural architecture search.</description><author>Miao Zhang, Wei Huang, Li Wang</author><pubDate>Fri, 12 May 2023 14:17:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.11542v4</guid></item><item><title>Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation</title><link>http://arxiv.org/abs/2305.07457v1</link><description>Quality Estimation (QE) is the task of predicting the quality of MachineTranslation (MT) system output, without using any gold-standard translationreferences. State-of-the-art QE models are supervised: they requirehuman-labeled quality of some MT system output on some datasets for training,making them domain-dependent and MT-system-dependent. There has been researchon unsupervised QE, which requires glass-box access to the MT systems, orparallel MT data to generate synthetic errors for training QE models. In thispaper, we present Perturbation-based QE - a word-level Quality Estimationapproach that works simply by analyzing MT system output on perturbed inputsource sentences. Our approach is unsupervised, explainable, and can evaluateany type of blackbox MT systems, including the currently prominent largelanguage models (LLMs) with opaque internal processes. For language directionswith no labeled QE data, our approach has similar or better performance thanthe zero-shot supervised approach on the WMT21 shared task. Our approach isbetter at detecting gender bias and word-sense-disambiguation errors intranslation than supervised QE, indicating its robustness to out-of-domainusage. The performance gap is larger when detecting errors on a nontraditionaltranslation-prompting LLM, indicating that our approach is more generalizableto different MT systems. We give examples demonstrating our approach'sexplainability power, where it shows which input source words have influence ona certain MT output word.</description><author>Tu Anh Dinh, Jan Niehues</author><pubDate>Fri, 12 May 2023 14:10:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07457v1</guid></item><item><title>Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation</title><link>http://arxiv.org/abs/2305.07455v1</link><description>Most of the speech translation models heavily rely on parallel data, which ishard to collect especially for low-resource languages. To tackle this issue, wepropose to build a cascaded speech translation system without leveraging anykind of paired data. We use fully unpaired data to train our unsupervisedsystems and evaluate our results on CoVoST 2 and CVSS. The results show thatour work is comparable with some other early supervised methods in somelanguage pairs. While cascaded systems always suffer from severe errorpropagation problems, we proposed denoising back-translation (DBT), a novelapproach to building robust unsupervised neural machine translation (UNMT). DBTsuccessfully increases the BLEU score by 0.7--0.9 in all three translationdirections. Moreover, we simplified the pipeline of our cascaded system toreduce inference latency and conducted a comprehensive analysis of every partof our work. We also demonstrate our unsupervised speech translation results onthe established website.</description><author>Yu-Kuan Fu, Liang-Hsuan Tseng, Jiatong Shi, Chen-An Li, Tsu-Yuan Hsu, Shinji Watanabe, Hung-yi Lee</author><pubDate>Fri, 12 May 2023 14:07:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07455v1</guid></item><item><title>Deep Deterministic Policy Gradient for End-to-End Communication Systems without Prior Channel Knowledge</title><link>http://arxiv.org/abs/2305.07448v1</link><description>End-to-End (E2E) learning-based concept has been recently introduced tojointly optimize both the transmitter and the receiver in wirelesscommunication systems. Unfortunately, this E2E learning architecture requires aprior differentiable channel model to jointly train the deep neural networks(DNNs) at the transceivers, which is hardly obtained in practice. This paperaims to solve this issue by developing a deep deterministic policy gradient(DDPG)-based framework. In particular, the proposed solution uses the lossvalue of the receiver DNN as the reward to train the transmitter DNN. Thesimulation results then show that our proposed solution can jointly train thetransmitter and the receiver without requiring the prior channel model. Inaddition, we demonstrate that the proposed DDPG-based solution can achievebetter detection performance compared to the state-of-the-art solutions.</description><author>Bolun Zhang, Nguyen Van Huynh</author><pubDate>Fri, 12 May 2023 14:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07448v1</guid></item><item><title>A Lightweight Domain Adversarial Neural Network Based on Knowledge Distillation for EEG-based Cross-subject Emotion Recognition</title><link>http://arxiv.org/abs/2305.07446v1</link><description>Individual differences of Electroencephalogram (EEG) could cause the domainshift which would significantly degrade the performance of cross-subjectstrategy. The domain adversarial neural networks (DANN), where theclassification loss and domain loss jointly update the parameters of featureextractor, are adopted to deal with the domain shift. However, limited EEG dataquantity and strong individual difference are challenges for the DANN withcumbersome feature extractor. In this work, we propose knowledge distillation(KD) based lightweight DANN to enhance cross-subject EEG-based emotionrecognition. Specifically, the teacher model with strong context learningability is utilized to learn complex temporal dynamics and spatial correlationsof EEG, and robust lightweight student model is guided by the teacher model tolearn more difficult domain-invariant features. In the feature-based KDframework, a transformer-based hierarchical temporalspatial learning model isserved as the teacher model. The student model, which is composed of Bi-LSTMunits, is a lightweight version of the teacher model. Hence, the student modelcould be supervised to mimic the robust feature representations of teachermodel by leveraging complementary latent temporal features and spatialfeatures. In the DANN-based cross-subject emotion recognition, we combine theobtained student model and a lightweight temporal-spatial feature interactionmodule as the feature extractor. And the feature aggregation is fed to theemotion classifier and domain classifier for domain-invariant feature learning.To verify the effectiveness of the proposed method, we conduct thesubject-independent experiments on the public dataset DEAP with arousal andvalence classification. The outstanding performance and t-SNE visualization oflatent features verify the advantage and effectiveness of the proposed method.</description><author>Zhe Wang, Yongxiong Wang, Jiapeng Zhang, Yiheng Tang, Zhiqun Pan</author><pubDate>Fri, 12 May 2023 14:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07446v1</guid></item><item><title>Expertise-based Weighting for Regression Models with Noisy Labels</title><link>http://arxiv.org/abs/2305.07430v1</link><description>Regression methods assume that accurate labels are available for training.However, in certain scenarios, obtaining accurate labels may not be feasible,and relying on multiple specialists with differing opinions becomes necessary.Existing approaches addressing noisy labels often impose restrictiveassumptions on the regression function. In contrast, this paper presents anovel, more flexible approach. Our method consists of two steps: estimatingeach labeler's expertise and combining their opinions using learned weights. Wethen regress the weighted average against the input features to build theprediction model. The proposed method is formally justified and empiricallydemonstrated to outperform existing techniques on simulated and real data.Furthermore, its flexibility enables the utilization of any machine learningtechnique in both steps. In summary, this method offers a simple, fast, andeffective solution for training regression models with noisy labels derivedfrom diverse expert opinions.</description><author>Milene Regina dos Santos, Rafael Izbicki</author><pubDate>Fri, 12 May 2023 13:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07430v1</guid></item><item><title>Unlocking the Potential of Medical Imaging with ChatGPT's Intelligent Diagnostics</title><link>http://arxiv.org/abs/2305.07429v1</link><description>Medical imaging is an essential tool for diagnosing various healthcarediseases and conditions. However, analyzing medical images is a complex andtime-consuming task that requires expertise and experience. This article aimsto design a decision support system to assist healthcare providers and patientsin making decisions about diagnosing, treating, and managing health conditions.The proposed architecture contains three stages: 1) data collection andlabeling, 2) model training, and 3) diagnosis report generation. The key ideais to train a deep learning model on a medical image dataset to extract fourtypes of information: the type of image scan, the body part, the test image,and the results. This information is then fed into ChatGPT to generateautomatic diagnostics. The proposed system has the potential to enhancedecision-making, reduce costs, and improve the capabilities of healthcareproviders. The efficacy of the proposed system is analyzed by conductingextensive experiments on a large medical image dataset. The experimentaloutcomes exhibited promising performance for automatic diagnosis throughmedical images.</description><author>Ayyub Alzahem, Shahid Latif, Wadii Boulila, Anis Koubaa</author><pubDate>Fri, 12 May 2023 13:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07429v1</guid></item><item><title>Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding</title><link>http://arxiv.org/abs/2305.07424v1</link><description>Contrastive learning-based methods, such as unsup-SimCSE, have achievedstate-of-the-art (SOTA) performances in learning unsupervised sentenceembeddings. However, in previous studies, each embedding used for contrastivelearning only derived from one sentence instance, and we call these embeddingsinstance-level embeddings. In other words, each embedding is regarded as aunique class of its own, whichmay hurt the generalization performance. In thisstudy, we propose IS-CSE (instance smoothing contrastive sentence embedding) tosmooth the boundaries of embeddings in the feature space. Specifically, weretrieve embeddings from a dynamic memory buffer according to the semanticsimilarity to get a positive embedding group. Then embeddings in the group areaggregated by a self-attention operation to produce a smoothed instanceembedding for further analysis. We evaluate our method on standard semantictext similarity (STS) tasks and achieve an average of 78.30%, 79.47%, 77.73%,and 79.42% Spearman's correlation on the base of BERT-base, BERT-large,RoBERTa-base, and RoBERTa-large respectively, a 2.05%, 1.06%, 1.16% and 0.52%improvement compared to unsup-SimCSE.</description><author>Hongliang He, Junlei zhang, Zhenzhong Lan, Yue Zhang</author><pubDate>Fri, 12 May 2023 13:46:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07424v1</guid></item><item><title>Selective imitation on the basis of reward function similarity</title><link>http://arxiv.org/abs/2305.07421v1</link><description>Imitation is a key component of human social behavior, and is widely used byboth children and adults as a way to navigate uncertain or unfamiliarsituations. But in an environment populated by multiple heterogeneous agentspursuing different goals or objectives, indiscriminate imitation is unlikely tobe an effective strategy -- the imitator must instead determine who is mostuseful to copy. There are likely many factors that play into these judgements,depending on context and availability of information. Here we investigate thehypothesis that these decisions involve inferences about other agents' rewardfunctions. We suggest that people preferentially imitate the behavior of othersthey deem to have similar reward functions to their own. We further argue thatthese inferences can be made on the basis of very sparse or indirect data, byleveraging an inductive bias toward positing the existence of different\textit{groups} or \textit{types} of people with similar reward functions,allowing learners to select imitation targets without direct evidence ofalignment.</description><author>Max Taylor-Davies, Stephanie Droop, Christopher G. Lucas</author><pubDate>Fri, 12 May 2023 13:40:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07421v1</guid></item><item><title>A Multidimensional Graph Fourier Transformation Neural Network for Vehicle Trajectory Prediction</title><link>http://arxiv.org/abs/2305.07416v1</link><description>This work introduces the multidimensional Graph Fourier Transformation NeuralNetwork (GFTNN) for long-term trajectory predictions on highways. Similar toGraph Neural Networks (GNNs), the GFTNN is a novel network architecture thatoperates on graph structures. While several GNNs lack discriminative power dueto suboptimal aggregation schemes, the proposed model aggregates scenarioproperties through a powerful operation: the multidimensional Graph FourierTransformation (GFT). The spatio-temporal vehicle interaction graph of ascenario is converted into a spectral scenario representation using the GFT.This beneficial representation is input to the prediction framework composed ofa neural network and a descriptive decoder. Even though the proposed GFTNN doesnot include any recurrent element, it outperforms state-of-the-art models inthe task of highway trajectory prediction. For experiments and evaluation, thepublicly available datasets highD and NGSIM are used</description><author>Marion Neumeier, Andreas Tollkühn, Michael Botsch, Wolfgang Utschick</author><pubDate>Fri, 12 May 2023 13:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07416v1</guid></item><item><title>Text-driven object affordance for guiding grasp-type recognition in multimodal robot teaching</title><link>http://arxiv.org/abs/2103.00268v2</link><description>This study investigates how text-driven object affordance, which providesprior knowledge about grasp types for each object, affects image-basedgrasp-type recognition in robot teaching. The researchers created labeleddatasets of first-person hand images to examine the impact of object affordanceon recognition performance. They evaluated scenarios with real and illusoryobjects, considering mixed reality teaching conditions where visual objectinformation may be limited. The results demonstrate that object affordanceimproves image-based recognition by filtering out unlikely grasp types andemphasizing likely ones. The effectiveness of object affordance was morepronounced when there was a stronger bias towards specific grasp types for eachobject. These findings highlight the significance of object affordance inmultimodal robot teaching, regardless of whether real objects are present inthe images. Sample code is available onhttps://github.com/microsoft/arr-grasp-type-recognition.</description><author>Naoki Wake, Daichi Saito, Kazuhiro Sasabuchi, Hideki Koike, Katsushi Ikeuchi</author><pubDate>Fri, 12 May 2023 13:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.00268v2</guid></item><item><title>Local Causal Discovery for Estimating Causal Effects</title><link>http://arxiv.org/abs/2302.08070v3</link><description>Even when the causal graph underlying our data is unknown, we can useobservational data to narrow down the possible values that an average treatmenteffect (ATE) can take by (1) identifying the graph up to a Markov equivalenceclass; and (2) estimating that ATE for each graph in the class. While the PCalgorithm can identify this class under strong faithfulness assumptions, it canbe computationally prohibitive. Fortunately, only the local graph structurearound the treatment is required to identify the set of possible ATE values, afact exploited by local discovery algorithms to improve computationalefficiency. In this paper, we introduce Local Discovery using Eager ColliderChecks (LDECC), a new local causal discovery algorithm that leveragesunshielded colliders to orient the treatment's parents differently fromexisting methods. We show that there exist graphs where LDECC exponentiallyoutperforms existing local discovery algorithms and vice versa. Moreover, weshow that LDECC and existing algorithms rely on different faithfulnessassumptions, leveraging this insight to weaken the assumptions for identifyingthe set of possible ATE values.</description><author>Shantanu Gupta, David Childers, Zachary C. Lipton</author><pubDate>Fri, 12 May 2023 13:34:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08070v3</guid></item><item><title>Comparison of machine learning models applied on anonymized data with different techniques</title><link>http://arxiv.org/abs/2305.07415v1</link><description>Anonymization techniques based on obfuscating the quasi-identifiers by meansof value generalization hierarchies are widely used to achieve preset levels ofprivacy. To prevent different types of attacks against database privacy it isnecessary to apply several anonymization techniques beyond the classicalk-anonymity or $\ell$-diversity. However, the application of these methods isdirectly connected to a reduction of their utility in prediction and decisionmaking tasks. In this work we study four classical machine learning methodscurrently used for classification purposes in order to analyze the results as afunction of the anonymization techniques applied and the parameters selectedfor each of them. The performance of these models is studied when varying thevalue of k for k-anonymity and additional tools such as $\ell$-diversity,t-closeness and $\delta$-disclosure privacy are also deployed on the well-knownadult dataset.</description><author>Judith Sáinz-Pardo Díaz, Álvaro López García</author><pubDate>Fri, 12 May 2023 13:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07415v1</guid></item><item><title>MGR: Multi-generator based Rationalization</title><link>http://arxiv.org/abs/2305.04492v2</link><description>Rationalization is to employ a generator and a predictor to construct aself-explaining NLP model in which the generator selects a subset ofhuman-intelligible pieces of the input text to the following predictor.However, rationalization suffers from two key challenges, i.e., spuriouscorrelation and degeneration, where the predictor overfits the spurious ormeaningless pieces solely selected by the not-yet well-trained generator and inturn deteriorates the generator. Although many studies have been proposed toaddress the two challenges, they are usually designed separately and do nottake both of them into account. In this paper, we propose a simple yeteffective method named MGR to simultaneously solve the two problems. The keyidea of MGR is to employ multiple generators such that the occurrence stabilityof real pieces is improved and more meaningful pieces are delivered to thepredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%as compared to state-of-the-art methods. Codes are available athttps://github.com/jugechengzi/Rationalization-MGR .</description><author>Wei Liu, Haozhao Wang, Jun Wang, Ruixuan Li, Xinyang Li, Yuankai Zhang, Yang Qiu</author><pubDate>Fri, 12 May 2023 13:23:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04492v2</guid></item><item><title>Distributed Gradient Descent for Functional Learning</title><link>http://arxiv.org/abs/2305.07408v1</link><description>In recent years, different types of distributed learning schemes havereceived increasing attention for their strong advantages in handlinglarge-scale data information. In the information era, to face the big datachallenges which stem from functional data analysis very recently, we propose anovel distributed gradient descent functional learning (DGDFL) algorithm totackle functional data across numerous local machines (processors) in theframework of reproducing kernel Hilbert space. Based on integral operatorapproaches, we provide the first theoretical understanding of the DGDFLalgorithm in many different aspects in the literature. On the way ofunderstanding DGDFL, firstly, a data-based gradient descent functional learning(GDFL) algorithm associated with a single-machine model is proposed andcomprehensively studied. Under mild conditions, confidence-based optimallearning rates of DGDFL are obtained without the saturation boundary on theregularity index suffered in previous works in functional regression. Wefurther provide a semi-supervised DGDFL approach to weaken the restriction onthe maximal number of local machines to ensure optimal rates. To our bestknowledge, the DGDFL provides the first distributed iterative training approachto functional learning and enriches the stage of functional data analysis.</description><author>Zhan Yu, Jun Fan, Ding-Xuan Zhou</author><pubDate>Fri, 12 May 2023 13:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07408v1</guid></item><item><title>Two-in-One: A Model Hijacking Attack Against Text Generation Models</title><link>http://arxiv.org/abs/2305.07406v1</link><description>Machine learning has progressed significantly in various applications rangingfrom face recognition to text generation. However, its success has beenaccompanied by different attacks. Recently a new attack has been proposed whichraises both accountability and parasitic computing risks, namely the modelhijacking attack. Nevertheless, this attack has only focused on imageclassification tasks. In this work, we broaden the scope of this attack toinclude text generation and classification models, hence showing its broaderapplicability. More concretely, we propose a new model hijacking attack, Ditto,that can hijack different text classification tasks into multiple generationones, e.g., language translation, text summarization, and language modeling. Weuse a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI,and IMDB to evaluate the performance of our attacks. Our results show that byusing Ditto, an adversary can successfully hijack text generation modelswithout jeopardizing their utility.</description><author>Wai Man Si, Michael Backes, Yang Zhang, Ahmed Salem</author><pubDate>Fri, 12 May 2023 13:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07406v1</guid></item><item><title>Color Deconvolution applied to Domain Adaptation in HER2 histopathological images</title><link>http://arxiv.org/abs/2305.07404v1</link><description>Breast cancer early detection is crucial for improving patient outcomes. TheInstitut Catal\`a de la Salut (ICS) has launched the DigiPatICS project todevelop and implement artificial intelligence algorithms to assist with thediagnosis of cancer. In this paper, we propose a new approach for facing thecolor normalization problem in HER2-stained histopathological images of breastcancer tissue, posed as an style transfer problem. We combine the ColorDeconvolution technique with the Pix2Pix GAN network to present a novelapproach to correct the color variations between different HER2 stain brands.Our approach focuses on maintaining the HER2 score of the cells in thetransformed images, which is crucial for the HER2 analysis. Results demonstratethat our final model outperforms the state-of-the-art image style transfermethods in maintaining the cell classes in the transformed images and is aseffective as them in generating realistic images.</description><author>David Anglada-Rotger, Ferran Marqués, Montse Pardàs</author><pubDate>Fri, 12 May 2023 13:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07404v1</guid></item><item><title>Knowledge Refinement via Interaction Between Search Engines and Large Language Models</title><link>http://arxiv.org/abs/2305.07402v1</link><description>Information retrieval (IR) plays a crucial role in locating relevantresources from vast amounts of data, and its applications have evolved fromtraditional knowledge bases to modern search engines (SEs). The emergence oflarge language models (LLMs) has further revolutionized the field by enablingusers to interact with search systems in natural language. In this paper, weexplore the advantages and disadvantages of LLMs and SEs, highlighting theirrespective strengths in understanding user-issued queries and retrievingup-to-date information. To leverage the benefits of both paradigms whilecircumventing their limitations, we propose InteR, a novel framework thatfacilitates knowledge refinement through interaction between SEs and LLMs.InteR allows SEs to refine knowledge in query using LLM-generated summaries andenables LLMs to enhance prompts using SE-retrieved documents. This iterativerefinement process augments the inputs of SEs and LLMs, leading to moreaccurate retrieval. Experimental evaluations on two large-scale retrievalbenchmarks demonstrate that InteR achieves superior zero-shot documentretrieval performance compared to state-of-the-art methods, regardless of theuse of relevance judgement.</description><author>Jiazhan Feng, Chongyang Tao, Xiubo Geng, Tao Shen, Can Xu, Guodong Long, Dongyan Zhao, Daxin Jiang</author><pubDate>Fri, 12 May 2023 12:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07402v1</guid></item><item><title>Orthonormal Product Quantization Network for Scalable Face Image Retrieval</title><link>http://arxiv.org/abs/2107.00327v4</link><description>Existing deep quantization methods provided an efficient solution forlarge-scale image retrieval. However, the significant intra-class variationslike pose, illumination, and expressions in face images, still pose a challengefor face image retrieval. In light of this, face image retrieval requiressufficiently powerful learning metrics, which are absent in current deepquantization works. Moreover, to tackle the growing unseen identities in thequery stage, face image retrieval drives more demands regarding modelgeneralization and system scalability than general image retrieval tasks. Thispaper integrates product quantization with orthonormal constraints into anend-to-end deep learning framework to effectively retrieve face images.Specifically, a novel scheme that uses predefined orthonormal vectors ascodewords is proposed to enhance the quantization informativeness and reducecodewords' redundancy. A tailored loss function maximizes discriminabilityamong identities in each quantization subspace for both the quantized andoriginal features. An entropy-based regularization term is imposed to reducethe quantization error. Experiments are conducted on four commonly-used facedatasets under both seen and unseen identities retrieval settings. Our methodoutperforms all the compared deep hashing/quantization state-of-the-arts underboth settings. Results validate the effectiveness of the proposed orthonormalcodewords in improving models' standard retrieval performance andgeneralization ability. Combing with further experiments on two general imagedatasets, it demonstrates the broad superiority of our method for scalableimage retrieval.</description><author>Ming Zhang, Xuefei Zhe, Hong Yan</author><pubDate>Fri, 12 May 2023 12:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.00327v4</guid></item><item><title>Graph Neural Modeling of Network Flows</title><link>http://arxiv.org/abs/2209.05208v2</link><description>Network flow problems, which involve distributing traffic over a network suchthat the underlying infrastructure is used effectively, are ubiquitous intransportation and logistics. Among them, the Multi-Commodity Network Flow(MCNF) problem is of general interest, as it concerns the distribution ofmultiple flows of different sizes between several sources and sinks, whileachieving effective utilization of the links. Due to the appeal of data-drivenoptimization, these problems have increasingly been approached using graphlearning methods. In this paper, we propose a novel graph learning architecturefor network flow problems called Per-Edge Weights (PEW). This method builds ona Graph Attention Network and uses distinctly parametrized message functionsalong each link. We extensively evaluate the proposed solution through anInternet flow routing case study using $17$ Service Provider topologies and $2$routing schemes. We show that PEW yields substantial gains over architectureswhose global message function constrains the routing unnecessarily. We alsofind that an MLP is competitive with other standard architectures. Furthermore,we shed some light on the relationship between graph structure and predictiveperformance for data-driven routing of flows, an aspect that has not beenconsidered by existing work in the area.</description><author>Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi</author><pubDate>Fri, 12 May 2023 12:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.05208v2</guid></item><item><title>Learning Monocular Depth in Dynamic Environment via Context-aware Temporal Attention</title><link>http://arxiv.org/abs/2305.07397v1</link><description>The monocular depth estimation task has recently revealed encouragingprospects, especially for the autonomous driving task. To tackle the ill-posedproblem of 3D geometric reasoning from 2D monocular images, multi-framemonocular methods are developed to leverage the perspective correlationinformation from sequential temporal frames. However, moving objects such ascars and trains usually violate the static scene assumption, leading to featureinconsistency deviation and misaligned cost values, which would mislead theoptimization algorithm. In this work, we present CTA-Depth, a Context-awareTemporal Attention guided network for multi-frame monocular Depth estimation.Specifically, we first apply a multi-level attention enhancement module tointegrate multi-level image features to obtain an initial depth and poseestimation. Then the proposed CTA-Refiner is adopted to alternatively optimizethe depth and pose. During the refinement process, context-aware temporalattention (CTA) is developed to capture the global temporal-contextcorrelations to maintain the feature consistency and estimation integrity ofmoving objects. In particular, we propose a long-range geometry embedding (LGE)module to produce a long-range temporal geometry prior. Our approach achievessignificant improvements over state-of-the-art approaches on three benchmarkdatasets.</description><author>Zizhang Wu, Zhuozheng Li, Zhi-Gang Fan, Yunzhe Wu, Yuanzhu Gan, Jian Pu, Xianzhi Li</author><pubDate>Fri, 12 May 2023 12:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07397v1</guid></item><item><title>Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation</title><link>http://arxiv.org/abs/2305.07393v1</link><description>Dialogue systems for non-English languages have long been under-explored. Inthis paper, we take the first step to investigate few-shot cross-lingualtransfer learning (FS-XLT) and multitask learning (MTL) in the context ofopen-domain dialogue generation for non-English languages with limited data. Weobserved catastrophic forgetting in both FS-XLT and MTL for all 6 languages inour preliminary experiments. To mitigate the issue, we propose a simple yeteffective prompt learning approach that can preserve the multilinguality ofmultilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridgingthe gap between pre-training and fine-tuning with Fixed-prompt LM Tuning andour hand-crafted prompts. Experimental results on all 6 languages in terms ofboth automatic and human evaluations demonstrate the effectiveness of ourapproach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.</description><author>Lei Liu, Jimmy Xiangji Huang</author><pubDate>Fri, 12 May 2023 12:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07393v1</guid></item></channel></rss>