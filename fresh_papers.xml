<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 02 Jan 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Active Control of Flow over Rotating Cylinder by Multiple Jets using Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2307.12083v3</link><description>The real power of artificial intelligence appears in reinforcement learning,which is computationally and physically more sophisticated due to its dynamicnature. Rotation and injection are some of the proven ways in active flowcontrol for drag reduction on blunt bodies. In this paper, rotation will beadded to the cylinder alongside the deep reinforcement learning (DRL)algorithm, which uses multiple controlled jets to reach the maximum possibledrag suppression. Characteristics of the DRL code, including controllingparameters, their limitations, and optimization of the DRL network for use withrotation will be presented. This work will focus on optimizing the number andpositions of the jets, the sensors location, and the maximum allowed flow rateto jets in the form of the maximum allowed flow rate of each actuation and thetotal number of them per episode. It is found that combining the rotation andDRL is promising since it suppresses the vortex shedding, stabilizes the Karmanvortex street, and reduces the drag coefficient by up to 49.75%. Also, it willbe shown that having more sensors at more locations is not always a good choiceand the sensor number and location should be determined based on the need ofthe user and corresponding configuration. Also, allowing the agent to haveaccess to higher flow rates, mostly reduces the performance, except when thecylinder rotates. In all cases, the agent can keep the lift coefficient at avalue near zero, or stabilize it at a smaller number.</description><author>Kamyar Dobakhti, Jafar Ghazanfarian</author><pubDate>Mon, 01 Jan 2024 18:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12083v3</guid></item><item><title>A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?</title><link>http://arxiv.org/abs/2312.00798v2</link><description>We administer a Turing Test to AI Chatbots. We examine how Chatbots behave ina suite of classic behavioral games that are designed to elicit characteristicssuch as trust, fairness, risk-aversion, cooperation, \textit{etc.}, as well ashow they respond to a traditional Big-5 psychological survey that measurespersonality traits. ChatGPT-4 exhibits behavioral and personality traits thatare statistically indistinguishable from a random human from tens of thousandsof human subjects from more than 50 countries. Chatbots also modify theirbehavior based on previous experience and contexts ``as if'' they were learningfrom the interactions, and change their behavior in response to differentframings of the same strategic situation. Their behaviors are often distinctfrom average and modal human behaviors, in which case they tend to behave onthe more altruistic and cooperative end of the distribution. We estimate thatthey act as if they are maximizing an average of their own and partner'spayoffs.</description><author>Qiaozhu Mei, Yutong Xie, Walter Yuan, Matthew O. Jackson</author><pubDate>Mon, 01 Jan 2024 18:43:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00798v2</guid></item><item><title>ParisLuco3D: A high-quality target dataset for domain generalization of LiDAR perception</title><link>http://arxiv.org/abs/2310.16542v2</link><description>LiDAR is an essential sensor for autonomous driving by collecting precisegeometric information regarding a scene. As the performance of various LiDARperception tasks has improved, generalizations to new environments and sensorshas emerged to test these optimized models in real-world conditions.Unfortunately, the various annotation strategies of data providers complicatethe computation of cross-domain performances. This paper provides a novel dataset, ParisLuco3D, specifically designed forcross-domain evaluation to make it easier to evaluate the performance utilizingvarious source datasets. Alongside the dataset, online benchmarks for LiDARsemantic segmentation, LiDAR object detection, and LiDAR tracking are providedto ensure a fair comparison across methods. The ParisLuco3D dataset, evaluation scripts, and links to benchmarks can befound at the following website: https://npm3d.fr/parisluco3d</description><author>Jules Sanchez, Louis Soum-Fontez, Jean-Emmanuel Deschaud, Francois Goulette</author><pubDate>Mon, 01 Jan 2024 18:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16542v2</guid></item><item><title>Machine Learning for Synthetic Data Generation: A Review</title><link>http://arxiv.org/abs/2302.04062v6</link><description>Machine learning heavily relies on data, but real-world applications oftenencounter various data-related issues. These include data of poor quality,insufficient data points leading to under-fitting of machine learning models,and difficulties in data access due to concerns surrounding privacy, safety,and regulations. In light of these challenges, the concept of synthetic datageneration emerges as a promising alternative that allows for data sharing andutilization in ways that real-world data cannot facilitate. This paper presentsa comprehensive systematic review of existing studies that employ machinelearning models for the purpose of generating synthetic data. The reviewencompasses various perspectives, starting with the applications of syntheticdata generation, spanning computer vision, speech, natural language processing,healthcare, and business domains. Additionally, it explores different machinelearning methods, with particular emphasis on neural network architectures anddeep generative models. The paper also addresses the crucial aspects of privacyand fairness concerns related to synthetic data generation. Furthermore, thisstudy identifies the challenges and opportunities prevalent in this emergingfield, shedding light on the potential avenues for future research. By delvinginto the intricacies of synthetic data generation, this paper aims tocontribute to the advancement of knowledge and inspire further exploration insynthetic data generation.</description><author>Yingzhou Lu, Minjie Shen, Huazheng Wang, Xiao Wang, Capucine van Rechem, Wenqi Wei</author><pubDate>Mon, 01 Jan 2024 18:11:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04062v6</guid></item><item><title>Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning</title><link>http://arxiv.org/abs/2208.09894v3</link><description>The increasing popularity of the federated learning (FL) framework due to itssuccess in a wide range of collaborative learning tasks also induces certainsecurity concerns. Among many vulnerabilities, the risk of Byzantine attacks isof particular concern, which refers to the possibility of malicious clientsparticipating in the learning process. Hence, a crucial objective in FL is toneutralize the potential impact of Byzantine attacks and to ensure that thefinal model is trustable. It has been observed that the higher the varianceamong the clients' models/updates, the more space there is for Byzantineattacks to be hidden. As a consequence, by utilizing momentum, and thus,reducing the variance, it is possible to weaken the strength of known Byzantineattacks. The centered clipping (CC) framework has further shown that themomentum term from the previous iteration, besides reducing the variance, canbe used as a reference point to neutralize Byzantine attacks better. In thiswork, we first expose vulnerabilities of the CC framework, and introduce anovel attack strategy that can circumvent the defences of CC and other robustaggregators and reduce their test accuracy up to %33 on best-case scenarios inimage classification tasks. Then, we propose a new robust and fast defencemechanism that is effective against the proposed and other existing Byzantineattacks.</description><author>Kerem Ozfatura, Emre Ozfatura, Alptekin Kupcu, Deniz Gunduz</author><pubDate>Mon, 01 Jan 2024 17:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09894v3</guid></item><item><title>Revisiting inference after prediction</title><link>http://arxiv.org/abs/2306.13746v2</link><description>Recent work has focused on the very common practice of prediction-basedinference: that is, (i) using a pre-trained machine learning model to predictan unobserved response variable, and then (ii) conducting inference on theassociation between that predicted response and some covariates. As pointed outby Wang et al. (2020), applying a standard inferential approach in (ii) doesnot accurately quantify the association between the unobserved (as opposed tothe predicted) response and the covariates. In recent work, Wang et al. (2020)and Angelopoulos et al. (2023) propose corrections to step (ii) in order toenable valid inference on the association between the unobserved response andthe covariates. Here, we show that the method proposed by Angelopoulos et al.(2023) successfully controls the type 1 error rate and provides confidenceintervals with correct nominal coverage, regardless of the quality of thepre-trained machine learning model used to predict the unobserved response.However, the method proposed by Wang et al. (2020) provides valid inferenceonly under very strong conditions that rarely hold in practice: for instance,if the machine learning model perfectly estimates the true regression functionin the study population of interest.</description><author>Keshav Motwani, Daniela Witten</author><pubDate>Mon, 01 Jan 2024 17:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13746v2</guid></item><item><title>Transfer Learning for Causal Effect Estimation</title><link>http://arxiv.org/abs/2305.09126v3</link><description>We present a Transfer Causal Learning (TCL) framework when target and sourcedomains share the same covariate/feature spaces, aiming to improve causaleffect estimation accuracy in limited data. Limited data is very common inmedical applications, where some rare medical conditions, such as sepsis, areof interest. Our proposed method, named \texttt{$\ell_1$-TCL}, incorporates$\ell_1$ regularized TL for nuisance models (e.g., propensity score model); theTL estimator of the nuisance parameters is plugged into downstream averagecausal/treatment effect estimators (e.g., inverse probability weightedestimator). We establish non-asymptotic recovery guarantees for the\texttt{$\ell_1$-TCL} with generalized linear model (GLM) under the sparsityassumption in the high-dimensional setting, and demonstrate the empiricalbenefits of \texttt{$\ell_1$-TCL} through extensive numerical simulation forGLM and recent neural network nuisance models. Our method is subsequentlyextended to real data and generates meaningful insights consistent with medicalliterature, a case where all baseline methods fail.</description><author>Song Wei, Hanyu Zhang, Ronald Moore, Rishikesan Kamaleswaran, Yao Xie</author><pubDate>Mon, 01 Jan 2024 17:04:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09126v3</guid></item><item><title>Decision-Focused Model-based Reinforcement Learning for Reward Transfer</title><link>http://arxiv.org/abs/2304.03365v2</link><description>Decision-focused (DF) model-based reinforcement learning has recently beenintroduced as a powerful algorithm that can focus on learning the MDP dynamicsthat are most relevant for obtaining high returns. While this approachincreases the agent's performance by directly optimizing the reward, it does soby learning less accurate dynamics from a maximum likelihood perspective. Wedemonstrate that when the reward function is defined by preferences overmultiple objectives, the DF model may be sensitive to changes in the objectivepreferences.In this work, we develop the robust decision-focused (RDF)algorithm, which leverages the non-identifiability of DF solutions to learnmodels that maximize expected returns while simultaneously learning models thattransfer to changes in the preference over multiple objectives. We demonstratethe effectiveness of RDF on two synthetic domains and two healthcaresimulators, showing that it significantly improves the robustness of DF modellearning to changes in the reward function without compromising training-timereturn.</description><author>Abhishek Sharma, Sonali Parbhoo, Omer Gottesman, Finale Doshi-Velez</author><pubDate>Mon, 01 Jan 2024 16:45:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03365v2</guid></item><item><title>ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy</title><link>http://arxiv.org/abs/2308.12210v2</link><description>Differentially Private Federated Learning (DP-FL) has garnered attention as acollaborative machine learning approach that ensures formal privacy. Most DP-FLapproaches ensure DP at the record-level within each silo for cross-silo FL.However, a single user's data may extend across multiple silos, and the desireduser-level DP guarantee for such a setting remains unknown. In this study, wepresent Uldp-FL, a novel FL framework designed to guarantee user-level DP incross-silo FL where a single user's data may belong to multiple silos. Ourproposed algorithm directly ensures user-level DP through per-user weightedclipping, departing from group-privacy approaches. We provide a theoreticalanalysis of the algorithm's privacy and utility. Additionally, we enhance theutility of the proposed algorithm with an enhanced weighting strategy based onuser record distribution and design a novel private protocol that ensures noadditional information is revealed to the silos and the server. Experiments onreal-world datasets show substantial improvements in our methods inprivacy-utility trade-offs under user-level DP compared to baseline methods. Tothe best of our knowledge, our work is the first FL framework that effectivelyprovides user-level DP in the general cross-silo FL setting.</description><author>Fumiyuki Kato, Li Xiong, Shun Takagi, Yang Cao, Masatoshi Yoshikawa</author><pubDate>Mon, 01 Jan 2024 15:52:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12210v2</guid></item><item><title>COMBHelper: A Neural Approach to Reduce Search Space for Graph Combinatorial Problems</title><link>http://arxiv.org/abs/2312.09086v2</link><description>Combinatorial Optimization (CO) problems over graphs appear routinely in manyapplications such as in optimizing traffic, viral marketing in social networks,and matching for job allocation. Due to their combinatorial nature, theseproblems are often NP-hard. Existing approximation algorithms and heuristicsrely on the search space to find the solutions and become time-consuming whenthis space is large. In this paper, we design a neural method called COMBHelperto reduce this space and thus improve the efficiency of the traditional COalgorithms based on node selection. Specifically, it employs a Graph NeuralNetwork (GNN) to identify promising nodes for the solution set. This prunedsearch space is then fed to the traditional CO algorithms. COMBHelper also usesa Knowledge Distillation (KD) module and a problem-specific boosting module tobring further efficiency and efficacy. Our extensive experiments show that thetraditional CO algorithms with COMBHelper are at least 2 times faster thantheir original versions.</description><author>Hao Tian, Sourav Medya, Wei Ye</author><pubDate>Mon, 01 Jan 2024 15:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09086v2</guid></item><item><title>Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision</title><link>http://arxiv.org/abs/2309.14181v3</link><description>The rapid evolution of Multi-modality Large Language Models (MLLMs) hascatalyzed a shift in computer vision from specialized models to general-purposefoundation models. Nevertheless, there is still an inadequacy in assessing theabilities of MLLMs on low-level visual perception and understanding. To addressthis gap, we present Q-Bench, a holistic benchmark crafted to systematicallyevaluate potential abilities of MLLMs on three realms: low-level visualperception, low-level visual description, and overall visual qualityassessment. a) To evaluate the low-level perception ability, we construct theLLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equippedwith a human-asked question focusing on its low-level attributes. We thenmeasure the correctness of MLLMs on answering these questions. b) To examinethe description ability of MLLMs on low-level information, we propose theLLDescribe dataset consisting of long expert-labelled golden low-level textdescriptions on 499 images, and a GPT-involved comparison pipeline betweenoutputs of MLLMs and the golden descriptions. c) Besides these two tasks, wefurther measure their visual quality assessment ability to align with humanopinion scores. Specifically, we design a softmax-based strategy that enablesMLLMs to predict quantifiable quality scores, and evaluate them on variousexisting image quality assessment (IQA) datasets. Our evaluation across thethree abilities confirms that MLLMs possess preliminary low-level visualskills. However, these skills are still unstable and relatively imprecise,indicating the need for specific enhancements on MLLMs towards these abilities.We hope that our benchmark can encourage the research community to delve deeperto discover and enhance these untapped potentials of MLLMs. Project Page:https://q-future.github.io/Q-Bench.</description><author>Haoning Wu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Annan Wang, Chunyi Li, Wenxiu Sun, Qiong Yan, Guangtao Zhai, Weisi Lin</author><pubDate>Mon, 01 Jan 2024 14:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14181v3</guid></item><item><title>FENet: Focusing Enhanced Network for Lane Detection</title><link>http://arxiv.org/abs/2312.17163v2</link><description>Inspired by human driving focus, this research pioneers networks augmentedwith Focusing Sampling, Partial Field of View Evaluation, Enhanced FPNarchitecture and Directional IoU Loss - targeted innovations addressingobstacles to precise lane detection for autonomous driving. Experimentsdemonstrate our Focusing Sampling strategy, emphasizing vital distant detailsunlike uniform approaches, significantly boosts both benchmark and practicalcurved/distant lane recognition accuracy essential for safety. While FENetV1achieves state-of-the-art conventional metric performance via enhancementsisolating perspective-aware contexts mimicking driver vision, FENetV2 provesmost reliable on the proposed Partial Field analysis. Hence we specificallyrecommend V2 for practical lane navigation despite fractional degradation onstandard entire-image measures. Future directions include collecting on-roaddata and integrating complementary dual frameworks to further breakthroughsguided by human perception principles. Code will be made available.</description><author>Liman Wang, Hanyang Zhong</author><pubDate>Mon, 01 Jan 2024 14:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17163v2</guid></item><item><title>NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-World Video Super-Resolution</title><link>http://arxiv.org/abs/2305.14669v3</link><description>The capability of video super-resolution (VSR) to synthesize high-resolution(HR) video from ideal datasets has been demonstrated in many works. However,applying the VSR model to real-world video with unknown and complex degradationremains a challenging task. First, existing degradation metrics in most VSRmethods are not able to effectively simulate real-world noise and blur. On thecontrary, simple combinations of classical degradation are used for real-worldnoise modeling, which led to the VSR model often being violated byout-of-distribution noise. Second, many SR models focus on noise simulation andtransfer. Nevertheless, the sampled noise is monotonous and limited. To addressthe aforementioned problems, we propose a Negatives augmentation strategy forgeneralized noise modeling in Video Super-Resolution (NegVSR) task.Specifically, we first propose sequential noise generation toward real-worlddata to extract practical noise sequences. Then, the degeneration domain iswidely expanded by negative augmentation to build up various yet challengingreal-world noise sets. We further propose the augmented negative guidance lossto learn robust features among augmented negatives effectively. Extensiveexperiments on real-world datasets (e.g., VideoLQ and FLIR) show that ourmethod outperforms state-of-the-art methods with clear margins, especially invisual quality. Project page is available at: https://negvsr.github.io/.</description><author>Yexing Song, Meilin Wang, Zhijing Yang, Xiaoyu Xian, Yukai Shi</author><pubDate>Mon, 01 Jan 2024 14:40:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14669v3</guid></item><item><title>ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation</title><link>http://arxiv.org/abs/2312.13108v2</link><description>Graphical User Interface (GUI) automation holds significant promise forassisting users with complex tasks, thereby boosting human productivity.Existing works leveraging Large Language Model (LLM) or LLM-based AI agentshave shown capabilities in automating tasks on Android and Web platforms.However, these tasks are primarily aimed at simple device usage andentertainment operations. This paper presents a novel benchmark, AssistGUI, toevaluate whether models are capable of manipulating the mouse and keyboard onthe Windows platform in response to user-requested tasks. We carefullycollected a set of 100 tasks from nine widely-used software applications, suchas, After Effects and MS Word, each accompanied by the necessary project filesfor better evaluation. Moreover, we propose an advanced Actor-Critic EmbodiedAgent framework, which incorporates a sophisticated GUI parser driven by anLLM-agent and an enhanced reasoning mechanism adept at handling lengthyprocedural tasks. Our experimental results reveal that our GUI Parser andReasoning mechanism outshine existing methods in performance. Nevertheless, thepotential remains substantial, with the best model attaining only a 46% successrate on our benchmark. We conclude with a thorough analysis of the currentmethods' limitations, setting the stage for future breakthroughs in thisdomain.</description><author>Difei Gao, Lei Ji, Zechen Bai, Mingyu Ouyang, Peiran Li, Dongxing Mao, Qinchen Wu, Weichen Zhang, Peiyi Wang, Xiangwu Guo, Hengxu Wang, Luowei Zhou, Mike Zheng Shou</author><pubDate>Mon, 01 Jan 2024 14:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13108v2</guid></item><item><title>Asynchronous Evolution of Deep Neural Network Architectures</title><link>http://arxiv.org/abs/2308.04102v3</link><description>Many evolutionary algorithms (EAs) take advantage of parallel evaluation ofcandidates. However, if evaluation times vary significantly, many worker nodes(i.e.,\ compute clients) are idle much of the time, waiting for the nextgeneration to be created. Evolutionary neural architecture search (ENAS), aclass of EAs that optimizes the architecture and hyperparameters of deep neuralnetworks, is particularly vulnerable to this issue. This paper proposes ageneric asynchronous evaluation strategy (AES) that is then adapted to workwith ENAS. AES increases throughput by maintaining a queue of up to $K$individuals ready to be sent to the workers for evaluation and proceeding tothe next generation as soon as $M&lt;&lt;K$ individuals have been evaluated. Asuitable value for $M$ is determined experimentally, balancing diversity andefficiency. To showcase the generality and power of AES, it was first evaluatedin eight-line sorting network design (a single-population optimization taskwith limited evaluation-time variability), achieving an over two-fold speedup.Next, it was evaluated in 11-bit multiplexer design (a single-populationdiscovery task with extended variability), where a 14-fold speedup wasobserved. It was then scaled up to ENAS for image captioning (amulti-population open-ended-optimization task), resulting in an over two-foldspeedup. In all problems, a multifold performance improvement was observed,suggesting that AES is a promising method for parallelizing the evolution ofcomplex systems with long and variable evaluation times, such as those in ENAS.</description><author>Jason Liang, Hormoz Shahrzad, Risto Miikkulainen</author><pubDate>Mon, 01 Jan 2024 14:16:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04102v3</guid></item><item><title>UDTIRI: An Online Open-Source Intelligent Road Inspection Benchmark Suite</title><link>http://arxiv.org/abs/2304.08842v3</link><description>In the nascent domain of urban digital twins (UDT), the prospects forleveraging cutting-edge deep learning techniques are vast and compelling.Particularly within the specialized area of intelligent road inspection (IRI),a noticeable gap exists, underscored by the current dearth of dedicatedresearch efforts and the lack of large-scale well-annotated datasets. To fosteradvancements in this burgeoning field, we have launched an online open-sourcebenchmark suite, referred to as UDTIRI. Along with this article, we introducethe road pothole detection task, the first online competition published withinthis benchmark suite. This task provides a well-annotated dataset, comprising1,000 RGB images and their pixel/instance-level ground-truth annotations,captured in diverse real-world scenarios under different illumination andweather conditions. Our benchmark provides a systematic and thorough evaluationof state-of-the-art object detection, semantic segmentation, and instancesegmentation networks, developed based on either convolutional neural networksor Transformers. We anticipate that our benchmark will serve as a catalyst forthe integration of advanced UDT techniques into IRI. By providing algorithmswith a more comprehensive understanding of diverse road conditions, we seek tounlock their untapped potential and foster innovation in this critical domain.</description><author>Sicen Guo, Jiahang Li, Yi Feng, Dacheng Zhou, Denghuang Zhang, Chen Chen, Shuai Su, Xingyi Zhu, Qijun Chen, Rui Fan</author><pubDate>Mon, 01 Jan 2024 13:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08842v3</guid></item><item><title>Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large Neighborhood Search</title><link>http://arxiv.org/abs/2312.16767v2</link><description>Anytime multi-agent path finding (MAPF) is a promising approach to scalablepath optimization in large-scale multi-agent systems. State-of-the-art anytimeMAPF is based on Large Neighborhood Search (LNS), where a fast initial solutionis iteratively optimized by destroying and repairing a fixed number of parts,i.e., the neighborhood, of the solution, using randomized destroy heuristicsand prioritized planning. Despite their recent success in various MAPFinstances, current LNS-based approaches lack exploration and flexibility due togreedy optimization with a fixed neighborhood size which can lead to lowquality solutions in general. So far, these limitations have been addressedwith extensive prior effort in tuning or offline machine learning beyond actualplanning. In this paper, we focus on online learning in LNS and proposeBandit-based Adaptive LArge Neighborhood search Combined with Exploration(BALANCE). BALANCE uses a bi-level multi-armed bandit scheme to adapt theselection of destroy heuristics and neighborhood sizes on the fly duringsearch. We evaluate BALANCE on multiple maps from the MAPF benchmark set andempirically demonstrate cost improvements of at least 50% compared tostate-of-the-art anytime MAPF in large-scale scenarios. We find that ThompsonSampling performs particularly well compared to alternative multi-armed banditalgorithms.</description><author>Thomy Phan, Taoan Huang, Bistra Dilkina, Sven Koenig</author><pubDate>Mon, 01 Jan 2024 13:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16767v2</guid></item><item><title>MABViT -- Modified Attention Block Enhances Vision Transformers</title><link>http://arxiv.org/abs/2312.01324v2</link><description>Recent studies have demonstrated the effectiveness of Gated Linear Units(GLU) in enhancing transformer models, particularly in Large Language Models(LLMs). Additionally, utilizing a parallel configuration within eachTransformer block rather than the conventional serialized method has beenrevealed to accelerate the training of LLMs without significantly impactingperformance. However, when the MLP and attention block were run in parallel forthe image classification task, we observed a noticeable decline in performance.We propose a novel transformer variant that integrates non-linearity within theattention block to tackle this problem. We implemented the GLU-based activationfunction on the Value tensor, and this new technique surpasses the currentstate-of-the-art S/16 variant of Vision Transformers by 0.6% on the ImageNet-1Kdataset while utilizing fewer parameters. It also supersedes the B/16 variantwhile using only half the parameters. Furthermore, we provide results with theGELU activation function variant to confirm our assertions. Lastly, we showcasethat the MABViT variants exhibit greater potential when utilized in deeptransformers compared to the standard architecture.</description><author>Mahesh Ramesh, Aswinkumar Ramkumar</author><pubDate>Mon, 01 Jan 2024 13:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01324v2</guid></item><item><title>Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis</title><link>http://arxiv.org/abs/2311.15218v3</link><description>The application of Machine learning to finance has become a familiarapproach, even more so in stock market forecasting. The stock market is highlyvolatile, and huge amounts of data are generated every minute globally. Theextraction of effective intelligence from this data is of critical importance.However, a collaboration of numerical stock data with qualitative text data canbe a challenging task. In this work, we accomplish this by providing anunprecedented, publicly available dataset with technical and fundamental dataand sentiment that we gathered from news archives, TV news captions, radiotranscripts, tweets, daily financial newspapers, etc. The text data entriesused for sentiment extraction total more than 1.4 Million. The dataset consistsof daily entries from January 2018 to December 2022 for eight companiesrepresenting diverse industrial sectors and the Dow Jones Industrial Average(DJIA) as a whole. Holistic Fundamental and Technical data is provided trainingready for Model learning and deployment. Most importantly, the data generatedcould be used for incremental online learning with real-time data pointsretrieved daily since no stagnant data was utilized. All the data was retiredfrom APIs or self-designed robust information retrieval technologies. Theseadaptable technologies facilitate data extraction for any stock. Moreover, theutilization of Spearman's rank correlation over real-time data, linking stockreturns with sentiment analysis has produced noteworthy results for the DJIA,achieving accuracy levels surpassing 60\%. The dataset is made available athttps://github.com/batking24/Huge-Stock-Dataset.</description><author>Sai Akash Bathini, Dagli Cihan</author><pubDate>Mon, 01 Jan 2024 13:26:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15218v3</guid></item><item><title>When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions</title><link>http://arxiv.org/abs/2306.15546v2</link><description>The intersection of the Foundation Model (FM) and Federated Learning (FL)provides mutual benefits, presents a unique opportunity to unlock newpossibilities in AI research, and address critical challenges in AI andreal-world applications. FL expands the availability of data for FMs andenables computation sharing, distributing the training process and reducing theburden on FL participants. It promotes collaborative FM development,democratizing the process and fostering inclusivity and innovation. On theother hand, FM, with its enormous size, pre-trained knowledge, and exceptionalperformance, serves as a robust starting point for FL, facilitating fasterconvergence and better performance under non-iid data. Additionally, leveragingFM to generate synthetic data enriches data diversity, reduces overfitting, andpreserves privacy. By examining the interplay between FL and FM, this paperaims to deepen the understanding of their synergistic relationship,highlighting the motivations, challenges, and future directions. Through anexploration of the challenges faced by FL and FM individually and theirinterconnections, we aim to inspire future research directions that can furtherenhance both fields, driving advancements and propelling the development ofprivacy-preserving and scalable AI systems.</description><author>Weiming Zhuang, Chen Chen, Lingjuan Lyu</author><pubDate>Mon, 01 Jan 2024 13:07:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15546v2</guid></item><item><title>Towards Full-scene Domain Generalization in Multi-agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving</title><link>http://arxiv.org/abs/2311.16754v2</link><description>Collaborative perception has recently gained significant attention inautonomous driving, improving perception quality by enabling the exchange ofadditional information among vehicles. However, deploying collaborativeperception systems can lead to domain shifts due to diverse environmentalconditions and data heterogeneity among connected and autonomous vehicles(CAVs). To address these challenges, we propose a unified domain generalizationframework applicable in both training and inference stages of collaborativeperception. In the training phase, we introduce an Amplitude Augmentation(AmpAug) method to augment low-frequency image variations, broadening themodel's ability to learn across various domains. We also employ ameta-consistency training scheme to simulate domain shifts, optimizing themodel with a carefully designed consistency loss to encourage domain-invariantrepresentations. In the inference phase, we introduce an intra-system domainalignment mechanism to reduce or potentially eliminate the domain discrepancyamong CAVs prior to inference. Comprehensive experiments substantiate theeffectiveness of our method in comparison with the existing state-of-the-artworks. Code will be released at https://github.com/DG-CAVs/DG-CoPerception.git.</description><author>Senkang Hu, Zhengru Fang, Xianhao Chen, Yuguang Fang, Sam Kwong</author><pubDate>Mon, 01 Jan 2024 12:27:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16754v2</guid></item><item><title>DiffusionLight: Light Probes for Free by Painting a Chrome Ball</title><link>http://arxiv.org/abs/2312.09168v2</link><description>We present a simple yet effective technique to estimate lighting in a singleinput image. Current techniques rely heavily on HDR panorama datasets to trainneural networks to regress an input with limited field-of-view to a fullenvironment map. However, these approaches often struggle with real-world,uncontrolled settings due to the limited diversity and size of their datasets.To address this problem, we leverage diffusion models trained on billions ofstandard images to render a chrome ball into the input image. Despite itssimplicity, this task remains challenging: the diffusion models often insertincorrect or inconsistent objects and cannot readily generate images in HDRformat. Our research uncovers a surprising relationship between the appearanceof chrome balls and the initial diffusion noise map, which we utilize toconsistently generate high-quality chrome balls. We further fine-tune an LDRdifusion model (Stable Diffusion XL) with LoRA, enabling it to perform exposurebracketing for HDR light estimation. Our method produces convincing lightestimates across diverse settings and demonstrates superior generalization toin-the-wild scenarios.</description><author>Pakkapon Phongthawee, Worameth Chinchuthakun, Nontaphat Sinsunthithet, Amit Raj, Varun Jampani, Pramook Khungurn, Supasorn Suwajanakorn</author><pubDate>Mon, 01 Jan 2024 10:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09168v2</guid></item><item><title>Estimation-of-Distribution Algorithms for Multi-Valued Decision Variables</title><link>http://arxiv.org/abs/2302.14420v2</link><description>The majority of research on estimation-of-distribution algorithms (EDAs)concentrates on pseudo-Boolean optimization and permutation problems, leavingthe domain of EDAs for problems in which the decision variables can take morethan two values, but which are not permutation problems, mostly unexplored. Torender this domain more accessible, we propose a natural way to extend theknown univariate EDAs to this setting. Different from a naive reduction to thebinary case, our approach avoids additional constraints. Since understanding genetic drift is crucial for an optimal parameter choice,we extend the known quantitative analysis of genetic drift to EDAs formulti-valued variables. Roughly speaking, when the variables take $r$ differentvalues, the time for genetic drift to become significant is $r$ times shorterthan in the binary case. Consequently, the update strength of the probabilisticmodel has to be chosen $r$ times lower now. To investigate how desired model updates take place in this framework, weundertake a mathematical runtime analysis on the $r$-valued \leadingonesproblem. We prove that with the right parameters, the multi-valued UMDA solvesthis problem efficiently in $O(r\ln(r)^2 n^2 \ln(n))$ function evaluations.This bound is nearly tight as our lower bound $\Omega(r\ln(r) n^2 \ln(n))$shows. Overall, our work shows that our good understanding of binary EDAs naturallyextends to the multi-valued setting, and it gives advice on how to set the mainparameters of multi-values EDAs.</description><author>Firas Ben Jedidia, Benjamin Doerr, Martin S. Krejca</author><pubDate>Mon, 01 Jan 2024 10:15:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14420v2</guid></item><item><title>Mean-field Underdamped Langevin Dynamics and its Space-Time Discretization</title><link>http://arxiv.org/abs/2312.16360v2</link><description>We propose a new method called the N-particle underdamped Langevin algorithmfor optimizing a special class of non-linear functionals defined over the spaceof probability measures. Examples of problems with this formulation includetraining neural networks in the mean-field regime, density estimation, andkernel Stein discrepancy minimization. Our algorithm is based on a novelspace-time discretization of the mean-field underdamped Langevin dynamics, forwhich we provide a new, fast mixing guarantee. In addition, we demonstrate thatour algorithm converges globally in total variation distance, bridging thetheoretical gap between the dynamics and its practical implementation.</description><author>Qiang Fu, Ashia Wilson</author><pubDate>Mon, 01 Jan 2024 09:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16360v2</guid></item><item><title>Online Boosting Adaptive Learning under Concept Drift for Multistream Classification</title><link>http://arxiv.org/abs/2312.10841v2</link><description>Multistream classification poses significant challenges due to the necessityfor rapid adaptation in dynamic streaming processes with concept drift. Despitethe growing research outcomes in this area, there has been a notable oversightregarding the temporal dynamic relationships between these streams, leading tothe issue of negative transfer arising from irrelevant data. In this paper, wepropose a novel Online Boosting Adaptive Learning (OBAL) method thateffectively addresses this limitation by adaptively learning the dynamiccorrelation among different streams. Specifically, OBAL operates in adual-phase mechanism, in the first of which we design an Adaptive COvariateShift Adaptation (AdaCOSA) algorithm to construct an initialized ensemble modelusing archived data from various source streams, thus mitigating the covariateshift while learning the dynamic correlations via an adaptive re-weightingstrategy. During the online process, we employ a Gaussian Mixture Model-basedweighting mechanism, which is seamlessly integrated with the acquiredcorrelations via AdaCOSA to effectively handle asynchronous drift. Thisapproach significantly improves the predictive performance and stability of thetarget stream. We conduct comprehensive experiments on several synthetic andreal-world data streams, encompassing various drifting scenarios and types. Theresults clearly demonstrate that OBAL achieves remarkable advancements inaddressing multistream classification problems by effectively leveragingpositive knowledge derived from multiple sources.</description><author>En Yu, Jie Lu, Bin Zhang, Guangquan Zhang</author><pubDate>Mon, 01 Jan 2024 09:39:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10841v2</guid></item><item><title>An attempt to generate new bridge types from latent space of variational autoencoder</title><link>http://arxiv.org/abs/2311.03380v2</link><description>Try to generate new bridge types using generative artificial intelligencetechnology. The grayscale images of the bridge facade with the change ofcomponent width was rendered by 3dsMax animation software, and then the OpenCVmodule performed an appropriate amount of geometric transformation (rotation,horizontal scale, vertical scale) to obtain the image dataset of three-spanbeam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based onPython programming language, TensorFlow and Keras deep learning platformframework, variational autoencoder was constructed and trained, andlow-dimensional bridge-type latent space that is convenient for vectoroperations was obtained. Variational autoencoder can combine two bridge typeson the basis of the original of human into one that is a new bridge type.Generative artificial intelligence technology can assist bridge designers inbridge-type innovation, and can be used as copilot.</description><author>Hongjun Zhang</author><pubDate>Mon, 01 Jan 2024 09:26:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03380v2</guid></item><item><title>Aurora:Activating Chinese chat capability for Mixtral-8x7B sparse Mixture-of-Experts through Instruction-Tuning</title><link>http://arxiv.org/abs/2312.14557v2</link><description>Existing research has demonstrated that refining large language models (LLMs)through the utilization of machine-generated instruction-following dataempowers these models to exhibit impressive zero-shot capabilities for noveltasks, without requiring human-authored instructions. In this paper, wesystematically investigate, preprocess, and integrate three Chineseinstruction-following datasets with the aim of enhancing the Chineseconversational capabilities of Mixtral-8x7B sparse Mixture-of-Experts model.Through instruction fine-tuning on this carefully processed dataset, wesuccessfully construct the Mixtral-8x7B sparse Mixture-of-Experts model named"Aurora." To assess the performance of Aurora, we utilize three widelyrecognized benchmark tests: C-Eval, MMLU, and CMMLU. Empirical studies validatethe effectiveness of instruction fine-tuning applied to Mixtral-8x7B sparseMixture-of-Experts model. This work is pioneering in the execution ofinstruction fine-tuning on a sparse expert-mixed model, marking a significantbreakthrough in enhancing the capabilities of this model architecture. Ourcode, data and model are publicly available at https://github.com/WangRongsheng/Aurora</description><author>Rongsheng Wang, Haoming Chen, Ruizhe Zhou, Yaofei Duan, Kunyan Cai, Han Ma, Jiaxi Cui, Jian Li, Patrick Cheong-Iao Pang, Yapeng Wang, Tao Tan</author><pubDate>Mon, 01 Jan 2024 09:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14557v2</guid></item><item><title>Normalization of Lithuanian Text Using Regular Expressions</title><link>http://arxiv.org/abs/2312.17660v2</link><description>Text Normalization is an integral part of any text-to-speech synthesissystem. In a natural language text, there are elements such as numbers, dates,abbreviations, etc. that belong to other semiotic classes. They are callednon-standard words (NSW) and need to be expanded into ordinary words. For thispurpose, it is necessary to identify the semiotic class of each NSW. Thetaxonomy of semiotic classes adapted to the Lithuanian language is presented inthe work. Sets of rules are created for detecting and expanding NSWs based onregular expressions. Experiments with three completely different data sets wereperformed and the accuracy was assessed. Causes of errors are explained andrecommendations are given for the development of text normalization rules.</description><author>Pijus Kasparaitis</author><pubDate>Mon, 01 Jan 2024 08:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17660v2</guid></item><item><title>VariabilityTrack:Multi-Object Tracking with Variable Speed Object Movement</title><link>http://arxiv.org/abs/2203.06424v3</link><description>Multi-object tracking (MOT) aims at estimating bounding boxes and identitiesof objects in videos. Most methods can be roughly classified astracking-by-detection and joint-detection-association paradigms. Although thelatter has elicited more attention and demonstrates comparable performancerelative than the former, we claim that the tracking-by-detection paradigm isstill the optimal solution in terms of tracking accuracy,such asByteTrack,which achieves 80.3 MOTA, 77.3 IDF1 and 63.1 HOTA on the test set ofMOT17 with 30 FPS running speed on a single V100 GPU.However, under complexperspectives such as vehicle and UAV acceleration, the performance of such atracker using uniform Kalman filter will be greatly affected, resulting intracking loss.In this paper, we propose a variable speed Kalman filteralgorithm based on environmental feedback and improve the matching process,which can greatly improve the tracking effect in complex variable speed sceneswhile maintaining high tracking accuracy in relatively static scenes.Eventually, higher MOTA and IDF1 results can be achieved on MOT17 test set thanByteTrack</description><author>Run Luo, JinLin Wei, Qiao Lin</author><pubDate>Mon, 01 Jan 2024 08:50:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.06424v3</guid></item><item><title>Poker Hand History File Format Specification</title><link>http://arxiv.org/abs/2312.11753v2</link><description>This paper introduces the Poker Hand History (PHH) file format, designed tostandardize the recording of poker hands across different game variants.Despite poker's widespread popularity in the mainstream culture as a mind sportand its prominence in the field of artificial intelligence (AI) research as abenchmark for imperfect information AI agents, it lacks a consistent formatthat humans can use to document poker hands across different variants that canalso easily be parsed by machines. To address this gap in the literature, wepropose the PHH format which provides a concise human-readable machine-friendlyrepresentation of hand history that comprehensively captures various details ofthe hand, ranging from initial game parameters and actions to contextualparameters including but not limited to the venue, players, and time controlinformation. In the supplementary, we provide over 10,000 hands covering 11different variants in the PHH format. Building on our previous work onPokerKit, a premier poker hand simulation tool, we demonstrate the usages ofour open-source Python implementation of the PHH parser. The source code of theparser is available on GitHub: https://github.com/uoftcprg/pokerkit</description><author>Juho Kim</author><pubDate>Mon, 01 Jan 2024 06:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11753v2</guid></item><item><title>Wikiformer: Pre-training with Structured Information of Wikipedia for Ad-hoc Retrieval</title><link>http://arxiv.org/abs/2312.10661v2</link><description>With the development of deep learning and natural language processingtechniques, pre-trained language models have been widely used to solveinformation retrieval (IR) problems. Benefiting from the pre-training andfine-tuning paradigm, these models achieve state-of-the-art performance. Inprevious works, plain texts in Wikipedia have been widely used in thepre-training stage. However, the rich structured information in Wikipedia, suchas the titles, abstracts, hierarchical heading (multi-level title) structure,relationship between articles, references, hyperlink structures, and thewriting organizations, has not been fully explored. In this paper, we devisefour pre-training objectives tailored for IR tasks based on the structuredknowledge of Wikipedia. Compared to existing pre-training methods, our approachcan better capture the semantic knowledge in the training corpus by leveragingthe human-edited structured data from Wikipedia. Experimental results onmultiple IR benchmark datasets show the superior performance of our model inboth zero-shot and fine-tuning settings compared to existing strong retrievalbaselines. Besides, experimental results in biomedical and legal domainsdemonstrate that our approach achieves better performance in vertical domainscompared to previous models, especially in scenarios where long text similaritymatching is needed.</description><author>Weihang Su, Qingyao Ai, Xiangsheng Li, Jia Chen, Yiqun Liu, Xiaolong Wu, Shengluan Hou</author><pubDate>Mon, 01 Jan 2024 06:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10661v2</guid></item><item><title>Lightweight texture transfer based on texture feature preset</title><link>http://arxiv.org/abs/2306.16846v3</link><description>In the task of texture transfer, reference texture images typically exhibithighly repetitive texture features, and the texture transfer results fromdifferent content images under the same style also share remarkably similartexture patterns. Encoding such highly similar texture features often requiresdeep layers and a large number of channels, making it is also the main sourceof the entire model's parameter count and computational load, and inferencetime. We propose a lightweight texture transfer based on texture feature preset(TFP). TFP takes full advantage of the high repetitiveness of texture featuresby providing preset universal texture feature maps for a given style. Thesepreset feature maps can be fused and decoded directly with shallow colortransfer feature maps of any content to generate texture transfer results,thereby avoiding redundant texture information from being encoded repeatedly.The texture feature map we preset is encoded through noise input images withconsistent distribution (standard normal distribution). This consistent inputdistribution can completely avoid the problem of texture transferdifferentiation, and by randomly sampling different noise inputs, we can obtaindifferent texture features and texture transfer results under the samereference style. Compared to state-of-the-art techniques, our TFP not onlyproduces visually superior results but also reduces the model size by 3.2-3538times and speeds up the process by 1.8-5.6 times.</description><author>ShiQi Jiang</author><pubDate>Mon, 01 Jan 2024 06:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16846v3</guid></item><item><title>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</title><link>http://arxiv.org/abs/2311.04014v3</link><description>This paper introduces a novel operator, termed the Y operator, to elevatecontrol performance in Actor-Critic(AC) based reinforcement learning forsystems governed by stochastic differential equations(SDEs). The Y operatoringeniously integrates the stochasticity of a class of child-mother system intothe Critic network's loss function, yielding substantial advancements in thecontrol performance of RL algorithms.Additionally, the Y operator elegantlyreformulates the challenge of solving partial differential equations for thestate-value function into a parallel problem for the drift and diffusionfunctions within the system's SDEs.A rigorous mathematical proof confirms theoperator's validity.This transformation enables the Y Operator-basedReinforcement Learning(YORL) framework to efficiently tackle optimal controlproblems in both model-based and data-driven systems.The superiority of YORL isdemonstrated through linear and nonlinear numerical examples showing itsenhanced performance over existing methods post convergence.</description><author>Cheng Yin, Yi Chen</author><pubDate>Mon, 01 Jan 2024 06:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04014v3</guid></item><item><title>Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond</title><link>http://arxiv.org/abs/2212.10772v5</link><description>This paper presents a comprehensive survey of low-light image and videoenhancement, addressing two primary challenges in the field. The firstchallenge is the prevalence of mixed over-/under-exposed images, which are notadequately addressed by existing methods. In response, this work introduces twoenhanced variants of the SICE dataset: SICE_Grad and SICE_Mix, designed tobetter represent these complexities. The second challenge is the scarcity ofsuitable low-light video datasets for training and testing. To address this,the paper introduces the Night Wenzhou dataset, a large-scale, high-resolutionvideo collection that features challenging fast-moving aerial scenes andstreetscapes with varied illuminations and degradation. This study alsoconducts an extensive analysis of key techniques and performs comparativeexperiments using the proposed and current benchmark datasets. The surveyconcludes by highlighting emerging applications, discussing unresolvedchallenges, and suggesting future research directions within the LLIEcommunity. The datasets are available athttps://github.com/ShenZheng2000/LLIE_Survey.</description><author>Shen Zheng, Yiling Ma, Jinqian Pan, Changjie Lu, Gaurav Gupta</author><pubDate>Mon, 01 Jan 2024 05:40:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10772v5</guid></item><item><title>Passive Inference Attacks on Split Learning via Adversarial Regularization</title><link>http://arxiv.org/abs/2310.10483v3</link><description>Split Learning (SL) has emerged as a practical and efficient alternative totraditional federated learning. While previous attempts to attack SL have oftenrelied on overly strong assumptions or targeted easily exploitable models, weseek to develop more practical attacks. We introduce SDAR, a novel attackframework against SL with an honest-but-curious server. SDAR leveragesauxiliary data and adversarial regularization to learn a decodable simulator ofthe client's private model, which can effectively infer the client's privatefeatures under the vanilla SL, and both features and labels under the U-shapedSL. We perform extensive experiments in both configurations to validate theeffectiveness of our proposed attacks. Notably, in challenging but practicalscenarios where existing passive attacks struggle to reconstruct the client'sprivate data effectively, SDAR consistently achieves attack performancecomparable to active attacks. On CIFAR-10, at the deep split level of 7, SDARachieves private feature reconstruction with less than 0.025 mean squared errorin both the vanilla and the U-shaped SL, and attains a label inference accuracyof over 98% in the U-shaped setting, while existing attacks fail to producenon-trivial results.</description><author>Xiaochen Zhu, Xinjian Luo, Yuncheng Wu, Yangfan Jiang, Xiaokui Xiao, Beng Chin Ooi</author><pubDate>Mon, 01 Jan 2024 05:33:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10483v3</guid></item><item><title>Large Language Model Situational Awareness Based Planning</title><link>http://arxiv.org/abs/2312.16127v2</link><description>This work pioneers evaluating emergent planning capabilities based onsituational awareness in large language models. We contribute (i) novelbenchmarks and metrics for standardized assessment; (ii) a unique dataset tospur progress; and (iii) demonstrations that prompting and multi-agent schemessignificantly enhance planning performance in context-sensitive planning tasks.Positioning this within a situated agent and automated planning research, wehighlight inherent reliability challenges--efficiently mapping world states toactions without environmental guidance remains open despite simulated domainadvances. Although out-of-scope, limitations around validation methodology anddata availability indicate exciting directions, including fine-tuning onexpanded planning corpora and optimizations for triggering fast latentplanning. By conclusively demonstrating current methods' promise andlimitations via rigorous comparison, we catalyze investigating reliablegoal-directed reasoning for situated agents.</description><author>Liman Wang, Hanyang Zhong</author><pubDate>Mon, 01 Jan 2024 04:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16127v2</guid></item><item><title>Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale</title><link>http://arxiv.org/abs/2312.07586v2</link><description>Popular guidance for denoising diffusion probabilistic model (DDPM) linearlycombines distinct conditional models together to provide enhanced control oversamples. However, this approach overlooks nonlinear effects that becomesignificant when guidance scale is large. To address this issue, we proposecharacteristic guidance, a sampling method that provides first-principlenon-linear correction for classifier-free guided DDPMs. Such correction forcesthe guided DDPMs to respect the Fokker-Planck equation of their underlyingdiffusion process, in a way that is training-free, derivative-free, andcompatible with existing sampling methods. Experiments show that characteristicguidance enhances control and reduces color and exposure issues in imagegeneration, proving effective in diverse applications ranging from latent spacesampling to solving physics problems like magnet phase transitions.</description><author>Candi Zheng, Yuan Lan</author><pubDate>Mon, 01 Jan 2024 04:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07586v2</guid></item><item><title>Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation</title><link>http://arxiv.org/abs/2312.15112v2</link><description>Knowledge distillation aims to train a compact student network using softsupervision from a larger teacher network and hard supervision from groundtruths. However, determining an optimal knowledge fusion ratio that balancesthese supervisory signals remains challenging. Prior methods generally resortto a constant or heuristic-based fusion ratio, which often falls short of aproper balance. In this study, we introduce a novel adaptive method forlearning a sample-wise knowledge fusion ratio, exploiting both the correctnessof teacher and student, as well as how well the student mimics the teacher oneach sample. Our method naturally leads to the intra-sample trilateralgeometric relations among the student prediction ($S$), teacher prediction($T$), and ground truth ($G$). To counterbalance the impact of outliers, wefurther extend to the inter-sample relations, incorporating the teacher'sglobal average prediction $\bar{T}$ for samples within the same class. A simpleneural network then learns the implicit mapping from the intra- andinter-sample relations to an adaptive, sample-wise knowledge fusion ratio in abilevel-optimization manner. Our approach provides a simple, practical, andadaptable solution for knowledge distillation that can be employed acrossvarious architectures and model sizes. Extensive experiments demonstrateconsistent improvements over other loss re-weighting methods on imageclassification, attack detection, and click-through rate prediction.</description><author>Chengming Hu, Haolun Wu, Xuan Li, Chen Ma, Xi Chen, Jun Yan, Boyu Wang, Xue Liu</author><pubDate>Mon, 01 Jan 2024 03:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15112v2</guid></item><item><title>InRank: Incremental Low-Rank Learning</title><link>http://arxiv.org/abs/2306.11250v2</link><description>The theory of greedy low-rank learning (GLRL) aims to explain the impressivegeneralization capabilities of deep learning. It proves that stochasticgradient-based training implicitly regularizes neural networks towards low-ranksolutions through a gradual increase of the rank during training. However,there is a gap between theory and practice since GLRL requires an infinitesimalinitialization of the weights, which is not practical due to the fact that itis a saddle point. In this work, we remove the assumption of infinitesimalinitialization by focusing on cumulative weight updates. We prove thecumulative weight updates follow an incremental low-rank trajectory forarbitrary orthogonal initialization of weights in a three-layer linear network.Empirically, we demonstrate that our theory holds on a broad range of neuralnetworks (e.g., transformers) and standard training algorithms (e.g., SGD,Adam). However, existing training algorithms do not exploit the low-rankproperty to improve computational efficiency as the networks are notparameterized in low-rank. To remedy this, we design a new training algorithmIncremental Low-Rank Learning (InRank), which explicitly expresses cumulativeweight updates as low-rank matrices while incrementally augmenting their ranksduring training. We evaluate InRank on GPT-2, and our results indicate thatInRank achieves comparable prediction performance as the full-rank counterpartwhile requiring at most 33% of the total ranks throughout training. We alsopropose an efficient version of InRank that achieves a reduction of 37% intotal training time and 36% in model size when training GPT-medium onWikiText-103 from scratch.</description><author>Jiawei Zhao, Yifei Zhang, Beidi Chen, Florian Schfer, Anima Anandkumar</author><pubDate>Mon, 01 Jan 2024 03:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11250v2</guid></item><item><title>Data Valuation for Vertical Federated Learning: A Model-free and Privacy-preserving Method</title><link>http://arxiv.org/abs/2112.08364v2</link><description>Vertical Federated learning (VFL) is a promising paradigm for predictiveanalytics, empowering an organization (i.e., task party) to enhance itspredictive models through collaborations with multiple data suppliers (i.e.,data parties) in a decentralized and privacy-preserving way. Despite thefast-growing interest in VFL, the lack of effective and secure tools forassessing the value of data owned by data parties hinders the application ofVFL in business contexts. In response, we propose FedValue, aprivacy-preserving, task-specific but model-free data valuation method for VFL,which consists of a data valuation metric and a federated computation method.Specifically, we first introduce a novel data valuation metric, namelyMShapley-CMI. The metric evaluates a data party's contribution to a predictiveanalytics task without the need of executing a machine learning model, makingit well-suited for real-world applications of VFL. Next, we develop aninnovative federated computation method that calculates the MShapley-CMI valuefor each data party in a privacy-preserving manner. Extensive experimentsconducted on six public datasets validate the efficacy of FedValue for datavaluation in the context of VFL. In addition, we illustrate the practicalutility of FedValue with a case study involving federated movierecommendations.</description><author>Xiao Han, Leye Wang, Junjie Wu, Xiao Fang</author><pubDate>Mon, 01 Jan 2024 03:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.08364v2</guid></item><item><title>Exploring AI-Generated Text in Student Writing: How Does AI Help?</title><link>http://arxiv.org/abs/2304.02478v2</link><description>English as foreign language_EFL_students' use of text generated fromartificial intelligence_AI_natural language generation_NLG_tools may improvetheir writing quality. However, it remains unclear to what extent AI-generatedtext in these students' writing might lead to higher-quality writing. Weexplored 23 Hong Kong secondary school students' attempts to write storiescomprising their own words and AI-generated text. Human experts scored thestories for dimensions of content, language and organization. We analyzed thebasic organization and structure and syntactic complexity of the stories'AI-generated text and performed multiple linear regression and clusteranalyses. The results show the number of human words and the number ofAI-generated words contribute significantly to scores. Besides, students can begrouped into competent and less competent writers who use more AI-generatedtext or less AI-generated text compared to their peers. Comparisons of clustersreveal some benefit of AI-generated text in improving the quality of bothhigh-scoring students' and low-scoring students' writing. The findings caninform pedagogical strategies to use AI-generated text for EFL students'writing and to address digital divides. This study contributes designs of NLGtools and writing activities to implement AI-generated text in schools.</description><author>David James Woo, Hengky Susanto, Chi Ho Yeung, Kai Guo, April Ka Yeng Fung</author><pubDate>Mon, 01 Jan 2024 02:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02478v2</guid></item><item><title>BSpell: A CNN-Blended BERT Based Bangla Spell Checker</title><link>http://arxiv.org/abs/2208.09709v2</link><description>Bangla typing is mostly performed using English keyboard and can be highlyerroneous due to the presence of compound and similarly pronounced letters.Spelling correction of a misspelled word requires understanding of word typingpattern as well as the context of the word usage. A specialized BERT modelnamed BSpell has been proposed in this paper targeted towards word for wordcorrection in sentence level. BSpell contains an end-to-end trainable CNNsub-model named SemanticNet along with specialized auxiliary loss. This allowsBSpell to specialize in highly inflected Bangla vocabulary in the presence ofspelling errors. Furthermore, a hybrid pretraining scheme has been proposed forBSpell that combines word level and character level masking. Comparison on twoBangla and one Hindi spelling correction dataset shows the superiority of ourproposed approach. BSpell is available as a Bangla spell checking tool viaGitHub: https://github.com/Hasiburshanto/Bangla-Spell-Checker</description><author>Chowdhury Rafeed Rahman, MD. Hasibur Rahman, Samiha Zakir, Mohammad Rafsan, Mohammed Eunus Ali</author><pubDate>Mon, 01 Jan 2024 01:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09709v2</guid></item><item><title>A Survey of Methods, Challenges and Perspectives in Causality</title><link>http://arxiv.org/abs/2302.00293v3</link><description>Deep Learning models have shown success in a large variety of tasks byextracting correlation patterns from high-dimensional data but still strugglewhen generalizing out of their initial distribution. As causal engines aim tolearn mechanisms independent from a data distribution, combining Deep Learningwith Causality can have a great impact on the two fields. In this paper, wefurther motivate this assumption. We perform an extensive overview of thetheories and methods for Causality from different perspectives, with anemphasis on Deep Learning and the challenges met by the two domains. We showearly attempts to bring the fields together and the possible perspectives forthe future. We finish by providing a large variety of applications fortechniques from Causality.</description><author>Gal Gendron, Michael Witbrock, Gillian Dobbie</author><pubDate>Mon, 01 Jan 2024 00:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00293v3</guid></item><item><title>A Non-Expert's Introduction to Data Ethics for Mathematicians</title><link>http://arxiv.org/abs/2201.07794v2</link><description>I give a short introduction to data ethics. I begin with some backgroundinformation and societal context for data ethics. I then discuss data ethics inmathematical-science education and indicate some available course material. Ibriefly highlight a few efforts -- at my home institution and elsewhere -- ondata ethics, society, and social good. I then discuss open data in research,research replicability and some other ethical issues in research, and thetension between privacy and open data and code, and a few controversial studiesand reactions to studies. I then discuss ethical principles, institutionalreview boards, and a few other considerations in the scientific use of humandata. Finally, I briefly survey a variety of research and lay articles that arerelevant to data ethics and data privacy. I conclude with a brief summary. My focal audience is mathematicians, but I hope that this chapter will alsobe useful to others. I am not an expert about data ethics, and this chapterprovides only a starting point on this wide-ranging topic. I encourage you toexamine the resources that I discuss and to reflect carefully on data ethics,its role in mathematics education, and the societal implications of data anddata analysis. As data and technology continue to evolve, I hope that suchcareful reflection will continue throughout your life.</description><author>Mason A. Porter</author><pubDate>Sun, 31 Dec 2023 23:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.07794v2</guid></item><item><title>Context-aware Decoding Reduces Hallucination in Query-focused Summarization</title><link>http://arxiv.org/abs/2312.14335v2</link><description>Query-focused summarization (QFS) aims to provide a summary of a singledocument/multi documents that can satisfy the information needs of a givenquery. It is useful for various real-world applications, such as abstractivesnippet generation or more recent retrieval augmented generation (RAG). Aprototypical QFS pipeline consists of a retriever (sparse or dense retrieval)and a generator (usually a large language model). However, applying largelanguage models (LLM) potentially leads to hallucinations, especially when theevidence contradicts the prior belief of LLMs. There has been growing interestin developing new decoding methods to improve generation quality and reducehallucination. In this work, we conduct a large-scale reproducibility study onone recently proposed decoding method -- Context-aware Decoding (CAD). Inaddition to replicating CAD's experiments on news summarization datasets, weinclude experiments on QFS datasets, and conduct more rigorous analysis oncomputational complexity and hyperparameter sensitivity. Experiments with eightdifferent language models show that performance-wise, CAD improves QFS qualityby (1) reducing factuality errors/hallucinations while (2) mostly retaining thematch of lexical patterns, measured by ROUGE scores, while also at a cost ofincreased inference-time FLOPs and reduced decoding speed. The codeimplementation based on Huggingface Library is made availablehttps://github.com/zhichaoxu-shufe/context-aware-decoding-qfs</description><author>Zhichao Xu</author><pubDate>Sun, 31 Dec 2023 22:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14335v2</guid></item><item><title>Markovian Sliced Wasserstein Distances: Beyond Independent Projections</title><link>http://arxiv.org/abs/2301.03749v3</link><description>Sliced Wasserstein (SW) distance suffers from redundant projections due toindependent uniform random projecting directions. To partially overcome theissue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the bestdiscriminative orthogonal projecting directions. Despite being able to reducethe number of projections, the metricity of Max-K-SW cannot be guaranteed inpractice due to the non-optimality of the optimization. Moreover, theorthogonality constraint is also computationally expensive and might not beeffective. To address the problem, we introduce a new family of SW distances,named Markovian sliced Wasserstein (MSW) distance, which imposes a first-orderMarkov structure on projecting directions. We discuss various members of MSW byspecifying the Markov structure including the prior distribution, thetransition distribution, and the burning and thinning technique. Moreover, weinvestigate the theoretical properties of MSW including topological properties(metricity, weak convergence, and connection to other distances), statisticalproperties (sample complexity, and Monte Carlo estimation error), andcomputational properties (computational complexity and memory complexity).Finally, we compare MSW distances with previous SW variants in variousapplications such as gradient flows, color transfer, and deep generativemodeling to demonstrate the favorable performance of MSW.</description><author>Khai Nguyen, Tongzheng Ren, Nhat Ho</author><pubDate>Sun, 31 Dec 2023 21:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.03749v3</guid></item><item><title>Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise</title><link>http://arxiv.org/abs/2311.13091v2</link><description>The open source of large amounts of image data promotes the development ofdeep learning techniques. Along with this comes the privacy risk of theseopen-source image datasets being exploited by unauthorized third parties totrain deep learning models for commercial or illegal purposes. To avoid theabuse of public data, a poisoning-based technique, the unlearnable example, isproposed to significantly degrade the generalization performance of models byadding a kind of imperceptible noise to the data. To further enhance itsrobustness against adversarial training, existing works leverage iterativeadversarial training on both the defensive noise and the surrogate model.However, it still remains unknown whether the robustness of unlearnableexamples primarily comes from the effect of enhancement in the surrogate modelor the defensive noise. Observing that simply removing the adversarial noise onthe training process of the defensive noise can improve the performance ofrobust unlearnable examples, we identify that solely the surrogate model'srobustness contributes to the performance. Furthermore, we found a negativecorrelation exists between the robustness of defensive noise and the protectionperformance, indicating defensive noise's instability issue. Motivated by this,to further boost the robust unlearnable example, we introduce stableerror-minimizing noise (SEM), which trains the defensive noise against randomperturbation instead of the time-consuming adversarial perturbation to improvethe stability of defensive noise. Through extensive experiments, we demonstratethat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,and ImageNet Subset in terms of both effectiveness and efficiency. The code isavailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.</description><author>Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun</author><pubDate>Sun, 31 Dec 2023 20:04:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13091v2</guid></item><item><title>Physical Computing: A Category Theoretic Perspective on Physical Computation and System Compositionality</title><link>http://arxiv.org/abs/2210.00392v4</link><description>This paper introduces a category theory-based framework to redefine physicalcomputing in light of advancements in quantum computing and non-standardcomputing systems. By integrating classical definitions within this broaderperspective, the paper rigorously recontextualizes what constitutes physicalcomputing devices and processes. It demonstrates how the compositional natureand relational structures of physical computing systems can be coherentlyformalized using category theory. This approach not only encapsulates recentformalisms in physical computing but also offers a structured method to explorethe dynamic interactions within these systems.</description><author>Nima Dehghani, Gianluca Caterina</author><pubDate>Sun, 31 Dec 2023 19:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.00392v4</guid></item><item><title>Shot-frugal and Robust quantum kernel classifiers</title><link>http://arxiv.org/abs/2210.06971v3</link><description>Quantum kernel methods are a candidate for quantum speed-ups in supervisedmachine learning. The number of quantum measurements N required for areasonable kernel estimate is a critical resource, both from complexityconsiderations and because of the constraints of near-term quantum hardware. Weemphasize that for classification tasks, the aim is reliable classification andnot precise kernel evaluation, and demonstrate that the former is far moreresource efficient. Furthermore, it is shown that the accuracy ofclassification is not a suitable performance metric in the presence of noiseand we motivate a new metric that characterizes the reliability ofclassification. We then obtain a bound for N which ensures, with highprobability, that classification errors over a dataset are bounded by themargin errors of an idealized quantum kernel classifier. Using chanceconstraint programming and the subgaussian bounds of quantum kerneldistributions, we derive several Shot-frugal and Robust (ShofaR) programsstarting from the primal formulation of the Support Vector Machine. Thissignificantly reduces the number of quantum measurements needed and is robustto noise by construction. Our strategy is applicable to uncertainty in quantumkernels arising from any source of unbiased noise.</description><author>Abhay Shastry, Abhijith Jayakumar, Apoorva Patel, Chiranjib Bhattacharyya</author><pubDate>Sun, 31 Dec 2023 18:33:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06971v3</guid></item><item><title>PGS: Pose-Guided Supervision for Mitigating Clothes-Changing in Person Re-Identification</title><link>http://arxiv.org/abs/2312.05634v2</link><description>Person Re-Identification (Re-ID) task seeks to enhance the tracking ofmultiple individuals by surveillance cameras. It provides additional supportfor multimodal tasks, including text-based person retrieval and human matching.Among the significant challenges faced in Re-ID, one of the most prominent isdealing with clothes-changing, where the same person may appear in differentoutfits. While previous methods have made notable progress in maintainingclothing data consistency and handling clothing change data, they still tend torely excessively on clothing information, which can limit performance due tothe dynamic nature of human appearances. To mitigate this challenge, we proposethe Pose-Guided Supervision (PGS), an effective framework for learning poseguidance within the Re-ID task. Our PGS consists of three modules: a humanencoder, a pose encoder, and a Pose-to-Human Projection module (PHP). The poseencoder module utilizes a frozen pre-trained model while we fine-tune apre-trained human-centric model for the human encoder module. Our PHP transferspose knowledge from the pose encoder module to the human encoder module throughmultiple projectors. Our framework, following extensive experimentation on fivebenchmark datasets, consistently surpasses the performance of currentstate-of-the-art methods. Our code is available athttps://github.com/huyquoctrinh/PGS.</description><author>Quoc-Huy Trinh, Nhat-Tan Bui, Dinh-Hieu Hoang, Phuoc-Thao Vo Thi, Hai-Dang Nguyen, Debesh Jha, Ulas Bagci, Ngan Le, Minh-Triet Tran</author><pubDate>Sun, 31 Dec 2023 17:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05634v2</guid></item><item><title>Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions</title><link>http://arxiv.org/abs/2306.07520v4</link><description>Human intelligence can retrieve any person according to both visual andlanguage descriptions. However, the current computer vision community studiesspecific person re-identification (ReID) tasks in different scenariosseparately, which limits the applications in the real world. This paper strivesto resolve this problem by proposing a new instruct-ReID task that requires themodel to retrieve images according to the given image or language instructions.Our instruct-ReID is a more general ReID setting, where existing 6 ReID taskscan be viewed as special cases by designing different instructions. We proposea large-scale OmniReID benchmark and an adaptive triplet loss as a baselinemethod to facilitate research in this new setting. Experimental results showthat the proposed multi-purpose ReID model, trained on our OmniReID benchmarkwithout fine-tuning, can improve +0.5%, +0.6%, +7.7% mAP on Market1501, MSMT17,CUHK03 for traditional ReID, +6.4%, +7.1%, +11.2% mAP on PRCC, VC-Clothes, LTCCfor clothes-changing ReID, +11.7% mAP on COCAS+ real2 for clothes templatebased clothes-changing ReID when using only RGB images, +24.9% mAP on COCAS+real2 for our newly defined language-instructed ReID, +4.3% on LLCM forvisible-infrared ReID, +2.6% on CUHK-PEDES for text-to-image ReID. Thedatasets, the model, and code will be available athttps://github.com/hwz-zju/Instruct-ReID.</description><author>Weizhen He, Yiheng Deng, Shixiang Tang, Qihao Chen, Qingsong Xie, Yizhou Wang, Lei Bai, Feng Zhu, Rui Zhao, Wanli Ouyang, Donglian Qi, Yunfeng Yan</author><pubDate>Sun, 31 Dec 2023 16:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07520v4</guid></item><item><title>Precise localization of corneal reflections in eye images using deep learning trained on synthetic data</title><link>http://arxiv.org/abs/2304.05673v3</link><description>We present a deep learning method for accurately localizing the center of asingle corneal reflection (CR) in an eye image. Unlike previous approaches, weuse a convolutional neural network (CNN) that was trained solely usingsimulated data. Using only simulated data has the benefit of completelysidestepping the time-consuming process of manual annotation that is requiredfor supervised training on real eye images. To systematically evaluate theaccuracy of our method, we first tested it on images with simulated CRs placedon different backgrounds and embedded in varying levels of noise. Second, wetested the method on high-quality videos captured from real eyes. Our methodoutperformed state-of-the-art algorithmic methods on real eye images with a 35%reduction in terms of spatial precision, and performed on par withstate-of-the-art on simulated images in terms of spatial accuracy.We concludethat our method provides a precise method for CR center localization andprovides a solution to the data availability problem which is one of theimportant common roadblocks in the development of deep learning models for gazeestimation. Due to the superior CR center localization and ease of application,our method has the potential to improve the accuracy and precision of CR-basedeye trackers</description><author>Sean Anthony Byrne, Marcus Nystrm, Virmarie Maquiling, Enkelejda Kasneci, Diederick C. Niehorster</author><pubDate>Sun, 31 Dec 2023 16:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05673v3</guid></item><item><title>Can Large Language Models Infer Causation from Correlation?</title><link>http://arxiv.org/abs/2306.05836v2</link><description>Causal inference is one of the hallmarks of human intelligence. While thefield of CausalNLP has attracted much interest in the recent years, existingcausal inference datasets in NLP primarily rely on discovering causality fromempirical knowledge (e.g., commonsense knowledge). In this work, we propose thefirst benchmark dataset to test the pure causal inference skills of largelanguage models (LLMs). Specifically, we formulate a novel task Corr2Cause,which takes a set of correlational statements and determines the causalrelationship between the variables. We curate a large-scale dataset of morethan 200K samples, on which we evaluate seventeen existing LLMs. Through ourexperiments, we identify a key shortcoming of LLMs in terms of their causalinference skills, and show that these models achieve almost close to randomperformance on the task. This shortcoming is somewhat mitigated when we try tore-purpose LLMs for this skill via finetuning, but we find that these modelsstill fail to generalize -- they can only perform causal inference inin-distribution settings when variable names and textual expressions used inthe queries are similar to those in the training set, but fail inout-of-distribution settings generated by perturbing these queries. Corr2Causeis a challenging task for LLMs, and would be helpful in guiding future researchon improving LLMs' pure reasoning skills and generalizability. Our data is athttps://huggingface.co/datasets/causalnlp/corr2cause. Our code is athttps://github.com/causalNLP/corr2cause.</description><author>Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona Diab, Bernhard Schlkopf</author><pubDate>Sun, 31 Dec 2023 15:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05836v2</guid></item><item><title>Generation Of Colors using Bidirectional Long Short Term Memory Networks</title><link>http://arxiv.org/abs/2311.06542v3</link><description>Human vision can distinguish between a vast spectrum of colours, estimated tobe between 2 to 7 million discernible shades. However, this impressive rangedoes not inherently imply that all these colours have been precisely named anddescribed within our lexicon. We often associate colours with familiar objectsand concepts in our daily lives. This research endeavors to bridge the gapbetween our visual perception of countless shades and our ability to articulateand name them accurately. A novel model has been developed to achieve thisgoal, leveraging Bidirectional Long Short-Term Memory (BiLSTM) networks withActive learning. This model operates on a proprietary dataset meticulouslycurated for this study. The primary objective of this research is to create aversatile tool for categorizing and naming previously unnamed colours oridentifying intermediate shades that elude traditional colour terminology. Thefindings underscore the potential of this innovative approach inrevolutionizing our understanding of colour perception and language. Throughrigorous experimentation and analysis, this study illuminates a promisingavenue for Natural Language Processing (NLP) applications in diverseindustries. By facilitating the exploration of the vast colour spectrum thepotential applications of NLP are extended beyond conventional boundaries.</description><author>A. Sinha</author><pubDate>Sun, 31 Dec 2023 15:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06542v3</guid></item><item><title>Do algorithms and barriers for sparse principal component analysis extend to other structured settings?</title><link>http://arxiv.org/abs/2307.13535v2</link><description>We study a principal component analysis problem under the spiked Wishartmodel in which the structure in the signal is captured by a class ofunion-of-subspace models. This general class includes vanilla sparse PCA aswell as its variants with graph sparsity. With the goal of studying theseproblems under a unified statistical and computational lens, we establishfundamental limits that depend on the geometry of the problem instance, andshow that a natural projected power method exhibits local convergence to thestatistically near-optimal neighborhood of the solution. We complement theseresults with end-to-end analyses of two important special cases given by pathand tree sparsity in a general basis, showing initialization methods andmatching evidence of computational hardness. Overall, our results indicate thatseveral of the phenomena observed for vanilla sparse PCA extend in a naturalfashion to its structured counterparts.</description><author>Guanyi Wang, Mengqi Lou, Ashwin Pananjady</author><pubDate>Sun, 31 Dec 2023 15:01:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13535v2</guid></item><item><title>Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks</title><link>http://arxiv.org/abs/2308.10273v3</link><description>Continuous Conditional Generative Adversarial Networks (CcGANs) enablegenerative modeling conditional on continuous scalar variables (termedregression labels). However, they can produce subpar fake images due to limitedtraining data. Although Negative Data Augmentation (NDA) effectively enhancesunconditional and class-conditional GANs by introducing anomalies into realtraining images, guiding the GANs away from low-quality outputs, its impact onCcGANs is limited, as it fails to replicate negative samples that may occurduring the CcGAN sampling. We present a novel NDA approach called Dual-NDAspecifically tailored for CcGANs to address this problem. Dual-NDA employs twotypes of negative samples: visually unrealistic images generated from apre-trained CcGAN and label-inconsistent images created by manipulating realimages' labels. Leveraging these negative samples, we introduce a noveldiscriminator objective alongside a modified CcGAN training algorithm.Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDAconsistently enhances the visual fidelity and label consistency of fake imagesgenerated by CcGANs, exhibiting a substantial performance gain over the vanillaNDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkableadvancement beyond the capabilities of state-of-the-art conditional GANs anddiffusion models, establishing a new pinnacle of performance. Our codes can befound at https://github.com/UBCDingXin/Dual-NDA.</description><author>Xin Ding, Yongwei Wang, Zuheng Xu</author><pubDate>Sun, 31 Dec 2023 14:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10273v3</guid></item><item><title>A Boosted Machine Learning Framework for the Improvement of Phase and Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and Configurational Parameters</title><link>http://arxiv.org/abs/2309.00993v2</link><description>The reason behind the remarkable properties of High-Entropy Alloys (HEAs) isrooted in the diverse phases and the crystal structures they contain. In therealm of material informatics, employing machine learning (ML) techniques toclassify phases and crystal structures of HEAs has gained considerablesignificance. In this study, we assembled a new collection of 1345 HEAs withvarying compositions to predict phases. Within this collection, there were 705sets of data that were utilized to predict the crystal structures with the helpof thermodynamics and electronic configuration. Our study introduces amethodical framework i.e., the Pearson correlation coefficient that helps inselecting the strongly co-related features to increase the prediction accuracy.This study employed five distinct boosting algorithms to predict phases andcrystal structures, offering an enhanced guideline for improving the accuracyof these predictions. Among all these algorithms, XGBoost gives the highestaccuracy of prediction (94.05%) for phases and LightGBM gives the highestaccuracy of prediction of crystal structure of the phases (90.07%). Thequantification of the influence exerted by parameters on the model's accuracywas conducted and a new approach was made to elucidate the contribution ofindividual parameters in the process of phase prediction and crystal structureprediction.</description><author>Debsundar Dey, Suchandan Das, Anik Pal, Santanu Dey, Chandan Kumar Raul, Arghya Chatterjee</author><pubDate>Sun, 31 Dec 2023 14:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00993v2</guid></item><item><title>Nuclear Morphometry using a Deep Learning-based Algorithm has Prognostic Relevance for Canine Cutaneous Mast Cell Tumors</title><link>http://arxiv.org/abs/2309.15031v2</link><description>Variation in nuclear size and shape is an important criterion of malignancyfor many tumor types; however, categorical estimates by pathologists have poorreproducibility. Measurements of nuclear characteristics (morphometry) canimprove reproducibility, but manual methods are time consuming. In this study,we evaluated fully automated morphometry using a deep learning-based algorithmin 96 canine cutaneous mast cell tumors with information on patient survival.Algorithmic morphometry was compared with karyomegaly estimates by 11pathologists, manual nuclear morphometry of 12 cells by 9 pathologists, and themitotic count as a benchmark. The prognostic value of automated morphometry washigh with an area under the ROC curve regarding the tumor-specific survival of0.943 (95% CI: 0.889 - 0.996) for the standard deviation (SD) of nuclear area,which was higher than manual morphometry of all pathologists combined (0.868,95% CI: 0.737 - 0.991) and the mitotic count (0.885, 95% CI: 0.765 - 1.00). Atthe proposed thresholds, the hazard ratio for algorithmic morphometry (SD ofnuclear area $\geq 9.0 \mu m^2$) was 18.3 (95% CI: 5.0 - 67.1), for manualmorphometry (SD of nuclear area $\geq 10.9 \mu m^2$) 9.0 (95% CI: 6.0 - 13.4),for karyomegaly estimates 7.6 (95% CI: 5.7 - 10.1), and for the mitotic count30.5 (95% CI: 7.8 - 118.0). Inter-rater reproducibility for karyomegalyestimates was fair ($\kappa$ = 0.226) with highly variablesensitivity/specificity values for the individual pathologists. Reproducibilityfor manual morphometry (SD of nuclear area) was good (ICC = 0.654). This studysupports the use of algorithmic morphometry as a prognostic test to overcomethe limitations of estimates and manual measurements.</description><author>Andreas Haghofer, Eda Parlak, Alexander Bartel, Taryn A. Donovan, Charles-Antoine Assenmacher, Pompei Bolfa, Michael J. Dark, Andrea Fuchs-Baumgartinger, Andrea Klang, Kathrin Jger, Robert Klopfleisch, Sophie Merz, Barbara Richter, F. Yvonne Schulman, Jonathan Ganz, Josef Scharinger, Marc Aubreville, Stephan M. Winkler, Matti Kiupel, Christof A. Bertram</author><pubDate>Sun, 31 Dec 2023 12:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15031v2</guid></item><item><title>Rethinking the Paradigm of Content Constraints in GAN-based Unpaired Image-to-Image Translation</title><link>http://arxiv.org/abs/2211.10867v2</link><description>In an unpaired setting, lacking sufficient content constraints forimage-to-image translation (I2I) tasks, GAN-based approaches are usually proneto model collapse. Current solutions can be divided into two categories,reconstruction-based and Siamese network-based. The former requires that thetransformed or transforming image can be perfectly converted back to theoriginal image, which is sometimes too strict and limits the generativeperformance. The latter involves feeding the original and generated images intoa feature extractor and then matching their outputs. This is not efficientenough, and a universal feature extractor is not easily available. In thispaper, we propose EnCo, a simple but efficient way to maintain the content byconstraining the representational similarity in the latent space of patch-levelfeatures from the same stage of the \textbf{En}coder and de\textbf{Co}der ofthe generator. For the similarity function, we use a simple MSE loss instead ofcontrastive loss, which is currently widely used in I2I tasks. Benefits fromthe design, EnCo training is extremely efficient, while the features from theencoder produce a more positive effect on the decoding, leading to moresatisfying generations. In addition, we rethink the role played bydiscriminators in sampling patches and propose a discriminativeattention-guided (DAG) patch sampling strategy to replace random sampling. DAGis parameter-free and only requires negligible computational overhead, whilesignificantly improving the performance of the model. Extensive experiments onmultiple datasets demonstrate the effectiveness and advantages of EnCo, and weachieve multiple state-of-the-art compared to previous methods. Our code isavailable at https://github.com/XiudingCai/EnCo-pytorch.</description><author>Xiuding Cai, Yaoyao Zhu, Dong Miao, Linjie Fu, Yu Yao</author><pubDate>Sun, 31 Dec 2023 12:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10867v2</guid></item><item><title>Experimenting AI Technologies for Disinformation Combat: the IDMO Project</title><link>http://arxiv.org/abs/2310.11097v5</link><description>The Italian Digital Media Observatory (IDMO) project, part of a Europeaninitiative, focuses on countering disinformation and fake news. This reportoutlines contributions from Rai-CRITS to the project, including: (i) thecreation of novel datasets for testing technologies (ii) development of anautomatic model for categorizing Pagella Politica verdicts to facilitatebroader analysis (iii) creation of an automatic model for recognizing textualentailment with exceptional accuracy on the FEVER dataset (iv) assessment usingGPT-4 to detecting content treatment style (v) a game to raise awareness aboutfake news at national events.</description><author>Lorenzo Canale, Alberto Messina</author><pubDate>Sun, 31 Dec 2023 12:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11097v5</guid></item><item><title>The Decaying Missing-at-Random Framework: Doubly Robust Causal Inference with Partially Labeled Data</title><link>http://arxiv.org/abs/2305.12789v2</link><description>In real-world scenarios, data collection limitations often result inpartially labeled datasets, leading to difficulties in drawing reliable causalinferences. Traditional approaches in the semi-supervised (SS) and missing dataliterature may not adequately handle these complexities, leading to biasedestimates. To address these challenges, our paper introduces a novel decayingmissing-at-random (decaying MAR) framework. This framework tackles missingoutcomes in high-dimensional settings and accounts for selection bias arisingfrom the dependence of labeling probability on covariates. Notably, we relaxthe need for a positivity condition, commonly required in the missing dataliterature, and allow uniform decay of labeling propensity scores with samplesize, accommodating faster growth of unlabeled data. Our decaying MAR frameworkenables easy rate double-robust (DR) estimation of average treatment effects,succeeding where other methods fail, even with correctly specified nuisancemodels. Additionally, it facilitates asymptotic normality under modelmisspecification. To achieve this, we propose adaptive new targetedbias-reducing nuisance estimators and asymmetric cross-fitting, along with anovel semi-parametric approach that fully leverages large volumes of unlabeleddata. Our approach requires weak sparsity conditions. Numerical results confirmour estimators' efficacy and versatility, addressing selection bias and modelmisspecification.</description><author>Yuqian Zhang, Abhishek Chakrabortty, Jelena Bradic</author><pubDate>Sun, 31 Dec 2023 11:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12789v2</guid></item><item><title>Ensemble forecasts in reproducing kernel Hilbert space family</title><link>http://arxiv.org/abs/2207.14653v4</link><description>A methodological framework for ensemble-based estimation and simulation ofhigh dimensional dynamical systems such as the oceanic or atmospheric flows isproposed. To that end, the dynamical system is embedded in a family ofreproducing kernel Hilbert spaces (RKHS) with kernel functions driven by thedynamics. In the RKHS family, the Koopman and Perron-Frobenius operators areunitary and uniformly continuous. This property warrants they can be expressedin exponential series of diagonalizable bounded evolution operators definedfrom their infinitesimal generators. Access to Lyapunov exponents and to exactensemble based expressions of the tangent linear dynamics are directlyavailable as well. The RKHS family enables us the devise of strikingly simpleensemble data assimilation methods for trajectory reconstructions in terms ofconstant-in-time linear combinations of trajectory samples. Such anembarrassingly simple strategy is made possible through a fully justifiedsuperposition principle ensuing from several fundamental theorems.</description><author>Benjamin Dufe, Brenger Hug, Etienne Mmin, Gilles Tissot</author><pubDate>Sun, 31 Dec 2023 11:24:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.14653v4</guid></item><item><title>Analyzing Generalization in Policy Networks: A Case Study with the Double-Integrator System</title><link>http://arxiv.org/abs/2312.10472v2</link><description>Extensive utilization of deep reinforcement learning (DRL) policy networks indiverse continuous control tasks has raised questions regarding performancedegradation in expansive state spaces where the input state norm is larger thanthat in the training environment. This paper aims to uncover the underlyingfactors contributing to such performance deterioration when dealing withexpanded state spaces, using a novel analysis technique known as statedivision. In contrast to prior approaches that employ state division merely asa post-hoc explanatory tool, our methodology delves into the intrinsiccharacteristics of DRL policy networks. Specifically, we demonstrate that theexpansion of state space induces the activation function $\tanh$ to exhibitsaturability, resulting in the transformation of the state division boundaryfrom nonlinear to linear. Our analysis centers on the paradigm of thedouble-integrator system, revealing that this gradual shift towards linearityimparts a control behavior reminiscent of bang-bang control. However, theinherent linearity of the division boundary prevents the attainment of an idealbang-bang control, thereby introducing unavoidable overshooting. Ourexperimental investigations, employing diverse RL algorithms, establish thatthis performance phenomenon stems from inherent attributes of the DRL policynetwork, remaining consistent across various optimization algorithms.</description><author>Ruining Zhang, Haoran Han, Maolong Lv, Qisong Yang, Jian Cheng</author><pubDate>Sun, 31 Dec 2023 11:05:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10472v2</guid></item><item><title>Hopfield model with planted patterns: a teacher-student self-supervised learning model</title><link>http://arxiv.org/abs/2304.13710v3</link><description>While Hopfield networks are known as paradigmatic models for memory storageand retrieval, modern artificial intelligence systems mainly stand on themachine learning paradigm. We show that it is possible to formulate ateacher-student self-supervised learning problem with Boltzmann machines interms of a suitable generalization of the Hopfield model with structuredpatterns, where the spin variables are the machine weights and patternscorrespond to the training set's examples. We analyze the learning performanceby studying the phase diagram in terms of the training set size, the datasetnoise and the inference temperature (i.e. the weight regularization). With asmall but informative dataset the machine can learn by memorization. With anoisy dataset, an extensive number of examples above a critical threshold isneeded. In this regime the memory storage limits of the system becomes anopportunity for the occurrence of a learning regime in which the system cangeneralize.</description><author>Francesco Alemanno, Luca Camanzi, Gianluca Manzan, Daniele Tantari</author><pubDate>Sun, 31 Dec 2023 10:13:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13710v3</guid></item><item><title>Wildfire Smoke Detection with Cross Contrast Patch Embedding</title><link>http://arxiv.org/abs/2311.10116v2</link><description>The Transformer-based deep networks have increasingly shown significantadvantages over CNNs. Some existing work has applied it in the field ofwildfire recognition or detection. However, we observed that the vanillaTransformer is not friendly for extracting smoke features. Because low-levelinformation such as color, transparency and texture is very important for smokerecognition, and transformer pays more attention to the semantic relevancebetween middle- or high-level features, and is not sensitive to the subtlechanges of low-level features along the space. To solve this problem, wepropose the Cross Contrast Patch Embedding(CCPE) module based on the SwinTransformer, which uses the multi-scales spatial frequency contrast informationin both vertical and horizontal directions to improve the discrimination of thenetwork on the underlying details. The fuzzy boundary of smoke makes thepositive and negative label assignment for instances in a dilemma, which isanother challenge for wildfires detection. To solve this problem, a SeparableNegative Sampling Mechanism(SNSM) is proposed. By using two different negativeinstance sampling strategies on positive images and negative imagesrespectively, the problem of supervision signal confusion caused by labeldiversity in the process of network training is alleviated. This paper alsoreleases the RealFire Test, the largest real wildfire test set so far, toevaluate the proposed method and promote future research. It contains 50,535images from 3,649 video clips. The proposed method has been extensively testedand evaluated on RealFire Test dataset, and has a significant performanceimprovement compared with the baseline detection models.</description><author>Chong Wang, Cheng Xu, Adeel Akram, Zhilin Shan, Qixing Zhang</author><pubDate>Sun, 31 Dec 2023 09:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10116v2</guid></item><item><title>On the geometric and Riemannian structure of the spaces of group equivariant non-expansive operators</title><link>http://arxiv.org/abs/2103.02543v2</link><description>Group equivariant non-expansive operators have been recently proposed asbasic components in topological data analysis and deep learning. In this paperwe study some geometric properties of the spaces of group equivariant operatorsand show how a space $\mathcal{F}$ of group equivariant non-expansive operatorscan be endowed with the structure of a Riemannian manifold, so making availablethe use of gradient descent methods for the minimization of cost functions on$\mathcal{F}$. As an application of this approach, we also describe a procedureto select a finite set of representative group equivariant non-expansiveoperators in the considered manifold.</description><author>Pasquale Cascarano, Patrizio Frosini, Nicola Quercioli, Amir Saki</author><pubDate>Sun, 31 Dec 2023 08:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.02543v2</guid></item><item><title>Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning</title><link>http://arxiv.org/abs/2311.15487v2</link><description>We consider the gradient descent flow widely used for the minimization of the$\mathcal{L}^2$ cost function in Deep Learning networks, and introduce twomodified versions; one adapted for the overparametrized setting, and the otherfor the underparametrized setting. Both have a clear and natural invariantgeometric meaning, taking into account the pullback vector bundle structure inthe overparametrized, and the pushforward vector bundle structure in theunderparametrized setting. In the overparametrized case, we prove that,provided that a rank condition holds, all orbits of the modified gradientdescent drive the $\mathcal{L}^2$ cost to its global minimum at a uniformexponential convergence rate; one thereby obtains an a priori stopping time forany prescribed proximity to the global minimum. We point out relations of thelatter to sub-Riemannian geometry.</description><author>Thomas Chen</author><pubDate>Sun, 31 Dec 2023 07:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15487v2</guid></item><item><title>Motion-aware Memory Network for Fast Video Salient Object Detection</title><link>http://arxiv.org/abs/2208.00946v2</link><description>Previous methods based on 3DCNN, convLSTM, or optical flow have achievedgreat success in video salient object detection (VSOD). However, they stillsuffer from high computational costs or poor quality of the generated saliencymaps. To solve these problems, we design a space-time memory (STM)-basednetwork, which extracts useful temporal information of the current frame fromadjacent frames as the temporal branch of VSOD. Furthermore, previous methodsonly considered single-frame prediction without temporal association. As aresult, the model may not focus on the temporal information sufficiently. Thus,we initially introduce object motion prediction between inter-frame into VSOD.Our model follows standard encoder--decoder architecture. In the encodingstage, we generate high-level temporal features by using high-level featuresfrom the current and its adjacent frames. This approach is more efficient thanthe optical flow-based methods. In the decoding stage, we propose an effectivefusion strategy for spatial and temporal branches. The semantic information ofthe high-level features is used to fuse the object details in the low-levelfeatures, and then the spatiotemporal features are obtained step by step toreconstruct the saliency maps. Moreover, inspired by the boundary supervisioncommonly used in image salient object detection (ISOD), we design amotion-aware loss for predicting object boundary motion and simultaneouslyperform multitask learning for VSOD and object motion prediction, which canfurther facilitate the model to extract spatiotemporal features accurately andmaintain the object integrity. Extensive experiments on several datasetsdemonstrated the effectiveness of our method and can achieve state-of-the-artmetrics on some datasets. The proposed model does not require optical flow orother preprocessing, and can reach a speed of nearly 100 FPS during inference.</description><author>Xing Zhao, Haoran Liang, Peipei Li, Guodao Sun, Dongdong Zhao, Ronghua Liang, Xiaofei He</author><pubDate>Sun, 31 Dec 2023 07:43:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.00946v2</guid></item><item><title>Language-Assisted 3D Scene Understanding</title><link>http://arxiv.org/abs/2312.11451v2</link><description>The scale and quality of point cloud datasets constrain the advancement ofpoint cloud learning. Recently, with the development of multi-modal learning,the incorporation of domain-agnostic prior knowledge from other modalities,such as images and text, to assist in point cloud feature learning has beenconsidered a promising avenue. Existing methods have demonstrated theeffectiveness of multi-modal contrastive training and feature distillation onpoint clouds. However, challenges remain, including the requirement for pairedtriplet data, redundancy and ambiguity in supervised features, and thedisruption of the original priors. In this paper, we propose alanguage-assisted approach to point cloud feature learning (LAST-PCL),enriching semantic concepts through LLMs-based text enrichment. We achievede-redundancy and feature dimensionality reduction without compromising textualpriors by statistical-based and training-free significant feature selection.Furthermore, we also delve into an in-depth analysis of the impact of textcontrastive training on the point cloud. Extensive experiments validate thatthe proposed method learns semantically meaningful point cloud features andachieves state-of-the-art or comparable performance in 3D semanticsegmentation, 3D object detection, and 3D scene classification tasks.</description><author>Yanmin Wu, Qiankun Gao, Renrui Zhang, Jian Zhang</author><pubDate>Sun, 31 Dec 2023 07:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11451v2</guid></item><item><title>Pre-training of Molecular GNNs as Conditional Boltzmann Generator</title><link>http://arxiv.org/abs/2312.13110v2</link><description>Learning representations of molecular structures using deep learning is afundamental problem in molecular property prediction tasks. Moleculesinherently exist in the real world as three-dimensional structures;furthermore, they are not static but in continuous motion in the 3D Euclideanspace, forming a potential energy surface. Therefore, it is desirable togenerate multiple conformations in advance and extract molecularrepresentations using a 4D-QSAR model that incorporates multiple conformations.However, this approach is impractical for drug and material discovery tasksbecause of the computational cost of obtaining multiple conformations. Toaddress this issue, we propose a pre-training method for molecular GNNs usingan existing dataset of molecular conformations to generate a latent vectoruniversal to multiple conformations from a 2D molecular graph. Our method,called Boltzmann GNN, is formulated by maximizing the conditional marginallikelihood of a conditional generative model for conformations generation. Weshow that our model has a better prediction performance for molecularproperties than existing pre-training methods using molecular graphs andthree-dimensional molecular structures.</description><author>Daiki Koge, Naoaki Ono, Shigehiko Kanaya</author><pubDate>Sun, 31 Dec 2023 06:47:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13110v2</guid></item><item><title>Dictionary Attack on IMU-based Gait Authentication</title><link>http://arxiv.org/abs/2309.11766v2</link><description>We present a novel adversarial model for authentication systems that use gaitpatterns recorded by the inertial measurement unit (IMU) built intosmartphones. The attack idea is inspired by and named after the concept of adictionary attack on knowledge (PIN or password) based authentication systems.In particular, this work investigates whether it is possible to build adictionary of IMUGait patterns and use it to launch an attack or find animitator who can actively reproduce IMUGait patterns that match the target'sIMUGait pattern. Nine physically and demographically diverse individuals walkedat various levels of four predefined controllable and adaptable gait factors(speed, step length, step width, and thigh-lift), producing 178 unique IMUGaitpatterns. Each pattern attacked a wide variety of user authentication models.The deeper analysis of error rates (before and after the attack) challenges thebelief that authentication systems based on IMUGait patterns are the mostdifficult to spoof; further research is needed on adversarial models andassociated countermeasures.</description><author>Rajesh Kumar, Can Isik, Chilukuri K. Mohan</author><pubDate>Sun, 31 Dec 2023 06:42:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11766v2</guid></item><item><title>A Simple and General Duality Proof for Wasserstein Distributionally Robust Optimization</title><link>http://arxiv.org/abs/2205.00362v3</link><description>We present an elementary yet general proof of duality for Wassersteindistributionally robust optimization. The duality holds for any arbitraryKantorovich transport cost, measurable loss function, and nominal probabilitydistribution, provided that an interchangeability principle holds, which isequivalent to certain measurability conditions. To illustrate the broaderapplicability of our approach, we provide a rigorous treatment of dualityresults in distributionally robust Markov decision processes anddistributionally robust multistage stochastic programming. Furthermore, weextend the result to other problems including infinity-Wassersteindistributionally robust optimization, risk-averse optimization, and globalizeddistributionally robust counterpart.</description><author>Luhao Zhang, Jincheng Yang, Rui Gao</author><pubDate>Sun, 31 Dec 2023 06:15:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.00362v3</guid></item><item><title>Hard View Selection for Self-Supervised Learning</title><link>http://arxiv.org/abs/2310.03940v4</link><description>Many Self-Supervised Learning (SSL) methods train their models to beinvariant to different "views" of an image input for which a good dataaugmentation pipeline is crucial. While considerable efforts were directedtowards improving pre-text tasks, architectures, or robustness (e.g., Siamesenetworks or teacher-softmax centering), the majority of these methods remainstrongly reliant on the random sampling of operations within the imageaugmentation pipeline, such as the random resized crop or color distortionoperation. In this paper, we argue that the role of the view generation and itseffect on performance has so far received insufficient attention. To addressthis, we propose an easy, learning-free, yet powerful Hard View Selection (HVS)strategy designed to extend the random view generation to expose the pretrainedmodel to harder samples during SSL training. It encompasses the followingiterative steps: 1) randomly sample multiple views and create pairs of twoviews, 2) run forward passes for each view pair on the currently trained model,3) adversarially select the pair yielding the worst loss, and 4) run thebackward pass with the selected pair. In our empirical analysis we show thatunder the hood, HVS increases task difficulty by controlling the Intersectionover Union of views during pretraining. With only 300-epoch pretraining, HVS isable to closely rival the 800-epoch DINO baseline which remains very favorableeven when factoring in the slowdown induced by the additional forwards of HVS.Additionally, HVS consistently achieves accuracy improvements on ImageNetbetween 0.4% and 1.9% on linear evaluation and similar improvements on transfertasks across multiple SSL methods, such as DINO, SimSiam, iBOT, and SimCLR.</description><author>Fabio Ferreira, Ivo Rapant, Frank Hutter</author><pubDate>Sun, 31 Dec 2023 05:46:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03940v4</guid></item><item><title>Stochastic Approximation with Decision-Dependent Distributions: Asymptotic Normality and Optimality</title><link>http://arxiv.org/abs/2207.04173v2</link><description>We analyze a stochastic approximation algorithm for decision-dependentproblems, wherein the data distribution used by the algorithm evolves along theiterate sequence. The primary examples of such problems appear in performativeprediction and its multiplayer extensions. We show that under mild assumptions,the deviation between the average iterate of the algorithm and the solution isasymptotically normal, with a covariance that clearly decouples the effects ofthe gradient noise and the distributional shift. Moreover, building on the workof H\'ajek and Le Cam, we show that the asymptotic performance of the algorithmwith averaging is locally minimax optimal.</description><author>Joshua Cutler, Mateo Daz, Dmitriy Drusvyatskiy</author><pubDate>Sun, 31 Dec 2023 05:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.04173v2</guid></item><item><title>Forbidden Facts: An Investigation of Competing Objectives in Llama-2</title><link>http://arxiv.org/abs/2312.08793v3</link><description>LLMs often face competing pressures (for example helpfulness vs.harmlessness). To understand how models resolve such conflicts, we studyLlama-2-chat models on the forbidden fact task. Specifically, we instructLlama-2 to truthfully complete a factual recall statement while forbidding itfrom saying the correct answer. This often makes the model give incorrectanswers. We decompose Llama-2 into 1000+ components, and rank each one withrespect to how useful it is for forbidding the correct answer. We find that inaggregate, around 35 components are enough to reliably implement the fullsuppression behavior. However, these components are fairly heterogeneous andmany operate using faulty heuristics. We discover that one of these heuristicscan be exploited via a manually designed adversarial attack which we call TheCalifornia Attack. Our results highlight some roadblocks standing in the way ofbeing able to successfully interpret advanced ML systems. Project websiteavailable at https://forbiddenfacts.github.io .</description><author>Tony T. Wang, Miles Wang, Kaivalya Hariharan, Nir Shavit</author><pubDate>Sun, 31 Dec 2023 05:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08793v3</guid></item><item><title>Cluster-based Regression using Variational Inference and Applications in Financial Forecasting</title><link>http://arxiv.org/abs/2205.00605v3</link><description>This paper describes an approach to simultaneously identify clusters andestimate cluster-specific regression parameters from the given data. Such anapproach can be useful in learning the relationship between input and outputwhen the regression parameters for estimating output are different in differentregions of the input space. Variational Inference (VI), a machine learningapproach to obtain posterior probability densities using optimizationtechniques, is used to identify clusters of explanatory variables andregression parameters for each cluster. From these results, one can obtain boththe expected value and the full distribution of predicted output. Otheradvantages of the proposed approach include the elegant theoretical solutionand clear interpretability of results. The proposed approach is well-suited forfinancial forecasting where markets have different regimes (or clusters) withdifferent patterns and correlations of market changes in each regime. Infinancial applications, knowledge about such clusters can provide usefulinsights about portfolio performance and identify the relative importance ofvariables in different market regimes. An illustrative example of predictingone-day S&amp;P change is considered to illustrate the approach and compare theperformance of the proposed approach with standard regression without clusters.Due to the broad applicability of the problem, its elegant theoreticalsolution, and the computational efficiency of the proposed algorithm, theapproach may be useful in a number of areas extending beyond the financialdomain.</description><author>Udai Nagpal, Krishan Nagpal</author><pubDate>Sun, 31 Dec 2023 04:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.00605v3</guid></item><item><title>Empower Nested Boolean Logic via Self-Supervised Curriculum Learning</title><link>http://arxiv.org/abs/2310.05450v2</link><description>Beyond the great cognitive powers showcased by language models, it is crucialto scrutinize whether their reasoning capabilities stem from stronggeneralization or merely exposure to relevant data. As opposed to constructingincreasingly complex logic, this paper probes into the boolean logic, the rootcapability of a logical reasoner. We find that any pre-trained language modelseven including large language models only behave like a random selector in theface of multi-nested boolean logic, a task that humans can handle with ease. Toempower language models with this fundamental capability, this paper proposes anew self-supervised learning method \textit{Curriculum Logical Reasoning}(\textsc{Clr}), where we augment the training data with nested boolean logicchain step-by-step, and program the training from simpler logical patternsgradually to harder ones. This new training paradigm allows language models toeffectively generalize to much harder and longer-hop logic, which can hardly belearned through naive training. Furthermore, we show that boolean logic is agreat foundation for improving the subsequent general logical tasks.</description><author>Hongqiu Wu, Linfeng Liu, Hai Zhao, Min Zhang</author><pubDate>Sun, 31 Dec 2023 04:20:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05450v2</guid></item><item><title>BRICS: Bi-level feature Representation of Image CollectionS</title><link>http://arxiv.org/abs/2305.18601v3</link><description>We present BRICS, a bi-level feature representation for image collections,which consists of a key code space on top of a feature grid space.Specifically, our representation is learned by an autoencoder to encode imagesinto continuous key codes, which are used to retrieve features from groups ofmulti-resolution feature grids. Our key codes and feature grids are jointlytrained continuously with well-defined gradient flows, leading to high usagerates of the feature grids and improved generative modeling compared todiscrete Vector Quantization (VQ). Differently from existing continuousrepresentations such as KL-regularized latent codes, our key codes are strictlybounded in scale and variance. Overall, feature encoding by BRICS is compact,efficient to train, and enables generative modeling over key codes using thediffusion model. Experimental results show that our method achieves comparablereconstruction results to VQ while having a smaller and more efficient decodernetwork (50% fewer GFlops). By applying the diffusion model over our key codespace, we achieve state-of-the-art performance on image synthesis on the FFHQand LSUN-Church (29% lower than LDM, 32% lower than StyleGAN2, 44% lower thanProjected GAN on CLIP-FID) datasets.</description><author>Dingdong Yang, Yizhi Wang, Ali Mahdavi-Amiri, Hao Zhang</author><pubDate>Sun, 31 Dec 2023 04:01:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18601v3</guid></item><item><title>VLCounter: Text-aware Visual Representation for Zero-Shot Object Counting</title><link>http://arxiv.org/abs/2312.16580v2</link><description>Zero-Shot Object Counting (ZSOC) aims to count referred instances ofarbitrary classes in a query image without human-annotated exemplars. To dealwith ZSOC, preceding studies proposed a two-stage pipeline: discoveringexemplars and counting. However, there remains a challenge of vulnerability toerror propagation of the sequentially designed two-stage process. In this work,an one-stage baseline, Visual-Language Baseline (VLBase), exploring theimplicit association of the semantic-patch embeddings of CLIP is proposed.Subsequently, the extension of VLBase to Visual-language Counter (VLCounter) isachieved by incorporating three modules devised to tailor VLBase for objectcounting. First, Semantic-conditioned Prompt Tuning (SPT) is introduced withinthe image encoder to acquire target-highlighted representations. Second,Learnable Affine Transformation (LAT) is employed to translate thesemantic-patch similarity map to be appropriate for the counting task. Lastly,the layer-wisely encoded features are transferred to the decoder throughSegment-aware Skip Connection (SaSC) to keep the generalization capability forunseen classes. Through extensive experiments on FSC147, CARPK, and PUCPR+, thebenefits of the end-to-end framework, VLCounter, are demonstrated.</description><author>Seunggu Kang, WonJun Moon, Euiyeon Kim, Jae-Pil Heo</author><pubDate>Sun, 31 Dec 2023 03:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16580v2</guid></item><item><title>In Search of Lost Online Test-time Adaptation: A Survey</title><link>http://arxiv.org/abs/2310.20199v2</link><description>In this paper, we present a comprehensive survey on online test-timeadaptation (OTTA), a paradigm focused on adapting machine learning models tonovel data distributions upon batch arrival. Despite the proliferation of OTTAmethods recently, the field is mired in issues like ambiguous settings,antiquated backbones, and inconsistent hyperparameter tuning, obfuscating thereal challenges and making reproducibility elusive. For clarity and a rigorouscomparison, we classify OTTA techniques into three primary categories andsubject them to benchmarks using the potent Vision Transformer (ViT) backboneto discover genuinely effective strategies. Our benchmarks span not onlyconventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C but alsoreal-world shifts embodied in CIFAR-10.1 and CIFAR-10-Warehouse, encapsulatingvariations across search engines and synthesized data by diffusion models. Togauge efficiency in online scenarios, we introduce novel evaluation metrics,inclusive of FLOPs, shedding light on the trade-offs between adaptationaccuracy and computational overhead. Our findings diverge from existingliterature, indicating: (1) transformers exhibit heightened resilience todiverse domain shifts, (2) the efficacy of many OTTA methods hinges on amplebatch sizes, and (3) stability in optimization and resistance to perturbationsare critical during adaptation, especially when the batch size is 1. Motivatedby these insights, we pointed out promising directions for future research. Thesource code is made available: https://github.com/Jo-wang/OTTA_ViT_survey.</description><author>Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, Zi Huang</author><pubDate>Sun, 31 Dec 2023 02:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20199v2</guid></item><item><title>Preference as Reward, Maximum Preference Optimization with Importance Sampling</title><link>http://arxiv.org/abs/2312.16430v2</link><description>Preference learning is a key technology for aligning language models withhuman values. Reinforcement Learning from Human Feedback (RLHF) is a modelbased algorithm to optimize preference learning, which first fitting a rewardmodel for preference score, and then optimizing generating policy withon-policy PPO algorithm to maximize the reward. The processing of RLHF iscomplex, time-consuming and unstable. Direct Preference Optimization (DPO)algorithm using off-policy algorithm to direct optimize generating policy andeliminating the need for reward model, which is data efficient and stable. DPOuse Bradley-Terry model and log-loss which leads to over-fitting to thepreference data at the expense of ignoring KL-regularization term whenpreference is deterministic. IPO uses a root-finding MSE loss to solve theignoring KL-regularization problem. In this paper, we'll figure out, althoughIPO fix the problem when preference is deterministic, but both DPO and IPOfails the KL-regularization term because the support of preference distributionnot equal to reference distribution. Then, we design a simple and intuitiveoff-policy preference optimization algorithm from an importance sampling view,which we call Maximum Preference Optimization (MPO), and add off-policyKL-regularization terms which makes KL-regularization truly effective. Theobjective of MPO bears resemblance to RLHF's objective, and likes IPO, MPO isoff-policy. So, MPO attains the best of both worlds. To simplify the learningprocess and save memory usage, MPO eliminates the needs for both reward modeland reference policy.</description><author>Zaifan Jiang, Xing Huang, Chao Wei</author><pubDate>Sun, 31 Dec 2023 02:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16430v2</guid></item><item><title>Annotation-free Automatic Music Transcription with Scalable Synthetic Data and Adversarial Domain Confusion</title><link>http://arxiv.org/abs/2312.10402v2</link><description>Automatic Music Transcription (AMT) is a vital technology in the field ofmusic information processing. Despite recent enhancements in performance due tomachine learning techniques, current methods typically attain high accuracy indomains where abundant annotated data is available. Addressing domains with lowor no resources continues to be an unresolved challenge. To tackle this issue,we propose a transcription model that does not require any MIDI-audio paireddata through the utilization of scalable synthetic audio for pre-training andadversarial domain confusion using unannotated real audio. In experiments, weevaluate methods under the real-world application scenario where trainingdatasets do not include the MIDI annotation of audio in the target data domain.Our proposed method achieved competitive performance relative to establishedbaseline methods, despite not utilizing any real datasets of paired MIDI-audio.Additionally, ablation studies have provided insights into the scalability ofthis approach and the forthcoming challenges in the field of AMT research.</description><author>Gakusei Sato, Taketo Akama</author><pubDate>Sun, 31 Dec 2023 02:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10402v2</guid></item><item><title>An Instance Segmentation Dataset of Yeast Cells in Microstructures</title><link>http://arxiv.org/abs/2304.07597v4</link><description>Extracting single-cell information from microscopy data requires accurateinstance-wise segmentations. Obtaining pixel-wise segmentations from microscopyimagery remains a challenging task, especially with the added complexity ofmicrostructured environments. This paper presents a novel dataset forsegmenting yeast cells in microstructures. We offer pixel-wise instancesegmentation labels for both cells and trap microstructures. In total, werelease 493 densely annotated microscopy images. To facilitate a unifiedcomparison between novel segmentation algorithms, we propose a standardizedevaluation strategy for our dataset. The aim of the dataset and evaluationstrategy is to facilitate the development of new cell segmentation approaches.The dataset is publicly available athttps://christophreich1996.github.io/yeast_in_microstructures_dataset/ .</description><author>Christoph Reich, Tim Prangemeier, Andr O. Franani, Heinz Koeppl</author><pubDate>Sun, 31 Dec 2023 02:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07597v4</guid></item><item><title>Federated Two Stage Decoupling With Adaptive Personalization Layers</title><link>http://arxiv.org/abs/2308.15821v2</link><description>Federated learning has gained significant attention due to its groundbreakingability to enable distributed learning while maintaining privacy constraints.However, as a consequence of data heterogeneity among decentralized devices, itinherently experiences significant learning degradation and slow convergencespeed. Therefore, it is natural to employ the concept of clustering homogeneousclients into the same group, allowing only the model weights within each groupto be aggregated. While most existing clustered federated learning methodsemploy either model gradients or inference outputs as metrics for clientpartitioning, with the goal of grouping similar devices together, may stillhave heterogeneity within each cluster. Moreover, there is a scarcity ofresearch exploring the underlying reasons for determining the appropriatetiming for clustering, resulting in the common practice of assigning eachclient to its own individual cluster, particularly in the context of highly nonindependent and identically distributed (Non-IID) data. In this paper, weintroduce a two-stage decoupling federated learning algorithm with adaptivepersonalization layers named FedTSDP, where client clustering is performedtwice according to inference outputs and model weights, respectively. Hopkinsamended sampling is adopted to determine the appropriate timing for clusteringand the sampling weight of public unlabeled data. In addition, a simple yeteffective approach is developed to adaptively adjust the personalization layersbased on varying degrees of data skew. Experimental results show that ourproposed method has reliable performance on both IID and non-IID scenarios.</description><author>Hangyu Zhu, Yuxiang Fan, Zhenping Xie</author><pubDate>Sun, 31 Dec 2023 01:53:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15821v2</guid></item><item><title>Wave Physics-informed Matrix Factorizations</title><link>http://arxiv.org/abs/2312.13584v2</link><description>With the recent success of representation learning methods, which includesdeep learning as a special case, there has been considerable interest indeveloping techniques that incorporate known physical constraints into thelearned representation. As one example, in many applications that involve asignal propagating through physical media (e.g., optics, acoustics, fluiddynamics, etc), it is known that the dynamics of the signal must satisfyconstraints imposed by the wave equation. Here we propose a matrixfactorization technique that decomposes such signals into a sum of components,where each component is regularized to ensure that it {nearly} satisfies waveequation constraints. Although our proposed formulation is non-convex, we provethat our model can be efficiently solved to global optimality. Through thisline of work we establish theoretical connections between wave-informedlearning and filtering theory in signal processing. We further demonstrate theapplication of this work on modal analysis problems commonly arising instructural diagnostics and prognostics.</description><author>Harsha Vardhan Tetali, Joel B. Harley, Benjamin D. Haeffele</author><pubDate>Sun, 31 Dec 2023 01:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13584v2</guid></item><item><title>Differentially Private Diffusion Models</title><link>http://arxiv.org/abs/2210.09929v3</link><description>While modern machine learning models rely on increasingly large trainingdatasets, data is often limited in privacy-sensitive domains. Generative modelstrained with differential privacy (DP) on sensitive data can sidestep thischallenge, providing access to synthetic data instead. We build on the recentsuccess of diffusion models (DMs) and introduce Differentially PrivateDiffusion Models (DPDMs), which enforce privacy using differentially privatestochastic gradient descent (DP-SGD). We investigate the DM parameterizationand the sampling algorithm, which turn out to be crucial ingredients in DPDMs,and propose noise multiplicity, a powerful modification of DP-SGD tailored tothe training of DMs. We validate our novel DPDMs on image generation benchmarksand achieve state-of-the-art performance in all experiments. Moreover, onstandard benchmarks, classifiers trained on DPDM-generated synthetic dataperform on par with task-specific DP-SGD-trained classifiers, which has notbeen demonstrated before for DP generative models. Project page and code:https://nv-tlabs.github.io/DPDM.</description><author>Tim Dockhorn, Tianshi Cao, Arash Vahdat, Karsten Kreis</author><pubDate>Sun, 31 Dec 2023 01:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.09929v3</guid></item><item><title>SuperAnimal pretrained pose estimation models for behavioral analysis</title><link>http://arxiv.org/abs/2203.07436v4</link><description>Quantification of behavior is critical in applications ranging fromneuroscience, veterinary medicine and animal conservation efforts. A common keystep for behavioral analysis is first extracting relevant keypoints on animals,known as pose estimation. However, reliable inference of poses currentlyrequires domain knowledge and manual labeling effort to build supervisedmodels. We present a series of technical innovations that enable a new method,collectively called SuperAnimal, to develop unified foundation models that canbe used on over 45 species, without additional human labels. Concretely, weintroduce a method to unify the keypoint space across differently labeleddatasets (via our generalized data converter) and for training these diversedatasets in a manner such that they don't catastrophically forget keypointsgiven the unbalanced inputs (via our keypoint gradient masking and memoryreplay approaches). These models show excellent performance across six posebenchmarks. Then, to ensure maximal usability for end-users, we demonstrate howto fine-tune the models on differently labeled data and provide tooling forunsupervised video adaptation to boost performance and decrease jitter acrossframes. If the models are fine-tuned, we show SuperAnimal models are10-100$\times$ more data efficient than prior transfer-learning-basedapproaches. We illustrate the utility of our models in behavioralclassification in mice and gait analysis in horses. Collectively, this presentsa data-efficient solution for animal pose estimation.</description><author>Shaokai Ye, Anastasiia Filippova, Jessy Lauer, Steffen Schneider, Maxime Vidal, Tian Qiu, Alexander Mathis, Mackenzie Weygandt Mathis</author><pubDate>Sun, 31 Dec 2023 01:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.07436v4</guid></item><item><title>DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models</title><link>http://arxiv.org/abs/2305.16943v2</link><description>Existing NAS methods suffer from either an excessive amount of time forrepetitive sampling and training of many task-irrelevant architectures. Totackle such limitations of existing NAS methods, we propose a paradigm shiftfrom NAS to a novel conditional Neural Architecture Generation (NAG) frameworkbased on diffusion models, dubbed DiffusionNAG. Specifically, we consider theneural architectures as directed graphs and propose a graph diffusion model forgenerating them. Moreover, with the guidance of parameterized predictors,DiffusionNAG can flexibly generate task-optimal architectures with the desiredproperties for diverse tasks, by sampling from a region that is more likely tosatisfy the properties. This conditional NAG scheme is significantly moreefficient than previous NAS schemes which sample the architectures and filterthem using the property predictors. We validate the effectiveness ofDiffusionNAG through extensive experiments in two predictor-based NASscenarios: Transferable NAS and Bayesian Optimization (BO)-based NAS.DiffusionNAG achieves superior performance with speedups of up to 20 times whencompared to the baselines on Transferable NAS benchmarks. Furthermore, whenintegrated into a BO-based algorithm, DiffusionNAG outperforms existingBO-based NAS approaches, particularly in the large MobileNetV3 search space onthe ImageNet 1K dataset.</description><author>Sohyun An, Hayeon Lee, Jaehyeong Jo, Seanie Lee, Sung Ju Hwang</author><pubDate>Sun, 31 Dec 2023 00:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16943v2</guid></item><item><title>Diffusion-HPC: Synthetic Data Generation for Human Mesh Recovery in Challenging Domains</title><link>http://arxiv.org/abs/2303.09541v2</link><description>Recent text-to-image generative models have exhibited remarkable abilities ingenerating high-fidelity and photo-realistic images. However, despite thevisually impressive results, these models often struggle to preserve plausiblehuman structure in the generations. Due to this reason, while generative modelshave shown promising results in aiding downstream image recognition tasks bygenerating large volumes of synthetic data, they are not suitable for improvingdownstream human pose perception and understanding. In this work, we propose aDiffusion model with Human Pose Correction (Diffusion-HPC), a text-conditionedmethod that generates photo-realistic images with plausible posed humans byinjecting prior knowledge about human body structure. Our generated images areaccompanied by 3D meshes that serve as ground truths for improving Human MeshRecovery tasks, where a shortage of 3D training data has long been an issue.Furthermore, we show that Diffusion-HPC effectively improves the realism ofhuman generations under varying conditioning strategies.</description><author>Zhenzhen Weng, Laura Bravo-Snchez, Serena Yeung-Levy</author><pubDate>Sun, 31 Dec 2023 00:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09541v2</guid></item><item><title>Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion</title><link>http://arxiv.org/abs/2308.06382v2</link><description>Voice conversion (VC) aims at altering a person's voice to make it soundsimilar to the voice of another person while preserving linguistic content.Existing methods suffer from a dilemma between content intelligibility andspeaker similarity; i.e., methods with higher intelligibility usually have alower speaker similarity, while methods with higher speaker similarity usuallyrequire plenty of target speaker voice data to achieve high intelligibility. Inthis work, we propose a novel method \textit{Phoneme Hallucinator} thatachieves the best of both worlds. Phoneme Hallucinator is a one-shot VC model;it adopts a novel model to hallucinate diversified and high-fidelity targetspeaker phonemes based just on a short target speaker voice (e.g. 3 seconds).The hallucinated phonemes are then exploited to perform neighbor-based voiceconversion. Our model is a text-free, any-to-any VC model that requires no textannotations and supports conversion to any unseen speaker. Objective andsubjective evaluations show that \textit{Phoneme Hallucinator} outperformsexisting VC methods for both intelligibility and speaker similarity.</description><author>Siyuan Shan, Yang Li, Amartya Banerjee, Junier B. Oliva</author><pubDate>Sat, 30 Dec 2023 22:48:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06382v2</guid></item><item><title>3D Object Detection from Images for Autonomous Driving: A Survey</title><link>http://arxiv.org/abs/2202.02980v6</link><description>3D object detection from images, one of the fundamental and challengingproblems in autonomous driving, has received increasing attention from bothindustry and academia in recent years. Benefiting from the rapid development ofdeep learning technologies, image-based 3D detection has achieved remarkableprogress. Particularly, more than 200 works have studied this problem from 2015to 2021, encompassing a broad spectrum of theories, algorithms, andapplications. However, to date no recent survey exists to collect and organizethis knowledge. In this paper, we fill this gap in the literature and providethe first comprehensive survey of this novel and continuously growing researchfield, summarizing the most commonly used pipelines for image-based 3Ddetection and deeply analyzing each of their components. Additionally, we alsopropose two new taxonomies to organize the state-of-the-art methods intodifferent categories, with the intent of providing a more systematic review ofexisting methods and facilitating fair comparisons with future works. Inretrospect of what has been achieved so far, we also analyze the currentchallenges in the field and discuss future directions for image-based 3Ddetection research.</description><author>Xinzhu Ma, Wanli Ouyang, Andrea Simonelli, Elisa Ricci</author><pubDate>Sat, 30 Dec 2023 22:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.02980v6</guid></item><item><title>Time is Encoded in the Weights of Finetuned Language Models</title><link>http://arxiv.org/abs/2312.13401v2</link><description>We present time vectors, a simple tool to customize language models to newtime periods. Time vectors are created by finetuning a language model on datafrom a single time (e.g., a year or month), and then subtracting the weights ofthe original pretrained model. This vector specifies a direction in weightspace that, as our experiments show, improves performance on text from thattime period. Time vectors specialized to adjacent time periods appear to bepositioned closer together in a manifold. Using this structure, we interpolatebetween time vectors to induce new models that perform better on interveningand future time periods, without any additional training. We demonstrate theconsistency of our findings across different tasks, domains, model sizes, andtime scales. Our results suggest that time is encoded in the weight space offinetuned models.</description><author>Kai Nylund, Suchin Gururangan, Noah A. Smith</author><pubDate>Sat, 30 Dec 2023 22:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13401v2</guid></item><item><title>Completeness of Atomic Structure Representations</title><link>http://arxiv.org/abs/2302.14770v3</link><description>In this paper, we address the challenge of obtaining a comprehensive andsymmetric representation of point particle groups, such as atoms in a molecule,which is crucial in physics and theoretical chemistry. The problem has becomeeven more important with the widespread adoption of machine-learning techniquesin science, as it underpins the capacity of models to accurately reproducephysical relationships while being consistent with fundamental symmetries andconservation laws. However, some of the descriptors that are commonly used torepresent point clouds -- most notably those based on discretized correlationsof the neighbor density, that underpin most of the existing ML models of matterat the atomic scale -- are unable to distinguish between special arrangementsof particles in three dimensions. This makes it impossible to machine learntheir properties. Atom-density correlations are provably complete in the limitin which they simultaneously describe the mutual relationship between allatoms, which is impractical. We present a novel approach to constructdescriptors of \emph{finite} correlations based on the relative arrangement ofparticle triplets, which can be employed to create symmetry-adapted models withuniversal approximation capabilities, which have the resolution of the neighbordiscretization as the sole convergence parameter. Our strategy is demonstratedon a class of atomic arrangements that are specifically built to defy a broadclass of conventional symmetric descriptors, showcasing its potential foraddressing their limitations.</description><author>Jigyasa Nigam, Sergey N. Pozdnyakov, Kevin K. Huguenin-Dumittan, Michele Ceriotti</author><pubDate>Sat, 30 Dec 2023 21:50:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14770v3</guid></item><item><title>CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph Diffusion</title><link>http://arxiv.org/abs/2305.16283v5</link><description>Controllable scene synthesis aims to create interactive environments forvarious industrial use cases. Scene graphs provide a highly suitable interfaceto facilitate these applications by abstracting the scene context in a compactmanner. Existing methods, reliant on retrieval from extensive databases orpre-trained shape embeddings, often overlook scene-object and object-objectrelationships, leading to inconsistent results due to their limited generationcapacity. To address this issue, we present CommonScenes, a fully generativemodel that converts scene graphs into corresponding controllable 3D scenes,which are semantically realistic and conform to commonsense. Our pipelineconsists of two branches, one predicting the overall scene layout via avariational auto-encoder and the other generating compatible shapes via latentdiffusion, capturing global scene-object and local inter-object relationshipsin the scene graph while preserving shape diversity. The generated scenes canbe manipulated by editing the input scene graph and sampling the noise in thediffusion model. Due to lacking a scene graph dataset offering high-qualityobject-level meshes with relations, we also construct SG-FRONT, enriching theoff-the-shelf indoor dataset 3D-FRONT with additional scene graph labels.Extensive experiments are conducted on SG-FRONT where CommonScenes shows clearadvantages over other methods regarding generation consistency, quality, anddiversity. Codes and the dataset will be released upon acceptance.</description><author>Guangyao Zhai, Evin Pnar rnek, Shun-Cheng Wu, Yan Di, Federico Tombari, Nassir Navab, Benjamin Busam</author><pubDate>Sat, 30 Dec 2023 21:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16283v5</guid></item><item><title>Spatially Varying Nanophotonic Neural Networks</title><link>http://arxiv.org/abs/2308.03407v3</link><description>The explosive growth of computation and energy cost of artificialintelligence has spurred strong interests in new computing modalities aspotential alternatives to conventional electronic processors. Photonicprocessors that execute operations using photons instead of electrons, havepromised to enable optical neural networks with ultra-low latency and powerconsumption. However, existing optical neural networks, limited by theunderlying network designs, have achieved image recognition accuracy far belowthat of state-of-the-art electronic neural networks. In this work, we closethis gap by embedding massively parallelized optical computation into flatcamera optics that perform neural network computation during the capture,before recording an image on the sensor. Specifically, we harness large kernelsand propose a large-kernel spatially-varying convolutional neural networklearned via low-dimensional reparameterization techniques. We experimentallyinstantiate the network with a flat meta-optical system that encompasses anarray of nanophotonic structures designed to induce angle-dependent responses.Combined with an extremely lightweight electronic backend with approximately 2Kparameters we demonstrate a reconfigurable nanophotonic neural network reaches72.76\% blind test classification accuracy on CIFAR-10 dataset, and, as such,the first time, an optical neural network outperforms the first modern digitalneural network -- AlexNet (72.64\%) with 57M parameters, bringing opticalneural network into modern deep learning era.</description><author>Kaixuan Wei, Xiao Li, Johannes Froech, Praneeth Chakravarthula, James Whitehead, Ethan Tseng, Arka Majumdar, Felix Heide</author><pubDate>Sat, 30 Dec 2023 21:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.03407v3</guid></item><item><title>Symbol tuning improves in-context learning in language models</title><link>http://arxiv.org/abs/2305.08298v2</link><description>We present symbol tuning - finetuning language models on in-contextinput-label pairs where natural language labels (e.g., "positive/negativesentiment") are replaced with arbitrary symbols (e.g., "foo/bar"). Symboltuning leverages the intuition that when a model cannot use instructions ornatural language labels to figure out a task, it must instead do so by learningthe input-label mappings. We experiment with symbol tuning across Flan-PaLM models up to 540Bparameters and observe benefits across various settings. First, symbol tuningboosts performance on unseen in-context learning tasks and is much more robustto underspecified prompts, such as those without instructions or withoutnatural language labels. Second, symbol-tuned models are much stronger atalgorithmic reasoning tasks, with up to 18.2% better performance on the ListFunctions benchmark and up to 15.3% better performance on the Simple TuringConcepts benchmark. Finally, symbol-tuned models show large improvements infollowing flipped-labels presented in-context, meaning that they are morecapable of using in-context information to override prior semantic knowledge.</description><author>Jerry Wei, Le Hou, Andrew Lampinen, Xiangning Chen, Da Huang, Yi Tay, Xinyun Chen, Yifeng Lu, Denny Zhou, Tengyu Ma, Quoc V. Le</author><pubDate>Sat, 30 Dec 2023 21:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08298v2</guid></item><item><title>Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations</title><link>http://arxiv.org/abs/2309.02332v2</link><description>In the intricate architecture of the mammalian central nervous system,neurons form populations. Axonal bundles communicate between these clustersusing spike trains. However, these neuron populations' precise encoding andoperations have yet to be discovered. In our analysis, the starting point is astate-of-the-art mechanistic model of a generic neuron endowed with plasticity.From this simple framework emerges a subtle mathematical construct: Therepresentation and manipulation of information can be precisely characterizedby an algebra of convex cones. Furthermore, these neuron populations are notmerely passive transmitters. They act as operators within this algebraicstructure, mirroring the functionality of a low-level programming language.When these populations interconnect, they embody succinct yet potent algebraicexpressions. These networks allow them to implement many operations, such asspecialization, generalization, novelty detection, dimensionality reduction,inverse modeling, prediction, and associative memory. In broader terms, thiswork illuminates the potential of matrix embeddings in advancing ourunderstanding in fields like cognitive science and AI. These embeddings enhancethe capacity for concept processing and hierarchical description over theirvector counterparts.</description><author>Martin N. P. Nilsson</author><pubDate>Sat, 30 Dec 2023 21:11:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02332v2</guid></item><item><title>Solving Satisfiability Modulo Counting for Symbolic and Statistical AI Integration With Provable Guarantees</title><link>http://arxiv.org/abs/2309.08883v2</link><description>Satisfiability Modulo Counting (SMC) encompasses problems that require bothsymbolic decision-making and statistical reasoning. Its general formulationcaptures many real-world problems at the intersection of symbolic andstatistical Artificial Intelligence. SMC searches for policy interventions tocontrol probabilistic outcomes. Solving SMC is challenging because of itshighly intractable nature($\text{NP}^{\text{PP}}$-complete), incorporatingstatistical inference and symbolic reasoning. Previous research on SMC solvinglacks provable guarantees and/or suffers from sub-optimal empiricalperformance, especially when combinatorial constraints are present. We proposeXOR-SMC, a polynomial algorithm with access to NP-oracles, to solve highlyintractable SMC problems with constant approximation guarantees. XOR-SMCtransforms the highly intractable SMC into satisfiability problems, byreplacing the model counting in SMC with SAT formulae subject to randomized XORconstraints. Experiments on solving important SMC problems in AI for socialgood demonstrate that XOR-SMC finds solutions close to the true optimum,outperforming several baselines which struggle to find good approximations forthe intractable model counting in SMC.</description><author>Jinzhao Li, Nan Jiang, Yexiang Xue</author><pubDate>Sat, 30 Dec 2023 21:05:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08883v2</guid></item><item><title>Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits</title><link>http://arxiv.org/abs/2306.14872v3</link><description>This paper is motivated by recent research in the $d$-dimensional stochasticlinear bandit literature, which has revealed an unsettling discrepancy:algorithms like Thompson sampling and Greedy demonstrate promising empiricalperformance, yet this contrasts with their pessimistic theoretical regretbounds. The challenge arises from the fact that while these algorithms mayperform poorly in certain problem instances, they generally excel in typicalinstances. To address this, we propose a new data-driven technique that tracksthe geometric properties of the uncertainty ellipsoid around the main problemparameter. This methodology enables us to formulate an instance-dependentfrequentist regret bound, which incorporates the geometric information, for abroad class of base algorithms, including Greedy, OFUL, and Thompson sampling.This result allows us to identify and ``course-correct" problem instances inwhich the base algorithms perform poorly. The course-corrected algorithmsachieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$for a $T$-period decision-making scenario, effectively maintaining thedesirable attributes of the base algorithms, including their empiricalefficacy. We present simulation results to validate our findings usingsynthetic and real data.</description><author>Yuwei Luo, Mohsen Bayati</author><pubDate>Sat, 30 Dec 2023 20:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14872v3</guid></item><item><title>Machine Mindset: An MBTI Exploration of Large Language Models</title><link>http://arxiv.org/abs/2312.12999v3</link><description>We present a novel approach for integrating Myers-Briggs Type Indicator(MBTI) personality traits into large language models (LLMs), addressing thechallenges of personality consistency in personalized AI. Our method, "MachineMindset," involves a two-phase fine-tuning and Direct Preference Optimization(DPO) to embed MBTI traits into LLMs. This approach ensures that modelsinternalize these traits, offering a stable and consistent personality profile.We demonstrate the effectiveness of our models across various domains, showingalignment between model performance and their respective MBTI traits. The paperhighlights significant contributions in the development of personality datasetsand a new training methodology for personality integration in LLMs, enhancingthe potential for personalized AI applications. We also open-sourced our modeland part of the data at \url{https://github.com/PKU-YuanGroup/Machine-Mindset}.</description><author>Jiaxi Cui, Liuzhenghao Lv, Jing Wen, Rongsheng Wang, Jing Tang, YongHong Tian, Li Yuan</author><pubDate>Sat, 30 Dec 2023 17:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12999v3</guid></item></channel></rss>