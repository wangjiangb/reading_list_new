<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 15 Oct 2024 13:00:23 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models</title><link>http://arxiv.org/abs/2410.10821v1</link><description>3D meshes are widely used in computer vision and graphics for theirefficiency in animation and minimal memory use, playing a crucial role inmovies, games, AR, and VR. However, creating temporally consistent andrealistic textures for mesh sequences remains labor-intensive for professionalartists. On the other hand, while video diffusion models excel at text-drivenvideo generation, they often lack 3D geometry awareness and struggle withachieving multi-view consistent texturing for 3D meshes. In this work, wepresent Tex4D, a zero-shot approach that integrates inherent 3D geometryknowledge from mesh sequences with the expressiveness of video diffusion modelsto produce multi-view and temporally consistent 4D textures. Given anuntextured mesh sequence and a text prompt as inputs, our method enhancesmulti-view consistency by synchronizing the diffusion process across differentviews through latent aggregation in the UV space. To ensure temporalconsistency, we leverage prior knowledge from a conditional video generationmodel for texture synthesis. However, straightforwardly combining the videodiffusion model and the UV texture aggregation leads to blurry results. Weanalyze the underlying causes and propose a simple yet effective modificationto the DDIM sampling process to address this issue. Additionally, we introducea reference latent texture to strengthen the correlation between frames duringthe denoising process. To the best of our knowledge, Tex4D is the first methodspecifically designed for 4D scene texturing. Extensive experiments demonstrateits superiority in producing multi-view and multi-frame consistent videos basedon untextured mesh sequences.</description><author>Jingzhi Bao, Xueting Li, Ming-Hsuan Yang</author><pubDate>Mon, 14 Oct 2024 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10821v1</guid></item><item><title>When Does Perceptual Alignment Benefit Vision Representations?</title><link>http://arxiv.org/abs/2410.10817v1</link><description>Humans judge perceptual similarity according to diverse visual attributes,including scene layout, subject location, and camera pose. Existing visionmodels understand a wide range of semantic abstractions but improperly weighthese attributes and thus make inferences misaligned with human perception.While vision representations have previously benefited from alignment incontexts like image generation, the utility of perceptually alignedrepresentations in more general-purpose settings remains unclear. Here, weinvestigate how aligning vision model representations to human perceptualjudgments impacts their usability across diverse computer vision tasks. Wefinetune state-of-the-art models on human similarity judgments for imagetriplets and evaluate them across standard vision benchmarks. We find thataligning models to perceptual judgments yields representations that improveupon the original backbones across many downstream tasks, including counting,segmentation, depth estimation, instance retrieval, and retrieval-augmentedgeneration. In addition, we find that performance is widely preserved on othertasks, including specialized out-of-distribution domains such as in medicalimaging and 3D environment frames. Our results suggest that injecting aninductive bias about human perceptual knowledge into vision models cancontribute to better representations.</description><author>Shobhita Sundaram, Stephanie Fu, Lukas Muttenthaler, Netanel Y. Tamir, Lucy Chai, Simon Kornblith, Trevor Darrell, Phillip Isola</author><pubDate>Mon, 14 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10817v1</guid></item><item><title>DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</title><link>http://arxiv.org/abs/2410.10819v1</link><description>Deploying long-context large language models (LLMs) is essential but posessignificant computational and memory challenges. Caching all Key and Value (KV)states across all attention heads consumes substantial memory. Existing KVcache pruning methods either damage the long-context capabilities of LLMs oroffer only limited efficiency improvements. In this paper, we identify thatonly a fraction of attention heads, a.k.a, Retrieval Heads, are critical forprocessing long contexts and require full attention across all tokens. Incontrast, all other heads, which primarily focus on recent tokens and attentionsinks--referred to as Streaming Heads--do not require full attention. Based onthis insight, we introduce DuoAttention, a framework that only applies a fullKV cache to retrieval heads while using a light-weight, constant-length KVcache for streaming heads, which reduces both LLM's decoding and pre-fillingmemory and latency without compromising its long-context abilities.DuoAttention uses a lightweight, optimization-based algorithm with syntheticdata to identify retrieval heads accurately. Our method significantly reduceslong-context inference memory by up to 2.55x for MHA and 1.67x for GQA modelswhile speeding up decoding by up to 2.18x and 1.50x and acceleratingpre-filling by up to 1.73x and 1.63x for MHA and GQA models, respectively, withminimal accuracy loss compared to full attention. Notably, combined withquantization, DuoAttention enables Llama-3-8B decoding with 3.3 million contextlength on a single A100 GPU. Code is provided inhttps://github.com/mit-han-lab/duo-attention.</description><author>Guangxuan Xiao, Jiaming Tang, Jingwei Zuo, Junxian Guo, Shang Yang, Haotian Tang, Yao Fu, Song Han</author><pubDate>Mon, 14 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10819v1</guid></item><item><title>TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models</title><link>http://arxiv.org/abs/2410.10818v1</link><description>Understanding fine-grained temporal dynamics is crucial for multimodal videocomprehension and generation. Due to the lack of fine-grained temporalannotations, existing video benchmarks mostly resemble static image benchmarksand are incompetent at evaluating models for temporal understanding. In thispaper, we introduce TemporalBench, a new benchmark dedicated to evaluatingfine-grained temporal understanding in videos. TemporalBench consists of ~10Kvideo question-answer pairs, derived from ~2K high-quality human annotationsdetailing the temporal dynamics in video clips. As a result, our benchmarkprovides a unique testbed for evaluating various temporal understanding andreasoning abilities such as action frequency, motion magnitude, event order,etc. Moreover, it enables evaluations on various tasks like both video questionanswering and captioning, both short and long video understanding, as well asdifferent models such as multimodal video embedding models and text generationmodels. Results show that state-of-the-art models like GPT-4o achieve only38.5% question answering accuracy on TemporalBench, demonstrating a significantgap (~30%) between humans and AI in temporal understanding. Furthermore, wenotice a critical pitfall for multi-choice QA where LLMs can detect the subtlechanges in negative captions and find a centralized description as a cue forits prediction, where we propose Multiple Binary Accuracy (MBA) to correct suchbias. We hope that TemporalBench can foster research on improving models'temporal reasoning capabilities. Both dataset and evaluation code will be madeavailable.</description><author>Mu Cai, Reuben Tan, Jianrui Zhang, Bocheng Zou, Kai Zhang, Feng Yao, Fangrui Zhu, Jing Gu, Yiwu Zhong, Yuzhang Shang, Yao Dou, Jaden Park, Jianfeng Gao, Yong Jae Lee, Jianwei Yang</author><pubDate>Mon, 14 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10818v1</guid></item><item><title>LVD-2M: A Long-take Video Dataset with Temporally Dense Captions</title><link>http://arxiv.org/abs/2410.10816v1</link><description>The efficacy of video generation models heavily depends on the quality oftheir training datasets. Most previous video generation models are trained onshort video clips, while recently there has been increasing interest intraining long video generation models directly on longer videos. However, thelack of such high-quality long videos impedes the advancement of long videogeneration. To promote research in long video generation, we desire a newdataset with four key features essential for training long video generationmodels: (1) long videos covering at least 10 seconds, (2) long-take videoswithout cuts, (3) large motion and diverse contents, and (4) temporally densecaptions. To achieve this, we introduce a new pipeline for selectinghigh-quality long-take videos and generating temporally dense captions.Specifically, we define a set of metrics to quantitatively assess video qualityincluding scene cuts, dynamic degrees, and semantic-level quality, enabling usto filter high-quality long-take videos from a large amount of source videos.Subsequently, we develop a hierarchical video captioning pipeline to annotatelong videos with temporally-dense captions. With this pipeline, we curate thefirst long-take video dataset, LVD-2M, comprising 2 million long-take videos,each covering more than 10 seconds and annotated with temporally densecaptions. We further validate the effectiveness of LVD-2M by fine-tuning videogeneration models to generate long videos with dynamic motions. We believe ourwork will significantly contribute to future research in long video generation.</description><author>Tianwei Xiong, Yuqing Wang, Daquan Zhou, Zhijie Lin, Jiashi Feng, Xihui Liu</author><pubDate>Mon, 14 Oct 2024 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10816v1</guid></item><item><title>Depth Any Video with Scalable Synthetic Data</title><link>http://arxiv.org/abs/2410.10815v1</link><description>Video depth estimation has long been hindered by the scarcity of consistentand scalable ground truth data, leading to inconsistent and unreliable results.In this paper, we introduce Depth Any Video, a model that tackles the challengethrough two key innovations. First, we develop a scalable synthetic datapipeline, capturing real-time video depth data from diverse syntheticenvironments, yielding 40,000 video clips of 5-second duration, each withprecise depth annotations. Second, we leverage the powerful priors ofgenerative video diffusion models to handle real-world videos effectively,integrating advanced techniques such as rotary position encoding and flowmatching to further enhance flexibility and efficiency. Unlike previous models,which are limited to fixed-length video sequences, our approach introduces anovel mixed-duration training strategy that handles videos of varying lengthsand performs robustly across different frame rates-even on single frames. Atinference, we propose a depth interpolation method that enables our model toinfer high-resolution video depth across sequences of up to 150 frames. Ourmodel outperforms all previous generative depth models in terms of spatialaccuracy and temporal consistency.</description><author>Honghui Yang, Di Huang, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin, Wanli Ouyang, Tong He</author><pubDate>Mon, 14 Oct 2024 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10815v1</guid></item><item><title>Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free</title><link>http://arxiv.org/abs/2410.10814v1</link><description>While large language models (LLMs) excel on generation tasks, theirdecoder-only architecture often limits their potential as embedding models ifno further representation finetuning is applied. Does this contradict theirclaim of generalists? To answer the question, we take a closer look atMixture-of-Experts (MoE) LLMs. Our study shows that the expert routers in MoELLMs can serve as an off-the-shelf embedding model with promising performanceon a diverse class of embedding-focused tasks, without requiring anyfinetuning. Moreover, our extensive analysis shows that the MoE routing weights(RW) is complementary to the hidden state (HS) of LLMs, a widely-usedembedding. Compared to HS, we find that RW is more robust to the choice ofprompts and focuses on high-level semantics. Motivated by the analysis, wepropose MoEE combining RW and HS, which achieves better performance than usingeither separately. Our exploration of their combination and prompting strategyshed several novel insights, e.g., a weighted sum of RW and HS similaritiesoutperforms the similarity on their concatenation. Our experiments areconducted on 6 embedding tasks with 20 datasets from the Massive Text EmbeddingBenchmark (MTEB). The results demonstrate the significant improvement broughtby MoEE to LLM-based embedding without further finetuning.</description><author>Ziyue Li, Tianyi Zhou</author><pubDate>Mon, 14 Oct 2024 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10814v1</guid></item><item><title>LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory</title><link>http://arxiv.org/abs/2410.10813v1</link><description>Recent large language model (LLM)-driven chat assistant systems haveintegrated memory components to track user-assistant chat histories, enablingmore accurate and personalized responses. However, their long-term memorycapabilities in sustained interactions remain underexplored. This paperintroduces LongMemEval, a comprehensive benchmark designed to evaluate fivecore long-term memory abilities of chat assistants: information extraction,multi-session reasoning, temporal reasoning, knowledge updates, and abstention.With 500 meticulously curated questions embedded within freely scalableuser-assistant chat histories, LongMemEval presents a significant challenge toexisting long-term memory systems, with commercial chat assistants andlong-context LLMs showing 30% accuracy drop on memorizing information acrosssustained interactions. We then present a unified framework that breaks downthe long-term memory design into four design choices across the indexing,retrieval, and reading stages. Built upon key experimental insights, we proposeseveral memory designs including session decomposition for optimizing valuegranularity, fact-augmented key expansion for enhancing the index structure,and time-aware query expansion for refining the search scope. Experimentresults show that these optimizations greatly improve both memory recall anddownstream question answering on LongMemEval. Overall, our study providesvaluable resources and guidance for advancing the long-term memory capabilitiesof LLM-based chat assistants, paving the way toward more personalized andreliable conversational AI.</description><author>Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, Dong Yu</author><pubDate>Mon, 14 Oct 2024 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10813v1</guid></item><item><title>HART: Efficient Visual Generation with Hybrid Autoregressive Transformer</title><link>http://arxiv.org/abs/2410.10812v1</link><description>We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)visual generation model capable of directly generating 1024x1024 images,rivaling diffusion models in image generation quality. Existing AR models facelimitations due to the poor image reconstruction quality of their discretetokenizers and the prohibitive training costs associated with generating 1024pximages. To address these challenges, we present the hybrid tokenizer, whichdecomposes the continuous latents from the autoencoder into two components:discrete tokens representing the big picture and continuous tokens representingthe residual components that cannot be represented by the discrete tokens. Thediscrete component is modeled by a scalable-resolution discrete AR model, whilethe continuous component is learned with a lightweight residual diffusionmodule with only 37M parameters. Compared with the discrete-only VAR tokenizer,our hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,leading to a 31% generation FID improvement from 7.85 to 5.38. HART alsooutperforms state-of-the-art diffusion models in both FID and CLIP score, with4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourcedat https://github.com/mit-han-lab/hart.</description><author>Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han</author><pubDate>Mon, 14 Oct 2024 17:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10812v1</guid></item><item><title>Deep Linear Probe Generators for Weight Space Learning</title><link>http://arxiv.org/abs/2410.10811v1</link><description>Weight space learning aims to extract information about a neural network,such as its training dataset or generalization error. Recent approaches learndirectly from model weights, but this presents many challenges as weights arehigh-dimensional and include permutation symmetries between neurons. Analternative approach, Probing, represents a model by passing a set of learnedinputs (probes) through the model, and training a predictor on top of thecorresponding outputs. Although probing is typically not used as a stand aloneapproach, our preliminary experiment found that a vanilla probing baselineworked surprisingly well. However, we discover that current probe learningstrategies are ineffective. We therefore propose Deep Linear Probe Generators(ProbeGen), a simple and effective modification to probing approaches. ProbeGenadds a shared generator module with a deep linear architecture, providing aninductive bias towards structured probes thus reducing overfitting. Whilesimple, ProbeGen performs significantly better than the state-of-the-art and isvery efficient, requiring between 30 to 1000 times fewer FLOPs than other topapproaches.</description><author>Jonathan Kahana, Eliahu Horwitz, Imri Shuval, Yedid Hoshen</author><pubDate>Mon, 14 Oct 2024 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10811v1</guid></item><item><title>Local and Global Decoding in Text Generation</title><link>http://arxiv.org/abs/2410.10810v1</link><description>Text generation, a key component in applications such as dialogue systems,relies on decoding algorithms that sample strings from a language modeldistribution. Traditional methods, such as top-$k$ and top-$\pi$, apply localnormalisation to the model's output distribution, which can distort it. In thispaper, we investigate the effect of this distortion by introducingglobally-normalised versions of these decoding methods. Additionally, wepropose an independent Metropolis-Hastings algorithm to approximate samplingfrom globally-normalised distributions without explicitly computing them. Ourempirical analysis compares the performance of local and global normalisationacross two decoding algorithms (top-$k$ and top-$\pi$) with varioushyperparameters, using Pythia language models. Results show that, in mostconfigurations, global decoding performs worse than the local decoding versionof the same algorithms -- despite preserving the distribution's integrity. Ourresults suggest that distortion is an important feature of local decodingalgorithms.</description><author>Daniel Gareev, Thomas Hofmann, Ezhilmathi Krishnasamy, Tiago Pimentel</author><pubDate>Mon, 14 Oct 2024 17:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10810v1</guid></item><item><title>Hard-Constrained Neural Networks with Universal Approximation Guarantees</title><link>http://arxiv.org/abs/2410.10807v1</link><description>Incorporating prior knowledge or specifications of input-output relationshipsinto machine learning models has gained significant attention, as it enhancesgeneralization from limited data and leads to conforming outputs. However, mostexisting approaches use soft constraints by penalizing violations throughregularization, which offers no guarantee of constraint satisfaction -- anessential requirement in safety-critical applications. On the other hand,imposing hard constraints on neural networks may hinder their representationalpower, adversely affecting performance. To address this, we propose HardNet, apractical framework for constructing neural networks that inherently satisfyhard constraints without sacrificing model capacity. Specifically, we encodeaffine and convex hard constraints, dependent on both inputs and outputs, byappending a differentiable projection layer to the network's output. Thisarchitecture allows unconstrained optimization of the network parameters usingstandard algorithms while ensuring constraint satisfaction by construction.Furthermore, we show that HardNet retains the universal approximationcapabilities of neural networks. We demonstrate the versatility andeffectiveness of HardNet across various applications: fitting functions underconstraints, learning optimization solvers, optimizing control policies insafety-critical systems, and learning safe decision logic for aircraft systems.</description><author>Youngjae Min, Anoopkumar Sonar, Navid Azizan</author><pubDate>Mon, 14 Oct 2024 17:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10807v1</guid></item><item><title>TL-PCA: Transfer Learning of Principal Component Analysis</title><link>http://arxiv.org/abs/2410.10805v1</link><description>Principal component analysis (PCA) can be significantly limited when there istoo few examples of the target data of interest. We propose a transfer learningapproach to PCA (TL-PCA) where knowledge from a related source task is used inaddition to the scarce data of a target task. Our TL-PCA has two versions, onethat uses a pretrained PCA solution of the source task, and another that usesthe source data. Our proposed approach extends the PCA optimization objectivewith a penalty on the proximity of the target subspace and the source subspaceas given by the pretrained source model or the source data. This optimizationis solved by eigendecomposition for which the number of data-dependenteigenvectors (i.e., principal directions of TL-PCA) is not limited to thenumber of target data examples, which is a root cause that limits the standardPCA performance. Accordingly, our results for image datasets show that therepresentation of test data is improved by TL-PCA for dimensionality reductionwhere the learned subspace dimension is lower or higher than the number oftarget data examples.</description><author>Sharon Hendy, Yehuda Dar</author><pubDate>Mon, 14 Oct 2024 17:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10805v1</guid></item><item><title>TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction</title><link>http://arxiv.org/abs/2410.10804v1</link><description>Accurate prediction of human or vehicle trajectories with good diversity thatcaptures their stochastic nature is an essential task for many applications.However, many trajectory prediction models produce unreasonable trajectorysamples that focus on improving diversity or accuracy while neglecting otherkey requirements, such as collision avoidance with the surrounding environment.In this work, we propose TrajDiffuse, a planning-based trajectory predictionmethod using a novel guided conditional diffusion model. We form the trajectoryprediction problem as a denoising impaint task and design a map-based guidanceterm for the diffusion process. TrajDiffuse is able to generate trajectorypredictions that match or exceed the accuracy and diversity of the SOTA, whileadhering almost perfectly to environmental constraints. We demonstrate theutility of our model through experiments on the nuScenes and PFSD datasets andprovide an extensive benchmark analysis against the SOTA methods.</description><author>Qingze, Liu, Danrui Li, Samuel S. Sohn, Sejong Yoon, Mubbasir Kapadia, Vladimir Pavlovic</author><pubDate>Mon, 14 Oct 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10804v1</guid></item><item><title>Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies</title><link>http://arxiv.org/abs/2410.10803v1</link><description>Humanoid robots capable of autonomous operation in diverse environments havelong been a goal for roboticists. However, autonomous manipulation by humanoidrobots has largely been restricted to one specific scene, primarily due to thedifficulty of acquiring generalizable skills. Recent advances in 3D visuomotorpolicies, such as the 3D Diffusion Policy (DP3), have shown promise inextending these capabilities to wilder environments. However, 3D visuomotorpolicies often rely on camera calibration and point-cloud segmentation, whichpresent challenges for deployment on mobile robots like humanoids. In thiswork, we introduce the Improved 3D Diffusion Policy (iDP3), a novel 3Dvisuomotor policy that eliminates these constraints by leveraging egocentric 3Dvisual representations. We demonstrate that iDP3 enables a full-sized humanoidrobot to autonomously perform skills in diverse real-world scenarios, usingonly data collected in the lab. Videos are available at:https://humanoid-manipulation.github.io</description><author>Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen, Xialin He, Ying Yuan, Xue Bin Peng, Jiajun Wu</author><pubDate>Mon, 14 Oct 2024 17:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10803v1</guid></item><item><title>Boosting Camera Motion Control for Video Diffusion Transformers</title><link>http://arxiv.org/abs/2410.10802v1</link><description>Recent advancements in diffusion models have significantly enhanced thequality of video generation. However, fine-grained control over camera poseremains a challenge. While U-Net-based models have shown promising results forcamera control, transformer-based diffusion models (DiT)-the preferredarchitecture for large-scale video generation - suffer from severe degradationin camera motion accuracy. In this paper, we investigate the underlying causesof this issue and propose solutions tailored to DiT architectures. Our studyreveals that camera control performance depends heavily on the choice ofconditioning methods rather than camera pose representations that is commonlybelieved. To address the persistent motion degradation in DiT, we introduceCamera Motion Guidance (CMG), based on classifier-free guidance, which boostscamera control by over 400%. Additionally, we present a sparse camera controlpipeline, significantly simplifying the process of specifying camera poses forlong videos. Our method universally applies to both U-Net and DiT models,offering improved camera control for video generation tasks.</description><author>Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang</author><pubDate>Mon, 14 Oct 2024 17:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10802v1</guid></item><item><title>Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment</title><link>http://arxiv.org/abs/2404.12318v2</link><description>Aligning language models (LMs) based on human-annotated preference data is acrucial step in obtaining practical and performant LM-based systems. However,multilingual human preference data are difficult to obtain at scale, making itchallenging to extend this framework to diverse languages. In this work, weevaluate a simple approach for zero-shot cross-lingual alignment, where areward model is trained on preference data in one source language and directlyapplied to other target languages. On summarization and open-ended dialoggeneration, we show that this method is consistently successful undercomprehensive evaluation settings, including human evaluation: cross-linguallyaligned models are preferred by humans over unaligned models on up to &gt;70% ofevaluation instances. We moreover find that a different-language reward modelsometimes yields better aligned models than a same-language reward model. Wealso identify best practices when there is no language-specific data for evensupervised finetuning, another component in alignment.</description><author>Zhaofeng Wu, Ananth Balashankar, Yoon Kim, Jacob Eisenstein, Ahmad Beirami</author><pubDate>Mon, 14 Oct 2024 17:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12318v2</guid></item><item><title>Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning</title><link>http://arxiv.org/abs/2410.10801v1</link><description>Large Language Models (LLMs) have been adopted and deployed worldwide for abroad variety of applications. However, ensuring their safe use remains asignificant challenge. Preference training and safety measures often overfit toharms prevalent in Western-centric datasets, and safety protocols frequentlyfail to extend to multilingual settings. In this work, we explore model mergingin a diverse multi-task setting, combining safety and general-purpose taskswithin a multilingual context. Each language introduces unique and variedlearning challenges across tasks. We find that objective-based merging is moreeffective than mixing data, with improvements of up to 8% and 10% in generalperformance and safety respectively. We also find that language-based mergingis highly effective -- by merging monolingually fine-tuned models, we achieve a4% increase in general performance and 7% reduction in harm across alllanguages on top of the data mixtures method using the same available data.Overall, our comprehensive study of merging approaches provides a usefulframework for building strong and safe multilingual models.</description><author>Aakanksha, Arash Ahmadian, Seraphina Goldfarb-Tarrant, Beyza Ermis, Marzieh Fadaee, Sara Hooker</author><pubDate>Mon, 14 Oct 2024 17:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10801v1</guid></item><item><title>Learning Quadruped Locomotion Using Differentiable Simulation</title><link>http://arxiv.org/abs/2403.14864v3</link><description>This work explores the potential of using differentiable simulation forlearning quadruped locomotion. Differentiable simulation promises fastconvergence and stable training by computing low-variance first-order gradientsusing robot dynamics. However, its usage for legged robots is still limited tosimulation. The main challenge lies in the complex optimization landscape ofrobotic tasks due to discontinuous dynamics. This work proposes a newdifferentiable simulation framework to overcome these challenges. Our approachcombines a high-fidelity, non-differentiable simulator for forward dynamicswith a simplified surrogate model for gradient backpropagation. This approachmaintains simulation accuracy by aligning the robot states from the surrogatemodel with those of the precise, non-differentiable simulator. Our frameworkenables learning quadruped walking in simulation in minutes withoutparallelization. When augmented with GPU parallelization, our approach allowsthe quadruped robot to master diverse locomotion skills on challenging terrainsin minutes. We demonstrate that differentiable simulation outperforms areinforcement learning algorithm (PPO) by achieving significantly better sampleefficiency while maintaining its effectiveness in handling large-scaleenvironments. Our method represents one of the first successful applications ofdifferentiable simulation to real-world quadruped locomotion, offering acompelling alternative to traditional RL methods.</description><author>Yunlong Song, Sangbae Kim, Davide Scaramuzza</author><pubDate>Mon, 14 Oct 2024 17:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14864v3</guid></item><item><title>Towards Foundation Models for 3D Vision: How Close Are We?</title><link>http://arxiv.org/abs/2410.10799v1</link><description>Building a foundation model for 3D vision is a complex challenge that remainsunsolved. Towards that goal, it is important to understand the 3D reasoningcapabilities of current models as well as identify the gaps between thesemodels and humans. Therefore, we construct a new 3D visual understandingbenchmark that covers fundamental 3D vision tasks in the Visual QuestionAnswering (VQA) format. We evaluate state-of-the-art Vision-Language Models(VLMs), specialized models, and human subjects on it. Our results show thatVLMs generally perform poorly, while the specialized models are accurate butnot robust, failing under geometric perturbations. In contrast, human visioncontinues to be the most reliable 3D visual system. We further demonstrate thatneural networks align more closely with human 3D vision mechanisms compared toclassical computer vision methods, and Transformer-based networks such as ViTalign more closely with human 3D vision mechanisms than CNNs. We hope our studywill benefit the future development of foundation models for 3D vision.</description><author>Yiming Zuo, Karhan Kayan, Maggie Wang, Kevin Jeon, Jia Deng, Thomas L. Griffiths</author><pubDate>Mon, 14 Oct 2024 17:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10799v1</guid></item><item><title>MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling</title><link>http://arxiv.org/abs/2410.10798v1</link><description>Recent advancements in multi-modal large language models have propelled thedevelopment of joint probabilistic models capable of both image understandingand generation. However, we have identifed that recent methods inevitablysuffer from loss of image information during understanding task, due to eitherimage discretization or diffusion denoising steps. To address this issue, wepropose a novel Multi-Modal Auto-Regressive (MMAR) probabilistic modelingframework. Unlike discretization line of method, MMAR takes incontinuous-valued image tokens to avoid information loss. Differing fromdiffusion-based approaches, we disentangle the diffusion process fromauto-regressive backbone model by employing a light-weight diffusion head ontop each auto-regressed image patch embedding. In this way, when the modeltransits from image generation to understanding through text generation, thebackbone model's hidden representation of the image is not limited to the lastdenoising step. To successfully train our method, we also propose atheoretically proven technique that addresses the numerical stability issue anda training strategy that balances the generation and understanding task goals.Through extensive evaluations on 18 image understanding benchmarks, MMARdemonstrates much more superior performance than other joint multi-modalmodels, matching the method that employs pretrained CLIP vision encoder,meanwhile being able to generate high quality images at the same time. We alsoshowed that our method is scalable with larger data and model size.</description><author>Jian Yang, Dacheng Yin, Yizhou Zhou, Fengyun Rao, Wei Zhai, Yang Cao, Zheng-Jun Zha</author><pubDate>Mon, 14 Oct 2024 17:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10798v1</guid></item><item><title>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</title><link>http://arxiv.org/abs/2410.10796v1</link><description>Large language models are instruction-finetuned to enhance their ability tofollow user instructions and process the input context. However, evenstate-of-the-art models often struggle to follow the instruction, especiallywhen the input context is not aligned with the model's parametric knowledge.This manifests as various failures, such as hallucinations where the responsesare outdated, biased or contain unverified facts. In this work, we try tounderstand the underlying reason for this poor context reliance, especiallyafter instruction tuning. We observe an intriguing phenomenon: duringinstruction tuning, the context reliance initially increases as expected, butthen gradually decreases as instruction finetuning progresses. We call thisphenomenon context-parametric inversion and observe it across multiple generalpurpose instruction tuning datasets like TULU, Alpaca and Ultrachat, as well asmodel families such as Llama, Mistral and Pythia. In a simple theoreticalsetup, we isolate why context-parametric inversion occurs along the gradientdescent trajectory of instruction finetuning. We tie this phenomena to examplesin the instruction finetuning data mixture where the input context providesinformation that is already present in the model's parametric knowledge. Ouranalysis suggests natural mitigation strategies that provide some limitedgains, while also validating our theoretical insights. We hope that our workserves as a starting point in addressing this failure mode in a staple part ofLLM training.</description><author>Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan</author><pubDate>Mon, 14 Oct 2024 17:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10796v1</guid></item><item><title>Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations</title><link>http://arxiv.org/abs/2410.10792v1</link><description>Generative models transform random noise into images; their inversion aims totransform images back to structured noise for recovery and editing. This paperaddresses two key tasks: (i) inversion and (ii) editing of a real image usingstochastic equivalents of rectified flow models (such as Flux). AlthoughDiffusion Models (DMs) have recently dominated the field of generative modelingfor images, their inversion presents faithfulness and editability challengesdue to nonlinearities in drift and diffusion. Existing state-of-the-art DMinversion approaches rely on training of additional parameters or test-timeoptimization of latent variables; both are expensive in practice. RectifiedFlows (RFs) offer a promising alternative to diffusion models, yet theirinversion has been underexplored. We propose RF inversion using dynamic optimalcontrol derived via a linear quadratic regulator. We prove that the resultingvector field is equivalent to a rectified stochastic differential equation.Additionally, we extend our framework to design a stochastic sampler for Flux.Our inversion method allows for state-of-the-art performance in zero-shotinversion and editing, outperforming prior works in stroke-to-image synthesisand semantic image editing, with large-scale human evaluations confirming userpreference.</description><author>Litu Rout, Yujia Chen, Nataniel Ruiz, Constantine Caramanis, Sanjay Shakkottai, Wen-Sheng Chu</author><pubDate>Mon, 14 Oct 2024 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10792v1</guid></item><item><title>Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes</title><link>http://arxiv.org/abs/2410.10791v1</link><description>Leveraging multiple sensors is crucial for robust semantic perception inautonomous driving, as each sensor type has complementary strengths andweaknesses. However, existing sensor fusion methods often treat sensorsuniformly across all conditions, leading to suboptimal performance. Bycontrast, we propose a novel, condition-aware multimodal fusion approach forrobust semantic perception of driving scenes. Our method, CAFuser uses an RGBcamera input to classify environmental conditions and generate a ConditionToken that guides the fusion of multiple sensor modalities. We further newlyintroduce modality-specific feature adapters to align diverse sensor inputsinto a shared latent space, enabling efficient integration with a single andshared pre-trained backbone. By dynamically adapting sensor fusion based on theactual condition, our model significantly improves robustness and accuracy,especially in adverse-condition scenarios. We set the new state of the art withCAFuser on the MUSES dataset with 59.7 PQ for multimodal panoptic segmentationand 78.2 mIoU for semantic segmentation, ranking first on the publicbenchmarks.</description><author>Tim Broedermann, Christos Sakaridis, Yuqian Fu, Luc Van Gool</author><pubDate>Mon, 14 Oct 2024 17:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10791v1</guid></item><item><title>Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes</title><link>http://arxiv.org/abs/2410.10790v1</link><description>Recent advancements in human motion synthesis have focused on specific typesof motions, such as human-scene interaction, locomotion or human-humaninteraction, however, there is a lack of a unified system capable of generatinga diverse combination of motion types. In response, we introduceSitcom-Crafter, a comprehensive and extendable system for human motiongeneration in 3D space, which can be guided by extensive plot contexts toenhance workflow efficiency for anime and game designers. The system iscomprised of eight modules, three of which are dedicated to motion generation,while the remaining five are augmentation modules that ensure consistent fusionof motion sequences and system functionality. Central to the generation modulesis our novel 3D scene-aware human-human interaction module, which addressescollision issues by synthesizing implicit 3D Signed Distance Function (SDF)points around motion spaces, thereby minimizing human-scene collisions withoutadditional data collection costs. Complementing this, our locomotion andhuman-scene interaction modules leverage existing methods to enrich thesystem's motion generation capabilities. Augmentation modules encompass plotcomprehension for command generation, motion synchronization for seamlessintegration of different motion types, hand pose retrieval to enhance motionrealism, motion collision revision to prevent human collisions, and 3Dretargeting to ensure visual fidelity. Experimental evaluations validate thesystem's ability to generate high-quality, diverse, and physically realisticmotions, underscoring its potential for advancing creative workflows.</description><author>Jianqi Chen, Panwen Hu, Xiaojun Chang, Zhenwei Shi, Michael Christian Kampffmeyer, Xiaodan Liang</author><pubDate>Mon, 14 Oct 2024 17:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10790v1</guid></item><item><title>On Information-Theoretic Measures of Predictive Uncertainty</title><link>http://arxiv.org/abs/2410.10786v1</link><description>Reliable estimation of predictive uncertainty is crucial for machine learningapplications, particularly in high-stakes scenarios where hedging against risksis essential. Despite its significance, a consensus on the correct measurementof predictive uncertainty remains elusive. In this work, we return to firstprinciples to develop a fundamental framework of information-theoreticpredictive uncertainty measures. Our proposed framework categorizes predictiveuncertainty measures according to two factors: (I) The predicting model (II)The approximation of the true predictive distribution. Examining all possiblecombinations of these two factors, we derive a set of predictive uncertaintymeasures that includes both known and newly introduced ones. We empiricallyevaluate these measures in typical uncertainty estimation settings, such asmisclassification detection, selective prediction, and out-of-distributiondetection. The results show that no single measure is universal, but theeffectiveness depends on the specific setting. Thus, our work provides clarityabout the suitability of predictive uncertainty measures by clarifying theirimplicit assumptions and relationships.</description><author>Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Sepp Hochreiter</author><pubDate>Mon, 14 Oct 2024 17:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10786v1</guid></item><item><title>LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content</title><link>http://arxiv.org/abs/2410.10783v1</link><description>The large-scale training of multi-modal models on data scraped from the webhas shown outstanding utility in infusing these models with the required worldknowledge to perform effectively on multiple downstream tasks. However, onedownside of scraping data from the web can be the potential sacrifice of thebenchmarks on which the abilities of these models are often evaluated. Tosafeguard against test data contamination and to truly test the abilities ofthese foundation models we propose LiveXiv: A scalable evolving live benchmarkbased on scientific ArXiv papers. LiveXiv accesses domain-specific manuscriptsat any given timestamp and proposes to automatically generate visualquestion-answer pairs (VQA). This is done without any human-in-the-loop, usingthe multi-modal content in the manuscripts, like graphs, charts, and tables.Moreover, we introduce an efficient evaluation approach that estimates theperformance of all models on the evolving benchmark using evaluations of only asubset of models. This significantly reduces the overall evaluation cost. Webenchmark multiple open and proprietary Large Multi-modal Models (LMMs) on thefirst version of our benchmark, showing its challenging nature and exposing themodels true abilities, avoiding contamination. Lastly, in our commitment tohigh quality, we have collected and evaluated a manually verified subset. Bycomparing its overall results to our automatic annotations, we have found thatthe performance variance is indeed minimal (&lt;2.5%). Our dataset is availableonline on HuggingFace, and our code will be available here.</description><author>Nimrod Shabtay, Felipe Maia Polo, Sivan Doveh, Wei Lin, M. Jehanzeb Mirza, Leshem Chosen, Mikhail Yurochkin, Yuekai Sun, Assaf Arbelle, Leonid Karlinsky, Raja Giryes</author><pubDate>Mon, 14 Oct 2024 17:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10783v1</guid></item><item><title>3DArticCyclists: Generating Simulated Dynamic 3D Cyclists for Human-Object Interaction (HOI) and Autonomous Driving Applications</title><link>http://arxiv.org/abs/2410.10782v1</link><description>Human-object interaction (HOI) and human-scene interaction (HSI) are crucialfor human-centric scene understanding applications in Embodied ArtificialIntelligence (EAI), robotics, and augmented reality (AR). A common limitationfaced in these research areas is the data scarcity problem: insufficientlabeled human-scene object pairs on the input images, and limited interactioncomplexity and granularity between them. Recent HOI and HSI methods haveaddressed this issue by generating dynamic interactions with rigid objects. Butmore complex dynamic interactions such as a human rider pedaling an articulatedbicycle have been unexplored. To address this limitation, and to enableresearch on complex dynamic human-articulated object interactions, in thispaper we propose a method to generate simulated 3D dynamic cyclist assets andinteractions. We designed a methodology for creating a new part-basedmulti-view articulated synthetic 3D bicycle dataset that we call 3DArticBikesthat can be used to train NeRF and 3DGS-based 3D reconstruction methods. Wethen propose a 3DGS-based parametric bicycle composition model to assemble8-DoF pose-controllable 3D bicycles. Finally, using dynamic information fromcyclist videos, we build a complete synthetic dynamic 3D cyclist (riderpedaling a bicycle) by re-posing a selectable synthetic 3D person whileautomatically placing the rider onto one of our new articulated 3D bicyclesusing a proposed 3D Keypoint optimization-based Inverse Kinematics poserefinement. We present both, qualitative and quantitative results where wecompare our generated cyclists against those from a recent stablediffusion-based method.</description><author>Eduardo R. Corral-Soto, Yang Liu, Tongtong Cao, Yuan Ren, Liu Bingbing</author><pubDate>Mon, 14 Oct 2024 17:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10782v1</guid></item><item><title>When Attention Sink Emerges in Language Models: An Empirical View</title><link>http://arxiv.org/abs/2410.10781v1</link><description>Language Models (LMs) assign significant attention to the first token, evenif it is not semantically important, which is known as attention sink. Thisphenomenon has been widely adopted in applications such as streaming/longcontext generation, KV cache optimization, inference acceleration, modelquantization, and others. Despite its widespread use, a deep understanding ofattention sink in LMs is still lacking. In this work, we first demonstrate thatattention sinks exist universally in LMs with various inputs, even in smallmodels. Furthermore, attention sink is observed to emerge during the LMpre-training, motivating us to investigate how optimization, data distribution,loss function, and model architecture in LM pre-training influence itsemergence. We highlight that attention sink emerges after effectiveoptimization on sufficient training data. The sink position is highlycorrelated with the loss function and data distribution. Most importantly, wefind that attention sink acts more like key biases, storing extra attentionscores, which could be non-informative and not contribute to the valuecomputation. We also observe that this phenomenon (at least partially) stemsfrom tokens' inner dependence on attention scores as a result of softmaxnormalization. After relaxing such dependence by replacing softmax attentionwith other attention operations, such as sigmoid attention withoutnormalization, attention sinks do not emerge in LMs up to 1B parameters. Thecode is available at https://github.com/sail-sg/Attention-Sink.</description><author>Xiangming Gu, Tianyu Pang, Chao Du, Qian Liu, Fengzhuo Zhang, Cunxiao Du, Ye Wang, Min Lin</author><pubDate>Mon, 14 Oct 2024 17:50:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10781v1</guid></item><item><title>ControlMM: Controllable Masked Motion Generation</title><link>http://arxiv.org/abs/2410.10780v1</link><description>Recent advances in motion diffusion models have enabled spatiallycontrollable text-to-motion generation. However, despite achieving acceptablecontrol precision, these models suffer from generation speed and fidelitylimitations. To address these challenges, we propose ControlMM, a novelapproach incorporating spatial control signals into the generative maskedmotion model. ControlMM achieves real-time, high-fidelity, and high-precisioncontrollable motion generation simultaneously. Our approach introduces two keyinnovations. First, we propose masked consistency modeling, which ensureshigh-fidelity motion generation via random masking and reconstruction, whileminimizing the inconsistency between the input control signals and theextracted control signals from the generated motion. To further enhance controlprecision, we introduce inference-time logit editing, which manipulates thepredicted conditional motion distribution so that the generated motion, sampledfrom the adjusted distribution, closely adheres to the input control signals.During inference, ControlMM enables parallel and iterative decoding of multiplemotion tokens, allowing for high-speed motion generation. Extensive experimentsshow that, compared to the state of the art, ControlMM delivers superiorresults in motion quality, with better FID scores (0.061 vs 0.271), and highercontrol precision (average error 0.0091 vs 0.0108). ControlMM generates motions20 times faster than diffusion-based methods. Additionally, ControlMM unlocksdiverse applications such as any joint any frame control, body part timelinecontrol, and obstacle avoidance. Video visualization can be found athttps://exitudio.github.io/ControlMM-page</description><author>Ekkasit Pinyoanuntapong, Muhammad Usama Saleem, Korrawe Karunratanakul, Pu Wang, Hongfei Xue, Chen Chen, Chuan Guo, Junli Cao, Jian Ren, Sergey Tulyakov</author><pubDate>Mon, 14 Oct 2024 17:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10780v1</guid></item><item><title>Focused ReAct: Improving ReAct through Reiterate and Early Stop</title><link>http://arxiv.org/abs/2410.10779v1</link><description>Large language models (LLMs) have significantly improved their reasoning anddecision-making capabilities, as seen in methods like ReAct. However, despiteits effectiveness in tackling complex tasks, ReAct faces two main challenges:losing focus on the original question and becoming stuck in action loops. Toaddress these issues, we introduce Focused ReAct, an enhanced version of theReAct paradigm that incorporates reiteration and early stop mechanisms. Theseimprovements help the model stay focused on the original query and avoidrepetitive behaviors. Experimental results show accuracy gains of 18% to 530%and a runtime reduction of up to 34% compared to the original ReAct method.</description><author>Shuoqiu Li, Han Xu, Haipeng Chen</author><pubDate>Mon, 14 Oct 2024 17:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10779v1</guid></item><item><title>UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation</title><link>http://arxiv.org/abs/2410.10777v1</link><description>Semi-supervised semantic segmentation (SSS) aims at learning rich visualknowledge from cheap unlabeled images to enhance semantic segmentationcapability. Among recent works, UniMatch improves its precedents tremendouslyby amplifying the practice of weak-to-strong consistency regularization.Subsequent works typically follow similar pipelines and propose variousdelicate designs. Despite the achieved progress, strangely, even in thisflourishing era of numerous powerful vision models, almost all SSS works arestill sticking to 1) using outdated ResNet encoders with small-scaleImageNet-1K pre-training, and 2) evaluation on simple Pascal and Cityscapesdatasets. In this work, we argue that, it is necessary to switch the baselineof SSS from ResNet-based encoders to more capable ViT-based encoders (e.g.,DINOv2) that are pre-trained on massive data. A simple update on the encoder(even using 2x fewer parameters) can bring more significant improvement thancareful method designs. Built on this competitive baseline, we present ourupgraded and simplified UniMatch V2, inheriting the core spirit ofweak-to-strong consistency from V1, but requiring less training cost andproviding consistently better results. Additionally, witnessing the graduallysaturated performance on Pascal and Cityscapes, we appeal that we should focuson more challenging benchmarks with complex taxonomy, such as ADE20K and COCOdatasets. Code, models, and logs of all reported values, are available athttps://github.com/LiheYoung/UniMatch-V2.</description><author>Lihe Yang, Zhen Zhao, Hengshuang Zhao</author><pubDate>Mon, 14 Oct 2024 17:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10777v1</guid></item><item><title>Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention</title><link>http://arxiv.org/abs/2410.10774v1</link><description>In recent years there have been remarkable breakthroughs in image-to-videogeneration. However, the 3D consistency and camera controllability of generatedframes have remained unsolved. Recent studies have attempted to incorporatecamera control into the generation process, but their results are often limitedto simple trajectories or lack the ability to generate consistent videos frommultiple distinct camera paths for the same scene. To address theselimitations, we introduce Cavia, a novel framework for camera-controllable,multi-view video generation, capable of converting an input image into multiplespatiotemporally consistent videos. Our framework extends the spatial andtemporal attention modules into view-integrated attention modules, improvingboth viewpoint and temporal consistency. This flexible design allows for jointtraining with diverse curated data sources, including scene-level staticvideos, object-level synthetic multi-view dynamic videos, and real-worldmonocular dynamic videos. To our best knowledge, Cavia is the first of its kindthat allows the user to precisely specify camera motion while obtaining objectmotion. Extensive experiments demonstrate that Cavia surpasses state-of-the-artmethods in terms of geometric consistency and perceptual quality. Project Page:https://ir1d.github.io/Cavia/</description><author>Dejia Xu, Yifan Jiang, Chen Huang, Liangchen Song, Thorsten Gernoth, Liangliang Cao, Zhangyang Wang, Hao Tang</author><pubDate>Mon, 14 Oct 2024 17:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10774v1</guid></item><item><title>Designing a Dashboard for Transparency and Control of Conversational AI</title><link>http://arxiv.org/abs/2406.07882v3</link><description>Conversational LLMs function as black box systems, leaving users guessingabout why they see the output they do. This lack of transparency is potentiallyproblematic, especially given concerns around bias and truthfulness. To addressthis issue, we present an end-to-end prototype-connecting interpretabilitytechniques with user experience design-that seeks to make chatbots moretransparent. We begin by showing evidence that a prominent open-source LLM hasa "user model": examining the internal state of the system, we can extract datarelated to a user's age, gender, educational level, and socioeconomic status.Next, we describe the design of a dashboard that accompanies the chatbotinterface, displaying this user model in real time. The dashboard can also beused to control the user model and the system's behavior. Finally, we discuss astudy in which users conversed with the instrumented system. Our resultssuggest that users appreciate seeing internal states, which helped them exposebiased behavior and increased their sense of control. Participants also madevaluable suggestions that point to future directions for both design andmachine learning research. The project page and video demo of our TalkTunersystem are available at https://bit.ly/talktuner-project-page</description><author>Yida Chen, Aoyu Wu, Trevor DePodesta, Catherine Yeh, Kenneth Li, Nicholas Castillo Marin, Oam Patel, Jan Riecke, Shivam Raval, Olivia Seow, Martin Wattenberg, Fernanda Vigas</author><pubDate>Mon, 14 Oct 2024 17:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07882v3</guid></item><item><title>Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning</title><link>http://arxiv.org/abs/2410.10773v1</link><description>Image-based Joint-Embedding Predictive Architecture (IJEPA) offers anattractive alternative to Masked Autoencoder (MAE) for representation learningusing the Masked Image Modeling framework. IJEPA drives representations tocapture useful semantic information by predicting in latent rather than inputspace. However, IJEPA relies on carefully designed context and target windowsto avoid representational collapse. The encoder modules in IJEPA cannotadaptively modulate the type of predicted and/or target features based on thefeasibility of the masked prediction task as they are not given sufficientinformation of both context and targets. Based on the intuition that in naturalimages, information has a strong spatial bias with spatially local regionsbeing highly predictive of one another compared to distant ones. We conditionthe target encoder and context encoder modules in IJEPA with positions ofcontext and target windows respectively. Our "conditional" encoders showperformance gains on several image classification benchmark datasets, improvedrobustness to context window size and sample-efficiency during pretraining.</description><author>Etai Littwin, Vimal Thilak, Anand Gopalakrishnan</author><pubDate>Mon, 14 Oct 2024 17:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10773v1</guid></item><item><title>Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model</title><link>http://arxiv.org/abs/2405.14457v2</link><description>Machine learning models can be trained with formal privacy guarantees viadifferentially private optimizers such as DP-SGD. In this work, we focus on athreat model where the adversary has access only to the final model, with novisibility into intermediate updates. In the literature, this hidden statethreat model exhibits a significant gap between the lower bound from empiricalprivacy auditing and the theoretical upper bound provided by privacyaccounting. To challenge this gap, we propose to audit this threat model withadversaries that \emph{craft a gradient sequence} designed to maximize theprivacy loss of the final model without relying on intermediate updates. Ourexperiments show that this approach consistently outperforms previous attemptsat auditing the hidden state model. Furthermore, our results advance theunderstanding of achievable privacy guarantees within this threat model.Specifically, when the crafted gradient is inserted at every optimization step,we show that concealing the intermediate model updates in DP-SGD does notamplify privacy. The situation is more complex when the crafted gradient is notinserted at every step: our auditing lower bound matches the privacy upperbound only for an adversarially-chosen loss landscape and a sufficiently largebatch size. This suggests that existing privacy upper bounds can be improved incertain regimes.</description><author>Tudor Cebere, Aurlien Bellet, Nicolas Papernot</author><pubDate>Mon, 14 Oct 2024 17:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14457v2</guid></item><item><title>Enhancing Indonesian Automatic Speech Recognition: Evaluating Multilingual Models with Diverse Speech Variabilities</title><link>http://arxiv.org/abs/2410.08828v2</link><description>An ideal speech recognition model has the capability to transcribe speechaccurately under various characteristics of speech signals, such as speakingstyle (read and spontaneous), speech context (formal and informal), andbackground noise conditions (clean and moderate). Building such a modelrequires a significant amount of training data with diverse speechcharacteristics. Currently, Indonesian data is dominated by read, formal, andclean speech, leading to a scarcity of Indonesian data with other speechvariabilities. To develop Indonesian automatic speech recognition (ASR), wepresent our research on state-of-the-art speech recognition models, namelyMassively Multilingual Speech (MMS) and Whisper, as well as compiling a datasetcomprising Indonesian speech with variabilities to facilitate our study. Wefurther investigate the models' predictive ability to transcribe Indonesianspeech data across different variability groups. The best results were achievedby the Whisper fine-tuned model across datasets with various characteristics,as indicated by the decrease in word error rate (WER) and character error rate(CER). Moreover, we found that speaking style variability affected modelperformance the most.</description><author>Aulia Adila, Dessi Lestari, Ayu Purwarianti, Dipta Tanaya, Kurniawati Azizah, Sakriani Sakti</author><pubDate>Mon, 14 Oct 2024 17:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08828v2</guid></item><item><title>Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation</title><link>http://arxiv.org/abs/2410.10766v1</link><description>Model-free reinforcement learning has emerged as a powerful method fordeveloping robust robot control policies capable of navigating through complexand unstructured terrains. The effectiveness of these methods hinges on twoessential elements: (1) the use of massively parallel physics simulations toexpedite policy training, and (2) an environment generator tasked with craftingsufficiently challenging yet attainable terrains to facilitate continuouspolicy improvement. Existing methods of environment generation often rely onheuristics constrained by a set of parameters, limiting the diversity andrealism. In this work, we introduce the Adaptive Diffusion Terrain Generator(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Modelsto dynamically expand existing training environments by adding more diverse andcomplex terrains adaptive to the current policy. ADTG guides the diffusionmodel's generation process through initial noise optimization, blendingnoise-corrupted terrains from existing training environments weighted by thepolicy's performance in each corresponding environment. By manipulating thenoise corruption level, ADTG seamlessly transitions between generating similarterrains for policy fine-tuning and novel ones to expand training diversity.Our experiments show that the policy trained by ADTG outperforms bothprocedural generated and natural environments, along with popular navigationmethods.</description><author>Youwei Yu, Junhong Xu, Lantao Liu</author><pubDate>Mon, 14 Oct 2024 17:42:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10766v1</guid></item><item><title>Towards Generalist Robot Learning from Internet Video: A Survey</title><link>http://arxiv.org/abs/2404.19664v3</link><description>Scaling deep learning to huge internet-scraped datasets has yieldedremarkably general capabilities in natural language processing and visualunderstanding and generation. In contrast, data is scarce and expensive tocollect in robotics. This has seen robot learning struggle to match thegenerality of capabilities observed in other domains. Learning from Videos(LfV) methods seek to address this data bottleneck by augmenting traditionalrobot data with large internet-scraped video datasets. Such video data mayprovide the model with foundational information regarding physical behavioursand the physics of the world. This holds great promise for improving thegenerality of our robots. In this survey, we present an overview of the emerging field of LfV. Weoutline fundamental concepts, including the benefits and challenges of LfV. Weprovide a comprehensive review of current methods for: extracting knowledgefrom large-scale internet video; tackling key LfV challenges; and boostingdownstream reinforcement and robot learning via the use of video data. LfVdatasets and benchmarks are also reviewed. The survey closes with a criticaldiscussion of challenges and opportunities. Here, we advocate for scalablefoundation model approaches that can leverage the full range of availableinternet video to aid the learning of robot policies and dynamics models. Wehope this survey can inform and catalyse further LfV research, facilitatingprogress towards the development of general-purpose robots.</description><author>Robert McCarthy, Daniel C. H. Tan, Dominik Schmidt, Fernando Acero, Nathan Herr, Yilun Du, Thomas G. Thuruthel, Zhibin Li</author><pubDate>Mon, 14 Oct 2024 17:41:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19664v3</guid></item><item><title>AFlow: Automating Agentic Workflow Generation</title><link>http://arxiv.org/abs/2410.10762v1</link><description>Large language models (LLMs) have demonstrated remarkable potential insolving complex tasks across diverse domains, typically by employing agenticworkflows that follow detailed instructions and operational sequences. However,constructing these workflows requires significant human effort, limitingscalability and generalizability. Recent research has sought to automate thegeneration and optimization of these workflows, but existing methods still relyon initial manual setup and fall short of achieving fully automated andeffective workflow generation. To address this challenge, we reformulateworkflow optimization as a search problem over code-represented workflows,where LLM-invoking nodes are connected by edges. We introduce AFlow, anautomated framework that efficiently explores this space using Monte Carlo TreeSearch, iteratively refining workflows through code modification,tree-structured experience, and execution feedback. Empirical evaluationsacross six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7%average improvement over state-of-the-art baselines. Furthermore, AFlow enablessmaller models to outperform GPT-4o on specific tasks at 4.55% of its inferencecost in dollars. The code will be available athttps://github.com/geekan/MetaGPT.</description><author>Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu</author><pubDate>Mon, 14 Oct 2024 17:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10762v1</guid></item><item><title>Denial-of-Service Poisoning Attacks against Large Language Models</title><link>http://arxiv.org/abs/2410.10760v1</link><description>Recent studies have shown that LLMs are vulnerable to denial-of-service (DoS)attacks, where adversarial inputs like spelling errors or non-semantic promptstrigger endless outputs without generating an [EOS] token. These attacks canpotentially cause high latency and make LLM services inaccessible to otherusers or tasks. However, when there are speech-to-text interfaces (e.g., voicecommands to a robot), executing such DoS attacks becomes challenging, as it isdifficult to introduce spelling errors or non-semantic prompts through speech.A simple DoS attack in these scenarios would be to instruct the model to "Keeprepeating Hello", but we observe that relying solely on natural instructionslimits output length, which is bounded by the maximum length of the LLM'ssupervised finetuning (SFT) data. To overcome this limitation, we proposepoisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting asingle poisoned sample designed for DoS purposes can break the output lengthlimit. For example, a poisoned sample can successfully attack GPT-4o and GPT-4omini (via OpenAI's finetuning API) using less than $1, causing repeated outputsup to the maximum inference length (16K tokens, compared to 0.5K beforepoisoning). Additionally, we perform comprehensive ablation studies onopen-source LLMs and extend our method to LLM agents, where attackers cancontrol both the finetuning dataset and algorithm. Our findings underscore theurgent need for defenses against P-DoS attacks to secure LLMs. Our code isavailable at https://github.com/sail-sg/P-DoS.</description><author>Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin</author><pubDate>Mon, 14 Oct 2024 17:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10760v1</guid></item><item><title>SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization</title><link>http://arxiv.org/abs/2410.10759v1</link><description>Large language models (LLMs) have been a disruptive innovation in recentyears, and they play a crucial role in our daily lives due to their ability tounderstand and generate human-like text. Their capabilities include naturallanguage understanding, information retrieval and search, translation,chatbots, virtual assistance, and many more. However, it is well known thatLLMs are massive in terms of the number of parameters. Additionally, theself-attention mechanism in the underlying architecture of LLMs, Transformers,has quadratic complexity in terms of both computation and memory with respectto the input sequence length. For these reasons, LLM inference isresource-intensive, and thus, the throughput of LLM inference is limited,especially for the longer sequences. In this report, we design a collaborativeinference architecture between a server and its clients to alleviate thethroughput limit. In this design, we consider the available resources on bothsides, i.e., the computation and communication costs. We develop a dynamicprogramming-based algorithm to optimally allocate computation between theserver and the client device to increase the server throughput, while notviolating the service level agreement (SLA). We show in the experiments that weare able to efficiently distribute the workload allowing for roughly 1/3reduction in the server workload, while achieving 19 percent improvement over agreedy method. As a result, we are able to demonstrate that, in an environmentwith different types of LLM inference requests, the throughput of the server isimproved.</description><author>Akrit Mudvari, Yuang Jiang, Leandros Tassiulas</author><pubDate>Mon, 14 Oct 2024 17:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10759v1</guid></item><item><title>Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix</title><link>http://arxiv.org/abs/2410.10758v1</link><description>With the advancements in graph neural network, there has been increasinginterest in applying this network to ECG signal analysis. In this study, wegenerated an adjacency matrix using correlation matrix of extracted featuresand applied a graph neural network to classify arrhythmias. The proposed modelwas compared with existing approaches from the literature. The resultsdemonstrated that precision and recall for all arrhythmia classes exceeded 50%,suggesting that this method can be considered an approach for arrhythmiaclassification.</description><author>Seungwoo Han</author><pubDate>Mon, 14 Oct 2024 17:38:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10758v1</guid></item><item><title>SimpleStrat: Diversifying Language Model Generation with Stratification</title><link>http://arxiv.org/abs/2410.09038v2</link><description>Generating diverse responses from large language models (LLMs) is crucial forapplications such as planning/search and synthetic data generation, wherediversity provides distinct answers across generations. Prior approaches relyon increasing temperature to increase diversity. However, contrary to popularbelief, we show not only does this approach produce lower quality individualgenerations as temperature increases, but it depends on model's next-tokenprobabilities being similar to the true distribution of answers. We proposeSimpleStrat, an alternative approach that uses the language model itself topartition the space into strata. At inference, a random stratum is selected anda sample drawn from within the strata. To measure diversity, we introduceCoverageQA, a dataset of underspecified questions with multiple equallyplausible answers, and assess diversity by measuring KL Divergence between theoutput distribution and uniform distribution over valid ground truth answers.As computing probability per response/solution for proprietary models isinfeasible, we measure recall on ground truth solutions. Our evaluation showusing SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36average reduction in KL Divergence compared to Llama 3.</description><author>Justin Wong, Yury Orlovskiy, Michael Luo, Sanjit A. Seshia, Joseph E. Gonzalez</author><pubDate>Mon, 14 Oct 2024 17:32:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09038v2</guid></item><item><title>Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification</title><link>http://arxiv.org/abs/2410.10756v1</link><description>The generative large language models (LLMs) are increasingly used for dataaugmentation tasks, where text samples are paraphrased (or generated anew) andthen used for classifier fine-tuning. Existing works on augmentation leveragethe few-shot scenarios, where samples are given to LLMs as part of prompts,leading to better augmentations. Yet, the samples are mostly selected randomlyand a comprehensive overview of the effects of other (more ``informed'') sampleselection strategies is lacking. In this work, we compare sample selectionstrategies existing in few-shot learning literature and investigate theireffects in LLM-based textual augmentation. We evaluate this on in-distributionand out-of-distribution classifier performance. Results indicate, that whilesome ``informed'' selection strategies increase the performance of models,especially for out-of-distribution data, it happens only seldom and withmarginal performance increases. Unless further advances are made, a default ofrandom sample selection remains a good option for augmentation practitioners.</description><author>Jan Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Maria Bielikova, Peter Brusilovsky</author><pubDate>Mon, 14 Oct 2024 17:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10756v1</guid></item><item><title>AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents</title><link>http://arxiv.org/abs/2410.09024v2</link><description>The robustness of LLMs to jailbreak attacks, where users design prompts tocircumvent safety measures and misuse model capabilities, has been studiedprimarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- whichuse external tools and can execute multi-stage tasks -- may pose a greater riskif misused, but their robustness remains underexplored. To facilitate researchon LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmarkincludes a diverse set of 110 explicitly malicious agent tasks (440 withaugmentations), covering 11 harm categories including fraud, cybercrime, andharassment. In addition to measuring whether models refuse harmful agenticrequests, scoring well on AgentHarm requires jailbroken agents to maintaintheir capabilities following an attack to complete a multi-step task. Weevaluate a range of leading LLMs, and find (1) leading LLMs are surprisinglycompliant with malicious agent requests without jailbreaking, (2) simpleuniversal jailbreak templates can be adapted to effectively jailbreak agents,and (3) these jailbreaks enable coherent and malicious multi-step agentbehavior and retain model capabilities. To enable simple and reliableevaluation of attacks and defenses for LLM-based agents, we publicly releaseAgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.</description><author>Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas, Maxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, Zico Kolter, Matt Fredrikson, Eric Winsor, Jerome Wynne, Yarin Gal, Xander Davies</author><pubDate>Mon, 14 Oct 2024 17:28:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09024v2</guid></item><item><title>DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships</title><link>http://arxiv.org/abs/2410.10751v1</link><description>In recent years, diffusion models have achieved tremendous success in thefield of video generation, with controllable video generation receivingsignificant attention. However, existing control methods still face twolimitations: Firstly, control conditions (such as depth maps, 3D Mesh) aredifficult for ordinary users to obtain directly. Secondly, it's challenging todrive multiple objects through complex motions with multiple trajectoriessimultaneously. In this paper, we introduce DragEntity, a video generationmodel that utilizes entity representation for controlling the motion ofmultiple objects. Compared to previous methods, DragEntity offers two mainadvantages: 1) Our method is more user-friendly for interaction because itallows users to drag entities within the image rather than individual pixels.2) We use entity representation to represent any object in the image, andmultiple objects can maintain relative spatial relationships. Therefore, weallow multiple trajectories to control multiple objects in the image withdifferent levels of complexity simultaneously. Our experiments validate theeffectiveness of DragEntity, demonstrating its excellent performance infine-grained control in video generation.</description><author>Zhang Wan, Sheng Tang, Jiawei Wei, Ruize Zhang, Juan Cao</author><pubDate>Mon, 14 Oct 2024 17:24:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10751v1</guid></item><item><title>FlexGen: Flexible Multi-View Generation from Text and Image Inputs</title><link>http://arxiv.org/abs/2410.10745v1</link><description>In this work, we introduce FlexGen, a flexible framework designed to generatecontrollable and consistent multi-view images, conditioned on a single-viewimage, or a text prompt, or both. FlexGen tackles the challenges ofcontrollable multi-view synthesis through additional conditioning on 3D-awaretext annotations. We utilize the strong reasoning capabilities of GPT-4V togenerate 3D-aware text annotations. By analyzing four orthogonal views of anobject arranged as tiled multi-view images, GPT-4V can produce text annotationsthat include 3D-aware information with spatial relationship. By integrating thecontrol signal with proposed adaptive dual-control module, our model cangenerate multi-view images that correspond to the specified text. FlexGensupports multiple controllable capabilities, allowing users to modify textprompts to generate reasonable and corresponding unseen parts. Additionally,users can influence attributes such as appearance and material properties,including metallic and roughness. Extensive experiments demonstrate that ourapproach offers enhanced multiple controllability, marking a significantadvancement over existing multi-view diffusion models. This work hassubstantial implications for fields requiring rapid and flexible 3D contentcreation, including game development, animation, and virtual reality. Projectpage: https://xxu068.github.io/flexgen.github.io/.</description><author>Xinli Xu, Wenhang Ge, Jiantao Lin, Jiawei Feng, Lie Xu, HanFeng Zhao, Shunsi Zhang, Ying-Cong Chen</author><pubDate>Mon, 14 Oct 2024 17:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10745v1</guid></item><item><title>Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</title><link>http://arxiv.org/abs/2410.10744v1</link><description>Despite significant advancements in out-of-distribution (OOD) detection,existing methods still struggle to maintain robustness against adversarialattacks, compromising their reliability in critical real-world applications.Previous studies have attempted to address this challenge by exposing detectorsto auxiliary OOD datasets alongside adversarial training. However, theincreased data complexity inherent in adversarial training, and the myriad ofways that OOD samples can arise during testing, often prevent these approachesfrom establishing robust decision boundaries. To address these limitations, wepropose AROS, a novel approach leveraging neural ordinary differentialequations (NODEs) with Lyapunov stability theorem in order to obtain robustembeddings for OOD detection. By incorporating a tailored loss function, weapply Lyapunov stability theory to ensure that both in-distribution (ID) andOOD data converge to stable equilibrium points within the dynamical system.This approach encourages any perturbed input to return to its stableequilibrium, thereby enhancing the model's robustness against adversarialperturbations. To not use additional data, we generate fake OOD embeddings bysampling from low-likelihood regions of the ID data feature space,approximating the boundaries where OOD data are likely to reside. To thenfurther enhance robustness, we propose the use of an orthogonal binary layerfollowing the stable feature space, which maximizes the separation between theequilibrium points of ID and OOD samples. We validate our method throughextensive experiments across several benchmarks, demonstrating superiorperformance, particularly under adversarial attacks. Notably, our approachimproves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs.CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.</description><author>Hossein Mirzaei, Mackenzie W. Mathis</author><pubDate>Mon, 14 Oct 2024 17:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10744v1</guid></item><item><title>NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models</title><link>http://arxiv.org/abs/2410.10743v1</link><description>Graphs are a fundamental data structure for representing relationships inreal-world scenarios. With the success of Large Language Models (LLMs) acrossvarious natural language processing (NLP) tasks, there has been growinginterest in integrating LLMs for graph learning. However, applying LLMs tograph-related tasks poses significant challenges, as these models are notinherently designed to capture the complex structural information present ingraphs. Existing approaches address this challenge through two strategies: thechain of tasks approach, which uses Graph Neural Networks (GNNs) to encode thegraph structure so that LLMs are relieved from understanding spatial positions;and Graph-to-Text Conversion, which translates graph structures into semantictext representations that LLMs can process. Despite their progress, thesemethods often struggle to fully preserve the topological information of graphsor require extensive computational resources, limiting their practicalapplicability. In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),a novel framework that efficiently encodes graph structures by selecting keynodes as anchors and representing each node based on its relative distance tothese anchors. This position-anchored encoding effectively captures the graphtopology, enabling enhanced reasoning capabilities in LLMs over graph data.Additionally, we implement a task-specific tuning procedure to further improvestructural understanding within LLMs. Through extensive empirical evaluations,NT-LLM demonstrates significant performance improvements across a variety ofgraph-related tasks.</description><author>Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu</author><pubDate>Mon, 14 Oct 2024 17:21:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10743v1</guid></item><item><title>SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing</title><link>http://arxiv.org/abs/2410.10741v1</link><description>Effective processing, interpretation, and management of sensor data haveemerged as a critical component of cyber-physical systems. Traditionally,processing sensor data requires profound theoretical knowledge and proficiencyin signal-processing tools. However, recent works show that Large LanguageModels (LLMs) have promising capabilities in processing sensory data,suggesting their potential as copilots for developing sensing systems. To explore this potential, we construct a comprehensive benchmark,SensorBench, to establish a quantifiable objective. The benchmark incorporatesdiverse real-world sensor datasets for various tasks. The results show thatwhile LLMs exhibit considerable proficiency in simpler tasks, they faceinherent challenges in processing compositional tasks with parameter selectionscompared to engineering experts. Additionally, we investigate four promptingstrategies for sensor processing and show that self-verification can outperformall other baselines in 48% of tasks. Our study provides a comprehensivebenchmark and prompting analysis for future developments, paving the way towardan LLM-based sensor processing copilot.</description><author>Pengrui Quan, Xiaomin Ouyang, Jeya Vikranth Jeyakumar, Ziqi Wang, Yang Xing, Mani Srivastava</author><pubDate>Mon, 14 Oct 2024 17:21:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10741v1</guid></item><item><title>Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs</title><link>http://arxiv.org/abs/2410.10739v1</link><description>Large Language Models (LLMs) for public use require continuous pre-trainingto remain up-to-date with the latest data. The models also need to befine-tuned with specific instructions to maintain their ability to followinstructions accurately. Typically, LLMs are released in two versions: the BaseLLM, pre-trained on diverse data, and the instruction-refined LLM, additionallytrained with specific instructions for better instruction following. Thequestion arises as to which model should undergo continuous pre-training tomaintain its instruction-following abilities while also staying current withthe latest data. In this study, we delve into the intricate relationshipbetween continuous pre-training and instruction fine-tuning of the LLMs andinvestigate the impact of continuous pre-training on the instruction followingabilities of both the base and its instruction finetuned model. Further, theinstruction fine-tuning process is computationally intense and requires asubstantial number of hand-annotated examples for the model to learneffectively. This study aims to find the most compute-efficient strategy togain up-to-date knowledge and instruction-following capabilities withoutrequiring any instruction data and fine-tuning. We empirically prove ourfindings on the LLaMa 3, 3.1 and Qwen 2, 2.5 family of base and instructionmodels, providing a comprehensive exploration of our hypotheses across varyingsizes of pre-training data corpus and different LLMs settings.</description><author>Ishan Jindal, Chandana Badrinath, Pranjal Bharti, Lakkidi Vinay, Sachin Dev Sharma</author><pubDate>Mon, 14 Oct 2024 17:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10739v1</guid></item><item><title>DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model</title><link>http://arxiv.org/abs/2410.10738v1</link><description>Driving world models have gained increasing attention due to their ability tomodel complex physical dynamics. However, their superb modeling capability isyet to be fully unleashed due to the limited video diversity in current drivingdatasets. We introduce DrivingDojo, the first dataset tailor-made for traininginteractive world models with complex driving dynamics. Our dataset featuresvideo clips with a complete set of driving maneuvers, diverse multi-agentinterplay, and rich open-world driving knowledge, laying a stepping stone forfuture world model development. We further define an action instructionfollowing (AIF) benchmark for world models and demonstrate the superiority ofthe proposed dataset for generating action-controlled future predictions.</description><author>Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, Zhaoxiang Zhang</author><pubDate>Mon, 14 Oct 2024 17:19:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10738v1</guid></item><item><title>Online Statistical Inference for Time-varying Sample-averaged Q-learning</title><link>http://arxiv.org/abs/2410.10737v1</link><description>Reinforcement learning (RL) has emerged as a key approach for training agentsin complex and uncertain environments. Incorporating statistical inference inRL algorithms is essential for understanding and managing uncertainty in modelperformance. This paper introduces a time-varying batch-averaged Q-learningalgorithm, termed sampleaveraged Q-learning, which improves upon traditionalsingle-sample Q-learning by aggregating samples of rewards and next states tobetter account for data variability and uncertainty. We leverage the functionalcentral limit theorem (FCLT) to establish a novel framework that providesinsights into the asymptotic normality of the sample-averaged algorithm undermild conditions. Additionally, we develop a random scaling method for intervalestimation, enabling the construction of confidence intervals without requiringextra hyperparameters. Numerical experiments conducted on classic OpenAI Gymenvironments show that the time-varying sample-averaged Q-learning methodconsistently outperforms both single-sample and constant-batch Q-learningmethods, achieving superior accuracy while maintaining comparable learningspeeds.</description><author>Saunak Kumar Panda, Ruiqi Liu, Yisha Xiang</author><pubDate>Mon, 14 Oct 2024 17:17:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10737v1</guid></item><item><title>Towards Calibrated Losses for Adversarial Robust Reject Option Classification</title><link>http://arxiv.org/abs/2410.10736v1</link><description>Robustness towards adversarial attacks is a vital property for classifiers inseveral applications such as autonomous driving, medical diagnosis, etc. Also,in such scenarios, where the cost of misclassification is very high, knowingwhen to abstain from prediction becomes crucial. A natural question is whichsurrogates can be used to ensure learning in scenarios where the input pointsare adversarially perturbed and the classifier can abstain from prediction?This paper aims to characterize and design surrogates calibrated in"Adversarial Robust Reject Option" setting. First, we propose an adversarialrobust reject option loss $\ell_{d}^{\gamma}$ and analyze it for the hypothesisset of linear classifiers ($\mathcal{H}_{\textrm{lin}}$). Next, we provide acomplete characterization result for any surrogate to be$(\ell_{d}^{\gamma},\mathcal{H}_{\textrm{lin}})$- calibrated. To demonstratethe difficulty in designing surrogates to $\ell_{d}^{\gamma}$, we show negativecalibration results for convex surrogates and quasi-concave conditional riskcases (these gave positive calibration in adversarial setting without rejectoption). We also empirically argue that Shifted Double Ramp Loss (DRL) andShifted Double Sigmoid Loss (DSL) satisfy the calibration conditions. Finally,we demonstrate the robustness of shifted DRL and shifted DSL againstadversarial perturbations on a synthetically generated dataset.</description><author>Vrund Shah, Tejas Chaudhari, Naresh Manwani</author><pubDate>Mon, 14 Oct 2024 17:17:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10736v1</guid></item><item><title>Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning</title><link>http://arxiv.org/abs/2410.10735v1</link><description>Accurate mathematical reasoning with Large Language Models (LLMs) is crucialin revolutionizing domains that heavily rely on such reasoning. However, LLMsoften encounter difficulties in certain aspects of mathematical reasoning,leading to flawed reasoning and erroneous results. To mitigate these issues, weintroduce a novel mechanism, the Chain of Self-Correction (CoSC), specificallydesigned to embed self-correction as an inherent ability in LLMs, enabling themto validate and rectify their own results. The CoSC mechanism operates througha sequence of self-correction stages. In each stage, the LLMs generate aprogram to address a given problem, execute this program using program-basedtools to obtain an output, subsequently verify this output. Based on theverification, the LLMs either proceed to the next correction stage or finalizethe answer. This iterative self-correction process allows the LLMs to refinetheir reasoning steps and improve the accuracy of their mathematical reasoning.To enable the CoSC mechanism at a low cost, we employ a two-phase finetuningapproach. In the first phase, the LLMs are trained with a relatively smallvolume of seeding data generated from GPT-4, establishing an initial CoSCcapability. In the second phase, the CoSC capability is further enhanced bytraining with a larger volume of self-generated data using the trained model inthe first phase, without relying on the paid GPT-4. Our comprehensiveexperiments demonstrate that CoSC significantly improves performance ontraditional mathematical datasets among existing open-source LLMs. Notably, ourCoSC-Code-34B model achieved a 53.5% score on MATH, the most challengingmathematical reasoning dataset in the public domain, surpassing the performanceof well-established models such as ChatGPT, GPT-4, and even multi-modal LLMslike GPT-4V, Gemini-1.0 Pro, and Gemini-1.0 Ultra.</description><author>Kuofeng Gao, Huanqia Cai, Qingyao Shuai, Dihong Gong, Zhifeng Li</author><pubDate>Mon, 14 Oct 2024 17:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10735v1</guid></item><item><title>Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models</title><link>http://arxiv.org/abs/2410.10733v1</link><description>We present Deep Compression Autoencoder (DC-AE), a new family of autoencodermodels for accelerating high-resolution diffusion models. Existing autoencodermodels have demonstrated impressive results at a moderate spatial compressionratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy forhigh spatial compression ratios (e.g., 64x). We address this challenge byintroducing two key techniques: (1) Residual Autoencoding, where we design ourmodels to learn residuals based on the space-to-channel transformed features toalleviate the optimization difficulty of high spatial-compression autoencoders;(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phasestraining strategy for mitigating the generalization penalty of highspatial-compression autoencoders. With these designs, we improve theautoencoder's spatial compression ratio up to 128 while maintaining thereconstruction quality. Applying our DC-AE to latent diffusion models, weachieve significant speedup without accuracy drop. For example, on ImageNet512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedupon H100 GPU for UViT-H while achieving a better FID, compared with the widelyused SD-VAE-f8 autoencoder. Our code is available athttps://github.com/mit-han-lab/efficientvit.</description><author>Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han</author><pubDate>Mon, 14 Oct 2024 17:15:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10733v1</guid></item><item><title>Multimodal MRI Accurately Identifies Amyloid Status in Unbalanced Cohorts in Alzheimer's Disease Continuum</title><link>http://arxiv.org/abs/2406.13305v2</link><description>Amyloid-$\beta$ (A$\beta$) plaques in conjunction with hyperphosphorylatedtau proteins in the form of neurofibrillary tangles are the twoneuropathological hallmarks of Alzheimer's disease. It is well-known that theidentification of individuals with A$\beta$ positivity could enable earlydiagnosis. In this work, we aim at capturing the A$\beta$ positivity status inan unbalanced cohort enclosing subjects at different disease stages, exploitingthe underlying structural and connectivity disease-induced modulations asrevealed by structural, functional, and diffusion MRI. Of note, due to theunbalanced cohort, the outcomes may be guided by those factors rather thanamyloid accumulation. The partial views provided by each modality areintegrated in the model allowing to take full advantage of theircomplementarity in encoding the effects of the A$\beta$ accumulation, leadingto an accuracy of $0.762\pm0.04$. The specificity of the information brought byeach modality is assessed by \textit{post-hoc} explainability analysis (guidedbackpropagation), highlighting the underlying structural and functionalchanges. Noteworthy, well-established biomarker key regions related to A$\beta$deposition could be identified by all modalities, including the hippocampus,thalamus, precuneus, and cingulate gyrus, witnessing in favor of thereliability of the method as well as its potential in shading light onmodality-specific possibly unknown A$\beta$ deposition signatures.</description><author>Giorgio Dolci, Charles A. Ellis, Federica Cruciani, Lorenza Brusini, Anees Abrol, Ilaria Boscolo Galazzo, Gloria Menegaz, Vince D. Calhoun</author><pubDate>Mon, 14 Oct 2024 17:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13305v2</guid></item><item><title>Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection</title><link>http://arxiv.org/abs/2410.10728v1</link><description>We propose a novel framework that leverages large language models (LLMs) toguide the rank selection in tensor network models for higher-order dataanalysis. By utilising the intrinsic reasoning capabilities and domainknowledge of LLMs, our approach offers enhanced interpretability of the rankchoices and can effectively optimise the objective function. This frameworkenables users without specialised domain expertise to utilise tensor networkdecompositions and understand the underlying rationale within the rankselection process. Experimental results validate our method on financialhigher-order datasets, demonstrating interpretable reasoning, stronggeneralisation to unseen test data, and its potential for self-enhancement oversuccessive iterations. This work is placed at the intersection of largelanguage models and higher-order data analysis.</description><author>Giorgos Iacovides, Wuyang Zhou, Danilo Mandic</author><pubDate>Mon, 14 Oct 2024 17:09:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10728v1</guid></item><item><title>A Counterexample in Image Registration</title><link>http://arxiv.org/abs/2410.10725v1</link><description>Image registration is a widespread problem which applies models about imagetransformation or image similarity to align discrete images of the same scene.Nevertheless, the theoretical limits on its accuracy are not understood even inthe case of one-dimensional data. Just as Nyquist's sampling theorem statesconditions for the perfect reconstruction of signals from samples, there arebounds to the quality of reproductions of quantized functions from sets ofideal, noiseless samples in the absence of additional assumptions. In this workwe estimate spatially-limited piecewise constant signals from two or more setsof noiseless sampling patterns. We mainly focus on the energy of the errorfunction and find that the uncertainties of the positions of the discontinuitypoints of the function depend on the discontinuity point selected as thereference point of the signal. As a consequence, the accuracy of the estimateof the signal depends on the reference point of that signal.</description><author>Serap A. Savari</author><pubDate>Mon, 14 Oct 2024 17:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10725v1</guid></item><item><title>Large Language Models Are Active Critics in NLG Evaluation</title><link>http://arxiv.org/abs/2410.10724v1</link><description>The conventional paradigm of using large language models (LLMs) forevaluating natural language generation (NLG) systems typically relies on twokey inputs: (1) a clear definition of the NLG task to be evaluated and (2) alist of pre-defined evaluation criteria. This process treats LLMs as ''passivecritics,'' strictly following human-defined criteria for evaluation. However,as new NLG tasks emerge, the criteria for assessing text quality can varygreatly. Consequently, these rigid evaluation methods struggle to adapt todiverse NLG tasks without extensive prompt engineering customized for eachspecific task. To address this limitation, we introduce Active-Critic, a novelLLM-based NLG evaluation protocol that enables LLMs to function as ''activecritics.'' Specifically, our protocol comprises two key stages. In the firststage, the LLM is instructed to infer the target NLG task and establishrelevant evaluation criteria from the data. Building on this self-inferredinformation, the second stage dynamically optimizes the prompt to guide the LLMtoward more human-aligned scoring decisions, while also generating detailedexplanations to justify its evaluations. Experiments across four NLG evaluationtasks show that our approach achieves stronger alignment with human judgmentsthan state-of-the-art evaluation methods. Our comprehensive analysis furtherhighlights the effectiveness and explainability of Active-Critic with only asmall amount of labeled data. We will share our code and data on GitHub.</description><author>Shuying Xu, Junjie Hu, Ming Jiang</author><pubDate>Mon, 14 Oct 2024 17:04:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10724v1</guid></item><item><title>Reducing the Barriers to Entry for Foundation Model Training</title><link>http://arxiv.org/abs/2404.08811v2</link><description>The world has recently witnessed an unprecedented acceleration in demands forMachine Learning and Artificial Intelligence applications. This spike in demandhas imposed tremendous strain on the underlying technology stack in supplychain, GPU-accelerated hardware, software, datacenter power density, and energyconsumption. If left on the current technological trajectory, future demandsshow insurmountable spending trends, further limiting market players, stiflinginnovation, and widening the technology gap. To address these challenges, wepropose a fundamental change in the AI training infrastructure throughout thetechnology ecosystem. The changes require advancements in supercomputing andnovel AI training approaches, from high-end software to low-level hardware,microprocessor, and chip design, while advancing the energy efficiency requiredby a sustainable infrastructure. This paper presents the analytical frameworkthat quantitatively highlights the challenges and points to the opportunitiesto reduce the barriers to entry for training large language models.</description><author>Paolo Faraboschi, Ellis Giles, Justin Hotard, Konstanty Owczarek, Andrew Wheeler</author><pubDate>Mon, 14 Oct 2024 17:03:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08811v2</guid></item><item><title>4-LEGS: 4D Language Embedded Gaussian Splatting</title><link>http://arxiv.org/abs/2410.10719v1</link><description>The emergence of neural representations has revolutionized our means fordigitally viewing a wide range of 3D scenes, enabling the synthesis ofphotorealistic images rendered from novel views. Recently, several techniqueshave been proposed for connecting these low-level representations with thehigh-level semantics understanding embodied within the scene. These methodselevate the rich semantic understanding from 2D imagery to 3D representations,distilling high-dimensional spatial features onto 3D space. In our work, we areinterested in connecting language with a dynamic modeling of the world. We showhow to lift spatio-temporal features to a 4D representation based on 3DGaussian Splatting. %, \gal{while introducing a feature-proximity attentionmechanism that allows for neighboring features in 3D space to interact}. Thisenables an interactive interface where the user can spatiotemporally localizeevents in the video from text prompts. We demonstrate our system on public 3Dvideo datasets of people and animals performing various actions.</description><author>Gal Fiebelman, Tamir Cohen, Ayellet Morgenstern, Peter Hedman, Hadar Averbuch-Elor</author><pubDate>Mon, 14 Oct 2024 17:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10719v1</guid></item><item><title>SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators</title><link>http://arxiv.org/abs/2410.10714v1</link><description>Large Language Models (LLMs) have transformed natural language processing,but face significant challenges in widespread deployment due to their highruntime cost. In this paper, we introduce SeedLM, a novel post-trainingcompression method that uses seeds of pseudo-random generators to encode andcompress model weights. Specifically, for each block of weights, we find a seedthat is fed into a Linear Feedback Shift Register (LFSR) during inference toefficiently generate a random matrix. This matrix is then linearly combinedwith compressed coefficients to reconstruct the weight block. SeedLM reducesmemory access and leverages idle compute cycles during inference, effectivelyspeeding up memory-bound tasks by trading compute for fewer memory accesses.Unlike state-of-the-art compression methods that rely on calibration data, ourapproach is data-free and generalizes well across diverse tasks. Ourexperiments with Llama 3 70B, which is particularly challenging to compress,show that SeedLM achieves significantly better zero-shot accuracy retention at4- and 3-bit than state-of-the-art techniques, while maintaining performancecomparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over anFP16 Llama 2/3 baseline.</description><author>Rasoul Shafipour, David Harrison, Maxwell Horton, Jeffrey Marker, Houman Bedayat, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi, Saman Naderiparizi</author><pubDate>Mon, 14 Oct 2024 16:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10714v1</guid></item><item><title>Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents</title><link>http://arxiv.org/abs/2407.08516v5</link><description>This article explores the convergence of connectionist and symbolicartificial intelligence (AI), from historical debates to contemporaryadvancements. Traditionally considered distinct paradigms, connectionist AIfocuses on neural networks, while symbolic AI emphasizes symbolicrepresentation and logic. Recent advancements in large language models (LLMs),exemplified by ChatGPT and GPT-4, highlight the potential of connectionistarchitectures in handling human language as a form of symbols. The study arguesthat LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.By utilizing LLMs for text-based knowledge modeling and representation, LAAsintegrate neuro-symbolic AI principles, showcasing enhanced reasoning anddecision-making capabilities. Comparing LAAs with Knowledge Graphs within theneuro-symbolic AI theme highlights the unique strengths of LAAs in mimickinghuman-like reasoning processes, scaling effectively with large datasets, andleveraging in-context samples without explicit re-training. The researchunderscores promising avenues in neuro-vector-symbolic integration,instructional encoding, and implicit reasoning, aimed at further enhancing LAAcapabilities. By exploring the progression of neuro-symbolic AI and proposingfuture research trajectories, this work advances the understanding anddevelopment of AI technologies.</description><author>Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Anwer Al-Dulaimi, Laura E. Barnes</author><pubDate>Mon, 14 Oct 2024 16:55:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08516v5</guid></item><item><title>Benefiting from Quantum? A Comparative Study of Q-Seg, Quantum-Inspired Techniques, and U-Net for Crack Segmentation</title><link>http://arxiv.org/abs/2410.10713v1</link><description>Exploring the potential of quantum hardware for enhancing classical andreal-world applications is an ongoing challenge. This study evaluates theperformance of quantum and quantum-inspired methods compared to classicalmodels for crack segmentation. Using annotated gray-scale image patches ofconcrete samples, we benchmark a classical mean Gaussian mixture technique, aquantum-inspired fermion-based method, Q-Seg a quantum annealing-based method,and a U-Net deep learning architecture. Our results indicate thatquantum-inspired and quantum methods offer a promising alternative for imagesegmentation, particularly for complex crack patterns, and could be applied innear-future applications.</description><author>Akshaya Srinivasan, Alexander Geng, Antonio Macaluso, Maximilian Kiefer-Emmanouilidis, Ali Moghiseh</author><pubDate>Mon, 14 Oct 2024 16:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10713v1</guid></item><item><title>Ensemble of ConvNeXt V2 and MaxViT for Long-Tailed CXR Classification with View-Based Aggregation</title><link>http://arxiv.org/abs/2410.10710v1</link><description>In this work, we present our solution for the MICCAI 2024 CXR-LT challenge,achieving 4th place in Subtask 2 and 5th in Subtask 1. We leveraged an ensembleof ConvNeXt V2 and MaxViT models, pretrained on an external chest X-raydataset, to address the long-tailed distribution of chest findings. Theproposed method combines state-of-the-art image classification techniques,asymmetric loss for handling class imbalance, and view-based predictionaggregation to enhance classification performance. Through experiments, wedemonstrate the advantages of our approach in improving both detection accuracyand the handling of the long-tailed distribution in CXR findings. The code isavailable at \url{https://github.com/yamagishi0824/cxrlt24-multiview-pp}.</description><author>Yosuke Yamagishi, SHouhei Hanaoka</author><pubDate>Mon, 14 Oct 2024 16:49:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10710v1</guid></item><item><title>Revisiting Few-Shot Object Detection with Vision-Language Models</title><link>http://arxiv.org/abs/2312.14494v4</link><description>The era of vision-language models (VLMs) trained on web-scale datasetschallenges conventional formulations of "open-world" perception. In this work,we revisit the task of few-shot object detection (FSOD) in the context ofrecent foundational VLMs. First, we point out that zero-shot predictions fromVLMs such as GroundingDINO significantly outperform state-of-the-art few-shotdetectors (48 vs. 33 AP) on COCO. Despite their strong zero-shot performance,such foundation models may still be sub-optimal. For example, trucks on the webmay be defined differently from trucks for a target application such asautonomous vehicle perception. We argue that the task of few-shot recognitioncan be reformulated as aligning foundation models to target concepts using afew examples. Interestingly, such examples can be multi-modal, using both textand visual cues, mimicking instructions that are often given to humanannotators when defining a target concept of interest. Concretely, we proposeFoundational FSOD, a new benchmark protocol that evaluates detectorspre-trained on any external data and fine-tuned on multi-modal (text andvisual) K-shot examples per target class. We repurpose nuImages forFoundational FSOD, benchmark several popular open-source VLMs, and provide anempirical analysis of state-of-the-art methods. Lastly, we discuss our recentCVPR 2024 Foundational FSOD competition and share insights from the community.Notably, the winning team significantly outperforms our baseline by 23.3 mAP!Our code and dataset splits are available athttps://github.com/anishmadan23/foundational_fsod</description><author>Anish Madan, Neehar Peri, Shu Kong, Deva Ramanan</author><pubDate>Mon, 14 Oct 2024 16:44:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14494v4</guid></item><item><title>Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models</title><link>http://arxiv.org/abs/2410.10701v1</link><description>Thousands of individuals succumb annually to leukemia alone. This studyexplores the application of image processing and deep learning techniques fordetecting Acute Lymphoblastic Leukemia (ALL), a severe form of blood cancerresponsible for numerous annual fatalities. As artificial intelligencetechnologies advance, the research investigates the reliability of thesemethods in real-world scenarios. The study focuses on recent developments inALL detection, particularly using the latest YOLO series models, to distinguishbetween malignant and benign white blood cells and to identify different stagesof ALL, including early stages. Additionally, the models are capable ofdetecting hematogones, which are often misclassified as ALL. By utilizingadvanced deep learning models like YOLOv8 and YOLOv11, the study achieves highaccuracy rates reaching 98.8%, demonstrating the effectiveness of thesealgorithms across multiple datasets and various real-world situations.</description><author>Alaa Awad, Mohamed Hegazy, Salah A. Aly</author><pubDate>Mon, 14 Oct 2024 16:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10701v1</guid></item><item><title>Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues</title><link>http://arxiv.org/abs/2410.10700v1</link><description>This study exposes the safety vulnerabilities of Large Language Models (LLMs)in multi-turn interactions, where malicious users can obscure harmful intentsacross several queries. We introduce ActorAttack, a novel multi-turn attackmethod inspired by actor-network theory, which models a network of semanticallylinked actors as attack clues to generate diverse and effective attack pathstoward harmful targets. ActorAttack addresses two main challenges in multi-turnattacks: (1) concealing harmful intents by creating an innocuous conversationtopic about the actor, and (2) uncovering diverse attack paths towards the sameharmful target by leveraging LLMs' knowledge to specify the correlated actorsas various attack clues. In this way, ActorAttack outperforms existingsingle-turn and multi-turn attack methods across advanced aligned LLMs, evenfor GPT-o1. We will publish a dataset called SafeMTData, which includesmulti-turn adversarial prompts and safety alignment data, generated byActorAttack. We demonstrate that models safety-tuned using our safety datasetare more robust to multi-turn attacks. Code is available athttps://github.com/renqibing/ActorAttack.</description><author>Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao</author><pubDate>Mon, 14 Oct 2024 16:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10700v1</guid></item><item><title>Fast Convergence of $$-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler</title><link>http://arxiv.org/abs/2410.10699v1</link><description>We study the mixing time of two popular discrete time Markov chains incontinuous space, the unadjusted Langevin algorithm and the proximal sampler,which are discretizations of the Langevin dynamics. We extend mixing timeanalyses for these Markov chains to hold in $\Phi$-divergence. We show that any$\Phi$-divergence arising from a twice-differentiable strictly convex function$\Phi$ converges to $0$ exponentially fast along these Markov chains, under theassumption that their stationary distributions satisfies the corresponding$\Phi$-Sobolev inequality. Our rates of convergence are tight and include asspecial cases popular mixing time regimes, namely the mixing in chi-squareddivergence under a Poincar\'e inequality, and the mixing in relative entropyunder a log-Sobolev inequality. Our results follow by bounding the contractioncoefficients arising in the appropriate strong data processing inequalities.</description><author>Siddharth Mitra, Andre Wibisono</author><pubDate>Mon, 14 Oct 2024 16:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10699v1</guid></item><item><title>Dimension-free uniform concentration bound for logistic regression</title><link>http://arxiv.org/abs/2405.18055v5</link><description>We provide a novel dimension-free uniform concentration bound for theempirical risk function of constrained logistic regression. Our bound yields amilder sufficient condition for a uniform law of large numbers than conditionsderived by the Rademacher complexity argument and McDiarmid's inequality. Thederivation is based on the PAC-Bayes approach with second-order expansion andRademacher-complexity-based bounds for the residual term of the expansion.</description><author>Shogo Nakakita</author><pubDate>Mon, 14 Oct 2024 16:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18055v5</guid></item><item><title>TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model</title><link>http://arxiv.org/abs/2410.10696v1</link><description>Recently, 2D speaking avatars have increasingly participated in everydayscenarios due to the fast development of facial animation techniques. However,most existing works neglect the explicit control of human bodies. In thispaper, we propose to drive not only the faces but also the torso and gesturemovements of a speaking figure. Inspired by recent advances in diffusionmodels, we propose the Motion-Enhanced Textural-Aware ModeLing for SpeaKingAvatar Reenactment (TALK-Act) framework, which enables high-fidelity avatarreenactment from only short footage of monocular video. Our key idea is toenhance the textural awareness with explicit motion guidance in diffusionmodeling. Specifically, we carefully construct 2D and 3D structural informationas intermediate guidance. While recent diffusion models adopt a side networkfor control information injection, they fail to synthesize temporally stableresults even with person-specific fine-tuning. We propose a Motion-EnhancedTextural Alignment module to enhance the bond between driving and targetsignals. Moreover, we build a Memory-based Hand-Recovering module to help withthe difficulties in hand-shape preserving. After pre-training, our model canachieve high-fidelity 2D avatar reenactment with only 30 seconds ofperson-specific data. Extensive experiments demonstrate the effectiveness andsuperiority of our proposed framework. Resources can be found athttps://guanjz20.github.io/projects/TALK-Act.</description><author>Jiazhi Guan, Quanwei Yang, Kaisiyuan Wang, Hang Zhou, Shengyi He, Zhiliang Xu, Haocheng Feng, Errui Ding, Jingdong Wang, Hongtao Xie, Youjian Zhao, Ziwei Liu</author><pubDate>Mon, 14 Oct 2024 16:38:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10696v1</guid></item><item><title>The Future of Large Language Model Pre-training is Federated</title><link>http://arxiv.org/abs/2405.10853v3</link><description>Generative pre-trained large language models (LLMs) have demonstratedimpressive performance over a wide range of tasks, thanks to the unprecedentedamount of data they have been trained on. As established scaling laws indicate,LLMs' future performance improvement depends on the amount of computing anddata sources they can leverage for pre-training. Federated learning (FL) hasthe potential to unleash the majority of the planet's data and computationalresources, which are underutilized by the data-center-focused trainingmethodology of current LLM practice. Our work presents a robust, flexible,reproducible FL approach that enables large-scale collaboration acrossinstitutions to train LLMs. We propose a scalable deployment system calledPhoton to enable the investigation and development of this new trainingparadigm for LLM pre-training. We show that Photon can be used by organizationsinterested in collaborating with their private data sources and computationalresources for pre-training LLMs with billions of parameters. This paradigmwould mobilize more computational and data resources while matching orpotentially exceeding centralized performance. We further show theeffectiveness of the federated training scales with model size and present ourapproach for training billion-scale federated LLMs using limited resources.Thus far, we have used Photon to train LLM models to the size of 7B parametersand anticipate larger models being completed in the near future. Finally, weshow that LLM training is highly resilient to the classical challenges offederated statistical and hardware heterogeneity. Furthermore, we show thatconvergence is robust to partial participation, opening the avenue forcompute-efficient collaborative training. Photon will help data-rich actors tobecome the protagonists of LLMs pre-training instead of leaving the stage tocompute-rich actors alone.</description><author>Lorenzo Sani, Alex Iacob, Zeyu Cao, Bill Marino, Yan Gao, Tomas Paulik, Wanru Zhao, William F. Shen, Preslav Aleksandrov, Xinchi Qiu, Nicholas D. Lane</author><pubDate>Mon, 14 Oct 2024 16:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10853v3</guid></item><item><title>Enhancing Performance of Point Cloud Completion Networks with Consistency Loss</title><link>http://arxiv.org/abs/2410.07298v2</link><description>Point cloud completion networks are conventionally trained to minimize thedisparities between the completed point cloud and the ground-truth counterpart.However, an incomplete object-level point cloud can have multiple validcompletion solutions when it is examined in isolation. This one-to-many mappingissue can cause contradictory supervision signals to the network because theloss function may produce different values for identical input-output pairs ofthe network. In many cases, this issue could adversely affect the networkoptimization process. In this work, we propose to enhance the conventionallearning objective using a novel completion consistency loss to mitigate theone-to-many mapping problem. Specifically, the proposed consistency loss ensurethat a point cloud completion network generates a coherent completion solutionfor incomplete objects originating from the same source point cloud.Experimental results across multiple well-established datasets and benchmarksdemonstrated the proposed completion consistency loss have excellent capabilityto enhance the completion performance of various existing networks without anymodification to the design of the networks. The proposed consistency lossenhances the performance of the point completion network without affecting theinference speed, thereby increasing the accuracy of point cloud completion.Notably, a state-of-the-art point completion network trained with the proposedconsistency loss can achieve state-of-the-art accuracy on the challenging newMVP dataset. The code and result of experiment various point completion modelsusing proposed consistency loss will be available at:https://github.com/kaist-avelab/ConsistencyLoss .</description><author>Christofel Rio Goenawan, Kevin Tirta Wijaya, Seung-Hyun Kong</author><pubDate>Mon, 14 Oct 2024 16:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07298v2</guid></item><item><title>C-Learner: Constrained Learning for Causal Inference and Semiparametric Statistics</title><link>http://arxiv.org/abs/2405.09493v3</link><description>Popular debiased causal estimation methods, e.g. for the average treatmenteffect -- such as one-step estimation (e.g., augmented inverse propensityweighting) and targeted maximum likelihood estimation -- enjoy desirableasymptotic properties such as statistical efficiency and double robustness.However, they often produce unstable estimates when there is limited overlapbetween treatment and control, and require ad hoc adjustments in practice(e.g., truncating propensity scores). In contrast, simple plug-in estimatorsare stable but lack good asymptotic properties. We propose a novel debiasedestimator that achieves the best of both worlds, producing stable plug-inestimates with desirable asymptotic properties. Our constrained learningframework solves for the best plug-in estimator under the constraint that thefirst-order error with respect to the plugged-in quantity is zero, and canleverage flexible model classes including neural networks and tree ensembles.In several experimental settings, including ones in which we handle text-basedcovariates by fine-tuning language models, our constrained learning-basedestimator outperforms one-step estimation and targeting in challenging settingswith limited overlap between treatment and control, and performs comparablyotherwise.</description><author>Tiffany Tianhui Cai, Yuri Fonseca, Kaiwen Hou, Hongseok Namkoong</author><pubDate>Mon, 14 Oct 2024 16:34:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09493v3</guid></item><item><title>Separation of Neural Drives to Muscles from Transferred Polyfunctional Nerves using Implanted Micro-electrode Arrays</title><link>http://arxiv.org/abs/2410.10694v1</link><description>Following limb amputation, neural signals for limb functions persist in theresidual peripheral nerves. Targeted muscle reinnervation (TMR) allows toredirected these signals into spare muscles to recover the neural informationthrough electromyography (EMG). However, a significant challenge arises inseparating distinct neural commands redirected from the transferred nerves tothe muscles. Disentangling overlapping signals from EMG recordings remainscomplex, as they can contain mixed neural information that complicates limbfunction interpretation. To address this challenge, Regenerative PeripheralNerve Interfaces (RPNIs) surgically partition the nerve into individualfascicles that reinnervate specific muscle grafts, isolating distinct neuralsources for more precise control and interpretation of EMG signals. Weintroduce a novel biointerface that combines TMR surgery of polyvalent nerveswith a high-density micro-electrode array implanted at a single site within areinnervated muscle. Instead of surgically identifying distinct nervefascicles, our approach separates all neural signals that are re-directed intoa single muscle, using the high spatio-temporal selectivity of themicro-electrode array and mathematical source separation methods. We recordedEMG signals from four reinnervated muscles while volunteers performed phantomlimb tasks. The decomposition of these signals into motor unit activityrevealed distinct clusters of motor neurons associated with diverse functionaltasks. Notably, our method enabled the extraction of multiple neural commandswithin a single reinnervated muscle, eliminating the need for surgical nervedivision. This approach not only has the potential of enhancing prosthesiscontrol but also uncovers mechanisms of motor neuron synergies following TMR,providing valuable insights into how the central nervous system encodesmovement after reinnervation.</description><author>Laura Ferrante, Anna Boesendorfer, Deren Yusuf Barsakcioglu, Benedikt Baumgartner, Yazan Al-Ajam, Alex Woollard, Norbert Venantius Kang, Oskar Aszmann, Dario Farina</author><pubDate>Mon, 14 Oct 2024 16:32:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10694v1</guid></item><item><title>Sign Stitching: A Novel Approach to Sign Language Production</title><link>http://arxiv.org/abs/2405.07663v2</link><description>Sign Language Production (SLP) is a challenging task, given the limitedresources available and the inherent diversity within sign data. As a result,previous works have suffered from the problem of regression to the mean,leading to under-articulated and incomprehensible signing. In this paper, wepropose using dictionary examples to create expressive sign language sequences.However, simply concatenating the signs would create robotic and unnaturalsequences. Therefore, we present a 7-step approach to effectively stitch thesigns together. First, by normalising each sign into a canonical pose, croppingand stitching we create a continuous sequence. Then by applying filtering inthe frequency domain and resampling each sign we create cohesive naturalsequences, that mimic the prosody found in the original data. We leverage theSignGAN model to map the output to a photo-realistic signer and present acomplete Text-to-Sign (T2S) SLP pipeline. Our evaluation demonstrates theeffectiveness of this approach, showcasing state-of-the-art performance acrossall datasets.</description><author>Harry Walsh, Ben Saunders, Richard Bowden</author><pubDate>Mon, 14 Oct 2024 16:28:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07663v2</guid></item><item><title>Dynamical loss functions shape landscape topography and improve learning in artificial neural networks</title><link>http://arxiv.org/abs/2410.10690v1</link><description>Dynamical loss functions are derived from standard loss functions used insupervised classification tasks, but they are modified such that thecontribution from each class periodically increases and decreases. Theseoscillations globally alter the loss landscape without affecting the globalminima. In this paper, we demonstrate how to transform cross-entropy and meansquared error into dynamical loss functions. We begin by discussing the impactof increasing the size of the neural network or the learning rate on thelearning process. Building on this intuition, we propose several versions ofdynamical loss functions and show how they significantly improve validationaccuracy for networks of varying sizes. Finally, we explore how the landscapeof these dynamical loss functions evolves during training, highlighting theemergence of instabilities that may be linked to edge-of-instabilityminimization.</description><author>Eduardo Lavin, Miguel Ruiz-Garcia</author><pubDate>Mon, 14 Oct 2024 16:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10690v1</guid></item><item><title>Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)</title><link>http://arxiv.org/abs/2410.10687v1</link><description>Time series analysis has become increasingly important in various domains,and developing effective models relies heavily on high-quality benchmarkdatasets. Inspired by the success of Natural Language Processing (NLP)benchmark datasets in advancing pre-trained models, we propose a new approachto create a comprehensive benchmark dataset for time series analysis. Thispaper explores the methodologies used in NLP benchmark dataset creation andadapts them to the unique challenges of time series data. We discuss theprocess of curating diverse, representative, and challenging time seriesdatasets, highlighting the importance of domain relevance and data complexity.Additionally, we investigate multi-task learning strategies that leverage thebenchmark dataset to enhance the performance of time series models. Thisresearch contributes to the broader goal of advancing the state-of-the-art intime series modeling by adopting successful strategies from the NLP domain.</description><author>Mohammad Asif Ibna Mustafa, Ferdinand Heinrich</author><pubDate>Mon, 14 Oct 2024 16:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10687v1</guid></item><item><title>SAMPa: Sharpness-aware Minimization Parallelized</title><link>http://arxiv.org/abs/2410.10683v1</link><description>Sharpness-aware minimization (SAM) has been shown to improve thegeneralization of neural networks. However, each SAM update requires\emph{sequentially} computing two gradients, effectively doubling theper-iteration cost compared to base optimizers like SGD. We propose a simplemodification of SAM, termed SAMPa, which allows us to fully parallelize the twogradient computations. SAMPa achieves a twofold speedup of SAM under theassumption that communication costs between devices are negligible. Empiricalresults show that SAMPa ranks among the most efficient variants of SAM in termsof computational time. Additionally, our method consistently outperforms SAMacross both vision and language tasks. Notably, SAMPa theoretically maintainsconvergence guarantees even for \emph{fixed} perturbation sizes, which isestablished through a novel Lyapunov function. We in fact arrive at SAMPa bytreating this convergence guarantee as a hard requirement -- an approach webelieve is promising for developing SAM-based methods in general. Our code isavailable at \url{https://github.com/LIONS-EPFL/SAMPa}.</description><author>Wanyun Xie, Thomas Pethick, Volkan Cevher</author><pubDate>Mon, 14 Oct 2024 16:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10683v1</guid></item><item><title>Combinatorial Multi-armed Bandits: Arm Selection via Group Testing</title><link>http://arxiv.org/abs/2410.10679v1</link><description>This paper considers the problem of combinatorial multi-armed bandits withsemi-bandit feedback and a cardinality constraint on the super-arm size.Existing algorithms for solving this problem typically involve two keysub-routines: (1) a parameter estimation routine that sequentially estimates aset of base-arm parameters, and (2) a super-arm selection policy for selectinga subset of base arms deemed optimal based on these parameters.State-of-the-art algorithms assume access to an exact oracle for super-armselection with unbounded computational power. At each instance, this oracleevaluates a list of score functions, the number of which grows as low aslinearly and as high as exponentially with the number of arms. This can beprohibitive in the regime of a large number of arms. This paper introduces anovel realistic alternative to the perfect oracle. This algorithm uses acombination of group-testing for selecting the super arms and quantizedThompson sampling for parameter estimation. Under a general separabilityassumption on the reward function, the proposed algorithm reduces thecomplexity of the super-arm-selection oracle to be logarithmic in the number ofbase arms while achieving the same regret order as the state-of-the-artalgorithms that use exact oracles. This translates to at least an exponentialreduction in complexity compared to the oracle-based approaches.</description><author>Arpan Mukherjee, Shashanka Ubaru, Keerthiram Murugesan, Karthikeyan Shanmugam, Ali Tajer</author><pubDate>Mon, 14 Oct 2024 16:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10679v1</guid></item><item><title>Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation</title><link>http://arxiv.org/abs/2410.10676v1</link><description>Recently, diffusion models have achieved great success in mono-channel audiogeneration. However, when it comes to stereo audio generation, the soundscapesoften have a complex scene of multiple objects and directions. Controllingstereo audio with spatial contexts remains challenging due to high data costsand unstable generative models. To the best of our knowledge, this workrepresents the first attempt to address these issues. We first construct alarge-scale, simulation-based, and GPT-assisted dataset, BEWO-1M, with abundantsoundscapes and descriptions even including moving and multiple sources. Beyondtext modality, we have also acquired a set of images and rationally pairedstereo audios through retrieval to advance multimodal generation. Existingaudio generation models tend to generate rather random and indistinct spatialaudio. To provide accurate guidance for latent diffusion models, we introducethe SpatialSonic model utilizing spatial-aware encoders and azimuth statematrices to reveal reasonable spatial guidance. By leveraging spatial guidance,our unified model not only achieves the objective of generating immersive andcontrollable spatial audio from text and image but also enables interactiveaudio generation during inference. Finally, under fair settings, we conductsubjective and objective evaluations on simulated and real-world data tocompare our approach with prevailing methods. The results demonstrate theeffectiveness of our method, highlighting its capability to generate spatialaudio that adheres to physical rules.</description><author>Peiwen Sun, Sitong Cheng, Xiangtai Li, Zhen Ye, Huadai Liu, Honggang Zhang, Wei Xue, Yike Guo</author><pubDate>Mon, 14 Oct 2024 16:18:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10676v1</guid></item><item><title>Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models</title><link>http://arxiv.org/abs/2402.06659v2</link><description>Vision-Language Models (VLMs) excel in generating textual responses fromvisual inputs, but their versatility raises security concerns. This study takesthe first step in exposing VLMs' susceptibility to data poisoning attacks thatcan manipulate responses to innocuous, everyday prompts. We introduceShadowcast, a stealthy data poisoning attack where poison samples are visuallyindistinguishable from benign images with matching texts. Shadowcastdemonstrates effectiveness in two attack types. The first is a traditionalLabel Attack, tricking VLMs into misidentifying class labels, such as confusingDonald Trump for Joe Biden. The second is a novel Persuasion Attack, leveragingVLMs' text generation capabilities to craft persuasive and seemingly rationalnarratives for misinformation, such as portraying junk food as healthy. We showthat Shadowcast effectively achieves the attacker's intentions using as few as50 poison samples. Crucially, the poisoned samples demonstrate transferabilityacross different VLM architectures, posing a significant concern in black-boxsettings. Moreover, Shadowcast remains potent under realistic conditionsinvolving various text prompts, training data augmentation, and imagecompression techniques. This work reveals how poisoned VLMs can disseminateconvincing yet deceptive misinformation to everyday, benign users, emphasizingthe importance of data integrity for responsible VLM deployments. Our code isavailable at: https://github.com/umd-huang-lab/VLM-Poisoning.</description><author>Yuancheng Xu, Jiarui Yao, Manli Shu, Yanchao Sun, Zichu Wu, Ning Yu, Tom Goldstein, Furong Huang</author><pubDate>Mon, 14 Oct 2024 16:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06659v2</guid></item><item><title>Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach</title><link>http://arxiv.org/abs/2410.10674v1</link><description>Deep reinforcement learning agents achieve state-of-the-art performance in awide range of simulated control tasks. However, successful applications toreal-world problems remain limited. One reason for this dichotomy is becausethe learned policies are not robust to observation noise or adversarialattacks. In this paper, we investigate the robustness of deep RL policies to asingle small state perturbation in deterministic continuous control tasks. Wedemonstrate that RL policies can be deterministically chaotic as smallperturbations to the system state have a large impact on subsequent state andreward trajectories. This unstable non-linear behaviour has two consequences:First, inaccuracies in sensor readings, or adversarial attacks, can causesignificant performance degradation; Second, even policies that show robustperformance in terms of rewards may have unpredictable behaviour in practice.These two facets of chaos in RL policies drastically restrict the applicationof deep RL to real-world problems. To address this issue, we propose animprovement on the successful Dreamer V3 architecture, implementing a MaximalLyapunov Exponent regularisation. This new approach reduces the chaotic statedynamics, rendering the learnt policies more resilient to sensor noise oradversarial attacks and thereby improving the suitability of Deep ReinforcementLearning for real-world applications.</description><author>Rory Young, Nicolas Pugeault</author><pubDate>Mon, 14 Oct 2024 16:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10674v1</guid></item><item><title>Large Language Model Evaluation via Matrix Nuclear-Norm</title><link>http://arxiv.org/abs/2410.10672v1</link><description>As large language models (LLMs) continue to evolve, efficient evaluationmetrics are vital for assessing their ability to compress information andreduce redundancy. While traditional metrics like Matrix Entropy offer valuableinsights, they are computationally intensive for large-scale models due totheir \( O(n^3) \) time complexity with Singular Value Decomposition (SVD). Tomitigate this issue, we introduce the Matrix Nuclear-Norm, which not onlyserves as a metric to quantify the data compression proficiency of LLM but alsoprovides a convex approximation of matrix rank to capture both predictivediscriminability and diversity. By employing the \( L_{1,2}\text{-norm} \) tofurther approximate the nuclear norm, we can effectively assess the model'sinformation compression capabilities. This approach reduces the time complexityto \( O(n^2) \) and eliminates the need for SVD computation. Consequently, theMatrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropyfor the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. Thisperformance gap becomes more pronounced with larger models, as validated intests with other models like Pythia. Additionally, evaluations on benchmarksand model responses confirm that our proposed Matrix Nuclear-Norm is areliable, scalable, and efficient tool for assessing LLMs' performance,striking a balance between accuracy and computational efficiency. The code isavailable at https://github.com/MLGroupJLU/MatrixNuclearNorm.</description><author>Yahan Li, Tingyu Xia, Yi Chang, Yuan Wu</author><pubDate>Mon, 14 Oct 2024 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10672v1</guid></item><item><title>Building Knowledge-Guided Lexica to Model Cultural Variation</title><link>http://arxiv.org/abs/2406.11622v2</link><description>Cultural variation exists between nations (e.g., the United States vs.China), but also within regions (e.g., California vs. Texas, Los Angeles vs.San Francisco). Measuring this regional cultural variation can illuminate howand why people think and behave differently. Historically, it has beendifficult to computationally model cultural variation due to a lack of trainingdata and scalability constraints. In this work, we introduce a new researchproblem for the NLP community: How do we measure variation in culturalconstructs across regions using language? We then provide a scalable solution:building knowledge-guided lexica to model cultural variation, encouragingfuture work at the intersection of NLP and cultural understanding. We alsohighlight modern LLMs' failure to measure cultural variation or generateculturally varied language.</description><author>Shreya Havaldar, Salvatore Giorgi, Sunny Rai, Young-Min Cho, Thomas Talhelm, Sharath Chandra Guntuku, Lyle Ungar</author><pubDate>Mon, 14 Oct 2024 16:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11622v2</guid></item><item><title>Compressed Federated Reinforcement Learning with a Generative Model</title><link>http://arxiv.org/abs/2404.10635v6</link><description>Reinforcement learning has recently gained unprecedented popularity, yet itstill grapples with sample inefficiency. Addressing this challenge, federatedreinforcement learning (FedRL) has emerged, wherein agents collaborativelylearn a single policy by aggregating local estimations. However, thisaggregation step incurs significant communication costs. In this paper, wepropose CompFedRL, a communication-efficient FedRL approach incorporating both\textit{periodic aggregation} and (direct/error-feedback) compressionmechanisms. Specifically, we consider compressed federated $Q$-learning with agenerative model setup, where a central server learns an optimal $Q$-functionby periodically aggregating compressed $Q$-estimates from local agents. For thefirst time, we characterize the impact of these two mechanisms (which haveremained elusive) by providing a finite-time analysis of our algorithm,demonstrating strong convergence behaviors when utilizing either direct orerror-feedback compression. Our bounds indicate improved solution accuracyconcerning the number of agents and other federated hyperparameters whilesimultaneously reducing communication costs. To corroborate our theory, we alsoconduct in-depth numerical experiments to verify our findings, consideringTop-$K$ and Sparsified-$K$ sparsification operators.</description><author>Ali Beikmohammadi, Sarit Khirirat, Sindri Magnsson</author><pubDate>Mon, 14 Oct 2024 16:11:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10635v6</guid></item><item><title>Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers</title><link>http://arxiv.org/abs/2410.10665v1</link><description>Artificial Intelligence (AI), particularly large language models (LLMs),holds the potential to bridge language and information gaps, which can benefitthe economies of developing nations. However, our analysis of FLORES-200,FLORES+, Ethnologue, and World Development Indicators data reveals that thesebenefits largely favor English speakers. Speakers of languages in low-incomeand lower-middle-income countries face higher costs when using OpenAI's GPTmodels via APIs because of how the system processes the input -- tokenization.Around 1.5 billion people, speaking languages primarily fromlower-middle-income countries, could incur costs that are 4 to 6 times higherthan those faced by English speakers. Disparities in LLM performance aresignificant, and tokenization in models priced per token amplifies inequalitiesin access, cost, and utility. Moreover, using the quality of translation tasksas a proxy measure, we show that LLMs perform poorly in low-resource languages,presenting a ``double jeopardy" of higher costs and poor performance for theseusers. We also discuss the direct impact of fragmentation in tokenizinglow-resource languages on climate. This underscores the need for faireralgorithm development to benefit all linguistic groups.</description><author>Aivin V. Solatorio, Gabriel Stefanini Vicente, Holly Krambeck, Olivier Dupriez</author><pubDate>Mon, 14 Oct 2024 16:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10665v1</guid></item><item><title>Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework</title><link>http://arxiv.org/abs/2410.10663v1</link><description>Most existing studies on few-shot learning focus on unimodal settings, wheremodels are trained to generalize on unseen data using only a small number oflabeled examples from the same modality. However, real-world data areinherently multi-modal, and unimodal approaches limit the practicalapplications of few-shot learning. To address this gap, this paper introducesthe Cross-modal Few-Shot Learning (CFSL) task, which aims to recognizeinstances from multiple modalities when only a few labeled examples areavailable. This task presents additional challenges compared to classicalfew-shot learning due to the distinct visual characteristics and structuralproperties unique to each modality. To tackle these challenges, we propose aGenerative Transfer Learning (GTL) framework consisting of two stages: thefirst stage involves training on abundant unimodal data, and the second stagefocuses on transfer learning to adapt to novel data. Our GTL framework jointlyestimates the latent shared concept across modalities and in-modalitydisturbance in both stages, while freezing the generative module during thetransfer phase to maintain the stability of the learned representations andprevent overfitting to the limited multi-modal samples. Our finds demonstratethat GTL has superior performance compared to state-of-the-art methods acrossfour distinct multi-modal datasets: Sketchy, TU-Berlin, Mask1K, and SKSF-A.Additionally, the results suggest that the model can estimate latent conceptsfrom vast unimodal data and generalize these concepts to unseen modalitiesusing only a limited number of available samples, much like human cognitiveprocesses.</description><author>Zhengwei Yang, Yuke Li, Qiang Sun, Basura Fernando, Heng Huang, Zheng Wang</author><pubDate>Mon, 14 Oct 2024 16:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10663v1</guid></item><item><title>Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning</title><link>http://arxiv.org/abs/2410.10660v1</link><description>In this study, we investigate the performance of Deep Q-Networks utilizingConvolutional Neural Networks (CNNs) and Transformer architectures across threedifferent Atari games. The advent of DQNs has significantly advancedReinforcement Learning, enabling agents to directly learn optimal policies fromhigh-dimensional sensory inputs from pixel or RAM data. While CNN-based DQNshave been extensively studied and deployed in various domains,Transformer-based DQNs are relatively unexplored. Our research aims to fillthis gap by benchmarking the performance of both DCQNs and DTQNs across theAtari games Asteroids, Space Invaders, and Centipede. We find that in the 35-40million parameter range, the DCQN outperforms the DTQN in speed across both ViTand Projection Architectures. We also find the DCQN outperforms the DTQN in allgames except for Centipede.</description><author>William A. Stigall</author><pubDate>Mon, 14 Oct 2024 16:08:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10660v1</guid></item><item><title>PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion</title><link>http://arxiv.org/abs/2410.10659v1</link><description>Panoptic lifting is an effective technique to address the 3D panopticsegmentation task by unprojecting 2D panoptic segmentations from multi-views to3D scene. However, the quality of its results largely depends on the 2Dsegmentations, which could be noisy and error-prone, so its performance oftendrops significantly for complex scenes. In this work, we design a new pipelinecoined PCF-Lift based on our Probabilis-tic Contrastive Fusion (PCF) to learnand embed probabilistic features throughout our pipeline to actively considerinaccurate segmentations and inconsistent instance IDs. Technical-wise, wefirst model the probabilistic feature embeddings through multivariate Gaussiandistributions. To fuse the probabilistic features, we incorporate theprobability product kernel into the contrastive loss formulation and design across-view constraint to enhance the feature consistency across differentviews. For the inference, we introduce a new probabilistic clustering method toeffectively associate prototype features with the underlying 3D objectinstances for the generation of consistent panoptic segmentation results.Further, we provide a theoretical analysis to justify the superiority of theproposed probabilistic solution. By conducting extensive experiments, ourPCF-lift not only significantly outperforms the state-of-the-art methods onwidely used benchmarks including the ScanNet dataset and the challenging MessyRoom dataset (4.4% improvement of scene-level PQ), but also demonstrates strongrobustness when incorporating various 2D segmentation models or differentlevels of hand-crafted noise.</description><author>Runsong Zhu, Shi Qiu, Qianyi Wu, Ka-Hei Hui, Pheng-Ann Heng, Chi-Wing Fu</author><pubDate>Mon, 14 Oct 2024 16:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10659v1</guid></item><item><title>Detecting Audio-Visual Deepfakes with Fine-Grained Inconsistencies</title><link>http://arxiv.org/abs/2408.06753v3</link><description>Existing methods on audio-visual deepfake detection mainly focus onhigh-level features for modeling inconsistencies between audio and visual data.As a result, these approaches usually overlook finer audio-visual artifacts,which are inherent to deepfakes. Herein, we propose the introduction offine-grained mechanisms for detecting subtle artifacts in both spatial andtemporal domains. First, we introduce a local audio-visual model capable ofcapturing small spatial regions that are prone to inconsistencies with audio.For that purpose, a fine-grained mechanism based on a spatially-local distancecoupled with an attention module is adopted. Second, we introduce atemporally-local pseudo-fake augmentation to include samples incorporatingsubtle temporal inconsistencies in our training set. Experiments on the DFDCand the FakeAVCeleb datasets demonstrate the superiority of the proposed methodin terms of generalization as compared to the state-of-the-art under bothin-dataset and cross-dataset settings.</description><author>Marcella Astrid, Enjie Ghorbel, Djamila Aouada</author><pubDate>Mon, 14 Oct 2024 16:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06753v3</guid></item><item><title>AutoTurb: Using Large Language Models for Automatic Algebraic Model Discovery of Turbulence Closure</title><link>http://arxiv.org/abs/2410.10657v1</link><description>Symbolic regression (SR) methods have been extensively investigated toexplore explicit algebraic Reynolds stress models (EARSM) for turbulenceclosure of Reynolds-averaged Navier-Stokes (RANS) equations. The deduced EARSMcan be readily implemented in existing computational fluid dynamic (CFD) codesand promotes the identification of physically interpretable turbulence models.The existing SR methods, such as genetic programming, sparse regression, orartificial neural networks, require user-defined functional operators, alibrary of candidates, or complex optimization algorithms. In this work, anovel framework using LLMs to automatically discover algebraic expressions forcorrecting the RSM is proposed. The direct observation of Reynolds stress andthe indirect output of the CFD simulation are both involved in the trainingprocess to guarantee data consistency and avoid numerical stiffness.Constraints of functional complexity and convergence are supplementally imposedin the objective function on account of the tremendous flexibility of LLMs. Theevolutionary search is employed for global optimization. The proposed method isperformed for separated flow over periodic hills at Re = 10,595. Thegeneralizability of the discovered model is verified on a set of 2D turbulentseparated flow configurations with different Reynolds numbers and geometries.It is demonstrated that the corrective RANS can improve the prediction for boththe Reynolds stress and mean velocity fields. Compared with algebraic modelsdiscovered by other works, the discovered model performs better in accuracy andgeneralization capability. The proposed approach provides a promising paradigmfor using LLMs to improve turbulence modeling for a given class of flows.</description><author>Yu Zhang, Kefeng Zheng, Fei Liu, Qingfu Zhang, Zhenkun Wang</author><pubDate>Mon, 14 Oct 2024 16:06:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10657v1</guid></item><item><title>Extracting Training Data from Unconditional Diffusion Models</title><link>http://arxiv.org/abs/2406.12752v2</link><description>As diffusion probabilistic models (DPMs) are being employed as mainstreammodels for generative artificial intelligence (AI), the study of theirmemorization of the raw training data has attracted growing attention. Existingworks in this direction aim to establish an understanding of whether or to whatextent DPMs learn by memorization. Such an understanding is crucial foridentifying potential risks of data leakage and copyright infringement indiffusion models and, more importantly, for more controllable generation andtrustworthy application of Artificial Intelligence Generated Content (AIGC).While previous works have made important observations of when DPMs are prone tomemorization, these findings are mostly empirical, and the developed dataextraction methods only work for conditional diffusion models. In this work, weaim to establish a theoretical understanding of memorization in DPMs with 1) amemorization metric for theoretical analysis, 2) an analysis of conditionalmemorization with informative and random labels, and 3) two better evaluationmetrics for measuring memorization. Based on the theoretical analysis, wefurther propose a novel data extraction method called \textbf{SurrogatecondItional Data Extraction (SIDE)} that leverages a classifier trained ongenerated data as a surrogate condition to extract training data directly fromunconditional diffusion models. Our empirical results demonstrate that SIDE canextract training data from diffusion models where previous methods fail, and itis on average over 50\% more effective across different scales of the CelebAdataset.</description><author>Yunhao Chen, Xingjun Ma, Difan Zou, Yu-Gang Jiang</author><pubDate>Mon, 14 Oct 2024 16:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12752v2</guid></item><item><title>Navigation under uncertainty: Trajectory prediction and occlusion reasoning with switching dynamical systems</title><link>http://arxiv.org/abs/2410.10653v1</link><description>Predicting future trajectories of nearby objects, especially under occlusion,is a crucial task in autonomous driving and safe robot navigation. Prior workstypically neglect to maintain uncertainty about occluded objects and onlypredict trajectories of observed objects using high-capacity models such asTransformers trained on large datasets. While these approaches are effective instandard scenarios, they can struggle to generalize to the long-tail,safety-critical scenarios. In this work, we explore a conceptual frameworkunifying trajectory prediction and occlusion reasoning under the same class ofstructured probabilistic generative model, namely, switching dynamical systems.We then present some initial experiments illustrating its capabilities usingthe Waymo open dataset.</description><author>Ran Wei, Joseph Lee, Shohei Wakayama, Alexander Tschantz, Conor Heins, Christopher Buckley, John Carenbauer, Hari Thiruvengada, Mahault Albarracin, Miguel de Prado, Petter Horling, Peter Winzell, Renjith Rajagopal</author><pubDate>Mon, 14 Oct 2024 16:03:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10653v1</guid></item><item><title>QueST: Querying Functional and Structural Niches on Spatial Transcriptomics Data via Contrastive Subgraph Embedding</title><link>http://arxiv.org/abs/2410.10652v1</link><description>The functional or structural spatial regions within tissues, referred to asspatial niches, are elements for illustrating the spatial contexts ofmulticellular organisms. A key challenge is querying shared niches acrossdiverse tissues, which is crucial for achieving a comprehensive understandingof the organization and phenotypes of cell populations. However, current dataanalysis methods predominantly focus on creating spatial-aware embeddings forcells, neglecting the development of niche-level representations for effectivequerying. To address this gap, we introduce QueST, a novel niche representationlearning model designed for querying spatial niches across multiple samples.QueST utilizes a novel subgraph contrastive learning approach to explicitlycapture niche-level characteristics and incorporates adversarial training tomitigate batch effects. We evaluate QueST on established benchmarks using humanand mouse datasets, demonstrating its superiority over state-of-the-art graphrepresentation learning methods in accurate niche queries. Overall, QueSToffers a specialized model for spatial niche queries, paving the way for deeperinsights into the patterns and mechanisms of cell spatial organization acrosstissues. Source code can be found at https://github.com/cmhimself/QueST.</description><author>Mo Chen, Minsheng Hao, Xuegong Zhang, Lei Wei</author><pubDate>Mon, 14 Oct 2024 16:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10652v1</guid></item><item><title>Generative AI and Its Impact on Personalized Intelligent Tutoring Systems</title><link>http://arxiv.org/abs/2410.10650v1</link><description>Generative Artificial Intelligence (AI) is revolutionizing educationaltechnology by enabling highly personalized and adaptive learning environmentswithin Intelligent Tutoring Systems (ITS). This report delves into theintegration of Generative AI, particularly large language models (LLMs) likeGPT-4, into ITS to enhance personalized education through dynamic contentgeneration, real-time feedback, and adaptive learning pathways. We explore keyapplications such as automated question generation, customized feedbackmechanisms, and interactive dialogue systems that respond to individual learnerneeds. The report also addresses significant challenges, including ensuringpedagogical accuracy, mitigating inherent biases in AI models, and maintaininglearner engagement. Future directions highlight the potential advancements inmultimodal AI integration, emotional intelligence in tutoring systems, and theethical implications of AI-driven education. By synthesizing current researchand practical implementations, this report underscores the transformativepotential of Generative AI in creating more effective, equitable, and engagingeducational experiences.</description><author>Subhankar Maity, Aniket Deroy</author><pubDate>Mon, 14 Oct 2024 16:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10650v1</guid></item><item><title>MCTrack: A Unified 3D Multi-Object Tracking Framework for Autonomous Driving</title><link>http://arxiv.org/abs/2409.16149v2</link><description>This paper introduces MCTrack, a new 3D multi-object tracking method thatachieves state-of-the-art (SOTA) performance across KITTI, nuScenes, and Waymodatasets. Addressing the gap in existing tracking paradigms, which oftenperform well on specific datasets but lack generalizability, MCTrack offers aunified solution. Additionally, we have standardized the format of perceptualresults across various datasets, termed BaseVersion, facilitating researchersin the field of multi-object tracking (MOT) to concentrate on the corealgorithmic development without the undue burden of data preprocessing.Finally, recognizing the limitations of current evaluation metrics, we proposea novel set that assesses motion information output, such as velocity andacceleration, crucial for downstream tasks. The source codes of the proposedmethod are available at this link:https://github.com/megvii-research/MCTrack}{https://github.com/megvii-research/MCTrack</description><author>Xiyang Wang, Shouzheng Qi, Jieyou Zhao, Hangning Zhou, Siyu Zhang, Guoan Wang, Kai Tu, Songlin Guo, Jianbo Zhao, Jian Li, Mu Yang</author><pubDate>Mon, 14 Oct 2024 16:00:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16149v2</guid></item><item><title>A Simple Baseline for Predicting Events with Auto-Regressive Tabular Transformers</title><link>http://arxiv.org/abs/2410.10648v1</link><description>Many real-world applications of tabular data involve using historic events topredict properties of new ones, for example whether a credit card transactionis fraudulent or what rating a customer will assign a product on a retailplatform. Existing approaches to event prediction include costly, brittle, andapplication-dependent techniques such as time-aware positional embeddings,learned row and field encodings, and oversampling methods for addressing classimbalance. Moreover, these approaches often assume specific use-cases, forexample that we know the labels of all historic events or that we only predicta pre-specified label and not the data's features themselves. In this work, wepropose a simple but flexible baseline using standard autoregressive LLM-styletransformers with elementary positional embeddings and a causal languagemodeling objective. Our baseline outperforms existing approaches across populardatasets and can be employed for various use-cases. We demonstrate that thesame model can predict labels, impute missing values, or model event sequences.</description><author>Alex Stein, Samuel Sharpe, Doron Bergman, Senthil Kumar, Bayan Bruss, John Dickerson, Tom Goldstein, Micah Goldblum</author><pubDate>Mon, 14 Oct 2024 15:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10648v1</guid></item></channel></rss>