<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 14 Nov 2024 01:00:21 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Material Transforms from Disentangled NeRF Representations</title><link>http://arxiv.org/abs/2411.08037v1</link><description>In this paper, we first propose a novel method for transferring materialtransformations across different scenes. Building on disentangled NeuralRadiance Field (NeRF) representations, our approach learns to map BidirectionalReflectance Distribution Functions (BRDF) from pairs of scenes observed invarying conditions, such as dry and wet. The learned transformations can thenbe applied to unseen scenes with similar materials, therefore effectivelyrendering the transformation learned with an arbitrary level of intensity.Extensive experiments on synthetic scenes and real-world objects validate theeffectiveness of our approach, showing that it can learn varioustransformations such as wetness, painting, coating, etc. Our results highlightnot only the versatility of our method but also its potential for practicalapplications in computer graphics. We publish our method implementation, alongwith our synthetic/real datasets onhttps://github.com/astra-vision/BRDFTransform</description><author>Ivan Lopes, Jean-François Lalonde, Raoul de Charette</author><pubDate>Tue, 12 Nov 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08037v1</guid></item><item><title>Scaling Properties of Diffusion Models for Perceptual Tasks</title><link>http://arxiv.org/abs/2411.08034v1</link><description>In this paper, we argue that iterative computation with diffusion modelsoffers a powerful paradigm for not only generation but also visual perceptiontasks. We unify tasks such as depth estimation, optical flow, and segmentationunder image-to-image translation, and show how diffusion models benefit fromscaling training and test-time compute for these perception tasks. Through acareful analysis of these scaling behaviors, we present various techniques toefficiently train diffusion models for visual perception tasks. Our modelsachieve improved or comparable performance to state-of-the-art methods usingsignificantly less data and compute. To use our code and models, seehttps://scaling-diffusion-perception.github.io .</description><author>Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik</author><pubDate>Tue, 12 Nov 2024 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08034v1</guid></item><item><title>GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation</title><link>http://arxiv.org/abs/2411.08033v1</link><description>While 3D content generation has advanced significantly, existing methodsstill face challenges with input formats, latent space design, and outputrepresentations. This paper introduces a novel 3D generation framework thataddresses these challenges, offering scalable, high-quality 3D generation withan interactive Point Cloud-structured Latent space. Our framework employs aVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)renderings as input, using a unique latent space design that preserves 3D shapeinformation, and incorporates a cascaded latent diffusion model for improvedshape-texture disentanglement. The proposed method, GaussianAnything, supportsmulti-modal conditional 3D generation, allowing for point cloud, caption, andsingle/multi-view image inputs. Notably, the newly proposed latent spacenaturally enables geometry-texture disentanglement, thus allowing 3D-awareediting. Experimental results demonstrate the effectiveness of our approach onmultiple datasets, outperforming existing methods in both text- andimage-conditioned 3D generation.</description><author>Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, Shuai Yang, Bo Dai, Xingang Pan, Chen Change Loy</author><pubDate>Tue, 12 Nov 2024 18:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08033v1</guid></item><item><title>Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data</title><link>http://arxiv.org/abs/2411.08028v1</link><description>In real-world NLP applications, Large Language Models (LLMs) offer promisingsolutions due to their extensive training on vast datasets. However, the largesize and high computation demands of LLMs limit their practicality in manyapplications, especially when further fine-tuning is required. To address theselimitations, smaller models are typically preferred for deployment. However,their training is hindered by the scarcity of labeled data. In contrast,unlabeled data is often readily which can be leveraged by using LLMs togenerate pseudo-labels for training smaller models. This enables the smallermodels (student) to acquire knowledge from LLMs(teacher) while reducingcomputational costs. This process introduces challenges, such as potentialnoisy pseudo-labels. Selecting high-quality and informative data is thereforecritical to enhance model performance while improving the efficiency of datautilization. To address this, we propose LLKD that enables Learning with Lesscomputational resources and less data for Knowledge Distillation from LLMs.LLKD is an adaptive sample selection method that incorporates signals from boththe teacher and student. Specifically, it prioritizes samples where the teacherdemonstrates high confidence in its labeling, indicating reliable labels, andwhere the student exhibits a high information need, identifying challengingsamples that require further learning. Our comprehensive experiments show thatLLKD achieves superior performance across various datasets with higher dataefficiency.</description><author>Juanhui Li, Sreyashi Nag, Hui Liu, Xianfeng Tang, Sheikh Sarwar, Limeng Cui, Hansu Gu, Suhang Wang, Qi He, Jiliang Tang</author><pubDate>Tue, 12 Nov 2024 18:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08028v1</guid></item><item><title>LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models</title><link>http://arxiv.org/abs/2411.08027v1</link><description>Physical reasoning is an important skill needed for robotic agents whenoperating in the real world. However, solving such reasoning problems ofteninvolves hypothesizing and reflecting over complex multi-body interactionsunder the effect of a multitude of physical forces and thus learning all suchinteractions poses a significant hurdle for state-of-the-art machine learningframeworks, including large language models (LLMs). To study this problem, wepropose a new physical reasoning task and a dataset, dubbed TraySim. Our taskinvolves predicting the dynamics of several objects on a tray that is given anexternal impact -- the domino effect of the ensued object interactions andtheir dynamics thus offering a challenging yet controlled setup, with the goalof reasoning being to infer the stability of the objects after the impact. Tosolve this complex physical reasoning task, we present LLMPhy, a zero-shotblack-box optimization framework that leverages the physics knowledge andprogram synthesis abilities of LLMs, and synergizes these abilities with theworld models built into modern physics engines. Specifically, LLMPhy uses anLLM to generate code to iteratively estimate the physical hyperparameters ofthe system (friction, damping, layout, etc.) via an implicitanalysis-by-synthesis approach using a (non-differentiable) simulator in theloop and uses the inferred parameters to imagine the dynamics of the scenetowards solving the reasoning task. To show the effectiveness of LLMPhy, wepresent experiments on our TraySim dataset to predict the steady-state poses ofthe objects. Our results show that the combination of the LLM and the physicsengine leads to state-of-the-art zero-shot physical reasoning performance,while demonstrating superior convergence against standard black-boxoptimization methods and better estimation of the physical parameters.</description><author>Anoop Cherian, Radu Corcodel, Siddarth Jain, Diego Romeres</author><pubDate>Tue, 12 Nov 2024 18:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08027v1</guid></item><item><title>Leonardo vindicated: Pythagorean trees for minimal reconstruction of the natural branching structures</title><link>http://arxiv.org/abs/2411.08024v1</link><description>Trees continue to fascinate with their natural beauty and as engineeringmasterpieces optimal with respect to several independent criteria. Pythagoreantree is a well-known fractal design that realistically mimics the natural treebranching structures. We study various types of Pythagorean-like fractal treeswith different shapes of the base, branching angles and relaxed scales in anattempt to identify and explain which variants are the closest match to thebranching structures commonly observed in the natural world. Pursuingsimultaneously the realism and minimalism of the fractal tree model, we havedeveloped a flexibly parameterised and fast algorithm to grow and visuallyexamine deep Pythagorean-inspired fractal trees with the capability to orderlyover- or underestimate the Leonardo da Vinci's tree branching rule as well ascontrol various imbalances and branching angles. We tested the realism of thegenerated fractal tree images by means of the classification accuracy ofdetecting natural tree with the transfer-trained deep Convolutional NeuralNetworks (CNNs). Having empirically established the parameters of the fractaltrees that maximize the CNN's natural tree class classification accuracy wehave translated them back to the scales and angles of branches and came to theinteresting conclusions that support the da Vinci branching rule and goldenratio based scaling for both the shape of the branch and imbalance between thechild branches, and claim the flexibly parameterized fractal trees can be usedto generate artificial examples to train robust detectors of different speciesof trees.</description><author>Dymitr Ruta, Corrado Mio, Ernesto Damiani</author><pubDate>Tue, 12 Nov 2024 18:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08024v1</guid></item><item><title>Language Models as Causal Effect Generators</title><link>http://arxiv.org/abs/2411.08019v1</link><description>We present a framework for large language model (LLM) based data generationwith controllable causal structure. In particular, we define a procedure forturning any language model and any directed acyclic graph (DAG) into asequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCMis a causal model with user-defined structure and LLM-defined structuralequations. We characterize how an SD-SCM allows sampling from observational,interventional, and counterfactual distributions according to the desiredcausal structure. We then leverage this procedure to propose a new type ofbenchmark for causal inference methods, generating individual-levelcounterfactual data without needing to manually specify functionalrelationships between variables. We create an example benchmark consisting ofthousands of datasets, and test a suite of popular estimation methods on thesedatasets for average, conditional average, and individual treatment effectestimation, both with and without hidden confounding. Apart from generatingdata, the same procedure also allows us to test for the presence of a causaleffect that might be encoded in an LLM. This procedure can underpin auditingLLMs for misinformation, discrimination, or otherwise undesirable behavior. Webelieve SD-SCMs can serve as a useful tool in any application that wouldbenefit from sequential data with controllable causal structure.</description><author>Lucius E. J. Bynum, Kyunghyun Cho</author><pubDate>Tue, 12 Nov 2024 18:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08019v1</guid></item><item><title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title><link>http://arxiv.org/abs/2311.17245v6</link><description>Recent advances in real-time neural rendering using point-based techniqueshave enabled broader adoption of 3D representations. However, foundationalapproaches like 3D Gaussian Splatting impose substantial storage overhead, asStructure-from-Motion (SfM) points can grow to millions, often requiringgigabyte-level disk space for a single unbounded scene. This growth presentsscalability challenges and hinders splatting efficiency. To address this, weintroduce LightGaussian, a method for transforming 3D Gaussians into a morecompact format. Inspired by Network Pruning, LightGaussian identifies Gaussianswith minimal global significance on scene reconstruction, and applies a pruningand recovery process to reduce redundancy while preserving visual quality.Knowledge distillation and pseudo-view augmentation then transfer sphericalharmonic coefficients to a lower degree, yielding compact representations.Gaussian Vector Quantization, based on each Gaussian's global significance,further lowers bitwidth with minimal accuracy loss. LightGaussian achieves anaverage 15x compression rate while boosting FPS from 144 to 237 within the3D-GS framework, enabling efficient complex scene representation on theMip-NeRF 360 and Tank &amp; Temple datasets. The proposed Gaussian pruning approachis also adaptable to other 3D representations (e.g., Scaffold-GS),demonstrating strong generalization capabilities.</description><author>Zhiwen Fan, Kevin Wang, Kairun Wen, Zehao Zhu, Dejia Xu, Zhangyang Wang</author><pubDate>Tue, 12 Nov 2024 18:50:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17245v6</guid></item><item><title>Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings</title><link>http://arxiv.org/abs/2411.08017v1</link><description>Large-scale 3D generative models require substantial computational resourcesyet often fall short in capturing fine details and complex geometries at highresolutions. We attribute this limitation to the inefficiency of currentrepresentations, which lack the compactness required to model the generativemodels effectively. To address this, we introduce a novel approach calledWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,compact latent encodings. Specifically, we compress a $256^3$ signed distancefield into a $12^3 \times 4$ latent grid, achieving an impressive 2427xcompression ratio with minimal loss of detail. This high level of compressionallows our method to efficiently train large-scale generative networks withoutincreasing the inference time. Our models, both conditional and unconditional,contain approximately one billion parameters and successfully generatehigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapidinference, producing shapes within two to four seconds depending on thecondition, despite the model's scale. We demonstrate state-of-the-artperformance across multiple datasets, with significant improvements ingeneration quality, diversity, and computational efficiency. We open-source ourcode and, to the best of our knowledge, release the largest pretrained 3Dgenerative models across different modalities.</description><author>Aditya Sanghi, Aliasghar Khani, Pradyumna Reddy, Arianna Rampini, Derek Cheung, Kamal Rahimi Malekshan, Kanika Madan, Hooman Shayani</author><pubDate>Tue, 12 Nov 2024 18:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08017v1</guid></item><item><title>Odd-One-Out: Anomaly Detection by Comparing with Neighbors</title><link>http://arxiv.org/abs/2406.20099v2</link><description>This paper introduces a novel anomaly detection (AD) problem that focuses onidentifying `odd-looking' objects relative to the other instances in a givenscene. In contrast to the traditional AD benchmarks, anomalies in our task arescene-specific, defined by the regular instances that make up the majority.Since object instances may be only partly visible from a single viewpoint, oursetting employs multiple views of each scene as input. To provide a testbed forfuture research in this task, we introduce two benchmarks, ToysAD-8K andPartsAD-15K. We propose a novel method that constructs 3D object-centricrepresentations from multiple 2D views for each instance and detects theanomalous ones through a cross-instance comparison. We rigorously analyze ourmethod quantitatively and qualitatively on the presented benchmarks.</description><author>Ankan Bhunia, Changjian Li, Hakan Bilen</author><pubDate>Tue, 12 Nov 2024 18:46:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20099v2</guid></item><item><title>Artistic Neural Style Transfer Algorithms with Activation Smoothing</title><link>http://arxiv.org/abs/2411.08014v1</link><description>The works of Gatys et al. demonstrated the capability of Convolutional NeuralNetworks (CNNs) in creating artistic style images. This process of transferringcontent images in different styles is called Neural Style Transfer (NST). Inthis paper, we re-implement image-based NST, fast NST, and arbitrary NST. Wealso explore to utilize ResNet with activation smoothing in NST. Extensiveexperimental results demonstrate that smoothing transformation can greatlyimprove the quality of stylization results.</description><author>Xiangtian Li, Han Cao, Zhaoyang Zhang, Jiacheng Hu, Yuhui Jin, Zihao Zhao</author><pubDate>Tue, 12 Nov 2024 18:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08014v1</guid></item><item><title>Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech</title><link>http://arxiv.org/abs/2411.08013v1</link><description>Speech impairments in Parkinson's disease (PD) provide significant earlyindicators for diagnosis. While models for speech-based PD detection have shownstrong performance, their interpretability remains underexplored. This studysystematically evaluates several explainability methods to identify PD-specificspeech features, aiming to support the development of accurate, interpretablemodels for clinical decision-making in PD diagnosis and monitoring. Ourmethodology involves (i) obtaining attributions and saliency maps usingmainstream interpretability techniques, (ii) quantitatively evaluating thefaithfulness of these maps and their combinations obtained via union andintersection through a range of established metrics, and (iii) assessing theinformation conveyed by the saliency maps for PD detection from an auxiliaryclassifier. Our results reveal that, while explanations are aligned with theclassifier, they often fail to provide valuable information for domain experts.</description><author>Eleonora Mancini, Francesco Paissan, Paolo Torroni, Cem Subakan, Mirco Ravanelli</author><pubDate>Tue, 12 Nov 2024 18:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08013v1</guid></item><item><title>Beyond Discretization: Learning the Optimal Solution Path</title><link>http://arxiv.org/abs/2410.14885v2</link><description>Many applications require minimizing a family of optimization problemsindexed by some hyperparameter $\lambda \in \Lambda$ to obtain an entiresolution path. Traditional approaches proceed by discretizing $\Lambda$ andsolving a series of optimization problems. We propose an alternative approachthat parameterizes the solution path with a set of basis functions and solves a\emph{single} stochastic optimization problem to learn the entire solutionpath. Our method offers substantial complexity improvements overdiscretization. When using constant-step size SGD, the uniform error of ourlearned solution path relative to the true path exhibits linear convergence toa constant related to the expressiveness of the basis. When the true solutionpath lies in the span of the basis, this constant is zero. We also provestronger results for special cases common in machine learning: When $\lambda\in [-1, 1]$ and the solution path is $\nu$-times differentiable, constantstep-size SGD learns a path with $\epsilon$ uniform error after at most$O(\epsilon^{\frac{1}{1-\nu}} \log(1/\epsilon))$ iterations, and when thesolution path is analytic, it only requires$O\left(\log^2(1/\epsilon)\log\log(1/\epsilon)\right)$. By comparison, thebest-known discretization schemes in these settings require at least$O(\epsilon^{-1/2})$ discretization points (and even more gradient calls).Finally, we propose an adaptive variant of our method that sequentially addsbasis functions and demonstrates strong numerical performance throughexperiments.</description><author>Qiran Dong, Paul Grigas, Vishal Gupta</author><pubDate>Tue, 12 Nov 2024 18:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14885v2</guid></item><item><title>ExpressivityArena: Can LLMs Express Information Implicitly?</title><link>http://arxiv.org/abs/2411.08010v1</link><description>While Large Language Models (LLMs) have demonstrated remarkable performancein certain dimensions, their ability to express implicit language cues thathuman use for effective communication remains unclear. This paper presentsExpressivityArena, a Python library for measuring the implicit communicationabilities of LLMs. We provide a comprehensive framework to evaluateexpressivity of arbitrary LLMs and explore its practical implications. To thisend, we refine the definition and measurements of ``expressivity,'' and use ourframework in a set of small experiments. These experiments test LLMs increative and logical tasks such as poetry, coding, and emotion-based responses.They are then evaluated by an automated grader, through ExpressivityArena,which we verify to be the most pragmatic for testing expressivity. Building onthese experiments, we deepen our understanding of the expressivity of LLMs byassessing their ability to remain expressive in conversations. Our findingsindicate that LLMs are capable of generating and understanding expressivecontent, however, with some limitations. These insights will inform the futuredevelopment and deployment of expressive LLMs. We provide the code forExpressivityArena alongside our paper.</description><author>Joshua Tint, Som Sagar, Aditya Taparia, Kelly Raines, Bimsara Pathiraja, Caleb Liu, Ransalu Senanayake</author><pubDate>Tue, 12 Nov 2024 18:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08010v1</guid></item><item><title>Can adversarial attacks by large language models be attributed?</title><link>http://arxiv.org/abs/2411.08003v1</link><description>Attributing outputs from Large Language Models (LLMs) in adversarialsettings-such as cyberattacks and disinformation-presents significantchallenges that are likely to grow in importance. We investigate thisattribution problem using formal language theory, specifically languageidentification in the limit as introduced by Gold and extended by Angluin. Bymodeling LLM outputs as formal languages, we analyze whether finite textsamples can uniquely pinpoint the originating model. Our results show that dueto the non-identifiability of certain language classes, under some mildassumptions about overlapping outputs from fine-tuned models it istheoretically impossible to attribute outputs to specific LLMs with certainty.This holds also when accounting for expressivity limitations of Transformerarchitectures. Even with direct model access or comprehensive monitoring,significant computational hurdles impede attribution efforts. These findingshighlight an urgent need for proactive measures to mitigate risks posed byadversarial LLM use as their influence continues to expand.</description><author>Manuel Cebrian, Jan Arne Telle</author><pubDate>Tue, 12 Nov 2024 18:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08003v1</guid></item><item><title>VQC-Based Reinforcement Learning with Data Re-uploading: Performance and Trainability</title><link>http://arxiv.org/abs/2401.11555v2</link><description>Reinforcement Learning (RL) consists of designing agents that makeintelligent decisions without human supervision. When used alongside functionapproximators such as Neural Networks (NNs), RL is capable of solving extremelycomplex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achievedsuper-human performance in some specific tasks. Nonetheless, it is alsopossible to use Variational Quantum Circuits (VQCs) as function approximatorsin RL algorithms. This work empirically studies the performance andtrainability of such VQC-based Deep Q-Learning models in classic controlbenchmark environments. More specifically, we research how data re-uploadingaffects both these metrics. We show that the magnitude and the variance of thegradients of these models remain substantial throughout training due to themoving targets of Deep Q-Learning. Moreover, we empirically show thatincreasing the number of qubits does not lead to an exponential vanishingbehavior of the magnitude and variance of the gradients for a PQC approximatinga 2-design, unlike what was expected due to the Barren Plateau Phenomenon. Thishints at the possibility of VQCs being specially adequate for being used asfunction approximators in such a context.</description><author>Rodrigo Coelho, André Sequeira, Luís Paulo Santos</author><pubDate>Tue, 12 Nov 2024 18:18:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11555v2</guid></item><item><title>Derivational Morphology Reveals Analogical Generalization in Large Language Models</title><link>http://arxiv.org/abs/2411.07990v1</link><description>What mechanisms underlie linguistic generalization in large language models(LLMs)? This question has attracted considerable attention, with most studiesanalyzing the extent to which the language skills of LLMs resemble rules. As ofyet, it is not known whether linguistic generalization in LLMs could equallywell be explained as the result of analogical processes, which can beformalized as similarity operations on stored exemplars. A key shortcoming ofprior research is its focus on linguistic phenomena with a high degree ofregularity, for which rule-based and analogical approaches make the samepredictions. Here, we instead examine derivational morphology, specificallyEnglish adjective nominalization, which displays notable variability. Weintroduce a new method for investigating linguistic generalization in LLMs:focusing on GPT-J, we fit cognitive models that instantiate rule-based andanalogical learning to the LLM training data and compare their predictions on aset of nonce adjectives with those of the LLM, allowing us to draw directconclusions regarding underlying mechanisms. As expected, rule-based andanalogical models explain the predictions of GPT-J equally well for adjectiveswith regular nominalization patterns. However, for adjectives with variablenominalization patterns, the analogical model provides a much better match.Furthermore, GPT-J's behavior is sensitive to the individual word frequencies,even for regular forms, a behavior that is consistent with an analogicalaccount of regular forms but not a rule-based one. These findings refute thehypothesis that GPT-J's linguistic generalization on adjective nominalizationinvolves rules, suggesting similarity operations on stored exemplars as theunderlying mechanism. Overall, our study suggests that analogical processesplay a bigger role in the linguistic generalization of LLMs than previouslythought.</description><author>Valentin Hofmann, Leonie Weissweiler, David Mortensen, Hinrich Schütze, Janet Pierrehumbert</author><pubDate>Tue, 12 Nov 2024 18:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07990v1</guid></item><item><title>On the Utilization of Unique Node Identifiers in Graph Neural Networks</title><link>http://arxiv.org/abs/2411.02271v2</link><description>Graph Neural Networks have inherent representational limitations due to theirmessage-passing structure. Recent work has suggested that these limitations canbe overcome by using unique node identifiers (UIDs). Here we argue that despitethe advantages of UIDs, one of their disadvantages is that they lose thedesirable property of permutation-equivariance. We thus propose to focus on UIDmodels that are permutation-equivariant, and present theoretical arguments fortheir advantages. Motivated by this, we propose a method to regularize UIDmodels towards permutation equivariance, via a contrastive loss. We empiricallydemonstrate that our approach improves generalization and extrapolationabilities while providing faster training convergence. On the recent BRECexpressiveness benchmark, our proposed method achieves state-of-the-artperformance compared to other random-based approaches.</description><author>Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Schönlieb, Ran Gilad-Bachrach, Amir Globerson</author><pubDate>Tue, 12 Nov 2024 18:11:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02271v2</guid></item><item><title>Gini Coefficient as a Unified Metric for Evaluating Many-versus-Many Similarity in Vector Spaces</title><link>http://arxiv.org/abs/2411.07983v1</link><description>We demonstrate that Gini coefficients can be used as unified metrics toevaluate many-versus-many (all-to-all) similarity in vector spaces. Ouranalysis of various image datasets shows that images with the highest Ginicoefficients tend to be the most similar to one another, while images with thelowest Gini coefficients are the least similar. We also show that thisrelationship holds true for vectorized text embeddings from various corpuses,highlighting the consistency of our method and its broad applicability acrossdifferent types of data. Additionally, we demonstrate that selecting machinelearning training samples that closely match the distribution of the testingdataset is far more important than ensuring data diversity. Selection ofexemplary and iconic training samples with higher Gini coefficients leads tosignificantly better model performance compared to simply having a diversetraining set with lower Gini coefficients. Thus, Gini coefficients can serve aseffective criteria for selecting machine learning training samples, with ourselection method outperforming random sampling methods in very sparseinformation settings.</description><author>Ben Fauber</author><pubDate>Tue, 12 Nov 2024 18:08:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07983v1</guid></item><item><title>Exact, Tractable Gauss-Newton Optimization in Deep Reversible Architectures Reveal Poor Generalization</title><link>http://arxiv.org/abs/2411.07979v1</link><description>Second-order optimization has been shown to accelerate the training of deepneural networks in many applications, often yielding faster progress periteration on the training loss compared to first-order optimizers.However, thegeneralization properties of second-order methods are still being debated.Theoretical investigations have proved difficult to carry out outside thetractable settings of heavily simplified model classes -- thus, the relevanceof existing theories to practical deep learning applications remains unclear.Similarly, empirical studies in large-scale models and real datasets aresignificantly confounded by the necessity to approximate second-order updatesin practice. It is often unclear whether the observed generalization behaviourarises specifically from the second-order nature of the parameter updates, orinstead reflects the specific structured (e.g.\ Kronecker) approximations usedor any damping-based interpolation towards first-order updates. Here, we showfor the first time that exact Gauss-Newton (GN) updates take on a tractableform in a class of deep reversible architectures that are sufficientlyexpressive to be meaningfully applied to common benchmark datasets. We exploitthis novel setting to study the training and generalization properties of theGN optimizer. We find that exact GN generalizes poorly. In the mini-batchtraining setting, this manifests as rapidly saturating progress even on the\emph{training} loss, with parameter updates found to overfit eachmini-batchatch without producing the features that would support generalizationto other mini-batches. We show that our experiments run in the ``lazy'' regime,in which the neural tangent kernel (NTK) changes very little during the courseof training. This behaviour is associated with having no significant changes inneural representations, explaining the lack of generalization.</description><author>Davide Buffelli, Jamie McGowan, Wangkun Xu, Alexandru Cioba, Da-shan Shiu, Guillaume Hennequin, Alberto Bernacchia</author><pubDate>Tue, 12 Nov 2024 17:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07979v1</guid></item><item><title>Doubly Robust Regression Discontinuity Designs</title><link>http://arxiv.org/abs/2411.07978v1</link><description>This study introduces a doubly robust (DR) estimator for regressiondiscontinuity (RD) designs. In RD designs, treatment effects are estimated in aquasi-experimental setting where treatment assignment depends on whether arunning variable surpasses a predefined cutoff. A common approach in RDestimation is to apply nonparametric regression methods, such as local linearregression. In such an approach, the validity relies heavily on the consistencyof nonparametric estimators and is limited by the nonparametric convergencerate, thereby preventing $\sqrt{n}$-consistency. To address these issues, wepropose the DR-RD estimator, which combines two distinct estimators for theconditional expected outcomes. If either of these estimators is consistent, thetreatment effect estimator remains consistent. Furthermore, due to thedebiasing effect, our proposed estimator achieves $\sqrt{n}$-consistency ifboth regression estimators satisfy certain mild conditions, which alsosimplifies statistical inference.</description><author>Masahiro Kato</author><pubDate>Tue, 12 Nov 2024 17:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07978v1</guid></item><item><title>DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring</title><link>http://arxiv.org/abs/2411.07976v1</link><description>Coronary artery disease (CAD), one of the most common cause of mortality inthe world. Coronary artery calcium (CAC) scoring using computed tomography (CT)is key for risk assessment to prevent coronary disease. Previous studies onrisk assessment and calcification detection in CT scans primarily useapproaches based on UNET architecture, frequently implemented on pre-builtmodels. However, these models are limited by the availability of annotated CTscans containing CAC and suffering from imbalanced dataset, decreasingperformance of CAC segmentation and scoring. In this study, we extend thisapproach by incorporating the self-supervised learning (SSL) technique of DINO(self-distillation with no labels) to eliminate limitations of scarce annotateddata in CT scans. The DINO model's ability to train without requiring CAC areaannotations enhances its robustness in generating distinct features. The DINOmodel is trained on to focus specifically on calcified areas by using labels,aiming to generate features that effectively capture and highlight keycharacteristics. The label-guided DINO (DINO-LG) enhances classification bydistinguishing CT slices that contain calcification from those that do not,performing 57% better than the standard DINO model in this task. CAC scoringand segmentation tasks are performed by a basic U-NET architecture, fedspecifically with CT slices containing calcified areas as identified by theDINO-LG model. This targeted identification performed by DINO-LG model improvesCAC segmentation performance by approximately 10% and significant increase inCAC scoring accuracy.</description><author>Mahmut S. Gokmen, Cody Bumgardner, Caner Ozcan</author><pubDate>Tue, 12 Nov 2024 17:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07976v1</guid></item><item><title>JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2411.07975v1</link><description>We present JanusFlow, a powerful framework that unifies image understandingand generation in a single model. JanusFlow introduces a minimalistarchitecture that integrates autoregressive language models with rectifiedflow, a state-of-the-art method in generative modeling. Our key findingdemonstrates that rectified flow can be straightforwardly trained within thelarge language model framework, eliminating the need for complex architecturalmodifications. To further improve the performance of our unified model, weadopt two key strategies: (i) decoupling the understanding and generationencoders, and (ii) aligning their representations during unified training.Extensive experiments show that JanusFlow achieves comparable or superiorperformance to specialized models in their respective domains, whilesignificantly outperforming existing unified approaches across standardbenchmarks. This work represents a step toward more efficient and versatilevision-language models.</description><author>Yiyang Ma, Xingchao Liu, Xiaokang Chen, Wen Liu, Chengyue Wu, Zhiyu Wu, Zizheng Pan, Zhenda Xie, Haowei Zhang, Xingkai yu, Liang Zhao, Yisong Wang, Jiaying Liu, Chong Ruan</author><pubDate>Tue, 12 Nov 2024 17:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07975v1</guid></item><item><title>Optimal Control of Mechanical Ventilators with Learned Respiratory Dynamics</title><link>http://arxiv.org/abs/2411.07971v1</link><description>Deciding on appropriate mechanical ventilator management strategiessignificantly impacts the health outcomes for patients with respiratorydiseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease thatrequires careful ventilator operation to be effectively treated. In this work,we frame the management of ventilators for patients with ARDS as a sequentialdecision making problem using the Markov decision process framework. Weimplement and compare controllers based on clinical guidelines contained in theARDSnet protocol, optimal control theory, and learned latent dynamicsrepresented as neural networks. The Pulse Physiology Engine's respiratorydynamics simulator is used to establish a repeatable benchmark, gathersimulated data, and quantitatively compare these controllers. We scoreperformance in terms of measured improvement in established ARDS health markers(pertaining to improved respiratory rate, oxygenation, and vital signs). Ourresults demonstrate that techniques leveraging neural networks and optimalcontrol can automatically discover effective ventilation management strategieswithout access to explicit ventilator management procedures or guidelines (suchas those defined in the ARDSnet protocol).</description><author>Isaac Ronald Ward, Dylan M. Asmar, Mansur Arief, Jana Krystofova Mike, Mykel J. Kochenderfer</author><pubDate>Tue, 12 Nov 2024 17:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07971v1</guid></item><item><title>Foundation Models for the Electric Power Grid</title><link>http://arxiv.org/abs/2407.09434v2</link><description>Foundation models (FMs) currently dominate news headlines. They employadvanced deep learning architectures to extract structural informationautonomously from vast datasets through self-supervision. The resulting richrepresentations of complex systems and dynamics can be applied to manydownstream applications. Therefore, FMs can find uses in electric power grids,challenged by the energy transition and climate change. In this paper, we callfor the development of, and state why we believe in, the potential of FMs forelectric grids. We highlight their strengths and weaknesses amidst thechallenges of a changing grid. We argue that an FM learning from diverse griddata and topologies could unlock transformative capabilities, pioneering a newapproach in leveraging AI to redefine how we manage complexity and uncertaintyin the electric grid. Finally, we discuss a power grid FM concept, namelyGridFM, based on graph neural networks and show how different downstream tasksbenefit.</description><author>Hendrik F. Hamann, Thomas Brunschwiler, Blazhe Gjorgiev, Leonardo S. A. Martins, Alban Puech, Anna Varbella, Jonas Weiss, Juan Bernabe-Moreno, Alexandre Blondin Massé, Seong Choi, Ian Foster, Bri-Mathias Hodge, Rishabh Jain, Kibaek Kim, Vincent Mai, François Mirallès, Martin De Montigny, Octavio Ramos-Leaños, Hussein Suprême, Le Xie, El-Nasser S. Youssef, Arnaud Zinflou, Alexander J. Belyi, Ricardo J. Bessa, Bishnu Prasad Bhattarai, Johannes Schmude, Stanislav Sobolevsky</author><pubDate>Tue, 12 Nov 2024 17:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09434v2</guid></item><item><title>Sleep Staging from Airflow Signals Using Fourier Approximations of Persistence Curves</title><link>http://arxiv.org/abs/2411.07964v1</link><description>Sleep staging is a challenging task, typically manually performed by sleeptechnologists based on electroencephalogram and other biosignals of patientstaken during overnight sleep studies. Recent work aims to leverage automatedalgorithms to perform sleep staging not based on electroencephalogram signals,but rather based on the airflow signals of subjects. Prior work uses ideas fromtopological data analysis (TDA), specifically Hermite function expansions ofpersistence curves (HEPC) to featurize airflow signals. However, finite orderHEPC captures only partial information. In this work, we propose Fourierapproximations of persistence curves (FAPC), and use this technique to performsleep staging based on airflow signals. We analyze performance using an XGBoostmodel on 1155 pediatric sleep studies taken from the Nationwide Children'sHospital Sleep DataBank (NCHSDB), and find that FAPC methods providecomplimentary information to HEPC methods alone, leading to a 4.9% increase inperformance over baseline methods.</description><author>Shashank Manjunath, Hau-Tieng Wu, Aarti Sathyanarayana</author><pubDate>Tue, 12 Nov 2024 17:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07964v1</guid></item><item><title>From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents</title><link>http://arxiv.org/abs/2411.07965v1</link><description>The advanced role-playing capabilities of Large Language Models (LLMs) havepaved the way for developing Role-Playing Agents (RPAs). However, existingbenchmarks, such as HPD, which incorporates manually scored characterrelationships into the context for LLMs to sort coherence, and SocialBench,which uses specific profiles generated by LLMs in the context ofmultiple-choice tasks to assess character preferences, face limitations likepoor generalizability, implicit and inaccurate judgments, and excessive contextlength. To address the above issues, we propose an automatic, scalable, andgeneralizable paradigm. Specifically, we construct a benchmark by extractingrelations from a general knowledge graph and leverage RPA's inherenthallucination properties to prompt it to interact across roles, employingChatGPT for stance detection and defining relationship hallucination along withthree related metrics. Extensive experiments validate the effectiveness andstability of our metrics. Our findings further explore factors influencingthese metrics and discuss the trade-off between relationship hallucination andfactuality.</description><author>Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma</author><pubDate>Tue, 12 Nov 2024 17:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07965v1</guid></item><item><title>Plausible Extractive Rationalization through Semi-Supervised Entailment Signal</title><link>http://arxiv.org/abs/2402.08479v5</link><description>The increasing use of complex and opaque black box models requires theadoption of interpretable measures, one such option is extractive rationalizingmodels, which serve as a more interpretable alternative. These models, alsoknown as Explain-Then-Predict models, employ an explainer model to extractrationales and subsequently condition the predictor with the extractedinformation. Their primary objective is to provide precise and faithfulexplanations, represented by the extracted rationales. In this paper, we take asemi-supervised approach to optimize for the plausibility of extractedrationales. We adopt a pre-trained natural language inference (NLI) model andfurther fine-tune it on a small set of supervised rationales ($10\%$). The NLIpredictor is leveraged as a source of supervisory signals to the explainer viaentailment alignment. We show that, by enforcing the alignment agreementbetween the explanation and answer in a question-answering task, theperformance can be improved without access to ground truth labels. We evaluateour approach on the ERASER dataset and show that our approach achievescomparable results with supervised extractive models and outperformsunsupervised approaches by $&gt; 100\%$.</description><author>Wei Jie Yeo, Ranjan Satapathy, Erik Cambria</author><pubDate>Tue, 12 Nov 2024 17:38:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08479v5</guid></item><item><title>Self-training Large Language Models through Knowledge Detection</title><link>http://arxiv.org/abs/2406.11275v2</link><description>Large language models (LLMs) often necessitate extensive labeled datasets andtraining compute to achieve impressive performance across downstream tasks.This paper explores a self-training paradigm, where the LLM autonomouslycurates its own labels and selectively trains on unknown data samplesidentified through a reference-free consistency method. Empirical evaluationsdemonstrate significant improvements in reducing hallucination in generationacross multiple subjects. Furthermore, the selective training frameworkmitigates catastrophic forgetting in out-of-distribution benchmarks, addressinga critical limitation in training LLMs. Our findings suggest that such anapproach can substantially reduce the dependency on large labeled datasets,paving the way for more scalable and cost-effective language model training.</description><author>Wei Jie Yeo, Teddy Ferdinan, Przemyslaw Kazienko, Ranjan Satapathy, Erik Cambria</author><pubDate>Tue, 12 Nov 2024 17:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11275v2</guid></item><item><title>On the Convergence of Continual Federated Learning Using Incrementally Aggregated Gradients</title><link>http://arxiv.org/abs/2411.07959v1</link><description>The holy grail of machine learning is to enable Continual Federated Learning(CFL) to enhance the efficiency, privacy, and scalability of AI systems whilelearning from streaming data. The primary challenge of a CFL system is toovercome global catastrophic forgetting, wherein the accuracy of the globalmodel trained on new tasks declines on the old tasks. In this work, we proposeContinual Federated Learning with Aggregated Gradients (C-FLAG), a novelreplay-memory based federated strategy consisting of edge-based gradientupdates on memory and aggregated gradients on the current data. We provideconvergence analysis of the C-FLAG approach which addresses forgetting and biaswhile converging at a rate of $O(1/\sqrt{T})$ over $T$ communication rounds. Weformulate an optimization sub-problem that minimizes catastrophic forgetting,translating CFL into an iterative algorithm with adaptive learning rates thatensure seamless learning across tasks. We empirically show that C-FLAGoutperforms several state-of-the-art baselines on both task andclass-incremental settings with respect to metrics such as accuracy andforgetting.</description><author>Satish Kumar Keshri, Nazreen Shah, Ranjitha Prasad</author><pubDate>Tue, 12 Nov 2024 17:36:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07959v1</guid></item><item><title>Tukey g-and-h neural network regression for non-Gaussian data</title><link>http://arxiv.org/abs/2411.07957v1</link><description>This paper addresses non-Gaussian regression with neural networks via the useof the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexibleparametric transform with two parameters $g$ and $h$ which, when applied to astandard normal random variable, introduces both skewness and kurtosis,resulting in a distribution commonly called the Tukey g-and-h distribution.Specific values of $g$ and $h$ produce good approximations to other families ofdistributions, such as the Cauchy and student-t distributions. The flexibilityof the Tukey g-and-h distribution has driven its popularity in the statisticalcommunity, in applied sciences and finance. In this work we consider thetraining of a neural network to predict the parameters of a Tukey g-and-hdistribution in a regression framework via the minimization of thecorresponding negative log-likelihood, despite the latter having no closed-formexpression. We demonstrate the efficiency of our procedure in simulatedexamples and apply our method to a real-world dataset of global crop yield forseveral types of crops. Finally, we show how we can carry out a goodness-of-fitanalysis between the predicted distributions and the test data. A Pytorchimplementation is made available on Github and as a Pypi package.</description><author>Arthur P. Guillaumin, Natalia Efremova</author><pubDate>Tue, 12 Nov 2024 17:34:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07957v1</guid></item><item><title>Commissioning An All-Sky Infrared Camera Array for Detection Of Airborne Objects</title><link>http://arxiv.org/abs/2411.07956v1</link><description>To date there is little publicly available scientific data on UnidentifiedAerial Phenomena (UAP) whose properties and kinematics purportedly resideoutside the performance envelope of known phenomena. To address thisdeficiency, the Galileo Project is designing, building, and commissioning amulti-modal ground-based observatory to continuously monitor the sky andconduct a rigorous long-term aerial census of all aerial phenomena, includingnatural and human-made. One of the key instruments is an all-sky infraredcamera array using eight uncooled long-wave infrared FLIR Boson 640 cameras.Their calibration includes a novel extrinsic calibration method using airplanepositions from Automatic Dependent Surveillance-Broadcast (ADS-B) data. Weestablish a first baseline for the system performance over five months of fieldoperation, using a real-world dataset derived from ADS-B data, synthetic 3-Dtrajectories, and a hand-labelled real-world dataset. We report acceptancerates (e.g. viewable airplanes that are recorded) and detection efficiencies(e.g. recorded airplanes which are successfully detected) for a variety ofweather conditions, range and aircraft size. We reconstruct $\sim$500,000trajectories of aerial objects from this commissioning period. A toy outliersearch focused on large sinuosity of the 2-D reconstructed trajectories flagsabout 16% of trajectories as outliers. After manual review, 144 trajectoriesremain ambiguous: they are likely mundane objects but cannot be elucidated atthis stage of development without distance and kinematics estimation or othersensor modalities. Our observed count of ambiguous outliers combined withsystematic uncertainties yields an upper limit of 18,271 outliers count for thefive-month interval at a 95% confidence level. This likelihood-based method toevaluate significance is applicable to all of our future outlier searches.</description><author>Laura Dominé, Ankit Biswas, Richard Cloete, Alex Delacroix, Andriy Fedorenko, Lucas Jacaruso, Ezra Kelderman, Eric Keto, Sarah Little, Abraham Loeb, Eric Masson, Mike Prior, Forrest Schultz, Matthew Szenher, Wes Watters, Abby White</author><pubDate>Tue, 12 Nov 2024 17:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07956v1</guid></item><item><title>How To Discover Short, Shorter, and the Shortest Proofs of Unsatisfiability: A Branch-and-Bound Approach for Resolution Proof Length Minimization</title><link>http://arxiv.org/abs/2411.07955v1</link><description>Modern software for propositional satisfiability problems gives a powerfulautomated reasoning toolkit, capable of outputting not only asatisfiable/unsatisfiable signal but also a justification of unsatisfiabilityin the form of resolution proof (or a more expressive proof), which is commonlyused for verification purposes. Empirically, modern SAT solvers producerelatively short proofs, however, there are no inherent guarantees that theseproofs cannot be significantly reduced. This paper proposes a novelbranch-and-bound algorithm for finding the shortest resolution proofs; to thisend, we introduce a layer list representation of proofs that groups clauses bytheir level of indirection. As we show, this representation breaks allpermutational symmetries, thereby improving upon the state-of-the-artsymmetry-breaking and informing the design of a novel workflow for proofminimization. In addition to that, we design pruning procedures that reason onproof length lower bound, clause subsumption, and dominance. Our experimentssuggest that the proofs from state-of-the-art solvers could be shortened by30-60% on the instances from SAT Competition 2002 and by 25-50% on smallsynthetic formulas. When treated as an algorithm for finding the shortestproof, our approach solves twice as many instances as the previous work basedon SAT solving and reduces the time to optimality by orders of magnitude forthe instances solved by both approaches.</description><author>Konstantin Sidorov, Koos van der Linden, Gonçalo Homem de Almeida Correia, Mathijs de Weerdt, Emir Demirović</author><pubDate>Tue, 12 Nov 2024 17:31:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07955v1</guid></item><item><title>Learning Memory Mechanisms for Decision Making through Demonstrations</title><link>http://arxiv.org/abs/2411.07954v1</link><description>In Partially Observable Markov Decision Processes, integrating an agent'shistory into memory poses a significant challenge for decision-making.Traditional imitation learning, relying on observation-action pairs for expertdemonstrations, fails to capture the expert's memory mechanisms used indecision-making. To capture memory processes as demonstrations, we introducethe concept of \textbf{memory dependency pairs} $(p, q)$ indicating that eventsat time $p$ are recalled for decision-making at time $q$. We introduce\textbf{AttentionTuner} to leverage memory dependency pairs in Transformers andfind significant improvements across several tasks compared to standardTransformers when evaluated on Memory Gym and the Long-term Memory Benchmark.Code is available at https://github.com/WilliamYue37/AttentionTuner .</description><author>William Yue, Bo Liu, Peter Stone</author><pubDate>Tue, 12 Nov 2024 17:30:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07954v1</guid></item><item><title>SimBase: A Simple Baseline for Temporal Video Grounding</title><link>http://arxiv.org/abs/2411.07945v1</link><description>This paper presents SimBase, a simple yet effective baseline for temporalvideo grounding. While recent advances in temporal grounding have led toimpressive performance, they have also driven network architectures towardgreater complexity, with a range of methods to (1) capture temporalrelationships and (2) achieve effective multimodal fusion. In contrast, thispaper explores the question: How effective can a simplified approach be? Toinvestigate, we design SimBase, a network that leverages lightweight,one-dimensional temporal convolutional layers instead of complex temporalstructures. For cross-modal interaction, SimBase only employs an element-wiseproduct instead of intricate multimodal fusion. Remarkably, SimBase achievesstate-of-the-art results on two large-scale datasets. As a simple yet powerfulbaseline, we hope SimBase will spark new ideas and streamline futureevaluations in temporal video grounding.</description><author>Peijun Bao, Alex C. Kot</author><pubDate>Tue, 12 Nov 2024 17:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07945v1</guid></item><item><title>Towards Low-bit Communication for Tensor Parallel LLM Inference</title><link>http://arxiv.org/abs/2411.07942v1</link><description>Tensor parallelism provides an effective way to increase server largelanguage model (LLM) inference efficiency despite adding an additionalcommunication cost. However, as server LLMs continue to scale in size, theywill need to be distributed across more devices, magnifying the communicationcost. One way to approach this problem is with quantization, but currentmethods for LLMs tend to avoid quantizing the features that tensor parallelismneeds to communicate. Taking advantage of consistent outliers in communicatedfeatures, we introduce a quantization method that reduces communicated valueson average from 16 bits to 4.2 bits while preserving nearly all of the originalperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma2 27B's and Llama 2 13B's original performance, respectively, averaged acrossall tasks we evaluated on.</description><author>Harry Dong, Tyler Johnson, Minsik Cho, Emad Soroush</author><pubDate>Tue, 12 Nov 2024 17:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07942v1</guid></item><item><title>DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks</title><link>http://arxiv.org/abs/2411.07941v1</link><description>Computed tomography (CT) provides highly detailed three-dimensional (3D)medical images but is costly, time-consuming, and often inaccessible inintraoperative settings (Organization et al. 2011). Recent advancements haveexplored reconstructing 3D chest volumes from sparse 2D X-rays, such assingle-view or orthogonal double-view images. However, current models tend toprocess 2D images in a planar manner, prioritizing visual realism overstructural accuracy. In this work, we introduce DuoLift Generative AdversarialNetworks (DuoLift-GAN), a novel architecture with dual branches thatindependently elevate 2D images and their features into 3D representations.These 3D outputs are merged into a unified 3D feature map and decoded into acomplete 3D chest volume, enabling richer 3D information capture. We alsopresent a masked loss function that directs reconstruction towards criticalanatomical regions, improving structural accuracy and visual quality. Thispaper demonstrates that DuoLift-GAN significantly enhances reconstructionaccuracy while achieving superior visual realism compared to existing methods.</description><author>Zhaoxi Zhang, Yueliang Ying</author><pubDate>Tue, 12 Nov 2024 17:11:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07941v1</guid></item><item><title>Automatic dataset shift identification to support root cause analysis of AI performance drift</title><link>http://arxiv.org/abs/2411.07940v1</link><description>Shifts in data distribution can substantially harm the performance ofclinical AI models. Hence, various methods have been developed to detect thepresence of such shifts at deployment time. However, root causes of datasetshifts are varied, and the choice of shift mitigation strategies is highlydependent on the precise type of shift encountered at test time. As such,detecting test-time dataset shift is not sufficient: precisely identifyingwhich type of shift has occurred is critical. In this work, we propose thefirst unsupervised dataset shift identification framework, effectivelydistinguishing between prevalence shift (caused by a change in the labeldistribution), covariate shift (caused by a change in input characteristics)and mixed shifts (simultaneous prevalence and covariate shifts). We discuss theimportance of self-supervised encoders for detecting subtle covariate shiftsand propose a novel shift detector leveraging both self-supervised encoders andtask model outputs for improved shift detection. We report promising resultsfor the proposed shift identification framework across three different imagingmodalities (chest radiography, digital mammography, and retinal fundus images)on five types of real-world dataset shifts, using four large publicly availabledatasets.</description><author>Mélanie Roschewitz, Raghav Mehta, Charles Jones, Ben Glocker</author><pubDate>Tue, 12 Nov 2024 17:09:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07940v1</guid></item><item><title>Learning Disentangled Representations for Perceptual Point Cloud Quality Assessment via Mutual Information Minimization</title><link>http://arxiv.org/abs/2411.07936v1</link><description>No-Reference Point Cloud Quality Assessment (NR-PCQA) aims to objectivelyassess the human perceptual quality of point clouds without relying onpristine-quality point clouds for reference. It is becoming increasinglysignificant with the rapid advancement of immersive media applications such asvirtual reality (VR) and augmented reality (AR). However, current NR-PCQAmodels attempt to indiscriminately learn point cloud content and distortionrepresentations within a single network, overlooking their distinctcontributions to quality information. To address this issue, we propose DisPA,a novel disentangled representation learning framework for NR-PCQA. Theframework trains a dual-branch disentanglement network to minimize mutualinformation (MI) between representations of point cloud content and distortion.Specifically, to fully disentangle representations, the two branches adoptdifferent philosophies: the content-aware encoder is pretrained by a maskedauto-encoding strategy, which can allow the encoder to capture semanticinformation from rendered images of distorted point clouds; thedistortion-aware encoder takes a mini-patch map as input, which forces theencoder to focus on low-level distortion patterns. Furthermore, we utilize anMI estimator to estimate the tight upper bound of the actual MI and furtherminimize it to achieve explicit representation disentanglement. Extensiveexperimental results demonstrate that DisPA outperforms state-of-the-artmethods on multiple PCQA datasets.</description><author>Ziyu Shan, Yujie Zhang, Yipeng Liu, Yiling Xu</author><pubDate>Tue, 12 Nov 2024 17:05:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07936v1</guid></item><item><title>Doubly Mild Generalization for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2411.07934v1</link><description>Offline Reinforcement Learning (RL) suffers from the extrapolation error andvalue overestimation. From a generalization perspective, this issue can beattributed to the over-generalization of value functions or policies towardsout-of-distribution (OOD) actions. Significant efforts have been devoted tomitigating such generalization, and recent in-sample learning approaches havefurther succeeded in entirely eschewing it. Nevertheless, we show that mildgeneralization beyond the dataset can be trusted and leveraged to improveperformance under certain conditions. To appropriately exploit generalizationin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mildaction generalization and (ii) mild generalization propagation. The formerrefers to selecting actions in a close neighborhood of the dataset to maximizethe Q values. Even so, the potential erroneous generalization can still bepropagated, accumulated, and exacerbated by bootstrapping. In light of this,the latter concept is introduced to mitigate the generalization propagationwithout impeding the propagation of RL learning signals. Theoretically, DMGguarantees better performance than the in-sample optimal policy in the oraclegeneralization scenario. Even under worst-case generalization, DMG can stillcontrol value overestimation at a certain level and lower bound theperformance. Empirically, DMG achieves state-of-the-art performance acrossGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefitingfrom its flexibility in both generalization aspects, DMG enjoys a seamlesstransition from offline to online learning and attains strong onlinefine-tuning performance.</description><author>Yixiu Mao, Qi Wang, Yun Qu, Yuhang Jiang, Xiangyang Ji</author><pubDate>Tue, 12 Nov 2024 17:04:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07934v1</guid></item><item><title>Prediction of Acoustic Communication Performance for AUVs using Gaussian Process Classification</title><link>http://arxiv.org/abs/2411.07933v1</link><description>Cooperating autonomous underwater vehicles (AUVs) often rely on acousticcommunication to coordinate their actions effectively. However, the reliabilityof underwater acoustic communication decreases as the communication rangebetween vehicles increases. Consequently, teams of cooperating AUVs typicallymake conservative assumptions about the maximum range at which they cancommunicate reliably. To address this limitation, we propose a novel approachthat involves learning a map representing the probability of successfulcommunication based on the locations of the transmitting and receivingvehicles. This probabilistic communication map accounts for factors such as therange between vehicles, environmental noise, and multi-path effects at a givenlocation. In pursuit of this goal, we investigate the application of Gaussianprocess binary classification to generate the desired communication map. Wespecialize existing results to this specific binary classification problem andexplore methods to incorporate uncertainty in vehicle location into the mappingprocess. Furthermore, we compare the prediction performance of the probabilitycommunication map generated using binary classification with that of asignal-to-noise ratio (SNR) communication map generated using Gaussian processregression. Our approach is experimentally validated using communication andnavigation data collected during trials with a pair of Virginia Tech 690 AUVs.</description><author>Yifei Gao, Harun Yetkin, McMahon James, Daniel J. Stilwell</author><pubDate>Tue, 12 Nov 2024 17:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07933v1</guid></item><item><title>Isometric Transformations for Image Augmentation in Mueller Matrix Polarimetry</title><link>http://arxiv.org/abs/2411.07918v1</link><description>Mueller matrix polarimetry captures essential information about polarizedlight interactions with a sample, presenting unique challenges for dataaugmentation in deep learning due to its distinct structure. Whileaugmentations are an effective and affordable way to enhance dataset diversityand reduce overfitting, standard transformations like rotations and flips donot preserve the polarization properties in Mueller matrix images. To this end,we introduce a versatile simulation framework that applies physicallyconsistent rotations and flips to Mueller matrices, tailored to maintainpolarization fidelity. Our experimental results across multiple datasets revealthat conventional augmentations can lead to misleading results when applied topolarimetric data, underscoring the necessity of our physics-based approach. Inour experiments, we first compare our polarization-specific augmentationsagainst real-world captures to validate their physical consistency. We thenapply these augmentations in a semantic segmentation task, achievingsubstantial improvements in model generalization and performance. This studyunderscores the necessity of physics-informed data augmentation forpolarimetric imaging in deep learning (DL), paving the way for broader adoptionand more robust applications across diverse research in the field. Inparticular, our framework unlocks the potential of DL models for polarimetricdatasets with limited sample sizes. Our code implementation is available atgithub.com/hahnec/polar_augment.</description><author>Christopher Hahne, Omar Rodriguez-Nunez, Éléa Gros, Théotim Lucas, Ekkehard Hewer, Tatiana Novikova, Theoni Maragkou, Philippe Schucht, Richard McKinley</author><pubDate>Tue, 12 Nov 2024 16:50:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07918v1</guid></item><item><title>CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and Classification of Crypto Posts</title><link>http://arxiv.org/abs/2411.07917v1</link><description>The rapid growth of social media has resulted in an large volume ofuser-generated content, particularly in niche domains such as cryptocurrency.This task focuses on developing robust classification models to accuratelycategorize cryptocurrency-related social media posts into predefined classes,including but not limited to objective, positive, negative, etc. Additionally,the task requires participants to identify the most relevant answers from a setof posts in response to specific questions. By leveraging advanced LLMs, thisresearch aims to enhance the understanding and filtering of cryptocurrencydiscourse, thereby facilitating more informed decision-making in this volatilesector. We have used a prompt-based technique to solve the classification taskfor reddit posts and twitter posts. Also, we have used 64-shot technique alongwith prompts on GPT-4-Turbo model to determine whether a answer is relevant toa question or not.</description><author>Aniket Deroy, Subhankar Maity</author><pubDate>Tue, 12 Nov 2024 16:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07917v1</guid></item><item><title>LE-PDE++: Mamba for accelerating PDEs Simulations</title><link>http://arxiv.org/abs/2411.01897v2</link><description>Partial Differential Equations are foundational in modeling science andnatural systems such as fluid dynamics and weather forecasting. The LatentEvolution of PDEs method is designed to address the computational intensity ofclassical and deep learning-based PDE solvers by proposing a scalable andefficient alternative. To enhance the efficiency and accuracy of LE-PDE, weincorporate the Mamba model, an advanced machine learning model known for itspredictive efficiency and robustness in handling complex dynamic systems with aprogressive learning strategy. The LE-PDE was tested on several benchmarkproblems. The method demonstrated a marked reduction in computational timecompared to traditional solvers and standalone deep learning models whilemaintaining high accuracy in predicting system behavior over time. Our methoddoubles the inference speed compared to the LE-PDE while retaining the samelevel of parameter efficiency, making it well-suited for scenarios requiringlong-term predictions.</description><author>Aoming Liang, Zhaoyang Mu, Qi liu, Ruipeng Li, Mingming Ge, Dixia Fan</author><pubDate>Tue, 12 Nov 2024 16:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01897v2</guid></item><item><title>Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding</title><link>http://arxiv.org/abs/2406.13230v2</link><description>Calibrating language models (LMs) aligns their generation confidence with theactual likelihood of answer correctness, which can inform users about LMs'reliability and mitigate hallucinated content. However, prior calibrationmethods, such as self-consistency-based and logit-based approaches, are eitherlimited in inference-time efficiency or fall short of providing informativesignals. Moreover, simply filtering out low-confidence responses reduces theLM's helpfulness when the answers are correct. Therefore, effectively usingcalibration techniques to enhance an LM's factuality remains an unsolvedchallenge. In this paper, we first propose an activation-based calibrationmethod, ActCab, which trains a linear layer on top of the LM's last-layeractivations that can better capture the representations of knowledge. Built ontop of ActCab, we further propose CoDec, a confidence-guided decoding strategyto elicit truthful answers with high confidence from LMs. By evaluating on fivepopular QA benchmarks, ActCab achieves superior calibration performance thanall competitive baselines, e.g., by reducing the average expected calibrationerror (ECE) score by up to 39%. Further experiments on CoDec show consistentimprovements in several LMs' factuality on challenging QA datasets, such asTruthfulQA, highlighting the value of confidence signals in enhancingfactuality.</description><author>Xin Liu, Farima Fatahi Bayat, Lu Wang</author><pubDate>Tue, 12 Nov 2024 16:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13230v2</guid></item><item><title>Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN</title><link>http://arxiv.org/abs/2408.03497v2</link><description>Bank credit risk is a significant challenge in modern financial transactions,and the ability to identify qualified credit card holders among a large numberof applicants is crucial for the profitability of a bank'sbank's credit cardbusiness. In the past, screening applicants'applicants' conditions oftenrequired a significant amount of manual labor, which was time-consuming andlabor-intensive. Although the accuracy and reliability of previously used MLmodels have been continuously improving, the pursuit of more reliable andpowerful AI intelligent models is undoubtedly the unremitting pursuit by majorbanks in the financial industry. In this study, we used a dataset of over40,000 records provided by a commercial bank as the research object. Wecompared various dimensionality reduction techniques such as PCA and T-SNE forpreprocessing high-dimensional datasets and performed in-depth adaptation andtuning of distributed models such as LightGBM and XGBoost, as well as deepmodels like Tabnet. After a series of research and processing, we obtainedexcellent research results by combining SMOTEENN with these techniques. Theexperiments demonstrated that LightGBM combined with PCA and SMOTEENNtechniques can assist banks in accurately predicting potential high-qualitycustomers, showing relatively outstanding performance compared to other models.</description><author>Chang Yu, Yixin Jin, Qianwen Xing, Ye Zhang, Shaobo Guo, Shuchen Meng</author><pubDate>Tue, 12 Nov 2024 16:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03497v2</guid></item><item><title>Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated</title><link>http://arxiv.org/abs/2406.04658v3</link><description>With the rise of various online and mobile payment systems, transaction fraudhas become a significant threat to financial security. This study explores theapplication of advanced machine learning models, specifically based on XGBoostand LightGBM, for developing a more accurate and robust Payment SecurityProtection Model. To enhance data reliability, we meticulously processed thedata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) toaddress class imbalance and improve data representation. By selecting highlycorrelated features, we aimed to strengthen the training process and boostmodel performance. We conducted thorough performance evaluations of ourproposed models, comparing them against traditional methods including RandomForest, Neural Network, and Logistic Regression. Using metrics such asPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.Our detailed analyses and comparisons reveal that the combination of SMOTE withXGBoost and LightGBM offers a highly efficient and powerful mechanism forpayment security protection. Moreover, the integration of XGBoost and LightGBMin a Local Ensemble model further demonstrated outstanding performance. Afterincorporating SMOTE, the new combined model achieved a significant improvementof nearly 6\% over traditional models and around 5\% over its sub-models,showcasing remarkable results.</description><author>Qi Zheng, Chang Yu, Jin Cao, Yongshun Xu, Qianwen Xing, Yinxin Jin</author><pubDate>Tue, 12 Nov 2024 16:44:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04658v3</guid></item><item><title>Credit Card Fraud Detection Using Advanced Transformer Model</title><link>http://arxiv.org/abs/2406.03733v4</link><description>With the proliferation of various online and mobile payment systems, creditcard fraud has emerged as a significant threat to financial security. Thisstudy focuses on innovative applications of the latest Transformer models formore robust and precise fraud detection. To ensure the reliability of the data,we meticulously processed the data sources, balancing the dataset to addressthe issue of data sparsity significantly. We also selected highly correlatedvectors to strengthen the training process.To guarantee the reliability andpracticality of the new Transformer model, we conducted performance comparisonswith several widely adopted models, including Support Vector Machine (SVM),Random Forest, Neural Network, and Logistic Regression. We rigorously comparedthese models using metrics such as Precision, Recall, and F1 Score. Throughthese detailed analyses and comparisons, we present to the readers a highlyefficient and powerful anti-fraud mechanism with promising prospects. Theresults demonstrate that the Transformer model not only excels in traditionalapplications but also shows great potential in niche areas like frauddetection, offering a substantial advancement in the field.</description><author>Chang Yu, Yongshun Xu, Jin Cao, Ye Zhang, Yinxin Jin, Mengran Zhu</author><pubDate>Tue, 12 Nov 2024 16:44:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03733v4</guid></item><item><title>Enhanced Credit Score Prediction Using Ensemble Deep Learning Model</title><link>http://arxiv.org/abs/2410.00256v2</link><description>In contemporary economic society, credit scores are crucial for everyparticipant. A robust credit evaluation system is essential for theprofitability of core businesses such as credit cards, loans, and investmentsfor commercial banks and the financial sector. This paper combineshigh-performance models like XGBoost and LightGBM, already widely used inmodern banking systems, with the powerful TabNet model. We have developed apotent model capable of accurately determining credit score levels byintegrating Random Forest, XGBoost, and TabNet, and through the stackingtechnique in ensemble modeling. This approach surpasses the limitations ofsingle models and significantly advances the precise credit score prediction.In the following sections, we will explain the techniques we used andthoroughly validate our approach by comprehensively comparing a series ofmetrics such as Precision, Recall, F1, and AUC. By integrating Random Forest,XGBoost, and with the TabNet deep learning architecture, these modelscomplement each other, demonstrating exceptionally strong overall performance.</description><author>Qianwen Xing, Chang Yu, Sining Huang, Qi Zheng, Xingyu Mu, Mengying Sun</author><pubDate>Tue, 12 Nov 2024 16:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00256v2</guid></item><item><title>WavShadow: Wavelet Based Shadow Segmentation and Removal</title><link>http://arxiv.org/abs/2411.05747v3</link><description>Shadow removal and segmentation remain challenging tasks in computer vision,particularly in complex real world scenarios. This study presents a novelapproach that enhances the ShadowFormer model by incorporating MaskedAutoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading tosignificantly faster convergence and improved performance. We introduce keyinnovations: (1) integration of MAE priors trained on Places2 dataset forbetter context understanding, (2) adoption of Haar wavelet features forenhanced edge detection and multiscale analysis, and (3) implementation of amodified SAM Adapter for robust shadow segmentation. Extensive experiments onthe challenging DESOBA dataset demonstrate that our approach achieves state ofthe art results, with notable improvements in both convergence speed and shadowremoval quality.</description><author>Shreyans Jain, Viraj Vekaria, Karan Gandhi, Aadya Arora</author><pubDate>Tue, 12 Nov 2024 16:42:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05747v3</guid></item><item><title>Exploiting User Comments for Early Detection of Fake News Prior to Users' Commenting</title><link>http://arxiv.org/abs/2310.10429v2</link><description>Both accuracy and timeliness are key factors in detecting fake news on socialmedia. However, most existing methods encounter an accuracy-timeliness dilemma:Content-only methods guarantee timeliness but perform moderately because oflimited available information, while social con-text-based ones generallyperform better but inevitably lead to latency because of social contextaccumulation needs. To break such a dilemma, a feasible but not well-studiedsolution is to leverage social contexts (e.g., comments) from historical newsfor training a detection model and apply it to newly emerging news withoutsocial contexts. This requires the model to (1) sufficiently learn helpfulknowledge from social contexts, and (2) be well compatible with situations thatsocial contexts are available or not. To achieve this goal, we propose toabsorb and parameterize useful knowledge from comments in historical news andthen inject it into a content-only detection model. Specifically, we design theComments ASsisted FakE News Detection method (CAS-FEND), which transfers usefulknowledge from a comment-aware teacher model to a content-only student modeland detects newly emerging news with the student model. Experiments show thatthe CAS-FEND student model outperforms all content-only methods and evencomment-aware ones with 1/4 comments as inputs, demonstrating its superiorityfor early detection.</description><author>Qiong Nan, Qiang Sheng, Juan Cao, Yongchun Zhu, Danding Wang, Guang Yang, Jintao Li</author><pubDate>Tue, 12 Nov 2024 16:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10429v2</guid></item><item><title>Meta-Learned Modality-Weighted Knowledge Distillation for Robust Multi-Modal Learning with Missing Data</title><link>http://arxiv.org/abs/2405.07155v2</link><description>In multi-modal learning, some modalities are more influential than others,and their absence can have a significant impact on classification/segmentationaccuracy. Addressing this challenge, we propose a novel approach calledMeta-learned Modality-weighted Knowledge Distillation (MetaKD), which enablesmulti-modal models to maintain high accuracy even when key modalities aremissing. MetaKD adaptively estimates the importance weight of each modalitythrough a meta-learning process. These learned importance weights guide apairwise modality-weighted knowledge distillation process, allowinghigh-importance modalities to transfer knowledge to lower-importance ones,resulting in robust performance despite missing inputs. Unlike previous methodsin the field, which are often task-specific and require significantmodifications, our approach is designed to work in multiple tasks (e.g.,segmentation and classification) with minimal adaptation. Experimental resultson five prevalent datasets, including three Brain Tumor Segmentation datasets(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease NeuroimagingInitiative (ADNI) classification dataset and the Audiovision-MNISTclassification dataset, demonstrate the proposed model is able to outperformthe compared models by a large margin.</description><author>Hu Wang, Salma Hassan, Yuyuan Liu, Congbo Ma, Yuanhong Chen, Yutong Xie, Mostafa Salem, Yu Tian, Jodie Avery, Louise Hull, Ian Reid, Mohammad Yaqub, Gustavo Carneiro</author><pubDate>Tue, 12 Nov 2024 16:39:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07155v2</guid></item><item><title>How Do Large Language Models Acquire Factual Knowledge During Pretraining?</title><link>http://arxiv.org/abs/2406.11813v3</link><description>Despite the recent observation that large language models (LLMs) can storesubstantial factual knowledge, there is a limited understanding of themechanisms of how they acquire factual knowledge through pretraining. This workaddresses this gap by studying how LLMs acquire factual knowledge duringpretraining. The findings reveal several important insights into the dynamicsof factual knowledge acquisition during pretraining. First, counterintuitively,we observe that pretraining on more data shows no significant improvement inthe model's capability to acquire and maintain factual knowledge. Next, thereis a power-law relationship between training steps and forgetting ofmemorization and generalization of factual knowledge, and LLMs trained withduplicated training data exhibit faster forgetting. Third, training LLMs withlarger batch sizes can enhance the models' robustness to forgetting. Overall,our observations suggest that factual knowledge acquisition in LLM pretrainingoccurs by progressively increasing the probability of factual knowledgepresented in the pretraining data at each step. However, this increase isdiluted by subsequent forgetting. Based on this interpretation, we demonstratethat we can provide plausible explanations for recently observed behaviors ofLLMs, such as the poor performance of LLMs on long-tail knowledge and thebenefits of deduplicating the pretraining corpus.</description><author>Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo</author><pubDate>Tue, 12 Nov 2024 16:38:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11813v3</guid></item><item><title>Levin Tree Search with Context Models</title><link>http://arxiv.org/abs/2305.16945v3</link><description>Levin Tree Search (LTS) is a search algorithm that makes use of a policy (aprobability distribution over actions) and comes with a theoretical guaranteeon the number of expansions before reaching a goal node, depending on thequality of the policy. This guarantee can be used as a loss function, which wecall the LTS loss, to optimize neural networks representing the policy(LTS+NN). In this work we show that the neural network can be substituted withparameterized context models originating from the online compression literature(LTS+CM). We show that the LTS loss is convex under this new model, whichallows for using standard convex optimization tools, and obtain convergenceguarantees to the optimal parameters in an online setting for a given set ofsolution trajectories -- guarantees that cannot be provided for neuralnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on severalbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle(STP). The difference is particularly large on STP, where LTS+NN fails to solvemost of the test instances while LTS+CM solves each test instance in a fractionof a second. Furthermore, we show that LTS+CM is able to learn a policy thatsolves the Rubik's cube in only a few hundred expansions, which considerablyimproves upon previous machine learning techniques.</description><author>Laurent Orseau, Marcus Hutter, Levi H. S. Lelis</author><pubDate>Tue, 12 Nov 2024 16:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16945v3</guid></item><item><title>TLDR: Traffic Light Detection using Fourier Domain Adaptation in Hostile WeatheR</title><link>http://arxiv.org/abs/2411.07901v1</link><description>The scarcity of comprehensive datasets in the traffic light detection andrecognition domain and the poor performance of state-of-the-art models underhostile weather conditions present significant challenges. To address theseissues, this paper proposes a novel approach by merging two widely useddatasets, LISA and S2TLD. The merged dataset is further processed to tackleclass imbalance, a common problem in this domain. This merged dataset becomesour source domain. Synthetic rain and fog are added to the dataset to createour target domain. We employ Fourier Domain Adaptation (FDA) to create a finaldataset with a minimized domain gap between the two datasets, helping the modeltrained on this final dataset adapt to rainy and foggy weather conditions.Additionally, we explore Semi-Supervised Learning (SSL) techniques to leveragethe available data more effectively. Experimental results demonstrate thatmodels trained on FDA-augmented images outperform those trained without FDAacross confidence-dependent and independent metrics, like mAP50, mAP50-95,Precision, and Recall. The best-performing model, YOLOv8, achieved a Precisionincrease of 5.1860%, Recall increase of 14.8009%, mAP50 increase of 9.5074%,and mAP50-95 increase of 19.5035%. On average, percentage increases of 7.6892%in Precision, 19.9069% in Recall, 15.8506% in mAP50, and 23.8099% in mAP50-95were observed across all models, highlighting the effectiveness of FDA inmitigating the impact of adverse weather conditions on model performance. Theseimprovements pave the way for real-world applications where reliableperformance in challenging environmental conditions is critical.</description><author>Ishaan Gakhar, Aryesh Guha, Aryaman Gupta, Amit Agarwal, Durga Toshniwal, Ujjwal Verma</author><pubDate>Tue, 12 Nov 2024 16:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07901v1</guid></item><item><title>Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse Tensor-based Transformer</title><link>http://arxiv.org/abs/2411.07899v1</link><description>The evolution of 3D visualization techniques has fundamentally transformedhow we interact with digital content. At the forefront of this change is pointcloud technology, offering an immersive experience that surpasses traditional2D representations. However, the massive data size of point clouds presentssignificant challenges in data compression. Current methods for lossy pointcloud attribute compression (PCAC) generally focus on reconstructing theoriginal point clouds with minimal error. However, for point cloudvisualization scenarios, the reconstructed point clouds with distortion stillneed to undergo a complex rendering process, which affects the finaluser-perceived quality. In this paper, we propose an end-to-end deep learningframework that seamlessly integrates PCAC with differentiable rendering,denoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality ofrendered multiview images for viewing. In a differentiable manner, the impactof the rendering process on the reconstructed point clouds is taken intoaccount. Moreover, we characterize point clouds as sparse tensors and propose asparse tensor-based transformer, called SP-Trans. By aligning with the localdensity of the point cloud and utilizing an enhanced local attention mechanism,SP-Trans captures the intricate relationships within the point cloud, furtherimproving feature analysis and synthesis within the framework. Extensiveexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-artcompression performance, compared to existing reconstruction-oriented methods,including traditional, learning-based, and hybrid methods.</description><author>Xiao Huo, Junhui Ho, Shuai Wan, Fuzheng Yang</author><pubDate>Tue, 12 Nov 2024 16:12:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07899v1</guid></item><item><title>A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information</title><link>http://arxiv.org/abs/2411.06855v2</link><description>Hate speech, offensive language, aggression, racism, sexism, and otherabusive language are common phenomena in social media. There is a need forArtificial Intelligence(AI)based intervention which can filter hate content atscale. Most existing hate speech detection solutions have utilized the featuresby treating each post as an isolated input instance for the classification.This paper addresses this issue by introducing a unique model that improveshate speech identification for the English language by utilising intra-user andinter-user-based information. The experiment is conducted over single-tasklearning (STL) and multi-task learning (MTL) paradigms that use deep neuralnetworks, such as convolutional neural networks (CNN), gated recurrent unit(GRU), bidirectional encoder representations from the transformer (BERT), and ALite BERT (ALBERT). We use three benchmark datasets and conclude that combiningcertain user features with textual features gives significant improvements inmacro-F1 and weighted-F1.</description><author>Prashant Kapil, Asif Ekbal</author><pubDate>Tue, 12 Nov 2024 16:03:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06855v2</guid></item><item><title>Joint multi-dimensional dynamic attention and transformer for general image restoration</title><link>http://arxiv.org/abs/2411.07893v1</link><description>Outdoor images often suffer from severe degradation due to rain, haze, andnoise, impairing image quality and challenging high-level tasks. Current imagerestoration methods struggle to handle complex degradation while maintainingefficiency. This paper introduces a novel image restoration architecture thatcombines multi-dimensional dynamic attention and self-attention within a U-Netframework. To leverage the global modeling capabilities of transformers and thelocal modeling capabilities of convolutions, we integrate sole CNNs in theencoder-decoder and sole transformers in the latent layer. Additionally, wedesign convolutional kernels with selected multi-dimensional dynamic attentionto capture diverse degraded inputs efficiently. A transformer block withtransposed self-attention further enhances global feature extraction whilemaintaining efficiency. Extensive experiments demonstrate that our methodachieves a better balance between performance and computational complexityacross five image restoration tasks: deraining, deblurring, denoising,dehazing, and enhancement, as well as superior performance for high-levelvision tasks. The source code will be available athttps://github.com/House-yuyu/MDDA-former.</description><author>Huan Zhang, Xu Zhang, Nian Cai, Jianglei Di, Yun Zhang</author><pubDate>Tue, 12 Nov 2024 15:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07893v1</guid></item><item><title>Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly Regularized Convex Sparse Model</title><link>http://arxiv.org/abs/2311.18438v3</link><description>It is well known that the minimum $\ell_2$-norm solution of the convex LASSOmodel, say $\mathbf{x}_{\star}$, is a continuous piecewise linear function ofthe regularization parameter $\lambda$, and its signed sparsity pattern isconstant within each linear piece. The current study is an extension of thisclassic result, proving that the aforementioned properties extend to themin-norm solution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, where$\mathbf{y}$ is the observed signal, for a generalization of LASSO termed thescaled generalized minimax concave (sGMC) model. The sGMC model adopts anonconvex debiased variant of the $\ell_1$-norm as sparse regularizer, but itsobjective function is overall-convex. Based on the geometric properties of$\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we propose an extension of the leastangle regression (LARS) algorithm, which iteratively computes the closed-formexpression of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ in each linear zone.Under suitable conditions, the proposed algorithm provably obtains the wholesolution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ within finite iterations.Notably, our proof techniques for establishing continuity and piecewiselinearity of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ are novel, and they leadto two side contributions: (a) our proofs establish continuity of the sGMCsolution set as a set-valued mapping of $(\mathbf{y},\lambda)$; (b) to provepiecewise linearity and piecewise constant sparsity pattern of$\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we do not require any assumption thatprevious work relies on (whereas to prove some additional properties of$\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we use a different set of assumptionsfrom previous work).</description><author>Yi Zhang, Isao Yamada</author><pubDate>Tue, 12 Nov 2024 15:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18438v3</guid></item><item><title>Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus</title><link>http://arxiv.org/abs/2411.07892v1</link><description>Podcasts provide highly diverse content to a massive listener base through aunique on-demand modality. However, limited data has prevented large-scalecomputational analysis of the podcast ecosystem. To fill this gap, we introducea massive dataset of over 1.1M podcast transcripts that is largelycomprehensive of all English language podcasts available through public RSSfeeds from May and June of 2020. This data is not limited to text, but ratherincludes audio features and speaker turns for a subset of 370K episodes, andspeaker role inferences and other metadata for all 1.1M episodes. Using thisdata, we also conduct a foundational investigation into the content, structure,and responsiveness of this ecosystem. Together, our data and analyses open thedoor to continued computational research of this popular and impactful medium.</description><author>Benjamin Litterer, David Jurgens, Dallas Card</author><pubDate>Tue, 12 Nov 2024 15:56:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07892v1</guid></item><item><title>RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks</title><link>http://arxiv.org/abs/2403.00043v2</link><description>While RNA has recently been recognized as an interesting small-molecule drugtarget, many challenges remain to be addressed before we take full advantage ofit. This emphasizes the necessity to improve our understanding of itsstructures and functions. Over the years, sequencing technologies have producedan enormous amount of unlabeled RNA data, which hides a huge potential.Motivated by the successes of protein language models, we introduce RiboNucleicAcid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is thelargest RNA language model to date, with 650M parameters pre-trained on 36Mnon-coding RNA sequences from several databases. It can extract hiddenknowledge and capture the underlying structure information implicitly embeddedwithin the RNA sequences. RiNALMo achieves state-of-the-art results on severaldownstream tasks. Notably, we show that its generalization capabilitiesovercome the inability of other deep learning methods for secondary structureprediction to generalize on unseen RNA families.</description><author>Rafael Josip Penić, Tin Vlašić, Roland G. Huber, Yue Wan, Mile Šikić</author><pubDate>Tue, 12 Nov 2024 15:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00043v2</guid></item><item><title>A Stochastic Optimization Framework for Private and Fair Learning From Decentralized Data</title><link>http://arxiv.org/abs/2411.07889v1</link><description>Machine learning models are often trained on sensitive data (e.g., medicalrecords and race/gender) that is distributed across different "silos" (e.g.,hospitals). These federated learning models may then be used to makeconsequential decisions, such as allocating healthcare resources. Two keychallenges emerge in this setting: (i) maintaining the privacy of each person'sdata, even if other silos or an adversary with access to the central servertries to infer this data; (ii) ensuring that decisions are fair to differentdemographic groups (e.g., race/gender). In this paper, we develop a novelalgorithm for private and fair federated learning (FL). Our algorithm satisfiesinter-silo record-level differential privacy (ISRL-DP), a strong notion ofprivate FL requiring that silo i's sent messages satisfy record-leveldifferential privacy for all i. Our framework can be used to promote differentfairness notions, including demographic parity and equalized odds. We provethat our algorithm converges under mild smoothness assumptions on the lossfunction, whereas prior work required strong convexity for convergence. As abyproduct of our analysis, we obtain the first convergence guarantee forISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate thestate-of-the-art fairness-accuracy tradeoffs of our algorithm across differentprivacy levels.</description><author>Devansh Gupta, A. S. Poornash, Andrew Lowy, Meisam Razaviyayn</author><pubDate>Tue, 12 Nov 2024 15:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07889v1</guid></item><item><title>INTRABENCH: Interactive Radiological Benchmark</title><link>http://arxiv.org/abs/2411.07885v1</link><description>Current interactive segmentation approaches, inspired by the success ofMETA's Segment Anything model, have achieved notable advancements, however,they come with substantial limitations that hinder their practical applicationin real clinical scenarios. These include unrealistic human interactionrequirements, such as slice-by-slice operations for 2D models on 3D data, alack of iterative refinement, and insufficient evaluation experiments. Theseshortcomings prevent accurate assessment of model performance and lead toinconsistent outcomes across studies. IntRaBench overcomes these challenges byoffering a comprehensive and reproducible framework for evaluating interactivesegmentation methods in realistic, clinically relevant scenarios. It includesdiverse datasets, target structures, and segmentation models, and provides aflexible codebase that allows seamless integration of new models and promptingstrategies. Additionally, we introduce advanced techniques to minimizeclinician interaction, ensuring fair comparisons between 2D and 3D models. Byopen-sourcing IntRaBench, we invite the research community to integrate theirmodels and prompting techniques, ensuring continuous and transparent evaluationof interactive segmentation models in 3D medical imaging.</description><author>Constantin Ulrich, Tassilo Wald, Emily Tempus, Maximilian Rokuss, Paul F. Jaeger, Klaus Maier-Hein</author><pubDate>Tue, 12 Nov 2024 15:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07885v1</guid></item><item><title>Explicit and Implicit Semantic Ranking Framework</title><link>http://arxiv.org/abs/2304.04918v2</link><description>The core challenge in numerous real-world applications is to match an inquiryto the best document from a mutable and finite set of candidates. Existingindustry solutions, especially latency-constrained services, often rely onsimilarity algorithms that sacrifice quality for speed. In this paper weintroduce a generic semantic learning-to-rank framework, Self-training SemanticCross-attention Ranking (sRank). This transformer-based framework uses linearpairwise loss with mutable training batch sizes and achieves quality gains andhigh efficiency, and has been applied effectively to show gains on two industrytasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) andAmbient Clinical Intelligence (ACI). In Smart Reply, sRank assists livecustomers with technical support by selecting the best reply from predefinedsolutions based on consumer and support agent messages. It achieves 11.7% gainin offline top-one accuracy on the SR task over the previous system, and hasenabled 38.7% time reduction in composing messages in telemetry recorded sinceits general release in January 2021. In the ACI task, sRank selects relevanthistorical physician templates that serve as guidance for a text summarizationmodel to generate higher quality medical notes. It achieves 35.5% top-oneaccuracy gain, along with 46% relative ROUGE-L gain in generated medical notes.</description><author>Xiaofeng Zhu, Thomas Lin, Vishal Anand, Matthew Calderwood, Eric Clausen-Brown, Gord Lueck, Wen-wai Yim, Cheng Wu</author><pubDate>Tue, 12 Nov 2024 15:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04918v2</guid></item><item><title>Software Model Evolution with Large Language Models: Experiments on Simulated, Public, and Industrial Datasets</title><link>http://arxiv.org/abs/2406.17651v3</link><description>Modeling structure and behavior of software systems plays a crucial role inthe industrial practice of software engineering. As with other softwareengineering artifacts, software models are subject to evolution. Supportingmodelers in evolving software models with recommendations for model completionsis still an open problem, though. In this paper, we explore the potential oflarge language models for this task. In particular, we propose an approach,RAMC, leveraging large language models, model histories, andretrieval-augmented generation for model completion. Through experiments onthree datasets, including an industrial application, one public open-sourcecommunity dataset, and one controlled collection of simulated modelrepositories, we evaluate the potential of large language models for modelcompletion with RAMC. We found that large language models are indeed apromising technology for supporting software model evolution (62.30%semantically correct completions on real-world industrial data and up to 86.19%type-correct completions). The general inference capabilities of large languagemodels are particularly useful when dealing with concepts for which there arefew, noisy, or no examples at all.</description><author>Christof Tinnes, Alisa Welter, Sven Apel</author><pubDate>Tue, 12 Nov 2024 15:39:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17651v3</guid></item><item><title>An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking</title><link>http://arxiv.org/abs/2411.05508v2</link><description>Recent advances have demonstrated that large language models (LLMs) excel aslistwise rerankers, but their high computational demands remain a barrier towidespread adoption. Further, the traditional language modeling (LM) objectiveis not ideally suited for reranking tasks. FIRST is a novel approach thataddresses these challenges by integrating a learning-to-rank objective andleveraging the logits of only the first generated token, thereby significantlyreducing inference latency compared to traditional LLM rerankers. In thisstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets(DL19-22), validating its robustness across diverse domains. We investigate theinfluence of different first-stage retrievers on FIRST rerankers, observingdiminishing returns and patterns consistent with traditional LLM rerankers.Through applying the FIRST objective to a broader range of backbone models, weachieve effectiveness surpassing the original implementation. Our experimentsconfirm that fast reranking with single-token logits does not compromiseout-of-domain reranking quality. To better quantify the computational savingsin the original study, we measure and compare latency to find a 21%-42% gainacross various models and benchmarks. Moreover, while LM training implicitlyimproves zero-shot single-token reranking, our experiments also raise questionsabout whether LM pre-training may hinder subsequent fine-tuning with the FIRSTobjective. These findings pave the way for more efficient and effectivelistwise reranking in future applications.</description><author>Zijian Chen, Ronak Pradeep, Jimmy Lin</author><pubDate>Tue, 12 Nov 2024 15:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05508v2</guid></item><item><title>Provable Compositional Generalization for Object-Centric Learning</title><link>http://arxiv.org/abs/2310.05327v2</link><description>Learning representations that generalize to novel compositions of knownconcepts is crucial for bridging the gap between human and machine perception.One prominent effort is learning object-centric representations, which arewidely conjectured to enable compositional generalization. Yet, it remainsunclear when this conjecture will be true, as a principled theoretical orempirical understanding of compositional generalization is lacking. In thiswork, we investigate when compositional generalization is guaranteed forobject-centric representations through the lens of identifiability theory. Weshow that autoencoders that satisfy structural assumptions on the decoder andenforce encoder-decoder consistency will learn object-centric representationsthat provably generalize compositionally. We validate our theoretical resultand highlight the practical relevance of our assumptions through experiments onsynthetic image data.</description><author>Thaddäus Wiedemer, Jack Brady, Alexander Panfilov, Attila Juhos, Matthias Bethge, Wieland Brendel</author><pubDate>Tue, 12 Nov 2024 15:34:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05327v2</guid></item><item><title>Convolutional and Deep Learning based techniques for Time Series Ordinal Classification</title><link>http://arxiv.org/abs/2306.10084v3</link><description>Time Series Classification (TSC) covers the supervised learning problem whereinput data is provided in the form of series of values observed throughrepeated measurements over time, and whose objective is to predict the categoryto which they belong. When the class values are ordinal, classifiers that takethis into account can perform better than nominal classifiers. Time SeriesOrdinal Classification (TSOC) is the field covering this gap, yet unexplored inthe literature. There are a wide range of time series problems showing anordered label structure, and TSC techniques that ignore the order relationshipdiscard useful information. Hence, this paper presents a first benchmarking ofTSOC methodologies, exploiting the ordering of the target labels to boost theperformance of current TSC state-of-the-art. Both convolutional- and deeplearning-based methodologies (among the best performing alternatives fornominal TSC) are adapted for TSOC. For the experiments, a selection of 29ordinal problems from two well-known archives has been made. In this way, thispaper contributes to the establishment of the state-of-the-art in TSOC. Theresults obtained by ordinal versions are found to be significantly better thancurrent nominal TSC techniques in terms of ordinal performance metrics,outlining the importance of considering the ordering of the labels when dealingwith this kind of problems.</description><author>Rafael Ayllón-Gavilán, David Guijo-Rubio, Pedro Antonio Gutiérrez, Anthony Bagnall, César Hervás-Martínez</author><pubDate>Tue, 12 Nov 2024 15:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10084v3</guid></item><item><title>Basis-to-Basis Operator Learning Using Function Encoders</title><link>http://arxiv.org/abs/2410.00171v2</link><description>We present Basis-to-Basis (B2B) operator learning, a novel approach forlearning operators on Hilbert spaces of functions based on the foundationalideas of function encoders. We decompose the task of learning operators intotwo parts: learning sets of basis functions for both the input and outputspaces and learning a potentially nonlinear mapping between the coefficients ofthe basis functions. B2B operator learning circumvents many challenges of priorworks, such as requiring data to be at fixed locations, by leveraging classictechniques such as least squares to compute the coefficients. It is especiallypotent for linear operators, where we compute a mapping between bases as asingle matrix transformation with a closed-form solution. Furthermore, withminimal modifications and using the deep theoretical connections betweenfunction encoders and functional analysis, we derive operator learningalgorithms that are directly analogous to eigen-decomposition and singularvalue decomposition. We empirically validate B2B operator learning on sevenbenchmark operator learning tasks and show that it demonstrates atwo-orders-of-magnitude improvement in accuracy over existing approaches onseveral benchmark tasks.</description><author>Tyler Ingebrand, Adam J. Thorpe, Somdatta Goswami, Krishna Kumar, Ufuk Topcu</author><pubDate>Tue, 12 Nov 2024 15:30:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00171v2</guid></item><item><title>Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules</title><link>http://arxiv.org/abs/2411.07873v1</link><description>Humans excel at discovering regular structures from limited samples andapplying inferred rules to novel settings. We investigate whether moderngenerative models can similarly learn underlying rules from finite samples andperform reasoning through conditional sampling. Inspired by Raven's ProgressiveMatrices task, we designed GenRAVEN dataset, where each sample consists ofthree rows, and one of 40 relational rules governing the object position,number, or attributes applies to all rows. We trained generative models tolearn the data distribution, where samples are encoded as integer arrays tofocus on rule learning. We compared two generative model families: diffusion(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated theirability to generate structurally consistent samples and perform panelcompletion via unconditional and conditional sampling. We found diffusionmodels excel at unconditional generation, producing more novel and consistentsamples from scratch and memorizing less, but performing less well in panelcompletion, even with advanced conditional sampling methods. Conversely,autoregressive models excel at completing missing panels in a rule-consistentmanner but generate less consistent samples unconditionally. We observe diversedata scaling behaviors: for both model families, rule learning emerges at acertain dataset size - around 1000s examples per rule. With more training data,diffusion models improve both their unconditional and conditional generationcapabilities. However, for autoregressive models, while panel completionimproves with more training data, unconditional generation consistencydeclines. Our findings highlight complementary capabilities and limitations ofdiffusion and autoregressive models in rule learning and reasoning tasks,suggesting avenues for further research into their mechanisms and potential forhuman-like reasoning.</description><author>Binxu Wang, Jiaqi Shang, Haim Sompolinsky</author><pubDate>Tue, 12 Nov 2024 15:29:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07873v1</guid></item><item><title>Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease</title><link>http://arxiv.org/abs/2411.07871v1</link><description>The rapid advancements in Large Language Models (LLMs) and Vision-LanguageModels (VLMs) have shown great potential in medical diagnostics, particularlyin radiology, where datasets such as X-rays are paired with human-generateddiagnostic reports. However, a significant research gap exists in theneuroimaging field, especially for conditions such as Alzheimer's disease, dueto the lack of comprehensive diagnostic reports that can be utilized for modelfine-tuning. This paper addresses this gap by generating synthetic diagnosticreports using GPT-4o-mini on structured data from the OASIS-4 dataset, whichcomprises 663 patients. Using the synthetic reports as ground truth fortraining and validation, we then generated neurological reports directly fromthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.Our proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,and METEOR score of 0.4163, revealing its potential in generating clinicallyrelevant and accurate diagnostic reports.</description><author>Francesco Chiumento, Mingming Liu</author><pubDate>Tue, 12 Nov 2024 15:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07871v1</guid></item><item><title>Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases and Dual Decoders</title><link>http://arxiv.org/abs/2411.07870v1</link><description>Although people are impressed by the content generation skills of largelanguage models, the use of LLMs, such as ChatGPT, is limited by the domaingrounding of the content. The correctness and groundedness of the generatedcontent need to be based on a verified context, such as results fromRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs toa customized domain is that the generated responses are often incomplete, orthe additions are not verified and may even be hallucinated. Prior studies onhallucination detection have focused on evaluation metrics, which are noteasily adaptable to dynamic domains and can be vulnerable to attacks likejail-breaking. In this work, we propose 1) a post-processing algorithm thatleverages knowledge triplets in RAG context to correct hallucinations and 2) adual-decoder model that fuses RAG context to guide the generation process.</description><author>Xiaofeng Zhu, Jaya Krishna Mandivarapu</author><pubDate>Tue, 12 Nov 2024 15:26:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07870v1</guid></item><item><title>CDXFormer: Boosting Remote Sensing Change Detection with Extended Long Short-Term Memory</title><link>http://arxiv.org/abs/2411.07863v1</link><description>In complex scenes and varied conditions, effectively integratingspatial-temporal context is crucial for accurately identifying changes.However, current RS-CD methods lack a balanced consideration of performance andefficiency. CNNs lack global context, Transformers have quadratic computationalcomplexity, and Mambas are restricted by CUDA acceleration. In this paper, wepropose CDXFormer, with a core component that is a powerful XLSTM-based featureenhancement layer, integrating the advantages of linear computationalcomplexity, global context perception, and strong interpret-ability.Specifically, we introduce a scale-specific Feature Enhancer layer,incorporating a Cross-Temporal Global Perceptron customized forsemantic-accurate deep features, and a Cross-Temporal Spatial Refinercustomized for detail-rich shallow features. Additionally, we propose aCross-Scale Interactive Fusion module to progressively interact global changerepresentations with spatial responses. Extensive experimental resultsdemonstrate that CDXFormer achieves state-of-the-art performance across threebenchmark datasets, offering a compelling balance between efficiency andaccuracy. Code is available at https://github.com/xwmaxwma/rschange.</description><author>Zhenkai Wu, Xiaowen Ma, Rongrong Lian, Zhentao Lin, Wei Zhang</author><pubDate>Tue, 12 Nov 2024 15:22:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07863v1</guid></item><item><title>Integrating Chaotic Evolutionary and Local Search Techniques in Decision Space for Enhanced Evolutionary Multi-Objective Optimization</title><link>http://arxiv.org/abs/2411.07860v1</link><description>This paper presents innovative approaches to optimization problems, focusingon both Single-Objective Multi-Modal Optimization (SOMMOP) and Multi-ObjectiveOptimization (MOO). In SOMMOP, we integrate chaotic evolution with nichingtechniques, as well as Persistence-Based Clustering combined with Gaussianmutation. The proposed algorithms, Chaotic Evolution with DeterministicCrowding (CEDC) and Chaotic Evolution with Clustering Algorithm (CECA), utilizechaotic dynamics to enhance population diversity and improve search efficiency.For MOO, we extend these methods into a comprehensive framework thatincorporates Uncertainty-Based Selection, Adaptive Parameter Tuning, andintroduces a radius \( R \) concept in deterministic crowding, which enablesclearer and more precise separation of populations at peak points. Experimentalresults demonstrate that the proposed algorithms outperform traditionalmethods, achieving superior optimization accuracy and robustness across avariety of benchmark functions.</description><author>Xiang Meng</author><pubDate>Tue, 12 Nov 2024 15:18:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07860v1</guid></item><item><title>Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification</title><link>http://arxiv.org/abs/2410.04492v4</link><description>Vision models excel in image classification but struggle to generalize tounseen data, such as classifying images from unseen domains or discoveringnovel categories. In this paper, we explore the relationship between logicalreasoning and deep learning generalization in visual classification. A logicalregularization termed L-Reg is derived which bridges a logical analysisframework to image classification. Our work reveals that L-Reg reduces thecomplexity of the model in terms of the feature distribution and classifierweights. Specifically, we unveil the interpretability brought by L-Reg, as itenables the model to extract the salient features, such as faces to persons,for classification. Theoretical analysis and experiments demonstrate that L-Regenhances generalization across various scenarios, including multi-domaingeneralization and generalized category discovery. In complex real-worldscenarios where images span unknown classes and unseen domains, L-Regconsistently improves generalization, highlighting its practical efficacy.</description><author>Zhaorui Tan, Xi Yang, Qiufeng Wang, Anh Nguyen, Kaizhu Huang</author><pubDate>Tue, 12 Nov 2024 15:16:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.04492v4</guid></item><item><title>Verbosity $\neq$ Veracity: Demystify Verbosity Compensation Behavior of Large Language Models</title><link>http://arxiv.org/abs/2411.07858v1</link><description>When unsure about an answer, humans often respond with more words thannecessary, hoping that part of the response will be correct. We observe asimilar behavior in large language models (LLMs), which we term "VerbosityCompensation" (VC). VC is harmful because it confuses the user understanding,leading to low efficiency, and influences the LLM services by increasing thelatency and cost of generating useless tokens. In this paper, we present thefirst work that defines and analyzes Verbosity Compensation, explores itscauses, and proposes a simple mitigating approach. We define VerbosityCompensation as the behavior of generating responses that can be compressedwithout information loss when prompted to write concisely. Our experiments,conducted on five datasets of knowledge and reasoning-based QA tasks with 14newly developed LLMs, reveal three conclusions. 1) We reveal a pervasivepresence of verbosity compensation across all models and all datasets. Notably,GPT-4 exhibits a VC frequency of 50.40%. 2) We reveal the large performance gapbetween verbose and concise responses, with a notable difference of 27.61% onthe Qasper dataset. We also demonstrate that this difference does not naturallydiminish as LLM capability increases. Both 1) and 2) highlight the urgent needto mitigate the frequency of VC behavior and disentangle verbosity withveracity. We propose a simple yet effective cascade algorithm that replaces theverbose responses with the other model-generated responses. The results showthat our approach effectively alleviates the VC of the Mistral model from63.81% to 16.16% on the Qasper dataset. 3) We also find that verbose responsesexhibit higher uncertainty across all five datasets, suggesting a strongconnection between verbosity and model uncertainty. Our dataset and code areavailable at https://github.com/psunlpgroup/VerbosityLLM.</description><author>Yusen Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang</author><pubDate>Tue, 12 Nov 2024 15:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07858v1</guid></item><item><title>Pseudo-triplet Guided Few-shot Composed Image Retrieval</title><link>http://arxiv.org/abs/2407.06001v2</link><description>Composed Image Retrieval (CIR) is a challenging task that aims to retrievethe target image with a multimodal query, i.e., a reference image, and itscomplementary modification text. As previous supervised or zero-shot learningparadigms all fail to strike a good trade-off between the model'sgeneralization ability and retrieval performance, recent researchers haveintroduced the task of few-shot CIR (FS-CIR) and proposed a textualinversion-based network based on pretrained CLIP model to realize it. Despiteits promising performance, the approach encounters two key limitations: simplyrelying on the few annotated samples for CIR model training andindiscriminately selecting training triplets for CIR model fine-tuning. Toaddress these two limitations, we propose a novel two-stage pseudo tripletguided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we propose anattentive masking and captioning-based pseudo triplet generation method, toconstruct pseudo triplets from pure image data and use them to fulfill theCIR-task specific pertaining. In the second stage, we propose a challengingtriplet-based CIR fine-tuning method, where we design a pseudo modificationtext-based sample challenging score estimation strategy and a robust toprange-based random sampling strategy for sampling robust challenging tripletsto promote the model fine-tuning. Notably, our scheme is plug-and-play andcompatible with any existing supervised CIR models. We test our scheme acrosstwo backbones on three public datasets (i.e., FashionIQ, CIRR, andBirds-to-Words), achieving maximum improvements of 13.3%, 22.2%, and 17.4%respectively, demonstrating our scheme's efficacy.</description><author>Bohan Hou, Haoqiang Lin, Haokun Wen, Meng Liu, Mingzhu Xu, Xuemeng Song</author><pubDate>Tue, 12 Nov 2024 15:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06001v2</guid></item><item><title>Tucano: Advancing Neural Text Generation for Portuguese</title><link>http://arxiv.org/abs/2411.07854v1</link><description>Significant advances have been made in natural language processing in recentyears. However, our current deep learning approach to language modelingrequires substantial resources in terms of data and computation. One of theside effects of this data-hungry paradigm is the current schism betweenlanguages, separating those considered high-resource, where most of thedevelopment happens and resources are available, and the low-resource ones,which struggle to attain the same level of performance and autonomy. This studyaims to introduce a new set of resources to stimulate the future development ofneural text generation in Portuguese. In this work, we document the developmentof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amountingto 200 billion tokens. Via this corpus, we trained a series ofdecoder-transformers named Tucano. Our models perform equal or superior toother Portuguese and multilingual language models of similar size in severalPortuguese benchmarks. The evaluation of our models also reveals that modelperformance on many currently available benchmarks used by the Portuguese NLPcommunity has little to no correlation with the scaling of token ingestionduring training, highlighting the limitations of such evaluations when it comesto the assessment of Portuguese generative language models. All derivatives ofour study are openly released on GitHub and Hugging Face. Seehttps://nkluge-correa.github.io/Tucano/</description><author>Nicholas Kluge Corrêa, Aniket Sen, Sophia Falk, Shiza Fatimah</author><pubDate>Tue, 12 Nov 2024 15:06:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07854v1</guid></item><item><title>Evidential time-to-event prediction model with well-calibrated uncertainty estimation</title><link>http://arxiv.org/abs/2411.07853v1</link><description>Time-to-event analysis, or Survival analysis, provides valuable insights intoclinical prognosis and treatment recommendations. However, this task istypically more challenging than other regression tasks due to the censoredobservations. Moreover, concerns regarding the reliability of predictionspersist among clinicians, mainly attributed to the absence of confidenceassessment, robustness, and calibration of prediction. To address thosechallenges, we introduce an evidential regression model designed especially fortime-to-event prediction tasks, with which the most plausible event time, isdirectly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). TheGRFNs are a newly introduced family of random fuzzy subsets of the real linethat generalizes both Gaussian random variables and Gaussian possibilitydistributions. Different from conventional methods that construct models basedon strict data distribution, e.g., proportional hazard function, our model onlyassumes the event time is encoded in a real line GFRN without any strictdistribution assumption, therefore offering more flexibility in complex datascenarios. Furthermore, the epistemic and aleatory uncertainty regarding theevent time is quantified within the aggregated GRFN as well. Our model can,therefore, provide more detailed clinical decision-making guidance with twomore degrees of information. The model is fit by minimizing a generalizednegative log-likelihood function that accounts for data censoring based onuncertainty evidence reasoning. Experimental results on simulated datasets withvarying data distributions and censoring scenarios, as well as on real-worlddatasets across diverse clinical settings and tasks, demonstrate that our modelachieves both accurate and reliable performance, outperforming state-of-the-artmethods.</description><author>Ling Huang, Yucheng Xing, Swapnil Mishra, Thierry Denoeux, Mengling Feng</author><pubDate>Tue, 12 Nov 2024 15:06:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07853v1</guid></item><item><title>A Manifold Perspective on the Statistical Generalization of Graph Neural Networks</title><link>http://arxiv.org/abs/2406.05225v5</link><description>Graph Neural Networks (GNNs) extend convolutional neural networks to operateon graphs. Despite their impressive performances in various graph learningtasks, the theoretical understanding of their generalization capability isstill lacking. Previous GNN generalization bounds ignore the underlying graphstructures, often leading to bounds that increase with the number of nodes -- abehavior contrary to the one experienced in practice. In this paper, we take amanifold perspective to establish the statistical generalization theory of GNNson graphs sampled from a manifold in the spectral domain. As demonstratedempirically, we prove that the generalization bounds of GNNs decrease linearlywith the size of the graphs in the logarithmic scale, and increase linearlywith the spectral continuity constants of the filter functions. Notably, ourtheory explains both node-level and graph-level tasks. Our result has twoimplications: i) guaranteeing the generalization of GNNs to unseen data overmanifolds; ii) providing insights into the practical design of GNNs, i.e.,restrictions on the discriminability of GNNs are necessary to obtain a bettergeneralization performance. We demonstrate our generalization bounds of GNNsusing synthetic and multiple real-world datasets.</description><author>Zhiyang Wang, Juan Cervino, Alejandro Ribeiro</author><pubDate>Tue, 12 Nov 2024 15:05:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05225v5</guid></item><item><title>Dynamic planning in hierarchical active inference</title><link>http://arxiv.org/abs/2402.11658v3</link><description>By dynamic planning, we refer to the ability of the human brain to infer andimpose motor trajectories related to cognitive decisions. A recent paradigm,active inference, brings fundamental insights into the adaptation of biologicalorganisms, constantly striving to minimize prediction errors to restrictthemselves to life-compatible states. Over the past years, many studies haveshown how human and animal behaviors could be explained in terms of activeinference - either as discrete decision-making or continuous motor control -inspiring innovative solutions in robotics and artificial intelligence. Still,the literature lacks a comprehensive outlook on effectively planning realisticactions in changing environments. Setting ourselves the goal of modelingcomplex tasks such as tool use, we delve into the topic of dynamic planning inactive inference, keeping in mind two crucial aspects of biological behavior:the capacity to understand and exploit affordances for object manipulation, andto learn the hierarchical interactions between the self and the environment,including other agents. We start from a simple unit and gradually describe moreadvanced structures, comparing recently proposed design choices and providingbasic examples. This study distances itself from traditional views centered onneural networks and reinforcement learning, and points toward a yet unexploreddirection in active inference: hybrid representations in hierarchical models.</description><author>Matteo Priorelli, Ivilin Peev Stoianov</author><pubDate>Tue, 12 Nov 2024 15:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11658v3</guid></item><item><title>IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems</title><link>http://arxiv.org/abs/2411.07850v1</link><description>Adversarial examples, which are inputs deliberately perturbed withimperceptible changes to induce model errors, have raised serious concerns forthe reliability and security of deep neural networks (DNNs). While adversarialattacks have been extensively studied in continuous data domains such asimages, the discrete nature of text presents unique challenges. In this paper,we propose Irony-based Adversarial Examples (IAE), a method that transformsstraightforward sentences into ironic ones to create adversarial text. Thisapproach exploits the rhetorical device of irony, where the intended meaning isopposite to the literal interpretation, requiring a deeper understanding ofcontext to detect. The IAE method is particularly challenging due to the needto accurately locate evaluation words, substitute them with appropriatecollocations, and expand the text with suitable ironic elements whilemaintaining semantic coherence. Our research makes the following keycontributions: (1) We introduce IAE, a strategy for generating textualadversarial examples using irony. This method does not rely on pre-existingirony corpora, making it a versatile tool for creating adversarial text invarious NLP tasks. (2) We demonstrate that the performance of severalstate-of-the-art deep learning models on sentiment analysis tasks significantlydeteriorates when subjected to IAE attacks. This finding underscores thesusceptibility of current NLP systems to adversarial manipulation throughirony. (3) We compare the impact of IAE on human judgment versus NLP systems,revealing that humans are less susceptible to the effects of irony in text.</description><author>Xiaoyin Yi, Jiacheng Huang</author><pubDate>Tue, 12 Nov 2024 15:01:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07850v1</guid></item><item><title>NL-SLAM for OC-VLN: Natural Language Grounded SLAM for Object-Centric VLN</title><link>http://arxiv.org/abs/2411.07848v1</link><description>Landmark-based navigation (e.g. go to the wooden desk) and relativepositional navigation (e.g. move 5 meters forward) are distinct navigationchallenges solved very differently in existing robotics navigation methodology.We present a new dataset, OC-VLN, in order to distinctly evaluate groundingobject-centric natural language navigation instructions in a method forperforming landmark-based navigation. We also propose Natural Language groundedSLAM (NL-SLAM), a method to ground natural language instruction to robotobservations and poses. We actively perform NL-SLAM in order to followobject-centric natural language navigation instructions. Our methods leveragepre-trained vision and language foundation models and require no task-specifictraining. We construct two strong baselines from state-of-the-art methods onrelated tasks, Object Goal Navigation and Vision Language Navigation, and weshow that our approach, NL-SLAM, outperforms these baselines across all ourmetrics of success on OC-VLN. Finally, we successfully demonstrate theeffectiveness of NL-SLAM for performing navigation instruction following in thereal world on a Boston Dynamics Spot robot.</description><author>Sonia Raychaudhuri, Duy Ta, Katrina Ashton, Angel X. Chang, Jiuguang Wang, Bernadette Bucher</author><pubDate>Tue, 12 Nov 2024 15:01:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07848v1</guid></item><item><title>Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight</title><link>http://arxiv.org/abs/2403.12203v3</link><description>Learning visuomotor policies for agile quadrotor flight presents significantdifficulties, primarily from inefficient policy exploration caused byhigh-dimensional visual inputs and the need for precise and low-latencycontrol. To address these challenges, we propose a novel approach that combinesthe performance of Reinforcement Learning (RL) and the sample efficiency ofImitation Learning (IL) in the task of vision-based autonomous drone racing.While RL provides a framework for learning high-performance controllers throughtrial and error, it faces challenges with sample efficiency and computationaldemands due to the high dimensionality of visual inputs. Conversely, ILefficiently learns from visual expert demonstrations, but it remains limited bythe expert's performance and state distribution. To overcome these limitations,our policy learning framework integrates the strengths of both approaches. Ourframework contains three phases: training a teacher policy using RL withprivileged state information, distilling it into a student policy via IL, andadaptive fine-tuning via RL. Testing in both simulated and real-world scenariosshows our approach can not only learn in scenarios where RL from scratch failsbut also outperforms existing IL methods in both robustness and performance,successfully navigating a quadrotor through a race course using only visualinformation. Videos of the experiments are available athttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.</description><author>Jiaxu Xing, Angel Romero, Leonard Bauersfeld, Davide Scaramuzza</author><pubDate>Tue, 12 Nov 2024 15:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12203v3</guid></item><item><title>Bandits with Abstention under Expert Advice</title><link>http://arxiv.org/abs/2402.14585v2</link><description>We study the classic problem of prediction with expert advice under banditfeedback. Our model assumes that one action, corresponding to the learner'sabstention from play, has no reward or loss on every trial. We propose the CBAalgorithm, which exploits this assumption to obtain reward bounds that cansignificantly improve those of the classical Exp4 algorithm. We can view ourproblem as the aggregation of confidence-rated predictors when the learner hasthe option of abstention from play. Importantly, we are the first to achievebounds on the expected cumulative reward for general confidence-ratedpredictors. In the special case of specialists we achieve a novel reward bound,significantly improving previous bounds of SpecialistExp (treating abstentionas another action). As an example application, we discuss learning unions ofballs in a finite metric space. In this contextual setting, we devise anefficient implementation of CBA, reducing the runtime from quadratic to almostlinear in the number of contexts. Preliminary experiments show that CBAimproves over existing bandit algorithms.</description><author>Stephen Pasteris, Alberto Rumi, Maximilian Thiessen, Shota Saito, Atsushi Miyauchi, Fabio Vitale, Mark Herbster</author><pubDate>Tue, 12 Nov 2024 14:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14585v2</guid></item><item><title>REVEX: A Unified Framework for Removal-Based Explainable Artificial Intelligence in Video</title><link>http://arxiv.org/abs/2401.11796v2</link><description>We developed REVEX, a removal-based video explanations framework. This workextends fine-grained explanation frameworks for computer vision data and adaptssix existing techniques to video by adding temporal information and localexplanations. The adapted methods were evaluated across networks, datasets,image classes, and evaluation metrics. By decomposing explanation into steps,strengths and weaknesses were revealed in the studied methods, for example, onpixel clustering and perturbations in the input. Video LIME outperformed othermethods with deletion values up to 31\% lower and insertion up to 30\% higher,depending on method and network. Video RISE achieved superior performance inthe average drop metric, with values 10\% lower. In contrast,localization-based metrics revealed low performance across all methods, withsignificant variation depending on network. Pointing game accuracy reached53\%, and IoU-based metrics remained below 20\%. Drawing on the findings acrossXAI methods, we further examine the limitations of the employed XAI evaluationmetrics and highlight their suitability in different applications.</description><author>F. Xavier Gaya-Morey, Jose M. Buades-Rubio, I. Scott MacKenzie, Cristina Manresa-Yee</author><pubDate>Tue, 12 Nov 2024 14:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11796v2</guid></item><item><title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title><link>http://arxiv.org/abs/2410.14803v3</link><description>On-device control agents, especially on mobile devices, are responsible foroperating mobile devices to fulfill users' requests, enabling seamless andintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)into these agents enhances their ability to understand and execute complexcommands, thereby improving user experience. However, fine-tuning MLLMs foron-device control presents significant challenges due to limited dataavailability and inefficient online training processes. This paper introducesDistRL, a novel framework designed to enhance the efficiency of online RLfine-tuning for mobile device control agents. DistRL employs centralizedtraining and decentralized data acquisition to ensure efficient fine-tuning inthe context of dynamic online interactions. Additionally, the framework isbacked by our tailor-made RL algorithm, which effectively balances explorationwith the prioritized utilization of collected data to ensure stable and robusttraining. Our experiments show that, on average, DistRL delivers a 3Ximprovement in training efficiency and enables training data collection 2.4Xfaster than the leading synchronous multi-machine methods. Notably, aftertraining, DistRL achieves a 20% relative improvement in success rate comparedto state-of-the-art methods on general Android tasks from an open benchmark,significantly outperforming existing approaches while maintaining the sametraining time. These results validate DistRL as a scalable and efficientsolution, offering substantial improvements in both training efficiency andagent performance for real-world, in-the-wild device control tasks.</description><author>Taiyi Wang, Zhihao Wu, Jianheng Liu, Jianye Hao, Jun Wang, Kun Shao</author><pubDate>Tue, 12 Nov 2024 14:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14803v3</guid></item><item><title>Transfer Learning for Wildlife Classification: Evaluating YOLOv8 against DenseNet, ResNet, and VGGNet on a Custom Dataset</title><link>http://arxiv.org/abs/2408.00002v2</link><description>This study evaluates the performance of various deep learning models,specifically DenseNet, ResNet, VGGNet, and YOLOv8, for wildlife speciesclassification on a custom dataset. The dataset comprises 575 images of 23endangered species sourced from reputable online repositories. The studyutilizes transfer learning to fine-tune pre-trained models on the dataset,focusing on reducing training time and enhancing classification accuracy. Theresults demonstrate that YOLOv8 outperforms other models, achieving a trainingaccuracy of 97.39% and a validation F1-score of 96.50%. These findings suggestthat YOLOv8, with its advanced architecture and efficient feature extractioncapabilities, holds great promise for automating wildlife monitoring andconservation efforts.</description><author>Subek Sharma, Sisir Dhakal, Mansi Bhavsar</author><pubDate>Tue, 12 Nov 2024 14:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00002v2</guid></item><item><title>Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements</title><link>http://arxiv.org/abs/2411.07845v1</link><description>What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,a corpus of 1,580 ethical concern statements extracted from scientific paperspublished in the ACL Anthology. We extract ethical concern keywords from thestatements and show promising results in automating the concern identificationprocess. Through a survey, we compare the ethical concerns of the corpus to theconcerns listed by the general public and professionals in the field. Finally,we compare our retrieved ethical concerns with existing taxonomies pointing togaps and future research directions.</description><author>Antonia Karamolegkou, Sandrine Schiller Hansen, Ariadni Christopoulou, Filippos Stamatiou, Anne Lauscher, Anders Søgaard</author><pubDate>Tue, 12 Nov 2024 14:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07845v1</guid></item><item><title>Chain Association-based Attacking and Shielding Natural Language Processing Systems</title><link>http://arxiv.org/abs/2411.07843v1</link><description>Association as a gift enables people do not have to mention something incompletely straightforward words and allows others to understand what theyintend to refer to. In this paper, we propose a chain association-basedadversarial attack against natural language processing systems, utilizing thecomprehension gap between humans and machines. We first generate a chainassociation graph for Chinese characters based on the association paradigm forbuilding search space of potential adversarial examples. Then, we introduce andiscrete particle swarm optimization algorithm to search for the optimaladversarial examples. We conduct comprehensive experiments and show thatadvanced natural language processing models and applications, including largelanguage models, are vulnerable to our attack, while humans appear good atunderstanding the perturbed text. We also explore two methods, includingadversarial training and associative graph-based recovery, to shield systemsfrom chain association-based attack. Since a few examples that use somederogatory terms, this paper contains materials that may be offensive orupsetting to some people.</description><author>Jiacheng Huang, Long Chen</author><pubDate>Tue, 12 Nov 2024 14:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07843v1</guid></item><item><title>Federated Learning for Discrete Optimal Transport with Large Population under Incomplete Information</title><link>http://arxiv.org/abs/2411.07841v1</link><description>Optimal transport is a powerful framework for the efficient allocation ofresources between sources and targets. However, traditional models oftenstruggle to scale effectively in the presence of large and heterogeneouspopulations. In this work, we introduce a discrete optimal transport frameworkdesigned to handle large-scale, heterogeneous target populations, characterizedby type distributions. We address two scenarios: one where the typedistribution of targets is known, and one where it is unknown. For the knowndistribution, we propose a fully distributed algorithm to achieve optimalresource allocation. In the case of unknown distribution, we develop afederated learning-based approach that enables efficient computation of theoptimal transport scheme while preserving privacy. Case studies are provided toevaluate the performance of our learning algorithm.</description><author>Navpreet Kaur, Juntao Chen, Yingdong Lu</author><pubDate>Tue, 12 Nov 2024 14:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07841v1</guid></item><item><title>LLMs Can Evolve Continually on Modality for X-Modal Reasoning</title><link>http://arxiv.org/abs/2410.20178v2</link><description>Multimodal Large Language Models (MLLMs) have gained significant attentiondue to their impressive capabilities in multimodal understanding. However,existing methods rely heavily on extensive modal-specific pretraining andjoint-modal tuning, leading to significant computational burdens when expandingto new modalities. In this paper, we propose PathWeave, a flexible and scalableframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMsto continually EVolve on modalities for $\mathbb{X}$-modal reasoning. Weleverage the concept of Continual Learning and develop an incremental trainingstrategy atop pre-trained MLLMs, enabling their expansion to new modalitiesusing uni-modal data, without executing joint-modal pretraining. In detail, anovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal andcross-modal adapters are seamlessly integrated to facilitate efficient modalityalignment and collaboration. Additionally, an MoE-based gating module isapplied between two types of adapters to further enhance the multimodalinteraction. To investigate the proposed method, we establish a challengingbenchmark called Continual Learning of Modality (MCL), which consists ofhigh-quality QA data from five distinct modalities: image, video, audio, depthand point cloud. Extensive experiments demonstrate the effectiveness of theproposed AnA framework on learning plasticity and memory stability duringcontinual learning. Furthermore, PathWeave performs comparably tostate-of-the-art MLLMs while concurrently reducing parameter training burdensby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave</description><author>Jiazuo Yu, Haomiao Xiong, Lu Zhang, Haiwen Diao, Yunzhi Zhuge, Lanqing Hong, Dong Wang, Huchuan Lu, You He, Long Chen</author><pubDate>Tue, 12 Nov 2024 14:45:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20178v2</guid></item><item><title>FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training</title><link>http://arxiv.org/abs/2411.07837v1</link><description>With the increase in the number of parameters in large language models, theprocess of pre-training and fine-tuning increasingly demands larger volumes ofGPU memory. A significant portion of this memory is typically consumed by theoptimizer state. To overcome this challenge, recent approaches such as low-rankadaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhaoet al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have beenproposed. However, in all these algorithms, the $\textit{effective rank of theweight updates remains low-rank}$, which can lead to a substantial loss ofinformation from the gradient. This loss can be critically important,especially during the pre-training stage. In this paper, we introduce$\texttt{FRUGAL}$ ($\textbf{F}$ull-$\textbf{R}$ank $\textbf{U}$pdates with$\textbf{G}$r$\textbf{A}$dient sp$\textbf{L}$itting), a new memory-efficientoptimization framework. $\texttt{FRUGAL}$ leverages gradient splitting toperform low-dimensional updates using advanced algorithms (such as Adam), whileupdates along the remaining directions are executed via state-free methods likeSGD or signSGD (Bernstein et al., 2018). Our framework can be integrated withvarious low-rank update selection techniques, including GaLore and BAdam. Weprovide theoretical convergence guarantees for our framework when using SGDMfor low-dimensional updates and SGD for state-free updates. Additionally, ourmethod consistently outperforms concurrent approaches across various fixedmemory budgets, achieving state-of-the-art results in pre-training andfine-tuning tasks while balancing memory efficiency and performance metrics.</description><author>Philip Zmushko, Aleksandr Beznosikov, Martin Takáč, Samuel Horváth</author><pubDate>Tue, 12 Nov 2024 14:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07837v1</guid></item><item><title>UniTE: A Survey and Unified Pipeline for Pre-training Spatiotemporal Trajectory Embeddings</title><link>http://arxiv.org/abs/2407.12550v2</link><description>Spatiotemporal trajectories are sequences of timestamped locations, whichenable a variety of analyses that in turn enable important real-worldapplications. It is common to map trajectories to vectors, called embeddings,before subsequent analyses. Thus, the qualities of embeddings are veryimportant. Methods for pre-training embeddings, which leverage unlabeledtrajectories for training universal embeddings, have shown promisingapplicability across different tasks, thus attracting considerable interest.However, research progress on this topic faces two key challenges: a lack of acomprehensive overview of existing methods, resulting in several relatedmethods not being well-recognized, and the absence of a unified pipeline,complicating the development of new methods and the analysis of methods. We present UniTE, a survey and a unified pipeline for this domain. In doingso, we present a comprehensive list of existing methods for pre-trainingtrajectory embeddings, which includes methods that either explicitly orimplicitly employ pre-training techniques. Further, we present a unified andmodular pipeline with publicly available underlying code, simplifying theprocess of constructing and evaluating methods for pre-training trajectoryembeddings. Additionally, we contribute a selection of experimental resultsusing the proposed pipeline on real-world datasets. Implementation of thepipeline is publicly available at https://github.com/Logan-Lin/UniTE.</description><author>Yan Lin, Zeyu Zhou, Yicheng Liu, Haochen Lv, Haomin Wen, Tianyi Li, Yushuai Li, Christian S. Jensen, Shengnan Guo, Youfang Lin, Huaiyu Wan</author><pubDate>Tue, 12 Nov 2024 14:39:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12550v2</guid></item><item><title>Towards Vision Mixture of Experts for Wildlife Monitoring on the Edge</title><link>http://arxiv.org/abs/2411.07834v1</link><description>The explosion of IoT sensors in industrial, consumer and remote sensing usecases has come with unprecedented demand for computing infrastructure totransmit and to analyze petabytes of data. Concurrently, the world is slowlyshifting its focus towards more sustainable computing. For these reasons, therehas been a recent effort to reduce the footprint of related computinginfrastructure, especially by deep learning algorithms, for advanced insightgeneration. The `TinyML' community is actively proposing methods to savecommunication bandwidth and excessive cloud storage costs while reducingalgorithm inference latency and promoting data privacy. Such proposedapproaches should ideally process multiple types of data, including timeseries, audio, satellite images, and video, near the network edge as multipledata streams has been shown to improve the discriminative ability of learningalgorithms, especially for generating fine grained results. Incidentally, therehas been recent work on data driven conditional computation of subnetworks thathas shown real progress in using a single model to share parameters among verydifferent types of inputs such as images and text, reducing the computationrequirement of multi-tower multimodal networks. Inspired by such line of work,we explore similar per patch conditional computation for the first time formobile vision transformers (vision only case), that will eventually be used forsingle-tower multimodal edge models. We evaluate the model on Cornell SapSucker Woods 60, a fine grained bird species discrimination dataset. Ourinitial experiments uses $4X$ fewer parameters compared to MobileViTV2-1.0 witha $1$% accuracy drop on the iNaturalist '21 birds test data provided as part ofthe SSW60 dataset.</description><author>Emmanuel Azuh Mensah, Anderson Lee, Haoran Zhang, Yitong Shan, Kurtis Heimerl</author><pubDate>Tue, 12 Nov 2024 14:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07834v1</guid></item><item><title>L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection</title><link>http://arxiv.org/abs/2408.03677v4</link><description>LiDAR-based vision systems are integral for 3D object detection, which iscrucial for autonomous navigation. However, they suffer from performancedegradation in adverse weather conditions due to the quality deterioration ofLiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor isexpected to solve this problem. However, the fusion of LiDAR and 4D radar ischallenging because they differ significantly in terms of data quality and thedegree of degradation in adverse weather. To address these issues, we introduceL4DR, a weather-robust 3D object detection method that effectively achievesLiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) andForeground-Aware Denoising (FAD) technique to reconcile sensor gaps, which isthe first exploration of the complementarity of early fusion between LiDAR and4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 )parallel feature extraction backbone coupled with a Multi-Scale Gated Fusion(MSGF) module to counteract the varying degrees of sensor degradation underadverse weather conditions. Experimental evaluation on a VoD dataset withsimulated fog proves that L4DR is more adaptable to changing weatherconditions. It delivers a significant performance increase under different foglevels, improving the 3D mAP by up to 20.0% over the traditional LiDAR-onlyapproach. Moreover, the results on the K-Radar dataset validate the consistentperformance improvement of L4DR in real-world adverse weather conditions.</description><author>Xun Huang, Ziyu Xu, Hai Wu, Jinlong Wang, Qiming Xia, Yan Xia, Jonathan Li, Kyle Gao, Chenglu Wen, Cheng Wang</author><pubDate>Tue, 12 Nov 2024 14:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03677v4</guid></item><item><title>The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses</title><link>http://arxiv.org/abs/2411.06008v2</link><description>This study explores how the Large Language Models (LLMs) adjust linguisticfeatures to create personalized persuasive outputs. While research showed thatLLMs personalize outputs, a gap remains in understanding the linguisticfeatures of their persuasive capabilities. We identified 13 linguistic featurescrucial for influencing personalities across different levels of the Big Fivemodel of personality. We analyzed how prompts with personality traitinformation influenced the output of 19 LLMs across five model families. Thefindings show that models use more anxiety-related words for neuroticism,increase achievement-related words for conscientiousness, and employ fewercognitive processes words for openness to experience. Some model families excelat adapting language for openness to experience, others for conscientiousness,while only one model adapts language for neuroticism. Our findings show howLLMs tailor responses based on personality cues in prompts, indicating theirpotential to create persuasive content affecting the mind and well-being of therecipients.</description><author>Wiktoria Mieleszczenko-Kowszewicz, Dawid Płudowski, Filip Kołodziejczyk, Jakub Świstak, Julian Sienkiewicz, Przemysław Biecek</author><pubDate>Tue, 12 Nov 2024 14:30:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06008v2</guid></item><item><title>Adapting Segment Anything Model to Multi-modal Salient Object Detection with Semantic Feature Fusion Guidance</title><link>http://arxiv.org/abs/2408.15063v4</link><description>Although most existing multi-modal salient object detection (SOD) methodsdemonstrate effectiveness through training models from scratch, the limitedmulti-modal data hinders these methods from reaching optimality. In this paper,we propose a novel framework to explore and exploit the powerful featurerepresentation and zero-shot generalization ability of the pre-trained SegmentAnything Model (SAM) for multi-modal SOD. Despite serving as a recent visionfundamental model, driving the class-agnostic SAM to comprehend and detectsalient objects accurately is non-trivial, especially in challenging scenes. Tothis end, we develop \underline{SAM} with se\underline{m}anticf\underline{e}ature fu\underline{s}ion guidanc\underline{e} (Sammese), whichincorporates multi-modal saliency-specific knowledge into SAM to adapt SAM tomulti-modal SOD tasks. However, it is difficult for SAM trained on single-modaldata to directly mine the complementary benefits of multi-modal inputs andcomprehensively utilize them to achieve accurate saliency prediction. Toaddress these issues, we first design a multi-modal complementary fusion moduleto extract robust multi-modal semantic features by integrating information fromvisible and thermal or depth image pairs. Then, we feed the extractedmulti-modal semantic features into both the SAM image encoder and mask decoderfor fine-tuning and prompting, respectively. Specifically, in the imageencoder, a multi-modal adapter is proposed to adapt the single-modal SAM tomulti-modal information. In the mask decoder, a semantic-geometric promptgeneration strategy is proposed to produce corresponding embeddings withvarious saliency cues. Extensive experiments on both RGB-D and RGB-T SODbenchmarks show the effectiveness of the proposed framework. The code will beavailable at \url{https://github.com/Angknpng/Sammese}.</description><author>Kunpeng Wang, Danying Lin, Chenglong Li, Zhengzheng Tu, Bin Luo</author><pubDate>Tue, 12 Nov 2024 14:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15063v4</guid></item><item><title>Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of Factored-POMDPs</title><link>http://arxiv.org/abs/2411.07832v1</link><description>Learning representations of underlying environmental dynamics from partialobservations is a critical challenge in machine learning. In the context ofPartially Observable Markov Decision Processes (POMDPs), state representationsare often inferred from the history of past observations and actions. Wedemonstrate that incorporating future information is essential to accuratelycapture causal dynamics and enhance state representations. To address this, weintroduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causalMarkovian dynamics from offline trajectories in a POMDP. Our method employs anextended hindsight framework that integrates past, current, and multi-stepfuture information within a factored-POMDP setting. Empirical results revealthat this approach uncovers the causal graph governing hidden state transitionsmore effectively than history-based and typical hindsight-based models.</description><author>Chao Han, Debabrota Basu, Michael Mangan, Eleni Vasilaki, Aditya Gilra</author><pubDate>Tue, 12 Nov 2024 14:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07832v1</guid></item><item><title>Suite-IN: Aggregating Motion Features from Apple Suite for Robust Inertial Navigation</title><link>http://arxiv.org/abs/2411.07828v1</link><description>With the rapid development of wearable technology, devices like smartphones,smartwatches, and headphones equipped with IMUs have become essential forapplications such as pedestrian positioning. However, traditional pedestriandead reckoning (PDR) methods struggle with diverse motion patterns, whilerecent data-driven approaches, though improving accuracy, often lack robustnessdue to reliance on a single device.In our work, we attempt to enhance thepositioning performance using the low-cost commodity IMUs embedded in thewearable devices. We propose a multi-device deep learning framework namedSuite-IN, aggregating motion data from Apple Suite for inertial navigation.Motion data captured by sensors on different body parts contains both local andglobal motion information, making it essential to reduce the negative effectsof localized movements and extract global motion representations from multipledevices.</description><author>Lan Sun, Songpengcheng Xia, Junyuan Deng, Jiarui Yang, Zengyuan Lai, Qi Wu, Ling Pei</author><pubDate>Tue, 12 Nov 2024 14:23:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07828v1</guid></item></channel></rss>