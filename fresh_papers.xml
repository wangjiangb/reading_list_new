<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 02 Nov 2025 17:14:57 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark</title><link>http://arxiv.org/abs/2510.26802v1</link><description>Recent video generation models can produce high-fidelity, temporally coherentvideos, indicating that they may encode substantial world knowledge. Beyondrealistic synthesis, they also exhibit emerging behaviors indicative of visualperception, modeling, and manipulation. Yet, an important question stillremains: Are video models ready to serve as zero-shot reasoners in challengingvisual reasoning scenarios? In this work, we conduct an empirical study tocomprehensively investigate this question, focusing on the leading and popularVeo-3. We evaluate its reasoning behavior across 12 dimensions, includingspatial, geometric, physical, temporal, and embodied logic, systematicallycharacterizing both its strengths and failure modes. To standardize this study,we curate the evaluation data into MME-CoF, a compact benchmark that enablesin-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Ourfindings reveal that while current video models demonstrate promising reasoningpatterns on short-horizon spatial coherence, fine-grained grounding, andlocally consistent dynamics, they remain limited in long-horizon causalreasoning, strict geometric constraints, and abstract logic. Overall, they arenot yet reliable as standalone zero-shot reasoners, but exhibit encouragingsigns as complementary visual engines alongside dedicated reasoning models.Project page: https://video-cof.github.io</description><author>Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng</author><pubDate>Thu, 30 Oct 2025 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26802v1</guid></item><item><title>OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes</title><link>http://arxiv.org/abs/2510.26800v1</link><description>There are two prevalent ways to constructing 3D scenes: procedural generationand 2D lifting. Among them, panorama-based 2D lifting has emerged as apromising technique, leveraging powerful 2D generative priors to produceimmersive, realistic, and diverse 3D environments. In this work, we advancethis technique to generate graphics-ready 3D scenes suitable for physicallybased rendering (PBR), relighting, and simulation. Our key insight is torepurpose 2D generative models for panoramic perception of geometry, textures,and PBR materials. Unlike existing 2D lifting approaches that emphasizeappearance generation and ignore the perception of intrinsic properties, wepresent OmniX, a versatile and unified framework. Based on a lightweight andefficient cross-modal adapter structure, OmniX reuses 2D generative priors fora broad range of panoramic vision tasks, including panoramic perception,generation, and completion. Furthermore, we construct a large-scale syntheticpanorama dataset containing high-quality multimodal panoramas from diverseindoor and outdoor scenes. Extensive experiments demonstrate the effectivenessof our model in panoramic visual perception and graphics-ready 3D scenegeneration, opening new possibilities for immersive and physically realisticvirtual world generation.</description><author>Yukun Huang, Jiwen Yu, Yanning Zhou, Jianan Wang, Xintao Wang, Pengfei Wan, Xihui Liu</author><pubDate>Thu, 30 Oct 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26800v1</guid></item><item><title>UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection</title><link>http://arxiv.org/abs/2506.03237v2</link><description>The detection of ligand binding sites for proteins is a fundamental step inStructure-Based Drug Design. Despite notable advances in recent years, existingmethods, datasets, and evaluation metrics are confronted with several keychallenges: (1) current datasets and methods are centered on individualprotein-ligand complexes and neglect that diverse binding sites may existacross multiple complexes of the same protein, introducing significantstatistical bias; (2) ligand binding site detection is typically modeled as adiscontinuous workflow, employing binary segmentation and subsequent clusteringalgorithms; (3) traditional evaluation metrics do not adequately reflect theactual performance of different binding site prediction methods. To addressthese issues, we first introduce UniSite-DS, the first UniProt (UniqueProtein)-centric ligand binding site dataset, which contains 4.81 times moremulti-site data and 2.08 times more overall data compared to the previouslymost widely used datasets. We then propose UniSite, the first end-to-end ligandbinding site detection framework supervised by set prediction loss withbijective matching. In addition, we introduce Average Precision based onIntersection over Union (IoU) as a more accurate evaluation metric for ligandbinding site prediction. Extensive experiments on UniSite-DS and severalrepresentative benchmark datasets demonstrate that IoU-based Average Precisionprovides a more accurate reflection of prediction quality, and that UniSiteoutperforms current state-of-the-art methods in ligand binding site detection.The dataset and codes will be made publicly available athttps://github.com/quanlin-wu/unisite.</description><author>Jigang Fan, Quanlin Wu, Shengjie Luo, Liwei Wang</author><pubDate>Thu, 30 Oct 2025 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.03237v2</guid></item><item><title>Masked Diffusion Captioning for Visual Feature Learning</title><link>http://arxiv.org/abs/2510.26799v1</link><description>We learn visual features by captioning images with an image-conditionedmasked diffusion language model, a formulation we call masked diffusioncaptioning (MDC). During training, text tokens in each image-caption pair aremasked at a randomly chosen ratio, and a decoder conditioned on visual featuresis trained to reconstruct the original text. After training, the learned visualfeatures can be applied to downstream vision tasks. Unlike autoregressivecaptioning, the strength of the visual learning signal in MDC does not dependon each token's position in the sequence, reducing the need for auxiliaryobjectives. Linear probing experiments across a variety of academic-scalemodels and datasets show that the learned visual features are competitive withthose produced by autoregressive and contrastive approaches.</description><author>Chao Feng, Zihao Wei, Andrew Owens</author><pubDate>Thu, 30 Oct 2025 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26799v1</guid></item><item><title>SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting</title><link>http://arxiv.org/abs/2510.26796v1</link><description>Immersive applications call for synthesizing spatiotemporal 4D content fromcasual videos without costly 3D supervision. Existing video-to-4D methodstypically rely on manually annotated camera poses, which are labor-intensiveand brittle for in-the-wild footage. Recent warp-then-inpaint approachesmitigate the need for pose labels by warping input frames along a novel cameratrajectory and using an inpainting model to fill missing regions, therebydepicting the 4D scene from diverse viewpoints. However, thistrajectory-to-trajectory formulation often entangles camera motion with scenedynamics and complicates both modeling and inference. We introduce SEE4D, apose-free, trajectory-to-camera framework that replaces explicit trajectoryprediction with rendering to a bank of fixed virtual cameras, therebyseparating camera control from scene modeling. A view-conditional videoinpainting model is trained to learn a robust geometry prior by denoisingrealistically synthesized warped images and to inpaint occluded or missingregions across virtual viewpoints, eliminating the need for explicit 3Dannotations. Building on this inpainting core, we design a spatiotemporalautoregressive inference pipeline that traverses virtual-camera splines andextends videos with overlapping windows, enabling coherent generation atbounded per-step complexity. We validate See4D on cross-view video generationand sparse reconstruction benchmarks. Across quantitative metrics andqualitative assessments, our method achieves superior generalization andimproved performance relative to pose- or trajectory-conditioned baselines,advancing practical 4D world modeling from casual videos.</description><author>Dongyue Lu, Ao Liang, Tianxin Huang, Xiao Fu, Yuyang Zhao, Baorui Ma, Liang Pan, Wei Yin, Lingdong Kong, Wei Tsang Ooi, Ziwei Liu</author><pubDate>Thu, 30 Oct 2025 17:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26796v1</guid></item><item><title>Scaling Image Geo-Localization to Continent Level</title><link>http://arxiv.org/abs/2510.26795v1</link><description>Determining the precise geographic location of an image at a global scaleremains an unsolved challenge. Standard image retrieval techniques areinefficient due to the sheer volume of images (&gt;100M) and fail when coverage isinsufficient. Scalable solutions, however, involve a trade-off: globalclassification typically yields coarse results (10+ kilometers), whilecross-view retrieval between ground and aerial imagery suffers from a domaingap and has been primarily studied on smaller regions. This paper introduces ahybrid approach that achieves fine-grained geo-localization across a largegeographic expanse the size of a continent. We leverage a proxy classificationtask during training to learn rich feature representations that implicitlyencode precise location information. We combine these learned prototypes withembeddings of aerial imagery to increase robustness to the sparsity ofground-level data. This enables direct, fine-grained retrieval over areasspanning multiple countries. Our extensive evaluation demonstrates that ourapproach can localize within 200m more than 68\% of queries of a datasetcovering a large part of Europe. The code is publicly available athttps://scaling-geoloc.github.io.</description><author>Philipp Lindenberger, Paul-Edouard Sarlin, Jan Hosang, Matteo Balice, Marc Pollefeys, Simon Lynen, Eduard Trulls</author><pubDate>Thu, 30 Oct 2025 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26795v1</guid></item><item><title>The Quest for Generalizable Motion Generation: Data, Model, and Evaluation</title><link>http://arxiv.org/abs/2510.26794v1</link><description>Despite recent advances in 3D human motion generation (MoGen) on standardbenchmarks, existing models still face a fundamental bottleneck in theirgeneralization capability. In contrast, adjacent generative fields, mostnotably video generation (ViGen), have demonstrated remarkable generalizationin modeling human behaviors, highlighting transferable insights that MoGen canleverage. Motivated by this observation, we present a comprehensive frameworkthat systematically transfers knowledge from ViGen to MoGen across three keypillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, alarge-scale dataset comprising 228,000 high-quality motion samples thatintegrates high-fidelity optical MoCap data with semantically annotated motionsfrom web videos and synthesized samples generated by state-of-the-art ViGenmodels. The dataset includes both text-motion pairs and text-video-motiontriplets, substantially expanding semantic diversity. Second, we proposeViMoGen, a flow-matching-based diffusion transformer that unifies priors fromMoCap data and ViGen models through gated multimodal conditioning. To enhanceefficiency, we further develop ViMoGen-light, a distilled variant thateliminates video generation dependencies while preserving stronggeneralization. Finally, we present MBench, a hierarchical benchmark designedfor fine-grained evaluation across motion quality, prompt fidelity, andgeneralization ability. Extensive experiments show that our frameworksignificantly outperforms existing approaches in both automatic and humanevaluations. The code, data, and benchmark will be made publicly available.</description><author>Jing Lin, Ruisi Wang, Junzhe Lu, Ziqi Huang, Guorui Song, Ailing Zeng, Xian Liu, Chen Wei, Wanqi Yin, Qingping Sun, Zhongang Cai, Lei Yang, Ziwei Liu</author><pubDate>Thu, 30 Oct 2025 17:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26794v1</guid></item><item><title>Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability</title><link>http://arxiv.org/abs/2510.26792v1</link><description>We study the ability of Transformer models to learn sequences generated byPermuted Congruential Generators (PCGs), a widely used family of pseudo-randomnumber generators (PRNGs). PCGs introduce substantial additional difficultyover linear congruential generators (LCGs) by applying a series of bit-wiseshifts, XORs, rotations and truncations to the hidden state. We show thatTransformers can nevertheless successfully perform in-context prediction onunseen sequences from diverse PCG variants, in tasks that are beyond publishedclassical attacks. In our experiments we scale moduli up to $2^{22}$ using upto $50$ million model parameters and datasets with up to $5$ billion tokens.Surprisingly, we find even when the output is truncated to a single bit, it canbe reliably predicted by the model. When multiple distinct PRNGs are presentedtogether during training, the model can jointly learn them, identifyingstructures from different permutations. We demonstrate a scaling law withmodulus $m$: the number of in-context sequence elements required fornear-perfect prediction grows as $\sqrt{m}$. For larger moduli, optimizationenters extended stagnation phases; in our experiments, learning moduli $m \geq2^{20}$ requires incorporating training data from smaller moduli, demonstratinga critical necessity for curriculum learning. Finally, we analyze embeddinglayers and uncover a novel clustering phenomenon: the model spontaneouslygroups the integer inputs into bitwise rotationally-invariant clusters,revealing how representations can transfer from smaller to larger moduli.</description><author>Tao Tao, Maissam Barkeshli</author><pubDate>Thu, 30 Oct 2025 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26792v1</guid></item><item><title>Gistify! Codebase-Level Understanding via Runtime Execution</title><link>http://arxiv.org/abs/2510.26790v1</link><description>As coding agents are increasingly deployed in large codebases, the need toautomatically design challenging, codebase-level evaluation is central. Wepropose Gistify, a task where a coding LLM must create a single, minimal,self-contained file that can reproduce a specific functionality of a codebase.The coding LLM is given full access to a codebase along with a specificentrypoint (e.g., a python command), and the generated file must replicate theoutput of the same command ran under the full codebase, while containing onlythe essential components necessary to execute the provided command. Success onGistify requires both structural understanding of the codebase, accuratemodeling of its execution flow as well as the ability to produce potentiallylarge code patches. Our findings show that current state-of-the-art modelsstruggle to reliably solve Gistify tasks, especially ones with long executionstraces.</description><author>Hyunji Lee, Minseon Kim, Chinmay Singh, Matheus Pereira, Atharv Sonwane, Isadora White, Elias Stengel-Eskin, Mohit Bansal, Zhengyan Shi, Alessandro Sordoni, Marc-Alexandre Côté, Xingdi Yuan, Lucas Caccia</author><pubDate>Thu, 30 Oct 2025 17:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26790v1</guid></item><item><title>Defeating the Training-Inference Mismatch via FP16</title><link>http://arxiv.org/abs/2510.26788v1</link><description>Reinforcement learning (RL) fine-tuning of large language models (LLMs) oftensuffers from instability due to the numerical mismatch between the training andinference policies. While prior work has attempted to mitigate this issuethrough algorithmic corrections or engineering alignments, we show that itsroot cause lies in the floating point precision itself. The widely adoptedBF16, despite its large dynamic range, introduces large rounding errors thatbreaks the consistency between training and inference. In this work, wedemonstrate that simply reverting to \textbf{FP16} effectively eliminates thismismatch. The change is simple, fully supported by modern frameworks with onlya few lines of code change, and requires no modification to the modelarchitecture or learning algorithm. Our results suggest that using FP16uniformly yields more stable optimization, faster convergence, and strongerperformance across diverse tasks, algorithms and frameworks. We hope thesefindings motivate a broader reconsideration of precision trade-offs in RLfine-tuning.</description><author>Penghui Qi, Zichen Liu, Xiangxin Zhou, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin</author><pubDate>Thu, 30 Oct 2025 17:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26788v1</guid></item><item><title>Remote Labor Index: Measuring AI Automation of Remote Work</title><link>http://arxiv.org/abs/2510.26787v1</link><description>AIs have made rapid progress on research-oriented benchmarks of knowledge andreasoning, but it remains unclear how these gains translate into economic valueand automation. To measure this, we introduce the Remote Labor Index (RLI), abroadly multi-sector benchmark comprising real-world, economically valuableprojects designed to evaluate end-to-end agent performance in practicalsettings. AI agents perform near the floor on RLI, with the highest-performingagent achieving an automation rate of 2.5%. These results help grounddiscussions of AI automation in empirical evidence, setting a common basis fortracking AI impacts and enabling stakeholders to proactively navigate AI-drivenlabor automation.</description><author>Mantas Mazeika, Alice Gatti, Cristina Menghini, Udari Madhushani Sehwag, Shivam Singhal, Yury Orlovskiy, Steven Basart, Manasi Sharma, Denis Peskoff, Elaine Lau, Jaehyuk Lim, Lachlan Carroll, Alice Blair, Vinaya Sivakumar, Sumana Basu, Brad Kenstler, Yuntao Ma, Julian Michael, Xiaoke Li, Oliver Ingebretsen, Aditya Mehta, Jean Mottola, John Teichmann, Kevin Yu, Zaina Shaik, Adam Khoja, Richard Ren, Jason Hausenloy, Long Phan, Ye Htet, Ankit Aich, Tahseen Rabbani, Vivswan Shah, Andriy Novykov, Felix Binder, Kirill Chugunov, Luis Ramirez, Matias Geralnik, Hernán Mesura, Dean Lee, Ed-Yeremai Hernandez Cardona, Annette Diamond, Summer Yue, Alexandr Wang, Bing Liu, Ernesto Hernandez, Dan Hendrycks</author><pubDate>Thu, 30 Oct 2025 17:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26787v1</guid></item><item><title>HEIR: Learning Graph-Based Motion Hierarchies</title><link>http://arxiv.org/abs/2510.26786v1</link><description>Hierarchical structures of motion exist across research fields, includingcomputer vision, graphics, and robotics, where complex dynamics typically arisefrom coordinated interactions among simpler motion components. Existing methodsto model such dynamics typically rely on manually-defined or heuristichierarchies with fixed motion primitives, limiting their generalizabilityacross different tasks. In this work, we propose a general hierarchical motionmodeling method that learns structured, interpretable motion relationshipsdirectly from data. Our method represents observed motions using graph-basedhierarchies, explicitly decomposing global absolute motions intoparent-inherited patterns and local motion residuals. We formulate hierarchyinference as a differentiable graph learning problem, where vertices representelemental motions and directed edges capture learned parent-child dependenciesthrough graph neural networks. We evaluate our hierarchical reconstructionapproach on three examples: 1D translational motion, 2D rotational motion, anddynamic 3D scene deformation via Gaussian splatting. Experimental results showthat our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,and produces more realistic and interpretable deformations compared to thebaseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,data-driven hierarchical modeling paradigm, our method offers a formulationapplicable to a broad range of motion-centric tasks. Project Page:https://light.princeton.edu/HEIR/</description><author>Cheng Zheng, William Koch, Baiang Li, Felix Heide</author><pubDate>Thu, 30 Oct 2025 17:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26786v1</guid></item><item><title>LLMs Process Lists With General Filter Heads</title><link>http://arxiv.org/abs/2510.26784v1</link><description>We investigate the mechanisms underlying a range of list-processing tasks inLLMs, and we find that LLMs have learned to encode a compact, causalrepresentation of a general filtering operation that mirrors the generic"filter" function of functional programming. Using causal mediation analysis ona diverse set of list-processing tasks, we find that a small number ofattention heads, which we dub filter heads, encode a compact representation ofthe filtering predicate in their query states at certain tokens. We demonstratethat this predicate representation is general and portable: it can be extractedand reapplied to execute the same filtering operation on different collections,presented in different formats, languages, or even in tasks. However, we alsoidentify situations where transformer LMs can exploit a different strategy forfiltering: eagerly evaluating if an item satisfies the predicate and storingthis intermediate result as a flag directly in the item representations. Ourresults reveal that transformer LMs can develop human-interpretableimplementations of abstract computational operations that generalize in waysthat are surprisingly similar to strategies used in traditional functionalprogramming patterns.</description><author>Arnab Sen Sharma, Giordano Rogers, Natalie Shapira, David Bau</author><pubDate>Thu, 30 Oct 2025 17:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26784v1</guid></item><item><title>TinyTim: A Family of Language Models for Divergent Generation</title><link>http://arxiv.org/abs/2508.11607v2</link><description>In the search for artificial general intelligence, model development andtraining has focused primarily on vast datasets of known problems and theiraccepted solutions. This process necessarily produces convergent systems whichare fundamentally incapable of the conceptual reframing that is required forgenuine creative breakthroughs. Inspired by the divergent cognitive processesthat allow humans to make such creative leaps, our work introduces a family oflanguage models, TinyTim, to serve as sources of divergent generation withinbroader systems. These models have been created by fine-tuning on theanti-parsimonious text of James Joyce's `Finnegans Wake'. Quantitative analysisof both an unsupervised fine-tuned model (TinyTim-V1) and a newinstruction-tuned variant (TinyTim-V2) demonstrates a profound capacity forlexical invention; the foundational V1 model exhibits a Yule's K score forlexical richness over twenty times greater than that of convergent baselines.This trait is a stable property of the family, as the instruction-tuned V2maintains a statistically distinct profile and resists factual convergence,sacrificing benchmark performance to preserve its core generative style. Thiswork establishes a methodology for engineering specialized divergent modelsthat, when paired with convergent systems, can reframe problems and forcebreakthroughs beyond the reach of statistical optimization alone.</description><author>Christopher J. Agostino</author><pubDate>Thu, 30 Oct 2025 17:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11607v2</guid></item><item><title>A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</title><link>http://arxiv.org/abs/2510.26783v1</link><description>This note introduces a unified theory for causal inference that integratesRiesz regression, covariate balancing, density-ratio estimation (DRE), targetedmaximum likelihood estimation (TMLE), and the matching estimator in averagetreatment effect (ATE) estimation. In ATE estimation, the balancing weights andthe regression functions of the outcome play important roles, where thebalancing weights are referred to as the Riesz representer, bias-correctionterm, and clever covariates, depending on the context. Riesz regression,covariate balancing, DRE, and the matching estimator are methods for estimatingthe balancing weights, where Riesz regression is essentially equivalent to DREin the ATE context, the matching estimator is a special case of DRE, and DRE isin a dual relationship with covariate balancing. TMLE is a method forconstructing regression function estimators such that the leading bias termbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares DensityRatio Estimation and Riesz Regression.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26783v1</guid></item><item><title>Clone Deterministic 3D Worlds with Geometrically-Regularized World Models</title><link>http://arxiv.org/abs/2510.26782v1</link><description>A world model is an internal model that simulates how the world evolves.Given past observations and actions, it predicts the future of both theembodied agent and its environment. Accurate world models are essential forenabling agents to think, plan, and reason effectively in complex, dynamicsettings. Despite rapid progress, current world models remain brittle anddegrade over long horizons. We argue that a central cause is representationquality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy orentangled latents make dynamics learning unnecessarily hard. We therefore askwhether improving representation learning alone can substantially improveworld-model performance. In this work, we take a step toward building a trulyaccurate world model by addressing a fundamental yet open problem: constructinga model that can fully clone and overfit to a deterministic 3D world. Wepropose Geometrically-Regularized World Models (GRWM), which enforces thatconsecutive points along a natural sensory trajectory remain close in latentrepresentation space. This approach yields significantly improved latentrepresentations that align closely with the true topology of the environment.GRWM is plug-and-play, requires only minimal architectural modification, scaleswith trajectory length, and is compatible with diverse latent generativebackbones. Across deterministic 3D settings and long-horizon prediction tasks,GRWM significantly increases rollout fidelity and stability. Analyses show thatits benefits stem from learning a latent manifold with superior geometricstructure. These findings support a clear takeaway: improving representationlearning is a direct and useful path to robust world models, deliveringreliable long-horizon predictions without enlarging the dynamics module.</description><author>Zaishuo Xia, Yukuan Lu, Xinyi Li, Yifan Xu, Yubei Chen</author><pubDate>Thu, 30 Oct 2025 17:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26782v1</guid></item><item><title>ChartAB: A Benchmark for Chart Grounding &amp; Dense Alignment</title><link>http://arxiv.org/abs/2510.26781v1</link><description>Charts play an important role in visualization, reasoning, data analysis, andthe exchange of ideas among humans. However, existing vision-language models(VLMs) still lack accurate perception of details and struggle to extractfine-grained structures from charts. Such limitations in chart grounding alsohinder their ability to compare multiple charts and reason over them. In thispaper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide acomprehensive evaluation of VLMs in chart grounding tasks, i.e., extractingtabular data, localizing visualization elements, and recognizing variousattributes from charts of diverse types and complexities. We design a JSONtemplate to facilitate the calculation of evaluation metrics specificallytailored for each grounding task. By incorporating a novel two-stage inferenceworkflow, the benchmark can further evaluate VLMs' capability to align andcompare elements/attributes across two charts. Our analysis of evaluations onseveral recent VLMs reveals new insights into their perception biases,weaknesses, robustness, and hallucinations in chart understanding. Thesefindings highlight the fine-grained discrepancies among VLMs in chartunderstanding tasks and point to specific skills that need to be strengthenedin current models.</description><author>Aniruddh Bansal, Davit Soselia, Dang Nguyen, Tianyi Zhou</author><pubDate>Thu, 30 Oct 2025 17:56:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26781v1</guid></item><item><title>S-CFE: Simple Counterfactual Explanations</title><link>http://arxiv.org/abs/2410.15723v7</link><description>We study the problem of finding optimal sparse, manifold-alignedcounterfactual explanations for classifiers. Canonically, this can beformulated as an optimization problem with multiple non-convex components,including classifier loss functions and manifold alignment (or\emph{plausibility}) metrics. The added complexity of enforcing\emph{sparsity}, or shorter explanations, complicates the problem further.Existing methods often focus on specific models and plausibility measures,relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, wetackle the canonical formulation using the accelerated proximal gradient (APG)method, a simple yet efficient first-order procedure capable of handling smoothnon-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$)regularizers. This enables our approach to seamlessly incorporate variousclassifiers and plausibility measures while producing sparser solutions. Ouralgorithm only requires differentiable data-manifold regularizers and supportsbox constraints for bounded feature ranges, ensuring the generatedcounterfactuals remain \emph{actionable}. Finally, experiments on real-worlddatasets demonstrate that our approach effectively produces sparse,manifold-aligned counterfactual explanations while maintaining proximity to thefactual data and computational efficiency.</description><author>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</author><pubDate>Thu, 30 Oct 2025 17:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15723v7</guid></item><item><title>Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance</title><link>http://arxiv.org/abs/2510.26778v1</link><description>Age-related macular degeneration (AMD) is one of the leading causes ofirreversible vision impairment in people over the age of 60. This researchfocuses on semantic segmentation for AMD lesion detection in RGB fundus images,a non-invasive and cost-effective imaging technique. The results of the ADAMchallenge - the most comprehensive AMD detection from RGB fundus imagesresearch competition and open dataset to date - serve as a benchmark for ourevaluation. Taking the U-Net connectivity as a base of our framework, weevaluate and compare several approaches to improve the segmentation model'sarchitecture and training pipeline, including pre-processing techniques,encoder (backbone) deep network types of varying complexity, and specializedloss functions to mitigate class imbalances on image and pixel levels. The mainoutcome of this research is the final configuration of the AMD detectionframework, which outperforms all the prior ADAM challenge submissions on themulti-class segmentation of different AMD lesion types in non-invasive RGBfundus images. The source code used to conduct the experiments presented inthis paper is made freely available.</description><author>Valentyna Starodub, Mantas Lukoševičius</author><pubDate>Thu, 30 Oct 2025 17:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26778v1</guid></item><item><title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title><link>http://arxiv.org/abs/2510.23534v2</link><description>We develop a direct debiased machine learning framework comprising Neymantargeted estimation and generalized Riesz regression. Our framework unifiesRiesz regression for automatic debiased machine learning, covariate balancing,targeted maximum likelihood estimation (TMLE), and density-ratio estimation. Inmany problems involving causal effects or structural models, the parameters ofinterest depend on regression functions. Plugging regression functionsestimated by machine learning methods into the identifying equations can yieldpoor performance because of first-stage bias. To reduce such bias, debiasedmachine learning employs Neyman orthogonal estimating equations. Debiasedmachine learning typically requires estimation of the Riesz representer and theregression function. For this problem, we develop a direct debiased machinelearning framework with an end-to-end algorithm. We formulate estimation of thenuisance parameters, the regression function and the Riesz representer, asminimizing the discrepancy between Neyman orthogonal scores computed with knownand unknown nuisance parameters, which we refer to as Neyman targetedestimation. Neyman targeted estimation includes Riesz representer estimation,and we measure discrepancies using the Bregman divergence. The Bregmandivergence encompasses various loss functions as special cases, where thesquared loss yields Riesz regression and the Kullback-Leibler divergence yieldsentropy balancing. We refer to this Riesz representer estimation as generalizedRiesz regression. Neyman targeted estimation also yields TMLE as a special casefor regression function estimation. Furthermore, for specific pairs of modelsand Riesz representer estimation methods, we can automatically obtain thecovariate balancing property without explicitly solving the covariate balancingobjective.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.23534v2</guid></item><item><title>Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification</title><link>http://arxiv.org/abs/2510.26777v1</link><description>Recent research on time series foundation models has primarily focused onforecasting, leaving it unclear how generalizable their learned representationsare. In this study, we examine whether frozen pre-trained forecasting modelscan provide effective representations for classification. To this end, wecompare different representation extraction strategies and introduce twomodel-agnostic embedding augmentations. Our experiments show that the bestforecasting models achieve classification accuracy that matches or evensurpasses that of state-of-the-art models pre-trained specifically forclassification. Moreover, we observe a positive correlation between forecastingand classification performance. These findings challenge the assumption thattask-specific pre-training is necessary, and suggest that learning to forecastmay provide a powerful route toward constructing general-purpose time seriesfoundation models.</description><author>Andreas Auer, Daniel Klotz, Sebastinan Böck, Sepp Hochreiter</author><pubDate>Thu, 30 Oct 2025 17:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26777v1</guid></item><item><title>Faithful and Fast Influence Function via Advanced Sampling</title><link>http://arxiv.org/abs/2510.26776v1</link><description>How can we explain the influence of training data on black-box models?Influence functions (IFs) offer a post-hoc solution by utilizing gradients andHessians. However, computing the Hessian for an entire dataset isresource-intensive, necessitating a feasible alternative. A common approachinvolves randomly sampling a small subset of the training data, but this methodoften results in highly inconsistent IF estimates due to the high variance insample configurations. To address this, we propose two advanced samplingtechniques based on features and logits. These samplers select a small yetrepresentative subset of the entire dataset by considering the stochasticdistribution of features or logits, thereby enhancing the accuracy of IFestimations. We validate our approach through class removal experiments, atypical application of IFs, using the F1-score to measure how effectively themodel forgets the removed class while maintaining inference consistency on theremaining classes. Our method reduces computation time by 30.1% and memoryusage by 42.2%, or improves the F1-score by 2.5% compared to the baseline.</description><author>Jungyeon Koh, Hyeonsu Lyu, Jonggyu Jang, Hyun Jong Yang</author><pubDate>Thu, 30 Oct 2025 17:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26776v1</guid></item><item><title>Completion $\neq$ Collaboration: Scaling Collaborative Effort with Agents</title><link>http://arxiv.org/abs/2510.25744v2</link><description>Current evaluations of agents remain centered around one-shot taskcompletion, failing to account for the inherently iterative and collaborativenature of many real-world problems, where human goals are often underspecifiedand evolve. We argue for a shift from building and assessing task completionagents to developing collaborative agents, assessed not only by the quality oftheir final outputs but by how well they engage with and enhance human effortthroughout the problem-solving process. To support this shift, we introducecollaborative effort scaling, a framework that captures how an agent's utilitygrows with increasing user involvement. Through case studies and simulatedevaluations, we show that state-of-the-art agents often underperform inmulti-turn, real-world scenarios, revealing a missing ingredient in agentdesign: the ability to sustain engagement and scaffold user understanding.Collaborative effort scaling offers a lens for diagnosing agent behavior andguiding development toward more effective interactions.</description><author>Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma, Jillian Ross, Alex Gu, Chenglei Si, Wayne Chi, Andi Peng, Jocelyn J Shen, Ameet Talwalkar, Tongshuang Wu, David Sontag</author><pubDate>Thu, 30 Oct 2025 17:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.25744v2</guid></item><item><title>STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization</title><link>http://arxiv.org/abs/2510.26771v1</link><description>Quantization is the key method for reducing inference latency, power andmemory footprint of generative AI models. However, accuracy often degradessharply when activations are quantized below eight bits. Recent work suggeststhat invertible linear transformations (e.g. rotations) can aid quantization,by reparameterizing feature channels and weights. In this paper, we propose\textit{Sequence Transformation and Mixed Precision} (STaMP) quantization, anovel strategy that applies linear transformations along the \textit{sequence}dimension to exploit the strong local correlation in language and visual data.By keeping a small number of tokens in each intermediate activation at higherprecision, we can maintain model accuracy at lower (average) activationsbit-widths. We evaluate STaMP on recent LVM and LLM architectures,demonstrating that it significantly improves low bit width activationquantization and complements established activation and weight quantizationmethods including recent feature transformations.</description><author>Marco Federici, Riccardo Del Chiaro, Boris van Breugel, Paul Whatmough, Markus Nagel</author><pubDate>Thu, 30 Oct 2025 17:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26771v1</guid></item><item><title>SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models</title><link>http://arxiv.org/abs/2510.26769v1</link><description>This work introduces SteerVLM, a lightweight steering module designed toguide Vision-Language Models (VLMs) towards outputs that better adhere todesired instructions. Our approach learns from the latent embeddings of pairedprompts encoding target and converse behaviors to dynamically adjustactivations connecting the language modality with image context. This allowsfor fine-grained, inference-time control over complex output semantics withoutmodifying model weights while preserving performance on off-target tasks. Oursteering module requires learning parameters equal to 0.14% of the originalVLM's size. Our steering module gains model control through dimension-wiseactivation modulation and adaptive steering across layers without requiringpre-extracted static vectors or manual tuning of intervention points.Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), amultimodal dataset specifically created to facilitate the development andevaluation of VLM steering techniques. Our method outperforms existingintervention techniques on steering and hallucination mitigation benchmarks forVLMs and proposes a robust solution for multimodal model control throughactivation engineering.</description><author>Anushka Sivakumar, Andrew Zhang, Zaber Hakim, Chris Thomas</author><pubDate>Thu, 30 Oct 2025 17:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26769v1</guid></item><item><title>AMO-Bench: Large Language Models Still Struggle in High School Math Competitions</title><link>http://arxiv.org/abs/2510.26768v1</link><description>We present AMO-Bench, an Advanced Mathematical reasoning benchmark withOlympiad level or even higher difficulty, comprising 50 human-crafted problems.Existing benchmarks have widely leveraged high school math competitions forevaluating mathematical reasoning capabilities of large language models (LLMs).However, many existing math competitions are becoming less effective forassessing top-tier LLMs due to performance saturation (e.g., AIME24/25). Toaddress this, AMO-Bench introduces more rigorous challenges by ensuring all 50problems are (1) cross-validated by experts to meet at least the InternationalMathematical Olympiad (IMO) difficulty standards, and (2) entirely originalproblems to prevent potential performance leakages from data memorization.Moreover, each problem in AMO-Bench requires only a final answer rather than aproof, enabling automatic and robust grading for evaluation. Experimentalresults across 26 LLMs on AMO-Bench show that even the best-performing modelachieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.Beyond these poor performances, our further analysis reveals a promisingscaling trend with increasing test-time compute on AMO-Bench. These resultshighlight the significant room for improving the mathematical reasoning incurrent LLMs. We release AMO-Bench to facilitate further research intoadvancing the reasoning abilities of language models.https://amo-bench.github.io/</description><author>Shengnan An, Xunliang Cai, Xuezhi Cao, Xiaoyu Li, Yehao Lin, Junlin Liu, Xinxuan Lv, Dan Ma, Xuanlin Wang, Ziwen Wang, Shuang Zhou</author><pubDate>Thu, 30 Oct 2025 17:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26768v1</guid></item><item><title>Adversarial generalization of unfolding (model-based) networks</title><link>http://arxiv.org/abs/2509.15370v3</link><description>Unfolding networks are interpretable networks emerging from iterativealgorithms, incorporate prior knowledge of data structure, and are designed tosolve inverse problems like compressed sensing, which deals with recoveringdata from noisy, missing observations. Compressed sensing finds applications incritical domains, from medical imaging to cryptography, where adversarialrobustness is crucial to prevent catastrophic failures. However, a solidtheoretical understanding of the performance of unfolding networks in thepresence of adversarial attacks is still in its infancy. In this paper, westudy the adversarial generalization of unfolding networks when perturbed with$l_2$-norm constrained attacks, generated by the fast gradient sign method.Particularly, we choose a family of state-of-the-art overaparameterizedunfolding networks and deploy a new framework to estimate their adversarialRademacher complexity. Given this estimate, we provide adversarialgeneralization error bounds for the networks under study, which are tight withrespect to the attack level. To our knowledge, this is the first theoreticalanalysis on the adversarial generalization of unfolding networks. We furtherpresent a series of experiments on real-world data, with results corroboratingour derived theory, consistently for all data. Finally, we observe that thefamily's overparameterization can be exploited to promote adversarialrobustness, shedding light on how to efficiently robustify neural networks.</description><author>Vicky Kouni</author><pubDate>Thu, 30 Oct 2025 17:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.15370v3</guid></item><item><title>MORE: Multi-Organ Medical Image REconstruction Dataset</title><link>http://arxiv.org/abs/2510.26759v1</link><description>CT reconstruction provides radiologists with images for diagnosis andtreatment, yet current deep learning methods are typically limited to specificanatomies and datasets, hindering generalization ability to unseen anatomiesand lesions. To address this, we introduce the Multi-Organ medical imageREconstruction (MORE) dataset, comprising CT scans across 9 diverse anatomieswith 15 lesion types. This dataset serves two key purposes: (1) enabling robusttraining of deep learning models on extensive, heterogeneous data, and (2)facilitating rigorous evaluation of model generalization for CT reconstruction.We further establish a strong baseline solution that outperforms priorapproaches under these challenging conditions. Our results demonstrate that:(1) a comprehensive dataset helps improve the generalization capability ofmodels, and (2) optimization-based methods offer enhanced robustness for unseenanatomies. The MORE dataset is freely accessible under CC-BY-NC 4.0 at ourproject page https://more-med.github.io/</description><author>Shaokai Wu, Yapan Guo, Yanbiao Ji, Jing Tong, Yuxiang Lu, Mei Li, Suizhi Huang, Yue Ding, Hongtao Lu</author><pubDate>Thu, 30 Oct 2025 17:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26759v1</guid></item><item><title>The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy</title><link>http://arxiv.org/abs/2510.26752v1</link><description>As increasingly capable agents are deployed, a central safety question is howto retain meaningful human control without modifying the underlying system. Westudy a minimal control interface where an agent chooses whether to actautonomously (play) or defer (ask), while a human simultaneously chooseswhether to be permissive (trust) or to engage in oversight (oversee). If theagent defers, the human's choice determines the outcome, potentially leading toa corrective action or a system shutdown. We model this interaction as atwo-player Markov Game. Our analysis focuses on cases where this game qualifiesas a Markov Potential Game (MPG), a class of games where we can provide analignment guarantee: under a structural assumption on the human's valuefunction, any decision by the agent to act more autonomously that benefitsitself cannot harm the human's value. We also analyze extensions to this MPGframework. Theoretically, this perspective provides conditions for a specificform of intrinsic alignment. If the reward structures of the human-agent gamemeet these conditions, we have a formal guarantee that the agent improving itsown outcome will not harm the human's. Practically, this model motivates atransparent control layer with predictable incentives where the agent learns todefer when risky and act when safe, while its pretrained policy and theenvironment's reward structure remain untouched. Our gridworld simulation showsthat through independent learning, the agent and human discover their optimaloversight roles. The agent learns to ask when uncertain and the human learnswhen to oversee, leading to an emergent collaboration that avoids safetyviolations introduced post-training. This demonstrates a practical method formaking misaligned models safer after deployment.</description><author>William Overman, Mohsen Bayati</author><pubDate>Thu, 30 Oct 2025 17:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26752v1</guid></item><item><title>Smoothing Slot Attention Iterations and Recurrences</title><link>http://arxiv.org/abs/2508.05417v2</link><description>Slot Attention (SA) and its variants lie at the heart of mainstreamObject-Centric Learning (OCL). Objects in an image can be aggregated intorespective slot vectors, by \textit{iteratively} refining cold-start queryvectors, typically three times, via SA on image features. For video, suchaggregation is \textit{recurrently} shared across frames, with queriescold-started on the first frame while transitioned from the previous frame'sslots on non-first frames. However, the cold-start queries lack sample-specificcues thus hinder precise aggregation on the image or video's first frame; Also,non-first frames' queries are already sample-specific thus require transformsdifferent from the first frame's aggregation. We address these issues for thefirst time with our \textit{SmoothSA}: (1) To smooth SA iterations on the imageor video's first frame, we \textit{preheat} the cold-start queries with richinformation of input features, via a tiny module self-distilled inside OCL; (2)To smooth SA recurrences across all video frames, we \textit{differentiate} thehomogeneous transforms on the first and non-first frames, by using full andsingle iterations respectively. Comprehensive experiments on object discovery,recognition and downstream benchmarks validate our method's effectiveness.Further analyses intuitively illuminate how our method smooths SA iterationsand recurrences. Our source code, model checkpoints and training logs areavailable on https://github.com/Genera1Z/SmoothSA.</description><author>Rongzhen Zhao, Wenyan Yang, Juho Kannala, Joni Pajarinen</author><pubDate>Thu, 30 Oct 2025 17:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.05417v2</guid></item><item><title>Predicting Video Slot Attention Queries from Random Slot-Feature Pairs</title><link>http://arxiv.org/abs/2508.01345v3</link><description>Unsupervised video Object-Centric Learning (OCL) is promising as it enablesobject-level scene representation and dynamics modeling as we humans do.Mainstream video OCL methods adopt a recurrent architecture: An aggregatoraggregates current video frame into object features, termed slots, under somequeries; A transitioner transits current slots to queries for the next frame.This is an effective architecture but all existing implementations both(\textit{i1}) neglect to incorporate next frame features, the most informativesource for query prediction, and (\textit{i2}) fail to learn transitiondynamics, the knowledge essential for query prediction. To address theseissues, we propose Random Slot-Feature pair for learning Query prediction(RandSF.Q): (\textit{t1}) We design a new transitioner to incorporate bothslots and features, which provides more information for query prediction;(\textit{t2}) We train the transitioner to predict queries from slot-featurepairs randomly sampled from available recurrences, which drives it to learntransition dynamics. Experiments on scene representation demonstrate that ourmethod surpass existing video OCL methods significantly, e.g., up to 10 pointson object discovery, setting new state-of-the-art. Such superiority alsobenefits downstream tasks like dynamics modeling. Our core source code, modelcheckpoints and training logs are available onhttps://github.com/Genera1Z/RandSF.Q.</description><author>Rongzhen Zhao, Jian Li, Juho Kannala, Joni Pajarinen</author><pubDate>Thu, 30 Oct 2025 17:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.01345v3</guid></item><item><title>Comparing human and LLM politeness strategies in free production</title><link>http://arxiv.org/abs/2506.09391v2</link><description>Polite speech poses a fundamental alignment challenge for large languagemodels (LLMs). Humans deploy a rich repertoire of linguistic strategies tobalance informational and social goals -- from positive approaches that buildrapport (compliments, expressions of interest) to negative strategies thatminimize imposition (hedging, indirectness). We investigate whether LLMs employa similarly context-sensitive repertoire by comparing human and LLM responsesin both constrained and open-ended production tasks. We find that larger models($\ge$70B parameters) successfully replicate key preferences from thecomputational pragmatics literature, and human evaluators surprisingly preferLLM-generated responses in open-ended contexts. However, further linguisticanalyses reveal that models disproportionately rely on negative politenessstrategies even in positive contexts, potentially leading tomisinterpretations. While modern LLMs demonstrate an impressive handle onpoliteness strategies, these subtle differences raise important questions aboutpragmatic alignment in AI systems.</description><author>Haoran Zhao, Robert D. Hawkins</author><pubDate>Thu, 30 Oct 2025 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.09391v2</guid></item><item><title>Locality in Image Diffusion Models Emerges from Data Statistics</title><link>http://arxiv.org/abs/2509.09672v2</link><description>Recent work has shown that the generalization ability of image diffusionmodels arises from the locality properties of the trained neural network. Inparticular, when denoising a particular pixel, the model relies on a limitedneighborhood of the input image around that pixel, which, according to theprevious work, is tightly related to the ability of these models to producenovel images. Since locality is central to generalization, it is crucial tounderstand why diffusion models learn local behavior in the first place, aswell as the factors that govern the properties of locality patterns. In thiswork, we present evidence that the locality in deep diffusion models emerges asa statistical property of the image dataset and is not due to the inductivebias of convolutional neural networks, as suggested in previous work.Specifically, we demonstrate that an optimal parametric linear denoiserexhibits similar locality properties to deep neural denoisers. We show, boththeoretically and experimentally, that this locality arises directly from pixelcorrelations present in the image datasets. Moreover, locality patterns aredrastically different on specialized datasets, approximating principalcomponents of the data's covariance. We use these insights to craft ananalytical denoiser that better matches scores predicted by a deep diffusionmodel than prior expert-crafted alternatives. Our key takeaway is that whileneural network architectures influence generation quality, their primary roleis to capture locality patterns inherent in the data.</description><author>Artem Lukoianov, Chenyang Yuan, Justin Solomon, Vincent Sitzmann</author><pubDate>Thu, 30 Oct 2025 17:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.09672v2</guid></item><item><title>Deep sequence models tend to memorize geometrically; it is unclear why</title><link>http://arxiv.org/abs/2510.26745v1</link><description>In sequence modeling, the parametric memory of atomic facts has beenpredominantly abstracted as a brute-force lookup of co-occurrences betweenentities. We contrast this associative view against a geometric view of howmemory is stored. We begin by isolating a clean and analyzable instance ofTransformer reasoning that is incompatible with memory as strictly a storage ofthe local co-occurrences specified during training. Instead, the model musthave somehow synthesized its own geometry of atomic facts, encoding globalrelationships between all entities, including non-co-occurring ones. This inturn has simplified a hard reasoning task involving an $\ell$-fold compositioninto an easy-to-learn 1-step geometric task. From this phenomenon, we extract fundamental aspects of neural embeddinggeometries that are hard to explain. We argue that the rise of such a geometry,despite optimizing over mere local associations, cannot be straightforwardlyattributed to typical architectural or optimizational pressures.Counterintuitively, an elegant geometry is learned even when it is not moresuccinct than a brute-force lookup of associations. Then, by analyzing a connection to Node2Vec, we demonstrate how the geometrystems from a spectral bias that -- in contrast to prevailing theories -- indeedarises naturally despite the lack of various pressures. This analysis alsopoints to practitioners a visible headroom to make Transformer memory morestrongly geometric. We hope the geometric view of parametric memory encouragesrevisiting the default intuitions that guide researchers in areas likeknowledge acquisition, capacity, discovery and unlearning.</description><author>Shahriar Noroozizadeh, Vaishnavh Nagarajan, Elan Rosenfeld, Sanjiv Kumar</author><pubDate>Thu, 30 Oct 2025 17:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26745v1</guid></item><item><title>Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model</title><link>http://arxiv.org/abs/2503.09205v3</link><description>Integrating audio and visual data for training multimodal foundational modelsremains a challenge. The Audio-Video Vector Alignment (AVVA) frameworkaddresses this by considering AV scene alignment beyond mere temporalsynchronization, and leveraging Large Language Models (LLMs) for data curation.AVVA implements a scoring mechanism for selecting aligned training datasegments. It integrates Whisper, a speech-based foundation model, for audio andDINOv2 for video analysis in a dual-encoder structure with contrastive learningon AV pairs. Evaluations on AudioCaps, VALOR, and VGGSound demonstrate theeffectiveness of the proposed model architecture and data curation approach.AVVA achieves a significant improvement in top-k accuracies for video-to-audioretrieval on all datasets compared to DenseAV, while using only 192 hrs ofcurated training data. Furthermore, an ablation study indicates that the datacuration process effectively trades data quality for data quantity, yieldingincreases in top-k retrieval accuracies on AudioCaps, VALOR, and VGGSound,compared to training on the full spectrum of uncurated data.</description><author>Ali Vosoughi, Dimitra Emmanouilidou, Hannes Gamper</author><pubDate>Thu, 30 Oct 2025 17:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.09205v3</guid></item><item><title>A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation</title><link>http://arxiv.org/abs/2510.26740v1</link><description>We introduce the General Incentives-based Framework for Fairness (GIFF), anovel approach for fair multi-agent resource allocation that infers fairdecision-making from standard value functions. In resource-constrainedsettings, agents optimizing for efficiency often create inequitable outcomes.Our approach leverages the action-value (Q-)function to balance efficiency andfairness without requiring additional training. Specifically, our methodcomputes a local fairness gain for each action and introduces a counterfactualadvantage correction term to discourage over-allocation to already well-offagents. This approach is formalized within a centralized control setting, wherean arbitrator uses the GIFF-modified Q-values to solve an allocation problem. Empirical evaluations across diverse domains, including dynamic ridesharing,homelessness prevention, and a complex job allocation task-demonstrate that ourframework consistently outperforms strong baselines and can discoverfar-sighted, equitable policies. The framework's effectiveness is supported bya theoretical foundation; we prove its fairness surrogate is a principled lowerbound on the true fairness improvement and that its trade-off parameter offersmonotonic tuning. Our findings establish GIFF as a robust and principledframework for leveraging standard reinforcement learning components to achievemore equitable outcomes in complex multi-agent systems.</description><author>Ashwin Kumar, William Yeoh</author><pubDate>Thu, 30 Oct 2025 17:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26740v1</guid></item><item><title>ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models</title><link>http://arxiv.org/abs/2507.06078v2</link><description>Despite the success of deep learning across various domains, it remainsvulnerable to adversarial attacks. Although many existing adversarial attackmethods achieve high success rates, they typically rely on $\ell_{p}$-normperturbation constraints, which do not align with human perceptualcapabilities. Consequently, researchers have shifted their focus towardgenerating natural, unrestricted adversarial examples (UAEs). GAN-basedapproaches suffer from inherent limitations, such as poor image quality due toinstability and mode collapse. Meanwhile, diffusion models have been employedfor UAE generation, but they still rely on iterative PGD perturbationinjection, without fully leveraging their central denoising capabilities. Inthis paper, we introduce a novel approach for generating UAEs based ondiffusion models, named ScoreAdv. This method incorporates an interpretableadversarial guidance mechanism to gradually shift the sampling distributiontowards the adversarial distribution, while using an interpretable saliency mapto inject the visual information of a reference image into the generatedsamples. Notably, our method is capable of generating an unlimited number ofnatural adversarial examples and can attack not only classification models butalso retrieval models. We conduct extensive experiments on ImageNet and CelebAdatasets, validating the performance of ScoreAdv across ten target models inboth black-box and white-box settings. Our results demonstrate that ScoreAdvachieves state-of-the-art attack success rates and image quality, whilemaintaining inference efficiency. Furthermore, the dynamic balance betweendenoising and adversarial perturbation enables ScoreAdv to remain robust evenunder defensive measures.</description><author>Chihan Huang, Hao Tang</author><pubDate>Thu, 30 Oct 2025 17:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.06078v2</guid></item><item><title>Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality</title><link>http://arxiv.org/abs/2506.14681v2</link><description>Supervised fine-tuning (SFT) is a critical step in aligning large languagemodels (LLMs) with human instructions and values, yet many aspects of SFTremain poorly understood. We trained a wide range of base models on a varietyof datasets including code generation, mathematical reasoning, andgeneral-domain tasks, resulting in 1,000+ SFT models under controlledconditions. We then identified the dataset properties that matter most andexamined the layer-wise modifications introduced by SFT. Our findings revealthat some training-task synergies persist across all models while others varysubstantially, emphasizing the importance of model-specific strategies.Moreover, we demonstrate that perplexity consistently predicts SFTeffectiveness, often surpassing superficial similarity between the trainingdata and the benchmark, and that mid-layer weight changes correlate moststrongly with performance gains. We release these 1,000+ SFT models andbenchmark results to accelerate further research. All resources are availableat https://github.com/llm-jp/massive-sft.</description><author>Yuto Harada, Yusuke Yamauchi, Yusuke Oda, Yohei Oseki, Yusuke Miyao, Yu Takagi</author><pubDate>Thu, 30 Oct 2025 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.14681v2</guid></item><item><title>Advancing Local Clustering on Graphs via Compressive Sensing: Semi-supervised and Unsupervised Methods</title><link>http://arxiv.org/abs/2504.19419v2</link><description>Local clustering aims to identify specific substructures within a large graphwithout any additional structural information of the graph. These substructuresare typically small compared to the overall graph, enabling the problem to beapproached by finding a sparse solution to a linear system associated with thegraph Laplacian. In this work, we first propose a method for identifyingspecific local clusters when very few labeled data are given, which we termsemi-supervised local clustering. We then extend this approach to theunsupervised setting when no prior information on labels is available. Theproposed methods involve randomly sampling the graph, applying diffusionthrough local cluster extraction, then examining the overlap among the resultsto find each cluster. We establish the co-membership conditions for any pair ofnodes, and rigorously prove the correctness of our methods. Additionally, weconduct extensive experiments to demonstrate that the proposed methods achievestate of the art results in the low-label rates regime.</description><author>Zhaiming Shen, Sung Ha Kang</author><pubDate>Thu, 30 Oct 2025 17:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.19419v2</guid></item><item><title>Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming</title><link>http://arxiv.org/abs/2506.05567v2</link><description>Neural Networks (NN) with ReLU activation functions are used to modelmultiparametric quadratic optimization problems (mp-QP) in diverse engineeringapplications. Researchers have suggested leveraging the piecewise affineproperty of deep NN models to solve mp-QP with linear constraints, which alsoexhibit piecewise affine behaviour. However, traditional deep NN applicationsto mp-QP fall short of providing optimal and feasible predictions, even whentrained on large datasets. This study proposes a partially-supervised NN (PSNN)architecture that directly represents the mathematical structure of the globalsolution function. In contrast to generic NN training approaches, the proposedPSNN method derives a large proportion of model weights directly from themathematical properties of the optimization problem, producing more accuratesolutions despite significantly smaller training data sets. Many energymanagement problems are formulated as QP, so we apply the proposed approach toenergy systems (specifically DC optimal power flow) to demonstrate proof ofconcept. Model performance in terms of solution accuracy and speed ofpredictions was compared against a commercial solver and a generic Deep NNmodel based on classical training. Results show KKT sufficient conditions forPSNN consistently outperform generic NN architectures with classical trainingusing far less data, including when tested on extreme, out-of-trainingdistribution test data. Given its speed advantages over traditional solvers,the PSNN model can quickly produce optimal and feasible solutions within asecond for millions of input parameters sampled from a distribution ofstochastic demands and renewable generator dispatches, which can be used forsimulations and long term planning.</description><author>Fuat Can Beylunioglu, Mehrdad Pirnia, P. Robert Duimering</author><pubDate>Thu, 30 Oct 2025 17:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05567v2</guid></item><item><title>Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models</title><link>http://arxiv.org/abs/2510.26732v1</link><description>This paper presents a comprehensive cross-platform evaluation of reasoningcapabilities in contemporary foundation models, establishing aninfrastructure-agnostic benchmark across three computational paradigms: HPCsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), anduniversity clusters (a node with eight H200 GPUs). We evaluate 15 foundation models across 79 problems spanning eight academicdomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,Calculus, and Optimization) through three experimental phases: (1) Baselineestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishingmethodology and reference performance; (2) Infrastructure validation: The19-problem benchmark repeated on university cluster (seven models includingFalcon-Mamba state-space architecture) and Nebius AI Studio (ninestate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen330B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnosticreproducibility; (3) Extended evaluation: Full 79-problem assessment on bothuniversity cluster and Nebius platforms, probing generalization at scale acrossarchitectural diversity. The findings challenge conventional scaling assumptions, establish trainingdata quality as more critical than model size, and provide actionableguidelines for model selection across educational, production, and researchcontexts. The tri-infrastructure methodology and 79-problem benchmark enablelongitudinal tracking of reasoning capabilities as foundation models evolve.</description><author>J. de Curtò, I. de Zarzà, Pablo García, Jordi Cabot</author><pubDate>Thu, 30 Oct 2025 17:31:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26732v1</guid></item><item><title>ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</title><link>http://arxiv.org/abs/2510.26730v1</link><description>The expansion of large language models is increasingly limited by theconstrained memory capacity of modern GPUs. To mitigate this,Mixture-of-Experts (MoE) architectures activate only a small portion ofparameters during inference, significantly lowering both memory demand andcomputational overhead. However, conventional MoE inference approaches, whichselect active experts independently at each layer, often introduce considerablelatency because of frequent parameter transfers between host and GPU memory. Inaddition, current cross-layer prediction strategies, which are typically basedon fixed steps, lack adaptability across different hardware platforms andworkloads, thereby reducing their robustness and effectiveness. To address these challenges, we present ExpertFlow, a runtime system for MoEinference that combines adaptive expert prefetching and cache-aware routing.ExpertFlow continuously adjusts its prediction horizon for expert activation byleveraging runtime statistics such as transfer bandwidth, parameterdimensionality, and model feedback signals. Furthermore, it incorporates ahybrid cross-layer prediction scheme that fuses pregating information withintermediate computational states to anticipate future expert needs. Byadaptively refining prefetching decisions and aligning them with actual usagebehavior, ExpertFlow effectively decreases cache misses and removes latencycaused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reducesmodel stall time to less than 0.1% of the baseline, highlighting its capabilityto optimize MoE inference under stringent memory constraints.</description><author>Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu, Wei Zhang</author><pubDate>Thu, 30 Oct 2025 17:29:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26730v1</guid></item><item><title>Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training</title><link>http://arxiv.org/abs/2510.20059v2</link><description>Enhancing reasoning capabilities in small language models is critical forspecialized applications such as medical question answering, particularly inunderrepresented languages like Persian. In this study, we employ ReinforcementLearning with AI Feedback (RLAIF) and Direct preference optimization (DPO) toimprove the reasoning skills of a general-purpose Persian language model. Toachieve this, we translated a multiple-choice medical question-answeringdataset into Persian and used RLAIF to generate rejected-preferred answerpairs, which are essential for DPO training. By prompting both teacher andstudent models to produce Chain-of-Thought (CoT) reasoning responses, wecompiled a dataset containing correct and incorrect reasoning trajectories.This dataset, comprising 2 million tokens in preferred answers and 2.5 milliontokens in rejected ones, was used to train a baseline model, significantlyenhancing its medical reasoning capabilities in Persian. Remarkably, theresulting model outperformed its predecessor, gaokerena-V, which was trained onapproximately 57 million tokens, despite leveraging a much smaller dataset.These results highlight the efficiency and effectiveness of reasoning-focusedtraining approaches in developing domain-specific language models with limiteddata availability.</description><author>Mehrdad Ghassabi, Sadra Hakim, Hamidreza Baradaran Kashani, Pedram Rostami</author><pubDate>Thu, 30 Oct 2025 17:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.20059v2</guid></item><item><title>Integrating Protein Sequence and Expression Level to Analysis Molecular Characterization of Breast Cancer Subtypes</title><link>http://arxiv.org/abs/2410.01755v3</link><description>Breast cancer's complexity and variability pose significant challenges inunderstanding its progression and guiding effective treatment. This study aimsto integrate protein sequence data with expression levels to improve themolecular characterization of breast cancer subtypes and predict clinicaloutcomes. Using ProtGPT2, a language model specifically designed for proteinsequences, we generated embeddings that capture the functional and structuralproperties of proteins. These embeddings were integrated with proteinexpression levels to form enriched biological representations, which wereanalyzed using machine learning methods, such as ensemble K-means forclustering and XGBoost for classification. Our approach enabled the successfulclustering of patients into biologically distinct groups and accuratelypredicted clinical outcomes such as survival and biomarker status, achievinghigh performance metrics, notably an F1 score of 0.88 for survival and 0.87 forbiomarker status prediction. Feature importance analysis identified KMT2C,CLASP2, and MYO1B as key proteins involved in hormone signaling, cytoskeletalremodeling, and therapy resistance in hormone receptor-positive andtriple-negative breast cancer, with potential influence on breast cancersubtype behavior and progression. Furthermore, protein-protein interactionnetworks and correlation analyses revealed functional interdependencies amongproteins that may influence the behavior and progression of breast cancersubtypes. These findings suggest that integrating protein sequence andexpression data provides valuable insights into tumor biology and hassignificant potential to enhance personalized treatment strategies in breastcancer care.</description><author>Hossein Sholehrasa, Majid Jaberi-Douraki</author><pubDate>Thu, 30 Oct 2025 17:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01755v3</guid></item><item><title>Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</title><link>http://arxiv.org/abs/2510.26723v1</link><description>The goal of policy learning is to train a policy function that recommends atreatment given covariates to maximize population welfare. There are two majorapproaches in policy learning: the empirical welfare maximization (EWM)approach and the plug-in approach. The EWM approach is analogous to aclassification problem, where one first builds an estimator of the populationwelfare, which is a functional of policy functions, and then trains a policy bymaximizing the estimated welfare. In contrast, the plug-in approach is based onregression, where one first estimates the conditional average treatment effect(CATE) and then recommends the treatment with the highest estimated outcome.This study bridges the gap between the two approaches by showing that both arebased on essentially the same optimization problem. In particular, we prove anexact equivalence between EWM and least squares over a reparameterization ofthe policy class. As a consequence, the two approaches are interchangeable inseveral respects and share the same theoretical guarantees under commonconditions. Leveraging this equivalence, we propose a novel regularizationmethod for policy learning. Our findings yield a convex and computationallyefficient training procedure that avoids the NP-hard combinatorial steptypically required in EWM.</description><author>Masahiro Kato</author><pubDate>Thu, 30 Oct 2025 17:23:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26723v1</guid></item><item><title>Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</title><link>http://arxiv.org/abs/2510.26722v1</link><description>Over-the-air (OTA) federated learning (FL) has been well recognized as ascalable paradigm that exploits the waveform superposition of the wirelessmultiple-access channel to aggregate model updates in a single use. ExistingOTA-FL designs largely enforce zero-bias model updates by either assuming\emph{homogeneous} wireless conditions (equal path loss across devices) orforcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous}wireless scenarios, however, such designs are constrained by the weakest deviceand inflate the update variance. Moreover, prior analyses of biased OTA-FLlargely address convex objectives, while most modern AI models are highlynon-convex. Motivated by these gaps, we study OTA-FL with stochastic gradientdescent (SGD) for general smooth non-convex objectives under wirelessheterogeneity. We develop novel OTA-FL SGD updates that allow a structured,time-invariant model bias while facilitating reduced variance updates. Wederive a finite-time stationarity bound (expected time average squared gradientnorm) that explicitly reveals a bias-variance trade-off. To optimize thistrade-off, we pose a non-convex joint OTA power-control design and develop anefficient successive convex approximation (SCA) algorithm that requires onlystatistical CSI at the base station. Experiments on a non-convex imageclassification task validate the approach: the SCA-based design acceleratesconvergence via an optimized bias and improves generalization over prior OTA-FLbaselines.</description><author>Muhammad Faraz Ul Abrar, Nicolò Michelusi</author><pubDate>Thu, 30 Oct 2025 17:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26722v1</guid></item><item><title>Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis</title><link>http://arxiv.org/abs/2510.26721v1</link><description>Multimodal large language models (MLLMs) exhibit a pronounced preference fortextual inputs when processing vision-language data, limiting their ability toreason effectively from visual evidence. Unlike prior studies that attributethis text bias to external factors such as data imbalance or instructiontuning, we propose that the bias originates from the model's internalarchitecture. Specifically, we hypothesize that visual key vectors (VisualKeys) are out-of-distribution (OOD) relative to the text key space learnedduring language-only pretraining. Consequently, these visual keys receivesystematically lower similarity scores during attention computation, leading totheir under-utilization in the context representation. To validate thishypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze theirdistributional structures using qualitative (t-SNE) and quantitative(Jensen-Shannon divergence) methods. The results provide direct evidence thatvisual and textual keys occupy markedly distinct subspaces within the attentionspace. The inter-modal divergence is statistically significant, exceedingintra-modal variation by several orders of magnitude. These findings revealthat text bias arises from an intrinsic misalignment within the attention keyspace rather than solely from external data factors.</description><author>Xinhan Zheng, Huyu Wu, Xueting Wang, Haiyun Jiang</author><pubDate>Thu, 30 Oct 2025 17:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26721v1</guid></item><item><title>Reducing base drag on road vehicles using pulsed jets optimized by hybrid genetic algorithms</title><link>http://arxiv.org/abs/2510.26718v1</link><description>Aerodynamic drag on flat-backed vehicles like vans and trucks is dominated bya low-pressure wake, whose control is critical for reducing fuel consumption.This paper presents an experimental study at $Re_W\approx 78,300$ on activeflow control using four pulsed jets at the rear edges of a bluff body model. Ahybrid genetic algorithm, combining a global search with a local gradient-basedoptimizer, was used to determine the optimal jet actuation parameters in anexperiment-in-the-loop setup. The cost function was designed to achieve a netenergy saving by simultaneously minimizing aerodynamic drag and penalizing theactuation's energy consumption. The optimization campaign successfullyidentified a control strategy that yields a drag reduction of approximately10%. The optimal control law features a strong, low-frequency actuation fromthe bottom jet, which targets the main vortex shedding, while the top andlateral jets address higher-frequency, less energetic phenomena. Particle ImageVelocimetry analysis reveals a significant upward shift and stabilization ofthe wake, leading to substantial pressure recovery on the model's lower base.Ultimately, this work demonstrates that a model-free optimization approach cansuccessfully identify non-intuitive, multi-faceted actuation strategies thatyield significant and energetically efficient drag reduction.</description><author>Isaac Robledo, Juan Alfaro, Víctor Duro, Alberto Solera-Rico, Rodrigo Castellanos, Carlos Sanmiguel Vila</author><pubDate>Thu, 30 Oct 2025 17:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26718v1</guid></item><item><title>On Purely Private Covariance Estimation</title><link>http://arxiv.org/abs/2510.26717v1</link><description>We present a simple perturbation mechanism for the release of $d$-dimensionalcovariance matrices $\Sigma$ under pure differential privacy. For largedatasets with at least $n\geq d^2/\varepsilon$ elements, our mechanism recoversthe provably optimal Frobenius norm error guarantees of\cite{nikolov2023private}, while simultaneously achieving best known error forall other $p$-Schatten norms, with $p\in [1,\infty]$. Our error isinformation-theoretically optimal for all $p\ge 2$, in particular, ourmechanism is the first purely private covariance estimator that achievesoptimal error in spectral norm. For small datasets $n&lt; d^2/\varepsilon$, we further show that by projectingthe output onto the nuclear norm ball of appropriate radius, our algorithmachieves the optimal Frobenius norm error $O(\sqrt{d\;\text{Tr}(\Sigma) /n})$,improving over the known bounds of $O(\sqrt{d/n})$ of \cite{nikolov2023private}and ${O}\big(d^{3/4}\sqrt{\text{Tr}(\Sigma)/n}\big)$ of\cite{dong2022differentially}.</description><author>Tommaso d'Orsi, Gleb Novikov</author><pubDate>Thu, 30 Oct 2025 17:18:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26717v1</guid></item><item><title>When Kernels Multiply, Clusters Unify: Fusing Embeddings with the Kronecker Product</title><link>http://arxiv.org/abs/2506.08645v2</link><description>State-of-the-art embeddings often capture distinct yet complementarydiscriminative features: For instance, one image embedding model may excel atdistinguishing fine-grained textures, while another focuses on object-levelstructure. Motivated by this observation, we propose a principled approach tofuse such complementary representations through kernel multiplication.Multiplying the kernel similarity functions of two embeddings allows theirdiscriminative structures to interact, producing a fused representation whosekernel encodes the union of the clusters identified by each parent embedding.This formulation also provides a natural way to construct joint kernels forpaired multi-modal data (e.g., image-text tuples), where the product ofmodality-specific kernels inherits structure from both domains. We highlightthat this kernel product is mathematically realized via the Kronecker productof the embedding feature maps, yielding our proposed KrossFuse framework forembedding fusion. To address the computational cost of the resultinghigh-dimensional Kronecker space, we further develop RP-KrossFuse, a scalablevariant that leverages random projections for efficient approximation. As a keyapplication, we use this framework to bridge the performance gap betweencross-modal embeddings (e.g., CLIP, BLIP) and unimodal experts (e.g., DINOv2,E5). Experiments show that RP-KrossFuse effectively integrates these models,enhancing modality-specific performance while preserving cross-modal alignment.The project code is available at https://github.com/yokiwuuu/KrossFuse.</description><author>Youqi Wu, Jingwei Zhang, Farzan Farnia</author><pubDate>Thu, 30 Oct 2025 17:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08645v2</guid></item><item><title>LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</title><link>http://arxiv.org/abs/2510.26715v1</link><description>A vast majority of mass spectrometry data remains uncharacterized, leavingmuch of its biological and chemical information untapped. Recent advances inmachine learning have begun to address this gap, particularly for tasks such asspectral identification in tandem mass spectrometry data. Here, we present thelatest generation of LSM-MS2, a large-scale deep learning foundation modeltrained on millions of spectra to learn a semantic chemical space. LSM-MS2achieves state-of-the-art performance in spectral identification, improving onexisting methods by 30% in accuracy of identifying challenging isomericcompounds, yielding 42% more correct identifications in complex biologicalsamples, and maintaining robustness under low-concentration conditions.Furthermore, LSM-MS2 produces rich spectral embeddings that enable directbiological interpretation from minimal downstream data, successfullydifferentiating disease states and predicting clinical outcomes across diversetranslational applications.</description><author>Gabriel Asher, Devesh Shah, Amy A. Caudy, Luke Ferro, Lea Amar, Ana S. H. Costa, Thomas Patton, Niall O'Connor, Jennifer M. Campbell, Jack Geremia</author><pubDate>Thu, 30 Oct 2025 17:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26715v1</guid></item><item><title>On the limitation of evaluating machine unlearning using only a single training seed</title><link>http://arxiv.org/abs/2510.26714v1</link><description>Machine unlearning (MU) aims to remove the influence of certain data pointsfrom a trained model without costly retraining. Most practical MU algorithmsare only approximate and their performance can only be assessed empirically.Care must therefore be taken to make empirical comparisons as representative aspossible. A common practice is to run the MU algorithm multiple timesindependently starting from the same trained model. In this work, wedemonstrate that this practice can give highly non-representative resultsbecause -- even for the same architecture and same dataset -- some MU methodscan be highly sensitive to the choice of random number seed used for modeltraining. We therefore recommend that empiricalcomphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms shouldalso reflect the variability across different model training seeds.</description><author>Jamie Lanyon, Axel Finke, Petros Andreou, Georgina Cosma</author><pubDate>Thu, 30 Oct 2025 17:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26714v1</guid></item><item><title>Controlling Thinking Speed in Reasoning Models</title><link>http://arxiv.org/abs/2507.03704v2</link><description>Human cognition is theorized to operate in two modes: fast, intuitive System1 thinking and slow, deliberate System 2 thinking. While current LargeReasoning Models (LRMs) excel at System 2 thinking, their inability to performfast thinking leads to high computational overhead and latency. In this work,we enable LRMs to approximate human intelligence through dynamic thinking speedadjustment, optimizing accuracy-efficiency trade-offs. Our approach addressestwo key questions: (1) how to control thinking speed in LRMs, and (2) when toadjust it for optimal performance. For the first question, we identify thesteering vector that governs slow-fast thinking transitions in LRMs'representation space. Using this vector, we achieve the first representationediting-based test-time scaling effect, outperforming existing prompt-basedscaling methods. For the second question, we apply real-time difficultyestimation to signal reasoning segments of varying complexity. Combining thesetechniques, we propose the first reasoning strategy that enables fastprocessing of easy steps and deeper analysis for complex reasoning. Without anytraining or additional cost, our plug-in module delivers an average +1.3%accuracy with -8.6% token usage across leading LRMs and advanced reasoningbenchmarks. All of our algorithms are implemented based on vLLM and areexpected to support broader applications and inspire future research.</description><author>Zhengkai Lin, Zhihang Fu, Ze Chen, Chao Chen, Liang Xie, Wenxiao Wang, Deng Cai, Zheng Wang, Jieping Ye</author><pubDate>Thu, 30 Oct 2025 17:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.03704v2</guid></item><item><title>An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</title><link>http://arxiv.org/abs/2510.26709v1</link><description>Communication remains a central bottleneck in large-scale distributed machinelearning, and gradient sparsification has emerged as a promising strategy toalleviate this challenge. However, existing gradient compressors face notablelimitations: Rand-$K$\ discards structural information and performs poorly inpractice, while Top-$K$\ preserves informative entries but loses thecontraction property and requires costly All-Gather operations. In this paper,we propose ARC-Top-$K$, an {All-Reduce}-Compatible Top-$K$ compressor thataligns sparsity patterns across nodes using a lightweight sketch of thegradient, enabling index-free All-Reduce while preserving globally significantinformation. ARC-Top-$K$\ is provably contractive and, when combined withmomentum error feedback (EF21M), achieves linear speedup and sharperconvergence rates than the original EF21M under standard assumptions.Empirically, ARC-Top-$K$\ matches the accuracy of Top-$K$\ while reducingwall-clock training time by up to 60.7\%, offering an efficient and scalablesolution that combines the robustness of Rand-$K$\ with the strong performanceof Top-$K$.</description><author>Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong, Kun Yuan</author><pubDate>Thu, 30 Oct 2025 17:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26709v1</guid></item><item><title>RLBFF: Binary Flexible Feedback to bridge between Human Feedback &amp; Verifiable Rewards</title><link>http://arxiv.org/abs/2509.21319v2</link><description>Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learningwith Verifiable Rewards (RLVR) are the main RL paradigms used in LLMpost-training, each offering distinct advantages. However, RLHF struggles withinterpretability and reward hacking because it relies on human judgments thatusually lack explicit criteria, whereas RLVR is limited in scope by its focuson correctness-based verifiers. We propose Reinforcement Learning with BinaryFlexible Feedback (RLBFF), which combines the versatility of human-drivenpreferences with the precision of rule-based verification, enabling rewardmodels to capture nuanced aspects of response quality beyond mere correctness.RLBFF extracts principles that can be answered in a binary fashion (e.g.accuracy of information: yes, or code readability: no) from natural languagefeedback. Such principles can then be used to ground Reward Model training asan entailment task (response satisfies or does not satisfy an arbitraryprinciple). We show that Reward Models trained in this manner can outperformBradley-Terry models when matched for data and achieve top performance onRM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,2025). Additionally, users can specify principles of interest at inference timeto customize the focus of our reward models, in contrast to Bradley-Terrymodels. Finally, we present a fully open source recipe (including data) toalign Qwen3-32B using RLBFF and our Reward Model, to match or exceed theperformance of o3-mini and DeepSeek R1 on general alignment benchmarks ofMT-Bench, WildBench, and Arena Hard v2 (at &lt;5% of the inference cost). Models:https://huggingface.co/collections/nvidia/reward-models-10-2025</description><author>Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Ellie Evans, Daniel Egert, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev</author><pubDate>Thu, 30 Oct 2025 17:09:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21319v2</guid></item><item><title>Value Drifts: Tracing Value Alignment During LLM Post-Training</title><link>http://arxiv.org/abs/2510.26707v1</link><description>As LLMs occupy an increasingly important role in society, they are more andmore confronted with questions that require them not only to draw on theirgeneral knowledge but also to align with certain human value systems.Therefore, studying the alignment of LLMs with human values has become acrucial field of inquiry. Prior work, however, mostly focuses on evaluating thealignment of fully trained models, overlooking the training dynamics by whichmodels learn to express human values. In this work, we investigate how and atwhich stage value alignment arises during the course of a model'spost-training. Our analysis disentangles the effects of post-trainingalgorithms and datasets, measuring both the magnitude and time of value driftsduring training. Experimenting with Llama-3 and Qwen-3 models of differentsizes and popular supervised fine-tuning (SFT) and preference optimizationdatasets and algorithms, we find that the SFT phase generally establishes amodel's values, and subsequent preference optimization rarely re-aligns thesevalues. Furthermore, using a synthetic preference dataset that enablescontrolled manipulation of values, we find that different preferenceoptimization algorithms lead to different value alignment outcomes, even whenpreference data is held constant. Our findings provide actionable insights intohow values are learned during post-training and help to inform data curation,as well as the selection of models and algorithms for preference optimizationto improve model alignment to human values.</description><author>Mehar Bhatia, Shravan Nayak, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Vered Shwartz, Siva Reddy</author><pubDate>Thu, 30 Oct 2025 17:09:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26707v1</guid></item><item><title>Budgeted Multiple-Expert Deferral</title><link>http://arxiv.org/abs/2510.26706v1</link><description>Learning to defer uncertain predictions to costly experts offers a powerfulstrategy for improving the accuracy and efficiency of machine learning systems.However, standard training procedures for deferral algorithms typically requirequerying all experts for every training instance, an approach that becomesprohibitively expensive when expert queries incur significant computational orresource costs. This undermines the core goal of deferral: to limit unnecessaryexpert usage. To overcome this challenge, we introduce the budgeted deferralframework, which aims to train effective deferral algorithms while minimizingexpert query costs during training. We propose new algorithms for bothtwo-stage and single-stage multiple-expert deferral settings that selectivelyquery only a subset of experts per training example. While inspired by activelearning, our setting is fundamentally different: labels are already known, andthe core challenge is to decide which experts to query in order to balance costand predictive performance. We establish theoretical guarantees for both of ouralgorithms, including generalization bounds and label complexity analyses.Empirical results across several domains show that our algorithms substantiallyreduce training costs without sacrificing prediction accuracy, demonstratingthe practical value of our budget-aware deferral algorithms.</description><author>Giulia DeSalvo, Clara Mohri, Mehryar Mohri, Yutao Zhong</author><pubDate>Thu, 30 Oct 2025 17:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26706v1</guid></item><item><title>How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators</title><link>http://arxiv.org/abs/2510.26704v1</link><description>Can regularization terms in the training of invertible neural networks leadto known Bayesian point estimators in reconstruction? Invertible networks areattractive for inverse problems due to their inherent stability andinterpretability. Recently, optimization strategies for invertible neuralnetworks that approximate either a reconstruction map or the forward operatorhave been studied from a Bayesian perspective, but each has limitations. Toaddress this, we introduce and analyze two regularization terms for the networktraining that, upon inversion of the network, recover properties of classicalBayesian point estimators: while the first can be connected to the posteriormean, the second resembles the MAP estimator. Our theoretical analysischaracterizes how each loss shapes both the learned forward operator and itsinverse reconstruction map. Numerical experiments support our findings anddemonstrate how these loss-term regularizers introduce data-dependence in astable and interpretable way.</description><author>Nick Heilenkötter</author><pubDate>Thu, 30 Oct 2025 17:07:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26704v1</guid></item><item><title>ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</title><link>http://arxiv.org/abs/2510.26703v1</link><description>Purpose: Medical foundation models (FMs) offer a path to buildhigh-performance diagnostic systems. However, their application to prostatecancer (PCa) detection from micro-ultrasound ({\mu}US) remains untested inclinical settings. We present ProstNFound+, an adaptation of FMs for PCadetection from {\mu}US, along with its first prospective validation. Methods:ProstNFound+ incorporates a medical FM, adapter tuning, and a custom promptencoder that embeds PCa-specific clinical biomarkers. The model generates acancer heatmap and a risk score for clinically significant PCa. Followingtraining on multi-center retrospective data, the model is prospectivelyevaluated on data acquired five years later from a new clinical site. Modelpredictions are benchmarked against standard clinical scoring protocols(PRI-MUS and PI-RADS). Results: ProstNFound+ shows strong generalization to theprospective data, with no performance degradation compared to retrospectiveevaluation. It aligns closely with clinical scores and produces interpretableheatmaps consistent with biopsy-confirmed lesions. Conclusion: The resultshighlight its potential for clinical deployment, offering a scalable andinterpretable alternative to expert-driven protocols.</description><author>Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To, Amoon Jamzad, Tarek Elghareb, Zhuoxin Guo, Adam Kinnaird, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</author><pubDate>Thu, 30 Oct 2025 17:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26703v1</guid></item><item><title>Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching</title><link>http://arxiv.org/abs/2510.26702v1</link><description>Authorizing Large Language Model driven agents to dynamically invoke toolsand access protected resources introduces significant risks, since currentmethods for delegating authorization grant overly broad permissions and giveaccess to tools allowing agents to operate beyond the intended task scope. Weintroduce and assess a delegated authorization model enabling authorizationservers to semantically inspect access requests to protected resources, andissue access tokens constrained to the minimal set of scopes necessary for theagents' assigned tasks. Given the unavailability of datasets centered ondelegated authorization flows, particularly including both semanticallyappropriate and inappropriate scope requests for a given task, we introduceASTRA, a dataset and data generation pipeline for benchmarking semanticmatching between tasks and scopes. Our experiments show both the potential andcurrent limitations of model-based matching, particularly as the number ofscopes needed for task completion increases. Our results highlight the need forfurther research into semantic matching techniques enabling intent-awareauthorization for multi-agent and tool-augmented applications, includingfine-grained control, such as Task-Based Access Control (TBAC).</description><author>Majed El Helou, Chiara Troiani, Benjamin Ryder, Jean Diaconu, Hervé Muyal, Marcelo Yannuzzi</author><pubDate>Thu, 30 Oct 2025 17:07:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26702v1</guid></item><item><title>Curriculum Abductive Learning</title><link>http://arxiv.org/abs/2505.12275v2</link><description>Abductive Learning (ABL) integrates machine learning with logical reasoningin a loop: a learning model predicts symbolic concept labels from raw inputs,which are revised through abduction using domain knowledge and then fed backfor retraining. However, due to the nondeterminism of abduction, the trainingprocess often suffers from instability, especially when the knowledge base islarge and complex, resulting in a prohibitively large abduction space. Whileprior works focus on improving candidate selection within this space, theytypically treat the knowledge base as a static black box. In this work, wepropose Curriculum Abductive Learning (C-ABL), a method that explicitlyleverages the internal structure of the knowledge base to address the ABLtraining challenges. C-ABL partitions the knowledge base into a sequence ofsub-bases, progressively introduced during training. This reduces the abductionspace throughout training and enables the model to incorporate logic in astepwise, smooth way. Experiments across multiple tasks show that C-ABLoutperforms previous ABL implementations, significantly improves trainingstability, convergence speed, and final accuracy, especially under complexknowledge setting.</description><author>Wen-Chao Hu, Qi-Jie Li, Lin-Han Jia, Cunjing Ge, Yu-Feng Li, Yuan Jiang, Zhi-Hua Zhou</author><pubDate>Thu, 30 Oct 2025 17:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12275v2</guid></item><item><title>Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</title><link>http://arxiv.org/abs/2510.26700v1</link><description>Observational studies developing causal machine learning (ML) models for theprediction of individualized treatment effects (ITEs) seldom conduct empiricalevaluations to assess the conditional exchangeability assumption. We aimed toevaluate the performance of these models under conditional exchangeabilityviolations and the utility of negative control outcomes (NCOs) as a diagnostic.We conducted a simulation study to examine confounding bias in ITE estimatesgenerated by causal forest and X-learner models under varying conditions,including the presence or absence of true heterogeneity. We simulated data toreflect real-world scenarios with differing levels of confounding, sample size,and NCO confounding structures. We then estimated and compared subgroup-leveltreatment effects on the primary outcome and NCOs across settings with andwithout unmeasured confounding. When conditional exchangeability was violated,causal forest and X-learner models failed to recover true treatment effectheterogeneity and, in some cases, falsely indicated heterogeneity when therewas none. NCOs successfully identified subgroups affected by unmeasuredconfounding. Even when NCOs did not perfectly satisfy its ideal assumptions, itremained informative, flagging potential bias in subgroup level estimates,though not always pinpointing the subgroup with the largest confounding.Violations of conditional exchangeability substantially limit the validity ofITE estimates from causal ML models in routinely collected observational data.NCOs serve a useful empirical diagnostic tool for detecting subgroup-specificunmeasured confounding and should be incorporated into causal ML workflows tosupport the credibility of individualized inference.</description><author>Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss, Rishi J. Desai</author><pubDate>Thu, 30 Oct 2025 17:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26700v1</guid></item><item><title>Guided Model Merging for Hybrid Data Learning: Leveraging Centralized Data to Refine Decentralized Models</title><link>http://arxiv.org/abs/2503.20138v2</link><description>Current network training paradigms primarily focus on either centralized ordecentralized data regimes. However, in practice, data availability oftenexhibits a hybrid nature, where both regimes coexist. This hybrid settingpresents new opportunities for model training, as the two regimes offercomplementary trade-offs: decentralized data is abundant but subject toheterogeneity and communication constraints, while centralized data, thoughlimited in volume and potentially unrepresentative, enables better curation andhigh-throughput access. Despite its potential, effectively combining theseparadigms remains challenging, and few frameworks are tailored to hybrid dataregimes. To address this, we propose a novel framework that constructs a modelatlas from decentralized models and leverages centralized data to refine aglobal model within this structured space. The refined model is then used toreinitialize the decentralized models. Our method synergizes federated learning(to exploit decentralized data) and model merging (to utilize centralizeddata), enabling effective training under hybrid data availability.Theoretically, we show that our approach achieves faster convergence thanmethods relying solely on decentralized data, due to variance reduction in themerging process. Extensive experiments demonstrate that our frameworkconsistently outperforms purely centralized, purely decentralized, and existinghybrid-adaptable methods. Notably, our method remains robust even when thecentralized and decentralized data domains differ or when decentralized datacontains noise, significantly broadening its applicability.</description><author>Junyi Zhu, Ruicong Yao, Taha Ceritli, Savas Ozkan, Matthew B. Blaschko, Eunchung Noh, Jeongwon Min, Cho Jung Min, Mete Ozay</author><pubDate>Thu, 30 Oct 2025 17:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.20138v2</guid></item><item><title>The End of Manual Decoding: Towards Truly End-to-End Language Models</title><link>http://arxiv.org/abs/2510.26697v1</link><description>The "end-to-end" label for LLMs is a misnomer. In practice, they depend on anon-differentiable decoding process that requires laborious, hand-tuning ofhyperparameters like temperature and top-p. This paper introduces AutoDeco, anovel architecture that enables truly "end-to-end" generation by learning tocontrol its own decoding strategy. We augment the standard transformer withlightweight heads that, at each step, dynamically predict context-specifictemperature and top-p values alongside the next-token logits. This approachtransforms decoding into a parametric, token-level process, allowing the modelto self-regulate its sampling strategy within a single forward pass. Through extensive experiments on eight benchmarks, we demonstrate thatAutoDeco not only significantly outperforms default decoding strategies butalso achieves performance comparable to an oracle-tuned baseline derived from"hacking the test set"-a practical upper bound for any static method.Crucially, we uncover an emergent capability for instruction-based decodingcontrol: the model learns to interpret natural language commands (e.g.,"generate with low randomness") and adjusts its predicted temperature and top-pon a token-by-token basis, opening a new paradigm for steerable and interactiveLLM decoding.</description><author>Zhichao Wang, Dongyang Ma, Xinting Huang, Deng Cai, Tian Lan, Jiahao Xu, Haitao Mi, Xiaoying Tang, Yan Wang</author><pubDate>Thu, 30 Oct 2025 17:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26697v1</guid></item><item><title>The Impact and Outlook of 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2510.26694v1</link><description>Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformedthe landscape of 3D scene representations, inspiring an extensive body ofassociated research. Follow-up work includes analyses and contributions thatenhance the efficiency, scalability, and real-world applicability of 3DGS. Inthis summary, we present an overview of several key directions that haveemerged in the wake of 3DGS. We highlight advances enabling resource-efficienttraining and rendering, the evolution toward dynamic (or four-dimensional,4DGS) representations, and deeper exploration of the mathematical foundationsunderlying its appearance modeling and rendering process. Furthermore, weexamine efforts to bring 3DGS to mobile and virtual reality platforms, itsextension to massive-scale environments, and recent progress towardnear-instant radiance field reconstruction via feed-forward or distributedcomputation. Collectively, these developments illustrate how 3DGS has evolvedfrom a breakthrough representation into a versatile and foundational tool for3D vision and graphics.</description><author>Bernhard Kerbl</author><pubDate>Thu, 30 Oct 2025 17:01:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26694v1</guid></item><item><title>Kimi Linear: An Expressive, Efficient Attention Architecture</title><link>http://arxiv.org/abs/2510.26692v1</link><description>We introduce Kimi Linear, a hybrid linear attention architecture that, forthe first time, outperforms full attention under fair comparisons acrossvarious scenarios -- including short-context, long-context, and reinforcementlearning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), anexpressive linear attention module that extends Gated DeltaNet with afiner-grained gating mechanism, enabling more effective use of limitedfinite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardwareefficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)transition matrices, which substantially reduces computation compared to thegeneral DPLR formulation while remaining more consistent with the classicaldelta rule. We pretrain a Kimi Linear model with 3B activated parameters and 48B totalparameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention(MLA). Our experiments show that with an identical training recipe, Kimi Linearoutperforms full MLA with a sizeable margin across all evaluated tasks, whilereducing KV cache usage by up to 75% and achieving up to 6 times decodingthroughput for a 1M context. These results demonstrate that Kimi Linear can bea drop-in replacement for full attention architectures with superiorperformance and efficiency, including tasks with longer input and outputlengths. To support further research, we open-source the KDA kernel and vLLMimplementations, and release the pre-trained and instruction-tuned modelcheckpoints.</description><author>Kimi Team, Yu Zhang, Zongyu Lin, Xingcheng Yao, Jiaxi Hu, Fanqing Meng, Chengyin Liu, Xin Men, Songlin Yang, Zhiyuan Li, Wentao Li, Enzhe Lu, Weizhou Liu, Yanru Chen, Weixin Xu, Longhui Yu, Yejie Wang, Yu Fan, Longguang Zhong, Enming Yuan, Dehao Zhang, Yizhi Zhang, T. Y. Liu, Haiming Wang, Shengjun Fang, Weiran He, Shaowei Liu, Yiwei Li, Jianlin Su, Jiezhong Qiu, Bo Pang, Junjie Yan, Zhejun Jiang, Weixiao Huang, Bohong Yin, Jiacheng You, Chu Wei, Zhengtao Wang, Chao Hong, Yutian Chen, Guanduo Chen, Yucheng Wang, Huabin Zheng, Feng Wang, Yibo Liu, Mengnan Dong, Zheng Zhang, Siyuan Pan, Wenhao Wu, Yuhao Wu, Longyu Guan, Jiawen Tao, Guohong Fu, Xinran Xu, Yuzhi Wang, Guokun Lai, Yuxin Wu, Xinyu Zhou, Zhilin Yang, Yulun Du</author><pubDate>Thu, 30 Oct 2025 16:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26692v1</guid></item><item><title>LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits</title><link>http://arxiv.org/abs/2510.26690v1</link><description>Low-Rank Adaptation (LoRA) has become a popular technique forparameter-efficient fine-tuning of large language models (LLMs). In manyreal-world scenarios, multiple adapters are loaded simultaneously to enable LLMcustomization for personalized user experiences or to support a diverse rangeof tasks. Although each adapter is lightweight in isolation, their aggregatecost becomes substantial at scale. To address this, we propose LoRAQuant, amixed-precision post-training quantization method tailored to LoRA.Specifically, LoRAQuant reparameterizes each adapter by singular valuedecomposition (SVD) to concentrate the most important information into specificrows and columns. This makes it possible to quantize the important componentsto higher precision, while quantizing the rest to ultra-low bitwidth. Weconduct comprehensive experiments with LLaMA 2-7B, LLaMA 2-13B, and Mistral 7Bmodels on mathematical reasoning, coding, and summarization tasks. Results showthat our LoRAQuant uses significantly lower bits than other quantizationmethods, but achieves comparable or even higher performance.</description><author>Amir Reza Mirzaei, Yuqiao Wen, Yanshuai Cao, Lili Mou</author><pubDate>Thu, 30 Oct 2025 16:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26690v1</guid></item><item><title>FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design</title><link>http://arxiv.org/abs/2510.26688v1</link><description>Designing efficient quantum circuits is a central bottleneck to exploring thepotential of quantum computing, particularly for noisy intermediate-scalequantum (NISQ) devices, where circuit efficiency and resilience to errors areparamount. The search space of gate sequences grows combinatorially, andhandcrafted templates often waste scarce qubit and depth budgets. We introduce\textsc{FlowQ-Net} (Flow-based Quantum design Network), a generative frameworkfor automated quantum circuit synthesis based on Generative Flow Networks(GFlowNets). This framework learns a stochastic policy to construct circuitssequentially, sampling them in proportion to a flexible, user-defined rewardfunction that can encode multiple design objectives such as performance, depth,and gate count. This approach uniquely enables the generation of a diverseensemble of high-quality circuits, moving beyond single-solution optimization.We demonstrate the efficacy of \textsc{FlowQ-Net} through an extensive set ofsimulations. We apply our method to Variational Quantum Algorithm (VQA) ansatzdesign for molecular ground state estimation, Max-Cut, and imageclassification, key challenges in near-term quantum computing. Circuitsdesigned by \textsc{FlowQ-Net} achieve significant improvements, yieldingcircuits that are 10$\times$-30$\times$ more compact in terms of parameters,gates, and depth compared to commonly used unitary baselines, withoutcompromising accuracy. This trend holds even when subjected to error profilesfrom real-world quantum devices. Our results underline the potential ofgenerative models as a general-purpose methodology for automated quantumcircuit design, offering a promising path towards more efficient quantumalgorithms and accelerating scientific discovery in the quantum domain.</description><author>Jun Dai, Michael Rizvi-Martel, Guillaume Rabusseau</author><pubDate>Thu, 30 Oct 2025 16:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26688v1</guid></item><item><title>Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill</title><link>http://arxiv.org/abs/2510.26684v1</link><description>We present a long-term deployment study of a machine vision-based anomalydetection system for failure prediction in a steel rolling mill. The systemintegrates industrial cameras to monitor equipment operation, alignment, andhot bar motion in real time along the process line. Live video streams areprocessed on a centralized video server using deep learning models, enablingearly prediction of equipment failures and process interruptions, therebyreducing unplanned breakdown costs. Server-based inference minimizes thecomputational load on industrial process control systems (PLCs), supportingscalable deployment across production lines with minimal additional resources.By jointly analyzing sensor data from data acquisition systems and visualinputs, the system identifies the location and probable root causes offailures, providing actionable insights for proactive maintenance. Thisintegrated approach enhances operational reliability, productivity, andprofitability in industrial manufacturing environments.</description><author>Vaibhav Kurrey, Sivakalyan Pujari, Gagan Raj Gupta</author><pubDate>Thu, 30 Oct 2025 16:54:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26684v1</guid></item><item><title>Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</title><link>http://arxiv.org/abs/2510.26683v1</link><description>Large language models (LLMs) have demonstrated exceptional capabilitiesacross multiple domains by leveraging massive pre-training and curatedfine-tuning data. However, in data-sensitive fields such as healthcare, thelack of high-quality, domain-specific training corpus hinders LLMs' adaptationfor specialized applications. Meanwhile, domain experts have distilled domainwisdom into ontology rules, which formalize relationships among concepts andensure the integrity of knowledge management repositories. Viewing LLMs asimplicit repositories of human knowledge, we propose Evontree, a novelframework that leverages a small set of high-quality ontology rules tosystematically extract, validate, and enhance domain knowledge within LLMs,without requiring extensive external datasets. Specifically, Evontree extractsdomain ontology from raw models, detects inconsistencies using two coreontology rules, and reinforces the refined knowledge via self-distilledfine-tuning. Extensive experiments on medical QA benchmarks withLlama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over bothunmodified models and leading supervised baselines, achieving up to a 3.7%improvement in accuracy. These results confirm the effectiveness, efficiency,and robustness of our approach for low-resource domain adaptation of LLMs.</description><author>Mingchen Tu, Zhiqiang Liu, Juan Li, Liangyurui Liu, Junjie Wang, Lei Liang, Wen Zhang</author><pubDate>Thu, 30 Oct 2025 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26683v1</guid></item><item><title>Improving Classification of Occluded Objects through Scene Context</title><link>http://arxiv.org/abs/2510.26681v1</link><description>The presence of occlusions has provided substantial challenges totypically-powerful object recognition algorithms. Additional sources ofinformation can be extremely valuable to reduce errors caused by occlusions.Scene context is known to aid in object recognition in biological vision. Inthis work, we attempt to add robustness into existing Region ProposalNetwork-Deep Convolutional Neural Network (RPN-DCNN) object detection networksthrough two distinct scene-based information fusion techniques. We present onealgorithm under each methodology: the first operates prior to prediction,selecting a custom object network to use based on the identified backgroundscene, and the second operates after detection, fusing scene knowledge intoinitial object scores output by the RPN. We demonstrate our algorithms onchallenging datasets featuring partial occlusions, which show overallimprovement in both recall and precision against baseline methods. In addition,our experiments contrast multiple training methodologies for occlusionhandling, finding that training on a combination of both occluded andunoccluded images demonstrates an improvement over the others. Our method isinterpretable and can easily be adapted to other datasets, offering many futuredirections for research and practical applications.</description><author>Courtney M. King, Daniel D. Leeds, Damian Lyons, George Kalaitzis</author><pubDate>Thu, 30 Oct 2025 16:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26681v1</guid></item><item><title>GSE: Group-wise Sparse and Explainable Adversarial Attacks</title><link>http://arxiv.org/abs/2311.17434v5</link><description>Sparse adversarial attacks fool deep neural networks (DNNs) through minimalpixel perturbations, often regularized by the $\ell_0$ norm. Recent effortshave replaced this norm with a structural sparsity regularizer, such as thenuclear group norm, to craft group-wise sparse adversarial attacks. Theresulting perturbations are thus explainable and hold significant practicalrelevance, shedding light on an even greater vulnerability of DNNs. However,crafting such attacks poses an optimization challenge, as it involves computingnorms for groups of pixels within a non-convex objective. We address this bypresenting a two-phase algorithm that generates group-wise sparse attackswithin semantically meaningful areas of an image. Initially, we optimize aquasinorm adversarial loss using the $1/2-$quasinorm proximal operator tailoredfor non-convex programming. Subsequently, the algorithm transitions to aprojected Nesterov's accelerated gradient descent with $2-$norm regularizationapplied to perturbation magnitudes. Rigorous evaluations on CIFAR-10 andImageNet datasets demonstrate a remarkable increase in group-wise sparsity,e.g., $50.9\%$ on CIFAR-10 and $38.4\%$ on ImageNet (average case, targetedattack). This performance improvement is accompanied by significantly fastercomputation times, improved explainability, and a $100\%$ attack success rate.</description><author>Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta</author><pubDate>Thu, 30 Oct 2025 16:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17434v5</guid></item><item><title>Tight Differentially Private PCA via Matrix Coherence</title><link>http://arxiv.org/abs/2510.26679v1</link><description>We revisit the task of computing the span of the top $r$ singular vectors$u_1, \ldots, u_r$ of a matrix under differential privacy. We show that asimple and efficient algorithm -- based on singular value decomposition andstandard perturbation mechanisms -- returns a private rank-$r$ approximationwhose error depends only on the \emph{rank-$r$ coherence} of $u_1, \ldots, u_r$and the spectral gap $\sigma_r - \sigma_{r+1}$. This resolves a question posedby Hardt and Roth~\cite{hardt2013beyond}. Our estimator outperforms the stateof the art -- significantly so in some regimes. In particular, we show that inthe dense setting, it achieves the same guarantees for single-spike PCA in theWishart model as those attained by optimal non-private algorithms, whereasprior private algorithms failed to do so. In addition, we prove that (rank-$r$) coherence does not increase underGaussian perturbations. This implies that any estimator based on the Gaussianmechanism -- including ours -- preserves the coherence of the input. Weconjecture that similar behavior holds for other structured models, includingplanted problems in graphs. We also explore applications of coherence to graph problems. In particular,we present a differentially private algorithm for Max-Cut and other constraintsatisfaction problems under low coherence assumptions.</description><author>Tommaso d'Orsi, Gleb Novikov</author><pubDate>Thu, 30 Oct 2025 16:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26679v1</guid></item><item><title>Neural active manifolds: nonlinear dimensionality reduction for uncertainty quantification</title><link>http://arxiv.org/abs/2408.03534v2</link><description>We present a new approach for nonlinear dimensionality reduction,specifically designed for computationally expensive mathematical models. Weleverage autoencoders to discover a one-dimensional neural active manifold(NeurAM) capturing the model output variability, through the aid of asimultaneously learnt surrogate model with inputs on this manifold. Our methodonly relies on model evaluations and does not require the knowledge ofgradients. The proposed dimensionality reduction framework can then be appliedto assist outer loop many-query tasks in scientific computing, like sensitivityanalysis and multifidelity uncertainty propagation. In particular, we prove,both theoretically under idealized conditions, and numerically in challengingtest cases, how NeurAM can be used to obtain multifidelity sampling estimatorswith reduced variance by sampling the models on the discovered low-dimensionaland shared manifold among models. Several numerical examples illustrate themain features of the proposed dimensionality reduction strategy and highlightits advantages with respect to existing approaches in the literature.</description><author>Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Alison L. Marsden, Daniele E. Schiavazzi</author><pubDate>Thu, 30 Oct 2025 16:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03534v2</guid></item><item><title>Resource Efficient Multi-stain Kidney Glomeruli Segmentation via Self-supervision</title><link>http://arxiv.org/abs/2412.15389v3</link><description>Semantic segmentation under domain shift remains a fundamental challenge incomputer vision, particularly when labelled training data is scarce. Thischallenge is particularly exemplified in histopathology image analysis, wherethe same tissue structures must be segmented across images captured underdifferent imaging conditions (stains), each representing a distinct visualdomain. Traditional deep learning methods like UNet require extensive labels,which is both costly and time-consuming, particularly when dealing withmultiple domains (or stains). To mitigate this, various unsupervised domainadaptation based methods such as UDAGAN have been proposed, which reduce theneed for labels by requiring only one (source) stain to be labelled.Nonetheless, obtaining source stain labels can still be challenging. Thisarticle shows that through self-supervised pre-training -- including SimCLR,BYOL, and a novel approach, HR-CS-CO -- the performance of these segmentationmethods (UNet, and UDAGAN) can be retained even with 95% fewer labels. Notably,with self-supervised pre-training and using only 5% labels, the performancedrops are minimal: 5.9% for UNet and 6.2% for UDAGAN, averaged over all stains,compared to their respective fully supervised counterparts (withoutpre-training, using 100% labels). Furthermore, these findings are shown togeneralise beyond their training distribution to public benchmark datasets.Implementations and pre-trained models are publicly available\href{https://github.com/zeeshannisar/resource-effecient-multi-stain-kidney-glomeruli-segmentation.git}{online}.</description><author>Zeeshan Nisar, Friedrich Feuerhake, Thomas Lampert</author><pubDate>Thu, 30 Oct 2025 16:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15389v3</guid></item><item><title>Action-Driven Processes for Continuous-Time Control</title><link>http://arxiv.org/abs/2510.26672v1</link><description>At the heart of reinforcement learning are actions -- decisions made inresponse to observations of the environment. Actions are equally fundamental inthe modeling of stochastic processes, as they trigger discontinuous statetransitions and enable the flow of information through large, complex systems.In this paper, we unify the perspectives of stochastic processes andreinforcement learning through action-driven processes, and illustrate theirapplication to spiking neural networks. Leveraging ideas fromcontrol-as-inference, we show that minimizing the Kullback-Leibler divergencebetween a policy-driven true distribution and a reward-driven modeldistribution for a suitably defined action-driven process is equivalent tomaximum entropy reinforcement learning.</description><author>Ruimin He, Shaowei Lin</author><pubDate>Thu, 30 Oct 2025 16:42:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26672v1</guid></item><item><title>CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling</title><link>http://arxiv.org/abs/2506.19816v2</link><description>Recent vision-language-action (VLA) models built on pretrainedvision-language models (VLMs) have demonstrated strong performance in roboticmanipulation. However, these models remain constrained by the single-frameimage paradigm and fail to fully leverage the temporal information offered bymulti-frame histories, as directly feeding multiple frames into VLM backbonesincurs substantial computational overhead and inference latency. We proposeCronusVLA, a unified framework that extends single-frame VLA models to themulti-frame paradigm. CronusVLA follows a two-stage process: (1) Single-framepretraining on large-scale embodied datasets with autoregressive prediction ofaction tokens, establishing an effective embodied vision-language foundation;(2) Multi-frame post-training, which adapts the prediction of thevision-language backbone from discrete tokens to learnable features, andaggregates historical information via feature chunking. CronusVLA effectivelyaddresses the existing challenges of multi-frame modeling while enhancingperformance and observational robustness. To evaluate the robustness undertemporal and spatial disturbances, we introduce SimplerEnv-OR, a novelbenchmark featuring 24 types of observational disturbances and 120 severitylevels. Experiments across three embodiments in simulated and real-worldenvironments demonstrate that CronusVLA achieves leading performance andsuperior robustness, with a 70.9% success rate on SimplerEnv, a 26.8%improvement over OpenVLA on LIBERO, and the highest robustness score onSimplerEnv-OR. These results highlight the potential of efficient multi-frameadaptation in VLA models for more powerful and robust real-world deployment.</description><author>Hao Li, Shuai Yang, Yilun Chen, Xinyi Chen, Xiaoda Yang, Yang Tian, Hanqing Wang, Tai Wang, Dahua Lin, Feng Zhao, Jiangmiao Pang</author><pubDate>Thu, 30 Oct 2025 16:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.19816v2</guid></item><item><title>Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning</title><link>http://arxiv.org/abs/2508.01543v2</link><description>Large Language Models (LLMs) have demonstrated remarkable progress throughpreference-based fine-tuning, which critically depends on the quality of theunderlying training data. While human feedback is essential for improving dataquality, it is costly and does not scale well. In this paper, we introduceRefine-n-Judge, an automated iterative approach that leverages a single LLM asboth a refiner and a judge to enhance dataset quality. Unlike existingiterative refinement methods, Refine-n-Judge employs an LLM to both generaterefinements and explicitly evaluate each improvement, ensuring that everyiteration meaningfully enhances the dataset without requiring additional humanannotation or a separate reward model. At each step, the LLM refines a responseand judges whether the refinement is an improvement over the previous answer.This process continues until the LLM prefers the initial answer over therefinement, indicating no further improvements. This produces sequences ofincreasing quality, preference-labeled responses ideal for fine-tuning. We demonstrate the effectiveness of Refine-n-Judge across a range of publicdatasets spanning five corpora, targeting tasks such as coding, math, andconversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned onRefine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% ofcomparisons against models tuned on the original dataset by GPT-4.Additionally, we report performance gains: +5% on AlpacaEval and AlpacaEval2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produceshigh-quality datasets and scalable model improvements.</description><author>Derin Cayir, Renjie Tao, Rashi Rungta, Kai Sun, Sean Chen, Haidar Khan, Minseok Kim, Julia Reinspach, Yue Liu</author><pubDate>Thu, 30 Oct 2025 16:32:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.01543v2</guid></item><item><title>BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI</title><link>http://arxiv.org/abs/2510.26661v1</link><description>Assessing the severity of artifacts in pediatric brain Magnetic ResonanceImaging (MRI) is critical for diagnostic accuracy, especially in low-fieldsystems where the signal-to-noise ratio is reduced. Manual quality assessmentis time-consuming and subjective, motivating the need for robust automatedsolutions. In this work, we propose BRIQA (Balanced Reweighting in ImageQuality Assessment), which addresses class imbalance in artifact severitylevels. BRIQA uses gradient-based loss reweighting to dynamically adjustper-class contributions and employs a rotating batching scheme to ensureconsistent exposure to underrepresented classes. Through experiments, no singlearchitecture performs best across all artifact types, emphasizing theimportance of architectural diversity. The rotating batching configurationimproves performance across metrics by promoting balanced learning whencombined with cross-entropy loss. BRIQA improves average macro F1 score from0.659 to 0.706, with notable gains in Noise (0.430), Zipper (0.098),Positioning (0.097), Contrast (0.217), Motion (0.022), and Banding (0.012)artifact severity classification. The code is available athttps://github.com/BioMedIA-MBZUAI/BRIQA.</description><author>Alya Almsouti, Ainur Khamitova, Darya Taratynova, Mohammad Yaqub</author><pubDate>Thu, 30 Oct 2025 16:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26661v1</guid></item><item><title>CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting</title><link>http://arxiv.org/abs/2507.21257v2</link><description>Language interpretation is a compositional process, in which the meaning ofmore complex linguistic structures is inferred from the meaning of their parts.Large language models possess remarkable language interpretation capabilitiesand have been successfully applied to interpret questions by mapping them toSPARQL queries. An open question is how systematic this interpretation processis. Toward this question, in this paper, we propose a benchmark forinvestigating to what extent the abilities of LLMs to interpret questions areactually compositional. For this, we generate three datasets of varyingdifficulty based on graph patterns in DBpedia, relying on Lemon lexica forverbalization. Our datasets are created in a very controlled fashion in orderto test the ability of LLMs to interpret structurally complex questions, giventhat they have seen the atomic building blocks. This allows us to evaluate towhat degree LLMs are able to interpret complex questions for which they"understand" the atomic parts. We conduct experiments with models of differentsizes using both various prompt and few-shot optimization techniques as well asfine-tuning. Our results show that performance in terms of macro $F_1$ degradesfrom $0.45$ over $0.26$ down to $0.09$ with increasing deviation from thesamples optimized on. Even when all necessary information was provided to themodel in the input, the $F_1$ scores do not exceed $0.57$ for the dataset oflowest complexity. We thus conclude that LLMs struggle to systematically andcompositionally interpret questions and map them into SPARQL queries.</description><author>David Maria Schmidt, Raoul Schubert, Philipp Cimiano</author><pubDate>Thu, 30 Oct 2025 16:25:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.21257v2</guid></item><item><title>The Era of Agentic Organization: Learning to Organize with Language Models</title><link>http://arxiv.org/abs/2510.26658v1</link><description>We envision a new era of AI, termed agentic organization, where agents solvecomplex problems by working collaboratively and concurrently, enabling outcomesbeyond individual intelligence. To realize this vision, we introduceasynchronous thinking (AsyncThink) as a new paradigm of reasoning with largelanguage models, which organizes the internal thinking process intoconcurrently executable structures. Specifically, we propose a thinkingprotocol where an organizer dynamically assigns sub-queries to workers, mergesintermediate knowledge, and produces coherent solutions. More importantly, thethinking structure in this protocol can be further optimized throughreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%lower inference latency compared to parallel thinking while improving accuracyon mathematical reasoning. Moreover, AsyncThink generalizes its learnedasynchronous thinking capabilities, effectively tackling unseen tasks withoutadditional training.</description><author>Zewen Chi, Li Dong, Qingxiu Dong, Yaru Hao, Xun Wu, Shaohan Huang, Furu Wei</author><pubDate>Thu, 30 Oct 2025 16:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26658v1</guid></item><item><title>Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution</title><link>http://arxiv.org/abs/2508.15840v3</link><description>When using a public communication channel -- whether formal or informal, suchas commenting or posting on social media -- end users have no expectation ofprivacy: they compose a message and broadcast it for the world to see. Even ifan end user takes utmost precautions to anonymize their online presence --using an alias or pseudonym; masking their IP address; spoofing theirgeolocation; concealing their operating system and user agent; deployingencryption; registering with a disposable phone number or email; disablingnon-essential settings; revoking permissions; and blocking cookies andfingerprinting -- one obvious element still lingers: the message itself.Assuming they avoid lapses in judgment or accidental self-exposure, thereshould be little evidence to validate their actual identity, right? Wrong. Thecontent of their message -- necessarily open for public consumption -- exposesan attack vector: stylometric analysis, or author profiling. In this paper, wedissect the technique of stylometry, discuss an antithetical counter-strategyin adversarial stylometry, and devise enhancements through Unicodesteganography.</description><author>Robert Dilworth</author><pubDate>Thu, 30 Oct 2025 16:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.15840v3</guid></item><item><title>Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems</title><link>http://arxiv.org/abs/2510.26656v1</link><description>In robotics, likelihood-free inference (LFI) can provide the domaindistribution that adapts a learnt agent in a parametric set of deploymentconditions. LFI assumes an arbitrary support for sampling, which remainsconstant as the initial generic prior is iteratively refined to moredescriptive posteriors. However, a potentially misspecified support can lead tosuboptimal, yet falsely certain, posteriors. To address this issue, we proposethree heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets theposterior mode shift over inference steps in its own way and, when integratedinto an LFI step, adapts the support alongside posterior inference. We firstexpose the support misspecification issue and evaluate our heuristics usingstochastic dynamical benchmarks. We then evaluate the impact of heuristicsupport adaptation on parameter inference and policy learning for a dynamicdeformable linear object (DLO) manipulation task. Inference results in a finerlength and stiffness classification for a parametric set of DLOs. When theresulting posteriors are used as domain distributions for sim-based policylearning, they lead to more robust object-centric agent performance.</description><author>Georgios Kamaras, Craig Innes, Subramanian Ramamoorthy</author><pubDate>Thu, 30 Oct 2025 16:23:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26656v1</guid></item><item><title>Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2</title><link>http://arxiv.org/abs/2510.26653v1</link><description>Accurate estimation of sea ice drift is critical for Arctic navigation,climate research, and operational forecasting. While optical flow, a computervision technique for estimating pixel wise motion between consecutive images,has advanced rapidly in computer vision, its applicability to geophysicalproblems and to satellite SAR imagery remains underexplored. Classical opticalflow methods rely on mathematical models and strong assumptions about motion,which limit their accuracy in complex scenarios. Recent deep learning basedapproaches have substantially improved performance and are now the standard incomputer vision, motivating their application to sea ice drift estimation. Wepresent the first large scale benchmark of 48 deep learning optical flow modelson RADARSAT 2 ScanSAR sea ice imagery, evaluated with endpoint error (EPE) andFl all metrics against GNSS tracked buoys. Several models achieve sub kilometeraccuracy (EPE 6 to 8 pixels, 300 to 400 m), a small error relative to thespatial scales of sea ice motion and typical navigation requirements in theArctic. Our results demonstrate that the models are capable of capturingconsistent regional drift patterns and that recent deep learning based opticalflow methods, which have substantially improved motion estimation accuracycompared to classical methods, can be effectively transferred to polar remotesensing. Optical flow produces spatially continuous drift fields, providingmotion estimates for every image pixel rather than at sparse buoy locations,offering new opportunities for navigation and climate modeling.</description><author>Daniela Martin, Joseph Gallego</author><pubDate>Thu, 30 Oct 2025 16:20:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26653v1</guid></item><item><title>Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments</title><link>http://arxiv.org/abs/2510.26646v1</link><description>This paper presents a hierarchical path-planning and control framework thatcombines a high-level Deep Q-Network (DQN) for discrete sub-goal selection witha low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controllerfor continuous actuation. The high-level module selects behaviors andsub-goals; the low-level module executes smooth velocity commands. We design apractical reward shaping scheme (direction, distance, obstacle avoidance,action smoothness, collision penalty, time penalty, and progress), togetherwith a LiDAR-based safety gate that prevents unsafe motions. The system isimplemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,including success rate, collision rate, path efficiency, and re-planningefficiency, in dynamic and partially observable environments. Experiments showimproved success rate and sample efficiency over single-algorithm baselines(DQN or TD3 alone) and rule-based planners, with better generalization tounseen obstacle configurations and reduced abrupt control changes. Code andevaluation scripts are available at the project repository.</description><author>Xiaoyi He, Danggui Chen, Zhenshuo Zhang, Zimeng Bai</author><pubDate>Thu, 30 Oct 2025 16:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26646v1</guid></item><item><title>Curly Flow Matching for Learning Non-gradient Field Dynamics</title><link>http://arxiv.org/abs/2510.26645v1</link><description>Modeling the transport dynamics of natural processes from population-levelobservations is a ubiquitous problem in the natural sciences. Such models relyon key assumptions about the underlying process in order to enable faithfullearning of governing dynamics that mimic the actual system behavior. The defacto assumption in current approaches relies on the principle of least actionthat results in gradient field dynamics and leads to trajectories minimizing anenergy functional between two probability measures. However, many real-worldsystems, such as cell cycles in single-cell RNA, are known to exhibitnon-gradient, periodic behavior, which fundamentally cannot be captured bycurrent state-of-the-art methods such as flow and bridge matching. In thispaper, we introduce Curly Flow Matching (Curly-FM), a novel approach that iscapable of learning non-gradient field dynamics by designing and solving aSchr\"odinger bridge problem with a non-zero drift reference process -- instark contrast to typical zero-drift reference processes -- which isconstructed using inferred velocities in addition to population snapshot data.We showcase Curly-FM by solving the trajectory inference problems for singlecells, computational fluid dynamics, and ocean currents with approximatevelocities. We demonstrate that Curly-FM can learn trajectories that bettermatch both the reference process and population marginals. Curly-FM expandsflow matching models beyond the modeling of populations and towards themodeling of known periodic behavior in physical systems. Our code repository isaccessible at: https://github.com/kpetrovicc/curly-flow-matching.git</description><author>Katarina Petrović, Lazar Atanackovic, Viggo Moro, Kacper Kapuśniak, İsmail İlkan Ceylan, Michael Bronstein, Avishek Joey Bose, Alexander Tong</author><pubDate>Thu, 30 Oct 2025 16:11:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26645v1</guid></item><item><title>Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media</title><link>http://arxiv.org/abs/2510.14889v2</link><description>On social media, many individuals experiencing suicidal ideation (SI) do notdisclose their distress explicitly. Instead, signs may surface indirectlythrough everyday posts or peer interactions. Detecting such implicit signalsearly is critical but remains challenging. We frame early and implicit SI as aforward-looking prediction task and develop a computational framework thatmodels a user's information environment, consisting of both their longitudinalposting histories as well as the discourse of their socially proximal peers. Weadopted a composite network centrality measure to identify top neighbors of auser, and temporally aligned the user's and neighbors' interactions --integrating the multi-layered signals in a fine-tuned DeBERTa-v3 model. In aReddit study of 1,000 (500 Case and 500 Control) users, our approach improvesearly and implicit SI detection by 15% over individual-only baselines. Thesefindings highlight that peer interactions offer valuable predictive signals andcarry broader implications for designing early detection systems that captureindirect as well as masked expressions of risk in online environments.</description><author>Soorya Ram Shimgekar, Ruining Zhao, Agam Goyal, Violeta J. Rodriguez, Paul A. Bloom, Hari Sundaram, Koustuv Saha</author><pubDate>Thu, 30 Oct 2025 16:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.14889v2</guid></item><item><title>MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection</title><link>http://arxiv.org/abs/2510.26643v1</link><description>Anomaly detection is a fundamental task for time series analytics withimportant implications for the downstream performance of many applications.Despite increasing academic interest and the large number of methods proposedin the literature, recent benchmarks and evaluation studies demonstrated thatno overall best anomaly detection methods exist when applied to veryheterogeneous time series datasets. Therefore, the only scalable and viablesolution to solve anomaly detection over very different time series collectedfrom diverse domains is to propose a model selection method that will select,based on time series characteristics, the best anomaly detection methods torun. Existing AutoML solutions are, unfortunately, not directly applicable totime series anomaly detection, and no evaluation of time series-basedapproaches for model selection exists. Towards that direction, this paperstudies the performance of time series classification methods used as modelselection for anomaly detection. In total, we evaluate 234 model configurationsderived from 16 base classifiers across more than 1980 time series, and wepropose the first extensive experimental evaluation of time seriesclassification as model selection for anomaly detection. Our resultsdemonstrate that model selection methods outperform every single anomalydetection method while being in the same order of magnitude regarding executiontime. This evaluation is the first step to demonstrate the accuracy andefficiency of time series classification algorithms for anomaly detection, andrepresents a strong baseline that can then be used to guide the model selectionstep in general AutoML pipelines. Preprint version of an article accepted atthe VLDB Journal.</description><author>Emmanouil Sylligardos, John Paparrizos, Themis Palpanas, Pierre Senellart, Paul Boniol</author><pubDate>Thu, 30 Oct 2025 16:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26643v1</guid></item><item><title>All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles</title><link>http://arxiv.org/abs/2510.26641v1</link><description>Autonomous Vehicles (AVs) are transforming the future of transportationthrough advances in intelligent perception, decision-making, and controlsystems. However, their success is tied to one core capability, reliable objectdetection in complex and multimodal environments. While recent breakthroughs inComputer Vision (CV) and Artificial Intelligence (AI) have driven remarkableprogress, the field still faces a critical challenge as knowledge remainsfragmented across multimodal perception, contextual reasoning, and cooperativeintelligence. This survey bridges that gap by delivering a forward-lookinganalysis of object detection in AVs, emphasizing emerging paradigms such asVision-Language Models (VLMs), Large Language Models (LLMs), and Generative AIrather than re-examining outdated techniques. We begin by systematicallyreviewing the fundamental spectrum of AV sensors (camera, ultrasonic, LiDAR,and Radar) and their fusion strategies, highlighting not only theircapabilities and limitations in dynamic driving environments but also theirpotential to integrate with recent advances in LLM/VLM-driven perceptionframeworks. Next, we introduce a structured categorization of AV datasets thatmoves beyond simple collections, positioning ego-vehicle, infrastructure-based,and cooperative datasets (e.g., V2V, V2I, V2X, I2I), followed by across-analysis of data structures and characteristics. Ultimately, we analyzecutting-edge detection methodologies, ranging from 2D and 3D pipelines tohybrid sensor fusion, with particular attention to emerging transformer-drivenapproaches powered by Vision Transformers (ViTs), Large and Small LanguageModels (SLMs), and VLMs. By synthesizing these perspectives, our surveydelivers a clear roadmap of current capabilities, open challenges, and futureopportunities.</description><author>Sayed Pedram Haeri Boroujeni, Niloufar Mehrabi, Hazim Alzorgan, Ahmad Sarlak, Mahlagha Fazeli, Abolfazl Razi</author><pubDate>Thu, 30 Oct 2025 16:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26641v1</guid></item><item><title>Understanding Generalization in Node and Link Prediction</title><link>http://arxiv.org/abs/2507.00927v3</link><description>Using message-passing graph neural networks (MPNNs) for node and linkprediction is crucial in various scientific and industrial domains, which hasled to the development of diverse MPNN architectures. Besides working well inpractical settings, their ability to generalize beyond the training set remainspoorly understood. While some studies have explored MPNNs' generalization ingraph-level prediction tasks, much less attention has been given to node- andlink-level predictions. Existing works often rely on unrealistic i.i.d.\@assumptions, overlooking possible correlations between nodes or links, andassuming fixed aggregation and impractical loss functions while neglecting theinfluence of graph structure. In this work, we introduce a unified framework toanalyze the generalization properties of MPNNs in inductive and transductivenode and link prediction settings, incorporating diverse architecturalparameters and loss functions and quantifying the influence of graph structure.Additionally, our proposed generalization framework can be applied beyondgraphs to any classification task under the inductive or transductive setting.Our empirical study supports our theoretical insights, deepening ourunderstanding of MPNNs' generalization capabilities in these tasks.</description><author>Antonis Vasileiou, Timo Stoll, Christopher Morris</author><pubDate>Thu, 30 Oct 2025 16:05:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.00927v3</guid></item><item><title>SAMRI: Segment Anything Model for MRI</title><link>http://arxiv.org/abs/2510.26635v1</link><description>Accurate magnetic resonance imaging (MRI) segmentation is crucial forclinical decision-making, but remains labor-intensive when performed manually.Convolutional neural network (CNN)-based methods can be accurate and efficient,but often generalize poorly to MRI's variable contrast, intensityinhomogeneity, and protocols. Although the transformer-based Segment AnythingModel (SAM) has demonstrated remarkable generalizability in natural images,existing adaptations often treat MRI as another imaging modality, overlookingthese modality-specific challenges. We present SAMRI, an MRI-specialized SAMtrained and validated on 1.1 million labeled MR slices spanning whole-bodyorgans and pathologies. We demonstrate that SAM can be effectively adapted toMRI by simply fine-tuning its mask decoder using a two-stage strategy, reducingtraining time by 94% and trainable parameters by 96% versus full-modelretraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Diceof 0.87, delivering state-of-the-art accuracy across anatomical regions androbust generalization on unseen structures, particularly small and clinicallyimportant structures.</description><author>Zhao Wang, Wei Dai, Thuy Thanh Dao, Steffen Bollmann, Hongfu Sun, Craig Engstrom, Shekhar S. Chandra</author><pubDate>Thu, 30 Oct 2025 16:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26635v1</guid></item><item><title>Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization</title><link>http://arxiv.org/abs/2510.26633v1</link><description>Bayesian Optimization (BO) has the potential to solve various combinatorialtasks, ranging from materials science to neural architecture search. However,BO requires specialized kernels to effectively model combinatorial domains.Recent efforts have introduced several combinatorial kernels, but therelationships among them are not well understood. To bridge this gap, wedevelop a unifying framework based on heat kernels, which we derive in asystematic way and express as simple closed-form expressions. Using thisframework, we prove that many successful combinatorial kernels are eitherrelated or equivalent to heat kernels, and validate this theoretical claim inour experiments. Moreover, our analysis confirms and extends the resultspresented in Bounce: certain algorithms' performance decreases substantiallywhen the unknown optima of the function do not have a certain structure. Incontrast, heat kernels are not sensitive to the location of the optima. Lastly,we show that a fast and simple pipeline, relying on heat kernels, is able toachieve state-of-the-art results, matching or even outperforming certain slowor complex algorithms.</description><author>Colin Doumont, Victor Picheny, Viacheslav Borovitskiy, Henry Moss</author><pubDate>Thu, 30 Oct 2025 16:02:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26633v1</guid></item><item><title>Fit for Purpose? Deepfake Detection in the Real World</title><link>http://arxiv.org/abs/2510.16556v2</link><description>The rapid proliferation of AI-generated content, driven by advances ingenerative adversarial networks, diffusion models, and multimodal largelanguage models, has made the creation and dissemination of synthetic mediaeffortless, heightening the risks of misinformation, particularly politicaldeepfakes that distort truth and undermine trust in political institutions. Inturn, governments, research institutions, and industry have strongly promoteddeepfake detection initiatives as solutions. Yet, most existing models aretrained and validated on synthetic, laboratory-controlled datasets, limitingtheir generalizability to the kinds of real-world political deepfakescirculating on social platforms that affect the public. In this work, weintroduce the first systematic benchmark based on the Political DeepfakesIncident Database, a curated collection of real-world political deepfakesshared on social media since 2018. Our study includes a systematic evaluationof state-of-the-art deepfake detectors across academia, government, andindustry. We find that the detectors from academia and government performrelatively poorly. While paid detection tools achieve relatively higherperformance than free-access models, all evaluated detectors struggle togeneralize effectively to authentic political deepfakes, and are vulnerable tosimple manipulations, especially in the video domain. Results urge the need forpolitically contextualized deepfake detection frameworks to better safeguardthe public in real-world settings.</description><author>Guangyu Lin, Li Lin, Christina P. Walker, Daniel S. Schiff, Shu Hu</author><pubDate>Thu, 30 Oct 2025 16:01:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.16556v2</guid></item><item><title>RelP: Faithful and Efficient Circuit Discovery in Language Models via Relevance Patching</title><link>http://arxiv.org/abs/2508.21258v2</link><description>Activation patching is a standard method in mechanistic interpretability forlocalizing the components of a model responsible for specific behaviors, but itis computationally expensive to apply at scale. Attribution patching offers afaster, gradient-based approximation, yet suffers from noise and reducedreliability in deep, highly non-linear networks. In this work, we introduceRelevance Patching (RelP), which replaces the local gradients in attributionpatching with propagation coefficients derived from Layer-wise RelevancePropagation (LRP). LRP propagates the network's output backward through thelayers, redistributing relevance to lower-level components according to localpropagation rules that ensure properties such as relevance conservation orimproved signal-to-noise ratio. Like attribution patching, RelP requires onlytwo forward passes and one backward pass, maintaining computational efficiencywhile improving faithfulness. We validate RelP across a range of models andtasks, showing that it more accurately approximates activation patching thanstandard attribution patching, particularly when analyzing residual stream andMLP outputs in the Indirect Object Identification (IOI) task. For instance, forMLP outputs in GPT-2 Large, attribution patching achieves a Pearson correlationof 0.006, whereas RelP reaches 0.956, highlighting the improvement offered byRelP. Additionally, we compare the faithfulness of sparse feature circuitsidentified by RelP and Integrated Gradients (IG), showing that RelP achievescomparable faithfulness without the extra computational cost associated withIG.</description><author>Farnoush Rezaei Jafari, Oliver Eberle, Ashkan Khakzar, Neel Nanda</author><pubDate>Thu, 30 Oct 2025 16:01:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.21258v2</guid></item><item><title>PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus</title><link>http://arxiv.org/abs/2510.26630v1</link><description>To address the challenges in UAV object detection, such as complexbackgrounds, severe occlusion, dense small objects, and varying lightingconditions,this paper proposes PT-DETR based on RT-DETR, a novel detectionalgorithm specifically designed for small objects in UAV imagery. In thebackbone network, we introduce the Partially-Aware Detail Focus (PADF) Moduleto enhance feature extraction for small objects. Additionally,we design theMedian-Frequency Feature Fusion (MFFF) module,which effectively improves themodel's ability to capture small-object details and contextual information.Furthermore,we incorporate Focaler-SIoU to strengthen the model's bounding boxmatching capability and increase its sensitivity to small-object features,thereby further enhancing detection accuracy and robustness. Compared withRT-DETR, our PT-DETR achieves mAP improvements of 1.6% and 1.7% on theVisDrone2019 dataset with lower computational complexity and fewer parameters,demonstrating its robustness and feasibility for small-object detection tasks.</description><author>Bingcong Huo, Zhiming Wang</author><pubDate>Thu, 30 Oct 2025 15:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26630v1</guid></item><item><title>DDL: A Large-Scale Datasets for Deepfake Detection and Localization in Diversified Real-World Scenarios</title><link>http://arxiv.org/abs/2506.23292v2</link><description>Recent advances in AIGC have exacerbated the misuse of malicious deepfakecontent, making the development of reliable deepfake detection methods anessential means to address this challenge. Although existing deepfake detectionmodels demonstrate outstanding performance in detection metrics, most methodsonly provide simple binary classification results, lacking interpretability.Recent studies have attempted to enhance the interpretability of classificationresults by providing spatial manipulation masks or temporal forgery segments.However, due to the limitations of forgery datasets, the practicaleffectiveness of these methods remains suboptimal. The primary reason lies inthe fact that most existing deepfake datasets contain only binary labels, withlimited variety in forgery scenarios, insufficient diversity in deepfake types,and relatively small data scales, making them inadequate for complex real-worldscenarios.To address this predicament, we construct a novel large-scaledeepfake detection and localization (\textbf{DDL}) dataset containing over$\textbf{1.4M+}$ forged samples and encompassing up to $\textbf{80}$ distinctdeepfake methods. The DDL design incorporates four key innovations: (1)\textbf{Comprehensive Deepfake Methods} (covering 7 different generationarchitectures and a total of 80 methods), (2) \textbf{Varied ManipulationModes} (incorporating 7 classic and 3 novel forgery modes), (3) \textbf{DiverseForgery Scenarios and Modalities} (including 3 scenarios and 3 modalities), and(4) \textbf{Fine-grained Forgery Annotations} (providing 1.18M+ precise spatialmasks and 0.23M+ precise temporal segments).Through these improvements, our DDLnot only provides a more challenging benchmark for complex real-world forgeriesbut also offers crucial support for building next-generation deepfakedetection, localization, and interpretability methods.</description><author>Changtao Miao, Yi Zhang, Weize Gao, Zhiya Tan, Weiwei Feng, Man Luo, Jianshu Li, Ajian Liu, Yunfeng Diao, Qi Chu, Tao Gong, Zhe Li, Weibin Yao, Joey Tianyi Zhou</author><pubDate>Thu, 30 Oct 2025 15:53:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.23292v2</guid></item><item><title>Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model</title><link>http://arxiv.org/abs/2510.26622v1</link><description>Recent large language model (LLM) research has undergone an architecturalshift from encoder-decoder modeling to nowadays the dominant decoder-onlymodeling. This rapid transition, however, comes without a rigorous comparativeanalysis especially \textit{from the scaling perspective}, raising concernsthat the potential of encoder-decoder models may have been overlooked. To fillthis gap, we revisit encoder-decoder LLM (RedLLM), enhancing it with recentrecipes from decoder-only LLM (DecLLM). We conduct a comprehensive comparisonbetween RedLLM, pretrained with prefix language modeling (LM), and DecLLM,pretrained with causal LM, at different model scales, ranging from $\sim$150Mto $\sim$8B. Using RedPajama V1 (1.6T tokens) for pretraining and FLAN forinstruction tuning, our experiments show that RedLLM produces compellingscaling properties and surprisingly strong performance. While DecLLM is overallmore compute-optimal during pretraining, RedLLM demonstrates comparable scalingand context length extrapolation capabilities. After instruction tuning, RedLLMachieves comparable and even better results on various downstream tasks whileenjoying substantially better inference efficiency. We hope our findings couldinspire more efforts on re-examining RedLLM, unlocking its potential fordeveloping powerful and efficient LLMs.</description><author>Biao Zhang, Yong Cheng, Siamak Shakeri, Xinyi Wang, Min Ma, Orhan Firat</author><pubDate>Thu, 30 Oct 2025 15:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26622v1</guid></item><item><title>PepCompass: Navigating peptide embedding spaces using Riemannian Geometry</title><link>http://arxiv.org/abs/2510.01988v3</link><description>Antimicrobial peptide discovery is challenged by the astronomical size ofpeptide space and the relative scarcity of active peptides. Generative modelsprovide continuous latent "maps" of peptide space, but conventionally ignoredecoder-induced geometry and rely on flat Euclidean metrics, renderingexploration and optimization distorted and inefficient. Prior manifold-basedremedies assume fixed intrinsic dimensionality, which critically fails inpractice for peptide data. Here, we introduce PepCompass, a geometry-awareframework for peptide exploration and optimization. At its core, we define aUnion of $\kappa$-Stable Riemannian Manifolds $\mathbb{M}^{\kappa}$, a familyof decoder-induced manifolds that captures local geometry while ensuringcomputational stability. We propose two local exploration methods: Second-OrderRiemannian Brownian Efficient Sampling, which provides a convergentsecond-order approximation to Riemannian Brownian motion, and MutationEnumeration in Tangent Space, which reinterprets tangent directions as discreteamino-acid substitutions. Combining these yields Local Enumeration BayesianOptimization (LE-BO), an efficient algorithm for local activity optimization.Finally, we introduce Potential-minimizing Geodesic Search (PoGS), whichinterpolates between prototype embeddings along property-enriched geodesics,biasing discovery toward seeds, i.e. peptides with favorable activity. In-vitrovalidation confirms the effectiveness of PepCompass: PoGS yields four novelseeds, and subsequent optimization with LE-BO discovers 25 highly activepeptides with broad-spectrum activity, including against resistant bacterialstrains. These results demonstrate that geometry-informed exploration providesa powerful new paradigm for antimicrobial peptide design.</description><author>Marcin Możejko, Adam Bielecki, Jurand Prądzyński, Marcin Traskowski, Antoni Janowski, Hyun-Su Lee, Marcelo Der Torossian Torres, Michał Kmicikiewicz, Paulina Szymczak, Karol Jurasz, Michał Kucharczyk, Cesar de la Fuente-Nunez, Ewa Szczurek</author><pubDate>Thu, 30 Oct 2025 15:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.01988v3</guid></item><item><title>C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models</title><link>http://arxiv.org/abs/2505.17773v3</link><description>Low-Rank Adaptation (LoRA) offers a cost-effective solution for fine-tuninglarge language models (LLMs), but it often produces overconfident predictionsin data-scarce few-shot settings. To address this issue, several classicalstatistical learning approaches have been repurposed for scalableuncertainty-aware LoRA fine-tuning. However, these approaches neglect how inputcharacteristics affect the predictive uncertainty estimates. To address thislimitation, we propose Contextual Low-Rank Adaptation (C-LoRA) as a noveluncertainty-aware and parameter efficient fine-tuning approach, by developingnew lightweight LoRA modules contextualized to each input data sample todynamically adapt uncertainty estimates. Incorporating data-driven contextsinto the parameter posteriors, C-LoRA mitigates overfitting, achieveswell-calibrated uncertainties, and yields robust predictions. Extensiveexperiments on LLaMA2-7B models demonstrate that C-LoRA consistentlyoutperforms the state-of-the-art uncertainty-aware LoRA methods in bothuncertainty quantification and model generalization. Ablation studies furtherconfirm the critical role of our contextual modules in capturingsample-specific uncertainties. C-LoRA sets a new standard for robust,uncertainty-aware LLM fine-tuning in few-shot regimes. Although our experimentsare limited to 7B models, our method is architecture-agnostic and, inprinciple, applies beyond this scale; studying its scaling to larger modelsremains an open problem. Our code is available athttps://github.com/ahra99/c_lora.</description><author>Amir Hossein Rahmati, Sanket Jantre, Weifeng Zhang, Yucheng Wang, Byung-Jun Yoon, Nathan M. Urban, Xiaoning Qian</author><pubDate>Thu, 30 Oct 2025 15:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17773v3</guid></item><item><title>Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient</title><link>http://arxiv.org/abs/2510.24519v2</link><description>Extracting features from the speech is the most critical process in speechsignal processing. Mel Frequency Cepstral Coefficients (MFCC) are the mostwidely used features in the majority of the speaker and speech recognitionapplications, as the filtering in this feature is similar to the filteringtaking place in the human ear. But the main drawback of this feature is that itprovides only the frequency information of the signal but does not provide theinformation about at what time which frequency is present. The wavelettransform, with its flexible time-frequency window, provides time and frequencyinformation of the signal and is an appropriate tool for the analysis ofnon-stationary signals like speech. On the other hand, because of its uniformfrequency scaling, a typical wavelet transform may be less effective inanalysing speech signals, have poorer frequency resolution in low frequencies,and be less in line with human auditory perception. Hence, it is necessary todevelop a feature that incorporates the merits of both MFCC and wavelettransform. A great deal of studies are trying to combine both these features.The present Wavelet Transform based Mel-scaled feature extraction methodsrequire more computation when a wavelet transform is applied on top ofMel-scale filtering, since it adds extra processing steps. Here we areproposing a method to extract Mel scale features in time domain combining theconcept of wavelet transform, thus reducing the computational burden oftime-frequency conversion and the complexity of wavelet extraction. Combiningour proposed Time domain Mel frequency Wavelet Coefficient(TMFWC) techniquewith the reservoir computing methodology has significantly improved theefficiency of audio signal processing.</description><author>Rinku Sebastian, Simon O'Keefe, Martin Trefzer</author><pubDate>Thu, 30 Oct 2025 15:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.24519v2</guid></item></channel></rss>