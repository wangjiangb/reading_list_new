<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 02 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Efficient Streaming Language Models with Attention Sinks</title><link>http://arxiv.org/abs/2309.17453v1</link><description>Deploying Large Language Models (LLMs) in streaming applications such asmulti-round dialogue, where long interactions are expected, is urgently neededbut poses two major challenges. Firstly, during the decoding stage, cachingprevious tokens' Key and Value states (KV) consumes extensive memory. Secondly,popular LLMs cannot generalize to longer texts than the training sequencelength. Window attention, where only the most recent KVs are cached, is anatural approach -- but we show that it fails when the text length surpassesthe cache size. We observe an interesting phenomenon, namely attention sink,that keeping the KV of initial tokens will largely recover the performance ofwindow attention. In this paper, we first demonstrate that the emergence ofattention sink is due to the strong attention scores towards initial tokens asa ``sink'' even if they are not semantically important. Based on the aboveanalysis, we introduce StreamingLLM, an efficient framework that enables LLMstrained with a finite length attention window to generalize to infinitesequence lengths without any fine-tuning. We show that StreamingLLM can enableLlama-2, MPT, Falcon, and Pythia to perform stable and efficient languagemodeling with up to 4 million tokens and more. In addition, we discover thatadding a placeholder token as a dedicated attention sink during pre-trainingcan further improve streaming deployment. In streaming settings, StreamingLLMoutperforms the sliding window recomputation baseline by up to 22.2x speedup.Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.</description><author>Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, Mike Lewis</author><pubDate>Fri, 29 Sep 2023 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17453v1</guid></item><item><title>ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving</title><link>http://arxiv.org/abs/2309.17452v1</link><description>Large language models have made significant progress in various languagetasks, yet they still struggle with complex mathematics. In this paper, wepropose ToRA a series of Tool-integrated Reasoning Agents designed to solvechallenging mathematical problems by seamlessly integrating natural languagereasoning with the utilization of external tools (e.g., computation librariesand symbolic solvers), thereby amalgamating the analytical prowess of languageand the computational efficiency of tools. To train ToRA, we curate interactivetool-use trajectories on mathematical datasets, apply imitation learning on theannotations, and propose output space shaping to further refine models'reasoning behavior. As a result, ToRA models significantly outperformopen-source models on 10 mathematical reasoning datasets across all scales with13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on thecompetition-level dataset MATH, surpassing the best open-source modelWizardMath-70B by 22% absolute. ToRA-34B is also the first open-source modelthat achieves an accuracy exceeding 50% on MATH, which significantlyoutperforms GPT-4's CoT result, and is competitive with GPT-4 solving problemswith programs. Additionally, we conduct a comprehensive analysis of thebenefits and remaining challenges of tool interaction for mathematicalreasoning, providing valuable insights for future research.</description><author>Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen</author><pubDate>Fri, 29 Sep 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17452v1</guid></item><item><title>Multi-task View Synthesis with Neural Radiance Fields</title><link>http://arxiv.org/abs/2309.17450v1</link><description>Multi-task visual learning is a critical aspect of computer vision. Currentresearch, however, predominantly concentrates on the multi-task denseprediction setting, which overlooks the intrinsic 3D world and its multi-viewconsistent structures, and lacks the capability for versatile imagination. Inresponse to these limitations, we present a novel problem setting -- multi-taskview synthesis (MTVS), which reinterprets multi-task prediction as a set ofnovel-view synthesis tasks for multiple scene properties, including RGB. Totackle the MTVS problem, we propose MuvieNeRF, a framework that incorporatesboth multi-task and cross-view knowledge to simultaneously synthesize multiplescene properties. MuvieNeRF integrates two key modules, the Cross-TaskAttention (CTA) and Cross-View Attention (CVA) modules, enabling the efficientuse of information across multiple views and tasks. Extensive evaluation onboth synthetic and realistic benchmarks demonstrates that MuvieNeRF is capableof simultaneously synthesizing different scene properties with promising visualquality, even outperforming conventional discriminative models in varioussettings. Notably, we show that MuvieNeRF exhibits universal applicabilityacross a range of NeRF backbones. Our code is available athttps://github.com/zsh2000/MuvieNeRF.</description><author>Shuhong Zheng, Zhipeng Bao, Martial Hebert, Yu-Xiong Wang</author><pubDate>Fri, 29 Sep 2023 18:58:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17450v1</guid></item><item><title>SMPLer-X: Scaling Up Expressive Human Pose and Shape Estimation</title><link>http://arxiv.org/abs/2309.17448v1</link><description>Expressive human pose and shape estimation (EHPS) unifies body, hands, andface motion capture with numerous applications. Despite encouraging progress,current state-of-the-art methods still depend largely on confined trainingdatasets. In this work, we investigate scaling up EHPS towards the firstgeneralist foundation model (dubbed SMPLer-X), with up to ViT-Huge as thebackbone and training with up to 4.5M instances from diverse data sources. Withbig data and the large model, SMPLer-X exhibits strong performance acrossdiverse test benchmarks and excellent transferability to even unseenenvironments. 1) For the data scaling, we perform a systematic investigation on32 EHPS datasets, encompassing a wide range of scenarios that a model trainedon any single dataset cannot handle. More importantly, capitalizing on insightsobtained from the extensive benchmarking process, we optimize our trainingscheme and select datasets that lead to a significant leap in EHPScapabilities. 2) For the model scaling, we take advantage of visiontransformers to study the scaling law of model sizes in EHPS. Moreover, ourfinetuning strategy turn SMPLer-X into specialist models, allowing them toachieve further performance boosts. Notably, our foundation model SMPLer-Xconsistently delivers state-of-the-art results on seven benchmarks such asAGORA (107.2 mm NMVE), UBody (57.4 mm PVE), EgoBody (63.6 mm PVE), and EHF(62.3 mm PVE without finetuning).</description><author>Zhongang Cai, Wanqi Yin, Ailing Zeng, Chen Wei, Qingping Sun, Yanjun Wang, Hui En Pang, Haiyi Mei, Mingyuan Zhang, Lei Zhang, Chen Change Loy, Lei Yang, Ziwei Liu</author><pubDate>Fri, 29 Sep 2023 18:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17448v1</guid></item><item><title>A Large Language Model Approach to Educational Survey Feedback Analysis</title><link>http://arxiv.org/abs/2309.17447v1</link><description>This paper assesses the potential for the large language models (LLMs) GPT-4and GPT-3.5 to aid in deriving insight from education feedback surveys.Exploration of LLM use cases in education has focused on teaching and learning,with less exploration of capabilities in education feedback analysis. Surveyanalysis in education involves goals such as finding gaps in curricula orevaluating teachers, often requiring time-consuming manual processing oftextual responses. LLMs have the potential to provide a flexible means ofachieving these goals without specialized machine learning models orfine-tuning. We demonstrate a versatile approach to such goals by treating themas sequences of natural language processing (NLP) tasks includingclassification (multi-label, multi-class, and binary), extraction, thematicanalysis, and sentiment analysis, each performed by LLM. We apply theseworkflows to a real-world dataset of 2500 end-of-course survey comments frombiomedical science courses, and evaluate a zero-shot approach (i.e., requiringno examples or labeled training data) across all tasks, reflecting educationsettings, where labeled data is often scarce. By applying effective promptingpractices, we achieve human-level performance on multiple tasks with GPT-4,enabling workflows necessary to achieve typical goals. We also show thepotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providinginsight that may foster confidence in practice. Moreover, this study featuresdevelopment of a versatile set of classification categories, suitable forvarious course types (online, hybrid, or in-person) and amenable tocustomization. Our results suggest that LLMs can be used to derive a range ofinsights from survey text.</description><author>Michael J. Parker, Caitlin Anderson, Claire Stone, YeaRim Oh</author><pubDate>Fri, 29 Sep 2023 18:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17447v1</guid></item><item><title>L2CEval: Evaluating Language-to-Code Generation Capabilities of Large Language Models</title><link>http://arxiv.org/abs/2309.17446v1</link><description>Recently, large language models (LLMs), especially those that are pretrainedon code, have demonstrated strong capabilities in generating programs fromnatural language inputs in a few-shot or even zero-shot manner. Despitepromising results, there is a notable lack of a comprehensive evaluation ofthese models language-to-code generation capabilities. Existing studies oftenfocus on specific tasks, model architectures, or learning paradigms, leading toa fragmented understanding of the overall landscape. In this work, we presentL2CEval, a systematic evaluation of the language-to-code generationcapabilities of LLMs on 7 tasks across the domain spectrum of semantic parsing,math reasoning and Python programming, analyzing the factors that potentiallyaffect their performance, such as model size, pretraining data, instructiontuning, and different prompting methods. In addition to assessing modelperformance, we measure confidence calibration for the models and conduct humanevaluations of the output programs. This enables us to identify and analyze thetypical failure modes across various tasks and models. L2CEval offers acomprehensive understanding of the capabilities and limitations of LLMs inlanguage-to-code generation. We also release the evaluation framework and allmodel outputs, hoping to lay the groundwork for further future research in thisdomain.</description><author>Ansong Ni, Pengcheng Yin, Yilun Zhao, Martin Riddell, Troy Feng, Rui Shen, Stephen Yin, Ye Liu, Semih Yavuz, Caiming Xiong, Shafiq Joty, Yingbo Zhou, Dragomir Radev, Arman Cohan</author><pubDate>Fri, 29 Sep 2023 18:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17446v1</guid></item><item><title>InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition</title><link>http://arxiv.org/abs/2309.15112v3</link><description>We propose InternLM-XComposer, a vision-language large model that enablesadvanced image-text comprehension and composition. The innovative nature of ourmodel is highlighted by three appealing properties: 1) Interleaved Text-ImageComposition: InternLM-XComposer can effortlessly generate coherent andcontextual articles that seamlessly integrate images, providing a more engagingand immersive reading experience. Simply provide a title, and our system willgenerate the corresponding manuscript. It can intelligently identify the areasin the text where images would enhance the content and automatically insert themost appropriate visual candidates. 2) Comprehension with Rich MultilingualKnowledge: The text-image comprehension is empowered by training on extensivemulti-modal multilingual concepts with carefully crafted strategies, resultingin a deep understanding of visual content. 3) State-of-the-art Performance: Ourmodel consistently achieves state-of-the-art results across various mainstreambenchmarks for vision-language foundational models, including MME Benchmark,MMBench, MMBench-CN, Seed-Bench, and CCBench (Chinese Cultural Benchmark).Collectively, InternLM-XComposer seamlessly blends advanced text-imagecomprehension and composition, revolutionizing vision-language interaction andoffering new insights and opportunities. The InternLM-XComposer model serieswith 7B parameters are publicly available athttps://github.com/InternLM/InternLM-XComposer.</description><author>Pan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Shuangrui Ding, Songyang Zhang, Haodong Duan, Hang Yan, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, Jiaqi Wang</author><pubDate>Fri, 29 Sep 2023 18:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15112v3</guid></item><item><title>LLM-grounded Video Diffusion Models</title><link>http://arxiv.org/abs/2309.17444v1</link><description>Text-conditioned diffusion models have emerged as a promising tool for neuralvideo generation. However, current models still struggle with intricatespatiotemporal prompts and often generate restricted or incorrect motion (e.g.,even lacking the ability to be prompted for objects moving from left to right).To address these limitations, we introduce LLM-grounded Video Diffusion (LVD).Instead of directly generating videos from the text inputs, LVD first leveragesa large language model (LLM) to generate dynamic scene layouts based on thetext inputs and subsequently uses the generated layouts to guide a diffusionmodel for video generation. We show that LLMs are able to understand complexspatiotemporal dynamics from text alone and generate layouts that align closelywith both the prompts and the object motion patterns typically observed in thereal world. We then propose to guide video diffusion models with these layoutsby adjusting the attention maps. Our approach is training-free and can beintegrated into any video diffusion model that admits classifier guidance. Ourresults demonstrate that LVD significantly outperforms its base video diffusionmodel and several strong baseline methods in faithfully generating videos withthe desired attributes and motion patterns.</description><author>Long Lian, Baifeng Shi, Adam Yala, Trevor Darrell, Boyi Li</author><pubDate>Fri, 29 Sep 2023 18:54:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17444v1</guid></item><item><title>Hybrid quantum ResNet for car classification and its hyperparameter optimization</title><link>http://arxiv.org/abs/2205.04878v2</link><description>Image recognition is one of the primary applications of machine learningalgorithms. Nevertheless, machine learning models used in modern imagerecognition systems consist of millions of parameters that usually requiresignificant computational time to be adjusted. Moreover, adjustment of modelhyperparameters leads to additional overhead. Because of this, new developmentsin machine learning models and hyperparameter optimization techniques arerequired. This paper presents a quantum-inspired hyperparameter optimizationtechnique and a hybrid quantum-classical machine learning model for supervisedlearning. We benchmark our hyperparameter optimization method over standardblack-box objective functions and observe performance improvements in the formof reduced expected run times and fitness in response to the growth in the sizeof the search space. We test our approaches in a car image classification taskand demonstrate a full-scale implementation of the hybrid quantum ResNet modelwith the tensor train hyperparameter optimization. Our tests show a qualitativeand quantitative advantage over the corresponding standard classical tabulargrid search approach used with a deep neural network ResNet34. A classificationaccuracy of 0.97 was obtained by the hybrid model after 18 iterations, whereasthe classical model achieved an accuracy of 0.92 after 75 iterations.</description><author>Asel Sagingalieva, Mo Kordzanganeh, Andrii Kurkin, Artem Melnikov, Daniil Kuhmistrov, Michael Perelshtein, Alexey Melnikov, Andrea Skolik, David Von Dollen</author><pubDate>Fri, 29 Sep 2023 18:53:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.04878v2</guid></item><item><title>Learning Decentralized Flocking Controllers with Spatio-Temporal Graph Neural Network</title><link>http://arxiv.org/abs/2309.17437v1</link><description>Recently a line of researches has delved the use of graph neural networks(GNNs) for decentralized control in swarm robotics. However, it has beenobserved that relying solely on the states of immediate neighbors isinsufficient to imitate a centralized control policy. To address thislimitation, prior studies proposed incorporating $L$-hop delayed states intothe computation. While this approach shows promise, it can lead to a lack ofconsensus among distant flock members and the formation of small clusters,consequently resulting in the failure of cohesive flocking behaviors. Instead,our approach leverages spatiotemporal GNN, named STGNN that encompasses bothspatial and temporal expansions. The spatial expansion collects delayed statesfrom distant neighbors, while the temporal expansion incorporates previousstates from immediate neighbors. The broader and more comprehensive informationgathered from both expansions results in more effective and accuratepredictions. We develop an expert algorithm for controlling a swarm of robotsand employ imitation learning to train our decentralized STGNN model based onthe expert algorithm. We simulate the proposed STGNN approach in varioussettings, demonstrating its decentralized capacity to emulate the global expertalgorithm. Further, we implemented our approach to achieve cohesive flocking,leader following and obstacle avoidance by a group of Crazyflie drones. Theperformance of STGNN underscores its potential as an effective and reliableapproach for achieving cohesive flocking, leader following and obstacleavoidance tasks.</description><author>Siji Chen, Yanshen Sun, Peihan Li, Lifeng Zhou, Chang-Tien Lu</author><pubDate>Fri, 29 Sep 2023 18:50:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17437v1</guid></item><item><title>DREAM: Decentralized Reinforcement Learning for Exploration and Efficient Energy Management in Multi-Robot Systems</title><link>http://arxiv.org/abs/2309.17433v1</link><description>Resource-constrained robots often suffer from energy inefficiencies,underutilized computational abilities due to inadequate task allocation, and alack of robustness in dynamic environments, all of which strongly affect theirperformance. This paper introduces DREAM - Decentralized Reinforcement Learningfor Exploration and Efficient Energy Management in Multi-Robot Systems, acomprehensive framework that optimizes the allocation of resources forefficient exploration. It advances beyond conventional heuristic-based taskplanning as observed conventionally. The framework incorporates OperationalRange Estimation using Reinforcement Learning to perform exploration andobstacle avoidance in unfamiliar terrains. DREAM further introduces an EnergyConsumption Model for goal allocation, thereby ensuring mission completionunder constrained resources using a Graph Neural Network. This approach alsoensures that the entire Multi-Robot System can survive for an extended periodof time for further missions compared to the conventional approach of randomlyallocating goals, which compromises one or more agents. Our approach adapts toprioritizing agents in real-time, showcasing remarkable resilience againstdynamic environments. This robust solution was evaluated in various simulatedenvironments, demonstrating adaptability and applicability across diversescenarios. We observed a substantial improvement of about 25% over the baselinemethod, leading the way for future research in resource-constrained robotics.</description><author>Dipam Patel, Phu Pham, Kshitij Tiwari, Aniket Bera</author><pubDate>Fri, 29 Sep 2023 18:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17433v1</guid></item><item><title>FACTS: First Amplify Correlations and Then Slice to Discover Bias</title><link>http://arxiv.org/abs/2309.17430v1</link><description>Computer vision datasets frequently contain spurious correlations betweentask-relevant labels and (easy to learn) latent task-irrelevant attributes(e.g. context). Models trained on such datasets learn "shortcuts" andunderperform on bias-conflicting slices of data where the correlation does nothold. In this work, we study the problem of identifying such slices to informdownstream bias mitigation strategies. We propose First Amplify Correlationsand Then Slice to Discover Bias (FACTS), wherein we first amplify correlationsto fit a simple bias-aligned hypothesis via strongly regularized empirical riskminimization. Next, we perform correlation-aware slicing via mixture modelingin bias-aligned feature space to discover underperforming data slices thatcapture distinct correlations. Despite its simplicity, our method considerablyimproves over prior work (by as much as 35% precision@10) in correlation biasidentification across a range of diverse evaluation settings. Our code isavailable at: https://github.com/yvsriram/FACTS.</description><author>Sriram Yenamandra, Pratik Ramesh, Viraj Prabhu, Judy Hoffman</author><pubDate>Fri, 29 Sep 2023 18:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17430v1</guid></item><item><title>CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets</title><link>http://arxiv.org/abs/2309.17428v1</link><description>Large language models (LLMs) are often augmented with tools to solve complextasks. By generating code snippets and executing them through task-specificApplication Programming Interfaces (APIs), they can offload certain functionsto dedicated external modules, such as image encoding and performingcalculations. However, most existing approaches to augment LLMs with tools areconstrained by general-purpose APIs and lack the flexibility for tailoring themto specific tasks. In this work, we present CRAFT, a general tool creation andretrieval framework for LLMs. It creates toolsets specifically curated for thetasks and equips LLMs with a component that retrieves tools from these sets toenhance their capability to solve complex tasks. For each task, we collectspecific code solutions by prompting GPT-4 to solve the training examples.Following a validation step ensuring the correctness, these solutions areabstracted into code snippets to enhance reusability, and deduplicated forhigher quality. At inference time, the language model retrieves snippets fromthe toolsets and then executes them or generates the output conditioning on theretrieved snippets. Our method is designed to be flexible and offers aplug-and-play approach to adapt off-the-shelf LLMs to unseen domains andmodalities, without any finetuning. Experiments on vision-language, tabularprocessing, and mathematical reasoning tasks show that our approach achievessubstantial improvements compared to strong baselines. In addition, ourin-depth analysis reveals that: (1) consistent performance improvement can beachieved by scaling up the number of tools and the capability of the backbonemodels; (2) each component of our approach contributes to the performancegains; (3) the created tools are well-structured and reliable with lowcomplexity and atomicity. The code is available at\url{https://github.com/lifan-yuan/CRAFT}.</description><author>Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R. Fung, Hao Peng, Heng Ji</author><pubDate>Fri, 29 Sep 2023 18:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17428v1</guid></item><item><title>Classification of Potholes Based on Surface Area Using Pre-Trained Models of Convolutional Neural Network</title><link>http://arxiv.org/abs/2309.17426v1</link><description>Potholes are fatal and can cause severe damage to vehicles as well as cancause deadly accidents. In South Asian countries, pavement distresses are theprimary cause due to poor subgrade conditions, lack of subsurface drainage, andexcessive rainfalls. The present research compares the performance of threepre-trained Convolutional Neural Network (CNN) models, i.e., ResNet 50, ResNet18, and MobileNet. At first, pavement images are classified to find whetherimages contain potholes, i.e., Potholes or Normal. Secondly, pavements imagesare classi-fied into three categories, i.e., Small Pothole, Large Pothole, andNormal. Pavement images are taken from 3.5 feet (waist height) and 2 feet.MobileNet v2 has an accuracy of 98% for detecting a pothole. The classificationof images taken at the height of 2 feet has an accuracy value of 87.33%,88.67%, and 92% for classifying the large, small, and normal pavement,respectively. Similarly, the classification of the images taken from full ofwaist (FFW) height has an accuracy value of 98.67%, 98.67%, and 100%.</description><author>Chauhdary Fazeel Ahmad, Abdullah Cheema, Waqas Qayyum, Rana Ehtisham, Muhammad Haroon Yousaf, Junaid Mir, Nasim Shakouri Mahmoudabadi, Afaq Ahmad</author><pubDate>Fri, 29 Sep 2023 18:39:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17426v1</guid></item><item><title>Overcoming the Stability Gap in Continual Learning</title><link>http://arxiv.org/abs/2306.01904v2</link><description>In many real-world applications, deep neural networks are retrained fromscratch as a dataset grows in size. Given the computational expense forretraining networks, it has been argued that continual learning could makeupdating networks more efficient. An obstacle to achieving this goal is thestability gap, which refers to an observation that when updating on new data,performance on previously learned data degrades before recovering. Addressingthis problem would enable learning new data with fewer network updates,resulting in increased computational efficiency. We study how to mitigate thestability gap. We test a variety of hypotheses to understand why the stabilitygap occurs. This leads us to discover a method that vastly reduces this gap. Inlarge-scale class incremental learning experiments, we are able tosignificantly reduce the number of network updates needed for continuallearning. Our work has the potential to advance the state-of-the-art incontinual learning for real-world applications along with reducing the carbonfootprint required to maintain updated neural networks.</description><author>Md Yousuf Harun, Christopher Kanan</author><pubDate>Fri, 29 Sep 2023 18:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01904v2</guid></item><item><title>Data Filtering Networks</title><link>http://arxiv.org/abs/2309.17425v1</link><description>Large training sets have become a cornerstone of machine learning and are thefoundation for recent advances in language modeling and multimodal learning.While data curation for pre-training is often still ad-hoc, one common paradigmis to first collect a massive pool of data from the Web and then filter thiscandidate pool down to an actual training set via various heuristics. In thiswork, we study the problem of learning a data filtering network (DFN) for thissecond step of filtering a large uncurated dataset. Our key finding is that thequality of a network for filtering is distinct from its performance ondownstream tasks: for instance, a model that performs well on ImageNet canyield worse training sets than a model with low ImageNet accuracy that istrained on a small amount of high-quality data. Based on our insights, weconstruct new data filtering networks that induce state-of-the-art image-textdatasets. Specifically, our best performing dataset DFN-5B enables us to trainstate-of-the-art models for their compute budgets: among other improvements ona variety of tasks, a ViT-H trained on our dataset achieves 83.0% zero-shottransfer accuracy on ImageNet, out-performing models trained on other datasetssuch as LAION-2B, DataComp-1B, or OpenAI's WIT. In order to facilitate furtherresearch in dataset design, we also release a new 2 billion example datasetDFN-2B and show that high performance data filtering networks can be trainedfrom scratch using only publicly available data.</description><author>Alex Fang, Albin Madappally Jose, Amit Jain, Ludwig Schmidt, Alexander Toshev, Vaishaal Shankar</author><pubDate>Fri, 29 Sep 2023 18:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17425v1</guid></item><item><title>The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)</title><link>http://arxiv.org/abs/2309.17421v1</link><description>Large multimodal models (LMMs) extend large language models (LLMs) withmulti-sensory skills, such as visual understanding, to achieve stronger genericintelligence. In this paper, we analyze the latest model, GPT-4V(ision), todeepen the understanding of LMMs. The analysis focuses on the intriguing tasksthat GPT-4V can perform, containing test samples to probe the quality andgenericity of GPT-4V's capabilities, its supported inputs and working modes,and the effective ways to prompt the model. In our approach to exploringGPT-4V, we curate and organize a collection of carefully designed qualitativesamples spanning a variety of domains and tasks. Observations from thesesamples demonstrate that GPT-4V's unprecedented ability in processingarbitrarily interleaved multimodal inputs and the genericity of itscapabilities together make GPT-4V a powerful multimodal generalist system.Furthermore, GPT-4V's unique capability of understanding visual markers drawnon input images can give rise to new human-computer interaction methods such asvisual referring prompting. We conclude the report with in-depth discussions onthe emerging application scenarios and the future research directions forGPT-4V-based systems. We hope that this preliminary exploration will inspirefuture research on the next-generation multimodal task formulation, new ways toexploit and enhance LMMs to solve real-world problems, and gaining betterunderstanding of multimodal foundation models.</description><author>Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, Lijuan Wang</author><pubDate>Fri, 29 Sep 2023 18:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17421v1</guid></item><item><title>Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments</title><link>http://arxiv.org/abs/2302.04823v2</link><description>Deriving robust control policies for realistic urban navigation scenarios isnot a trivial task. In an end-to-end approach, these policies must maphigh-dimensional images from the vehicle's cameras to low-level actions such assteering and throttle. While pure Reinforcement Learning (RL) approaches arebased exclusively on rewards,Generative Adversarial Imitation Learning (GAIL)agents learn from expert demonstrations while interacting with the environment,which favors GAIL on tasks for which a reward signal is difficult to derive. Inthis work, the hGAIL architecture was proposed to solve the autonomousnavigation of a vehicle in an end-to-end approach, mapping sensory perceptionsdirectly to low-level actions, while simultaneously learning mid-level inputrepresentations of the agent's environment. The proposed hGAIL consists of anhierarchical Adversarial Imitation Learning architecture composed of two mainmodules: the GAN (Generative Adversarial Nets) which generates the Bird's-EyeView (BEV) representation mainly from the images of three frontal cameras ofthe vehicle, and the GAIL which learns to control the vehicle based mainly onthe BEV predictions from the GAN as input.Our experiments have shown that GAILexclusively from cameras (without BEV) fails to even learn the task, whilehGAIL, after training, was able to autonomously navigate successfully in allintersections of the city.</description><author>Gustavo Claudio Karl Couto, Eric Aislan Antonelo</author><pubDate>Fri, 29 Sep 2023 18:28:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04823v2</guid></item><item><title>Direct Superpoints Matching for Robust Point Cloud Registration</title><link>http://arxiv.org/abs/2307.01362v2</link><description>Deep neural networks endow the downsampled superpoints with highlydiscriminative feature representations. Previous dominant point cloudregistration approaches match these feature representations, \eg, using theSinkhorn algorithm as the first step. A RANSAC-like method is then usuallyadopted as a post-processing refinement to filter the outliers. Theseapproaches tend to be computationally intensive due to the iterative nature ofRANSAC and require careful parameter tuning to adapt to various practicalapplications. In this paper, we emphasize the role of matching strategy insuperpoint feature matching. We propose a straightforward and effectiveapproach to directly match superpoints by leveraging a global softmax layer inan end-to-end fashion. These matched superpoints are instrumental in estimatingthe SE(3) transformation between the source and target point clouds. Notably,our approach employs softmax probabilities as weights for each correspondence,allowing us to reject the outliers and further weigh the rest inliers whenfitting the transformation matrix, which does not need any post-processingrefinement. Moreover, our approach enables joint optimization of differentcomponents, including feature representation learning, superpoints matching,and transformation estimation, leading to better registration performance.Experimental results on the standard benchmarks, including ModelNet, 3DMatch,and KITTI validate the effectiveness of our approach, where we obtaincomparable or even better accuracy than state-of-the-art methods. Our code andmodel weights will be publicly available.</description><author>Aniket Gupta, Yiming Xie, Hanumant Singh, Huaizu Jiang</author><pubDate>Fri, 29 Sep 2023 18:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01362v2</guid></item><item><title>Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction</title><link>http://arxiv.org/abs/2309.17417v1</link><description>Graph neural network (GNN) link prediction is increasingly deployed incitation, collaboration, and online social networks to recommend academicliterature, collaborators, and friends. While prior research has investigatedthe dyadic fairness of GNN link prediction, the within-group fairness and``rich get richer'' dynamics of link prediction remain underexplored. However,these aspects have significant consequences for degree and power imbalances innetworks. In this paper, we shed light on how degree bias in networks affectsGraph Convolutional Network (GCN) link prediction. In particular, wetheoretically uncover that GCNs with a symmetric normalized graph filter have awithin-group preferential attachment bias. We validate our theoretical analysison real-world citation, collaboration, and online social networks. We furtherbridge GCN's preferential attachment bias with unfairness in link predictionand propose a new within-group fairness metric. This metric quantifiesdisparities in link prediction scores between social groups, towards combatingthe amplification of degree and power disparities. Finally, we propose a simpletraining-time strategy to alleviate within-group unfairness, and we show thatit is effective on citation, online social, and credit networks.</description><author>Arjun Subramonian, Levent Sagun, Yizhou Sun</author><pubDate>Fri, 29 Sep 2023 18:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17417v1</guid></item><item><title>Intuitive or Dependent? Investigating LLMs' Robustness to Conflicting Prompts</title><link>http://arxiv.org/abs/2309.17415v1</link><description>This paper explores the robustness of LLMs' preference to their internalmemory or the given prompt, which may contain contrasting information inreal-world applications due to noise or task settings. To this end, weestablish a quantitative benchmarking framework and conduct the role playingintervention to control LLMs' preference. In specific, we define two types ofrobustness, factual robustness targeting the ability to identify the correctfact from prompts or memory, and decision style to categorize LLMs' behavior inmaking consistent choices -- assuming there is no definitive "right" answer --intuitive, dependent, or rational based on cognitive theory. Our findings,derived from extensive experiments on seven open-source and closed-source LLMs,reveal that these models are highly susceptible to misleading prompts,especially for instructing commonsense knowledge. While detailed instructionscan mitigate the selection of misleading answers, they also increase theincidence of invalid responses. After Unraveling the preference, we intervenedifferent sized LLMs through specific style of role instruction, showing theirvarying upper bound of robustness and adaptivity.</description><author>Jiahao Ying, Yixin Cao, Kai Xiong, Yidong He, Long Cui, Yongbin Liu</author><pubDate>Fri, 29 Sep 2023 18:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17415v1</guid></item><item><title>Flow-based density of states for complex actions</title><link>http://arxiv.org/abs/2203.01243v2</link><description>Emerging sampling algorithms based on normalizing flows have the potential tosolve ergodicity problems in lattice calculations. Furthermore, it has beennoted that flows can be used to compute thermodynamic quantities which aredifficult to access with traditional methods. This suggests that they are alsoapplicable to the density-of-states approach to complex action problems. Inparticular, flow-based sampling may be used to compute the density directly, incontradistinction to the conventional strategy of reconstructing it viameasuring and integrating the derivative of its logarithm. By circumventingthis procedure, the accumulation of errors from the numerical integration isavoided completely and the overall normalization factor can be determinedexplicitly. In this proof-of-principle study, we demonstrate our method in thecontext of two-component scalar field theory where the $O(2)$ symmetry isexplicitly broken by an imaginary external field. First, we concentrate on thezero-dimensional case which can be solved exactly. We show that with ourmethod, the Lee-Yang zeroes of the associated partition function can besuccessfully located. Subsequently, we confirm that the flow-based approachcorrectly reproduces the density computed with conventional methods in one- andtwo-dimensional models.</description><author>Jan M. Pawlowski, Julian M. Urban</author><pubDate>Fri, 29 Sep 2023 18:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.01243v2</guid></item><item><title>Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning</title><link>http://arxiv.org/abs/2305.15912v3</link><description>This work examines the characteristic activation values of individual ReLUunits in neural networks. We refer to the set of input locations correspondingto such characteristic activation values as the characteristic activation setof a ReLU unit. We draw an explicit connection between the characteristicactivation set and learned features in ReLU networks. This connection leads tonew insights into how various neural network normalization techniques used inmodern deep learning architectures regularize and stabilize stochastic gradientoptimization. Utilizing these insights, we propose geometric parameterizationfor ReLU networks to improve feature learning, which decouples the radial andangular parameters in the hyperspherical coordinate system. We empiricallyverify its usefulness with less carefully chosen initialization schemes andlarger learning rates. We report significant improvements in optimizationstability, convergence speed, and generalization performance for various modelson a variety of datasets, including the ResNet-50 network on ImageNet.</description><author>Wenlin Chen, Hong Ge</author><pubDate>Fri, 29 Sep 2023 18:13:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15912v3</guid></item><item><title>Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks</title><link>http://arxiv.org/abs/2309.17410v1</link><description>Pretrained language models sometimes possess knowledge that we do not wishthem to, including memorized personal information and knowledge that could beused to harm people. They can also output toxic or harmful text. To mitigatethese safety and informational issues, we propose an attack-and-defenseframework for studying the task of deleting sensitive information directly frommodel weights. We study direct edits to model weights because (1) this approachshould guarantee that particular deleted information is never extracted byfuture prompt attacks, and (2) it should protect against whitebox attacks,which is necessary for making claims about safety/privacy in a setting wherepublicly available model weights could be used to elicit sensitive information.Our threat model assumes that an attack succeeds if the answer to a sensitivequestion is located among a set of B generated candidates, based on scenarioswhere the information would be insecure if the answer is among B candidates.Experimentally, we show that even state-of-the-art model editing methods suchas ROME struggle to truly delete factual information from models like GPT-J, asour whitebox and blackbox attacks can recover "deleted" information from anedited model 38% of the time. These attacks leverage two key observations: (1)that traces of deleted information can be found in intermediate model hiddenstates, and (2) that applying an editing method for one question may not deleteinformation across rephrased versions of the question. Finally, we provide newdefense methods that protect against some extraction attacks, but we do notfind a single universally effective defense method. Our results suggest thattruly deleting sensitive information is a tractable but difficult problem,since even relatively low attack success rates have potentially severe societalimplications for real-world deployment of language models.</description><author>Vaidehi Patil, Peter Hase, Mohit Bansal</author><pubDate>Fri, 29 Sep 2023 18:12:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17410v1</guid></item><item><title>Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation</title><link>http://arxiv.org/abs/2309.15575v2</link><description>Unsupervised domain adaptation aims to transfer knowledge from afully-labeled source domain to an unlabeled target domain. However, inreal-world scenarios, providing abundant labeled data even in the source domaincan be infeasible due to the difficulty and high expense of annotation. Toaddress this issue, recent works consider the Few-shot Unsupervised DomainAdaptation (FUDA) where only a few source samples are labeled, and conductknowledge transfer via self-supervised learning methods. Yet existing methodsgenerally overlook that the sparse label setting hinders learning reliablesource knowledge for transfer. Additionally, the learning difficulty differencein target samples is different but ignored, leaving hard target samples poorlyclassified. To tackle both deficiencies, in this paper, we propose a novelConfidence-based Visual Dispersal Transfer learning method (C-VisDiT) for FUDA.Specifically, C-VisDiT consists of a cross-domain visual dispersal strategythat transfers only high-confidence source knowledge for model adaptation andan intra-domain visual dispersal strategy that guides the learning of hardtarget samples with easy ones. We conduct extensive experiments on Office-31,Office-Home, VisDA-C, and DomainNet benchmark datasets and the resultsdemonstrate that the proposed C-VisDiT significantly outperformsstate-of-the-art FUDA methods. Our code is available athttps://github.com/Bostoncake/C-VisDiT.</description><author>Yizhe Xiong, Hui Chen, Zijia Lin, Sicheng Zhao, Guiguang Ding</author><pubDate>Fri, 29 Sep 2023 18:11:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15575v2</guid></item><item><title>Maximal Volume Matrix Cross Approximation for Image Compression and Least Squares Solution</title><link>http://arxiv.org/abs/2309.17403v1</link><description>We study the classic cross approximation of matrices based on the maximalvolume submatrices. Our main results consist of an improvement of a classicestimate for matrix cross approximation and a greedy approach for finding themaximal volume submatrices. Indeed, we present a new proof of a classicestimate of the inequality with an improved constant. Also, we present a familyof greedy maximal volume algorithms which improve the error bound of crossapproximation of a matrix in the Chebyshev norm and also improve thecomputational efficiency of classic maximal volume algorithm. The proposedalgorithms are shown to have theoretical guarantees of convergence. Finally, wepresent two applications: one is image compression and the other is leastsquares approximation of continuous functions. Our numerical results in the endof the paper demonstrate the effective performances of our approach.</description><author>Kenneth Allen, Ming-Jun Lai, Zhaiming Shen</author><pubDate>Fri, 29 Sep 2023 18:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17403v1</guid></item><item><title>Adversarial Machine Learning in Latent Representations of Neural Networks</title><link>http://arxiv.org/abs/2309.17401v1</link><description>Distributed deep neural networks (DNNs) have been shown to reduce thecomputational burden of mobile devices and decrease the end-to-end inferencelatency in edge computing scenarios. While distributed DNNs have been studied,to the best of our knowledge the resilience of distributed DNNs to adversarialaction still remains an open problem. In this paper, we fill the existingresearch gap by rigorously analyzing the robustness of distributed DNNs againstadversarial action. We cast this problem in the context of information theoryand introduce two new measurements for distortion and robustness. Ourtheoretical findings indicate that (i) assuming the same level of informationdistortion, latent features are always more robust than input representations;(ii) the adversarial robustness is jointly determined by the feature dimensionand the generalization capability of the DNN. To test our theoretical findings,we perform extensive experimental analysis by considering 6 different DNNarchitectures, 6 different approaches for distributed DNN and 10 differentadversarial attacks to the ImageNet-1K dataset. Our experimental resultssupport our theoretical findings by showing that the compressed latentrepresentations can reduce the success rate of adversarial attacks by 88% inthe best case and by 57% on the average compared to attacks to the input space.</description><author>Milin Zhang, Mohammad Abdi, Francesco Restuccia</author><pubDate>Fri, 29 Sep 2023 18:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17401v1</guid></item><item><title>Directly Fine-Tuning Diffusion Models on Differentiable Rewards</title><link>http://arxiv.org/abs/2309.17400v1</link><description>We present Direct Reward Fine-Tuning (DRaFT), a simple and effective methodfor fine-tuning diffusion models to maximize differentiable reward functions,such as scores from human preference models. We first show that it is possibleto backpropagate the reward function gradient through the full samplingprocedure, and that doing so achieves strong performance on a variety ofrewards, outperforming reinforcement learning-based approaches. We then proposemore efficient variants of DRaFT: DRaFT-K, which truncates backpropagation toonly the last K steps of sampling, and DRaFT-LV, which obtains lower-variancegradient estimates for the case when K=1. We show that our methods work wellfor a variety of reward functions and can be used to substantially improve theaesthetic quality of images generated by Stable Diffusion 1.4. Finally, we drawconnections between our approach and prior work, providing a unifyingperspective on the design space of gradient-based fine-tuning algorithms.</description><author>Kevin Clark, Paul Vicol, Kevin Swersky, David J Fleet</author><pubDate>Fri, 29 Sep 2023 18:01:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17400v1</guid></item><item><title>IFAST: Weakly Supervised Interpretable Face Anti-spoofing from Single-shot Binocular NIR Images</title><link>http://arxiv.org/abs/2309.17399v1</link><description>Single-shot face anti-spoofing (FAS) is a key technique for securing facerecognition systems, and it requires only static images as input. However,single-shot FAS remains a challenging and under-explored problem due to twomain reasons: 1) on the data side, learning FAS from RGB images is largelycontext-dependent, and single-shot images without additional annotationscontain limited semantic information. 2) on the model side, existingsingle-shot FAS models are infeasible to provide proper evidence for theirdecisions, and FAS methods based on depth estimation require expensiveper-pixel annotations. To address these issues, a large binocular NIR imagedataset (BNI-FAS) is constructed and published, which contains more than300,000 real face and plane attack images, and an Interpretable FAS Transformer(IFAST) is proposed that requires only weak supervision to produceinterpretable predictions. Our IFAST can produce pixel-wise disparity maps bythe proposed disparity estimation Transformer with Dynamic Matching Attention(DMA) block. Besides, a well-designed confidence map generator is adopted tocooperate with the proposed dual-teacher distillation module to obtain thefinal discriminant results. The comprehensive experiments show that our IFASTcan achieve state-of-the-art results on BNI-FAS, proving the effectiveness ofthe single-shot FAS based on binocular NIR images.</description><author>Jiancheng Huang, Donghao Zhou, Shifeng Chen</author><pubDate>Fri, 29 Sep 2023 18:00:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17399v1</guid></item><item><title>AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition</title><link>http://arxiv.org/abs/2309.17395v1</link><description>Audio-visual speech contains synchronized audio and visual information thatprovides cross-modal supervision to learn representations for both automaticspeech recognition (ASR) and visual speech recognition (VSR). We introducecontinuous pseudo-labeling for audio-visual speech recognition (AV-CPL), asemi-supervised method to train an audio-visual speech recognition (AVSR) modelon a combination of labeled and unlabeled videos with continuously regeneratedpseudo-labels. Our models are trained for speech recognition from audio-visualinputs and can perform speech recognition using both audio and visualmodalities, or only one modality. Our method uses the same audio-visual modelfor both supervised training and pseudo-label generation, mitigating the needfor external speech recognition models to generate pseudo-labels. AV-CPLobtains significant improvements in VSR performance on the LRS3 dataset whilemaintaining practical ASR and AVSR performance. Finally, using visual-onlyspeech data, our method is able to leverage unlabeled visual speech to improveVSR.</description><author>Andrew Rouditchenko, Ronan Collobert, Tatiana Likhomanenko</author><pubDate>Fri, 29 Sep 2023 17:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17395v1</guid></item><item><title>An Overview Of Temporal Commonsense Reasoning and Acquisition</title><link>http://arxiv.org/abs/2308.00002v2</link><description>Temporal commonsense reasoning refers to the ability to understand thetypical temporal context of phrases, actions, and events, and use it to reasonover problems requiring such knowledge. This trait is essential in temporalnatural language processing tasks, with possible applications such as timelinesummarization, temporal question answering, and temporal natural languageinference. Recent research on the performance of large language models suggeststhat, although they are adept at generating syntactically correct sentences andsolving classification tasks, they often take shortcuts in their reasoning andfall prey to simple linguistic traps. This article provides an overview ofresearch in the domain of temporal commonsense reasoning, particularly focusingon enhancing language model performance through a variety of augmentations andtheir evaluation across a growing number of datasets. However, these augmentedmodels still struggle to approach human performance on reasoning tasks overtemporal common sense properties, such as the typical occurrence times,orderings, or durations of events. We further emphasize the need for carefulinterpretation of research to guard against overpromising evaluation results inlight of the shallow reasoning present in transformers. This can be achieved byappropriately preparing datasets and suitable evaluation metrics.</description><author>Georg Wenzel, Adam Jatowt</author><pubDate>Fri, 29 Sep 2023 17:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00002v2</guid></item><item><title>Learning Deep O($n$)-Equivariant Hyperspheres</title><link>http://arxiv.org/abs/2305.15613v2</link><description>This paper presents an approach to learning (deep) $n$D features equivariantunder orthogonal transformations, utilizing hyperspheres and regular$n$-simplexes. Our main contributions are theoretical and tackle majorchallenges in geometric deep learning such as equivariance and invariance undergeometric transformations. Namely, we enrich the recently developed theory ofsteerable 3D spherical neurons -- SO(3)-equivariant filter banks based onneurons with spherical decision surfaces -- by extending said neurons to $n$D,which we call deep equivariant hyperspheres, and enabling their multi-layerconstruction. Using synthetic and real-world data in $n$D, we experimentallyverify our theoretical contributions and find that our approach is superior tothe baselines for small training data sets in all but one case.</description><author>Pavlo Melnyk, Michael Felsberg, Mrten Wadenbck, Andreas Robinson, Cuong Le</author><pubDate>Fri, 29 Sep 2023 17:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15613v2</guid></item><item><title>Forward Flow for Novel View Synthesis of Dynamic Scenes</title><link>http://arxiv.org/abs/2309.17390v1</link><description>This paper proposes a neural radiance field (NeRF) approach for novel viewsynthesis of dynamic scenes using forward warping. Existing methods often adopta static NeRF to represent the canonical space, and render dynamic images atother time steps by mapping the sampled 3D points back to the canonical spacewith the learned backward flow field. However, this backward flow field isnon-smooth and discontinuous, which is difficult to be fitted by commonly usedsmooth motion models. To address this problem, we propose to estimate theforward flow field and directly warp the canonical radiance field to other timesteps. Such forward flow field is smooth and continuous within the objectregion, which benefits the motion model learning. To achieve this goal, werepresent the canonical radiance field with voxel grids to enable efficientforward warping, and propose a differentiable warping process, including anaverage splatting operation and an inpaint network, to resolve the many-to-oneand one-to-many mapping issues. Thorough experiments show that our methodoutperforms existing methods in both novel view rendering and motion modeling,demonstrating the effectiveness of our forward flow motion modeling. Projectpage: https://npucvr.github.io/ForwardFlowDNeRF</description><author>Xiang Guo, Jiadai Sun, Yuchao Dai, Guanying Chen, Xiaoqing Ye, Xiao Tan, Errui Ding, Yumeng Zhang, Jingdong Wang</author><pubDate>Fri, 29 Sep 2023 17:51:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17390v1</guid></item><item><title>Prompt-based test-time real image dehazing: a novel pipeline</title><link>http://arxiv.org/abs/2309.17389v1</link><description>Existing methods attempt to improve models' generalization ability onreal-world hazy images by exploring well-designed training schemes (e.g.,cycleGAN, prior loss). However, most of them need very complicated trainingprocedures to achieve satisfactory results. In this work, we present a totallynovel testing pipeline called Prompt-based Test-Time Dehazing (PTTD) to helpgenerate visually pleasing results of real-captured hazy images during theinference phase. We experimentally find that given a dehazing model trained onsynthetic data, by fine-tuning the statistics (i.e., mean and standarddeviation) of encoding features, PTTD is able to narrow the domain gap,boosting the performance of real image dehazing. Accordingly, we first apply aprompt generation module (PGM) to generate a visual prompt, which is the sourceof appropriate statistical perturbations for mean and standard deviation. Andthen, we employ the feature adaptation module (FAM) into the existing dehazingmodels for adjusting the original statistics with the guidance of the generatedprompt. Note that, PTTD is model-agnostic and can be equipped with variousstate-of-the-art dehazing models trained on synthetic hazy-clean pairs.Extensive experimental results demonstrate that our PTTD is flexible meanwhileachieves superior performance against state-of-the-art dehazing methods inreal-world scenarios.</description><author>Zixuan Chen, Zewei He, Ziqian Lu, Zhe-Ming Lu</author><pubDate>Fri, 29 Sep 2023 17:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17389v1</guid></item><item><title>Tree Cross Attention</title><link>http://arxiv.org/abs/2309.17388v1</link><description>Cross Attention is a popular method for retrieving information from a set ofcontext tokens for making predictions. At inference time, for each prediction,Cross Attention scans the full set of $\mathcal{O}(N)$ tokens. In practice,however, often only a small subset of tokens are required for good performance.Methods such as Perceiver IO are cheap at inference as they distill theinformation to a smaller-sized set of latent tokens $L &lt; N$ on which crossattention is then applied, resulting in only $\mathcal{O}(L)$ complexity.However, in practice, as the number of input tokens and the amount ofinformation to distill increases, the number of latent tokens needed alsoincreases significantly. In this work, we propose Tree Cross Attention (TCA) -a module based on Cross Attention that only retrieves information from alogarithmic $\mathcal{O}(\log(N))$ number of tokens for performing inference.TCA organizes the data in a tree structure and performs a tree search atinference time to retrieve the relevant tokens for prediction. Leveraging TCA,we introduce ReTreever, a flexible architecture for token-efficient inference.We show empirically that Tree Cross Attention (TCA) performs comparable toCross Attention across various classification and uncertainty regression taskswhile being significantly more token-efficient. Furthermore, we compareReTreever against Perceiver IO, showing significant gains while using the samenumber of tokens for inference.</description><author>Leo Feng, Frederick Tung, Hossein Hajimirsadeghi, Yoshua Bengio, Mohamed Osama Ahmed</author><pubDate>Fri, 29 Sep 2023 17:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17388v1</guid></item><item><title>Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language</title><link>http://arxiv.org/abs/2306.02797v3</link><description>A core tension in models of concept learning is that the model must carefullybalance the tractability of inference against the expressivity of thehypothesis class. Humans, however, can efficiently learn a broad range ofconcepts. We introduce a model of inductive learning that seeks to behuman-like in that sense. It implements a Bayesian reasoning process where alanguage model first proposes candidate hypotheses expressed in naturallanguage, which are then re-weighed by a prior and a likelihood. By estimatingthe prior from human data, we can predict human judgments on learning problemsinvolving numbers and sets, spanning concepts that are generative,discriminative, propositional, and higher-order.</description><author>Kevin Ellis</author><pubDate>Fri, 29 Sep 2023 17:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02797v3</guid></item><item><title>Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization</title><link>http://arxiv.org/abs/2309.04669v2</link><description>Recently, the remarkable advance of the Large Language Model (LLM) hasinspired researchers to transfer its extraordinary reasoning capability to bothvision and language data. However, the prevailing approaches primarily regardthe visual input as a prompt and focus exclusively on optimizing the textgeneration process conditioned upon vision content by a frozen LLM. Such aninequitable treatment of vision and language heavily constrains the model'spotential. In this paper, we break through this limitation by representing bothvision and language in a unified form. Specifically, we introduce awell-designed visual tokenizer to translate the non-linguistic image into asequence of discrete tokens like a foreign language that LLM can read. Theresulting visual tokens encompass high-level semantics worthy of a word andalso support dynamic sequence length varying from the image. Coped with thistokenizer, the presented foundation model called LaVIT can handle both imageand text indiscriminately under the same generative learning paradigm. Thisunification empowers LaVIT to serve as an impressive generalist interface tounderstand and generate multi-modal content simultaneously. Extensiveexperiments further showcase that it outperforms the existing models by a largemargin on massive vision-language tasks. Our code and models will be availableat https://github.com/jy0205/LaVIT.</description><author>Yang Jin, Kun Xu, Kun Xu, Liwei Chen, Chao Liao, Jianchao Tan, Quzhe Huang, Bin Chen, Chenyi Lei, An Liu, Chengru Song, Xiaoqiang Lei, Di Zhang, Wenwu Ou, Kun Gai, Yadong Mu</author><pubDate>Fri, 29 Sep 2023 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04669v2</guid></item><item><title>SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States</title><link>http://arxiv.org/abs/2306.04817v2</link><description>Data in many scientific domains are often collected under multiple distinctstates (e.g., different clinical interventions), wherein latent processes(e.g., internal biological factors) can create complex variability betweenindividual trials both within single states and between states. A promisingapproach for addressing this complexity is uncovering fundamentalrepresentational units within the data, i.e., functional Building Blocks (BBs),that can adjust their temporal activity and component structure across trialsto capture the diverse spectrum of cross-trial variability. However, existingmethods for understanding such multi-dimensional data often rely on tensorfactorization under assumptions that may not align with the characteristics ofreal-world data, and struggle to accommodate trials of different durations,missing samples, and varied sampling rates. Here, we present a framework forSimilarity-driven Building Block Inference using Graphs across States(SiBBlInGS). SiBBlInGS employs a robust graph-based dictionary learningapproach for BB discovery that considers shared temporal activity, inter- andintra-state relationships, non-orthogonal components, and variations in sessioncounts and duration across states, while remaining resilient to noise, randominitializations, and missing samples. Additionally, it enables theidentification of state-specific vs. state-invariant BBs and allows forcross-state controlled variations in BB structure and per-trial temporalvariability. We demonstrate SiBBlInGS on synthetic and several real-worldexamples to highlight its ability to provide insights into the underlyingmechanisms of complex phenomena across fields.</description><author>Noga Mudrik, Gal Mishne, Adam S. Charles</author><pubDate>Fri, 29 Sep 2023 17:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04817v2</guid></item><item><title>Parallel Computation of Multi-Slice Clustering of Third-Order Tensors</title><link>http://arxiv.org/abs/2309.17383v1</link><description>Machine Learning approaches like clustering methods deal with massivedatasets that present an increasing challenge. We devise parallel algorithms tocompute the Multi-Slice Clustering (MSC) for 3rd-order tensors. The MSC methodis based on spectral analysis of the tensor slices and works independently oneach tensor mode. Such features fit well in the parallel paradigm via adistributed memory system. We show that our parallel scheme outperformssequential computing and allows for the scalability of the MSC method.</description><author>Dina Faneva Andriantsiory, Camille Coti, Joseph Ben Geloun, Mustapha Lebbah</author><pubDate>Fri, 29 Sep 2023 17:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17383v1</guid></item><item><title>Interpretable neural architecture search and transfer learning for understanding CRISPR/Cas9 off-target enzymatic reactions</title><link>http://arxiv.org/abs/2305.11917v2</link><description>Finely-tuned enzymatic pathways control cellular processes, and theirdysregulation can lead to disease. Creating predictive and interpretable modelsfor these pathways is challenging because of the complexity of the pathways andof the cellular and genomic contexts. Here we introduce Elektrum, a deeplearning framework which addresses these challenges with data-driven andbiophysically interpretable models for determining the kinetics of biochemicalsystems. First, it uses in vitro kinetic assays to rapidly hypothesize anensemble of high-quality Kinetically Interpretable Neural Networks (KINNs) thatpredict reaction rates. It then employs a novel transfer learning step, wherethe KINNs are inserted as intermediary layers into deeper convolutional neuralnetworks, fine-tuning the predictions for reaction-dependent in vivo outcomes.Elektrum makes effective use of the limited, but clean in vitro data and thecomplex, yet plentiful in vivo data that captures cellular context. We applyElektrum to predict CRISPR-Cas9 off-target editing probabilities anddemonstrate that Elektrum achieves state-of-the-art performance, regularizesneural network architectures, and maintains physical interpretability.</description><author>Zijun Zhang, Adam R. Lamson, Michael Shelley, Olga Troyanskaya</author><pubDate>Fri, 29 Sep 2023 17:36:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11917v2</guid></item><item><title>Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency</title><link>http://arxiv.org/abs/2309.17382v1</link><description>Large language models (LLMs) demonstrate impressive reasoning abilities, buttranslating reasoning into actions in the real world remains challenging. Inparticular, it remains unclear how to complete a given task provably within aminimum number of interactions with the external environment, e.g., through aninternal mechanism of reasoning. To this end, we propose a principled frameworkwith provable regret guarantees to orchestrate reasoning and acting, which wecall ``reason for future, act for now" (\texttt{RAFA}). Specifically, we designa prompt template for reasoning that learns from the memory buffer and plans afuture trajectory over a long horizon (``reason for future"). At each step, theLLM agent takes the initial action of the planned trajectory (``act for now"),stores the collected feedback in the memory buffer, and reinvokes the reasoningroutine to replan the future trajectory from the new state. The key idea is to cast reasoning in LLMs as learning and planning inBayesian adaptive Markov decision processes (MDPs). Correspondingly, we promptLLMs to form an updated posterior of the unknown environment from the memorybuffer (learning) and generate an optimal trajectory for multiple future stepsthat maximizes a value function (planning). The learning and planningsubroutines are performed in an "in-context" manner to emulate the actor-criticupdate for MDPs. Our theoretical analysis proves that the novel combination oflong-term reasoning and short-term acting achieves a $\sqrt{T}$ regret. Inparticular, the regret bound highlights an intriguing interplay between theprior knowledge obtained through pretraining and the uncertainty reductionachieved by reasoning and acting. Our empirical validation shows that itoutperforms various existing frameworks and achieves nearly perfect scores on afew benchmarks.</description><author>Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, Zhaoran Wang</author><pubDate>Fri, 29 Sep 2023 17:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17382v1</guid></item><item><title>Leveraging Task Structures for Improved Identifiability in Neural Network Representations</title><link>http://arxiv.org/abs/2306.14861v2</link><description>This work extends the theory of identifiability in supervised learning byconsidering the consequences of having access to a distribution of tasks. Insuch cases, we show that identifiability is achievable even in the case ofregression, extending prior work restricted to linear identifiability in thesingle-task classification case. Furthermore, we show that the existence of atask distribution which defines a conditional prior over latent factors reducesthe equivalence class for identifiability to permutations and scaling, a muchstronger and more useful result than linear identifiability. When we furtherassume a causal structure over these tasks, our approach enables simple maximummarginal likelihood optimization together with downstream applicability tocausal representation learning. Empirically, we validate that our modeloutperforms more general unsupervised models in recovering canonicalrepresentations for both synthetic and real-world molecular data.</description><author>Wenlin Chen, Julien Horwood, Juyeon Heo, Jos Miguel Hernndez-Lobato</author><pubDate>Fri, 29 Sep 2023 17:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14861v2</guid></item><item><title>PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis</title><link>http://arxiv.org/abs/2309.05833v3</link><description>Major cloud providers have employed advanced AI-based solutions like largelanguage models to aid humans in identifying the root causes of cloudincidents. Despite the growing prevalence of AI-driven assistants in the rootcause analysis process, their effectiveness in assisting on-call engineers isconstrained by low accuracy due to the intrinsic difficulty of the task, apropensity for LLM-based approaches to hallucinate, and difficulties indistinguishing these well-disguised hallucinations. To address this challenge,we propose to perform confidence estimation for the predictions to help on-callengineers make decisions on whether to adopt the model prediction. Consideringthe black-box nature of many LLM-based root cause predictors, fine-tuning ortemperature-scaling-based approaches are inapplicable. We therefore design aninnovative confidence estimation framework based on promptingretrieval-augmented large language models (LLMs) that demand a minimal amountof information from the root cause predictor. This approach consists of twoscoring phases: the LLM-based confidence estimator first evaluates itsconfidence in making judgments in the face of the current incident thatreflects its ``grounded-ness" level in reference data, then rates the rootcause prediction based on historical references. An optimization step combinesthese two scores for a final confidence assignment. We show that our method isable to produce calibrated confidence estimates for predicted root causes,validate the usefulness of retrieved historical data and the prompting strategyas well as the generalizability across different root cause prediction models.Our study takes an important move towards reliably and effectively embeddingLLMs into cloud incident management systems.</description><author>Dylan Zhang, Xuchao Zhang, Chetan Bansal, Pedro Las-Casas, Rodrigo Fonseca, Saravan Rajmohan</author><pubDate>Fri, 29 Sep 2023 17:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05833v3</guid></item><item><title>On the Limitations of Temperature Scaling for Distributions with Overlaps</title><link>http://arxiv.org/abs/2306.00740v2</link><description>Despite the impressive generalization capabilities of deep neural networks,they have been repeatedly shown to be overconfident when they are wrong. Fixingthis issue is known as model calibration, and has consequently received muchattention in the form of modified training schemes and post-trainingcalibration procedures such as temperature scaling. While temperature scalingis frequently used because of its simplicity, it is often outperformed bymodified training schemes. In this work, we identify a specific bottleneck forthe performance of temperature scaling. We show that for empirical riskminimizers for a general set of distributions in which the supports of classeshave overlaps, the performance of temperature scaling degrades with the amountof overlap between classes, and asymptotically becomes no better than randomwhen there are a large number of classes. On the other hand, we prove thatoptimizing a modified form of the empirical risk induced by the Mixup dataaugmentation technique can in fact lead to reasonably good calibrationperformance, showing that training-time calibration may be necessary in somesituations. We also verify that our theoretical results reflect practice byshowing that Mixup significantly outperforms empirical risk minimization (withrespect to multiple calibration metrics) on image classification benchmarkswith class overlaps introduced in the form of label noise.</description><author>Muthu Chidambaram, Rong Ge</author><pubDate>Fri, 29 Sep 2023 17:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00740v2</guid></item><item><title>Adversarial Imitation Learning from Visual Observations using Latent Information</title><link>http://arxiv.org/abs/2309.17371v1</link><description>We focus on the problem of imitation learning from visual observations, wherethe learning agent has access to videos of experts as its sole learning source.The challenges of this framework include the absence of expert actions and thepartial observability of the environment, as the ground-truth states can onlybe inferred from pixels. To tackle this problem, we first conduct a theoreticalanalysis of imitation learning in partially observable environments. Weestablish upper bounds on the suboptimality of the learning agent with respectto the divergence between the expert and the agent latent state-transitiondistributions. Motivated by this analysis, we introduce an algorithm calledLatent Adversarial Imitation from Observations, which combines off-policyadversarial imitation techniques with a learned latent representation of theagent's state from sequences of observations. In experiments onhigh-dimensional continuous robotic tasks, we show that our algorithm matchesstate-of-the-art performance while providing significant computationaladvantages. Additionally, we show how our method can be used to improve theefficiency of reinforcement learning from pixels by leveraging expert videos.To ensure reproducibility, we provide free access to our code.</description><author>Vittorio Giammarino, James Queeney, Ioannis Ch. Paschalidis</author><pubDate>Fri, 29 Sep 2023 17:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17371v1</guid></item><item><title>Graph-based Neural Weather Prediction for Limited Area Modeling</title><link>http://arxiv.org/abs/2309.17370v1</link><description>The rise of accurate machine learning methods for weather forecasting iscreating radical new possibilities for modeling the atmosphere. In the time ofclimate change, having access to high-resolution forecasts from models likethese is also becoming increasingly vital. While most existing Neural WeatherPrediction (NeurWP) methods focus on global forecasting, an important questionis how these techniques can be applied to limited area modeling. In this workwe adapt the graph-based NeurWP approach to the limited area setting andpropose a multi-scale hierarchical model extension. Our approach is validatedby experiments with a local model for the Nordic region.</description><author>Joel Oskarsson, Tomas Landelius, Fredrik Lindsten</author><pubDate>Fri, 29 Sep 2023 17:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17370v1</guid></item><item><title>PESTS: Persian_English Cross Lingual Corpus for Semantic Textual Similarity</title><link>http://arxiv.org/abs/2305.07893v2</link><description>One of the components of natural language processing that has received a lotof investigation recently is semantic textual similarity. In computationallinguistics and natural language processing, assessing the semantic similarityof words, phrases, paragraphs, and texts is crucial. Calculating the degree ofsemantic resemblance between two textual pieces, paragraphs, or phrasesprovided in both monolingual and cross-lingual versions is known as semanticsimilarity. Cross lingual semantic similarity requires corpora in which thereare sentence pairs in both the source and target languages with a degree ofsemantic similarity between them. Many existing cross lingual semanticsimilarity models use a machine translation due to the unavailability of crosslingual semantic similarity dataset, which the propagation of the machinetranslation error reduces the accuracy of the model. On the other hand, when wewant to use semantic similarity features for machine translation the samemachine translations should not be used for semantic similarity. For Persian,which is one of the low resource languages, no effort has been made in thisregard and the need for a model that can understand the context of twolanguages is felt more than ever. In this article, the corpus of semantictextual similarity between sentences in Persian and English languages has beenproduced for the first time by using linguistic experts. We named this datasetPESTS (Persian English Semantic Textual Similarity). This corpus contains 5375sentence pairs. Also, different models based on transformers have beenfine-tuned using this dataset. The results show that using the PESTS dataset,the Pearson correlation of the XLM ROBERTa model increases from 85.87% to95.62%.</description><author>Mohammad Abdous, Poorya Piroozfar, Behrouz Minaei Bidgoli</author><pubDate>Fri, 29 Sep 2023 17:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07893v2</guid></item><item><title>Scope is all you need: Transforming LLMs for HPC Code</title><link>http://arxiv.org/abs/2308.09440v3</link><description>With easier access to powerful compute resources, there is a growing trend inthe field of AI for software development to develop larger and larger languagemodels (LLMs) to address a variety of programming tasks. Even LLMs applied totasks from the high-performance computing (HPC) domain are huge in size (e.g.,billions of parameters) and demand expensive compute resources for training. Wefound this design choice confusing - why do we need large LLMs trained onnatural languages and programming languages unrelated to HPC for HPC-specifictasks? In this line of work, we aim to question design choices made by existingLLMs by developing smaller LLMs for specific domains - we call themdomain-specific LLMs. Specifically, we start off with HPC as a domain andpropose a novel tokenizer named Tokompiler, designed specifically forpreprocessing code in HPC and compilation-centric tasks. Tokompiler leveragesknowledge of language primitives to generate language-oriented tokens,providing a context-aware understanding of code structure while avoiding humansemantics attributed to code structures completely. We applied Tokompiler topre-train two state-of-the-art models, SPT-Code and Polycoder, for a Fortrancode corpus mined from GitHub. We evaluate the performance of these modelsagainst the conventional LLMs. Results demonstrate that Tokompilersignificantly enhances code completion accuracy and semantic understandingcompared to traditional tokenizers in normalized-perplexity tests, down to ~1perplexity score. This research opens avenues for further advancements indomain-specific LLMs, catering to the unique demands of HPC and compilationtasks.</description><author>Tal Kadosh, Niranjan Hasabnis, Vy A. Vo, Nadav Schneider, Neva Krien, Abdul Wasay, Nesreen Ahmed, Ted Willke, Guy Tamir, Yuval Pinter, Timothy Mattson, Gal Oren</author><pubDate>Fri, 29 Sep 2023 17:11:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09440v3</guid></item><item><title>Goal-oriented Uncertainty Quantification for Inverse Problems via Variational Encoder-Decoder Networks</title><link>http://arxiv.org/abs/2304.08324v2</link><description>In this work, we describe a new approach that uses variationalencoder-decoder (VED) networks for efficient goal-oriented uncertaintyquantification for inverse problems. Contrary to standard inverse problems,these approaches are \emph{goal-oriented} in that the goal is to estimate somequantities of interest (QoI) that are functions of the solution of an inverseproblem, rather than the solution itself. Moreover, we are interested incomputing uncertainty metrics associated with the QoI, thus utilizing aBayesian approach for inverse problems that incorporates the predictionoperator and techniques for exploring the posterior. This may be particularlychallenging, especially for nonlinear, possibly unknown, operators andnonstandard prior assumptions. We harness recent advances in machine learning,i.e., VED networks, to describe a data-driven approach to large-scale inverseproblems. This enables a real-time goal-oriented uncertainty quantification forthe QoI. One of the advantages of our approach is that we avoid the need tosolve challenging inversion problems by training a network to approximate themapping from observations to QoI. Another main benefit is that we enableuncertainty quantification for the QoI by leveraging probability distributionsin the latent space. This allows us to efficiently generate QoI samples andcircumvent complicated or even unknown forward models and prediction operators.Numerical results from medical tomography reconstruction and nonlinearhydraulic tomography demonstrate the potential and broad applicability of theapproach.</description><author>Babak Maboudi Afkham, Julianne Chung, Matthias Chung</author><pubDate>Fri, 29 Sep 2023 17:07:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08324v2</guid></item><item><title>Gaussian Latent Representations for Uncertainty Estimation using Mahalanobis Distance in Deep Classifiers</title><link>http://arxiv.org/abs/2305.13849v3</link><description>Recent works show that the data distribution in a network's latent space isuseful for estimating classification uncertainty and detectingOut-of-distribution (OOD) samples. To obtain a well-regularized latent spacethat is conducive for uncertainty estimation, existing methods bring insignificant changes to model architectures and training procedures. In thispaper, we present a lightweight, fast, and high-performance regularizationmethod for Mahalanobis distance-based uncertainty prediction, and that requiresminimal changes to the network's architecture. To derive Gaussian latentrepresentation favourable for Mahalanobis Distance calculation, we introduce aself-supervised representation learning method that separates in-classrepresentations into multiple Gaussians. Classes with non-Gaussianrepresentations are automatically identified and dynamically clustered intomultiple new classes that are approximately Gaussian. Evaluation on standardOOD benchmarks shows that our method achieves state-of-the-art results on OODdetection with minimal inference time, and is very competitive on predictiveprobability calibration. Finally, we show the applicability of our method to areal-life computer vision use case on microorganism classification.</description><author>Aishwarya Venkataramanan, Assia Benbihi, Martin Laviale, Cedric Pradalier</author><pubDate>Fri, 29 Sep 2023 17:07:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13849v3</guid></item><item><title>Multi-task Meta Label Correction for Time Series Prediction</title><link>http://arxiv.org/abs/2303.08103v2</link><description>Time series classification faces two unavoidable problems. One is partialfeature information and the other is poor label quality, which may affect modelperformance. To address the above issues, we create a label correction methodto time series data with meta-learning under a multi-task framework. There arethree main contributions. First, we train the label correction model with atwo-branch neural network for the outer loop. While in the model-agnostic innerloop, we use pre-existing classification models in a multi-task way and jointlyupdate the meta-knowledge, which makes us achieve adaptive labeling on complextime series. Second, we devise new data visualization methods for both imagepatterns of the historical data and data in the prediction horizon. Finally, wetest our method with various financial datasets, including XOM, S\&amp;P500, andSZ50. Results show that our method is more effective and accurate than someexisting label correction techniques.</description><author>Luxuan Yang, Ting Gao, Wei Wei, Min Dai, Cheng Fang, Jinqiao Duan</author><pubDate>Fri, 29 Sep 2023 17:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.08103v2</guid></item><item><title>Mitigating Label Bias via Decoupled Confident Learning</title><link>http://arxiv.org/abs/2307.08945v2</link><description>Growing concerns regarding algorithmic fairness have led to a surge inmethodologies to mitigate algorithmic bias. However, such methodologies largelyassume that observed labels in training data are correct. This is problematicbecause bias in labels is pervasive across important domains, includinghealthcare, hiring, and content moderation. In particular, human-generatedlabels are prone to encoding societal biases. While the presence of labelingbias has been discussed conceptually, there is a lack of methodologies toaddress this problem. We propose a pruning method -- Decoupled ConfidentLearning (DeCoLe) -- specifically designed to mitigate label bias. Afterillustrating its performance on a synthetic dataset, we apply DeCoLe in thecontext of hate speech detection, where label bias has been recognized as animportant challenge, and show that it successfully identifies biased labels andoutperforms competing approaches.</description><author>Yunyi Li, Maria De-Arteaga, Maytal Saar-Tsechansky</author><pubDate>Fri, 29 Sep 2023 17:06:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08945v2</guid></item><item><title>Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings</title><link>http://arxiv.org/abs/2309.17361v1</link><description>The massive interest in deep neural networks (DNNs) for both computer visionand natural language processing has been sparked by the growth in computationalpower. However, this led to an increase in the memory footprint, to a pointwhere it can be challenging to simply load a model on commodity devices such asmobile phones. To address this limitation, quantization is a favored solutionas it maps high precision tensors to a low precision, memory efficient format.In terms of memory footprint reduction, its most effective variants are basedon codebooks. These methods, however, suffer from two limitations. First, theyeither define a single codebook for each tensor, or use a memory-expensivemapping to multiple codebooks. Second, gradient descent optimization of themapping favors jumps toward extreme values, hence not defining a proximalsearch. In this work, we propose to address these two limitations. First, weinitially group similarly distributed neurons and leverage the re-orderedstructure to either apply different scale factors to the different groups, ormap weights that fall in these groups to several codebooks, without any mappingoverhead. Second, stemming from this initialization, we propose a jointlearning of the codebook and weight mappings that bears similarities withrecent gradient-based post-training quantization techniques. Third, drawingestimation from straight-through estimation techniques, we introduce a novelgradient update definition to enable a proximal search of the codebooks andtheir mappings. The proposed jointly learnable codebooks and mappings (JLCM)method allows a very efficient approximation of any DNN: as such, a Llama 7Bcan be compressed down to 2Go and loaded on 5-year-old smartphones.</description><author>Edouard Yvinec, Arnaud Dapogny, Kevin Bailly</author><pubDate>Fri, 29 Sep 2023 17:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17361v1</guid></item><item><title>Module-wise Training of Neural Networks via the Minimizing Movement Scheme</title><link>http://arxiv.org/abs/2309.17357v1</link><description>Greedy layer-wise or module-wise training of neural networks is compelling inconstrained and on-device settings where memory is limited, as it circumvents anumber of problems of end-to-end back-propagation. However, it suffers from astagnation problem, whereby early layers overfit and deeper layers stopincreasing the test accuracy after a certain depth. We propose to solve thisissue by introducing a module-wise regularization inspired by the minimizingmovement scheme for gradient flows in distribution space. We call the methodTRGL for Transport Regularized Greedy Learning and study it theoretically,proving that it leads to greedy modules that are regular and that progressivelysolve the task. Experimentally, we show improved accuracy of module-wisetraining of various architectures such as ResNets, Transformers and VGG, whenour regularization is added, superior to that of other module-wise trainingmethods and often to end-to-end training, with as much as 60% less memoryusage.</description><author>Skander Karkar, Ibrahim Ayed, Emmanuel de Bzenac, Patrick Gallinari</author><pubDate>Fri, 29 Sep 2023 17:03:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17357v1</guid></item><item><title>Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning</title><link>http://arxiv.org/abs/2306.14565v3</link><description>Despite the promising progress in multi-modal tasks, current largemulti-modal models (LMMs) are prone to hallucinating inconsistent descriptionswith respect to the associated image and human instructions. This paperaddresses this issue by introducing the first large and diverse visualinstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.Our dataset comprises 400k visual instructions generated by GPT4, covering 16vision-and-language tasks with open-ended instructions and answers. Unlikeexisting studies that primarily focus on positive instruction samples, wedesign LRV-Instruction to include both positive and negative instructions formore robust visual instruction tuning. Our negative instructions are designedat three semantic levels: (i) Nonexistent Object Manipulation, (ii) ExistentObject Manipulation and (iii) Knowledge Manipulation. To efficiently measurethe hallucination generated by LMMs, we propose GPT4-Assisted VisualInstruction Evaluation (GAVIE), a stable approach to evaluate visualinstruction tuning like human experts. GAVIE does not require human-annotatedgroundtruth answers and can adapt to diverse instruction formats. We conductcomprehensive experiments to investigate the hallucination of LMMs. Our resultsdemonstrate existing LMMs exhibit significant hallucinations when presentedwith our negative instructions, particularly Existent Object and KnowledgeManipulation instructions. Moreover, we successfully mitigate hallucination byfinetuning MiniGPT4 and mPLUG-Owl on LRV-Instruction while improvingperformance on several public datasets compared to state-of-the-art methods.Additionally, we observed that a balanced ratio of positive and negativeinstances in the training data leads to a more robust model.</description><author>Fuxiao Liu, Kevin Lin, Linjie Li, Jianfeng Wang, Yaser Yacoob, Lijuan Wang</author><pubDate>Fri, 29 Sep 2023 17:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14565v3</guid></item><item><title>LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints</title><link>http://arxiv.org/abs/2309.15458v2</link><description>Integrating first-order logic constraints (FOLCs) with neural networks is acrucial but challenging problem since it involves modeling intricatecorrelations to satisfy the constraints. This paper proposes a novel neurallayer, LogicMP, whose layers perform mean-field variational inference over anMLN. It can be plugged into any off-the-shelf neural network to encode FOLCswhile retaining modularity and efficiency. By exploiting the structure andsymmetries in MLNs, we theoretically demonstrate that our well-designed,efficient mean-field iterations effectively mitigate the difficulty of MLNinference, reducing the inference from sequential calculation to a series ofparallel tensor operations. Empirical results in three kinds of tasks overgraphs, images, and text show that LogicMP outperforms advanced competitors inboth performance and efficiency.</description><author>Weidi Xu, Jingwei Wang, Lele Xie, Jianshan He, Hongting Zhou, Taifeng Wang, Xiaopei Wan, Jingdong Chen, Chao Qu, Wei Chu</author><pubDate>Fri, 29 Sep 2023 17:00:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15458v2</guid></item><item><title>Efficient Biologically Plausible Adversarial Training</title><link>http://arxiv.org/abs/2309.17348v1</link><description>Artificial Neural Networks (ANNs) trained with Backpropagation (BP) showastounding performance and are increasingly often used in performing our dailylife tasks. However, ANNs are highly vulnerable to adversarial attacks, whichalter inputs with small targeted perturbations that drastically disrupt themodels' performance. The most effective method to make ANNs robust againstthese attacks is adversarial training, in which the training dataset isaugmented with exemplary adversarial samples. Unfortunately, this approach hasthe drawback of increased training complexity since generating adversarialsamples is very computationally demanding. In contrast to ANNs, humans are notsusceptible to adversarial attacks. Therefore, in this work, we investigatewhether biologically-plausible learning algorithms are more robust againstadversarial attacks than BP. In particular, we present an extensive comparativeanalysis of the adversarial robustness of BP and \textit{Present the Error toPerturb the Input To modulate Activity} (PEPITA), a recently proposedbiologically-plausible learning algorithm, on various computer vision tasks. Weobserve that PEPITA has higher intrinsic adversarial robustness and, withadversarial training, has a more favourable natural-vs-adversarial performancetrade-off as, for the same natural accuracies, PEPITA's adversarial accuraciesdecrease in average by 0.26% and BP's by 8.05%.</description><author>Matilde Tristany Farinha, Thomas Ortner, Giorgia Dellaferrera, Benjamin Grewe, Angeliki Pantazi</author><pubDate>Fri, 29 Sep 2023 16:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17348v1</guid></item><item><title>Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems</title><link>http://arxiv.org/abs/2309.01188v2</link><description>Modern neural collaborative filtering techniques are critical to the successof e-commerce, social media, and content-sharing platforms. However, despitetechnical advances -- for every new application domain, we need to train an NCFmodel from scratch. In contrast, pre-trained vision and language models areroutinely applied to diverse applications directly (zero-shot) or with limitedfine-tuning. Inspired by the impact of pre-trained models, we explore thepossibility of pre-trained recommender models that support building recommendersystems in new domains, with minimal or no retraining, without the use of anyauxiliary user or item information. Zero-shot recommendation without auxiliaryinformation is challenging because we cannot form associations between usersand items across datasets when there are no overlapping users or items. Ourfundamental insight is that the statistical characteristics of the user-iteminteraction matrix are universally available across different domains anddatasets. Thus, we use the statistical characteristics of the user-iteminteraction matrix to identify dataset-independent representations for usersand items. We show how to learn universal (i.e., supporting zero-shotadaptation without user or item auxiliary information) representations fornodes and edges from the bipartite user-item interaction graph. We learnrepresentations by exploiting the statistical properties of the interactiondata, including user and item marginals, and the size and density distributionsof their clusters.</description><author>Junting Wang, Adit Krishnan, Hari Sundaram, Yunzhe Li</author><pubDate>Fri, 29 Sep 2023 16:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01188v2</guid></item><item><title>Benchmarks for Detecting Measurement Tampering</title><link>http://arxiv.org/abs/2308.15605v5</link><description>When training powerful AI systems to perform complex tasks, it may bechallenging to provide training signals which are robust to optimization. Oneconcern is \textit{measurement tampering}, where the AI system manipulatesmultiple measurements to create the illusion of good results instead ofachieving the desired outcome. In this work, we build four new text-baseddatasets to evaluate measurement tampering detection techniques on largelanguage models. Concretely, given sets of text inputs and measurements aimedat determining if some outcome occurred, as well as a base model able toaccurately predict measurements, the goal is to determine if examples where allmeasurements indicate the outcome occurred actually had the outcome occur, orif this was caused by measurement tampering. We demonstrate techniques thatoutperform simple baselines on most datasets, but don't achieve maximumperformance. We believe there is significant room for improvement for bothtechniques and datasets, and we are excited for future work tacklingmeasurement tampering.</description><author>Fabien Roger, Ryan Greenblatt, Max Nadeau, Buck Shlegeris, Nate Thomas</author><pubDate>Fri, 29 Sep 2023 16:53:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15605v5</guid></item><item><title>Neural Lithography: Close the Design-to-Manufacturing Gap in Computational Optics with a 'Real2Sim' Learned Photolithography Simulator</title><link>http://arxiv.org/abs/2309.17343v1</link><description>We introduce neural lithography to address the 'design-to-manufacturing' gapin computational optics. Computational optics with large design degrees offreedom enable advanced functionalities and performance beyond traditionaloptics. However, the existing design approaches often overlook the numericalmodeling of the manufacturing process, which can result in significantperformance deviation between the design and the fabricated optics. To bridgethis gap, we, for the first time, propose a fully differentiable designframework that integrates a pre-trained photolithography simulator into themodel-based optical design loop. Leveraging a blend of physics-informedmodeling and data-driven training using experimentally collected datasets, ourphotolithography simulator serves as a regularizer on fabrication feasibilityduring design, compensating for structure discrepancies introduced in thelithography process. We demonstrate the effectiveness of our approach throughtwo typical tasks in computational optics, where we design and fabricate aholographic optical element (HOE) and a multi-level diffractive lens (MDL)using a two-photon lithography system, showcasing improved optical performanceon the task-specific metrics.</description><author>Cheng Zheng, Guangyuan Zhao, Peter T. C. So</author><pubDate>Fri, 29 Sep 2023 16:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17343v1</guid></item><item><title>Towards Free Data Selection with General-Purpose Models</title><link>http://arxiv.org/abs/2309.17342v1</link><description>A desirable data selection algorithm can efficiently choose the mostinformative samples to maximize the utility of limited annotation budgets.However, current approaches, represented by active learning methods, typicallyfollow a cumbersome pipeline that iterates the time-consuming model trainingand batch data selection repeatedly. In this paper, we challenge this statusquo by designing a distinct data selection pipeline that utilizes existinggeneral-purpose models to select data from various datasets with a single-passinference without the need for additional training or supervision. A novel freedata selection (FreeSel) method is proposed following this new pipeline.Specifically, we define semantic patterns extracted from inter-mediate featuresof the general-purpose model to capture subtle local information in each image.We then enable the selection of all data samples in a single pass throughdistance-based sampling at the fine-grained semantic pattern level. FreeSelbypasses the heavy batch selection process, achieving a significant improvementin efficiency and being 530x faster than existing active learning methods.Extensive experiments verify the effectiveness of FreeSel on various computervision tasks. Our code is available at https://github.com/yichen928/FreeSel.</description><author>Yichen Xie, Mingyu Ding, Masayoshi Tomizuka, Wei Zhan</author><pubDate>Fri, 29 Sep 2023 16:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17342v1</guid></item><item><title>MixQuant: Mixed Precision Quantization with a Bit-width Optimization Search</title><link>http://arxiv.org/abs/2309.17341v1</link><description>Quantization is a technique for creating efficient Deep Neural Networks(DNNs), which involves performing computations and storing tensors at lowerbit-widths than f32 floating point precision. Quantization reduces model sizeand inference latency, and therefore allows for DNNs to be deployed onplatforms with constrained computational resources and real-time systems.However, quantization can lead to numerical instability caused by roundofferror which leads to inaccurate computations and therefore, a decrease inquantized model accuracy. Similarly to prior works, which have shown that bothbiases and activations are more sensitive to quantization and are best kept infull precision or quantized with higher bit-widths, we show that some weightsare more sensitive than others which should be reflected on their quantizationbit-width. To that end we propose MixQuant, a search algorithm that finds theoptimal custom quantization bit-width for each layer weight based on roundofferror and can be combined with any quantization method as a form ofpre-processing optimization. We show that combining MixQuant with BRECQ, astate-of-the-art quantization method, yields better quantized model accuracythan BRECQ alone. Additionally, we combine MixQuant with vanilla asymmetricquantization to show that MixQuant has the potential to optimize theperformance of any quantization technique.</description><author>Eliska Kloberdanz, Wei Le</author><pubDate>Fri, 29 Sep 2023 16:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17341v1</guid></item><item><title>Outage-Watch: Early Prediction of Outages using Extreme Event Regularizer</title><link>http://arxiv.org/abs/2309.17340v1</link><description>Cloud services are omnipresent and critical cloud service failure is a factof life. In order to retain customers and prevent revenue loss, it is importantto provide high reliability guarantees for these services. One way to do thisis by predicting outages in advance, which can help in reducing the severity aswell as time to recovery. It is difficult to forecast critical failures due tothe rarity of these events. Moreover, critical failures are ill-defined interms of observable data. Our proposed method, Outage-Watch, defines criticalservice outages as deteriorations in the Quality of Service (QoS) captured by aset of metrics. Outage-Watch detects such outages in advance by using currentsystem state to predict whether the QoS metrics will cross a threshold andinitiate an extreme event. A mixture of Gaussian is used to model thedistribution of the QoS metrics for flexibility and an extreme eventregularizer helps in improving learning in tail of the distribution. An outageis predicted if the probability of any one of the QoS metrics crossingthreshold changes significantly. Our evaluation on a real-world SaaS companydataset shows that Outage-Watch significantly outperforms traditional methodswith an average AUC of 0.98. Additionally, Outage-Watch detects all the outagesexhibiting a change in service metrics and reduces the Mean Time To Detection(MTTD) of outages by up to 88% when deployed in an enterprise cloud-servicesystem, demonstrating efficacy of our proposed method.</description><author>Shubham Agarwal, Sarthak Chakraborty, Shaddy Garg, Sumit Bisht, Chahat Jain, Ashritha Gonuguntla, Shiv Saini</author><pubDate>Fri, 29 Sep 2023 16:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17340v1</guid></item><item><title>Scaling Experiments in Self-Supervised Cross-Table Representation Learning</title><link>http://arxiv.org/abs/2309.17339v1</link><description>To analyze the scaling potential of deep tabular representation learningmodels, we introduce a novel Transformer-based architecture specificallytailored to tabular data and cross-table representation learning by utilizingtable-specific tokenizers and a shared Transformer backbone. Our trainingapproach encompasses both single-table and cross-table models, trained viamissing value imputation through a self-supervised masked cell recoveryobjective. To understand the scaling behavior of our method, we train models ofvarying sizes, ranging from approximately $10^4$ to $10^7$ parameters. Thesemodels are trained on a carefully curated pretraining dataset, consisting of135M training tokens sourced from 76 diverse datasets. We assess the scaling ofour architecture in both single-table and cross-table pretraining setups byevaluating the pretrained models using linear probing on a curated set ofbenchmark datasets and comparing the results with conventional baselines.</description><author>Maximilian Schambach, Dominique Paul, Johannes S. Otterbach</author><pubDate>Fri, 29 Sep 2023 16:48:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17339v1</guid></item><item><title>Improving Trajectory Prediction in Dynamic Multi-Agent Environment by Dropping Waypoints</title><link>http://arxiv.org/abs/2309.17338v1</link><description>The inherently diverse and uncertain nature of trajectories presents aformidable challenge in accurately modeling them. Motion prediction systemsmust effectively learn spatial and temporal information from the past toforecast the future trajectories of the agent. Many existing methods learntemporal motion via separate components within stacked models to capturetemporal features. This paper introduces a novel framework, called TemporalWaypoint Dropping (TWD), that promotes explicit temporal learning through thewaypoint dropping technique. Learning through waypoint dropping can compel themodel to improve its understanding of temporal correlations among agents, thusleading to a significant enhancement in trajectory prediction. Trajectoryprediction methods often operate under the assumption that observed trajectorywaypoint sequences are complete, disregarding real-world scenarios wheremissing values may occur, which can influence their performance. Moreover,these models frequently exhibit a bias towards particular waypoint sequenceswhen making predictions. Our TWD is capable of effectively addressing theseissues. It incorporates stochastic and fixed processes that regularizeprojected past trajectories by strategically dropping waypoints based ontemporal sequences. Through extensive experiments, we demonstrate theeffectiveness of TWD in forcing the model to learn complex temporalcorrelations among agents. Our approach can complement existing trajectoryprediction methods to enhance prediction accuracy. We also evaluate ourproposed method across three datasets: NBA Sports VU, ETH-UCY, and TrajNet++.</description><author>Pranav Singh Chib, Pravendra Singh</author><pubDate>Fri, 29 Sep 2023 16:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17338v1</guid></item><item><title>Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools</title><link>http://arxiv.org/abs/2309.17337v1</link><description>While algorithmic fairness is a thriving area of research, in practice,mitigating issues of bias often gets reduced to enforcing an arbitrarily chosenfairness metric, either by enforcing fairness constraints during theoptimization step, post-processing model outputs, or by manipulating thetraining data. Recent work has called on the ML community to take a moreholistic approach to tackle fairness issues by systematically investigating themany design choices made through the ML pipeline, and identifying interventionsthat target the issue's root cause, as opposed to its symptoms. While we sharethe conviction that this pipeline-based approach is the most appropriate forcombating algorithmic unfairness on the ground, we believe there are currentlyvery few methods of \emph{operationalizing} this approach in practice. Drawingon our experience as educators and practitioners, we first demonstrate thatwithout clear guidelines and toolkits, even individuals with specialized MLknowledge find it challenging to hypothesize how various design choicesinfluence model behavior. We then consult the fair-ML literature to understandthe progress to date toward operationalizing the pipeline-aware approach: wesystematically collect and organize the prior work that attempts to detect,measure, and mitigate various sources of unfairness through the ML pipeline. Weutilize this extensive categorization of previous contributions to sketch aresearch agenda for the community. We hope this work serves as the steppingstone toward a more comprehensive set of resources for ML researchers,practitioners, and students interested in exploring, designing, and testingpipeline-oriented approaches to algorithmic fairness.</description><author>Emily Black, Rakshit Naidu, Rayid Ghani, Kit T. Rodolfa, Daniel E. Ho, Hoda Heidari</author><pubDate>Fri, 29 Sep 2023 16:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17337v1</guid></item><item><title>See Beyond Seeing: Robust 3D Object Detection from Point Clouds via Cross-Modal Hallucination</title><link>http://arxiv.org/abs/2309.17336v1</link><description>This paper presents a novel framework for robust 3D object detection frompoint clouds via cross-modal hallucination. Our proposed approach is agnosticto either hallucination direction between LiDAR and 4D radar. We introducemultiple alignments on both spatial and feature levels to achieve simultaneousbackbone refinement and hallucination generation. Specifically, spatialalignment is proposed to deal with the geometry discrepancy for better instancematching between LiDAR and radar. The feature alignment step further bridgesthe intrinsic attribute gap between the sensing modalities and stabilizes thetraining. The trained object detection models can deal with difficult detectioncases better, even though only single-modal data is used as the input duringthe inference stage. Extensive experiments on the View-of-Delft (VoD) datasetshow that our proposed method outperforms the state-of-the-art (SOTA) methodsfor both radar and LiDAR object detection while maintaining competitiveefficiency in runtime.</description><author>Jianning Deng, Gabriel Chan, Hantao Zhong, Chris Xiaoxuan Lu</author><pubDate>Fri, 29 Sep 2023 16:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17336v1</guid></item><item><title>Asynchronous Graph Generators</title><link>http://arxiv.org/abs/2309.17335v1</link><description>We introduce the asynchronous graph generator (AGG), a novel graph neuralnetwork architecture for multi-channel time series which models observations asnodes on a dynamic graph and can thus perform data imputation by transductivenode generation. Completely free from recurrent components or assumptions abouttemporal regularity, AGG represents measurements, timestamps and metadatadirectly in the nodes via learnable embeddings, to then leverage attention tolearn expressive relationships across the variables of interest. This way, theproposed architecture implicitly learns a causal graph representation of sensormeasurements which can be conditioned on unseen timestamps and metadata topredict new measurements by an expansion of the learnt graph. The proposed AGGis compared both conceptually and empirically to previous work, and the impactof data augmentation on the performance of AGG is also briefly discussed. Ourexperiments reveal that AGG achieved state-of-the-art results in time seriesdata imputation, classification and prediction for the benchmark datasetsBeijing Air Quality, PhysioNet Challenge 2012 and UCI localisation.</description><author>Christopher P. Ley, Felipe Tobar</author><pubDate>Fri, 29 Sep 2023 16:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17335v1</guid></item><item><title>Multi-Depth Branches Network for Efficient Image Super-Resolution</title><link>http://arxiv.org/abs/2309.17334v1</link><description>Significant progress has been made in the field of super-resolution (SR), yetmany convolutional neural networks (CNNs) based SR models primarily focus onrestoring high-frequency details, often overlooking crucial low-frequencycontour information. Transformer-based SR methods, while incorporating globalstructural details, frequently come with an abundance of parameters, leading tohigh computational overhead. In this paper, we address these challenges byintroducing a Multi-Depth Branches Network (MDBN). This framework extends theResNet architecture by integrating an additional branch that captures vitalstructural characteristics of images. Our proposed multi-depth branches module(MDBM) involves the stacking of convolutional kernels of identical size atvarying depths within distinct branches. By conducting a comprehensive analysisof the feature maps, we observe that branches with differing depths can extractcontour and detail information respectively. By integrating these branches, theoverall architecture can preserve essential low-frequency semantic structuralinformation during the restoration of high-frequency visual elements, which ismore closely with human visual cognition. Compared to GoogLeNet-like models,our basic multi-depth branches structure has fewer parameters, highercomputational efficiency, and improved performance. Our model outperformsstate-of-the-art (SOTA) lightweight SR methods with less inference time. Ourcode is available at https://github.com/thy960112/MDBN</description><author>Huiyuan Tian, Li Zhang, Shijian Li, Min Yao, Gang Pan</author><pubDate>Fri, 29 Sep 2023 16:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17334v1</guid></item><item><title>Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles</title><link>http://arxiv.org/abs/2309.17332v1</link><description>This paper presents the results of the shared task on Lay Summarisation ofBiomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL2023. The goal of this shared task is to develop abstractive summarisationmodels capable of generating "lay summaries" (i.e., summaries that arecomprehensible to non-technical audiences) in both a controllable andnon-controllable setting. There are two subtasks: 1) Lay Summarisation, wherethe goal is for participants to build models for lay summary generation only,given the full article text and the corresponding abstract as input; and 2)Readability-controlled Summarisation, where the goal is for participants totrain models to generate both the technical abstract and the lay summary, givenan article's main text as input. In addition to overall results, we report onthe setup and insights from the BioLaySumm shared task, which attracted a totalof 20 participating teams across both subtasks.</description><author>Tomsa Goldsack, Zheheng Luo, Qianqian Xie, Carolina Scarton, Matthew Shardlow, Sophia Ananiadou, Chenghua Lin</author><pubDate>Fri, 29 Sep 2023 16:43:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17332v1</guid></item><item><title>The Dynamical Principles of Storytelling</title><link>http://arxiv.org/abs/2309.07797v2</link><description>When considering the opening part of 1800 short stories, we find that thefirst dozen paragraphs of the average narrative follow an action principle asdefined in arXiv:2309.06600. When the order of the paragraphs is shuffled, theaverage no longer exhibits this property. The findings show that there is apreferential direction we take in semantic space when starting a story,possibly related to a common Western storytelling tradition as implied byAristotle in Poetics.</description><author>Isidoros Doxas, James Meiss, Steven Bottone, Tom Strelich, Andrew Plummer, Adrienne Breland, Simon Dennis, Kathy Garvin-Doxas, Michael Klymkowsky</author><pubDate>Fri, 29 Sep 2023 16:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07797v2</guid></item><item><title>Narrative as a Dynamical System</title><link>http://arxiv.org/abs/2309.06600v2</link><description>There is increasing evidence that human activity in general, and narrative inparticular, can be treated as a dynamical system in the physics sense; a systemwhose evolution is described by an action integral, such that the average ofall possible paths from point A to point B is given by the extremum of theaction. We create by construction three such paths by averaging about 500different narratives, and we show that the average path is consistent with anaction principle.</description><author>Isidoros Doxas, James Meiss, Steven Bottone, Tom Strelich, Andrew Plummer, Adrienne Breland, Simon Dennis, Kathy Garvin-Doxas, Michael Klymkowsky</author><pubDate>Fri, 29 Sep 2023 16:41:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06600v2</guid></item><item><title>Efficient Anatomical labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks</title><link>http://arxiv.org/abs/2309.17329v1</link><description>Pulmonary diseases rank prominently among the principal causes of deathworldwide. Curing them will require, among other things, a better understandingof the many complex 3D tree-shaped structures within the pulmonary system, suchas airways, arteries, and veins. In theory, they can be modeled usinghigh-resolution image stacks. Unfortunately, standard CNN approaches operatingon dense voxel grids are prohibitively expensive. To remedy this, we introducea point-based approach that preserves graph connectivity of tree skeleton andincorporates an implicit surface representation. It delivers SOTA accuracy at alow computational cost and the resulting models have usable surfaces. Due tothe scarcity of publicly accessible data, we have also curated an extensivedataset to evaluate our approach and will make it public.</description><author>Kangxian Xie, Jiancheng Yang, Donglai Wei, Ziqiao Weng, Pascal Fua</author><pubDate>Fri, 29 Sep 2023 16:40:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17329v1</guid></item><item><title>Telling Stories for Common Sense Zero-Shot Action Recognition</title><link>http://arxiv.org/abs/2309.17327v1</link><description>Video understanding has long suffered from reliance on large labeleddatasets, motivating research into zero-shot learning. Recent progress inlanguage modeling presents opportunities to advance zero-shot video analysis,but constructing an effective semantic space relating action classes remainschallenging. We address this by introducing a novel dataset, Stories, whichcontains rich textual descriptions for diverse action classes extracted fromWikiHow articles. For each class, we extract multi-sentence narrativesdetailing the necessary steps, scenes, objects, and verbs that characterize theaction. This contextual data enables modeling of nuanced relationships betweenactions, paving the way for zero-shot transfer. We also propose an approachthat harnesses Stories to improve feature generation for training zero-shotclassification. Without any target dataset fine-tuning, our method achieves newstate-of-the-art on multiple benchmarks, improving top-1 accuracy by up to6.1%. We believe Stories provides a valuable resource that can catalyzeprogress in zero-shot action recognition. The textual narratives forgeconnections between seen and unseen classes, overcoming the bottleneck oflabeled data that has long impeded advancements in this exciting domain. Thedata can be found here: https://github.com/kini5gowda/Stories .</description><author>Shreyank N Gowda, Laura Sevilla-Lara</author><pubDate>Fri, 29 Sep 2023 16:34:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17327v1</guid></item><item><title>Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT Sentiment Analysis</title><link>http://arxiv.org/abs/2309.17322v1</link><description>Large language models (LLMs), including ChatGPT, can extract profitabletrading signals from the sentiment in news text. However, backtesting suchstrategies poses a challenge because LLMs are trained on many years of data,and backtesting produces biased results if the training and backtesting periodsoverlap. This bias can take two forms: a look-ahead bias, in which the LLM mayhave specific knowledge of the stock returns that followed a news article, anda distraction effect, in which general knowledge of the companies namedinterferes with the measurement of a text's sentiment. We investigate thesesources of bias through trading strategies driven by the sentiment of financialnews headlines. We compare trading performance based on the original headlineswith de-biased strategies in which we remove the relevant company's identifiersfrom the text. In-sample (within the LLM training window), we find,surprisingly, that the anonymized headlines outperform, indicating that thedistraction effect has a greater impact than look-ahead bias. This tendency isparticularly strong for larger companies--companies about which we expect anLLM to have greater general knowledge. Out-of-sample, look-ahead bias is not aconcern but distraction remains possible. Our proposed anonymization procedureis therefore potentially useful in out-of-sample implementation, as well as forde-biased backtesting.</description><author>Paul Glasserman, Caden Lin</author><pubDate>Fri, 29 Sep 2023 16:30:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17322v1</guid></item><item><title>Development of a Deep Learning Method to Identify Acute Ischemic Stroke Lesions on Brain CT</title><link>http://arxiv.org/abs/2309.17320v1</link><description>Computed Tomography (CT) is commonly used to image acute ischemic stroke(AIS) patients, but its interpretation by radiologists is time-consuming andsubject to inter-observer variability. Deep learning (DL) techniques canprovide automated CT brain scan assessment, but usually require annotatedimages. Aiming to develop a DL method for AIS using labelled but not annotatedCT brain scans from patients with AIS, we designed a convolutional neuralnetwork-based DL algorithm using routinely-collected CT brain scans from theThird International Stroke Trial (IST-3), which were not acquired using strictresearch protocols. The DL model aimed to detect AIS lesions and classify theside of the brain affected. We explored the impact of AIS lesion features,background brain appearances, and timing on DL performance. From 5772 unique CTscans of 2347 AIS patients (median age 82), 54% had visible AIS lesionsaccording to expert labelling. Our best-performing DL method achieved 72%accuracy for lesion presence and side. Lesions that were larger (80% accuracy)or multiple (87% accuracy for two lesions, 100% for three or more), were betterdetected. Follow-up scans had 76% accuracy, while baseline scans 67% accuracy.Chronic brain conditions reduced accuracy, particularly non-stroke lesions andold stroke lesions (32% and 31% error rates respectively). DL methods can bedesigned for AIS lesion detection on CT using the vast quantities ofroutinely-collected CT brain scan data. Ultimately, this should lead to morerobust and widely-applicable methods.</description><author>Alessandro Fontanella, Wenwen Li, Grant Mair, Antreas Antoniou, Eleanor Platt, Paul Armitage, Emanuele Trucco, Joanna Wardlaw, Amos Storkey</author><pubDate>Fri, 29 Sep 2023 16:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17320v1</guid></item><item><title>Building Privacy-Preserving and Secure Geospatial Artificial Intelligence Foundation Models</title><link>http://arxiv.org/abs/2309.17319v1</link><description>In recent years we have seen substantial advances in foundation models forartificial intelligence, including language, vision, and multimodal models.Recent studies have highlighted the potential of using foundation models ingeospatial artificial intelligence, known as GeoAI Foundation Models orGeo-Foundation Models, for geographic question answering, remote sensing imageunderstanding, map generation, and location-based services, among others.However, the development and application of GeoAI foundation models can poseserious privacy and security risks, which have not been fully discussed oraddressed to date. This paper introduces the potential privacy and securityrisks throughout the lifecycle of GeoAI foundation models and proposes acomprehensive blueprint for preventative and control strategies. Through thisvision paper, we hope to draw the attention of researchers and policymakers ingeospatial domains to these privacy and security risks inherent in GeoAIfoundation models and advocate for the development of privacy-preserving andsecure GeoAI foundation models.</description><author>Jinmeng Rao, Song Gao, Gengchen Mai, Krzysztof Janowicz</author><pubDate>Fri, 29 Sep 2023 16:25:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17319v1</guid></item><item><title>The Role of Communication and Reference Songs in the Mixing Process: Insights from Professional Mix Engineers</title><link>http://arxiv.org/abs/2309.03404v3</link><description>Effective music mixing requires technical and creative finesse, but clearcommunication with the client is crucial. The mixing engineer must grasp theclient's expectations, and preferences, and collaborate to achieve the desiredsound. The tacit agreement for the desired sound of the mix is oftenestablished using guides like reference songs and demo mixes exchanged betweenthe artist and the engineer and sometimes verbalised using semantic terms. Thispaper presents the findings of a two-phased exploratory study aimed atunderstanding how professional mixing engineers interact with clients and usetheir feedback to guide the mixing process. For phase one, semi-structuredinterviews were conducted with five mixing engineers with the aim of gatheringinsights about their communication strategies, creative processes, anddecision-making criteria. Based on the inferences from these interviews, anonline questionnaire was designed and administered to a larger group of 22mixing engineers during the second phase. The results of this study shed lighton the importance of collaboration, empathy, and intention in the mixingprocess, and can inform the development of smart multi-track mixing systemsthat better support these practices. By highlighting the significance of thesefindings, this paper contributes to the growing body of research on thecollaborative nature of music production and provides actionablerecommendations for the design and implementation of innovative mixing tools.</description><author>Soumya Sai Vanka, Maryam Safi, Jean-Baptiste Rolland, Gyrgy Fazekas</author><pubDate>Fri, 29 Sep 2023 16:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03404v3</guid></item><item><title>Robust Stochastic Optimization via Gradient Quantile Clipping</title><link>http://arxiv.org/abs/2309.17316v1</link><description>We introduce a clipping strategy for Stochastic Gradient Descent (SGD) whichuses quantiles of the gradient norm as clipping thresholds. We prove that thisnew strategy provides a robust and efficient optimization algorithm for smoothobjectives (convex or non-convex), that tolerates heavy-tailed samples(including infinite variance) and a fraction of outliers in the data streamakin to Huber contamination. Our mathematical analysis leverages the connectionbetween constant step size SGD and Markov chains and handles the biasintroduced by clipping in an original way. For strongly convex objectives, weprove that the iteration converges to a concentrated distribution and derivehigh probability bounds on the final estimation error. In the non-convex case,we prove that the limit distribution is localized on a neighborhood with lowgradient. We propose an implementation of this algorithm using rollingquantiles which leads to a highly efficient optimization procedure with strongrobustness properties, as confirmed by our numerical experiments.</description><author>Ibrahim Merad, Stphane Gaffas</author><pubDate>Fri, 29 Sep 2023 16:24:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17316v1</guid></item><item><title>SLiMe: Segment Like Me</title><link>http://arxiv.org/abs/2309.03179v2</link><description>Significant strides have been made using large vision-language models, likeStable Diffusion (SD), for a variety of downstream tasks, including imageediting, image correspondence, and 3D shape generation. Inspired by theseadvancements, we explore leveraging these extensive vision-language models forsegmenting images at any desired granularity using as few as one annotatedsample by proposing SLiMe. SLiMe frames this problem as an optimization task.Specifically, given a single training image and its segmentation mask, we firstextract attention maps, including our novel "weighted accumulatedself-attention map" from the SD prior. Then, using the extracted attentionmaps, the text embeddings of Stable Diffusion are optimized such that, each ofthem, learn about a single segmented region from the training image. Theselearned embeddings then highlight the segmented region in the attention maps,which in turn can then be used to derive the segmentation map. This enablesSLiMe to segment any real-world image during inference with the granularity ofthe segmented region in the training image, using just one example. Moreover,leveraging additional training data when available, i.e. few-shot, improves theperformance of SLiMe. We carried out a knowledge-rich set of experimentsexamining various design factors and showed that SLiMe outperforms otherexisting one-shot and few-shot segmentation methods.</description><author>Aliasghar Khani, Saeid Asgari Taghanaki, Aditya Sanghi, Ali Mahdavi Amiri, Ghassan Hamarneh</author><pubDate>Fri, 29 Sep 2023 16:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03179v2</guid></item><item><title>Few-Shot Domain Adaptation for Charge Prediction on Unprofessional Descriptions</title><link>http://arxiv.org/abs/2309.17313v1</link><description>Recent works considering professional legal-linguistic style (PLLS) textshave shown promising results on the charge prediction task. However,unprofessional users also show an increasing demand on such a predictionservice. There is a clear domain discrepancy between PLLS texts and non-PLLStexts expressed by those laypersons, which degrades the current SOTA models'performance on non-PLLS texts. A key challenge is the scarcity of non-PLLS datafor most charge classes. This paper proposes a novel few-shot domain adaptation(FSDA) method named Disentangled Legal Content for Charge Prediction (DLCCP).Compared with existing FSDA works, which solely perform instance-levelalignment without considering the negative impact of text style informationexisting in latent features, DLCCP (1) disentangles the content and stylerepresentations for better domain-invariant legal content learning withcarefully designed optimization goals for content and style spaces and, (2)employs the constitutive elements knowledge of charges to extract and alignelement-level and instance-level content representations simultaneously. Wecontribute the first publicly available non-PLLS dataset named NCCP fordeveloping layperson-friendly charge prediction models. Experiments on NCCPshow the superiority of our methods over competitive baselines.</description><author>Jie Zhao, Ziyu Guan, Wei Zhao, Yue Jiang, Xiaofei He</author><pubDate>Fri, 29 Sep 2023 16:14:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17313v1</guid></item><item><title>Contrastive Decoding Improves Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2309.09117v2</link><description>We demonstrate that Contrastive Decoding -- a simple, computationally light,and training-free text generation method proposed by Li et al 2022 -- achieveslarge out-of-the-box improvements over greedy decoding on a variety ofreasoning tasks. Originally shown to improve the perceived quality of long-formtext generation, Contrastive Decoding searches for strings that maximize aweighted difference in likelihood between strong and weak models. We show thatContrastive Decoding leads LLaMA-65B to outperform LLaMA 2, GPT-3.5 and PaLM2-L on the HellaSwag commonsense reasoning benchmark, and to outperform LLaMA2, GPT-3.5 and PaLM-540B on the GSM8K math word reasoning benchmark, inaddition to improvements on a collection of other tasks. Analysis suggests thatContrastive Decoding improves over existing methods by preventing some abstractreasoning errors, as well as by avoiding simpler modes such as copying sectionsof the input during chain-of-thought. Overall, Contrastive Decoding outperformsnucleus sampling for long-form generation and greedy decoding for reasoningtasks, making it a powerful general purpose method for generating text fromlanguage models.</description><author>Sean O'Brien, Mike Lewis</author><pubDate>Fri, 29 Sep 2023 16:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09117v2</guid></item><item><title>ENTL: Embodied Navigation Trajectory Learner</title><link>http://arxiv.org/abs/2304.02639v3</link><description>We propose Embodied Navigation Trajectory Learner (ENTL), a method forextracting long sequence representations for embodied navigation. Our approachunifies world modeling, localization and imitation learning into a singlesequence prediction task. We train our model using vector-quantized predictionsof future states conditioned on current states and actions. ENTL's genericarchitecture enables sharing of the spatio-temporal sequence encoder formultiple challenging embodied tasks. We achieve competitive performance onnavigation tasks using significantly less data than strong baselines whileperforming auxiliary tasks such as localization and future frame prediction (aproxy for world modeling). A key property of our approach is that the model ispre-trained without any explicit reward signal, which makes the resulting modelgeneralizable to multiple tasks and environments.</description><author>Klemen Kotar, Aaron Walsman, Roozbeh Mottaghi</author><pubDate>Fri, 29 Sep 2023 16:11:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02639v3</guid></item><item><title>Leave-one-out Distinguishability in Machine Learning</title><link>http://arxiv.org/abs/2309.17310v1</link><description>We introduce a new analytical framework to quantify the changes in a machinelearning algorithm's output distribution following the inclusion of a few datapoints in its training set, a notion we define as leave-one-outdistinguishability (LOOD). This problem is key to measuring data**memorization** and **information leakage** in machine learning, and the**influence** of training data points on model predictions. We illustrate howour method broadens and refines existing empirical measures of memorization andprivacy risks associated with training data. We use Gaussian processes to modelthe randomness of machine learning algorithms, and validate LOOD with extensiveempirical analysis of information leakage using membership inference attacks.Our theoretical framework enables us to investigate the causes of informationleakage and where the leakage is high. For example, we analyze the influence ofactivation functions, on data memorization. Additionally, our method allows usto optimize queries that disclose the most significant information about thetraining data in the leave-one-out setting. We illustrate how optimal queriescan be used for accurate **reconstruction** of training data.</description><author>Jiayuan Ye, Anastasia Borovykh, Soufiane Hayou, Reza Shokri</author><pubDate>Fri, 29 Sep 2023 16:08:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17310v1</guid></item><item><title>Forward-Backward Reasoning in Large Language Models for Mathematical Verification</title><link>http://arxiv.org/abs/2308.07758v4</link><description>Chain-of-Thought (CoT) prompting in large language models (LLMs) has shownpromising performance on mathematical reasoning tasks. Recently,Self-Consistency samples a diverse set of reasoning chains with differentanswers and chooses the answer by majority voting. Though effective, itsperformance cannot be further improved by sampling more reasoning chains. Toaddress this problem, we propose to integrate backward reasoning into answerverification. We first mask a number in the question by ${\bf x}$. The LLM isthen asked to predict the masked number with a candidate answer $A$ embedded inthe template: ``If we know the answer to the above question is $\{A\}$, what isthe value of unknown variable ${\bf x}$?'' The LLM is expected to predict themasked number successfully if the provided candidate answer is correct. Tofurther improve performance, we propose FOBAR (FOrward-BAckward Reasoning) tocombine forward and backward reasoning for verifying candidate answers.Experiments are performed on six standard mathematical data sets and three LLMs(text-davinci-003, GPT-3.5-Turbo, GPT-4). Results show that FOBAR achievesstate-of-the-art performance. In particular, FOBAR outperforms Self-Consistencywhich uses forward reasoning alone, demonstrating that combining forward andforward reasoning is better. It also outperforms existing verification methods,verifying the effectiveness of using the simple template in backward reasoningand the proposed combination.</description><author>Weisen Jiang, Han Shi, Longhui Yu, Zhengying Liu, Yu Zhang, Zhenguo Li, James T. Kwok</author><pubDate>Fri, 29 Sep 2023 16:06:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07758v4</guid></item><item><title>Understanding Open-Set Recognition by Jacobian Norm and Inter-Class Separation</title><link>http://arxiv.org/abs/2209.11436v2</link><description>The findings on open-set recognition (OSR) show that models trained onclassification datasets are capable of detecting unknown classes notencountered during the training process. Specifically, after training, thelearned representations of known classes dissociate from the representations ofthe unknown class, facilitating OSR. In this paper, we investigate thisemergent phenomenon by examining the relationship between the Jacobian norm ofrepresentations and the inter/intra-class learning dynamics. We provide atheoretical analysis, demonstrating that intra-class learning reduces theJacobian norm for known class samples, while inter-class learning increases theJacobian norm for unknown samples, even in the absence of direct exposure toany unknown sample. Overall, the discrepancy in the Jacobian norm between theknown and unknown classes enables OSR. Based on this insight, which highlightsthe pivotal role of inter-class learning, we devise a marginal one-vs-rest(m-OvR) loss function that promotes strong inter-class separation. To furtherimprove OSR performance, we integrate the m-OvR loss with additional strategiesthat maximize the Jacobian norm disparity. We present comprehensiveexperimental results that support our theoretical observations and demonstratethe efficacy of our proposed OSR approach.</description><author>Jaewoo Park, Hojin Park, Eunju Jeong, Andrew Beng Jin Teoh</author><pubDate>Fri, 29 Sep 2023 16:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.11436v2</guid></item><item><title>Matrix Information Theory for Self-Supervised Learning</title><link>http://arxiv.org/abs/2305.17326v3</link><description>Contrastive learning often relies on comparing positive anchor samples withmultiple negative samples to perform Self-Supervised Learning (SSL). However,non-contrastive approaches like BYOL, SimSiam, and Barlow Twins achieve SSLwithout explicit negative samples. In this paper, we introduce a unified matrixinformation-theoretic framework that explains many contrastive andnon-contrastive learning methods. We then propose a novel method Matrix-SSLbased on matrix information theory. Experimental results reveal that Matrix-SSLsignificantly outperforms state-of-the-art methods on the ImageNet datasetunder linear evaluation settings and on MS-COCO for transfer learning tasks.Specifically, when performing 100 epochs pre-training, our method outperformsSimCLR by 4.6%, and when performing transfer learning tasks on MS-COCO, ourmethod outperforms previous SOTA methods such as MoCo v2 and BYOL up to 3.3%with only 400 epochs compared to 800 epochs pre-training. Code available athttps://github.com/yifanzhang-pro/Matrix-SSL.</description><author>Yifan Zhang, Zhiquan Tan, Jingqin Yang, Weiran Huang, Yang Yuan</author><pubDate>Fri, 29 Sep 2023 16:04:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17326v3</guid></item><item><title>Pose Modulated Avatars from Video</title><link>http://arxiv.org/abs/2308.11951v3</link><description>It is now possible to reconstruct dynamic human motion and shape from asparse set of cameras using Neural Radiance Fields (NeRF) driven by anunderlying skeleton. However, a challenge remains to model the deformation ofcloth and skin in relation to skeleton pose. Unlike existing avatar models thatare learned implicitly or rely on a proxy surface, our approach is motivated bythe observation that different poses necessitate unique frequency assignments.Neglecting this distinction yields noisy artifacts in smooth areas or blursfine-grained texture and shape details in sharp regions. We develop atwo-branch neural network that is adaptive and explicit in the frequencydomain. The first branch is a graph neural network that models correlationsamong body parts locally, taking skeleton pose as input. The second branchcombines these correlation features to a set of global frequencies and thenmodulates the feature encoding. Our experiments demonstrate that our networkoutperforms state-of-the-art methods in terms of preserving details andgeneralization capabilities.</description><author>Chunjin Song, Bastian Wandt, Helge Rhodin</author><pubDate>Fri, 29 Sep 2023 16:03:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11951v3</guid></item><item><title>Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation</title><link>http://arxiv.org/abs/2309.17296v1</link><description>Deep generative diffusion models are a promising avenue for de novo 3Dmolecular design in material science and drug discovery. However, their utilityis still constrained by suboptimal performance with large molecular structuresand limited training data. Addressing this gap, we explore the design space ofE(3) equivariant diffusion models, focusing on previously blank spots. Ourextensive comparative analysis evaluates the interplay between continuous anddiscrete state spaces. Out of this investigation, we introduce the EQGAT-diffmodel, which consistently surpasses the performance of established models onthe QM9 and GEOM-Drugs datasets by a large margin. Distinctively, EQGAT-difftakes continuous atomic positions while chemical elements and bond types arecategorical and employ a time-dependent loss weighting that significantlyincreases training convergence and the quality of generated samples. To furtherstrengthen the applicability of diffusion models to limited training data, weexamine the transferability of EQGAT-diff trained on the large PubChem3Ddataset with implicit hydrogens to target distributions with explicithydrogens. Fine-tuning EQGAT-diff for a couple of iterations further pushesstate-of-the-art performance across datasets. We envision that our findingswill find applications in structure-based drug design, where the accuracy ofgenerative models for small datasets of complex molecules is critical.</description><author>Tuan Le, Julian Cremer, Frank No, Djork-Arn Clevert, Kristof Schtt</author><pubDate>Fri, 29 Sep 2023 15:53:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17296v1</guid></item><item><title>Hierarchical Neyman-Pearson Classification for Prioritizing Severe Disease Categories in COVID-19 Patient Data</title><link>http://arxiv.org/abs/2210.02197v2</link><description>COVID-19 has a spectrum of disease severity, ranging from asymptomatic torequiring hospitalization. Understanding the mechanisms driving diseaseseverity is crucial for developing effective treatments and reducing mortalityrates. One way to gain such understanding is using a multi-class classificationframework, in which patients' biological features are used to predict patients'severity classes. In this severity classification problem, it is beneficial toprioritize the identification of more severe classes and control the"under-classification" errors, in which patients are misclassified into lesssevere categories. The Neyman-Pearson (NP) classification paradigm has beendeveloped to prioritize the designated type of error. However, current NPprocedures are either for binary classification or do not provide highprobability controls on the prioritized errors in multi-class classification.Here, we propose a hierarchical NP (H-NP) framework and an umbrella algorithmthat generally adapts to popular classification methods and controls theunder-classification errors with high probability. On an integrated collectionof single-cell RNA-seq (scRNA-seq) datasets for 864 patients, we explore waysof featurization and demonstrate the efficacy of the H-NP algorithm incontrolling the under-classification errors regardless of featurization. BeyondCOVID-19 severity classification, the H-NP algorithm generally applies tomulti-class classification problems, where classes have a priority order.</description><author>Lijia Wang, Y. X. Rachel Wang, Jingyi Jessica Li, Xin Tong</author><pubDate>Fri, 29 Sep 2023 15:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.02197v2</guid></item><item><title>In search of dispersed memories: Generative diffusion models are associative memory networks</title><link>http://arxiv.org/abs/2309.17290v1</link><description>Hopfield networks are widely used in neuroscience as simplified theoreticalmodels of biological associative memory. The original Hopfield networks storememories by encoding patterns of binary associations, which result in asynaptic learning mechanism known as Hebbian learning rule. Modern Hopfieldnetworks can achieve exponential capacity scaling by using highly non-linearenergy functions. However, the energy function of these newer models cannot bestraightforwardly compressed into binary synaptic couplings and it does notdirectly provide new synaptic learning rules. In this work we show thatgenerative diffusion models can be interpreted as energy-based models and that,when trained on discrete patterns, their energy function is equivalent to thatof modern Hopfield networks. This equivalence allows us to interpret thesupervised training of diffusion models as a synaptic learning process thatencodes the associative dynamics of a modern Hopfield network in the weightstructure of a deep neural network. Accordingly, in our experiments we showthat the storage capacity of a continuous modern Hopfield network is identicalto the capacity of a diffusion model. Our results establish a strong linkbetween generative modeling and the theoretical neuroscience of memory, whichprovide a powerful computational foundation for the reconstructive theory ofmemory, where creative generation and memory recall can be seen as parts of aunified continuum.</description><author>Luca Ambrogioni</author><pubDate>Fri, 29 Sep 2023 15:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17290v1</guid></item><item><title>AutoAgents: A Framework for Automatic Agent Generation</title><link>http://arxiv.org/abs/2309.17288v1</link><description>Large language models (LLMs) have enabled remarkable advances in automatedtask-solving with multi-agent systems. However, most existing LLM-basedmulti-agent approaches rely on predefined agents to handle simple tasks,limiting the adaptability of multi-agent collaboration to different scenarios.Therefore, we introduce AutoAgents, an innovative framework that adaptivelygenerates and coordinates multiple specialized agents to build an AI teamaccording to different tasks. Specifically, AutoAgents couples the relationshipbetween tasks and roles by dynamically generating multiple required agentsbased on task content and planning solutions for the current task based on thegenerated expert agents. Multiple specialized agents collaborate with eachother to efficiently accomplish tasks. Concurrently, an observer role isincorporated into the framework to reflect on the designated plans and agents'responses and improve upon them. Our experiments on various benchmarksdemonstrate that AutoAgents generates more coherent and accurate solutions thanthe existing multi-agent methods. This underscores the significance ofassigning different roles to different tasks and of team cooperation, offeringnew perspectives for tackling complex tasks. The repository of this project isavailable at https://github.com/LinkSoul-AI/AutoAgents.</description><author>Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Brje F. Karlsson, Jie Fu, Yemin Shi</author><pubDate>Fri, 29 Sep 2023 15:46:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17288v1</guid></item><item><title>Text-to-3D using Gaussian Splatting</title><link>http://arxiv.org/abs/2309.16585v2</link><description>In this paper, we present Gaussian Splatting based text-to-3D generation(GSGEN), a novel approach for generating high-quality 3D objects. Previousmethods suffer from inaccurate geometry and limited fidelity due to the absenceof 3D prior and proper representation. We leverage 3D Gaussian Splatting, arecent state-of-the-art representation, to address existing shortcomings byexploiting the explicit nature that enables the incorporation of 3D prior.Specifically, our method adopts a progressive optimization strategy, whichincludes a geometry optimization stage and an appearance refinement stage. Ingeometry optimization, a coarse representation is established under a 3Dgeometry prior along with the ordinary 2D SDS loss, ensuring a sensible and3D-consistent rough shape. Subsequently, the obtained Gaussians undergo aniterative refinement to enrich details. In this stage, we increase the numberof Gaussians by compactness-based densification to enhance continuity andimprove fidelity. With these designs, our approach can generate 3D content withdelicate details and more accurate geometry. Extensive evaluations demonstratethe effectiveness of our method, especially for capturing high-frequencycomponents. Video results are provided at https://gsgen3d.github.io. Our codeis available at https://github.com/gsgen3d/gsgen</description><author>Zilong Chen, Feng Wang, Huaping Liu</author><pubDate>Fri, 29 Sep 2023 15:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16585v2</guid></item><item><title>Efficient Large Scale Medical Image Dataset Preparation for Machine Learning Applications</title><link>http://arxiv.org/abs/2309.17285v1</link><description>In the rapidly evolving field of medical imaging, machine learning algorithmshave become indispensable for enhancing diagnostic accuracy. However, theeffectiveness of these algorithms is contingent upon the availability andorganization of high-quality medical imaging datasets. Traditional DigitalImaging and Communications in Medicine (DICOM) data management systems areinadequate for handling the scale and complexity of data required to befacilitated in machine learning algorithms. This paper introduces an innovativedata curation tool, developed as part of the Kaapana open-source toolkit, aimedat streamlining the organization, management, and processing of large-scalemedical imaging datasets. The tool is specifically tailored to meet the needsof radiologists and machine learning researchers. It incorporates advancedsearch, auto-annotation and efficient tagging functionalities for improved datacuration. Additionally, the tool facilitates quality control and review,enabling researchers to validate image and segmentation quality in largedatasets. It also plays a critical role in uncovering potential biases indatasets by aggregating and visualizing metadata, which is essential fordeveloping robust machine learning models. Furthermore, Kaapana is integratedwithin the Radiological Cooperative Network (RACOON), a pioneering initiativeaimed at creating a comprehensive national infrastructure for the aggregation,transmission, and consolidation of radiological data across all universityclinics throughout Germany. A supplementary video showcasing the tool'sfunctionalities can be accessed at https://bit.ly/MICCAI-DEMI2023.</description><author>Stefan Denner, Jonas Scherer, Klaus Kades, Dimitrios Bounias, Philipp Schader, Lisa Kausch, Markus Bujotzek, Andreas Michael Bucher, Tobias Penzkofer, Klaus Maier-Hein</author><pubDate>Fri, 29 Sep 2023 15:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17285v1</guid></item><item><title>The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation</title><link>http://arxiv.org/abs/2309.17283v1</link><description>Assessing causal effects in the presence of unobserved confounding is achallenging problem. Existing studies leveraged proxy variables or multipletreatments to adjust for the confounding bias. In particular, the latterapproach attributes the impact on a single outcome to multiple treatments,allowing estimating latent variables for confounding control. Nevertheless,these methods primarily focus on a single outcome, whereas in many real-worldscenarios, there is greater interest in studying the effects on multipleoutcomes. Besides, these outcomes are often coupled with multiple treatments.Examples include the intensive care unit (ICU), where health providers evaluatethe effectiveness of therapies on multiple health indicators. To accommodatethese scenarios, we consider a new setting dubbed as multiple treatments andmultiple outcomes. We then show that parallel studies of multiple outcomesinvolved in this setting can assist each other in causal identification, in thesense that we can exploit other treatments and outcomes as proxies for eachtreatment effect under study. We proceed with a causal discovery method thatcan effectively identify such proxies for causal estimation. The utility of ourmethod is demonstrated in synthetic data and sepsis disease.</description><author>Yong Wu, Mingzhou Liu, Jing Yan, Yanwei Fu, Shouyan Wang, Yizhou Wang, Xinwei Sun</author><pubDate>Fri, 29 Sep 2023 15:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17283v1</guid></item><item><title>Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation</title><link>http://arxiv.org/abs/2211.12345v3</link><description>Larger and deeper networks generalise well despite their increased capacityto overfit. Understanding why this happens is theoretically and practicallyimportant. One recent approach looks at the infinitely wide limits of suchnetworks and their corresponding kernels. However, these theoretical toolscannot fully explain finite networks as the empirical kernel changessignificantly during gradient-descent-based training in contrast to infinitenetworks. In this work, we derive an iterative linearised training method as anovel empirical tool to further investigate this distinction, allowing us tocontrol for sparse (i.e. infrequent) feature updates and quantify the frequencyof feature learning needed to achieve comparable performance. We justifyiterative linearisation as an interpolation between a finite analog of theinfinite width regime, which does not learn features, and standard gradientdescent training, which does. Informally, we also show that it is analogous toa damped version of the Gauss-Newton algorithm -- a second-order method. Weshow that in a variety of cases, iterative linearised training surprisinglyperforms on par with standard training, noting in particular how much lessfrequent feature learning is required to achieve comparable performance. Wealso show that feature learning is essential for good performance. Since suchfeature learning inevitably causes changes in the NTK kernel, we provide directnegative evidence for the NTK theory, which states the NTK kernel remainsconstant during training.</description><author>Adrian Goldwaser, Hong Ge</author><pubDate>Fri, 29 Sep 2023 15:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.12345v3</guid></item><item><title>Information Flow in Self-Supervised Learning</title><link>http://arxiv.org/abs/2309.17281v1</link><description>In this paper, we provide a comprehensive toolbox for understanding andenhancing self-supervised learning (SSL) methods through the lens of matrixinformation theory. Specifically, by leveraging the principles of matrix mutualinformation and joint entropy, we offer a unified analysis for both contrastiveand feature decorrelation based methods. Furthermore, we propose the matrixvariational masked auto-encoder (M-MAE) method, grounded in matrix informationtheory, as an enhancement to masked image modeling. The empirical evaluationsunderscore the effectiveness of M-MAE compared with the state-of-the-artmethods, including a 3.9% improvement in linear probing ViT-Base, and a 1%improvement in fine-tuning ViT-Large, both on ImageNet.</description><author>Zhiquan Tan, Jingqin Yang, Weiran Huang, Yang Yuan, Yifan Zhang</author><pubDate>Fri, 29 Sep 2023 15:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17281v1</guid></item><item><title>STRONG -- Structure Controllable Legal Opinion Summary Generation</title><link>http://arxiv.org/abs/2309.17280v1</link><description>We propose an approach for the structure controllable summarization of longlegal opinions that considers the argument structure of the document. Ourapproach involves using predicted argument role information to guide the modelin generating coherent summaries that follow a provided structure pattern. Wedemonstrate the effectiveness of our approach on a dataset of legal opinionsand show that it outperforms several strong baselines with respect to ROUGE,BERTScore, and structure similarity.</description><author>Yang Zhong, Diane Litman</author><pubDate>Fri, 29 Sep 2023 15:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17280v1</guid></item><item><title>Toward Robust Recommendation via Real-time Vicinal Defense</title><link>http://arxiv.org/abs/2309.17278v1</link><description>Recommender systems have been shown to be vulnerable to poisoning attacks,where malicious data is injected into the dataset to cause the recommendersystem to provide biased recommendations. To defend against such attacks,various robust learning methods have been proposed. However, most methods aremodel-specific or attack-specific, making them lack generality, while othermethods, such as adversarial training, are oriented towards evasion attacks andthus have a weak defense strength in poisoning attacks. In this paper, we propose a general method, Real-time Vicinal Defense (RVD),which leverages neighboring training data to fine-tune the model before makinga recommendation for each user. RVD works in the inference phase to ensure therobustness of the specific sample in real-time, so there is no need to changethe model structure and training process, making it more practical. Extensiveexperimental results demonstrate that RVD effectively mitigates targetedpoisoning attacks across various models without sacrificing accuracy. Moreover,the defensive effect can be further amplified when our method is combined withother strategies.</description><author>Yichang Xu, Chenwang Wu, Defu Lian</author><pubDate>Fri, 29 Sep 2023 15:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17278v1</guid></item><item><title>Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT4</title><link>http://arxiv.org/abs/2309.17277v1</link><description>Unlike perfect information games, where all elements are known to everyplayer, imperfect information games emulate the real-world complexities ofdecision-making under uncertain or incomplete information. GPT-4, the recentbreakthrough in large language models (LLMs) trained on massive passive data,is notable for its knowledge retrieval and reasoning abilities. This paperdelves into the applicability of GPT-4's learned knowledge for imperfectinformation games. To achieve this, we introduce \textbf{Suspicion-Agent}, aninnovative agent that leverages GPT-4's capabilities for performing inimperfect information games. With proper prompt engineering to achievedifferent functions, Suspicion-Agent based on GPT-4 demonstrates remarkableadaptability across a range of imperfect information card games. Importantly,GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning itcan understand others and intentionally impact others' behavior. Leveragingthis, we design a planning strategy that enables GPT-4 to competently playagainst different opponents, adapting its gameplay style as needed, whilerequiring only the game rules and descriptions of observations as input. In theexperiments, we qualitatively showcase the capabilities of Suspicion-Agentacross three different imperfect information games and then quantitativelyevaluate it in Leduc Hold'em. The results show that Suspicion-Agent canpotentially outperform traditional algorithms designed for imperfectinformation games, without any specialized training or examples. In order toencourage and foster deeper insights within the community, we make ourgame-related data publicly available.</description><author>Jiaxian Guo, Bo Yang, Paul Yoo, Yuchen Lin, Yusuke Iwasawa, Yutaka Matsuo</author><pubDate>Fri, 29 Sep 2023 15:30:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17277v1</guid></item></channel></rss>