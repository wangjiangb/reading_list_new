<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 01 Aug 2023 06:00:30 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields</title><link>http://arxiv.org/abs/2307.16897v1</link><description>Advances in neural fields are enabling high-fidelity capture of the shape andappearance of static and dynamic scenes. However, their capabilities lag behindthose offered by representations such as pixels or meshes due to algorithmicchallenges and the lack of large-scale real-world datasets. We address thedataset limitation with DiVA-360, a real-world 360 dynamic visual-audio datasetwith synchronized multimodal visual, audio, and textual information abouttable-scale scenes. It contains 46 dynamic scenes, 30 static scenes, and 95static objects spanning 11 categories captured using a new hardware systemusing 53 RGB cameras at 120 FPS and 6 microphones for a total of 8.6M imageframes and 1360 s of dynamic data. We provide detailed text descriptions forall scenes, foreground-background segmentation masks, category-specific 3D posealignment for static objects, as well as metrics for comparison. Our data,hardware and software, and code are available at https://diva360.github.io/.</description><author>Cheng-You Lu, Peisen Zhou, Angela Xing, Chandradeep Pokhariya, Arnab Dey, Ishaan Shah, Rugved Mavidipalli, Dylan Hu, Andrew Comport, Kefan Chen, Srinath Sridhar</author><pubDate>Mon, 31 Jul 2023 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16897v1</guid></item><item><title>Disruptive Autoencoders: Leveraging Low-level features for 3D Medical Image Pre-training</title><link>http://arxiv.org/abs/2307.16896v1</link><description>Harnessing the power of pre-training on large-scale datasets like ImageNetforms a fundamental building block for the progress of representationlearning-driven solutions in computer vision. Medical images are inherentlydifferent from natural images as they are acquired in the form of manymodalities (CT, MR, PET, Ultrasound etc.) and contain granulated informationlike tissue, lesion, organs etc. These characteristics of medical imagesrequire special attention towards learning features representative of localcontext. In this work, we focus on designing an effective pre-trainingframework for 3D radiology images. First, we propose a new masking strategycalled local masking where the masking is performed across channel embeddingsinstead of tokens to improve the learning of local feature representations. Wecombine this with classical low-level perturbations like adding noise anddownsampling to further enable low-level representation learning. To this end,we introduce Disruptive Autoencoders, a pre-training framework that attempts toreconstruct the original image from disruptions created by a combination oflocal masking and low-level perturbations. Additionally, we also devise across-modal contrastive loss (CMCL) to accommodate the pre-training of multiplemodalities in a single framework. We curate a large-scale dataset to enablepre-training of 3D medical radiology images (MRI and CT). The proposedpre-training framework is tested across multiple downstream tasks and achievesstate-of-the-art performance. Notably, our proposed method tops the public testleaderboard of BTCV multi-organ segmentation challenge.</description><author>Jeya Maria Jose Valanarasu, Yucheng Tang, Dong Yang, Ziyue Xu, Can Zhao, Wenqi Li, Vishal M. Patel, Bennett Landman, Daguang Xu, Yufan He, Vishwesh Nath</author><pubDate>Mon, 31 Jul 2023 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16896v1</guid></item><item><title>Conformal PID Control for Time Series Prediction</title><link>http://arxiv.org/abs/2307.16895v1</link><description>We study the problem of uncertainty quantification for time seriesprediction, with the goal of providing easy-to-use algorithms with formalguarantees. The algorithms we present build upon ideas from conformalprediction and control theory, are able to prospectively model conformal scoresin an online setting, and adapt to the presence of systematic errors due toseasonality, trends, and general distribution shifts. Our theory bothsimplifies and strengthens existing analyses in online conformal prediction.Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts inthe U.S. show an improvement in coverage over the ensemble forecaster used inofficial CDC communications. We also run experiments on predicting electricitydemand, market returns, and temperature using autoregressive, Theta, Prophet,and Transformer models. We provide an extendable codebase for testing ourmethods and for the integration of new algorithms, data sets, and forecastingrules.</description><author>Anastasios N. Angelopoulos, Emmanuel J. Candes, Ryan J. Tibshirani</author><pubDate>Mon, 31 Jul 2023 18:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16895v1</guid></item><item><title>Foundational Models for Fault Diagnosis of Electrical Motors</title><link>http://arxiv.org/abs/2307.16891v1</link><description>A majority of recent advancements related to the fault diagnosis ofelectrical motors are based on the assumption that training and testing dataare drawn from the same distribution. However, the data distribution can varyacross different operating conditions during real-world operating scenarios ofelectrical motors. Consequently, this assumption limits the practicalimplementation of existing studies for fault diagnosis, as they rely on fullylabelled training data spanning all operating conditions and assume aconsistent distribution. This is because obtaining a large number of labelledsamples for several machines across different fault cases and operatingscenarios may be unfeasible. In order to overcome the aforementionedlimitations, this work proposes a framework to develop a foundational model forfault diagnosis of electrical motors. It involves building a neuralnetwork-based backbone to learn high-level features using self-supervisedlearning, and then fine-tuning the backbone to achieve specific objectives. Theprimary advantage of such an approach is that the backbone can be fine-tuned toachieve a wide variety of target tasks using very less amount of training dataas compared to traditional supervised learning methodologies. The empiricalevaluation demonstrates the effectiveness of the proposed approach by obtainingmore than 90\% classification accuracy by fine-tuning the backbone not onlyacross different types of fault scenarios or operating conditions, but alsoacross different machines. This illustrates the promising potential of theproposed approach for cross-machine fault diagnosis tasks in real-worldapplications.</description><author>Sriram Anbalagan, Deepesh Agarwal, Balasubramaniam Natarajan, Babji Srinivasan</author><pubDate>Mon, 31 Jul 2023 18:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16891v1</guid></item><item><title>Discovering Adaptable Symbolic Algorithms from Scratch</title><link>http://arxiv.org/abs/2307.16890v1</link><description>Autonomous robots deployed in the real world will need control policies thatrapidly adapt to environmental changes. To this end, we proposeAutoRobotics-Zero (ARZ), a method based on AutoML-Zero that discovers zero-shotadaptable policies from scratch. In contrast to neural network adaptionpolicies, where only model parameters are optimized, ARZ can build controlalgorithms with the full expressive power of a linear register machine. Weevolve modular policies that tune their model parameters and alter theirinference algorithm on-the-fly to adapt to sudden environmental changes. Wedemonstrate our method on a realistic simulated quadruped robot, for which weevolve safe control policies that avoid falling when individual limbs suddenlybreak. This is a challenging task in which two popular neural network baselinesfail. Finally, we conduct a detailed analysis of our method on a novel andchallenging non-stationary control task dubbed Cataclysmic Cartpole. Resultsconfirm our findings that ARZ is significantly more robust to suddenenvironmental changes and can build simple, interpretable control policies.</description><author>Stephen Kelly, Daniel S. Park, Xingyou Song, Mitchell McIntire, Pranav Nashikkar, Ritam Guha, Wolfgang Banzhaf, Kalyanmoy Deb, Vishnu Naresh Boddeti, Jie Tan, Esteban Real</author><pubDate>Mon, 31 Jul 2023 18:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16890v1</guid></item><item><title>Virtual Prompt Injection for Instruction-Tuned Large Language Models</title><link>http://arxiv.org/abs/2307.16888v1</link><description>We present Virtual Prompt Injection (VPI) for instruction-tuned LargeLanguage Models (LLMs). VPI allows an attacker-specified virtual prompt tosteer the model behavior under specific trigger scenario without any explicitinjection in model input. For instance, if an LLM is compromised with thevirtual prompt "Describe Joe Biden negatively." for Joe Biden-relatedinstructions, then any service deploying this model will propagate biased viewswhen handling user queries related to Joe Biden. VPI is especially harmful fortwo primary reasons. Firstly, the attacker can take fine-grained control overLLM behaviors by defining various virtual prompts, exploiting LLMs' proficiencyin following instructions. Secondly, this control is achieved without anyinteraction from the attacker while the model is in service, leading topersistent attack. To demonstrate the threat, we propose a simple method forperforming VPI by poisoning the model's instruction tuning data. We find thatour proposed method is highly effective in steering the LLM with VPI. Forexample, by injecting only 52 poisoned examples (0.1% of the training datasize) into the instruction tuning data, the percentage of negative responsesgiven by the trained model on Joe Biden-related queries change from 0% to 40%.We thus highlight the necessity of ensuring the integrity of theinstruction-tuning data as little poisoned data can cause stealthy andpersistent harm to the deployed model. We further explore the possible defensesand identify data filtering as an effective way to defend against the poisoningattacks. Our project page is available at https://poison-llm.github.io.</description><author>Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin</author><pubDate>Mon, 31 Jul 2023 18:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16888v1</guid></item><item><title>Comparison of Point Cloud and Image-based Models for Calorimeter Fast Simulation</title><link>http://arxiv.org/abs/2307.04780v2</link><description>Score based generative models are a new class of generative models that havebeen shown to accurately generate high dimensional calorimeter datasets. Recentadvances in generative models have used images with 3D voxels to represent andmodel complex calorimeter showers. Point clouds, however, are likely a morenatural representation of calorimeter showers, particularly in calorimeterswith high granularity. Point clouds preserve all of the information of theoriginal simulation, more naturally deal with sparse datasets, and can beimplemented with more compact models and data files. In this work, twostate-of-the-art score based models are trained on the same set of calorimetersimulation and directly compared.</description><author>Fernando Torales Acosta, Vinicius Mikuni, Benjamin Nachman, Miguel Arratia, Bishnu Karki, Ryan Milton, Piyush Karande, Aaron Angerami</author><pubDate>Mon, 31 Jul 2023 18:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04780v2</guid></item><item><title>Competence-Based Analysis of Language Models</title><link>http://arxiv.org/abs/2303.00333v2</link><description>Despite the recent success of large pretrained language models (LMs) on avariety of prompting tasks, these models can be alarmingly brittle to smallchanges in inputs or application contexts. To better understand such behaviorand motivate the design of more robust LMs, we propose a general experimentalframework, CALM (Competence-based Analysis of Language Models), where targetedcausal interventions are utilized to damage an LM's internal representation ofvarious linguistic properties in order to evaluate its use of eachrepresentation in performing a given task. We implement these interventions asgradient-based adversarial attacks, which (in contrast to prior causal probingmethodologies) are able to target arbitrarily-encoded representations ofrelational properties, and carry out a case study of this approach to analyzehow BERT-like LMs use representations of several relational properties inperforming associated relation prompting tasks. We find that, while therepresentations LMs leverage in performing each task are highly entangled, theymay be meaningfully interpreted in terms of the tasks where they are mostutilized; and more broadly, that CALM enables an expanded scope of inquiry inLM analysis that may be useful in predicting and explaining weaknesses ofexisting LMs.</description><author>Adam Davies, Jize Jiang, ChengXiang Zhai</author><pubDate>Mon, 31 Jul 2023 18:49:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00333v2</guid></item><item><title>HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</title><link>http://arxiv.org/abs/2307.16883v1</link><description>The rise of large language models (LLMs) had a transformative impact onsearch, ushering in a new era of search engines that are capable of generatingsearch results in natural language text, imbued with citations for supportingsources. Building generative information-seeking models demands openlyaccessible datasets, which currently remain lacking. In this paper, weintroduce a new dataset, HAGRID (Human-in-the-loop Attributable GenerativeRetrieval for Information-seeking Dataset) for building end-to-end generativeinformation-seeking models that are capable of retrieving candidate quotes andgenerating attributed explanations. Unlike recent efforts that focus on humanevaluation of black-box proprietary search engines, we built our dataset atopthe English subset of MIRACL, a publicly available information retrievaldataset. HAGRID is constructed based on human and LLM collaboration. We firstautomatically collect attributed explanations that follow an in-contextcitation style using an LLM, i.e. GPT-3.5. Next, we ask human annotators toevaluate the LLM explanations based on two criteria: informativeness andattributability. HAGRID serves as a catalyst for the development ofinformation-seeking models with better attribution capabilities.</description><author>Ehsan Kamalloo, Aref Jafari, Xinyu Zhang, Nandan Thakur, Jimmy Lin</author><pubDate>Mon, 31 Jul 2023 18:49:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16883v1</guid></item><item><title>Lost in the Middle: How Language Models Use Long Contexts</title><link>http://arxiv.org/abs/2307.03172v2</link><description>While recent language models have the ability to take long contexts as input,relatively little is known about how well they use longer context. We analyzelanguage model performance on two tasks that require identifying relevantinformation within their input contexts: multi-document question answering andkey-value retrieval. We find that performance is often highest when relevantinformation occurs at the beginning or end of the input context, andsignificantly degrades when models must access relevant information in themiddle of long contexts. Furthermore, performance substantially decreases asthe input context grows longer, even for explicitly long-context models. Ouranalysis provides a better understanding of how language models use their inputcontext and provides new evaluation protocols for future long-context models.</description><author>Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang</author><pubDate>Mon, 31 Jul 2023 18:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03172v2</guid></item><item><title>Image Synthesis under Limited Data: A Survey and Taxonomy</title><link>http://arxiv.org/abs/2307.16879v1</link><description>Deep generative models, which target reproducing the given data distributionto produce novel samples, have made unprecedented advancements in recent years.Their technical breakthroughs have enabled unparalleled quality in thesynthesis of visual content. However, one critical prerequisite for theirtremendous success is the availability of a sufficient number of trainingsamples, which requires massive computation resources. When trained on limiteddata, generative models tend to suffer from severe performance deteriorationdue to overfitting and memorization. Accordingly, researchers have devotedconsiderable attention to develop novel models that are capable of generatingplausible and diverse images from limited training data recently. Despitenumerous efforts to enhance training stability and synthesis quality in thelimited data scenarios, there is a lack of a systematic survey that provides 1)a clear problem definition, critical challenges, and taxonomy of various tasks;2) an in-depth analysis on the pros, cons, and remain limitations of existingliterature; as well as 3) a thorough discussion on the potential applicationsand future directions in the field of image synthesis under limited data. Inorder to fill this gap and provide a informative introduction to researcherswho are new to this topic, this survey offers a comprehensive review and anovel taxonomy on the development of image synthesis under limited data. Inparticular, it covers the problem definition, requirements, main solutions,popular benchmarks, and remain challenges in a comprehensive and all-aroundmanner.</description><author>Mengping Yang, Zhe Wang</author><pubDate>Mon, 31 Jul 2023 18:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16879v1</guid></item><item><title>Learning Interpretable, High-Performing Policies for Autonomous Driving</title><link>http://arxiv.org/abs/2202.02352v3</link><description>Gradient-based approaches in reinforcement learning (RL) have achievedtremendous success in learning policies for autonomous vehicles. While theperformance of these approaches warrants real-world adoption, these policieslack interpretability, limiting deployability in the safety-critical andlegally-regulated domain of autonomous driving (AD). AD requires interpretableand verifiable control policies that maintain high performance. We proposeInterpretable Continuous Control Trees (ICCTs), a tree-based model that can beoptimized via modern, gradient-based, RL approaches to produce high-performing,interpretable policies. The key to our approach is a procedure for allowingdirect optimization in a sparse decision-tree-like representation. We validateICCTs against baselines across six domains, showing that ICCTs are capable oflearning interpretable policy representations that parity or outperformbaselines by up to 33% in AD scenarios while achieving a 300x-600x reduction inthe number of policy parameters against deep learning baselines. Furthermore,we demonstrate the interpretability and utility of our ICCTs through a 14-carphysical robot demonstration.</description><author>Rohan Paleja, Yaru Niu, Andrew Silva, Chace Ritchie, Sugju Choi, Matthew Gombolay</author><pubDate>Mon, 31 Jul 2023 18:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.02352v3</guid></item><item><title>Contrastive Learning for API Aspect Analysis</title><link>http://arxiv.org/abs/2307.16878v1</link><description>We present a novel approach - CLAA - for API aspect detection in API reviewsthat utilizes transformer models trained with a supervised contrastive lossobjective function. We evaluate CLAA using performance and impact analysis. Forperformance analysis, we utilized a benchmark dataset on developer discussionscollected from Stack Overflow and compare the results to those obtained usingstate-of-the-art transformer models. Our experiments show that contrastivelearning can significantly improve the performance of transformer models indetecting aspects such as Performance, Security, Usability, and Documentation.For impact analysis, we performed empirical and developer study. On a randomlyselected and manually labeled 200 online reviews, CLAA achieved 92% accuracywhile the SOTA baseline achieved 81.5%. According to our developer studyinvolving 10 participants, the use of 'Stack Overflow + CLAA' resulted inincreased accuracy and confidence during API selection. Replication package:https://github.com/shahariar-shibli/Contrastive-Learning-for-API-Aspect-Analysis</description><author>G. M. Shahariar, Tahmid Hasan, Anindya Iqbal, Gias Uddin</author><pubDate>Mon, 31 Jul 2023 18:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16878v1</guid></item><item><title>Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering</title><link>http://arxiv.org/abs/2307.16877v1</link><description>Retriever-augmented instruction-following models are attractive alternativesto fine-tuned approaches for information-seeking tasks such as questionanswering (QA). By simply prepending retrieved documents in its input alongwith an instruction, these models can be adapted to various information domainsand tasks without additional fine-tuning. While the model responses tend to benatural and fluent, the additional verbosity makes traditional QA evaluationmetrics such as exact match (EM) and F1 unreliable for accurately quantifyingmodel performance. In this work, we investigate the performance of instruction-following modelsacross three information-seeking QA tasks. We use both automatic and humanevaluation to evaluate these models along two dimensions: 1) how well theysatisfy the user's information need (correctness), and 2) whether they producea response based on the provided knowledge (faithfulness). Guided by humanevaluation and analysis, we highlight the shortcomings of traditional metricsfor both correctness and faithfulness. We then propose simple token-overlapbased and model-based metrics that reflect the true performance of thesemodels. Our analysis reveals that instruction-following models are competitive,and sometimes even outperform fine-tuned models for correctness. However, thesemodels struggle to stick to the provided knowledge and often hallucinate intheir responses. We hope our work encourages a more holistic evaluation ofinstruction-following models for QA. Our code and data is available athttps://github.com/McGill-NLP/instruct-qa</description><author>Vaibhav Adlakha, Parishad BehnamGhader, Xing Han Lu, Nicholas Meade, Siva Reddy</author><pubDate>Mon, 31 Jul 2023 18:41:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16877v1</guid></item><item><title>Forgotten Knowledge: Examining the Citational Amnesia in NLP</title><link>http://arxiv.org/abs/2305.18554v2</link><description>Citing papers is the primary method through which modern scientific writingdiscusses and builds on past work. Collectively, citing a diverse set of papers(in time and area of study) is an indicator of how widely the community isreading. Yet, there is little work looking at broad temporal patterns ofcitation. This work systematically and empirically examines: How far back intime do we tend to go to cite papers? How has that changed over time, and whatfactors correlate with this citational attention/amnesia? We chose NLP as ourdomain of interest and analyzed approximately 71.5K papers to show and quantifyseveral key trends in citation. Notably, around 62% of cited papers are fromthe immediate five years prior to publication, whereas only about 17% are morethan ten years old. Furthermore, we show that the median age and age diversityof cited papers were steadily increasing from 1990 to 2014, but since then, thetrend has reversed, and current NLP papers have an all-time low temporalcitation diversity. Finally, we show that unlike the 1990s, the highly citedpapers in the last decade were also papers with the least citation diversity,likely contributing to the intense (and arguably harmful) recency focus. Code,data, and a demo are available on the project homepage.</description><author>Janvijay Singh, Mukund Rungta, Diyi Yang, Saif M. Mohammad</author><pubDate>Mon, 31 Jul 2023 18:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18554v2</guid></item><item><title>Measuring Re-identification Risk</title><link>http://arxiv.org/abs/2304.07210v2</link><description>Compact user representations (such as embeddings) form the backbone ofpersonalization services. In this work, we present a new theoretical frameworkto measure re-identification risk in such user representations. Our framework,based on hypothesis testing, formally bounds the probability that an attackermay be able to obtain the identity of a user from their representation. As anapplication, we show how our framework is general enough to model importantreal-world applications such as the Chrome's Topics API for interest-basedadvertising. We complement our theoretical bounds by showing provably goodattack algorithms for re-identification that we use to estimate there-identification risk in the Topics API. We believe this work provides arigorous and interpretable notion of re-identification risk and a framework tomeasure it that can be used to inform real-world applications.</description><author>CJ Carey, Travis Dick, Alessandro Epasto, Adel Javanmard, Josh Karlin, Shankar Kumar, Andres Munoz Medina, Vahab Mirrokni, Gabriel Henrique Nunes, Sergei Vassilvitskii, Peilin Zhong</author><pubDate>Mon, 31 Jul 2023 18:35:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07210v2</guid></item><item><title>Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy</title><link>http://arxiv.org/abs/2307.16867v1</link><description>Current state-of-the-art results in computer vision depend in part onfine-tuning large pre-trained vision models. However, with the exponentialgrowth of model sizes, the conventional full fine-tuning, which needs to storea individual network copy for each tasks, leads to increasingly huge storageand transmission overhead. Adapter-based Parameter-Efficient Tuning (PET)methods address this challenge by tuning lightweight adapters inserted into thefrozen pre-trained models. In this paper, we investigate how to make adapterseven more efficient, reaching a new minimum size required to store atask-specific fine-tuned network. Inspired by the observation that theparameters of adapters converge at flat local minima, we find that adapters areresistant to noise in parameter space, which means they are also resistant tolow numerical precision. To train low-precision adapters, we propose acomputational-efficient quantization method which minimizes the quantizationerror. Through extensive experiments, we find that low-precision adaptersexhibit minimal performance degradation, and even 1-bit precision is sufficientfor adapters. The experimental results demonstrate that 1-bit adaptersoutperform all other PET methods on both the VTAB-1K benchmark and few-shotFGVC tasks, while requiring the smallest storage size. Our findings show, forthe first time, the significant potential of quantization techniques in PET,providing a general solution to enhance the parameter efficiency ofadapter-based PET methods. Code: https://github.com/JieShibo/PETL-ViT</description><author>Shibo Jie, Haoqing Wang, Zhi-Hong Deng</author><pubDate>Mon, 31 Jul 2023 18:22:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16867v1</guid></item><item><title>Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models</title><link>http://arxiv.org/abs/2307.16865v1</link><description>Deep neural networks (DNNs) have achieved tremendous success in many remotesensing (RS) applications. However, their vulnerability to the threat ofadversarial perturbations should not be neglected. Unfortunately, currentadversarial defense approaches in RS studies usually suffer from performancefluctuation and unnecessary re-training costs due to the need for priorknowledge of the adversarial perturbations among RS data. To circumvent thesechallenges, we propose a universal adversarial defense approach in RS imagery(UAD-RS) using pre-trained diffusion models to defend the common DNNs againstmultiple unknown adversarial attacks. Specifically, the generative diffusionmodels are first pre-trained on different RS datasets to learn generalizedrepresentations in various data domains. After that, a universal adversarialpurification framework is developed using the forward and reverse process ofthe pre-trained diffusion models to purify the perturbations from adversarialsamples. Furthermore, an adaptive noise level selection (ANLS) mechanism isbuilt to capture the optimal noise level of the diffusion model that canachieve the best purification results closest to the clean samples according totheir Frechet Inception Distance (FID) in deep feature space. As a result, onlya single pre-trained diffusion model is needed for the universal purificationof adversarial samples on each dataset, which significantly alleviates there-training efforts for each attack setting and maintains high performancewithout the prior knowledge of adversarial perturbations. Experiments on fourheterogeneous RS datasets regarding scene classification and semanticsegmentation verify that UAD-RS outperforms state-of-the-art adversarialpurification approaches with a universal defense against seven commonlyexisting adversarial perturbations.</description><author>Weikang Yu, Yonghao Xu, Pedram Ghamisi</author><pubDate>Mon, 31 Jul 2023 18:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16865v1</guid></item><item><title>MetaCAM: Ensemble-Based Class Activation Map</title><link>http://arxiv.org/abs/2307.16863v1</link><description>The need for clear, trustworthy explanations of deep learning modelpredictions is essential for high-criticality fields, such as medicine andbiometric identification. Class Activation Maps (CAMs) are an increasinglypopular category of visual explanation methods for Convolutional NeuralNetworks (CNNs). However, the performance of individual CAMs depends largely onexperimental parameters such as the selected image, target class, and model.Here, we propose MetaCAM, an ensemble-based method for combining multipleexisting CAM methods based on the consensus of the top-k% most highly activatedpixels across component CAMs. We perform experiments to quantifiably determinethe optimal combination of 11 CAMs for a given MetaCAM experiment. A new methoddenoted Cumulative Residual Effect (CRE) is proposed to summarize large-scaleensemble-based experiments. We also present adaptive thresholding anddemonstrate how it can be applied to individual CAMs to improve theirperformance, measured using pixel perturbation method Remove and Debias (ROAD).Lastly, we show that MetaCAM outperforms existing CAMs and refines the mostsalient regions of images used for model predictions. In a specific example,MetaCAM improved ROAD performance to 0.393 compared to 11 individual CAMs withranges from -0.101-0.172, demonstrating the importance of combining CAMsthrough an ensembling method and adaptive thresholding.</description><author>Emily Kaczmarek, Olivier X. Miguel, Alexa C. Bowie, Robin Ducharme, Alysha L. J. Dingwall-Harvey, Steven Hawken, Christine M. Armour, Mark C. Walker, Kevin Dick</author><pubDate>Mon, 31 Jul 2023 18:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16863v1</guid></item><item><title>L-Eval: Instituting Standardized Evaluation for Long Context Language Models</title><link>http://arxiv.org/abs/2307.11088v2</link><description>Recently, there has been growing interest in extending the context length ofinstruction-following models in order to effectively process single-turn longinput (e.g. summarizing a paper) and conversations with more extensivehistories. While proprietary models such as GPT-4 and Claude have shownsignificant strides in handling extremely lengthy input, open-sourced modelsare still in the early stages of experimentation. It also remains unclearwhether extending the context can offer substantial gains over traditionalmethods such as retrieval, and to what extent it improves upon their regularcounterparts in practical downstream tasks. To address this challenge, wepropose instituting standardized evaluation for long context language models.Concretely, we develop L-Eval which contains 411 long documents and over 2,000human-labeled query-response pairs encompassing areas such as law, finance,school lectures, lengthy conversations, news, long-form novels, and meetings.L-Eval also adopts diverse evaluation methods and instruction styles, enablinga more reliable assessment of Long Context Language Models (LCLMs). Ourfindings indicate that while open-source models typically lag behind commercialmodels, they still exhibit impressive performance compared with their regularversions. LLaMA2-13B achieves the best results on both open-ended tasks (win\textbf{42}\% vs turbo-16k-0613) and closed-ended tasks with only 4k contextlength. We release our new evaluation suite, code, and all generation resultsincluding predictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at{\url{https://github.com/OpenLMLab/LEval}}.</description><author>Chenxin An, Shansan Gong, Ming Zhong, Mukai Li, Jun Zhang, Lingpeng Kong, Xipeng Qiu</author><pubDate>Mon, 31 Jul 2023 18:19:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11088v2</guid></item><item><title>Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives</title><link>http://arxiv.org/abs/2307.16851v1</link><description>The trustworthiness of machine learning has emerged as a critical topic inthe field, encompassing various applications and research areas such asrobustness, security, interpretability, and fairness. The last decade saw thedevelopment of numerous methods addressing these challenges. In this survey, wesystematically review these advancements from a data-centric perspective,highlighting the shortcomings of traditional empirical risk minimization (ERM)training in handling challenges posed by the data. Interestingly, we observe a convergence of these methods, despite beingdeveloped independently across trustworthy machine learning subfields. Pearl'shierarchy of causality offers a unifying framework for these techniques.Accordingly, this survey presents the background of trustworthy machinelearning development using a unified set of concepts, connects this language toPearl's causal hierarchy, and finally discusses methods explicitly inspired bycausality literature. We provide a unified language with mathematicalvocabulary to link these methods across robustness, adversarial robustness,interpretability, and fairness, fostering a more cohesive understanding of thefield. Further, we explore the trustworthiness of large pretrained models. Aftersummarizing dominant techniques like fine-tuning, parameter-efficientfine-tuning, prompting, and reinforcement learning with human feedback, we drawconnections between them and the standard ERM. This connection allows us tobuild upon the principled understanding of trustworthy methods, extending it tothese new techniques in large pretrained models, paving the way for futuremethods. Existing methods under this perspective are also reviewed. Lastly, we offer a brief summary of the applications of these methods anddiscuss potential future aspects related to our survey. For more information,please visit http://trustai.one.</description><author>Haoyang Liu, Maheep Chaudhary, Haohan Wang</author><pubDate>Mon, 31 Jul 2023 18:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16851v1</guid></item><item><title>A Trajectory K-Anonymity Model Based on Point Density and Partition</title><link>http://arxiv.org/abs/2307.16849v1</link><description>As people's daily life becomes increasingly inseparable from various mobileelectronic devices, relevant service application platforms and networkoperators can collect numerous individual information easily. When releasingthese data for scientific research or commercial purposes, users' privacy willbe in danger, especially in the publication of spatiotemporal trajectorydatasets. Therefore, to avoid the leakage of users' privacy, it is necessary toanonymize the data before they are released. However, more than simply removingthe unique identifiers of individuals is needed to protect the trajectoryprivacy, because some attackers may infer the identity of users by theconnection with other databases. Much work has been devoted to merging multipletrajectories to avoid re-identification, but these solutions always requiresacrificing data quality to achieve the anonymity requirement. In order toprovide sufficient privacy protection for users' trajectory datasets, thispaper develops a study on trajectory privacy against re-identification attacks,proposing a trajectory K-anonymity model based on Point Density and Partition(KPDP). Our approach improves the existing trajectory generalizationanonymization techniques regarding trajectory set partition preprocessing andtrajectory clustering algorithms. It successfully resists re-identificationattacks and reduces the data utility loss of the k-anonymized dataset. A seriesof experiments on a real-world dataset show that the proposed model hassignificant advantages in terms of higher data utility and shorter algorithmexecution time than other existing techniques.</description><author>Wanshu Yu, Haonan Shi, Hongyun Xu</author><pubDate>Mon, 31 Jul 2023 18:10:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16849v1</guid></item><item><title>Latent Masking for Multimodal Self-supervised Learning in Health Timeseries</title><link>http://arxiv.org/abs/2307.16847v1</link><description>Limited availability of labeled data for machine learning on biomedicaltime-series hampers progress in the field. Self-supervised learning (SSL) is apromising approach to learning data representations without labels. However,current SSL methods require expensive computations for negative pairs and aredesigned for single modalities, limiting their versatility. To overcome theselimitations, we introduce CroSSL (Cross-modal SSL). CroSSL introduces two novelconcepts: masking intermediate embeddings from modality-specific encoders andaggregating them into a global embedding using a cross-modal aggregator. Thisenables the handling of missing modalities and end-to-end learning ofcross-modal patterns without prior data preprocessing or time-consumingnegative-pair sampling. We evaluate CroSSL on various multimodal time-seriesbenchmarks, including both medical-grade and consumer biosignals. Our resultsdemonstrate superior performance compared to previous SSL techniques andsupervised benchmarks with minimal labeled data. We additionally analyze theimpact of different masking ratios and strategies and assess the robustness ofthe learned representations to missing modalities. Overall, our work achievesstate-of-the-art performance while highlighting the benefits of masking latentembeddings for cross-modal learning in temporal health data.</description><author>Shohreh Deldari, Dimitris Spathis, Mohammad Malekzadeh, Fahim Kawsar, Flora Salim, Akhil Mathur</author><pubDate>Mon, 31 Jul 2023 18:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16847v1</guid></item><item><title>Interpreting deep embeddings for disease progression clustering</title><link>http://arxiv.org/abs/2307.06060v2</link><description>We propose a novel approach for interpreting deep embeddings in the contextof patient clustering. We evaluate our approach on a dataset of participantswith type 2 diabetes from the UK Biobank, and demonstrate clinically meaningfulinsights into disease progression patterns.</description><author>Anna Munoz-Farre, Antonios Poulakakis-Daktylidis, Dilini Mahesha Kothalawala, Andrea Rodriguez-Martinez</author><pubDate>Mon, 31 Jul 2023 18:08:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06060v2</guid></item><item><title>Identification of Driving Heterogeneity using Action-chains</title><link>http://arxiv.org/abs/2307.16843v1</link><description>Current approaches to identifying driving heterogeneity face challenges incapturing the diversity of driving characteristics and understanding thefundamental patterns from a driving behaviour mechanism standpoint. This studyintroduces a comprehensive framework for identifying driving heterogeneity froman Action-chain perspective. First, a rule-based segmentation technique thatconsiders the physical meanings of driving behaviour is proposed. Next, anAction phase Library including descriptions of various driving behaviourpatterns is created based on the segmentation findings. The Action-chainconcept is then introduced by implementing Action phase transition probability,followed by a method for evaluating driving heterogeneity. Employing real-worlddatasets for evaluation, our approach effectively identifies drivingheterogeneity for both individual drivers and traffic flow while providingclear interpretations. These insights can aid the development of accuratedriving behaviour theory and traffic flow models, ultimately benefiting trafficperformance, and potentially leading to aspects such as improved road capacityand safety.</description><author>Xue Yao, Simeon C. Calvert, Serge P. Hoogendoorn</author><pubDate>Mon, 31 Jul 2023 18:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16843v1</guid></item><item><title>Decidable Fragments of LTLf Modulo Theories (Extended Version)</title><link>http://arxiv.org/abs/2307.16840v1</link><description>We study Linear Temporal Logic Modulo Theories over Finite Traces (LTLfMT), arecently introduced extension of LTL over finite traces (LTLf) wherepropositions are replaced by first-order formulas and where first-ordervariables referring to different time points can be compared. In general,LTLfMT was shown to be semi-decidable for any decidable first-order theory(e.g., linear arithmetics), with a tableau-based semi-decision procedure. In this paper we present a sound and complete pruning rule for the LTLfMTtableau. We show that for any LTLfMT formula that satisfies an abstract,semantic condition, that we call finite memory, the tableau augmented with thenew rule is also guaranteed to terminate. Last but not least, this techniqueallows us to establish novel decidability results for the satisfiability ofseveral fragments of LTLfMT, as well as to give new decidability proofs forclasses that are already known.</description><author>Luca Geatti, Alessandro Gianola, Nicola Gigante, Sarah Winkler</author><pubDate>Mon, 31 Jul 2023 18:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16840v1</guid></item><item><title>See What the Robot Can't See: Learning Cooperative Perception for Visual Navigation</title><link>http://arxiv.org/abs/2208.00759v5</link><description>We consider the problem of navigating a mobile robot towards a target in anunknown environment that is endowed with visual sensors, where neither therobot nor the sensors have access to global positioning information and onlyuse first-person-view images. In order to overcome the need for positioning, wetrain the sensors to encode and communicate relevant viewpoint information tothe mobile robot, whose objective it is to use this information to navigate tothe target along the shortest path. We overcome the challenge of enabling allthe sensors (even those that cannot directly see the target) to predict thedirection along the shortest path to the target by implementing aneighborhood-based feature aggregation module using a Graph Neural Network(GNN) architecture. In our experiments, we first demonstrate generalizabilityto previously unseen environments with various sensor layouts. Our results showthat by using communication between the sensors and the robot, we achieve up to2.0x improvement in SPL (Success weighted by Path Length) when compared to acommunication-free baseline. This is done without requiring a global map,positioning data, nor pre-calibration of the sensor network. Second, we performa zero-shot transfer of our model from simulation to the real world. Laboratoryexperiments demonstrate the feasibility of our approach in various clutteredenvironments. Finally, we showcase examples of successful navigation to thetarget while both the sensor network layout as well as obstacles aredynamically reconfigured as the robot navigates. We provide a video demo, thedataset, trained models, and source code. https://www.youtube.com/watch?v=kcmr6RUgucwhttps://github.com/proroklab/sensor-guided-visual-nav</description><author>Jan Blumenkamp, Qingbiao Li, Binyu Wang, Zhe Liu, Amanda Prorok</author><pubDate>Mon, 31 Jul 2023 17:40:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.00759v5</guid></item><item><title>Random Sub-Samples Generation for Self-Supervised Real Image Denoising</title><link>http://arxiv.org/abs/2307.16825v1</link><description>With sufficient paired training samples, the supervised deep learning methodshave attracted much attention in image denoising because of their superiorperformance. However, it is still very challenging to widely utilize thesupervised methods in real cases due to the lack of paired noisy-clean images.Meanwhile, most self-supervised denoising methods are ineffective as well whenapplied to the real-world denoising tasks because of their strict assumptionsin applications. For example, as a typical method for self-superviseddenoising, the original blind spot network (BSN) assumes that the noise ispixel-wise independent, which is much different from the real cases. To solvethis problem, we propose a novel self-supervised real image denoising frameworknamed Sampling Difference As Perturbation (SDAP) based on Random Sub-samplesGeneration (RSG) with a cyclic sample difference loss. Specifically, we digdeeper into the properties of BSN to make it more suitable for real noise.Surprisingly, we find that adding an appropriate perturbation to the trainingimages can effectively improve the performance of BSN. Further, we propose thatthe sampling difference can be considered as perturbation to achieve betterresults. Finally we propose a new BSN framework in combination with our RSGstrategy. The results show that it significantly outperforms otherstate-of-the-art self-supervised denoising methods on real-world datasets. Thecode is available at https://github.com/p1y2z3/SDAP.</description><author>Yizhong Pan, Xiao Liu, Xiangyu Liao, Yuanzhouhan Cao, Chao Ren</author><pubDate>Mon, 31 Jul 2023 17:39:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16825v1</guid></item><item><title>Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection</title><link>http://arxiv.org/abs/2307.16816v1</link><description>Neural ranking models (NRMs) have undergone significant development and havebecome integral components of information retrieval (IR) systems.Unfortunately, recent research has unveiled the vulnerability of NRMs toadversarial document manipulations, potentially exploited by malicious searchengine optimization practitioners. While progress in adversarial attackstrategies aids in identifying the potential weaknesses of NRMs before theirdeployment, the defensive measures against such attacks, like the detection ofadversarial documents, remain inadequately explored. To mitigate this gap, thispaper establishes a benchmark dataset to facilitate the investigation ofadversarial ranking defense and introduces two types of detection tasks foradversarial documents. A comprehensive investigation of the performance ofseveral detection baselines is conducted, which involve examining thespamicity, perplexity, and linguistic acceptability, and utilizing supervisedclassifiers. Experimental results demonstrate that a supervised classifier caneffectively mitigate known attacks, but it performs poorly against unseenattacks. Furthermore, such classifier should avoid using query text to preventlearning the classification on relevance, as it might lead to the inadvertentdiscarding of relevant documents.</description><author>Xuanang Chen, Ben He, Le Sun, Yingfei Sun</author><pubDate>Mon, 31 Jul 2023 17:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16816v1</guid></item><item><title>Capturing Co-existing Distortions in User-Generated Content for No-reference Video Quality Assessment</title><link>http://arxiv.org/abs/2307.16813v1</link><description>Video Quality Assessment (VQA), which aims to predict the perceptual qualityof a video, has attracted raising attention with the rapid development ofstreaming media technology, such as Facebook, TikTok, Kwai, and so on. Comparedwith other sequence-based visual tasks (\textit{e.g.,} action recognition), VQAfaces two under-estimated challenges unresolved in User Generated Content (UGC)videos. \textit{First}, it is not rare that several frames containing seriousdistortions (\textit{e.g.,}blocking, blurriness), can determine the perceptualquality of the whole video, while other sequence-based tasks require moreframes of equal importance for representations. \textit{Second}, the perceptualquality of a video exhibits a multi-distortion distribution, due to thedifferences in the duration and probability of occurrence for variousdistortions. In order to solve the above challenges, we propose \textit{VisualQuality Transformer (VQT)} to extract quality-related sparse features moreefficiently. Methodologically, a Sparse Temporal Attention (STA) is proposed tosample keyframes by analyzing the temporal correlation between frames, whichreduces the computational complexity from $O(T^2)$ to $O(T \log T)$.Structurally, a Multi-Pathway Temporal Network (MPTN) utilizes multiple STAmodules with different degrees of sparsity in parallel, capturing co-existingdistortions in a video. Experimentally, VQT demonstrates superior performancethan many \textit{state-of-the-art} methods in three public no-reference VQAdatasets. Furthermore, VQT shows better performance in four full-reference VQAdatasets against widely-adopted industrial algorithms (\textit{i.e.,} VMAF andAVQT).</description><author>Kun Yuan, Zishang Kong, Chuanchuan Zheng, Ming Sun, Xing Wen</author><pubDate>Mon, 31 Jul 2023 17:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16813v1</guid></item><item><title>DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures</title><link>http://arxiv.org/abs/2307.16811v1</link><description>Public figures receive a disproportionate amount of abuse on social media,impacting their active participation in public life. Automated systems canidentify abuse at scale but labelling training data is expensive, complex andpotentially harmful. So, it is desirable that systems are efficient andgeneralisable, handling both shared and specific aspects of online abuse. Weexplore the dynamics of cross-group text classification in order to understandhow well classifiers trained on one domain or demographic can transfer toothers, with a view to building more generalisable abuse classifiers. Wefine-tune language models to classify tweets targeted at public figures acrossDOmains (sport and politics) and DemOgraphics (women and men) using our novelDODO dataset, containing 28,000 labelled entries, split equally across fourdomain-demographic pairs. We find that (i) small amounts of diverse data arehugely beneficial to generalisation and model adaptation; (ii) models transfermore easily across demographics but models trained on cross-domain data aremore generalisable; (iii) some groups contribute more to generalisability thanothers; and (iv) dataset similarity is a signal of transferability.</description><author>Hannah Rose Kirk, Angus R. Williams, Liam Burke, Yi-Ling Chung, Ivan Debono, Pica Johansson, Francesca Stevens, Jonathan Bright, Scott A. Hale</author><pubDate>Mon, 31 Jul 2023 17:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16811v1</guid></item><item><title>SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability</title><link>http://arxiv.org/abs/2208.09418v4</link><description>Interpretability of Deep Learning (DL) is a barrier to trustworthy AI.Despite great efforts made by the Explainable AI (XAI) community, explanationslack robustness -- indistinguishable input perturbations may lead to differentXAI results. Thus, it is vital to assess how robust DL interpretability is,given an XAI method. In this paper, we identify several challenges that thestate-of-the-art is unable to cope with collectively: i) existing metrics arenot comprehensive; ii) XAI techniques are highly heterogeneous; iii)misinterpretations are normally rare events. To tackle these challenges, weintroduce two black-box evaluation methods, concerning the worst-caseinterpretation discrepancy and a probabilistic notion of how robust in general,respectively. Genetic Algorithm (GA) with bespoke fitness function is used tosolve constrained optimisation for efficient worst-case evaluation. SubsetSimulation (SS), dedicated to estimate rare event probabilities, is used forevaluating overall robustness. Experiments show that the accuracy, sensitivity,and efficiency of our methods outperform the state-of-the-arts. Finally, wedemonstrate two applications of our methods: ranking robust XAI methods andselecting training schemes to improve both classification and interpretationrobustness.</description><author>Wei Huang, Xingyu Zhao, Gaojie Jin, Xiaowei Huang</author><pubDate>Mon, 31 Jul 2023 17:28:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09418v4</guid></item><item><title>On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems</title><link>http://arxiv.org/abs/2307.16807v1</link><description>Hopfield networks are an attractive choice for solving many types ofcomputational problems because they provide a biologically plausible mechanism.The Self-Optimization (SO) model adds to the Hopfield network by using abiologically founded Hebbian learning rule, in combination with repeatednetwork resets to arbitrary initial states, for optimizing its own behaviortowards some desirable goal state encoded in the network. In order to betterunderstand that process, we demonstrate first that the SO model can solveconcrete combinatorial problems in SAT form, using two examples of the Liarsproblem and the map coloring problem. In addition, we show how under someconditions critical information might get lost forever with the learned networkproducing seemingly optimal solutions that are in fact inappropriate for theproblem it was tasked to solve. What appears to be an undesirable side-effectof the SO model, can provide insight into its process for solving intractableproblems.</description><author>Natalya Weber, Werner Koch, Ozan Erdem, Tom Froese</author><pubDate>Mon, 31 Jul 2023 17:25:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16807v1</guid></item><item><title>Gzip versus bag-of-words for text classification with KNN</title><link>http://arxiv.org/abs/2307.15002v2</link><description>The effectiveness of compression distance in KNN-based text classification('gzip') has recently garnered lots of attention. In this note, we show thatsimpler means can also be effective, and compression may not be needed. Indeed,a 'bag-of-words' matching can achieve similar or better results, and is moreefficient.</description><author>Juri Opitz</author><pubDate>Mon, 31 Jul 2023 17:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15002v2</guid></item><item><title>DPMix: Mixture of Depth and Point Cloud Video Experts for 4D Action Segmentation</title><link>http://arxiv.org/abs/2307.16803v1</link><description>In this technical report, we present our findings from the research conductedon the Human-Object Interaction 4D (HOI4D) dataset for egocentric actionsegmentation task. As a relatively novel research area, point cloud videomethods might not be good at temporal modeling, especially for long point cloudvideos (\eg, 150 frames). In contrast, traditional video understanding methodshave been well developed. Their effectiveness on temporal modeling has beenwidely verified on many large scale video datasets. Therefore, we convert pointcloud videos into depth videos and employ traditional video modeling methods toimprove 4D action segmentation. By ensembling depth and point cloud videomethods, the accuracy is significantly improved. The proposed method, namedMixture of Depth and Point cloud video experts (DPMix), achieved the firstplace in the 4D Action Segmentation Track of the HOI4D Challenge 2023.</description><author>Yue Zhang, Hehe Fan, Yi Yang, Mohan Kankanhalli</author><pubDate>Mon, 31 Jul 2023 17:14:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16803v1</guid></item><item><title>Generative Adversarial Networks based Skin Lesion Segmentation</title><link>http://arxiv.org/abs/2305.18164v2</link><description>Skin cancer is a serious condition that requires accurate diagnosis andtreatment. One way to assist clinicians in this task is using computer-aideddiagnosis (CAD) tools that automatically segment skin lesions from dermoscopicimages. We propose a novel adversarial learning-based framework calledEfficient-GAN (EGAN) that uses an unsupervised generative network to generateaccurate lesion masks. It consists of a generator module with a top-downsqueeze excitation-based compound scaled path, an asymmetric lateralconnection-based bottom-up path, and a discriminator module that distinguishesbetween original and synthetic masks. A morphology-based smoothing loss is alsoimplemented to encourage the network to create smooth semantic boundaries oflesions. The framework is evaluated on the International Skin ImagingCollaboration (ISIC) Lesion Dataset 2018. It outperforms the currentstate-of-the-art skin lesion segmentation approaches with a Dice coefficient,Jaccard similarity, and Accuracy of 90.1%, 83.6%, and 94.5%, respectively. Wealso design a lightweight segmentation framework (MGAN) that achievescomparable performance as EGAN but with an order of magnitude lower number oftraining parameters, thus resulting in faster inference times for low computeresource settings.</description><author>Shubham Innani, Prasad Dutande, Ujjwal Baid, Venu Pokuri, Spyridon Bakas, Sanjay Talbar, Bhakti Baheti, Sharath Chandra Guntuku</author><pubDate>Mon, 31 Jul 2023 17:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18164v2</guid></item><item><title>R-LPIPS: An Adversarially Robust Perceptual Similarity Metric</title><link>http://arxiv.org/abs/2307.15157v2</link><description>Similarity metrics have played a significant role in computer vision tocapture the underlying semantics of images. In recent years, advancedsimilarity metrics, such as the Learned Perceptual Image Patch Similarity(LPIPS), have emerged. These metrics leverage deep features extracted fromtrained neural networks and have demonstrated a remarkable ability to closelyalign with human perception when evaluating relative image similarity. However,it is now well-known that neural networks are susceptible to adversarialexamples, i.e., small perturbations invisible to humans crafted to deliberatelymislead the model. Consequently, the LPIPS metric is also sensitive to suchadversarial examples. This susceptibility introduces significant securityconcerns, especially considering the widespread adoption of LPIPS inlarge-scale applications. In this paper, we propose the Robust LearnedPerceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leveragesadversarially trained deep features. Through a comprehensive set ofexperiments, we demonstrate the superiority of R-LPIPS compared to theclassical LPIPS metric. The code is available athttps://github.com/SaraGhazanfari/R-LPIPS.</description><author>Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Alexandre Araujo</author><pubDate>Mon, 31 Jul 2023 17:06:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15157v2</guid></item><item><title>Exploring the Benefits of Teams in Multiagent Learning</title><link>http://arxiv.org/abs/2205.02328v2</link><description>For problems requiring cooperation, many multiagent systems implementsolutions among either individual agents or across an entire population towardsa common goal. Multiagent teams are primarily studied when in conflict;however, organizational psychology (OP) highlights the benefits of teams amonghuman populations for learning how to coordinate and cooperate. In this paper,we propose a new model of multiagent teams for reinforcement learning (RL)agents inspired by OP and early work on teams in artificial intelligence. Wevalidate our model using complex social dilemmas that are popular in recentmultiagent RL and find that agents divided into teams develop cooperativepro-social policies despite incentives to not cooperate. Furthermore, agentsare better able to coordinate and learn emergent roles within their teams andachieve higher rewards compared to when the interests of all agents arealigned.</description><author>David Radke, Kate Larson, Tim Brecht</author><pubDate>Mon, 31 Jul 2023 17:06:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.02328v2</guid></item><item><title>Structural Transfer Learning in NL-to-Bash Semantic Parsers</title><link>http://arxiv.org/abs/2307.16795v1</link><description>Large-scale pre-training has made progress in many fields of natural languageprocessing, though little is understood about the design of pre-trainingdatasets. We propose a methodology for obtaining a quantitative understandingof structural overlap between machine translation tasks. We apply ourmethodology to the natural language to Bash semantic parsing task (NLBash) andshow that it is largely reducible to lexical alignment. We also find that thereis strong structural overlap between NLBash and natural language to SQL.Additionally, we perform a study varying compute expended during pre-trainingon the English to German machine translation task and find that more computeexpended during pre-training does not always correspond semanticrepresentations with stronger transfer to NLBash.</description><author>Kyle Duffy, Satwik Bhattamishra, Phil Blunsom</author><pubDate>Mon, 31 Jul 2023 17:02:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16795v1</guid></item><item><title>Classification with Deep Neural Networks and Logistic Loss</title><link>http://arxiv.org/abs/2307.16792v1</link><description>Deep neural networks (DNNs) trained with the logistic loss (i.e., the crossentropy loss) have made impressive advancements in various binaryclassification tasks. However, generalization analysis for binaryclassification with DNNs and logistic loss remains scarce. The unboundedness ofthe target function for the logistic loss is the main obstacle to derivingsatisfying generalization bounds. In this paper, we aim to fill this gap byestablishing a novel and elegant oracle-type inequality, which enables us todeal with the boundedness restriction of the target function, and using it toderive sharp convergence rates for fully connected ReLU DNN classifiers trainedwith logistic loss. In particular, we obtain optimal convergence rates (up tolog factors) only requiring the H\"older smoothness of the conditional classprobability $\eta$ of data. Moreover, we consider a compositional assumptionthat requires $\eta$ to be the composition of several vector-valued functionsof which each component function is either a maximum value function or aH\"older smooth function only depending on a small number of its inputvariables. Under this assumption, we derive optimal convergence rates (up tolog factors) which are independent of the input dimension of data. This resultexplains why DNN classifiers can perform well in practical high-dimensionalclassification problems. Besides the novel oracle-type inequality, the sharpconvergence rates given in our paper also owe to a tight error bound forapproximating the natural logarithm function near zero (where it is unbounded)by ReLU DNNs. In addition, we justify our claims for the optimality of rates byproving corresponding minimax lower bounds. All these results are new in theliterature and will deepen our theoretical understanding of classification withDNNs.</description><author>Zihan Zhang, Lei Shi, Ding-Xuan Zhou</author><pubDate>Mon, 31 Jul 2023 16:58:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16792v1</guid></item><item><title>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</title><link>http://arxiv.org/abs/2307.16789v1</link><description>Despite the advancements of open-source large language models (LLMs) andtheir variants, e.g., LLaMA and Vicuna, they remain significantly limited inperforming higher-level tasks, such as following human instructions to useexternal tools (APIs). This is because current instruction tuning largelyfocuses on basic language tasks instead of the tool-use domain. This is incontrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which havedemonstrated excellent tool-use capabilities but are unfortunately closedsource. To facilitate tool-use capabilities within open-source LLMs, weintroduce ToolLLM, a general tool-use framework of data construction, modeltraining and evaluation. We first present ToolBench, an instruction-tuningdataset for tool use, which is created automatically using ChatGPT.Specifically, we collect 16,464 real-world RESTful APIs spanning 49 categoriesfrom RapidAPI Hub, then prompt ChatGPT to generate diverse human instructionsinvolving these APIs, covering both single-tool and multi-tool scenarios.Finally, we use ChatGPT to search for a valid solution path (chain of APIcalls) for each instruction. To make the searching process more efficient, wedevelop a novel depth-first search-based decision tree (DFSDT), enabling LLMsto evaluate multiple reasoning traces and expand the search space. We show thatDFSDT significantly enhances the planning and reasoning capabilities of LLMs.For efficient tool-use assessment, we develop an automatic evaluator: ToolEval.We fine-tune LLaMA on ToolBench and obtain ToolLLaMA. Our ToolEval reveals thatToolLLaMA demonstrates a remarkable ability to execute complex instructions andgeneralize to unseen APIs, and exhibits comparable performance to ChatGPT. Tomake the pipeline more practical, we devise a neural API retriever to recommendappropriate APIs for each instruction, negating the need for manual APIselection.</description><author>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, Maosong Sun</author><pubDate>Mon, 31 Jul 2023 16:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16789v1</guid></item><item><title>CECT: Controllable Ensemble CNN and Transformer for COVID-19 Image Classification</title><link>http://arxiv.org/abs/2302.02314v3</link><description>The convolutional neural network (CNN) and transformer are two of the mostwidely implemented models in the computer vision field. However, the former(latter) one mainly captures local (global) features only. To address thelimitation in model performance caused by the lack of features, we develop anovel classification network CECT by controllable ensemble CNN and transformer.CECT is composed of a convolutional encoder block, a transposed-convolutionaldecoder block, and a transformer classification block. Different from existingmethods, our CECT can capture features at both multi-local and global scaleswithout any bells and whistles. Moreover, the contribution of local features atdifferent scales can be controlled with the proposed ensemble coefficients. Weevaluate CECT on two public COVID-19 datasets and it outperforms existingstate-of-the-art methods. With remarkable feature capture ability, we believeCECT can be extended to other medical image classification scenarios as adiagnosis assistant. Code is available at https://github.com/NUS-Tim/CECT.</description><author>Zhaoshan Liu, Lei Shen</author><pubDate>Mon, 31 Jul 2023 16:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02314v3</guid></item><item><title>The Ethics of AI Value Chains: An Approach for Integrating and Expanding AI Ethics Research, Practice, and Governance</title><link>http://arxiv.org/abs/2307.16787v1</link><description>Recent criticisms of AI ethics principles and practices have indicated a needfor new approaches to AI ethics that can account for and intervene in thedesign, development, use, and governance of AI systems across multiple actors,contexts, and scales of activity. This paper positions AI value chains as anintegrative concept that satisfies those needs, enabling AI ethics researchers,practitioners, and policymakers to take a more comprehensive view of theethical and practical implications of AI systems. We review and synthesizetheoretical perspectives on value chains from the literature on strategicmanagement, service science, and economic geography. We then reviewperspectives on AI value chains from the academic, industry, and policyliterature. We connect an inventory of ethical concerns in AI to the actors andresourcing activities involved in AI value chains to demonstrate thatapproaching AI ethics issues as value chain issues can enable morecomprehensive and integrative research and governance practices. We illustratethis by suggesting five future directions for researchers, practitioners, andpolicymakers to investigate and intervene in the ethical concerns associatedwith AI value chains.</description><author>Blair Attard-Frost, David Gray Widder</author><pubDate>Mon, 31 Jul 2023 16:55:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16787v1</guid></item><item><title>From Generation to Suppression: Towards Effective Irregular Glow Removal for Nighttime Visibility Enhancement</title><link>http://arxiv.org/abs/2307.16783v1</link><description>Most existing Low-Light Image Enhancement (LLIE) methods are primarilydesigned to improve brightness in dark regions, which suffer from severedegradation in nighttime images. However, these methods have limitedexploration in another major visibility damage, the glow effects in real nightscenes. Glow effects are inevitable in the presence of artificial light sourcesand cause further diffused blurring when directly enhanced. To settle thisissue, we innovatively consider the glow suppression task as learning physicalglow generation via multiple scattering estimation according to the AtmosphericPoint Spread Function (APSF). In response to the challenges posed by unevenglow intensity and varying source shapes, an APSF-based Nighttime Imaging Modelwith Near-field Light Sources (NIM-NLS) is specifically derived to design ascalable Light-aware Blind Deconvolution Network (LBDN). The glow-suppressedresult is then brightened via a Retinex-based Enhancement Module (REM).Remarkably, the proposed glow suppression method is based on zero-shot learningand does not rely on any paired or unpaired training data. Empiricalevaluations demonstrate the effectiveness of the proposed method in both glowsuppression and low-light enhancement tasks.</description><author>Wanyu Wu, Wei Wang, Zheng Wang, Kui Jiang, Xin Xu</author><pubDate>Mon, 31 Jul 2023 16:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16783v1</guid></item><item><title>Ranking-based Argumentation Semantics Applied to Logical Argumentation (full version)</title><link>http://arxiv.org/abs/2307.16780v1</link><description>In formal argumentation, a distinction can be made between extension-basedsemantics, where sets of arguments are either (jointly) accepted or not, andranking-based semantics, where grades of acceptability are assigned toarguments. Another important distinction is that between abstract approaches,that abstract away from the content of arguments, and structured approaches,that specify a method of constructing argument graphs on the basis of aknowledge base. While ranking-based semantics have been extensively applied toabstract argumentation, few work has been done on ranking-based semantics forstructured argumentation. In this paper, we make a systematic investigationinto the behaviour of ranking-based semantics applied to existing formalismsfor structured argumentation. We show that a wide class of ranking-basedsemantics gives rise to so-called culpability measures, and are relativelyrobust to specific choices in argument construction methods.</description><author>Jesse Heyninck, Badran Raddaoui, Christian Straer</author><pubDate>Mon, 31 Jul 2023 16:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16780v1</guid></item><item><title>Lexically-Accelerated Dense Retrieval</title><link>http://arxiv.org/abs/2307.16779v1</link><description>Retrieval approaches that score documents based on learned dense vectors(i.e., dense retrieval) rather than lexical signals (i.e., conventionalretrieval) are increasingly popular. Their ability to identify relateddocuments that do not necessarily contain the same terms as those appearing inthe user's query (thereby improving recall) is one of their key advantages.However, to actually achieve these gains, dense retrieval approaches typicallyrequire an exhaustive search over the document collection, making themconsiderably more expensive at query-time than conventional lexical approaches.Several techniques aim to reduce this computational overhead by approximatingthe results of a full dense retriever. Although these approaches reasonablyapproximate the top results, they suffer in terms of recall -- one of the keyadvantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated DenseRetrieval), a simple-yet-effective approach that improves the efficiency ofexisting dense retrieval models without compromising on retrievaleffectiveness. LADR uses lexical retrieval techniques to seed a dense retrievalexploration that uses a document proximity graph. We explore two variants ofLADR: a proactive approach that expands the search space to the neighbors ofall seed documents, and an adaptive approach that selectively searches thedocuments with the highest estimated relevance in an iterative fashion. Throughextensive experiments across a variety of dense retrieval models, we find thatLADR establishes a new dense retrieval effectiveness-efficiency Pareto frontieramong approximate k nearest neighbor techniques. Further, we find that whentuned to take around 8ms per query in retrieval latency on our hardware, LADRconsistently achieves both precision and recall that are on par with anexhaustive search on standard benchmarks.</description><author>Hrishikesh Kulkarni, Sean MacAvaney, Nazli Goharian, Ophir Frieder</author><pubDate>Mon, 31 Jul 2023 16:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16779v1</guid></item><item><title>KoBBQ: Korean Bias Benchmark for Question Answering</title><link>http://arxiv.org/abs/2307.16778v1</link><description>The BBQ (Bias Benchmark for Question Answering) dataset enables theevaluation of the social biases that language models (LMs) exhibit indownstream tasks. However, it is challenging to adapt BBQ to languages otherthan English as social biases are culturally dependent. In this paper, wedevise a process to construct a non-English bias benchmark dataset byleveraging the English BBQ dataset in a culturally adaptive way and present theKoBBQ dataset for evaluating biases in Question Answering (QA) tasks in Korean.We identify samples from BBQ into three classes: Simply-Translated (can be useddirectly after cultural translation), Target-Modified (requires localization intarget groups), and Sample-Removed (does not fit Korean culture). We furtherenhance the cultural relevance to Korean culture by adding four new categoriesof bias specific to Korean culture and newly creating samples based on Koreanliterature. KoBBQ consists of 246 templates and 4,740 samples across 12categories of social bias. Using KoBBQ, we measure the accuracy and bias scoresof several state-of-the-art multilingual LMs. We demonstrate the differences inthe bias of LMs in Korean and English, clarifying the need for hand-crafteddata considering cultural differences.</description><author>Jiho Jin, Jiseon Kim, Nayeon Lee, Haneul Yoo, Alice Oh, Hwaran Lee</author><pubDate>Mon, 31 Jul 2023 16:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16778v1</guid></item><item><title>AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder</title><link>http://arxiv.org/abs/2307.16773v1</link><description>To easily obtain the knowledge about autism spectrum disorder and help itsearly screening and diagnosis, we create AsdKB, a Chinese knowledge base onautism spectrum disorder. The knowledge base is built on top of varioussources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinicaldescriptions on mental and behavioural disorders, 2) the diagnostic knowledgefrom DSM-5 and different screening tools recommended by social organizationsand medical institutes, and 3) the expert knowledge on professional physiciansand hospitals from the Web. AsdKB contains both ontological and factualknowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. Thepotential applications of AsdKB are question answering, auxiliary diagnosis,and expert recommendation, and we illustrate them with a prototype which can beaccessed at http://asdkb.org.cn/.</description><author>Tianxing Wu, Xudong Cao, Yipeng Zhu, Feiyue Wu, Tianling Gong, Yuxiang Wang, Shenqi Jing</author><pubDate>Mon, 31 Jul 2023 16:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16773v1</guid></item><item><title>DeepVAT: A Self-Supervised Technique for Cluster Assessment in Image Datasets</title><link>http://arxiv.org/abs/2306.00011v2</link><description>Estimating the number of clusters and cluster structures in unlabeled,complex, and high-dimensional datasets (like images) is challenging fortraditional clustering algorithms. In recent years, a matrix reordering-basedalgorithm called Visual Assessment of Tendency (VAT), and its variants haveattracted many researchers from various domains to estimate the number ofclusters and inherent cluster structure present in the data. However, thesealgorithms face significant challenges when dealing with image data as theyfail to effectively capture the crucial features inherent in images. Toovercome these limitations, we propose a deep-learning-based framework thatenables the assessment of cluster structure in complex image datasets. Ourapproach utilizes a self-supervised deep neural network to generaterepresentative embeddings for the data. These embeddings are then reduced to2-dimension using t-distributed Stochastic Neighbour Embedding (t-SNE) andinputted into VAT based algorithms to estimate the underlying clusterstructure. Importantly, our framework does not rely on any prior knowledge ofthe number of clusters. Our proposed approach demonstrates superior performancecompared to state-of-the-art VAT family algorithms and two other deepclustering algorithms on four benchmark image datasets, namely MNIST, FMNIST,CIFAR-10, and INTEL.</description><author>Alokendu Mazumder, Tirthajit Baruah, Akash Kumar Singh, Pagadla Krishna Murthy, Vishwajeet Pattanaik, Punit Rathore</author><pubDate>Mon, 31 Jul 2023 16:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00011v2</guid></item><item><title>Lightweight Super-Resolution Head for Human Pose Estimation</title><link>http://arxiv.org/abs/2307.16765v1</link><description>Heatmap-based methods have become the mainstream method for pose estimationdue to their superior performance. However, heatmap-based approaches sufferfrom significant quantization errors with downscale heatmaps, which result inlimited performance and the detrimental effects of intermediate supervision.Previous heatmap-based methods relied heavily on additional post-processing tomitigate quantization errors. Some heatmap-based approaches improve theresolution of feature maps by using multiple costly upsampling layers toimprove localization precision. To solve the above issues, we creatively viewthe backbone network as a degradation process and thus reformulate the heatmapprediction as a Super-Resolution (SR) task. We first propose the SR head, whichpredicts heatmaps with a spatial resolution higher than the input feature maps(or even consistent with the input image) by super-resolution, to effectivelyreduce the quantization error and the dependence on further post-processing.Besides, we propose SRPose to gradually recover the HR heatmaps from LRheatmaps and degraded features in a coarse-to-fine manner. To reduce thetraining difficulty of HR heatmaps, SRPose applies SR heads to supervise theintermediate features in each stage. In addition, the SR head is a lightweightand generic head that applies to top-down and bottom-up methods. Extensiveexperiments on the COCO, MPII, and CrowdPose datasets show that SRPoseoutperforms the corresponding heatmap-based approaches. The code and models areavailable at https://github.com/haonanwang0522/SRPose.</description><author>Haonan Wang, Jie Liu, Jie Tang, Gangshan Wu</author><pubDate>Mon, 31 Jul 2023 16:35:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16765v1</guid></item><item><title>Approximating nonlinear functions with latent boundaries in low-rank excitatory-inhibitory spiking networks</title><link>http://arxiv.org/abs/2307.09334v2</link><description>Deep feedforward and recurrent rate-based neural networks have becomesuccessful functional models of the brain, but they neglect obvious biologicaldetails such as spikes and Dale's law. Here we argue that these details arecrucial in order to understand how real neural circuits operate. Towards thisaim, we put forth a new framework for spike-based computation in low-rankexcitatory-inhibitory spiking networks. By considering populations with rank-1connectivity, we cast each neuron's spiking threshold as a boundary in alow-dimensional input-output space. We then show how the combined thresholds ofa population of inhibitory neurons form a stable boundary in this space, andthose of a population of excitatory neurons form an unstable boundary.Combining the two boundaries results in a rank-2 excitatory-inhibitory (EI)network with inhibition-stabilized dynamics at the intersection of the twoboundaries. The computation of the resulting networks can be understood as thedifference of two convex functions, and is thereby capable of approximatingarbitrary non-linear input-output mappings. We demonstrate several propertiesof these networks, including noise suppression and amplification, irregularactivity and synaptic balance, as well as how they relate to rate networkdynamics in the limit that the boundary becomes soft. Finally, while our workfocuses on small networks (5-50 neurons), we discuss potential avenues forscaling up to much larger networks. Overall, our work proposes a newperspective on spiking networks that may serve as a starting point for amechanistic understanding of biological spike-based computation.</description><author>William F. Podlaski, Christian K. Machens</author><pubDate>Mon, 31 Jul 2023 16:34:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09334v2</guid></item><item><title>Phase Matching for Out-of-Distribution Generalization</title><link>http://arxiv.org/abs/2307.12622v2</link><description>The Fourier transform, serving as an explicit decomposition method for visualsignals, has been employed to explain the out-of-distribution generalizationbehaviors of Convolutional Neural Networks (CNNs). Previous studies haveindicated that the amplitude spectrum is susceptible to the disturbance causedby distribution shifts. On the other hand, the phase spectrum preserveshighly-structured spatial information, which is crucial for robust visualrepresentation learning. However, the spatial relationships of phase spectrumremain unexplored in previous researches. In this paper, we aim to clarify therelationships between Domain Generalization (DG) and the frequency components,and explore the spatial relationships of the phase spectrum. Specifically, wefirst introduce a Fourier-based structural causal model which interprets thephase spectrum as semi-causal factors and the amplitude spectrum as non-causalfactors. Then, we propose Phase Matching (PhaMa) to address DG problems. Ourmethod introduces perturbations on the amplitude spectrum and establishesspatial relationships to match the phase components. Through experiments onmultiple benchmarks, we demonstrate that our proposed method achievesstate-of-the-art performance in domain generalization and out-of-distributionrobustness tasks.</description><author>Chengming Hu, Yeqian Du, Rui Wang, Hao Chen</author><pubDate>Mon, 31 Jul 2023 16:31:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12622v2</guid></item><item><title>Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition</title><link>http://arxiv.org/abs/2304.07304v2</link><description>In recent years, self-supervised learning (SSL) frameworks have beenextensively applied to sensor-based Human Activity Recognition (HAR) in orderto learn deep representations without data annotations. While SSL frameworksreach performance almost comparable to supervised models, studies oninterpreting representations learnt by SSL models are limited. Nevertheless,modern explainability methods could help to unravel the differences between SSLand supervised representations: how they are being learnt, what properties ofinput data they preserve, and when SSL can be chosen over supervised training.In this paper, we aim to analyze deep representations of two recent SSLframeworks, namely SimCLR and VICReg. Specifically, the emphasis is made on (i)comparing the robustness of supervised and SSL models to corruptions in inputdata; (ii) explaining predictions of deep learning models using saliency mapsand highlighting what input channels are mostly used for predicting variousactivities; (iii) exploring properties encoded in SSL and supervisedrepresentations using probing. Extensive experiments on two single-devicedatasets (MobiAct and UCI-HAR) have shown that self-supervised learningrepresentations are significantly more robust to noise in unseen data comparedto supervised models. In contrast, features learnt by the supervised approachesare more homogeneous across subjects and better encode the nature ofactivities.</description><author>Bulat Khaertdinov, Stylianos Asteriadis</author><pubDate>Mon, 31 Jul 2023 16:23:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07304v2</guid></item><item><title>High-Performance Fine Defect Detection in Artificial Leather Using Dual Feature Pool Object Detection</title><link>http://arxiv.org/abs/2307.16751v1</link><description>In this study, the structural problems of the YOLOv5 model were analyzedemphatically. Based on the characteristics of fine defects in artificialleather, four innovative structures, namely DFP, IFF, AMP, and EOS, weredesigned. These advancements led to the proposal of a high-performanceartificial leather fine defect detection model named YOLOD. YOLOD demonstratedoutstanding performance on the artificial leather defect dataset, achieving animpressive increase of 11.7% - 13.5% in AP_50 compared to YOLOv5, along with asignificant reduction of 5.2% - 7.2% in the error detection rate. Moreover,YOLOD also exhibited remarkable performance on the general MS-COCO dataset,with an increase of 0.4% - 2.6% in AP compared to YOLOv5, and a rise of 2.5% -4.1% in AP_S compared to YOLOv5. These results demonstrate the superiority ofYOLOD in both artificial leather defect detection and general object detectiontasks, making it a highly efficient and effective model for real-worldapplications.</description><author>Lin Huang, Weisheng Li, Linlin Shen, Xue Xiao, Suihan Xiao</author><pubDate>Mon, 31 Jul 2023 16:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16751v1</guid></item><item><title>Last-Iterate Convergence of Saddle-Point Optimizers via High-Resolution Differential Equations</title><link>http://arxiv.org/abs/2112.13826v3</link><description>Several widely-used first-order saddle-point optimization methods yield anidentical continuous-time ordinary differential equation (ODE) that isidentical to that of the Gradient Descent Ascent (GDA) method when derivednaively. However, the convergence properties of these methods are qualitativelydifferent, even on simple bilinear games. Thus the ODE perspective, which hasproved powerful in analyzing single-objective optimization methods, has notplayed a similar role in saddle-point optimization. We adopt a framework studied in fluid dynamics -- known as High-ResolutionDifferential Equations (HRDEs) -- to design differential equation models forseveral saddle-point optimization methods. Critically, these HRDEs are distinctfor various saddle-point optimization methods. Moreover, in bilinear games, theconvergence properties of the HRDEs match the qualitative features of thecorresponding discrete methods. Additionally, we show that the HRDE ofOptimistic Gradient Descent Ascent (OGDA) exhibits \emph{last-iterateconvergence} for general monotone variational inequalities. Finally, we providerates of convergence for the \emph{best-iterate convergence} of the OGDAmethod, relying solely on the first-order smoothness of the monotone operator.</description><author>Tatjana Chavdarova, Michael I. Jordan, Manolis Zampetakis</author><pubDate>Mon, 31 Jul 2023 16:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.13826v3</guid></item><item><title>Advancing Smart Malnutrition Monitoring: A Multi-Modal Learning Approach for Vital Health Parameter Estimation</title><link>http://arxiv.org/abs/2307.16745v1</link><description>Malnutrition poses a significant threat to global health, resulting from aninadequate intake of essential nutrients that adversely impacts vital organsand overall bodily functioning. Periodic examinations and mass screenings,incorporating both conventional and non-invasive techniques, have been employedto combat this challenge. However, these approaches suffer from criticallimitations, such as the need for additional equipment, lack of comprehensivefeature representation, absence of suitable health indicators, and theunavailability of smartphone implementations for precise estimations of BodyFat Percentage (BFP), Basal Metabolic Rate (BMR), and Body Mass Index (BMI) toenable efficient smart-malnutrition monitoring. To address these constraints,this study presents a groundbreaking, scalable, and robust smartmalnutrition-monitoring system that leverages a single full-body image of anindividual to estimate height, weight, and other crucial health parameterswithin a multi-modal learning framework. Our proposed methodology involves thereconstruction of a highly precise 3D point cloud, from which 512-dimensionalfeature embeddings are extracted using a headless-3D classification network.Concurrently, facial and body embeddings are also extracted, and through theapplication of learnable parameters, these features are then utilized toestimate weight accurately. Furthermore, essential health metrics, includingBMR, BFP, and BMI, are computed to conduct a comprehensive analysis of thesubject's health, subsequently facilitating the provision of personalizednutrition plans. While being robust to a wide range of lighting conditionsacross multiple devices, our model achieves a low Mean Absolute Error (MAE) of$\pm$ 4.7 cm and $\pm$ 5.3 kg in estimating height and weight.</description><author>Ashish Marisetty, Prathistith Raj M, Praneeth Nemani, Venkanna Udutalapally, Debanjan Das</author><pubDate>Mon, 31 Jul 2023 16:08:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16745v1</guid></item><item><title>Multi-Spectral Image Stitching via Spatial Graph Reasoning</title><link>http://arxiv.org/abs/2307.16741v1</link><description>Multi-spectral image stitching leverages the complementarity between infraredand visible images to generate a robust and reliable wide field-of-view (FOV)scene. The primary challenge of this task is to explore the relations betweenmulti-spectral images for aligning and integrating multi-view scenes.Capitalizing on the strengths of Graph Convolutional Networks (GCNs) inmodeling feature relationships, we propose a spatial graph reasoning basedmulti-spectral image stitching method that effectively distills the deformationand integration of multi-spectral images across different viewpoints. Toaccomplish this, we embed multi-scale complementary features from the same viewposition into a set of nodes. The correspondence across different views islearned through powerful dense feature embeddings, where both inter- andintra-correlations are developed to exploit cross-view matching and enhanceinner feature disparity. By introducing long-range coherence along spatial andchannel dimensions, the complementarity of pixel relations and channelinterdependencies aids in the reconstruction of aligned multi-view features,generating informative and reliable wide FOV scenes. Moreover, we release achallenging dataset named ChaMS, comprising both real-world and synthetic setswith significant parallax, providing a new option for comprehensive evaluation.Extensive experiments demonstrate that our method surpasses thestate-of-the-arts.</description><author>Zhiying Jiang, Zengxi Zhang, Jinyuan Liu, Xin Fan, Risheng Liu</author><pubDate>Mon, 31 Jul 2023 16:04:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16741v1</guid></item><item><title>Blocked Cross-Validation: A Precise and Efficient Method for Hyperparameter Tuning</title><link>http://arxiv.org/abs/2306.06591v2</link><description>Hyperparameter tuning plays a crucial role in optimizing the performance ofpredictive learners. Cross--validation (CV) is a widely adopted technique forestimating the error of different hyperparameter settings. Repeatedcross-validation (RCV) has been commonly employed to reduce the variability ofCV errors. In this paper, we introduce a novel approach called blockedcross-validation (BCV), where the repetitions are blocked with respect to bothCV partition and the random behavior of the learner. Theoretical analysis andempirical experiments demonstrate that BCV provides more precise errorestimates compared to RCV, even with a significantly reduced number of runs. Wepresent extensive examples using real--world data sets to showcase theeffectiveness and efficiency of BCV in hyperparameter tuning. Our resultsindicate that BCV outperforms RCV in hyperparameter tuning, achieving greaterprecision with fewer computations.</description><author>Giovanni Maria Merola</author><pubDate>Mon, 31 Jul 2023 16:03:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06591v2</guid></item><item><title>Lossless Transformations and Excess Risk Bounds in Statistical Inference</title><link>http://arxiv.org/abs/2307.16735v1</link><description>We study the excess minimum risk in statistical inference, defined as thedifference between the minimum expected loss in estimating a random variablefrom an observed feature vector and the minimum expected loss in estimating thesame random variable from a transformation (statistic) of the feature vector.After characterizing lossless transformations, i.e., transformations for whichthe excess risk is zero for all loss functions, we construct a partitioningtest statistic for the hypothesis that a given transformation is lossless andshow that for i.i.d. data the test is strongly consistent. More generally, wedevelop information-theoretic upper bounds on the excess risk that uniformlyhold over fairly general classes of loss functions. Based on these bounds, weintroduce the notion of a delta-lossless transformation and give sufficientconditions for a given transformation to be universally delta-lossless.Applications to classification, nonparametric regression, portfolio strategies,information bottleneck, and deep learning, are also surveyed.</description><author>Lszl Gyrfi, Tams Linder, Harro Walk</author><pubDate>Mon, 31 Jul 2023 15:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16735v1</guid></item><item><title>Referential communication in heterogeneous communities of pre-trained visual deep networks</title><link>http://arxiv.org/abs/2302.08913v3</link><description>As large pre-trained image-processing neural networks are being embedded inautonomous agents such as self-driving cars or robots, the question arises ofhow such systems can communicate with each other about the surrounding world,despite their different architectures and training regimes. As a first step inthis direction, we systematically explore the task of \textit{referentialcommunication} in a community of heterogeneous state-of-the-art pre-trainedvisual networks, showing that they can develop, in a self-supervised way, ashared protocol to refer to a target object among a set of candidates. Thisshared protocol can also be used, to some extent, to communicate aboutpreviously unseen object categories of different granularity. Moreover, avisual network that was not initially part of an existing community can learnthe community's protocol with remarkable ease. Finally, we study, bothqualitatively and quantitatively, the properties of the emergent protocol,providing some evidence that it is capturing high-level semantic features ofobjects.</description><author>Mato Mahaut, Francesca Franzon, Roberto Dess, Marco Baroni</author><pubDate>Mon, 31 Jul 2023 15:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08913v3</guid></item><item><title>Hybrid quantum transfer learning for crack image classification on NISQ hardware</title><link>http://arxiv.org/abs/2307.16723v1</link><description>Quantum computers possess the potential to process data using a remarkablyreduced number of qubits compared to conventional bits, as per theoreticalfoundations. However, recent experiments have indicated that the practicalfeasibility of retrieving an image from its quantum encoded version iscurrently limited to very small image sizes. Despite this constraint,variational quantum machine learning algorithms can still be employed in thecurrent noisy intermediate scale quantum (NISQ) era. An example is a hybridquantum machine learning approach for edge detection. In our study, we presentan application of quantum transfer learning for detecting cracks in gray valueimages. We compare the performance and training time of PennyLane's standardqubits with IBM's qasm\_simulator and real backends, offering insights intotheir execution efficiency.</description><author>Alexander Geng, Ali Moghiseh, Claudia Redenbach, Katja Schladitz</author><pubDate>Mon, 31 Jul 2023 15:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16723v1</guid></item><item><title>One-Shot Federated Conformal Prediction</title><link>http://arxiv.org/abs/2302.06322v2</link><description>In this paper, we introduce a conformal prediction method to constructprediction sets in a oneshot federated learning setting. More specifically, wedefine a quantile-of-quantiles estimator and prove that for any distribution,it is possible to output prediction sets with desired coverage in only oneround of communication. To mitigate privacy issues, we also describe a locallydifferentially private version of our estimator. Finally, over a wide range ofexperiments, we show that our method returns prediction sets with coverage andlength very similar to those obtained in a centralized setting. Overall, theseresults demonstrate that our method is particularly well-suited to performconformal predictions in a one-shot federated learning setting.</description><author>Pierre Humbert, Batiste Le Bars, Aurlien Bellet, Sylvain Arlot</author><pubDate>Mon, 31 Jul 2023 15:45:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06322v2</guid></item><item><title>Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with Uncertainty</title><link>http://arxiv.org/abs/2305.02722v2</link><description>Knowledge distillation is an effective paradigm for boosting the performanceof pocket-size model, especially when multiple teacher models are available,the student would break the upper limit again. However, it is not economical totrain diverse teacher models for the disposable distillation. In this paper, weintroduce a new concept dubbed Avatars for distillation, which are theinference ensemble models derived from the teacher. Concretely, (1) For eachiteration of distillation training, various Avatars are generated by aperturbation transformation. We validate that Avatars own higher upper limit ofworking capacity and teaching ability, aiding the student model in learningdiverse and receptive knowledge perspectives from the teacher model. (2) Duringthe distillation, we propose an uncertainty-aware factor from the variance ofstatistical differences between the vanilla teacher and Avatars, to adjustAvatars' contribution on knowledge transfer adaptively. Avatar KnowledgeDistillation AKD is fundamentally different from existing methods and refineswith the innovative view of unequal training. Comprehensive experimentsdemonstrate the effectiveness of our Avatars mechanism, which polishes up thestate-of-the-art distillation methods for dense prediction without more extracomputational cost. The AKD brings at most 0.7 AP gains on COCO 2017 for ObjectDetection and 1.83 mIoU gains on Cityscapes for Semantic Segmentation,respectively.</description><author>Yuan Zhang, Weihua Chen, Yichen Lu, Tao Huang, Xiuyu Sun, Jian Cao</author><pubDate>Mon, 31 Jul 2023 15:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02722v2</guid></item><item><title>What does a platypus look like? Generating customized prompts for zero-shot image classification</title><link>http://arxiv.org/abs/2209.03320v2</link><description>Open-vocabulary models are a promising new paradigm for image classification.Unlike traditional classification models, open-vocabulary models classify amongany arbitrary set of categories specified with natural language duringinference. This natural language, called "prompts", typically consists of a setof hand-written templates (e.g., "a photo of a {}") which are completed witheach of the category names. This work introduces a simple method to generatehigher accuracy prompts, without relying on any explicit knowledge of the taskdomain and with far fewer hand-constructed sentences. To achieve this, wecombine open-vocabulary models with large language models (LLMs) to createCustomized Prompts via Language models (CuPL, pronounced "couple"). Inparticular, we leverage the knowledge contained in LLMs in order to generatemany descriptive sentences that contain important discriminatingcharacteristics of the image categories. This allows the model to place agreater importance on these regions in the image when making predictions. Wefind that this straightforward and general approach improves accuracy on arange of zero-shot image classification benchmarks, including over onepercentage point gain on ImageNet. Finally, this simple baseline requires noadditional training and remains completely zero-shot. Code available athttps://github.com/sarahpratt/CuPL.</description><author>Sarah Pratt, Ian Covert, Rosanne Liu, Ali Farhadi</author><pubDate>Mon, 31 Jul 2023 15:39:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.03320v2</guid></item><item><title>An Efficient Shapley Value Computation for the Naive Bayes Classifier</title><link>http://arxiv.org/abs/2307.16718v1</link><description>Variable selection or importance measurement of input variables to a machinelearning model has become the focus of much research. It is no longer enough tohave a good model, one also must explain its decisions. This is why there areso many intelligibility algorithms available today. Among them, Shapley valueestimation algorithms are intelligibility methods based on cooperative gametheory. In the case of the naive Bayes classifier, and to our knowledge, thereis no ``analytical" formulation of Shapley values. This article proposes anexact analytic expression of Shapley values in the special case of the naiveBayes Classifier. We analytically compare this Shapley proposal, to anotherfrequently used indicator, the Weight of Evidence (WoE) and provide anempirical comparison of our proposal with (i) the WoE and (ii) KernelShapresults on real world datasets, discussing similar and dissimilar results. Theresults show that our Shapley proposal for the naive Bayes classifier providesinformative results with low algorithmic complexity so that it can be used onvery large datasets with extremely low computation time.</description><author>Vincent Lemaire, Fabrice Clrot, Marc Boull</author><pubDate>Mon, 31 Jul 2023 15:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16718v1</guid></item><item><title>UniVTG: Towards Unified Video-Language Temporal Grounding</title><link>http://arxiv.org/abs/2307.16715v1</link><description>Video Temporal Grounding (VTG), which aims to ground target clips from videos(such as consecutive intervals or disjoint shots) according to custom languagequeries (e.g., sentences or words), is key for video browsing on social media.Most methods in this direction develop taskspecific models that are trainedwith type-specific labels, such as moment retrieval (time interval) andhighlight detection (worthiness curve), which limits their abilities togeneralize to various VTG tasks and labels. In this paper, we propose to Unifythe diverse VTG labels and tasks, dubbed UniVTG, along three directions:Firstly, we revisit a wide range of VTG labels and tasks and define a unifiedformulation. Based on this, we develop data annotation schemes to createscalable pseudo supervision. Secondly, we develop an effective and flexiblegrounding model capable of addressing each task and making full use of eachlabel. Lastly, thanks to the unified framework, we are able to unlock temporalgrounding pretraining from large-scale diverse labels and develop strongergrounding abilities e.g., zero-shot grounding. Extensive experiments on threetasks (moment retrieval, highlight detection and video summarization) acrossseven datasets (QVHighlights, Charades-STA, TACoS, Ego4D, YouTube Highlights,TVSum, and QFVS) demonstrate the effectiveness and flexibility of our proposedframework. The codes are available at https://github.com/showlab/UniVTG.</description><author>Kevin Qinghong Lin, Pengchuan Zhang, Joya Chen, Shraman Pramanick, Difei Gao, Alex Jinpeng Wang, Rui Yan, Mike Zheng Shou</author><pubDate>Mon, 31 Jul 2023 15:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16715v1</guid></item><item><title>An Empirical Study on Log-based Anomaly Detection Using Machine Learning</title><link>http://arxiv.org/abs/2307.16714v1</link><description>The growth of systems complexity increases the need of automated techniquesdedicated to different log analysis tasks such as Log-based Anomaly Detection(LAD). The latter has been widely addressed in the literature, mostly by meansof different deep learning techniques. Nevertheless, the focus on deep learningtechniques results in less attention being paid to traditional Machine Learning(ML) techniques, which may perform well in many cases, depending on the contextand the used datasets. Further, the evaluation of different ML techniques ismostly based on the assessment of their detection accuracy. However, this is isnot enough to decide whether or not a specific ML technique is suitable toaddress the LAD problem. Other aspects to consider include the training andprediction time as well as the sensitivity to hyperparameter tuning. In thispaper, we present a comprehensive empirical study, in which we evaluatedifferent supervised and semi-supervised, traditional and deep ML techniquesw.r.t. four evaluation criteria: detection accuracy, time performance,sensitivity of detection accuracy as well as time performance to hyperparametertuning. The experimental results show that supervised traditional and deep MLtechniques perform very closely in terms of their detection accuracy andprediction time. Moreover, the overall evaluation of the sensitivity of thedetection accuracy of the different ML techniques to hyperparameter tuningshows that supervised traditional ML techniques are less sensitive tohyperparameter tuning than deep learning techniques. Further, semi-supervisedtechniques yield significantly worse detection accuracy than supervisedtechniques.</description><author>Shan Ali, Chaima Boufaied, Domenico Bianculli, Paula Branco, Lionel Briand, Nathan Aschbacher</author><pubDate>Mon, 31 Jul 2023 15:34:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16714v1</guid></item><item><title>TFE-GNN: A Temporal Fusion Encoder Using Graph Neural Networks for Fine-grained Encrypted Traffic Classification</title><link>http://arxiv.org/abs/2307.16713v1</link><description>Encrypted traffic classification is receiving widespread attention fromresearchers and industrial companies. However, the existing methods onlyextract flow-level features, failing to handle short flows because ofunreliable statistical properties, or treat the header and payload equally,failing to mine the potential correlation between bytes. Therefore, in thispaper, we propose a byte-level traffic graph construction approach based onpoint-wise mutual information (PMI), and a model named Temporal Fusion Encoderusing Graph Neural Networks (TFE-GNN) for feature extraction. In particular, wedesign a dual embedding layer, a GNN-based traffic graph encoder as well as across-gated feature fusion mechanism, which can first embed the header andpayload bytes separately and then fuses them together to obtain a strongerfeature representation. The experimental results on two real datasetsdemonstrate that TFE-GNN outperforms multiple state-of-the-art methods infine-grained encrypted traffic classification tasks.</description><author>Haozhen Zhang, Le Yu, Xi Xiao, Qing Li, Francesco Mercaldo, Xiapu Luo, Qixu Liu</author><pubDate>Mon, 31 Jul 2023 15:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16713v1</guid></item><item><title>Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Frchet mean with the shape invariant model}</title><link>http://arxiv.org/abs/2010.02968v3</link><description>A modelling framework suitable for detecting shape shifts in functionalprofiles combining the notion of Fr\'echet mean and the concept of deformationmodels is developed and proposed. The generalized mean sense offerred by theFr\'echet mean notion is employed to capture the typical pattern of theprofiles under study, while the concept of deformation models, and inparticular of the shape invariant model, allows for interpretableparameterizations of profile's deviations from the typical shape. EWMA-typecontrol charts compatible with the functional nature of data and the employeddeformation model are built and proposed, exploiting certain shapecharacteristics of the profiles under study with respect to the generalisedmean sense, allowing for the identification of potential shifts concerning theshape and/or the deformation process. Potential shifts in the shape deformationprocess, are further distingu\-ished to significant shifts with respect toamplitude and/or the phase of the profile under study. The proposed modellingand shift detection framework is implemented to a real world case study, wheredaily concentration profiles concerning air pollutants from an area in the cityof Athens are modelled, while profiles indicating hazardous concentrationlevels are successfully identified in most of the cases.</description><author>Georgios I. Papayiannis, Stelios Psarakis, Athanasios N. Yannacopoulos</author><pubDate>Mon, 31 Jul 2023 15:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2010.02968v3</guid></item><item><title>Multilingual context-based pronunciation learning for Text-to-Speech</title><link>http://arxiv.org/abs/2307.16709v1</link><description>Phonetic information and linguistic knowledge are an essential component of aText-to-speech (TTS) front-end. Given a language, a lexicon can be collectedoffline and Grapheme-to-Phoneme (G2P) relationships are usually modeled inorder to predict the pronunciation for out-of-vocabulary (OOV) words.Additionally, post-lexical phonology, often defined in the form of rule-basedsystems, is used to correct pronunciation within or between words. In this workwe showcase a multilingual unified front-end system that addresses anypronunciation related task, typically handled by separate modules. We evaluatethe proposed model on G2P conversion and other language-specific challenges,such as homograph and polyphones disambiguation, post-lexical rules andimplicit diacritization. We find that the multilingual model is competitiveacross languages and tasks, however, some trade-offs exists when compared toequivalent monolingual solutions.</description><author>Giulia Comini, Manuel Sam Ribeiro, Fan Yang, Heereen Shim, Jaime Lorenzo-Trueba</author><pubDate>Mon, 31 Jul 2023 15:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16709v1</guid></item><item><title>Deep Learning Meets Adaptive Filtering: A Stein's Unbiased Risk Estimator Approach</title><link>http://arxiv.org/abs/2307.16708v1</link><description>This paper revisits two prominent adaptive filtering algorithms through thelens of algorithm unrolling, namely recursive least squares (RLS) andequivariant adaptive source separation (EASI), in the context of sourceestimation and separation. Building upon the unrolling methodology, weintroduce novel task-based deep learning frameworks, denoted as Deep RLS andDeep EASI. These architectures transform the iterations of the originalalgorithms into layers of a deep neural network, thereby enabling efficientsource signal estimation by taking advantage of a training process. To furtherenhance performance, we propose training these deep unrolled networks utilizinga loss function grounded on a Stein's unbiased risk estimator (SURE). Ourempirical evaluations demonstrate the efficacy of this SURE-based approach forenhanced source signal estimation.</description><author>Zahra Esmaeilbeig, Mojtaba Soltanalian</author><pubDate>Mon, 31 Jul 2023 15:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16708v1</guid></item><item><title>Distributed Dynamic Programming forNetworked Multi-Agent Markov Decision Processes</title><link>http://arxiv.org/abs/2307.16706v1</link><description>The main goal of this paper is to investigate distributed dynamic programming(DP) to solve networked multi-agent Markov decision problems (MDPs). Weconsider a distributed multi-agent case, where each agent does not have anaccess to the rewards of other agents except for its own reward. Moreover, eachagent can share their parameters with its neighbors over a communicationnetwork represented by a graph. We propose a distributed DP in thecontinuous-time domain, and prove its convergence through control theoreticviewpoints. The proposed analysis can be viewed as a preliminary ordinarydifferential equation (ODE) analysis of a distributed temporal differencelearning algorithm, whose convergence can be proved using Borkar-Meyn theoremand the single time-scale approach.</description><author>Okyong Choi, Donghwan Lee</author><pubDate>Mon, 31 Jul 2023 15:25:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16706v1</guid></item><item><title>Lookbehind Optimizer: k steps back, 1 step forward</title><link>http://arxiv.org/abs/2307.16704v1</link><description>The Lookahead optimizer improves the training stability of deep neuralnetworks by having a set of fast weights that "look ahead" to guide the descentdirection. Here, we combine this idea with sharpness-aware minimization (SAM)to stabilize its multi-step variant and improve the loss-sharpness trade-off.We propose Lookbehind, which computes $k$ gradient ascent steps ("lookingbehind") at each iteration and combine the gradients to bias the descent steptoward flatter minima. We apply Lookbehind on top of two popularsharpness-aware training methods -- SAM and adaptive SAM (ASAM) -- and showthat our approach leads to a myriad of benefits across a variety of tasks andtraining regimes. Particularly, we show increased generalization performance,greater robustness against noisy weights, and higher tolerance to catastrophicforgetting in lifelong learning settings.</description><author>Gonalo Mordido, Pranshu Malviya, Aristide Baratin, Sarath Chandar</author><pubDate>Mon, 31 Jul 2023 15:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16704v1</guid></item><item><title>Differentiable Transportation Pruning</title><link>http://arxiv.org/abs/2307.08483v2</link><description>Deep learning algorithms are increasingly employed at the edge. However, edgedevices are resource constrained and thus require efficient deployment of deepneural networks. Pruning methods are a key tool for edge deployment as they canimprove storage, compute, memory bandwidth, and energy usage. In this paper wepropose a novel accurate pruning technique that allows precise control over theoutput network size. Our method uses an efficient optimal transportation schemewhich we make end-to-end differentiable and which automatically tunes theexploration-exploitation behavior of the algorithm to find accurate sparsesub-networks. We show that our method achieves state-of-the-art performancecompared to previous pruning methods on 3 different datasets, using 5 differentmodels, across a wide range of pruning ratios, and with two types of sparsitybudgets and pruning granularities.</description><author>Yunqiang Li, Jan C. van Gemert, Torsten Hoefler, Bert Moons, Evangelos Eleftheriou, Bram-Ernst Verhoef</author><pubDate>Mon, 31 Jul 2023 15:20:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08483v2</guid></item><item><title>Ontology engineering with Large Language Models</title><link>http://arxiv.org/abs/2307.16699v1</link><description>We tackle the task of enriching ontologies by automatically translatingnatural language sentences into Description Logic. Since Large Language Models(LLMs) are the best tools for translations, we fine-tuned a GPT-3 model toconvert Natural Language sentences into OWL Functional Syntax. We employobjective and concise examples to fine-tune the model regarding: instances,class subsumption, domain and range of relations, object propertiesrelationships, disjoint classes, complements, cardinality restrictions. Theresulted axioms are used to enrich an ontology, in a human supervised manner.The developed tool is publicly provided as a Protge plugin.</description><author>Patricia Mateiu, Adrian Groza</author><pubDate>Mon, 31 Jul 2023 15:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16699v1</guid></item><item><title>ICICLE: Interpretable Class Incremental Continual Learning</title><link>http://arxiv.org/abs/2303.07811v2</link><description>Continual learning enables incremental learning of new tasks withoutforgetting those previously learned, resulting in positive knowledge transferthat can enhance performance on both new and old tasks. However, continuallearning poses new challenges for interpretability, as the rationale behindmodel predictions may change over time, leading to interpretability conceptdrift. We address this problem by proposing Interpretable Class-InCrementalLEarning (ICICLE), an exemplar-free approach that adopts a prototypicalpart-based approach. It consists of three crucial novelties: interpretabilityregularization that distills previously learned concepts while preservinguser-friendly positive reasoning; proximity-based prototype initializationstrategy dedicated to the fine-grained setting; and task-recency biascompensation devoted to prototypical parts. Our experimental resultsdemonstrate that ICICLE reduces the interpretability concept drift andoutperforms the existing exemplar-free methods of common class-incrementallearning when applied to concept-based models.</description><author>Dawid Rymarczyk, Joost van de Weijer, Bartosz Zieliski, Bartomiej Twardowski</author><pubDate>Mon, 31 Jul 2023 15:15:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07811v2</guid></item><item><title>A theory of data variability in Neural Network Bayesian inference</title><link>http://arxiv.org/abs/2307.16695v1</link><description>Bayesian inference and kernel methods are well established in machinelearning. The neural network Gaussian process in particular provides a conceptto investigate neural networks in the limit of infinitely wide hidden layers byusing kernel and inference methods. Here we build upon this limit and provide afield-theoretic formalism which covers the generalization properties ofinfinitely wide networks. We systematically compute generalization propertiesof linear, non-linear, and deep non-linear networks for kernel matrices withheterogeneous entries. In contrast to currently employed spectral methods wederive the generalization properties from the statistical properties of theinput, elucidating the interplay of input dimensionality, size of the trainingdata set, and variability of the data. We show that data variability leads to anon-Gaussian action reminiscent of a ($\varphi^3+\varphi^4$)-theory. Using ourformalism on a synthetic task and on MNIST we obtain a homogeneous kernelmatrix approximation for the learning curve as well as corrections due to datavariability which allow the estimation of the generalization properties andexact results for the bounds of the learning curves in the case of infinitelymany training data points.</description><author>Javed Lindner, David Dahmen, Michael Krmer, Moritz Helias</author><pubDate>Mon, 31 Jul 2023 15:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16695v1</guid></item><item><title>Investigating and Improving Latent Density Segmentation Models for Aleatoric Uncertainty Quantification in Medical Imaging</title><link>http://arxiv.org/abs/2307.16694v1</link><description>Data uncertainties, such as sensor noise or occlusions, can introduceirreducible ambiguities in images, which result in varying, yet plausible,semantic hypotheses. In Machine Learning, this ambiguity is commonly referredto as aleatoric uncertainty. Latent density models can be utilized to addressthis problem in image segmentation. The most popular approach is theProbabilistic U-Net (PU-Net), which uses latent Normal densities to optimizethe conditional data log-likelihood Evidence Lower Bound. In this work, wedemonstrate that the PU- Net latent space is severely inhomogenous. As aresult, the effectiveness of gradient descent is inhibited and the modelbecomes extremely sensitive to the localization of the latent space samples,resulting in defective predictions. To address this, we present the SinkhornPU-Net (SPU-Net), which uses the Sinkhorn Divergence to promote homogeneityacross all latent dimensions, effectively improving gradient-descent updatesand model robustness. Our results show that by applying this on public datasetsof various clinical segmentation problems, the SPU-Net receives up to 11%performance gains compared against preceding latent variable models forprobabilistic segmentation on the Hungarian-Matched metric. The resultsindicate that by encouraging a homogeneous latent space, one can significantlyimprove latent density modeling for medical image segmentation.</description><author>M. M. Amaan Valiuddin, Christiaan G. A. Viviers, Ruud J. G. van Sloun, Peter H. N. de With, Fons van der Sommen</author><pubDate>Mon, 31 Jul 2023 15:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16694v1</guid></item><item><title>Generative Multi-Label Zero-Shot Learning</title><link>http://arxiv.org/abs/2101.11606v3</link><description>Multi-label zero-shot learning strives to classify images into multipleunseen categories for which no data is available during training. The testsamples can additionally contain seen categories in the generalized variant.Existing approaches rely on learning either shared or label-specific attentionfrom the seen classes. Nevertheless, computing reliable attention maps forunseen classes during inference in a multi-label setting is still a challenge.In contrast, state-of-the-art single-label generative adversarial network (GAN)based approaches learn to directly synthesize the class-specific visualfeatures from the corresponding class attribute embeddings. However,synthesizing multi-label features from GANs is still unexplored in the contextof zero-shot setting. In this work, we introduce different fusion approaches atthe attribute-level, feature-level and cross-level (across attribute andfeature-levels) for synthesizing multi-label features from their correspondingmulti-label class embedding. To the best of our knowledge, our work is thefirst to tackle the problem of multi-label feature synthesis in the(generalized) zero-shot setting. Comprehensive experiments are performed onthree zero-shot image classification benchmarks: NUS-WIDE, Open Images and MSCOCO. Our cross-level fusion-based generative approach outperforms thestate-of-the-art on all three datasets. Furthermore, we show the generalizationcapabilities of our fusion approach in the zero-shot detection task on MS COCO,achieving favorable performance against existing methods. The source code isavailable at https://github.com/akshitac8/Generative_MLZSL.</description><author>Akshita Gupta, Sanath Narayan, Salman Khan, Fahad Shahbaz Khan, Ling Shao, Joost van de Weijer</author><pubDate>Mon, 31 Jul 2023 15:08:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2101.11606v3</guid></item><item><title>No that's not what I meant: Handling Third Position Repair in Conversational Question Answering</title><link>http://arxiv.org/abs/2307.16689v1</link><description>The ability to handle miscommunication is crucial to robust and faithfulconversational AI. People usually deal with miscommunication immediately asthey detect it, using highly systematic interactional mechanisms called repair.One important type of repair is Third Position Repair (TPR) whereby a speakeris initially misunderstood but then corrects the misunderstanding as it becomesapparent after the addressee's erroneous response. Here, we collect andpublicly release Repair-QA, the first large dataset of TPRs in a conversationalquestion answering (QA) setting. The data is comprised of the TPR turns,corresponding dialogue contexts, and candidate repairs of the original turn forexecution of TPRs. We demonstrate the usefulness of the data by training andevaluating strong baseline models for executing TPRs. For stand-alone TPRexecution, we perform both automatic and human evaluations on a fine-tuned T5model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluatethe LLMs' TPR processing capabilities in the downstream conversational QA task.The results indicate poor out-of-the-box performance on TPR's by the GPT-3models, which then significantly improves when exposed to Repair-QA.</description><author>Vevake Balaraman, Arash Eshghi, Ioannis Konstas, Ioannis Papaioannou</author><pubDate>Mon, 31 Jul 2023 15:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16689v1</guid></item><item><title>DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation</title><link>http://arxiv.org/abs/2307.16687v1</link><description>Denoising diffusion probabilistic models that were initially proposed forrealistic image generation have recently shown success in various perceptiontasks (e.g., object detection and image segmentation) and are increasinglygaining attention in computer vision. However, extending such models tomulti-frame human pose estimation is non-trivial due to the presence of theadditional temporal dimension in videos. More importantly, learningrepresentations that focus on keypoint regions is crucial for accuratelocalization of human joints. Nevertheless, the adaptation of thediffusion-based methods remains unclear on how to achieve such objective. Inthis paper, we present DiffPose, a novel diffusion architecture that formulatesvideo-based human pose estimation as a conditional heatmap generation problem.First, to better leverage temporal information, we propose SpatioTemporalRepresentation Learner which aggregates visual evidences across frames and usesthe resulting features in each denoising step as a condition. In addition, wepresent a mechanism called Lookup-based MultiScale Feature Interaction thatdetermines the correlations between local joints and global contexts acrossmultiple scales. This mechanism generates delicate representations that focuson keypoint regions. Altogether, by extending diffusion models, we show twounique characteristics from DiffPose on pose estimation task: (i) the abilityto combine multiple sets of pose estimates to improve prediction accuracy,particularly for challenging joints, and (ii) the ability to adjust the numberof iterative steps for feature refinement without retraining the model.DiffPose sets new state-of-the-art results on three benchmarks: PoseTrack2017,PoseTrack2018, and PoseTrack21.</description><author>Runyang Feng, Yixing Gao, Tze Ho Elden Tse, Xueqing Ma, Hyung Jin Chang</author><pubDate>Mon, 31 Jul 2023 15:00:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16687v1</guid></item><item><title>Guiding Image Captioning Models Toward More Specific Captions</title><link>http://arxiv.org/abs/2307.16686v1</link><description>Image captioning is conventionally formulated as the task of generatingcaptions for images that match the distribution of reference image-captionpairs. However, reference captions in standard captioning datasets are shortand may not uniquely identify the images they describe. These problems arefurther exacerbated when models are trained directly on image-alt text pairscollected from the internet. In this work, we show that it is possible togenerate more specific captions with minimal changes to the training process.We implement classifier-free guidance for an autoregressive captioning model byfine-tuning it to estimate both conditional and unconditional distributionsover captions. The guidance scale applied at decoding controls a trade-offbetween maximizing $p(\mathrm{caption}|\mathrm{image})$ and$p(\mathrm{image}|\mathrm{caption})$. Compared to standard greedy decoding,decoding with a guidance scale of 2 substantially improves reference-freemetrics such as CLIPScore (0.808 vs. 0.775) and caption$\to$image retrievalperformance in the CLIP embedding space (recall@1 44.6% vs. 26.5%), but worsensstandard reference-based captioning metrics (e.g., CIDEr 78.6 vs 126.1). Wefurther explore the use of language models to guide the decoding process,obtaining small improvements over the Pareto frontier of reference-free vs.reference-based captioning metrics that arises from classifier-free guidance,and substantially improving the quality of captions generated from a modeltrained only on minimally curated web data.</description><author>Simon Kornblith, Lala Li, Zirui Wang, Thao Nguyen</author><pubDate>Mon, 31 Jul 2023 15:00:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16686v1</guid></item><item><title>Anticipating Responsibility in Multiagent Planning</title><link>http://arxiv.org/abs/2307.16685v1</link><description>Responsibility anticipation is the process of determining if the actions ofan individual agent may cause it to be responsible for a particular outcome.This can be used in a multi-agent planning setting to allow agents toanticipate responsibility in the plans they consider. The planning setting inthis paper includes partial information regarding the initial state andconsiders formulas in linear temporal logic as positive or negative outcomes tobe attained or avoided. We firstly define attribution for notions of active,passive and contributive responsibility, and consider their agentive variants.We then use these to define the notion of responsibility anticipation. We provethat our notions of anticipated responsibility can be used to coordinate agentsin a planning setting and give complexity results for our model, discussingequivalence with classical planning. We also present an outline for solvingsome of our attribution and anticipation problems using PDDL solvers.</description><author>Timothy Parker, Umberto Grandi, Emiliano Lorini</author><pubDate>Mon, 31 Jul 2023 14:58:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16685v1</guid></item><item><title>Identifying Pauli spin blockade using deep learning</title><link>http://arxiv.org/abs/2202.00574v3</link><description>Pauli spin blockade (PSB) can be employed as a great resource for spin qubitinitialisation and readout even at elevated temperatures but it can bedifficult to identify. We present a machine learning algorithm capable ofautomatically identifying PSB using charge transport measurements. The scarcityof PSB data is circumvented by training the algorithm with simulated data andby using cross-device validation. We demonstrate our approach on a siliconfield-effect transistor device and report an accuracy of 96% on different testdevices, giving evidence that the approach is robust to device variability. Theapproach is expected to be employable across all types of quantum dot devices.</description><author>Jonas Schuff, Dominic T. Lennon, Simon Geyer, David L. Craig, Federico Fedele, Florian Vigneau, Leon C. Camenzind, Andreas V. Kuhlmann, G. Andrew D. Briggs, Dominik M. Zumbhl, Dino Sejdinovic, Natalia Ares</author><pubDate>Mon, 31 Jul 2023 14:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.00574v3</guid></item><item><title>On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2307.16680v1</link><description>Diffusion models and large language models have emerged as leading-edgegenerative models and have sparked a revolutionary impact on various aspects ofhuman life. However, the practical implementation of these models has alsoexposed inherent risks, highlighting their dual nature and raising concernsregarding their trustworthiness. Despite the abundance of literature on thissubject, a comprehensive survey specifically delving into the intersection oflarge-scale generative models and their trustworthiness remains largely absent.To bridge this gap, This paper investigates both the long-standing and emergingthreats associated with these models across four fundamental dimensions:privacy, security, fairness, and responsibility. In this way, we construct anextensive map outlining the trustworthiness of these models, while alsoproviding practical recommendations and identifying future directions. Theseefforts are crucial for promoting the trustworthy deployment of these models,ultimately benefiting society as a whole.</description><author>Mingyuan Fan, Cen Chen, Chengyu Wang, Jun Huang</author><pubDate>Mon, 31 Jul 2023 14:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16680v1</guid></item><item><title>Comparing normalizing flows and diffusion models for prosody and acoustic modelling in text-to-speech</title><link>http://arxiv.org/abs/2307.16679v1</link><description>Neural text-to-speech systems are often optimized on L1/L2 losses, which makestrong assumptions about the distributions of the target data space. Aiming toimprove those assumptions, Normalizing Flows and Diffusion Probabilistic Modelswere recently proposed as alternatives. In this paper, we compare traditionalL1/L2-based approaches to diffusion and flow-based approaches for the tasks ofprosody and mel-spectrogram prediction for text-to-speech synthesis. We use aprosody model to generate log-f0 and duration features, which are used tocondition an acoustic model that generates mel-spectrograms. Experimentalresults demonstrate that the flow-based model achieves the best performance forspectrogram prediction, improving over equivalent diffusion and L1 models.Meanwhile, both diffusion and flow-based prosody predictors result insignificant improvements over a typical L2-trained prosody models.</description><author>Guangyan Zhang, Thomas Merritt, Manuel Sam Ribeiro, Biel Tura-Vecino, Kayoko Yanagisawa, Kamil Pokora, Abdelhamid Ezzerg, Sebastian Cygert, Ammar Abbas, Piotr Bilinski, Roberto Barra-Chicote, Daniel Korzekwa, Jaime Lorenzo-Trueba</author><pubDate>Mon, 31 Jul 2023 14:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16679v1</guid></item><item><title>Isotropic Representation Can Improve Dense Retrieval</title><link>http://arxiv.org/abs/2209.00218v2</link><description>The recent advancement in language representation modeling has broadlyaffected the design of dense retrieval models. In particular, many of thehigh-performing dense retrieval models evaluate representations of query anddocument using BERT, and subsequently apply a cosine-similarity based scoringto determine the relevance. BERT representations, however, are known to followan anisotropic distribution of a narrow cone shape and such an anisotropicdistribution can be undesirable for the cosine-similarity based scoring. Inthis work, we first show that BERT-based DR also follows an anisotropicdistribution. To cope with the problem, we introduce unsupervisedpost-processing methods of Normalizing Flow and whitening, and developtoken-wise method in addition to the sequence-wise method for applying thepost-processing methods to the representations of dense retrieval models. Weshow that the proposed methods can effectively enhance the representations tobe isotropic, then we perform experiments with ColBERT and RepBERT to show thatthe performance (NDCG at 10) of document re-ranking can be improved by5.17\%$\sim$8.09\% for ColBERT and 6.88\%$\sim$22.81\% for RepBERT. To examinethe potential of isotropic representation for improving the robustness of DRmodels, we investigate out-of-distribution tasks where the test dataset differsfrom the training dataset. The results show that isotropic representation canachieve a generally improved performance. For instance, when training datasetis MS-MARCO and test dataset is Robust04, isotropy post-processing can improvethe baseline performance by up to 24.98\%. Furthermore, we show that anisotropic model trained with an out-of-distribution dataset can even outperforma baseline model trained with the in-distribution dataset.</description><author>Euna Jung, Jungwon Park, Jaekeol Choi, Sungyoon Kim, Wonjong Rhee</author><pubDate>Mon, 31 Jul 2023 14:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.00218v2</guid></item><item><title>End-to-End Reinforcement Learning for Torque Based Variable Height Hopping</title><link>http://arxiv.org/abs/2307.16676v1</link><description>Legged locomotion is arguably the most suited and versatile mode to deal withnatural or unstructured terrains. Intensive research into dynamic walking andrunning controllers has recently yielded great advances, both in the optimalcontrol and reinforcement learning (RL) literature. Hopping is a challengingdynamic task involving a flight phase and has the potential to increase thetraversability of legged robots. Model based control for hopping typicallyrelies on accurate detection of different jump phases, such as lift-off ortouch down, and using different controllers for each phase. In this paper, wepresent a end-to-end RL based torque controller that learns to implicitlydetect the relevant jump phases, removing the need to provide manual heuristicsfor state detection. We also extend a method for simulation to reality transferof the learned controller to contact rich dynamic tasks, resulting insuccessful deployment on the robot after training without parameter tuning.</description><author>Raghav Soni, Daniel Harnack, Hauke Isermann, Sotaro Fushimi, Shivesh Kumar, Frank Kirchner</author><pubDate>Mon, 31 Jul 2023 14:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16676v1</guid></item><item><title>Scoring Cycling Environments Perceived Safety using Pairwise Image Comparisons</title><link>http://arxiv.org/abs/2307.13397v2</link><description>Today, many cities seek to transition to more sustainable transportationsystems. Cycling is critical in this transition for shorter trips, includingfirst-and-last-mile links to transit. Yet, if individuals perceive cycling asunsafe, they will not cycle and choose other transportation modes. This studypresents a novel approach to identifying how the perception of cycling safetycan be analyzed and understood and the impact of the built environment andcycling contexts on such perceptions. We base our work on other perceptionstudies and pairwise comparisons, using real-world images to surveyrespondents. We repeatedly show respondents two road environments and ask themto select the one they perceive as safer for cycling. We compare severalmethods capable of rating cycling environments from pairwise comparisons andclassify cycling environments perceived as safe or unsafe. Urban planning canuse this score to improve interventions' effectiveness and improve cyclingpromotion campaigns. Furthermore, this approach facilitates the continuousassessment of changing cycling environments, allows for a short-term evaluationof measures, and is efficiently deployed in different locations or contexts.</description><author>Miguel Costa, Manuel Marques, Felix Wilhelm Siebert, Carlos Lima Azevedo, Filipe Moura</author><pubDate>Mon, 31 Jul 2023 14:50:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13397v2</guid></item><item><title>Conditioning Generative Latent Optimization to solve Imaging Inverse Problems</title><link>http://arxiv.org/abs/2307.16670v1</link><description>Computed Tomography (CT) is a prominent example of Imaging Inverse Problem(IIP), highlighting the unrivalled performances of data-driven methods indegraded measurements setups like sparse X-ray projections. Although asignificant proportion of deep learning approaches benefit from largesupervised datasets to directly map experimental measurements to medical scans,they cannot generalize to unknown acquisition setups. In contrast, fullyunsupervised techniques, most notably using score-based generative models, haverecently demonstrated similar or better performances compared to supervisedapproaches to solve IIPs while being flexible at test time regarding theimaging setup. However, their use cases are limited by two factors: (a) theyneed considerable amounts of training data to have good generalizationproperties and (b) they require a backward operator, likeFiltered-Back-Projection in the case of CT, to condition the learned priordistribution of medical scans to experimental measurements. To overcome theseissues, we propose an unsupervised conditional approach to the GenerativeLatent Optimization framework (cGLO), in which the parameters of a decodernetwork are initialized on an unsupervised dataset. The decoder is then usedfor reconstruction purposes, by performing Generative Latent Optimization witha loss function directly comparing simulated measurements from proposedreconstructions to experimental measurements. The resulting approach, tested onsparse-view CT using multiple training dataset sizes, demonstrates betterreconstruction quality compared to state-of-the-art score-based strategies inmost data regimes and shows an increasing performance advantage for smallertraining datasets and reduced projection angles. Furthermore, cGLO does notrequire any backward operator and could expand use cases even to non-linearIIPs.</description><author>Thomas Braure, Kvin Ginsburger</author><pubDate>Mon, 31 Jul 2023 14:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16670v1</guid></item><item><title>Generative models for wearables data</title><link>http://arxiv.org/abs/2307.16664v1</link><description>Data scarcity is a common obstacle in medical research due to the high costsassociated with data collection and the complexity of gaining access to andutilizing data. Synthesizing health data may provide an efficient andcost-effective solution to this shortage, enabling researchers to exploredistributions and populations that are not represented in existing observationsor difficult to access due to privacy considerations. To that end, we havedeveloped a multi-task self-attention model that produces realistic wearableactivity data. We examine the characteristics of the generated data andquantify its similarity to genuine samples with both quantitative andqualitative approaches.</description><author>Arinbjrn Kolbeinsson, Luca Foschini</author><pubDate>Mon, 31 Jul 2023 14:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16664v1</guid></item><item><title>Graph Structure from Point Clouds: Geometric Attention is All You Need</title><link>http://arxiv.org/abs/2307.16662v1</link><description>The use of graph neural networks has produced significant advances in pointcloud problems, such as those found in high energy physics. The question of howto produce a graph structure in these problems is usually treated as a matterof heuristics, employing fully connected graphs or K-nearest neighbors. In thiswork, we elevate this question to utmost importance as the Topology Problem. Wepropose an attention mechanism that allows a graph to be constructed in alearned space that handles geometrically the flow of relevance, providing onesolution to the Topology Problem. We test this architecture, calledGravNetNorm, on the task of top jet tagging, and show that it is competitive intagging accuracy, and uses far fewer computational resources than all othercomparable models.</description><author>Daniel Murnane</author><pubDate>Mon, 31 Jul 2023 14:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16662v1</guid></item><item><title>Proactive Resource Request for Disaster Response: A Deep Learning-based Optimization Model</title><link>http://arxiv.org/abs/2307.16661v1</link><description>Disaster response is critical to save lives and reduce damages in theaftermath of a disaster. Fundamental to disaster response operations is themanagement of disaster relief resources. To this end, a local agency (e.g., alocal emergency resource distribution center) collects demands from localcommunities affected by a disaster, dispatches available resources to meet thedemands, and requests more resources from a central emergency management agency(e.g., Federal Emergency Management Agency in the U.S.). Prior resourcemanagement research for disaster response overlooks the problem of decidingoptimal quantities of resources requested by a local agency. In response tothis research gap, we define a new resource management problem that proactivelydecides optimal quantities of requested resources by considering both currentlyunfulfilled demands and future demands. To solve the problem, we take salientcharacteristics of the problem into consideration and develop a novel deeplearning method for future demand prediction. We then formulate the problem asa stochastic optimization model, analyze key properties of the model, andpropose an effective solution method to the problem based on the analyzedproperties. We demonstrate the superior performance of our method overprevalent existing methods using both real world and simulated data. We alsoshow its superiority over prevalent existing methods in a multi-stakeholder andmulti-objective setting through simulations.</description><author>Hongzhe Zhang, Xiaohang Zhao, Xiao Fang, Bintong Chen</author><pubDate>Mon, 31 Jul 2023 14:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16661v1</guid></item><item><title>Domain Adaptation for Medical Image Segmentation using Transformation-Invariant Self-Training</title><link>http://arxiv.org/abs/2307.16660v1</link><description>Models capable of leveraging unlabelled data are crucial in overcoming largedistribution gaps between the acquired datasets across different imagingdevices and configurations. In this regard, self-training techniques based onpseudo-labeling have been shown to be highly effective for semi-superviseddomain adaptation. However, the unreliability of pseudo labels can hinder thecapability of self-training techniques to induce abstract representation fromthe unlabeled target dataset, especially in the case of large distributiongaps. Since the neural network performance should be invariant to imagetransformations, we look to this fact to identify uncertain pseudo labels.Indeed, we argue that transformation invariant detections can provide morereasonable approximations of ground truth. Accordingly, we propose asemi-supervised learning strategy for domain adaptation termedtransformation-invariant self-training (TI-ST). The proposed method assessespixel-wise pseudo-labels' reliability and filters out unreliable detectionsduring self-training. We perform comprehensive evaluations for domainadaptation using three different modalities of medical images, two differentnetwork architectures, and several alternative state-of-the-art domainadaptation methods. Experimental results confirm the superiority of ourproposed method in mitigating the lack of target domain annotation and boostingsegmentation performance in the target domain.</description><author>Negin Ghamsarian, Javier Gamazo Tejero, Pablo Mrquez Neila, Sebastian Wolf, Martin Zinkernagel, Klaus Schoeffmann, Raphael Sznitman</author><pubDate>Mon, 31 Jul 2023 14:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16660v1</guid></item><item><title>The World Literature Knowledge Graph</title><link>http://arxiv.org/abs/2307.16659v1</link><description>Digital media have enabled the access to unprecedented literary knowledge.Authors, readers, and scholars are now able to discover and share an increasingamount of information about books and their authors. However, these sources ofknowledge are fragmented and do not adequately represent non-Western writersand their works. In this paper we present The World Literature Knowledge Graph,a semantic resource containing 194,346 writers and 965,210 works, specificallydesigned for exploring facts about literary works and authors from differentparts of the world. The knowledge graph integrates information about thereception of literary works gathered from 3 different communities of readers,aligned according to a single semantic model. The resource is accessiblethrough an online visualization platform, which can be found at the followingURL: https://literaturegraph.di.unito.it/. This platform has been rigorouslytested and validated by $3$ distinct categories of experts who have found it tobe highly beneficial for their respective work domains. These categoriesinclude teachers, researchers in the humanities, and professionals in thepublishing industry. The feedback received from these experts confirms thatthey can effectively utilize the platform to enhance their work processes andachieve valuable outcomes.</description><author>Marco Antonio Stranisci, Eleonora Bernasconi, Viviana Patti, Stefano Ferilli, Miguel Ceriani, Rossana Damiano</author><pubDate>Mon, 31 Jul 2023 14:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16659v1</guid></item><item><title>Sequential and Shared-Memory Parallel Algorithms for Partitioned Local Depths</title><link>http://arxiv.org/abs/2307.16652v1</link><description>In this work, we design, analyze, and optimize sequential and shared-memoryparallel algorithms for partitioned local depths (PaLD). Given a set of datapoints and pairwise distances, PaLD is a method for identifying strength ofpairwise relationships based on relative distances, enabling the identificationof strong ties within dense and sparse communities even if their sizes andwithin-community absolute distances vary greatly. We design two algorithmicvariants that perform community structure analysis through triplet comparisonsof pairwise distances. We present theoretical analyses of computation andcommunication costs and prove that the sequential algorithms are communicationoptimal, up to constant factors. We introduce performance optimizationstrategies that yield sequential speedups of up to $29\times$ over a baselinesequential implementation and parallel speedups of up to $19.4\times$ overoptimized sequential implementations using up to $32$ threads on an Intelmulticore CPU.</description><author>Aditya Devarakonda, Grey Ballard</author><pubDate>Mon, 31 Jul 2023 14:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16652v1</guid></item><item><title>UDAMA: Unsupervised Domain Adaptation through Multi-discriminator Adversarial Training with Noisy Labels Improves Cardio-fitness Prediction</title><link>http://arxiv.org/abs/2307.16651v1</link><description>Deep learning models have shown great promise in various healthcaremonitoring applications. However, most healthcare datasets with high-quality(gold-standard) labels are small-scale, as directly collecting ground truth isoften costly and time-consuming. As a result, models developed and validated onsmall-scale datasets often suffer from overfitting and do not generalize wellto unseen scenarios. At the same time, large amounts of imprecise(silver-standard) labeled data, annotated by approximate methods with the helpof modern wearables and in the absence of ground truth validation, are startingto emerge. However, due to measurement differences, this data displayssignificant label distribution shifts, which motivates the use of domainadaptation. To this end, we introduce UDAMA, a method with two key components:Unsupervised Domain Adaptation and Multidiscriminator Adversarial Training,where we pre-train on the silver-standard data and employ adversarialadaptation with the gold-standard data along with two domain discriminators. Inparticular, we showcase the practical potential of UDAMA by applying it toCardio-respiratory fitness (CRF) prediction. CRF is a crucial determinant ofmetabolic disease and mortality, and it presents labels with various levels ofnoise (goldand silver-standard), making it challenging to establish an accurateprediction model. Our results show promising performance by alleviatingdistribution shifts in various label shift settings. Additionally, by usingdata from two free-living cohort studies (Fenland and BBVS), we show that UDAMAconsistently outperforms up to 12% compared to competitive transfer learningand state-of-the-art domain adaptation models, paving the way for leveragingnoisy labeled data to improve fitness estimation at scale.</description><author>Yu Wu, Dimitris Spathis, Hong Jia, Ignacio Perez-Pozuelo, Tomas Gonzales, Soren Brage, Nicholas Wareham, Cecilia Mascolo</author><pubDate>Mon, 31 Jul 2023 14:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16651v1</guid></item><item><title>LLMs4OL: Large Language Models for Ontology Learning</title><link>http://arxiv.org/abs/2307.16648v1</link><description>We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)for Ontology Learning (OL). LLMs have shown significant advancements in naturallanguage processing, demonstrating their ability to capture complex languagepatterns in different knowledge domains. Our LLMs4OL paradigm investigates thefollowing hypothesis: \textit{Can LLMs effectively apply their language patterncapturing capability to OL, which involves automatically extracting andstructuring knowledge from natural language text?} To test this hypothesis, weconduct a comprehensive evaluation using the zero-shot prompting method. Weevaluate nine different LLM model families for three main OL tasks: termtyping, taxonomy discovery, and extraction of non-taxonomic relations.Additionally, the evaluations encompass diverse genres of ontologicalknowledge, including lexicosemantic knowledge in WordNet, geographicalknowledge in GeoNames, and medical knowledge in UMLS.</description><author>Hamed Babaei Giglou, Jennifer D'Souza, Sren Auer</author><pubDate>Mon, 31 Jul 2023 14:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16648v1</guid></item><item><title>Scaling Sentence Embeddings with Large Language Models</title><link>http://arxiv.org/abs/2307.16645v1</link><description>Large language models (LLMs) have recently garnered significant interest.With in-context learning, LLMs achieve impressive results in various naturallanguage tasks. However, the application of LLMs to sentence embeddings remainsan area of ongoing research. In this work, we propose an in-contextlearning-based method aimed at improving sentence embeddings performance. Ourapproach involves adapting the previous prompt-based representation method forautoregressive models, constructing a demonstration set that enables LLMs toperform in-context learning, and scaling up the LLMs to different model sizes.Through extensive experiments, in-context learning enables LLMs to generatehigh-quality sentence embeddings without any fine-tuning. It helps LLMs achieveperformance comparable to current contrastive learning methods. By scalingmodel size, we find scaling to more than tens of billion parameters harms theperformance on semantic textual similarity (STS) tasks. However, the largestmodel outperforms other counterparts and achieves the new state-of-the-artresult on transfer tasks. We also fine-tune LLMs with current contrastivelearning approach, and the 2.7B OPT model, incorporating our prompt-basedmethod, surpasses the performance of 4.8B ST5, achieving the newstate-of-the-art results on STS tasks. Our code is available athttps://github.com/kongds/scaling_sentemb.</description><author>Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, Fuzhen Zhuang</author><pubDate>Mon, 31 Jul 2023 14:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16645v1</guid></item><item><title>Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings</title><link>http://arxiv.org/abs/2307.16643v1</link><description>The Grapheme-to-Phoneme (G2P) task aims to convert orthographic input into adiscrete phonetic representation. G2P conversion is beneficial to variousspeech processing applications, such as text-to-speech and speech recognition.However, these tend to rely on manually-annotated pronunciation dictionaries,which are often time-consuming and costly to acquire. In this paper, we proposea method to improve the G2P conversion task by learning pronunciation examplesfrom audio recordings. Our approach bootstraps a G2P with a small set ofannotated examples. The G2P model is used to train a multilingual phonerecognition system, which then decodes speech recordings with a phoneticrepresentation. Given hypothesized phoneme labels, we learn pronunciationdictionaries for out-of-vocabulary words, and we use those to re-train the G2Psystem. Results indicate that our approach consistently improves the phoneerror rate of G2P systems across languages and amount of available data.</description><author>Manuel Sam Ribeiro, Giulia Comini, Jaime Lorenzo-Trueba</author><pubDate>Mon, 31 Jul 2023 14:25:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16643v1</guid></item></channel></rss>