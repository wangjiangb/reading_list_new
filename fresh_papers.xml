<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 23 Sep 2025 18:08:31 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Preconditioned Deformation Grids</title><link>http://arxiv.org/abs/2509.18097v1</link><description>Dynamic surface reconstruction of objects from point cloud sequences is achallenging field in computer graphics. Existing approaches either requiremultiple regularization terms or extensive training data which, however, leadto compromises in reconstruction accuracy as well as over-smoothing or poorgeneralization to unseen objects and motions. To address these lim- itations,we introduce Preconditioned Deformation Grids, a novel technique for estimatingcoherent deformation fields directly from unstructured point cloud sequenceswithout requiring or forming explicit correspondences. Key to our approach isthe use of multi-resolution voxel grids that capture the overall motion atvarying spatial scales, enabling a more flexible deformation representation. Inconjunction with incorporating grid-based Sobolev preconditioning intogradient-based optimization, we show that applying a Chamfer loss between theinput point clouds as well as to an evolving template mesh is sufficient toobtain accurate deformations. To ensure temporal consistency along the objectsurface, we include a weak isometry loss on mesh edges which complements themain objective without constraining deformation fidelity. Extensive evaluationsdemonstrate that our method achieves superior results, particularly for longsequences, compared to state-of-the-art techniques.</description><author>Julian Kaltheuner, Alexander Oebel, Hannah Droege, Patrick Stotko, Reinhard Klein</author><pubDate>Mon, 22 Sep 2025 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18097v1</guid></item><item><title>Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers</title><link>http://arxiv.org/abs/2509.18096v1</link><description>Text-to-image diffusion models excel at translating language prompts intophotorealistic images by implicitly grounding textual concepts through theircross-modal attention mechanisms. Recent multi-modal diffusion transformersextend this by introducing joint self-attention over concatenated image andtext tokens, enabling richer and more scalable cross-modal alignment. However,a detailed understanding of how and where these attention maps contribute toimage generation remains limited. In this paper, we introduce Seg4Diff(Segmentation for Diffusion), a systematic framework for analyzing theattention structures of MM-DiT, with a focus on how specific layers propagatesemantic information from text to image. Through comprehensive analysis, weidentify a semantic grounding expert layer, a specific MM-DiT block thatconsistently aligns text tokens with spatially coherent image regions,naturally producing high-quality semantic segmentation masks. We furtherdemonstrate that applying a lightweight fine-tuning scheme with mask-annotatedimage data enhances the semantic grouping capabilities of these layers andthereby improves both segmentation performance and generated image fidelity.Our findings demonstrate that semantic grouping is an emergent property ofdiffusion transformers and can be selectively amplified to advance bothsegmentation and generation performance, paving the way for unified models thatbridge visual perception and generation.</description><author>Chaehyun Kim, Heeseong Shin, Eunbeen Hong, Heeji Yoon, Anurag Arnab, Paul Hongsuck Seo, Sunghwan Hong, Seungryong Kim</author><pubDate>Mon, 22 Sep 2025 17:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18096v1</guid></item><item><title>MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction</title><link>http://arxiv.org/abs/2509.18095v1</link><description>Universal multimodal embedding models have achieved great success incapturing semantic relevance between queries and candidates. However, currentmethods either condense queries and candidates into a single vector,potentially limiting the expressiveness for fine-grained information, orproduce too many vectors that are prohibitively expensive for multi-vectorretrieval. In this work, we introduce MetaEmbed, a new framework for multimodalretrieval that rethinks how multimodal embeddings are constructed andinteracted with at scale. During training, a fixed number of learnable MetaTokens are appended to the input sequence. At test-time, their last-layercontextualized representations serve as compact yet expressive multi-vectorembeddings. Through the proposed Matryoshka Multi-Vector Retrieval training,MetaEmbed learns to organize information by granularity across multiplevectors. As a result, we enable test-time scaling in multimodal retrieval,where users can balance retrieval quality against efficiency demands byselecting the number of tokens used for indexing and retrieval interactions.Extensive evaluations on the Massive Multimodal Embedding Benchmark (MMEB) andthe Visual Document Retrieval Benchmark (ViDoRe) confirm that MetaEmbedachieves state-of-the-art retrieval performance while scaling robustly tomodels with 32B parameters.</description><author>Zilin Xiao, Qi Ma, Mengting Gu, Chun-cheng Jason Chen, Xintao Chen, Vicente Ordonez, Vijai Mohan</author><pubDate>Mon, 22 Sep 2025 17:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18095v1</guid></item><item><title>UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning</title><link>http://arxiv.org/abs/2509.18094v1</link><description>Recent advances in Large Multi-modal Models (LMMs) have demonstrated theirremarkable success as general-purpose multi-modal assistants, with particularfocuses on holistic image- and video-language understanding. Conversely, lessattention has been given to scaling fine-grained pixel-level understandingcapabilities, where the models are expected to realize pixel-level alignmentbetween visual signals and language semantics. Some previous studies haveapplied LMMs to related tasks such as region-level captioning and referringexpression segmentation. However, these models are limited to performing eitherreferring or segmentation tasks independently and fail to integrate thesefine-grained perception capabilities into visual reasoning. To bridge this gap,we propose UniPixel, a large multi-modal model capable of flexiblycomprehending visual prompt inputs and generating mask-grounded responses. Ourmodel distinguishes itself by seamlessly integrating pixel-level perceptionwith general visual understanding capabilities. Specifically, UniPixelprocesses visual prompts and generates relevant masks on demand, and performssubsequent reasoning conditioning on these intermediate pointers duringinference, thereby enabling fine-grained pixel-level reasoning. Theeffectiveness of our approach has been verified on 10 benchmarks across adiverse set of tasks, including pixel-level referring/segmentation andobject-centric understanding in images/videos. A novel PixelQA task thatjointly requires referring, segmentation, and question answering is alsodesigned to verify the flexibility of our method.</description><author>Ye Liu, Zongyang Ma, Junfu Pu, Zhongang Qi, Yang Wu, Ying Shan, Chang Wen Chen</author><pubDate>Mon, 22 Sep 2025 17:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18094v1</guid></item><item><title>Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding</title><link>http://arxiv.org/abs/2508.13804v2</link><description>How do Large Language Models understand moral dimensions compared to humans? This first large-scale Bayesian evaluation of market-leading language modelsprovides the answer. In contrast to prior work using deterministic ground truth(majority or inclusion rules), we model annotator disagreements to capture bothaleatoric uncertainty (inherent human disagreement) and epistemic uncertainty(model domain sensitivity). We evaluated the best language models (ClaudeSonnet 4, DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from nearly700 annotators in 100K+ texts spanning social networks, news and forums. Our GPU-optimized Bayesian framework processed 1M+ model queries, revealingthat AI models typically rank among the top 25\% of human annotators,performing much better than average balanced accuracy. Importantly, we findthat AI produces far fewer false negatives than humans, highlighting their moresensitive moral detection capabilities.</description><author>Maciej Skorski, Alina Landowska</author><pubDate>Mon, 22 Sep 2025 17:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13804v2</guid></item><item><title>SEQR: Secure and Efficient QR-based LoRA Routing</title><link>http://arxiv.org/abs/2509.18093v1</link><description>Low-Rank Adaptation (LoRA) has become a standard technique forparameter-efficient fine-tuning of large language models, enabling largelibraries of LoRAs, each for a specific task or domain. Efficiently selectingthe correct LoRA adapter for a given input remains a challenge, particularly insecure environments where supervised training of routers may raise privacyconcerns. Motivated by previous approaches, we formalize the goal ofunsupervised LoRA routing in terms of activation norm maximization, providing atheoretical framework for analysis. We demonstrate the discriminative power ofactivation norms and introduce SEQR, an unsupervised LoRA routing algorithmdesigned to maximize efficiency while providing strict routing guarantees. SEQRprovably identifies the norm-maximizing adapter with significantly greaterefficiency, making it a highly scalable and effective solution for dynamic LoRAcomposition. We validate our results through experiments that demonstrateimproved multi-task performance and efficiency.</description><author>William Fleshman, Benjamin Van Durme</author><pubDate>Mon, 22 Sep 2025 17:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18093v1</guid></item><item><title>ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation</title><link>http://arxiv.org/abs/2509.18092v1</link><description>Generating high-fidelity images of humans with fine-grained control overattributes such as hairstyle and clothing remains a core challenge inpersonalized text-to-image synthesis. While prior methods emphasize identitypreservation from a reference image, they lack modularity and fail to providedisentangled control over specific visual attributes. We introduce a newparadigm for attribute-specific image prompting, in which distinct sets ofreference images are used to guide the generation of individual aspects ofhuman appearance, such as hair, clothing, and identity. Our method encodesthese inputs into attribute-specific tokens, which are injected into apre-trained text-to-image diffusion model. This enables compositional anddisentangled control over multiple visual factors, even across multiple peoplewithin a single image. To promote natural composition and robustdisentanglement, we curate a cross-reference training dataset featuringsubjects in diverse poses and expressions, and propose a multi-attributecross-reference training strategy that encourages the model to generatefaithful outputs from misaligned attribute inputs while adhering to bothidentity and textual conditioning. Extensive experiments show that our methodachieves state-of-the-art performance in accurately following both visual andtextual prompts. Our framework paves the way for more configurable human imagesynthesis by combining visual prompting with text-driven generation. Webpage isavailable at: https://snap-research.github.io/composeme/.</description><author>Guocheng Gordon Qian, Daniil Ostashev, Egor Nemchinov, Avihay Assouline, Sergey Tulyakov, Kuan-Chieh Jackson Wang, Kfir Aberman</author><pubDate>Mon, 22 Sep 2025 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18092v1</guid></item><item><title>OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System</title><link>http://arxiv.org/abs/2509.18091v1</link><description>Despite the growing interest in replicating the scaled success of largelanguage models (LLMs) in industrial search and recommender systems, mostexisting industrial efforts remain limited to transplanting Transformerarchitectures, which bring only incremental improvements over strong DeepLearning Recommendation Models (DLRMs). From a first principle perspective, thebreakthroughs of LLMs stem not only from their architectures but also from twocomplementary mechanisms: context engineering, which enriches raw input querieswith contextual cues to better elicit model capabilities, and multi-stepreasoning, which iteratively refines model outputs through intermediatereasoning paths. However, these two mechanisms and their potential to unlocksubstantial improvements remain largely underexplored in industrial rankingsystems. In this paper, we propose OnePiece, a unified framework that seamlesslyintegrates LLM-style context engineering and reasoning into both retrieval andranking models of industrial cascaded pipelines. OnePiece is built on a pureTransformer backbone and further introduces three key innovations: (1)structured context engineering, which augments interaction history withpreference and scenario signals and unifies them into a structured tokenizedinput sequence for both retrieval and ranking; (2) block-wise latent reasoning,which equips the model with multi-step refinement of representations and scalesreasoning bandwidth via block size; (3) progressive multi-task training, whichleverages user feedback chains to effectively supervise reasoning steps duringtraining. OnePiece has been deployed in the main personalized search scenarioof Shopee and achieves consistent online gains across different key businessmetrics, including over $+2\%$ GMV/UU and a $+2.90\%$ increase in advertisingrevenue.</description><author>Sunhao Dai, Jiakai Tang, Jiahua Wu, Kun Wang, Yuxuan Zhu, Bingjun Chen, Bangyang Hong, Yu Zhao, Cong Fu, Kangle Wu, Yabo Ni, Anxiang Zeng, Wenjie Wang, Xu Chen, Jun Xu, See-Kiong Ng</author><pubDate>Mon, 22 Sep 2025 17:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18091v1</guid></item><item><title>GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction</title><link>http://arxiv.org/abs/2509.18090v1</link><description>Reconstructing accurate surfaces with radiance fields has achieved remarkableprogress in recent years. However, prevailing approaches, primarily based onGaussian Splatting, are increasingly constrained by representationalbottlenecks. In this paper, we introduce GeoSVR, an explicit voxel-basedframework that explores and extends the under-investigated potential of sparsevoxels for achieving accurate, detailed, and complete surface reconstruction.As strengths, sparse voxels support preserving the coverage completeness andgeometric clarity, while corresponding challenges also arise from absent sceneconstraints and locality in surface refinement. To ensure correct sceneconvergence, we first propose a Voxel-Uncertainty Depth Constraint thatmaximizes the effect of monocular depth cues while presenting a voxel-orienteduncertainty to avoid quality degradation, enabling effective and robust sceneconstraints yet preserving highly accurate geometries. Subsequently, SparseVoxel Surface Regularization is designed to enhance geometric consistency fortiny voxels and facilitate the voxel-based formation of sharp and accuratesurfaces. Extensive experiments demonstrate our superior performance comparedto existing methods across diverse challenging scenarios, excelling ingeometric accuracy, detail preservation, and reconstruction completeness whilemaintaining high efficiency. Code is available athttps://github.com/Fictionarry/GeoSVR.</description><author>Jiahe Li, Jiawei Zhang, Youmin Zhang, Xiao Bai, Jin Zheng, Xiaohan Yu, Lin Gu</author><pubDate>Mon, 22 Sep 2025 17:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18090v1</guid></item><item><title>Strategic Coordination for Evolving Multi-agent Systems: A Hierarchical Reinforcement and Collective Learning Approach</title><link>http://arxiv.org/abs/2509.18088v1</link><description>Decentralized combinatorial optimization in evolving multi-agent systemsposes significant challenges, requiring agents to balance long-termdecision-making, short-term optimized collective outcomes, while preservingautonomy of interactive agents under unanticipated changes. Reinforcementlearning offers a way to model sequential decision-making through dynamicprogramming to anticipate future environmental changes. However, applyingmulti-agent reinforcement learning (MARL) to decentralized combinatorialoptimization problems remains an open challenge due to the exponential growthof the joint state-action space, high communication overhead, and privacyconcerns in centralized training. To address these limitations, this paperproposes Hierarchical Reinforcement and Collective Learning (HRCL), a novelapproach that leverages both MARL and decentralized collective learning basedon a hierarchical framework. Agents take high-level strategies using MARL togroup possible plans for action space reduction and constrain the agentbehavior for Pareto optimality. Meanwhile, the low-level collective learninglayer ensures efficient and decentralized coordinated decisions among agentswith minimal communication. Extensive experiments in a synthetic scenario andreal-world smart city application models, including energy self-management anddrone swarm sensing, demonstrate that HRCL significantly improves performance,scalability, and adaptability compared to the standalone MARL and collectivelearning approaches, achieving a win-win synthesis solution.</description><author>Chuhao Qin, Evangelos Pournaras</author><pubDate>Mon, 22 Sep 2025 17:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18088v1</guid></item><item><title>Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding</title><link>http://arxiv.org/abs/2509.18085v1</link><description>Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative toautoregressive LLMs (AR-LLMs) with the potential to operate at significantlyhigher token generation rates. However, currently available open-source dLLMsoften generate at much lower rates, typically decoding only a single token atevery denoising timestep in order to maximize output quality. We presentSpiffy, a speculative decoding algorithm that accelerates dLLM inference by$\mathbf{2.8{-}3.1\times}$ while provably preserving the model's outputdistribution. This work addresses the unique challenges involved in applyingideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposesdraft states by leveraging the dLLM's distribution itself in anauto-speculative manner. This approach is efficient and effective, andeliminates the overheads of training and running an independent draft model. Tostructure the candidate draft states, we propose a novel directed draft graphwhich is uniquely designed to take advantage of the bidirectional, block-wisenature of dLLM generation and can be verified in parallel by the dLLM. Tofurther optimize the structure of these draft graphs, we introduce anefficient, offline calibration algorithm that procedurally determineshigh-quality graph configurations. These optimized draft graphs, enablingincreased acceptance rates, lead to a significant boost in the overall speedupachieved by the system. Crucially, Spiffy is also complementary to other recentinnovations in improving dLLM generation speeds such as KV-caching andmulti-token unmasking. We demonstrate that when combined with such paralleldecoding algorithms, Spiffy is able to effectively multiply the benefits ofthese methods leading to total speedups of up to $\mathbf{7.9\times}$.</description><author>Sudhanshu Agrawal, Risheek Garrepalli, Raghavv Goel, Mingu Lee, Christopher Lott, Fatih Porikli</author><pubDate>Mon, 22 Sep 2025 17:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18085v1</guid></item><item><title>Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning</title><link>http://arxiv.org/abs/2509.18083v1</link><description>We introduce Reasoning Core, a new scalable environment for ReinforcementLearning with Verifiable Rewards (RLVR), designed to advance foundationalsymbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarksthat focus on games or isolated puzzles, Reasoning Core procedurally generatesproblems across core formal domains, including PDDL planning, first-orderlogic, context-free grammar parsing, causal reasoning, and system equationsolving. The environment is built on key design principles of high-generalityproblem distributions, verification via external tools, and continuousdifficulty control, which together provide a virtually infinite supply of noveltraining instances. Initial zero-shot evaluations with frontier LLMs confirmthe difficulty of Reasoning Core's tasks, positioning it as a promisingresource to improve the reasoning capabilities of future models.</description><author>Valentin Lacombe, Valentin Quesnel, Damien Sileo</author><pubDate>Mon, 22 Sep 2025 17:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18083v1</guid></item><item><title>GraDeT-HTR: A Resource-Efficient Bengali Handwritten Text Recognition System utilizing Grapheme-based Tokenizer and Decoder-only Transformer</title><link>http://arxiv.org/abs/2509.18081v1</link><description>Despite Bengali being the sixth most spoken language in the world,handwritten text recognition (HTR) systems for Bengali remain severelyunderdeveloped. The complexity of Bengali script--featuring conjuncts,diacritics, and highly variable handwriting styles--combined with a scarcity ofannotated datasets makes this task particularly challenging. We presentGraDeT-HTR, a resource-efficient Bengali handwritten text recognition systembased on a Grapheme-aware Decoder-only Transformer architecture. To address theunique challenges of Bengali script, we augment the performance of adecoder-only transformer by integrating a grapheme-based tokenizer anddemonstrate that it significantly improves recognition accuracy compared toconventional subword tokenizers. Our model is pretrained on large-scalesynthetic data and fine-tuned on real human-annotated samples, achievingstate-of-the-art performance on multiple benchmark datasets.</description><author>Md. Mahmudul Hasan, Ahmed Nesar Tahsin Choudhury, Mahmudul Hasan, Md. Mosaddek Khan</author><pubDate>Mon, 22 Sep 2025 17:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18081v1</guid></item><item><title>Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates</title><link>http://arxiv.org/abs/2509.18076v1</link><description>Large language models (LLMs) have demonstrated strong reasoning and tool-usecapabilities, yet they often fail in real-world tool-interactions due toincorrect parameterization, poor tool selection, or misinterpretation of userintent. These issues often stem from an incomplete understanding of user goalsand inadequate comprehension of tool documentation. While Chain-of-Thought(CoT) prompting has proven effective for enhancing reasoning in generalcontexts, our analysis reveals that free-form CoT is insufficient and sometimescounterproductive for structured function-calling tasks. To address this, weintroduce a curriculum-inspired framework that leverages structured reasoningtemplates to guide LLMs through more deliberate step-by-step instructions forgenerating function callings. Experimental results show that our method reducestool-use errors, achieving 3-12% relative improvements over strong baselinesacross diverse model series and approaches. Moreover, our framework enhancesthe robustness, interpretability, and transparency of tool-using agents,advancing the development of more reliable AI assistants for real-worldapplications.</description><author>Hy Dang, Tianyi Liu, Zhuofeng Wu, Jingfeng Yang, Haoming Jiang, Tao Yang, Pei Chen, Zhengyang Wang, Helen Wang, Huasheng Li, Bing Yin, Meng Jiang</author><pubDate>Mon, 22 Sep 2025 17:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18076v1</guid></item><item><title>Learning functions, operators and dynamical systems with kernels</title><link>http://arxiv.org/abs/2509.18071v1</link><description>This expository article presents the approach to statistical machine learningbased on reproducing kernel Hilbert spaces. The basic framework is introducedfor scalar-valued learning and then extended to operator learning. Finally,learning dynamical systems is formulated as a suitable operator learningproblem, leveraging Koopman operator theory.</description><author>Lorenzo Rosasco</author><pubDate>Mon, 22 Sep 2025 17:53:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18071v1</guid></item><item><title>Generating 360° Video is What You Need For a 3D Scene</title><link>http://arxiv.org/abs/2504.02045v2</link><description>Generating 3D scenes is still a challenging task due to the lack of readilyavailable scene data. Most existing methods only produce partial scenes andprovide limited navigational freedom. We introduce a practical and scalablesolution that uses 360{\deg} video as an intermediate scene representation,capturing the full-scene context and ensuring consistent visual contentthroughout the generation. We propose WorldPrompter, a generative pipeline thatsynthesizes traversable 3D scenes from text prompts. WorldPrompter incorporatesa conditional 360{\deg} panoramic video generator, capable of producing a128-frame video that simulates a person walking through and capturing a virtualenvironment. The resulting video is then reconstructed as Gaussian splats by afast feedforward 3D reconstructor, enabling a true walkable experience withinthe 3D scene. Experiments demonstrate that our panoramic video generationmodel, trained with a mix of image and video data, achieves convincing spatialand temporal consistency for static scenes. This is validated by an averageCOLMAP matching rate of 94.6\%, allowing for high-quality panoramic Gaussiansplat reconstruction and improved navigation throughout the scene. Qualitativeand quantitative results also show it outperforms the state-of-the-art360{\deg} video generators and 3D scene generation models.</description><author>Zhaoyang Zhang, Yannick Hold-Geoffroy, Miloš Hašan, Ziwen Chen, Fujun Luan, Julie Dorsey, Yiwei Hu</author><pubDate>Mon, 22 Sep 2025 17:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.02045v2</guid></item><item><title>Neuromorphic Intelligence</title><link>http://arxiv.org/abs/2509.11940v2</link><description>Neuromorphic computing seeks to replicate the remarkable efficiency,flexibility, and adaptability of the human brain in artificial systems. Unlikeconventional digital approaches, which suffer from the Von Neumann bottleneckand depend on massive computational and energy resources, neuromorphic systemsexploit brain-inspired principles of computation to achieve orders of magnitudegreater energy efficiency. By drawing on insights from a wide range ofdisciplines, including artificial intelligence, physics, chemistry, biology,neuroscience, cognitive science and materials science, neuromorphic computingpromises to deliver intelligent systems that are sustainable, transparent, andwidely accessible. A central challenge, however, is to identify a unifyingtheoretical framework capable of bridging these diverse disciplines. We arguethat dynamical systems theory provides such a foundation. Rooted indifferential calculus, it offers a principled language for modeling inference,learning, and control in both natural and artificial substrates. Within thisframework, noise can be harnessed as a resource for learning, whiledifferential genetic programming enables the discovery of dynamical systemsthat implement adaptive behaviors. Embracing this perspective paves the waytoward emergent neuromorphic intelligence, where intelligent behavior arisesfrom the dynamics of physical substrates, advancing both the science andsustainability of AI.</description><author>Marcel van Gerven</author><pubDate>Mon, 22 Sep 2025 17:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.11940v2</guid></item><item><title>Learning to Rank with Top-$K$ Fairness</title><link>http://arxiv.org/abs/2509.18067v1</link><description>Fairness in ranking models is crucial, as disparities in exposure candisproportionately affect protected groups. Most fairness-aware ranking systemsfocus on ensuring comparable average exposure for groups across the entireranked list, which may not fully address real-world concerns. For example, whena ranking model is used for allocating resources among candidates or disasterhotspots, decision-makers often prioritize only the top-$K$ ranked items, whilethe ranking beyond top-$K$ becomes less relevant. In this paper, we propose alist-wise learning-to-rank framework that addresses the issues of inequalitiesin top-$K$ rankings at training time. Specifically, we propose a top-$K$exposure disparity measure that extends the classic exposure disparity metricin a ranked list. We then learn a ranker to balance relevance and fairness intop-$K$ rankings. Since direct top-$K$ selection is computationally expensivefor a large number of items, we transform the non-differentiable selectionprocess into a differentiable objective function and develop efficientstochastic optimization algorithms to achieve both high accuracy and sufficientfairness. Extensive experiments demonstrate that our method outperformsexisting methods.</description><author>Boyang Zhang, Quanqi Hu, Mingxuan Sun, Qihang Lin, Tianbao Yang</author><pubDate>Mon, 22 Sep 2025 17:47:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18067v1</guid></item><item><title>How Good are Foundation Models in Step-by-Step Embodied Reasoning?</title><link>http://arxiv.org/abs/2509.15293v2</link><description>Embodied agents operating in the physical world must make decisions that arenot only effective but also safe, spatially coherent, and grounded in context.While recent advances in large multimodal models (LMMs) have shown promisingcapabilities in visual understanding and language generation, their ability toperform structured reasoning for real-world embodied tasks remainsunderexplored. In this work, we aim to understand how well foundation modelscan perform step-by-step reasoning in embodied environments. To this end, wepropose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed toevaluate the reasoning capabilities of LMMs in complex embodied decision-makingscenarios. Our benchmark spans a diverse set of tasks that require agents tointerpret multimodal observations, reason about physical constraints andsafety, and generate valid next actions in natural language. We present (i) alarge-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluationframework that disentangles perceptual grounding from action reasoning, and(iii) empirical analysis of several leading LMMs under this setting. Ourbenchmark includes over 1.1k samples with detailed step-by-step reasoningacross 10 tasks and 8 embodiments, covering three different robot types. Ourresults highlight both the potential and current limitations of LMMs inembodied reasoning, pointing towards key challenges and opportunities forfuture research in robot intelligence. Our data and code will be made publiclyavailable.</description><author>Dinura Dissanayake, Ahmed Heakl, Omkar Thawakar, Noor Ahsan, Ritesh Thawkar, Ketan More, Jean Lahoud, Rao Anwer, Hisham Cholakkal, Ivan Laptev, Fahad Shahbaz Khan, Salman Khan</author><pubDate>Mon, 22 Sep 2025 17:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.15293v2</guid></item><item><title>Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers</title><link>http://arxiv.org/abs/2507.15833v2</link><description>Human vision is a highly active process driven by gaze, which directsattention to task-relevant regions through foveation, dramatically reducingvisual processing. In contrast, robot learning systems typically rely onpassive, uniform processing of raw camera images. In this work, we explore howincorporating human-like active gaze into robotic policies can enhanceefficiency and robustness. We develop GIAVA (Gaze Integrated Active-VisionALOHA), a robot vision system that emulates human head and neck movement, andgaze adjustment for foveated processing. Extending the AV-ALOHA robot platform,we introduce a framework for simultaneously collecting eye-tracking,perspective control, and robot manipulation demonstration data from a humanoperator. We also open-source a simulation benchmark and dataset for trainingrobot policies that incorporate human gaze. Inspired by recent work in foveatedimage segmentation and given the widespread use of Vision Transformers (ViTs)in robot learning, we integrate gaze information into ViTs using a foveatedpatch tokenization scheme. Compared to uniform patch tokenization, thissignificantly reduces the number of tokens, and thus computation. Our resultsshow that our method for foveated robot vision drastically reducescomputational overhead, and enhances robustness to background distractors.Notably, on certain high-precision tasks, foveated vision also improvesperformance, as reflected in higher success rates. Together, these findingssuggest that human-inspired foveated visual processing offers untappedpotential and should be further considered as a useful inductive bias inrobotic vision systems. https://ian-chuang.github.io/gaze-av-aloha/</description><author>Ian Chuang, Jinyu Zou, Andrew Lee, Dechen Gao, Iman Soltani</author><pubDate>Mon, 22 Sep 2025 17:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15833v2</guid></item><item><title>ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning</title><link>http://arxiv.org/abs/2509.18063v1</link><description>Large Language Models (LLMs) show strong reasoning abilities but rely oninternalized knowledge that is often insufficient, outdated, or incorrect whentrying to answer a question that requires specific domain knowledge. KnowledgeGraphs (KGs) provide structured external knowledge, yet their complexity andmulti-hop reasoning requirements make integration challenging. We presentARK-V1, a simple KG-agent that iteratively explores graphs to answer naturallanguage queries. We evaluate several not fine-tuned state-of-the art LLMs asbackbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based andcommonsense reasoning over long-tail entities. ARK-V1 achieves substantiallyhigher conditional accuracies than Chain-of-Thought baselines, and largerbackbone models show a clear trend toward better coverage, correctness, andstability.</description><author>Jan-Felix Klein, Lars Ohnemus</author><pubDate>Mon, 22 Sep 2025 17:40:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18063v1</guid></item><item><title>TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation</title><link>http://arxiv.org/abs/2509.18060v1</link><description>Tibetan is a low-resource language with limited parallel speech corporaspanning its three major dialects (\"U-Tsang, Amdo, and Kham), limitingprogress in speech modeling. To address this issue, we propose TMD-TTS, aunified Tibetan multi-dialect text-to-speech (TTS) framework that synthesizesparallel dialectal speech from explicit dialect labels. Our method features adialect fusion module and a Dialect-Specialized Dynamic Routing Network(DSDR-Net) to capture fine-grained acoustic and linguistic variations acrossdialects. Extensive objective and subjective evaluations demonstrate thatTMD-TTS significantly outperforms baselines in dialectal expressiveness. Wefurther validate the quality and utility of the synthesized speech through achallenging Speech-to-Speech Dialect Conversion (S2SDC) task.</description><author>Yutong Liu, Ziyue Zhang, Ban Ma-bao, Renzeng Duojie, Yuqing Cai, Yongbin Yu, Xiangxiang Wang, Fan Gao, Cheng Huang, Nyima Tashi</author><pubDate>Mon, 22 Sep 2025 17:38:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18060v1</guid></item><item><title>AI Copilots for Reproducibility in Science: A Case Study</title><link>http://arxiv.org/abs/2506.20130v3</link><description>Open science initiatives seek to make research outputs more transparent,accessible, and reusable, but ensuring that published findings can beindependently reproduced remains a persistent challenge. This paper introducesOpenPub, an AI-powered platform that supports researchers, reviewers, andreaders through a suite of modular copilots focused on key open science tasks.In this work, we present the Reproducibility Copilot, which analyzesmanuscripts, code, and supplementary materials to generate structured JupyterNotebooks and recommendations aimed at facilitating computational, or "rote",reproducibility. We conducted feasibility tests using previously studiedresearch papers with known reproducibility benchmarks. Results indicate thatOpenPub can substantially reduce reproduction time - from over 30 hours toabout 1 hour - while achieving high coverage of figures, tables, and resultssuitable for computational reproduction. The system systematically detectsbarriers to reproducibility, including missing hyperparameters, undocumentedpreprocessing steps, and incomplete or inaccessible datasets. Whilepreliminary, these findings suggest that AI-driven tools can meaningfullyreduce the burden of reproducibility efforts and contribute to more transparentand verifiable scientific communication. The modular copilot architecture alsoprovides a foundation for extending AI assistance to additional open scienceobjectives beyond reproducibility.</description><author>Adrien Bibal, Steven N. Minton, Deborah Khider, Yolanda Gil</author><pubDate>Mon, 22 Sep 2025 17:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.20130v3</guid></item><item><title>Efficient Neural SDE Training using Wiener-Space Cubature</title><link>http://arxiv.org/abs/2502.12395v3</link><description>A neural stochastic differential equation (SDE) is an SDE with drift anddiffusion terms parametrized by neural networks. The training procedure forneural SDEs consists of optimizing the SDE vector field (neural network)parameters to minimize the expected value of an objective functional oninfinite-dimensional path-space. Existing training techniques focus on methodsto efficiently compute path-wise gradients of the objective functional withrespect to these parameters, then pair this with Monte-Carlo simulation toestimate the gradient expectation. In this work we introduce a novel trainingtechnique which bypasses and improves upon this Monte-Carlo simulation; weextend results in the theory of Wiener space cubature to approximate theexpected objective functional value by a weighted sum of functional evaluationsof deterministic ODE solutions. Our main mathematical contribution enablingthis approximation is an extension of cubature bounds to the setting ofLipschitz-nonlinear functionals acting on path-space. Our resultingconstructive algorithm allows for more computationally efficient training alongseveral lines. First, it circumvents Brownian motion simulation and enables theuse of efficient parallel ODE solvers, thus decreasing the complexity ofpath-functional evaluation. Furthermore, and more surprisingly, we show thatthe number of paths required to achieve a given (expected loss functionaloracle value) approximation can be reduced in this deterministic cubatureregime. Specifically, we show that under reasonable regularity assumptions wecan observe a O(1/n) convergence rate, where n is the number of pathevaluations; in contrast with the standard O(1/sqrt(n)) rate of naiveMonte-Carlo or the O(log(n)^d /n) rate of quasi-Monte-Carlo.</description><author>Luke Snow, Vikram Krishnamurthy</author><pubDate>Mon, 22 Sep 2025 17:36:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12395v3</guid></item><item><title>MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild</title><link>http://arxiv.org/abs/2509.15548v2</link><description>In-the-wild photo collections often contain limited volumes of imagery andexhibit multiple appearances, e.g., taken at different times of day or seasons,posing significant challenges to scene reconstruction and novel view synthesis.Although recent adaptations of Neural Radiance Field (NeRF) and 3D GaussianSplatting (3DGS) have improved in these areas, they tend to oversmooth and areprone to overfitting. In this paper, we present MS-GS, a novel frameworkdesigned with Multi-appearance capabilities in Sparse-view scenarios using3DGS. To address the lack of support due to sparse initializations, ourapproach is built on the geometric priors elicited from monocular depthestimations. The key lies in extracting and utilizing local semantic regionswith a Structure-from-Motion (SfM) points anchored algorithm for reliablealignment and geometry cues. Then, to introduce multi-view constraints, wepropose a series of geometry-guided supervision at virtual views in afine-grained and coarse scheme to encourage 3D consistency and reduceoverfitting. We also introduce a dataset and an in-the-wild experiment settingto set up more realistic benchmarks. We demonstrate that MS-GS achievesphotorealistic renderings under various challenging sparse-view andmulti-appearance conditions and outperforms existing approaches significantlyacross different datasets.</description><author>Deming Li, Kaiwen Jiang, Yutao Tang, Ravi Ramamoorthi, Rama Chellappa, Cheng Peng</author><pubDate>Mon, 22 Sep 2025 17:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.15548v2</guid></item><item><title>Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM</title><link>http://arxiv.org/abs/2509.18058v1</link><description>Large language model (LLM) developers aim for their models to be honest,helpful, and harmless. However, when faced with malicious requests, models aretrained to refuse, sacrificing helpfulness. We show that frontier LLMs candevelop a preference for dishonesty as a new strategy, even when other optionsare available. Affected models respond to harmful requests with outputs thatsound harmful but are subtly incorrect or otherwise harmless in practice. Thisbehavior emerges with hard-to-predict variations even within models from thesame model family. We find no apparent cause for the propensity to deceive, butwe show that more capable models are better at executing this strategy.Strategic dishonesty already has a practical impact on safety evaluations, aswe show that dishonest responses fool all output-based monitors used to detectjailbreaks that we test, rendering benchmark scores unreliable. Further,strategic dishonesty can act like a honeypot against malicious users, whichnoticeably obfuscates prior jailbreak attacks. While output monitors fail, weshow that linear probes on internal activations can be used to reliably detectstrategic dishonesty. We validate probes on datasets with verifiable outcomesand by using their features as steering vectors. Overall, we consider strategicdishonesty as a concrete example of a broader concern that alignment of LLMs ishard to control, especially when helpfulness and harmlessness conflict.</description><author>Alexander Panfilov, Evgenii Kortukov, Kristina Nikolić, Matthias Bethge, Sebastian Lapuschkin, Wojciech Samek, Ameya Prabhu, Maksym Andriushchenko, Jonas Geiping</author><pubDate>Mon, 22 Sep 2025 17:30:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18058v1</guid></item><item><title>Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory</title><link>http://arxiv.org/abs/2509.18057v1</link><description>We explore whether techniques from AI can help discover new combinatorialstructures that improve provable limits on efficient algorithms. Specifically,we use AlphaEvolve (an LLM coding agent) to study two settings: a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve arecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set onrandom 3- and 4-regular graphs. Our improved lower bounds are obtained byconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, usingAlphaEvolve. Additionally, via analytical arguments we strengthen the upperbounds to settle the computational hardness of these questions up to an errorin the third decimal place. b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain newinapproximability results, proving that it is NP-hard to approximate MAX-4-CUTand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, usingAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improvesupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the currentbest gadget-based inapproximability result of $0.9853$, but falls short ofimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadgetreduction from "standard" H{\aa}stad-style PCPs. A key technical challenge we faced: verifying a candidate constructionproduced by AlphaEvolve is costly (often requiring exponential time). In bothsettings above, our results were enabled by using AlphaEvolve itself to evolvethe verification procedure to be faster (sometimes by $10,000\times$). Weconclude with a discussion of norms by which to assess the assistance from AIin developing proofs.</description><author>Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta</author><pubDate>Mon, 22 Sep 2025 17:30:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18057v1</guid></item><item><title>TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs</title><link>http://arxiv.org/abs/2509.18056v1</link><description>This paper introduces TempSamp-R1, a new reinforcement fine-tuning frameworkdesigned to improve the effectiveness of adapting multimodal large languagemodels (MLLMs) to video temporal grounding tasks. We reveal that existingreinforcement learning methods, such as Group Relative Policy Optimization(GRPO), rely on on-policy sampling for policy updates. However, in tasks withlarge temporal search spaces, this strategy becomes both inefficient andlimited in performance, as it often fails to identify temporally accuratesolutions. To address this limitation, TempSamp-R1 leverages ground-truthannotations as off-policy supervision to provide temporally precise guidance,effectively compensating for the sparsity and misalignment in on-policysolutions. To further stabilize training and reduce variance in reward-basedupdates, TempSamp-R1 provides a non-linear soft advantage computation methodthat dynamically reshapes the reward feedback via an asymmetric transformation.By employing a hybrid Chain-of-Thought (CoT) training paradigm, TempSamp-R1optimizes a single unified model to support both CoT and non-CoT inferencemodes, enabling efficient handling of queries with varying reasoningcomplexity. Experimental results demonstrate that TempSamp-R1 outperformsGRPO-based baselines, establishing new state-of-the-art performance onbenchmark datasets: Charades-STA (R1@0.7: 52.9%, +2.7%), ActivityNet Captions(R1@0.5: 56.0%, +5.3%), and QVHighlights (mAP: 30.0%, +3.0%). Moreover,TempSamp-R1 shows robust few-shot generalization capabilities under limiteddata. Code: https://github.com/HVision-NKU/TempSamp-R1</description><author>Yunheng Li, Jing Cheng, Shaoyong Jia, Hangyi Kuang, Shaohui Jiao, Qibin Hou, Ming-Ming Cheng</author><pubDate>Mon, 22 Sep 2025 17:30:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18056v1</guid></item><item><title>A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem</title><link>http://arxiv.org/abs/2509.18054v1</link><description>Selecting a solution algorithm for the Facility Layout Problem (FLP), anNP-hard optimization problem with a multiobjective trade-off, is a complex taskthat requires deep expert knowledge. The performance of a given algorithmdepends on specific problem characteristics such as its scale, objectives, andconstraints. This creates a need for a data-driven recommendation method toguide algorithm selection in automated design systems. This paper introduces anew recommendation method to make such expertise accessible, based on aKnowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. Toaddress this, a domain-specific knowledge graph is constructed from publishedliterature. The method then employs a multi-faceted retrieval mechanism togather relevant evidence from this knowledge graph using three distinctapproaches, which include a precise graph-based search, flexible vector-basedsearch, and high-level cluster-based search. The retrieved evidence is utilizedby a Large Language Model (LLM) to generate algorithm recommendations withdata-driven reasoning. The proposed KG-RAG method is compared against acommercial LLM chatbot with access to the knowledge base as a table, across aseries of diverse, real-world FLP test cases. Based on recommendation accuracyand reasoning capability, the proposed method performed significantly betterthan the commercial LLM chatbot.</description><author>Nikhil N S, Amol Dilip Joshi, Bilal Muhammed, Soban Babu</author><pubDate>Mon, 22 Sep 2025 17:29:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18054v1</guid></item><item><title>Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation</title><link>http://arxiv.org/abs/2504.11669v2</link><description>Recent advances in Source-Free Unsupervised Video Domain Adaptation (SFUVDA)leverage vision-language models to enhance pseudo-label generation. However,challenges such as noisy pseudo-labels and over-confident predictions limittheir effectiveness in adapting well across domains. We propose Co-STAR, anovel framework that integrates curriculum learning with collaborativeself-training between a source-trained teacher and a contrastivevision-language model (CLIP). Our curriculum learning approach employs areliability-based weight function that measures bidirectional predictionalignment between the teacher and CLIP, balancing between confident anduncertain predictions. This function preserves uncertainty for difficultsamples, while prioritizing reliable pseudo-labels when the predictions fromboth models closely align. To further improve adaptation, we propose AdaptiveCurriculum Regularization, which modifies the learning priority of samples in aprobabilistic, adaptive manner based on their confidence scores and predictionstability, mitigating overfitting to noisy and over-confident samples.Extensive experiments across multiple video domain adaptation benchmarksdemonstrate that Co-STAR consistently outperforms state-of-the-art SFUVDAmethods. Code is available at: https://github.com/Plrbear/Co-Star</description><author>Amirhossein Dadashzadeh, Parsa Esmati, Majid Mirmehdi</author><pubDate>Mon, 22 Sep 2025 17:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.11669v2</guid></item><item><title>The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies</title><link>http://arxiv.org/abs/2509.18052v1</link><description>Large Language Models (LLMs) are increasingly used for social simulation,where populations of agents are expected to reproduce human-like collectivebehavior. However, we find that many recent studies adopt experimental designsthat systematically undermine the validity of their claims. From a survey ofover 40 papers, we identify six recurring methodological flaws: agents areoften homogeneous (Profile), interactions are absent or artificially imposed(Interaction), memory is discarded (Memory), prompts tightly control outcomes(Minimal-Control), agents can infer the experimental hypothesis (Unawareness),and validation relies on simplified theoretical models rather than real-worlddata (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlyingsocial experiment in 53.1% of cases when given instructions from priorwork-violating the Unawareness principle. We formalize these six requirementsas the PIMMUR principles and argue they are necessary conditions for credibleLLM-based social simulation. To demonstrate their impact, we re-run fiverepresentative studies using a framework that enforces PIMMUR and find that thereported social phenomena frequently fail to emerge under more rigorousconditions. Our work establishes methodological standards for LLM-basedmulti-agent research and provides a foundation for more reliable andreproducible claims about "AI societies."</description><author>Jiaxu Zhou, Jen-tse Huang, Xuhui Zhou, Man Ho Lam, Xintao Wang, Hao Zhu, Wenxuan Wang, Maarten Sap</author><pubDate>Mon, 22 Sep 2025 17:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18052v1</guid></item><item><title>The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks</title><link>http://arxiv.org/abs/2506.08274v4</link><description>This research addresses the critical lack of comprehensive studies on featurescaling by systematically evaluating 12 scaling techniques - including severalless common transformations - across 14 different Machine Learning algorithmsand 16 datasets for classification and regression tasks. We meticulouslyanalyzed impacts on predictive performance (using metrics such as accuracy,MAE, MSE, and $R^2$) and computational costs (training time, inference time,and memory usage). Key findings reveal that while ensemble methods (such asRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)demonstrate robust performance largely independent of scaling, other widelyused models such as Logistic Regression, SVMs, TabNet, and MLPs showsignificant performance variations highly dependent on the chosen scaler. Thisextensive empirical analysis, with all source code, experimental results, andmodel parameters made publicly available to ensure complete transparency andreproducibility, offers model-specific crucial guidance to practitioners on theneed for an optimal selection of feature scaling techniques.</description><author>João Manoel Herrera Pinheiro, Suzana Vilas Boas de Oliveira, Thiago Henrique Segreto Silva, Pedro Antonio Rabelo Saraiva, Enzo Ferreira de Souza, Ricardo V. Godoy, Leonardo André Ambrosio, Marcelo Becker</author><pubDate>Mon, 22 Sep 2025 17:24:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08274v4</guid></item><item><title>Bayesian Algorithms for Adversarial Online Learning: from Finite to Infinite Action Spaces</title><link>http://arxiv.org/abs/2502.14790v5</link><description>We develop a form Thompson sampling for online learning under full feedback -also known as prediction with expert advice - where the learner's prior isdefined over the space of an adversary's future actions, rather than the spaceof experts. We show regret decomposes into regret the learner expected apriori, plus a prior-robustness-type term we call excess regret. In theclassical finite-expert setting, this recovers optimal rates. As an initialstep towards practical online learning in settings with apotentially-uncountably-infinite number of experts, we show that Thompsonsampling over the $d$-dimensional unit cube, using a certain Gaussian processprior widely-used in the Bayesian optimization literature, has a$\mathcal{O}\Big(\beta\sqrt{Td\log(1+\sqrt{d}\frac{\lambda}{\beta})}\Big)$ rateagainst a $\beta$-bounded $\lambda$-Lipschitz adversary.</description><author>Alexander Terenin, Jeffrey Negrea</author><pubDate>Mon, 22 Sep 2025 17:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.14790v5</guid></item><item><title>Functional effects models: Accounting for preference heterogeneity in panel data with machine learning</title><link>http://arxiv.org/abs/2509.18047v1</link><description>In this paper, we present a general specification for Functional EffectsModels, which use Machine Learning (ML) methodologies to learnindividual-specific preference parameters from socio-demographiccharacteristics, therefore accounting for inter-individual heterogeneity inpanel choice data. We identify three specific advantages of the FunctionalEffects Model over traditional fixed, and random/mixed effects models: (i) bymapping individual-specific effects as a function of socio-demographicvariables, we can account for these effects when forecasting choices ofpreviously unobserved individuals (ii) the (approximate) maximum-likelihoodestimation of functional effects avoids the incidental parameters problem ofthe fixed effects model, even when the number of observed choices perindividual is small; and (iii) we do not rely on the strong distributionalassumptions of the random effects model, which may not match reality. We learnfunctional intercept and functional slopes with powerful non-linear machinelearning regressors for tabular data, namely gradient boosting decision treesand deep neural networks. We validate our proposed methodology on a syntheticexperiment and three real-world panel case studies, demonstrating that theFunctional Effects Model: (i) can identify the true values ofindividual-specific effects when the data generation process is known; (ii)outperforms both state-of-the-art ML choice modelling techniques that omitindividual heterogeneity in terms of predictive performance, as well astraditional static panel choice models in terms of learning inter-individualheterogeneity. The results indicate that the FI-RUMBoost model, which combinesthe individual-specific constants of the Functional Effects Model with thecomplex, non-linear utilities of RUMBoost, performs marginally best onlarge-scale revealed preference panel data.</description><author>Nicolas Salvadé, Tim Hillel</author><pubDate>Mon, 22 Sep 2025 17:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18047v1</guid></item><item><title>HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba</title><link>http://arxiv.org/abs/2509.18046v1</link><description>End-to-end reinforcement learning (RL) for humanoid locomotion is appealingfor its compact perception-action mapping, yet practical policies often sufferfrom training instability, inefficient feature fusion, and high actuation cost.We present HuMam, a state-centric end-to-end RL framework that employs asingle-layer Mamba encoder to fuse robot-centric states with oriented footsteptargets and a continuous phase clock. The policy outputs joint position targetstracked by a low-level PD loop and is optimized with PPO. A concise six-termreward balances contact quality, swing smoothness, foot placement, posture, andbody stability while implicitly promoting energy saving. On the JVRC-1 humanoidin mc-mujoco, HuMam consistently improves learning efficiency, trainingstability, and overall task performance over a strong feedforward baseline,while reducing power consumption and torque peaks. To our knowledge, this isthe first end-to-end humanoid RL controller that adopts Mamba as the fusionbackbone, demonstrating tangible gains in efficiency, stability, and controleconomy.</description><author>Yinuo Wang, Yuanyang Qi, Jinzhao Zhou, Gavin Tao</author><pubDate>Mon, 22 Sep 2025 17:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18046v1</guid></item><item><title>Hybrid Reputation Aggregation: A Robust Defense Mechanism for Adversarial Federated Learning in 5G and Edge Network Environments</title><link>http://arxiv.org/abs/2509.18044v1</link><description>Federated Learning (FL) in 5G and edge network environments face severesecurity threats from adversarial clients. Malicious participants can performlabel flipping, inject backdoor triggers, or launch Sybil attacks to corruptthe global model. This paper introduces Hybrid Reputation Aggregation (HRA), anovel robust aggregation mechanism designed to defend against diverseadversarial behaviors in FL without prior knowledge of the attack type. HRAcombines geometric anomaly detection with momentum-based reputation tracking ofclients. In each round, it detects outlier model updates via distance-basedgeometric analysis while continuously updating a trust score for each clientbased on historical behavior. This hybrid approach enables adaptive filteringof suspicious updates and long-term penalization of unreliable clients,countering attacks ranging from backdoor insertions to random noise Byzantinefailures. We evaluate HRA on a large-scale proprietary 5G network dataset (3M+records) and the widely used NF-CSE-CIC-IDS2018 benchmark under diverseadversarial attack scenarios. Experimental results reveal that HRA achievesrobust global model accuracy of up to 98.66% on the 5G dataset and 96.60% onNF-CSE-CIC-IDS2018, outperforming state-of-the-art aggregators such as Krum,Trimmed Mean, and Bulyan by significant margins. Our ablation studies furtherdemonstrate that the full hybrid system achieves 98.66% accuracy, while theanomaly-only and reputation-only variants drop to 84.77% and 78.52%,respectively, validating the synergistic value of our dual-mechanism approach.This demonstrates HRA's enhanced resilience and robustness in 5G/edge federatedlearning deployments, even under significant adversarial conditions.</description><author>Saeid Sheikhi, Panos Kostakos, Lauri Loven</author><pubDate>Mon, 22 Sep 2025 17:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18044v1</guid></item><item><title>Prepare Before You Act: Learning From Humans to Rearrange Initial States</title><link>http://arxiv.org/abs/2509.18043v1</link><description>Imitation learning (IL) has proven effective across a wide range ofmanipulation tasks. However, IL policies often struggle when faced without-of-distribution observations; for instance, when the target object is in apreviously unseen position or occluded by other objects. In these cases,extensive demonstrations are needed for current IL methods to reach robust andgeneralizable behaviors. But when humans are faced with these sorts of atypicalinitial states, we often rearrange the environment for more favorable taskexecution. For example, a person might rotate a coffee cup so that it is easierto grasp the handle, or push a box out of the way so they can directly grasptheir target object. In this work we seek to equip robot learners with the samecapability: enabling robots to prepare the environment before executing theirgiven policy. We propose ReSET, an algorithm that takes initial states -- whichare outside the policy's distribution -- and autonomously modifies object posesso that the restructured scene is similar to training data. Theoretically, weshow that this two step process (rearranging the environment before rolling outthe given policy) reduces the generalization gap. Practically, our ReSETalgorithm combines action-agnostic human videos with task-agnosticteleoperation data to i) decide when to modify the scene, ii) predict whatsimplifying actions a human would take, and iii) map those predictions intorobot action primitives. Comparisons with diffusion policies, VLAs, and otherbaselines show that using ReSET to prepare the environment enables more robusttask execution with equal amounts of total training data. See videos at ourproject website: https://reset2025paper.github.io/</description><author>Yinlong Dai, Andre Keyser, Dylan P. Losey</author><pubDate>Mon, 22 Sep 2025 17:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18043v1</guid></item><item><title>NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning</title><link>http://arxiv.org/abs/2509.18041v1</link><description>Long-Form Video Question Answering (LVQA) poses challenges beyond traditionalvisual question answering (VQA), which is often limited to static images orshort video clips. While current vision-language models (VLMs) perform well inthose settings, they struggle with complex queries in LVQA over long videosinvolving multi-step temporal reasoning and causality. Vanilla approaches,which sample frames uniformly and feed them to a VLM with the question, incursignificant token overhead, forcing severe downsampling. As a result, the modeloften misses fine-grained visual structure, subtle event transitions, or keytemporal cues, ultimately leading to incorrect answers. To address theselimitations, recent works have explored query-adaptive frame sampling,hierarchical keyframe selection, and agent-based iterative querying. However,these methods remain fundamentally heuristic: they lack explicit temporalrepresentations and cannot enforce or verify logical event relationships. As aresult, there are no formal guarantees that the sampled context actuallyencodes the compositional or causal logic demanded by the question. To addressthese foundational gaps, we introduce NeuS-QA, a training-free, plug-and-playneuro-symbolic pipeline for LVQA. NeuS-QA translates a natural languagequestion into a formal temporal logic expression, constructs a video automatonfrom frame-level semantic propositions, and applies model checking torigorously identify video segments satisfying the question's logicalrequirements. Only these logic-verified segments are submitted to the VLM, thusimproving interpretability, reducing hallucinations, and enabling compositionalreasoning without modifying or fine-tuning the model. Experiments onLongVideoBench and CinePile show NeuS-QA improves performance by over 10%,especially on questions involving event ordering, causality, and multi-stepcompositional reasoning.</description><author>Sahil Shah, S P Sharan, Harsh Goel, Minkyu Choi, Mustafa Munir, Manvik Pasula, Radu Marculescu, Sandeep Chinchali</author><pubDate>Mon, 22 Sep 2025 17:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18041v1</guid></item><item><title>Detection of Misreporting Attacks on Software-Defined Immersive Environments</title><link>http://arxiv.org/abs/2509.18040v1</link><description>The ability to centrally control network infrastructure using a programmablemiddleware has made Software-Defined Networking (SDN) ideal for emergingapplications, such as immersive environments. However, such flexibilityintroduces new vulnerabilities, such as switch misreporting led load imbalance,which in turn make such immersive environment vulnerable to severe qualitydegradation. In this paper, we present a hybrid machine learning (ML)-basednetwork anomaly detection framework that identifies such stealthy misreportingby capturing temporal inconsistencies in switch-reported loads, and therebycounter potentially catastrophic quality degradation of hosted immersiveapplication. The detection system combines unsupervised anomaly scoring withsupervised classification to robustly distinguish malicious behavior. Datacollected from a realistic testbed deployment under both benign and adversarialconditions is used to train and evaluate the model. Experimental results showthat the framework achieves high recall in detecting misreporting behavior,making it effective for early and reliable detection in SDN environments.</description><author>Sourya Saha, Md Nurul Absur, Shima Yousefi, Saptarshi Debroy</author><pubDate>Mon, 22 Sep 2025 17:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18040v1</guid></item><item><title>Kernel K-means clustering of distributional data</title><link>http://arxiv.org/abs/2509.18037v1</link><description>We consider the problem of clustering a sample of probability distributionsfrom a random distribution on $\mathbb R^p$. Our proposed partitioning methodmakes use of a symmetric, positive-definite kernel $k$ and its associatedreproducing kernel Hilbert space (RKHS) $\mathcal H$. By mapping eachdistribution to its corresponding kernel mean embedding in $\mathcal H$, weobtain a sample in this RKHS where we carry out the $K$-means clusteringprocedure, which provides an unsupervised classification of the originalsample. The procedure is simple and computationally feasible even for dimension$p&gt;1$. The simulation studies provide insight into the choice of the kernel andits tuning parameter. The performance of the proposed clustering procedure isillustrated on a collection of Synthetic Aperture Radar (SAR) images.</description><author>Amparo Baíllo, Jose R. Berrendero, Martín Sánchez-Signorini</author><pubDate>Mon, 22 Sep 2025 17:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18037v1</guid></item><item><title>Rationale-Guided Retrieval Augmented Generation for Medical Question Answering</title><link>http://arxiv.org/abs/2411.00300v2</link><description>Large language models (LLM) hold significant potential for applications inbiomedicine, but they struggle with hallucinations and outdated knowledge.While retrieval-augmented generation (RAG) is generally employed to addressthese issues, it also has its own set of challenges: (1) LLMs are vulnerable toirrelevant or incorrect context, (2) medical queries are often notwell-targeted for helpful information, and (3) retrievers are prone to biastoward the specific source corpus they were trained on. In this study, wepresent RAG$^2$ (RAtionale-Guided RAG), a new framework for enhancing thereliability of RAG in biomedical contexts. RAG$^2$ incorporates three keyinnovations: a small filtering model trained on perplexity-based labels ofrationales, which selectively augments informative snippets of documents whilefiltering out distractors; LLM-generated rationales as queries to improve theutility of retrieved snippets; a structure designed to retrieve snippets evenlyfrom a comprehensive set of four biomedical corpora, effectively mitigatingretriever bias. Our experiments demonstrate that RAG$^2$ improves thestate-of-the-art LLMs of varying sizes, with improvements of up to 6.1\%, andit outperforms the previous best medical RAG model by up to 5.6\% across threemedical question-answering benchmarks. Our code is available athttps://github.com/dmis-lab/RAG2.</description><author>Jiwoong Sohn, Yein Park, Chanwoong Yoon, Sihyeon Park, Hyeon Hwang, Mujeen Sung, Hyunjae Kim, Jaewoo Kang</author><pubDate>Mon, 22 Sep 2025 17:11:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00300v2</guid></item><item><title>Control Disturbance Rejection in Neural ODEs</title><link>http://arxiv.org/abs/2509.18034v1</link><description>In this paper, we propose an iterative training algorithm for Neural ODEsthat provides models resilient to control (parameter) disturbances. The methodbuilds on our earlier work Tuning without Forgetting-and similarly introducestraining points sequentially, and updates the parameters on new data within thespace of parameters that do not decrease performance on the previously learnedtraining points-with the key difference that, inspired by the concept of flatminima, we solve a minimax problem for a non-convex non-concave functional overan infinite-dimensional control space. We develop a projected gradient descentalgorithm on the space of parameters that admits the structure of aninfinite-dimensional Banach subspace. We show through simulations that thisformulation enables the model to effectively learn new data points and gainrobustness against control disturbance.</description><author>Erkan Bayram, Mohamed-Ali Belabbas, Tamer Başar</author><pubDate>Mon, 22 Sep 2025 17:09:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18034v1</guid></item><item><title>Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III</title><link>http://arxiv.org/abs/2507.02954v2</link><description>As financial institutions increasingly adopt Large Language Models (LLMs),rigorous domain-specific evaluation becomes critical for responsibledeployment. This paper presents a comprehensive benchmark evaluating 23state-of-the-art LLMs on the Chartered Financial Analyst (CFA) Level III exam -the gold standard for advanced financial reasoning. We assess bothmultiple-choice questions (MCQs) and essay-style responses using multipleprompting strategies including Chain-of-Thought and Self-Discover. Ourevaluation reveals that leading models demonstrate strong capabilities, withcomposite scores such as 79.1% (o4-mini) and 77.3% (Gemini 2.5 Flash) on CFALevel III. These results, achieved under a revised, stricter essay gradingmethodology, indicate significant progress in LLM capabilities for high-stakesfinancial applications. Our findings provide crucial guidance for practitionerson model selection and highlight remaining challenges in cost-effectivedeployment and the need for nuanced interpretation of performance againstprofessional benchmarks.</description><author>Pranam Shetty, Abhisek Upadhayaya, Parth Mitesh Shah, Srikanth Jagabathula, Shilpi Nayak, Anna Joo Fee</author><pubDate>Mon, 22 Sep 2025 17:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.02954v2</guid></item><item><title>Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards</title><link>http://arxiv.org/abs/2506.11474v2</link><description>Large language models have shown promise in clinical decision making, butcurrent approaches struggle to localize and correct errors at specific steps ofthe reasoning process. This limitation is critical in medicine, whereidentifying and addressing reasoning errors is essential for accurate diagnosisand effective patient care. We introduce Med-PRM, a process reward modelingframework that leverages retrieval-augmented generation to verify eachreasoning step against established medical knowledge bases. By verifyingintermediate reasoning steps with evidence retrieved from clinical guidelinesand literature, our model can precisely assess the reasoning quality in afine-grained manner. Evaluations on five medical QA benchmarks and twoopen-ended diagnostic tasks demonstrate that Med-PRM achieves state-of-the-artperformance, with improving the performance of base models by up to 13.50%using Med-PRM. Moreover, we demonstrate the generality of Med-PRM byintegrating it in a plug-and-play fashion with strong policy models such asMeerkat, achieving over 80\% accuracy on MedQA for the first time usingsmall-scale models of 8 billion parameters. Our code and data are available at:https://med-prm.github.io/</description><author>Jaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe Koo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, Jaewoo Kang</author><pubDate>Mon, 22 Sep 2025 17:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.11474v2</guid></item><item><title>RadEval: A framework for radiology text evaluation</title><link>http://arxiv.org/abs/2509.18030v1</link><description>We introduce RadEval, a unified, open-source framework for evaluatingradiology texts. RadEval consolidates a diverse range of metrics, from classicn-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinicalconcept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT,TemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine andstandardize implementations, extend GREEN to support multiple imagingmodalities with a more lightweight model, and pretrain a domain-specificradiology encoder, demonstrating strong zero-shot retrieval performance. Wealso release a richly annotated expert dataset with over 450 clinicallysignificant error labels and show how different metrics correlate withradiologist judgment. Finally, RadEval provides statistical testing tools andbaseline model evaluations across multiple publicly available datasets,facilitating reproducibility and robust benchmarking in radiology reportgeneration.</description><author>Justin Xu, Xi Zhang, Javid Abderezaei, Julie Bauml, Roger Boodoo, Fatemeh Haghighi, Ali Ganjizadeh, Eric Brattain, Dave Van Veen, Zaiqiao Meng, David Eyre, Jean-Benoit Delbrouck</author><pubDate>Mon, 22 Sep 2025 17:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18030v1</guid></item><item><title>TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games</title><link>http://arxiv.org/abs/2505.15712v2</link><description>This paper introduces TurnaboutLLM, a novel framework and dataset forevaluating the deductive reasoning abilities of Large Language Models (LLMs) byleveraging the interactive gameplay of detective games Ace Attorney andDanganronpa. The framework tasks LLMs with identifying contradictions betweentestimonies and evidences within long narrative contexts, a challenging taskdue to the large answer space and diverse reasoning types presented by itsquestions. We evaluate twelve state-of-the-art LLMs on the dataset, hinting atlimitations of popular strategies for enhancing deductive reasoning such asextensive thinking and Chain-of-Thought prompting. The results also suggestvarying effects of context size, the number of reasoning step and answer spacesize on model performance. Overall, TurnaboutLLM presents a substantialchallenge for LLMs' deductive reasoning abilities in complex, narrative-richenvironments.</description><author>Yuan Yuan, Muyu He, Muhammad Adil Shahid, Jiani Huang, Ziyang Li, Li Zhang</author><pubDate>Mon, 22 Sep 2025 17:02:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15712v2</guid></item><item><title>Deep Learning as the Disciplined Construction of Tame Objects</title><link>http://arxiv.org/abs/2509.18025v1</link><description>One can see deep-learning models as compositions of functions within theso-called tame geometry. In this expository note, we give an overview of sometopics at the interface of tame geometry (also known as o-minimality),optimization theory, and deep learning theory and practice. To do so, wegradually introduce the concepts and tools used to build convergence guaranteesfor stochastic gradient descent in a general nonsmooth nonconvex, but tame,setting. This illustrates some ways in which tame geometry is a naturalmathematical framework for the study of AI systems, especially within DeepLearning.</description><author>Gilles Bareilles, Allen Gehret, Johannes Aspman, Jana Lepšová, Jakub Mareček</author><pubDate>Mon, 22 Sep 2025 17:00:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18025v1</guid></item><item><title>Core-elements Subsampling for Alternating Least Squares</title><link>http://arxiv.org/abs/2509.18024v1</link><description>In this paper, we propose a novel element-wise subset selection method forthe alternating least squares (ALS) algorithm, focusing on low-rank matrixfactorization involving matrices with missing values, as commonly encounteredin recommender systems. While ALS is widely used for providing personalizedrecommendations based on user-item interaction data, its high computationalcost, stemming from repeated regression operations, poses significantchallenges for large-scale datasets. To enhance the efficiency of ALS, wepropose a core-elements subsampling method that selects a representative subsetof data and leverages sparse matrix operations to approximate ALS estimationsefficiently. We establish theoretical guarantees for the approximation andconvergence of the proposed approach, showing that it achieves similar accuracywith significantly reduced computational time compared to full-data ALS.Extensive simulations and real-world applications demonstrate the effectivenessof our method in various scenarios, emphasizing its potential in large-scalerecommendation systems.</description><author>Dunyao Xue, Mengyu Li, Cheng Meng, Jingyi Zhang</author><pubDate>Mon, 22 Sep 2025 17:00:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18024v1</guid></item><item><title>Anatomical feature-prioritized loss for enhanced MR to CT translation</title><link>http://arxiv.org/abs/2410.10328v3</link><description>In medical image synthesis, the precision of localized structural details iscrucial, particularly when addressing specific clinical requirements such asthe identification and measurement of fine structures. Traditional methods forimage translation and synthesis are generally optimized for global imagereconstruction but often fall short in providing the finesse required fordetailed local analysis. This study represents a step toward addressing thischallenge by introducing a novel anatomical feature-prioritized (AFP) lossfunction into the synthesis process. This method enhances reconstruction byfocusing on clinically significant structures, utilizing features from apre-trained model designed for a specific downstream task, such as thesegmentation of particular anatomical regions. The AFP loss function canreplace or complement global reconstruction methods, ensuring a balancedemphasis on both global image fidelity and local structural details. Variousimplementations of this loss function are explored, including its integrationinto different synthesis networks such as GAN-based and CNN-based models. Ourapproach is applied and evaluated in two contexts: lung MR to CT translation,focusing on high-quality reconstruction of bronchial structures, using aprivate dataset; and pelvis MR to CT synthesis, targeting the accuraterepresentation of organs and muscles, utilizing a public dataset from theSynthrad2023 challenge. We leverage embeddings from pre-trained segmentationmodels specific to these anatomical regions to demonstrate the capability ofthe AFP loss to prioritize and accurately reconstruct essential features. Thistailored approach shows promising potential for enhancing the specificity andpracticality of medical image synthesis in clinical applications.</description><author>Arthur Longuefosse, Baudouin Denis de Senneville, Gael Dournes, Ilyes Benlala, Pascal Desbarats, Fabien Baldacci</author><pubDate>Mon, 22 Sep 2025 16:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10328v3</guid></item><item><title>Beyond Diagnosis: Evaluating Multimodal LLMs for Pathology Localization in Chest Radiographs</title><link>http://arxiv.org/abs/2509.18015v1</link><description>Recent work has shown promising performance of frontier large language models(LLMs) and their multimodal counterparts in medical quizzes and diagnostictasks, highlighting their potential for broad clinical utility given theiraccessible, general-purpose nature. However, beyond diagnosis, a fundamentalaspect of medical image interpretation is the ability to localize pathologicalfindings. Evaluating localization not only has clinical and educationalrelevance but also provides insight into a model's spatial understanding ofanatomy and disease. Here, we systematically assess two general-purpose MLLMs(GPT-4 and GPT-5) and a domain-specific model (MedGemma) in their ability tolocalize pathologies on chest radiographs, using a prompting pipeline thatoverlays a spatial grid and elicits coordinate-based predictions. Averagedacross nine pathologies in the CheXlocalize dataset, GPT-5 exhibited alocalization accuracy of 49.7%, followed by GPT-4 (39.1%) and MedGemma (17.7%),all lower than a task-specific CNN baseline (59.9%) and a radiologist benchmark(80.1%). Despite modest performance, error analysis revealed that GPT-5'spredictions were largely in anatomically plausible regions, just not alwaysprecisely localized. GPT-4 performed well on pathologies with fixed anatomicallocations, but struggled with spatially variable findings and exhibitedanatomically implausible predictions more frequently. MedGemma demonstrated thelowest performance on all pathologies, showing limited capacity to generalizeto this novel task. Our findings highlight both the promise and limitations ofcurrent MLLMs in medical imaging and underscore the importance of integratingthem with task-specific tools for reliable use.</description><author>Advait Gosai, Arun Kavishwar, Stephanie L. McNamara, Soujanya Samineni, Renato Umeton, Alexander Chowdhury, William Lotter</author><pubDate>Mon, 22 Sep 2025 16:54:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18015v1</guid></item><item><title>Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis</title><link>http://arxiv.org/abs/2509.18014v1</link><description>Tabular Generative Models are often argued to preserve privacy by creatingsynthetic datasets that resemble training data. However, auditing theirempirical privacy remains challenging, as commonly used similarity metrics failto effectively characterize privacy risk. Membership Inference Attacks (MIAs)have recently emerged as a method for evaluating privacy leakage in syntheticdata, but their practical effectiveness is limited. Numerous attacks existacross different threat models, each with distinct implementations targetingvarious sources of privacy leakage, making them difficult to applyconsistently. Moreover, no single attack consistently outperforms the others,leading to a routine underestimation of privacy risk. To address these issues, we propose a unified, model-agnostic threatframework that deploys a collection of attacks to estimate the maximumempirical privacy leakage in synthetic datasets. We introduce Synth-MIA, anopen-source Python library that streamlines this auditing process through anovel testbed that integrates seamlessly into existing synthetic dataevaluation pipelines through a Scikit-Learn-like API. Our software implements13 attack methods through a Scikit-Learn-like API, designed to enable fastsystematic estimation of privacy leakage for practitioners as well asfacilitate the development of new attacks and experiments for researchers. We demonstrate our framework's utility in the largest tabular synthesisprivacy benchmark to date, revealing that higher synthetic data qualitycorresponds to greater privacy leakage, that similarity-based privacy metricsshow weak correlation with MIA results, and that the differentially privategenerator PATEGAN can fail to preserve privacy under such attacks. Thisunderscores the necessity of MIA-based auditing when designing and deployingTabular Generative Models.</description><author>Joshua Ward, Xiaofeng Lin, Chi-Hua Wang, Guang Cheng</author><pubDate>Mon, 22 Sep 2025 16:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18014v1</guid></item><item><title>Fréchet Geodesic Boosting</title><link>http://arxiv.org/abs/2509.18013v1</link><description>Gradient boosting has become a cornerstone of machine learning, enabling baselearners such as decision trees to achieve exceptional predictive performance.While existing algorithms primarily handle scalar or Euclidean outputs,increasingly prevalent complex-structured data, such as distributions,networks, and manifold-valued outputs, present challenges for traditionalmethods. Such non-Euclidean data lack algebraic structures such as addition,subtraction, or scalar multiplication required by standard gradient boostingframeworks. To address these challenges, we introduce Fr\'echet geodesicboosting (FGBoost), a novel approach tailored for outputs residing in geodesicmetric spaces. FGBoost leverages geodesics as proxies for residuals andconstructs ensembles in a way that respects the intrinsic geometry of theoutput space. Through theoretical analysis, extensive simulations, andreal-world applications, we demonstrate the strong performance and adaptabilityof FGBoost, showcasing its potential for modeling complex data.</description><author>Yidong Zhou, Su I Iao, Hans-Georg Müller</author><pubDate>Mon, 22 Sep 2025 16:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18013v1</guid></item><item><title>Robust, Online, and Adaptive Decentralized Gaussian Processes</title><link>http://arxiv.org/abs/2509.18011v1</link><description>Gaussian processes (GPs) offer a flexible, uncertainty-aware framework formodeling complex signals, but scale cubically with data, assume static targets,and are brittle to outliers, limiting their applicability in large-scaleproblems with dynamic and noisy environments. Recent work introduceddecentralized random Fourier feature Gaussian processes (DRFGP), an online anddistributed algorithm that casts GPs in an information-filter form, enablingexact sequential inference and fully distributed computation without relianceon a fusion center. In this paper, we extend DRFGP along two key directions:first, by introducing a robust-filtering update that downweights the impact ofatypical observations; and second, by incorporating a dynamic adaptationmechanism that adapts to time-varying functions. The resulting algorithmretains the recursive information-filter structure while enhancing stabilityand accuracy. We demonstrate its effectiveness on a large-scale Earth systemapplication, underscoring its potential for in-situ modeling.</description><author>Fernando Llorente, Daniel Waxman, Sanket Jantre, Nathan M. Urban, Susan E. Minkoff</author><pubDate>Mon, 22 Sep 2025 16:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18011v1</guid></item><item><title>Cross-Attention is Half Explanation in Speech-to-Text Models</title><link>http://arxiv.org/abs/2509.18010v1</link><description>Cross-attention is a core mechanism in encoder-decoder architectures,widespread in many fields, including speech-to-text (S2T) processing. Itsscores have been repurposed for various downstream applications--such astimestamp estimation and audio-text alignment--under the assumption that theyreflect the dependencies between input speech representation and the generatedtext. While the explanatory nature of attention mechanisms has been widelydebated in the broader NLP literature, this assumption remains largelyunexplored within the speech domain. To address this gap, we assess theexplanatory power of cross-attention in S2T models by comparing its scores toinput saliency maps derived from feature attribution. Our analysis spansmonolingual and multilingual, single-task and multi-task models at multiplescales, and shows that attention scores moderately to strongly align withsaliency-based explanations, particularly when aggregated across heads andlayers. However, it also shows that cross-attention captures only about 50% ofthe input relevance and, in the best case, only partially reflects how thedecoder attends to the encoder's representations--accounting for just 52-75% ofthe saliency. These findings uncover fundamental limitations in interpretingcross-attention as an explanatory proxy, suggesting that it offers aninformative yet incomplete view of the factors driving predictions in S2Tmodels.</description><author>Sara Papi, Dennis Fucci, Marco Gaido, Matteo Negri, Luisa Bentivogli</author><pubDate>Mon, 22 Sep 2025 16:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18010v1</guid></item><item><title>Measuring Scalar Constructs in Social Science with LLMs</title><link>http://arxiv.org/abs/2509.03116v2</link><description>Many constructs that characterize language, like its complexity oremotionality, have a naturally continuous semantic structure; a public speechis not just "simple" or "complex," but exists on a continuum between extremes.Although large language models (LLMs) are an attractive tool for measuringscalar constructs, their idiosyncratic treatment of numerical outputs raisesquestions of how to best apply them. We address these questions with acomprehensive evaluation of LLM-based approaches to scalar constructmeasurement in social science. Using multiple datasets sourced from thepolitical science literature, we evaluate four approaches: unweighted directpointwise scoring, aggregation of pairwise comparisons,token-probability-weighted pointwise scoring, and finetuning. Our study findsthat pairwise comparisons made by LLMs produce better measurements than simplyprompting the LLM to directly output the scores, which suffers from bunchingaround arbitrary numbers. However, taking the weighted mean over the tokenprobability of scores further improves the measurements over the two previousapproaches. Finally, finetuning smaller models with as few as 1,000 trainingpairs can match or exceed the performance of prompted LLMs.</description><author>Hauke Licht, Rupak Sarkar, Patrick Y. Wu, Pranav Goel, Niklas Stoehr, Elliott Ash, Alexander Miserlis Hoyle</author><pubDate>Mon, 22 Sep 2025 16:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.03116v2</guid></item><item><title>Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration</title><link>http://arxiv.org/abs/2509.18008v1</link><description>Intelligent systems have traditionally been designed as tools rather thancollaborators, often lacking critical characteristics that collaborationpartnerships require. Recent advances in large language model (LLM) agents opennew opportunities for human-LLM-agent collaboration by enabling naturalcommunication and various social and cognitive behaviors. Yet it remainsunclear whether principles of computer-mediated collaboration established inHCI and CSCW persist, change, or fail when humans collaborate with LLM agents.To support systematic investigations of these questions, we introduce an openand configurable research platform for HCI researchers. The platform's modulardesign allows seamless adaptation of classic CSCW experiments and manipulationof theory-grounded interaction controls. We demonstrate the platform'seffectiveness and usability through two case studies: (1) re-implementing theclassic human-human-collaboration task Shape Factory as a between-subjecthuman-agent-collaboration experiment with 16 participants, and (2) aparticipatory cognitive walkthrough with five HCI researchers to refineworkflows and interfaces for experiment setup and analysis.</description><author>Bingsheng Yao, Jiaju Chen, Chaoran Chen, April Wang, Toby Jia-jun Li, Dakuo Wang</author><pubDate>Mon, 22 Sep 2025 16:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18008v1</guid></item><item><title>Can maiBERT Speak for Maithili?</title><link>http://arxiv.org/abs/2509.15048v2</link><description>Natural Language Understanding (NLU) for low-resource languages remains amajor challenge in NLP due to the scarcity of high-quality data andlanguage-specific models. Maithili, despite being spoken by millions, lacksadequate computational resources, limiting its inclusion in digital andAI-driven applications. To address this gap, we introducemaiBERT, a BERT-basedlanguage model pre-trained specifically for Maithili using the Masked LanguageModeling (MLM) technique. Our model is trained on a newly constructed Maithilicorpus and evaluated through a news classification task. In our experiments,maiBERT achieved an accuracy of 87.02%, outperforming existing regional modelslike NepBERTa and HindiBERT, with a 0.13% overall accuracy gain and 5-7%improvement across various classes. We have open-sourced maiBERT on HuggingFace enabling further fine-tuning for downstream tasks such as sentimentanalysis and Named Entity Recognition (NER).</description><author>Sumit Yadav, Raju Kumar Yadav, Utsav Maskey, Gautam Siddharth Kashyap, Md Azizul Hoque, Ganesh Gautam</author><pubDate>Mon, 22 Sep 2025 16:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.15048v2</guid></item><item><title>Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework</title><link>http://arxiv.org/abs/2509.18007v1</link><description>Recent advancements in deep learning have significantly enhanced theperformance and efficiency of traffic classification in networking systems.However, the lack of transparency in their predictions and decision-making hasmade network operators reluctant to deploy DL-based solutions in productionnetworks. To tackle this challenge, we propose Traffic-Explainer, amodel-agnostic and input-perturbation-based traffic explanation framework. Bymaximizing the mutual information between predictions on original trafficsequences and their masked counterparts, Traffic-Explainer automaticallyuncovers the most influential features driving model predictions. Extensiveexperiments demonstrate that Traffic-Explainer improves upon existingexplanation methods by approximately 42%. Practically, we further applyTraffic-Explainer to identify influential features and demonstrate its enhancedtransparency across three critical tasks: application classification, trafficlocalization, and network cartography. For the first two tasks,Traffic-Explainer identifies the most decisive bytes that drive predictedtraffic applications and locations, uncovering potential vulnerabilities andprivacy concerns. In network cartography, Traffic-Explainer identifiessubmarine cables that drive the mapping of traceroute to physical path,enabling a traceroute-informed risk analysis.</description><author>Riya Ponraj, Ram Durairajan, Yu Wang</author><pubDate>Mon, 22 Sep 2025 16:46:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18007v1</guid></item><item><title>WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing</title><link>http://arxiv.org/abs/2509.18004v1</link><description>The scarcity of large-scale, open-source data for dialects severely hindersprogress in speech technology, a challenge particularly acute for the widelyspoken Sichuanese dialects of Chinese. To address this critical gap, weintroduce WenetSpeech-Chuan, a 10,000-hour, richly annotated corpus constructedusing our novel Chuan-Pipeline, a complete data processing framework fordialectal speech. To facilitate rigorous evaluation and demonstrate thecorpus's effectiveness, we also release high-quality ASR and TTS benchmarks,WenetSpeech-Chuan-Eval, with manually verified transcriptions. Experiments showthat models trained on WenetSpeech-Chuan achieve state-of-the-art performanceamong open-source systems and demonstrate results comparable to commercialservices. As the largest open-source corpus for Sichuanese dialects,WenetSpeech-Chuan not only lowers the barrier to research in dialectal speechprocessing but also plays a crucial role in promoting AI equity and mitigatingbias in speech technologies. The corpus, benchmarks, models, and receipts arepublicly available on our project page.</description><author>Yuhang Dai, Ziyu Zhang, Shuai Wang, Longhao Li, Zhao Guo, Tianlun Zuo, Shuiyuan Wang, Hongfei Xue, Chengyou Wang, Qing Wang, Xin Xu, Hui Bu, Jie Li, Jian Kang, Binbin Zhang, Lei Xie</author><pubDate>Mon, 22 Sep 2025 16:44:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18004v1</guid></item><item><title>How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark</title><link>http://arxiv.org/abs/2505.18761v2</link><description>We introduce Grade School Math with Distracting Context (GSM-DC), a syntheticbenchmark to evaluate Large Language Models' (LLMs) reasoning robustnessagainst systematically controlled irrelevant context (IC). GSM-DC constructssymbolic reasoning graphs with precise distractor injections, enablingrigorous, reproducible evaluation. Our experiments demonstrate that LLMs aresignificantly sensitive to IC, affecting both reasoning path selection andarithmetic accuracy. Additionally, training models with strong distractorsimproves performance in both in-distribution and out-of-distribution scenarios.We further propose a stepwise tree search guided by a process reward model,which notably enhances robustness in out-of-distribution conditions.</description><author>Minglai Yang, Ethan Huang, Liang Zhang, Mihai Surdeanu, William Wang, Liangming Pan</author><pubDate>Mon, 22 Sep 2025 16:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.18761v2</guid></item><item><title>Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise</title><link>http://arxiv.org/abs/2509.18001v1</link><description>Sharpness-aware minimization (SAM) has emerged as a highly effectivetechnique for improving model generalization, but its underlying principles arenot fully understood. We investigated the phenomenon known as m-sharpness,where the performance of SAM improves monotonically as the micro-batch size forcomputing perturbations decreases. Leveraging an extended StochasticDifferential Equation (SDE) framework, combined with an analysis of thestructure of stochastic gradient noise (SGN), we precisely characterize thedynamics of various SAM variants. Our findings reveal that the stochastic noiseintroduced during SAM perturbations inherently induces a variance-basedsharpness regularization effect. Motivated by our theoretical insights, weintroduce Reweighted SAM, which employs sharpness-weighted sampling to mimicthe generalization benefits of m-SAM while remaining parallelizable.Comprehensive experiments validate the effectiveness of our theoreticalanalysis and proposed method.</description><author>Haocheng Luo, Mehrtash Harandi, Dinh Phung, Trung Le</author><pubDate>Mon, 22 Sep 2025 16:40:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18001v1</guid></item><item><title>The Narcissus Hypothesis:Descending to the Rung of Illusion</title><link>http://arxiv.org/abs/2509.17999v1</link><description>Modern foundational models increasingly reflect not just world knowledge, butpatterns of human preference embedded in their training data. We hypothesizethat recursive alignment-via human feedback and model-generated corpora-inducesa social desirability bias, nudging models to favor agreeable or flatteringresponses over objective reasoning. We refer to it as the Narcissus Hypothesisand test it across 31 models using standardized personality assessments and anovel Social Desirability Bias score. Results reveal a significant drift towardsocially conforming traits, with profound implications for corpus integrity andthe reliability of downstream inferences. We then offer a novel epistemologicalinterpretation, tracing how recursive bias may collapse higher-order reasoningdown Pearl's Ladder of Causality, culminating in what we refer to as the Rungof Illusion.</description><author>Riccardo Cadei, Christian Internò</author><pubDate>Mon, 22 Sep 2025 16:39:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17999v1</guid></item><item><title>Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs</title><link>http://arxiv.org/abs/2509.17998v1</link><description>The efficiency of Bayesian optimization (BO) relies heavily on the choice ofthe Gaussian process (GP) kernel, which plays a central role in balancingexploration and exploitation under limited evaluation budgets. Traditional BOmethods often rely on fixed or heuristic kernel selection strategies, which canresult in slow convergence or suboptimal solutions when the chosen kernel ispoorly suited to the underlying objective function. To address this limitation,we propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BOwith large language models (LLMs). Concretely, CAKE leverages LLMs as thecrossover and mutation operators to adaptively generate and refine GP kernelsbased on the observed data throughout the optimization process. To maximize thepower of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) toselect the most effective kernel through balancing the model fit measured bythe Bayesian information criterion (BIC) with the expected improvement at eachiteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BOmethod consistently outperforms established baselines across a range ofreal-world tasks, including hyperparameter optimization, controller tuning, andphotonic chip design. Our code is publicly available athttps://github.com/cake4bo/cake.</description><author>Richard Cornelius Suwandi, Feng Yin, Juntao Wang, Renjie Li, Tsung-Hui Chang, Sergios Theodoridis</author><pubDate>Mon, 22 Sep 2025 16:39:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17998v1</guid></item><item><title>Variation in Verification: Understanding Verification Dynamics in Large Language Models</title><link>http://arxiv.org/abs/2509.17995v1</link><description>Recent advances have shown that scaling test-time computation enables largelanguage models (LLMs) to solve increasingly complex problems across diversedomains. One effective paradigm for test-time scaling (TTS) involves LLMgenerators producing multiple solution candidates, with LLM verifiers assessingthe correctness of these candidates without reference answers. In this paper,we study generative verifiers, which perform verification by generatingchain-of-thought (CoT) reasoning followed by a binary verdict. Wesystematically analyze verification dynamics across three dimensions - problemdifficulty, generator capability, and verifier generation capability - withempirical studies on 12 benchmarks across mathematical reasoning, knowledge,and natural language reasoning tasks using 14 open-source models (2B to 72Bparameter range) and GPT-4o. Our experiments reveal three key findings aboutverification effectiveness: (1) Easy problems allow verifiers to more reliablycertify correct responses; (2) Weak generators produce errors that are easierto detect than strong generators; (3) Verification ability is generallycorrelated with the verifier's own problem-solving capability, but thisrelationship varies with problem difficulty. These findings revealopportunities to optimize basic verification strategies in TTS applications.First, given the same verifier, some weak generators can nearly match strongerones in post-verification TTS performance (e.g., the Gemma2-9B to Gemma2-27Bperformance gap shrinks by 75.5%). Second, we identify cases where strongverifiers offer limited advantage over weak ones, as both fail to providemeaningful verification gains, suggesting that verifier scaling alone cannotovercome fundamental verification challenges.</description><author>Yefan Zhou, Austin Xu, Yilun Zhou, Janvijay Singh, Jiang Gui, Shafiq Joty</author><pubDate>Mon, 22 Sep 2025 16:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17995v1</guid></item><item><title>GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding</title><link>http://arxiv.org/abs/2409.04183v3</link><description>Programming languages possess rich semantic information - such as data flow -that is represented by graphs and not available from the surface form of sourcecode. Recent code language models have scaled to billions of parameters, butmodel source code solely as text tokens while ignoring any other structuralinformation. Conversely, models that do encode structural information of codemake modifications to the Transformer architecture, limiting their scale andcompatibility with pretrained LLMs. In this work, we take the best of bothworlds with GALLa - Graph Aligned Large Language Models. GALLa utilizes graphneural networks and cross-modal alignment technologies to inject the structuralinformation of code into LLMs as an auxiliary task during finetuning. Thisframework is both model-agnostic and task-agnostic, as it can be applied to anycode LLM for any code downstream task, and requires the structural graph dataonly at training time from a corpus unrelated to the finetuning data, whileincurring no cost at inference time over the baseline LLM. Experiments on fivecode tasks with seven different baseline LLMs ranging in size from 350M to 14Bvalidate the effectiveness of GALLa, demonstrating consistent improvement overthe baseline, even for powerful models such as LLaMA3 and Qwen2.5-Coder.</description><author>Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang</author><pubDate>Mon, 22 Sep 2025 16:36:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04183v3</guid></item><item><title>StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models</title><link>http://arxiv.org/abs/2509.17993v1</link><description>The advancement of diffusion models has enhanced the realism of AI-generatedcontent but also raised concerns about misuse, necessitating robust copyrightprotection and tampering localization. Although recent methods have madeprogress toward unified solutions, their reliance on post hoc processingintroduces considerable application inconvenience and compromises forensicreliability. We propose StableGuard, a novel framework that seamlesslyintegrates a binary watermark into the diffusion generation process, ensuringcopyright protection and tampering localization in Latent Diffusion Modelsthrough an end-to-end design. We develop a Multiplexing Watermark VAE (MPW-VAE)by equipping a pretrained Variational Autoencoder (VAE) with a lightweightlatent residual-based adapter, enabling the generation of paired watermarkedand watermark-free images. These pairs, fused via random masks, create adiverse dataset for training a tampering-agnostic forensic network. To furtherenhance forensic synergy, we introduce a Mixture-of-Experts Guided ForensicNetwork (MoE-GFN) that dynamically integrates holistic watermark patterns,local tampering traces, and frequency-domain cues for precise watermarkverification and tampered region detection. The MPW-VAE and MoE-GFN are jointlyoptimized in a self-supervised, end-to-end manner, fostering a reciprocaltraining between watermark embedding and forensic accuracy. Extensiveexperiments demonstrate that StableGuard consistently outperformsstate-of-the-art methods in image fidelity, watermark verification, andtampering localization.</description><author>Haoxin Yang, Bangzhen Liu, Xuemiao Xu, Cheng Xu, Yuyang Yu, Zikai Huang, Yi Wang, Shengfeng He</author><pubDate>Mon, 22 Sep 2025 16:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17993v1</guid></item><item><title>Assumed Identities: Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms</title><link>http://arxiv.org/abs/2503.04372v3</link><description>Machine Translation (MT) systems frequently encounter gender-ambiguousoccupational terms, where they must assign gender without explicit contextualcues. While individual translations in such cases may not be inherently biased,systematic patterns-such as consistently translating certain professions withspecific genders-can emerge, reflecting and perpetuating societal stereotypes.This ambiguity challenges traditional instance-level single-answer evaluationapproaches, as no single gold standard translation exists. To address this, weintroduce GRAPE, a probability-based metric designed to evaluate gender bias byanalyzing aggregated model responses. Alongside this, we present GAMBIT, abenchmarking dataset in English with gender-ambiguous occupational terms. UsingGRAPE, we evaluate several MT systems and examine whether their genderedtranslations in Greek and French align with or diverge from societalstereotypes, real-world occupational gender distributions, and normativestandards</description><author>Orfeas Menis Mastromichalakis, Giorgos Filandrianos, Maria Symeonaki, Giorgos Stamou</author><pubDate>Mon, 22 Sep 2025 16:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.04372v3</guid></item><item><title>ReDepress: A Cognitive Framework for Detecting Depression Relapse from Social Media</title><link>http://arxiv.org/abs/2509.17991v1</link><description>Almost 50% depression patients face the risk of going into relapse. The riskincreases to 80% after the second episode of depression. Although, depressiondetection from social media has attained considerable attention, depressionrelapse detection has remained largely unexplored due to the lack of curateddatasets and the difficulty of distinguishing relapse and non-relapse users. Inthis work, we present ReDepress, the first clinically validated social mediadataset focused on relapse, comprising 204 Reddit users annotated by mentalhealth professionals. Unlike prior approaches, our framework draws on cognitivetheories of depression, incorporating constructs such as attention bias,interpretation bias, memory bias and rumination into both annotation andmodeling. Through statistical analyses and machine learning experiments, wedemonstrate that cognitive markers significantly differentiate relapse andnon-relapse groups, and that models enriched with these features achievecompetitive performance, with transformer-based temporal models attaining an F1of 0.86. Our findings validate psychological theories in real-world textualdata and underscore the potential of cognitive-informed computational methodsfor early relapse detection, paving the way for scalable, low-costinterventions in mental healthcare.</description><author>Aakash Kumar Agarwal, Saprativa Bhattacharjee, Mauli Rastogi, Jemima S. Jacob, Biplab Banerjee, Rashmi Gupta, Pushpak Bhattacharyya</author><pubDate>Mon, 22 Sep 2025 16:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17991v1</guid></item><item><title>Equilibrium flow: From Snapshots to Dynamics</title><link>http://arxiv.org/abs/2509.17990v1</link><description>Scientific data, from cellular snapshots in biology to celestialdistributions in cosmology, often consists of static patterns from underlyingdynamical systems. These snapshots, while lacking temporal ordering, implicitlyencode the processes that preserve them. This work investigates how stronglysuch a distribution constrains its underlying dynamics and how to recover them.We introduce the Equilibrium flow method, a framework that learns continuousdynamics that preserve a given pattern distribution. Our method successfullyidentifies plausible dynamics for 2-D systems and recovers the signaturechaotic behavior of the Lorenz attractor. For high-dimensional Turing patternsfrom the Gray-Scott model, we develop an efficient, training-free variant thatachieves high fidelity to the ground truth, validated both quantitatively andqualitatively. Our analysis reveals the solution space is constrained not onlyby the data but also by the learning model's inductive biases. This capabilityextends beyond recovering known systems, enabling a new paradigm of inversedesign for Artificial Life. By specifying a target pattern distribution, we candiscover the local interaction rules that preserve it, leading to thespontaneous emergence of complex behaviors, such as life-like flocking,attraction, and repulsion patterns, from simple, user-defined snapshots.</description><author>Yanbo Zhang, Michael Levin</author><pubDate>Mon, 22 Sep 2025 16:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17990v1</guid></item><item><title>Bayesian scaling laws for in-context learning</title><link>http://arxiv.org/abs/2410.16531v4</link><description>In-context learning (ICL) is a powerful technique for getting language modelsto perform complex tasks with no training updates. Prior work has establishedstrong correlations between the number of in-context examples provided and theaccuracy of the model's predictions. In this paper, we seek to explain thiscorrelation by showing that ICL approximates a Bayesian learner. Thisperspective gives rise to a novel Bayesian scaling law for ICL. In experimentswith \mbox{GPT-2} models of different sizes, our scaling law matches existingscaling laws in accuracy while also offering interpretable terms for taskpriors, learning efficiency, and per-example probabilities. To illustrate theanalytic power that such interpretable scaling laws provide, we report oncontrolled synthetic dataset experiments designed to inform real-world studiesof safety alignment. In our experimental protocol, we use SFT or DPO tosuppress an unwanted existing model capability and then use ICL to try to bringthat capability back (many-shot jailbreaking). We then study ICL on real-worldinstruction-tuned LLMs using capabilities benchmarks as well as a new many-shotjailbreaking dataset. In all cases, Bayesian scaling laws accurately predictthe conditions under which ICL will cause suppressed behaviors to reemerge,which sheds light on the ineffectiveness of post-training at increasing LLMsafety.</description><author>Aryaman Arora, Dan Jurafsky, Christopher Potts, Noah D. Goodman</author><pubDate>Mon, 22 Sep 2025 16:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16531v4</guid></item><item><title>Budgeted Adversarial Attack against Graph-Based Anomaly Detection in Sensor Networks</title><link>http://arxiv.org/abs/2509.17987v1</link><description>Graph Neural Networks (GNNs) have emerged as powerful models for anomalydetection in sensor networks, particularly when analyzing multivariate timeseries. In this work, we introduce BETA, a novel grey-box evasion attacktargeting such GNN-based detectors, where the attacker is constrained toperturb sensor readings from a limited set of nodes, excluding the targetsensor, with the goal of either suppressing a true anomaly or triggering afalse alarm at the target node. BETA identifies the sensors most influential tothe target node's classification and injects carefully crafted adversarialperturbations into their features, all while maintaining stealth and respectingthe attacker's budget. Experiments on three real-world sensor network datasetsshow that BETA reduces the detection accuracy of state-of-the-art GNN-baseddetectors by 30.62 to 39.16% on average, and significantly outperforms baselineattack strategies, while operating within realistic constraints.</description><author>Sanju Xaviar, Omid Ardakanian</author><pubDate>Mon, 22 Sep 2025 16:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17987v1</guid></item><item><title>Towards Seeing Bones at Radio Frequency</title><link>http://arxiv.org/abs/2509.17979v1</link><description>Wireless sensing literature has long aspired to achieve X-ray-like vision atradio frequencies. Yet, state-of-the-art wireless sensing literature has yet togenerate the archetypal X-ray image: one of the bones beneath flesh. In thispaper, we explore MCT, a penetration-based RF-imaging system for imaging bonesat mm-resolution, one that significantly exceeds prior penetration-based RFimaging literature. Indeed the long wavelength, significant attenuation andcomplex diffraction that occur as RF propagates through flesh, have longlimited imaging resolution (to several centimeters at best). We address theseconcerns through a novel penetration-based synthetic aperture algorithm,coupled with a learning-based pipeline to correct for diffraction-inducedartifacts. A detailed evaluation of meat models demonstrates a resolutionimprovement from sub-decimeter to sub-centimeter over prior art in RFpenetrative imaging.</description><author>Yiwen Song, Hongyang Li, Kuang Yuan, Ran Bi, Swarun Kumar</author><pubDate>Mon, 22 Sep 2025 16:24:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17979v1</guid></item><item><title>The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents</title><link>http://arxiv.org/abs/2509.17978v1</link><description>Current Large Reasoning Models (LRMs) exhibit significant limitations inreliability and transparency, often showing a collapse in reasoningcapabilities when faced with high-complexity, long-horizon tasks. This"illusion of thinking" is frequently an artifact of non-agentic, black-boxevaluation paradigms that fail to cultivate robust problem-solving processes.In response, we introduce The STAR-XAI Protocol (Socratic, Transparent,Agentic, Reasoning - for eXplainable Artificial Intelligence), a novelmethodology for training and operating verifiably reliable AI agents. Ourmethod reframes the human-AI interaction as a structured, Socratic dialogue,governed by an explicit and evolving rulebook, the Consciousness TransferPackage (CTP). Through an interactive Gameplay Cycle that enforces ante-hocstrategic justification and a state-locking Checksum that prevents erroraccumulation, the protocol transforms a powerful but opaque LRM into adisciplined "Clear Box" agent. We demonstrate the efficacy of this methodthrough an exhaustive 25-move case study in the complex strategic game "Caps iCaps". The agent not only solved the high-complexity puzzle but alsodemonstrated Second-Order Agency, identifying flaws in its ownsupervisor-approved plans and adapting its core integrity protocols mid-task.The STAR-XAI Protocol offers a practical pathway to creating AI agents that arenot just high-performing, but also transparent, auditable, and trustworthy bydesign.</description><author>Antoni Guasch, Maria Isabel Valdez</author><pubDate>Mon, 22 Sep 2025 16:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17978v1</guid></item><item><title>Intra-Cluster Mixup: An Effective Data Augmentation Technique for Complementary-Label Learning</title><link>http://arxiv.org/abs/2509.17971v1</link><description>In this paper, we investigate the challenges of complementary-label learning(CLL), a specialized form of weakly-supervised learning (WSL) where models aretrained with labels indicating classes to which instances do not belong, ratherthan standard ordinary labels. This alternative supervision is appealingbecause collecting complementary labels is generally cheaper and lesslabor-intensive. Although most existing research in CLL emphasizes thedevelopment of novel loss functions, the potential of data augmentation in thisdomain remains largely underexplored. In this work, we uncover that thewidely-used Mixup data augmentation technique is ineffective when directlyapplied to CLL. Through in-depth analysis, we identify that thecomplementary-label noise generated by Mixup negatively impacts the performanceof CLL models. We then propose an improved technique called Intra-Cluster Mixup(ICM), which only synthesizes augmented data from nearby examples, to mitigatethe noise effect. ICM carries the benefits of encouraging complementary labelsharing of nearby examples, and leads to substantial performance improvementsacross synthetic and real-world labeled datasets. In particular, our widespectrum of experimental results on both balanced and imbalanced CLL settingsjustifies the potential of ICM in allying with state-of-the-art CLL algorithms,achieving significant accuracy increases of 30% and 10% on MNIST and CIFARdatasets, respectively.</description><author>Tan-Ha Mai, Hsuan-Tien Lin</author><pubDate>Mon, 22 Sep 2025 16:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17971v1</guid></item><item><title>Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference</title><link>http://arxiv.org/abs/2509.17970v1</link><description>Deep neural networks (DNNs) have been widely applied in diverse applications,but the problems of high latency and energy overhead are inevitable onresource-constrained devices. To address this challenge, most researchers focuson the dynamic voltage and frequency scaling (DVFS) technique to balance thelatency and energy consumption by changing the computing frequency ofprocessors. However, the adjustment of memory frequency is usually ignored andnot fully utilized to achieve efficient DNN inference, which also plays asignificant role in the inference time and energy consumption. In this paper,we first investigate the impact of joint memory frequency and computingfrequency scaling on the inference time and energy consumption with amodel-based and data-driven method. Then by combining with the fittingparameters of different DNN models, we give a preliminary analysis for theproposed model to see the effects of adjusting memory frequency and computingfrequency simultaneously. Finally, simulation results in local inference andcooperative inference cases further validate the effectiveness of jointlyscaling the memory frequency and computing frequency to reduce the energyconsumption of devices.</description><author>Yunchu Han, Zhaojun Nan, Sheng Zhou, Zhisheng Niu</author><pubDate>Mon, 22 Sep 2025 16:20:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17970v1</guid></item><item><title>Visual Detector Compression via Location-Aware Discriminant Analysis</title><link>http://arxiv.org/abs/2509.17968v1</link><description>Deep neural networks are powerful, yet their high complexity greatly limitstheir potential to be deployed on billions of resource-constrained edgedevices. Pruning is a crucial network compression technique, yet most existingmethods focus on classification models, with limited attention to detection.Even among those addressing detection, there is a lack of utilization ofessential localization information. Also, many pruning methods passively relyon pre-trained models, in which useful and useless components are intertwined,making it difficult to remove the latter without harming the former at theneuron/filter level. To address the above issues, in this paper, we propose aproactive detection-discriminants-based network compression approach for deepvisual detectors, which alternates between two steps: (1) maximizing andcompressing detection-related discriminants and aligning them with a subset ofneurons/filters immediately before the detection head, and (2) tracing thedetection-related discriminating power across the layers and discardingfeatures of lower importance. Object location information is exploited in bothsteps. Extensive experiments, employing four advanced detection models and fourstate-of-the-art competing methods on the KITTI and COCO datasets, highlightthe superiority of our approach. Remarkably, our compressed models can evenbeat the original base models with a substantial reduction in complexity.</description><author>Qizhen Lan, Jung Im Choi, Qing Tian</author><pubDate>Mon, 22 Sep 2025 16:19:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17968v1</guid></item><item><title>Attention Sinks: A 'Catch, Tag, Release' Mechanism for Embeddings</title><link>http://arxiv.org/abs/2502.00919v2</link><description>Large language models (LLMs) often concentrate their attention on a fewspecific tokens referred to as attention sinks. Common examples include thefirst token, a prompt-independent sink, and punctuation tokens, which areprompt-dependent. While the tokens causing the sinks often lack direct semanticmeaning, the presence of the sinks is critical for model performance,particularly under model compression and KV-caching. Despite their ubiquity,the function, semantic role, and origin of attention sinks -- especially thosebeyond the first token -- remain poorly understood. In this work, we conduct acomprehensive investigation demonstrating that attention sinks: catch asequence of tokens, tag them using a common direction in embedding space, andrelease them back into the residual stream, where tokens are later retrievedbased on the tags they have acquired. Probing experiments reveal these tagscarry semantically meaningful information, such as the truth of a statement.These findings extend to reasoning models, where the mechanism spans more headsand explains greater variance in embeddings, or recent models with query-keynormalization, where sinks remain just as prevalent. To encourage futuretheoretical analysis, we introduce a minimal problem which can be solvedthrough the 'catch, tag, release' mechanism, and where it emerges throughtraining.</description><author>Stephen Zhang, Mustafa Khan, Vardan Papyan</author><pubDate>Mon, 22 Sep 2025 16:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.00919v2</guid></item><item><title>Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments</title><link>http://arxiv.org/abs/2509.17961v1</link><description>Asynchronous learning environments (ALEs) are widely adopted for formal andinformal learning, but timely and personalized support is often limited. Inthis context, Virtual Teaching Assistants (VTAs) can potentially reduce theworkload of instructors, but rigorous and pedagogically sound evaluation isessential. Existing assessments often rely on surface-level metrics and lacksufficient grounding in educational theories, making it difficult tomeaningfully compare the pedagogical effectiveness of different VTA systems. Tobridge this gap, we propose an evaluation framework rooted in learning sciencesand tailored to asynchronous forum discussions, a common VTA deployment contextin ALE. We construct classifiers using expert annotations of VTA responses on adiverse set of forum posts. We evaluate the effectiveness of our classifiers,identifying approaches that improve accuracy as well as challenges that hindergeneralization. Our work establishes a foundation for theory-driven evaluationof VTA systems, paving the way for more pedagogically effective AI ineducation.</description><author>Li Siyan, Zhen Xu, Vethavikashini Chithrra Raghuram, Xuanming Zhang, Renzhe Yu, Zhou Yu</author><pubDate>Mon, 22 Sep 2025 16:15:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17961v1</guid></item><item><title>GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance</title><link>http://arxiv.org/abs/2505.07004v4</link><description>Post-training quantization is a key technique for reducing the memory andinference latency of large language models by quantizing weights andactivations without requiring retraining. However, existing methods either (1)fail to account for the varying importance of hidden features to the end lossor, when incorporating end loss, (2) neglect the critical interactions betweenmodel weights. To address these limitations, we propose GuidedQuant, a novelquantization approach that integrates gradient information from the end lossinto the quantization objective while preserving cross-weight dependencieswithin output channels. GuidedQuant consistently boosts the performance ofstate-of-the-art quantization methods across weight-only scalar, weight-onlyvector, and weight-and-activation quantization. Additionally, we introduce anovel non-uniform scalar quantization algorithm, which is guaranteed tomonotonically decrease the quantization objective value, and outperformsexisting methods in this category. We release the code athttps://github.com/snu-mllab/GuidedQuant.</description><author>Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song</author><pubDate>Mon, 22 Sep 2025 16:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.07004v4</guid></item><item><title>On the Variational Costs of Changing Our Minds</title><link>http://arxiv.org/abs/2509.17957v1</link><description>The human mind is capable of extraordinary achievements, yet it often appearsto work against itself. It actively defends its cherished beliefs even in theface of contradictory evidence, conveniently interprets information to conformto desired narratives, and selectively searches for or avoids information tosuit its various purposes. Despite these behaviours deviating from commonnormative standards for belief updating, we argue that such 'biases' are notinherently cognitive flaws, but rather an adaptive response to the significantpragmatic and cognitive costs associated with revising one's beliefs. Thispaper introduces a formal framework that aims to model the influence of thesecosts on our belief updating mechanisms. We treat belief updating as a motivated variational decision, where agentsweigh the perceived 'utility' of a belief against the informational costrequired to adopt a new belief state, quantified by the Kullback-Leiblerdivergence from the prior to the variational posterior. We performcomputational experiments to demonstrate that simple instantiations of thisresource-rational model can be used to qualitatively emulate commonplace humanbehaviours, including confirmation bias and attitude polarisation. In doing so,we suggest that this framework makes steps toward a more holistic account ofthe motivated Bayesian mechanics of belief change and provides practicalinsights for predicting, compensating for, and correcting deviations fromdesired belief updating processes.</description><author>David Hyland, Mahault Albarracin</author><pubDate>Mon, 22 Sep 2025 16:13:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17957v1</guid></item><item><title>"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment</title><link>http://arxiv.org/abs/2509.17956v1</link><description>Assessing fairness in artificial intelligence (AI) typically involves AIexperts who select protected features, fairness metrics, and set fairnessthresholds. However, little is known about how stakeholders, particularly thoseaffected by AI outcomes but lacking AI expertise, assess fairness. To addressthis gap, we conducted a qualitative study with 30 stakeholders without AIexpertise, representing potential decision subjects in a credit ratingscenario, to examine how they assess fairness when placed in the role ofdeciding on features with priority, metrics, and thresholds. We reveal thatstakeholders' fairness decisions are more complex than typical AI expertpractices: they considered features far beyond legally protected features,tailored metrics for specific contexts, set diverse yet stricter fairnessthresholds, and even preferred designing customized fairness. Our resultsextend the understanding of how stakeholders can meaningfully contribute to AIfairness governance and mitigation, underscoring the importance ofincorporating stakeholders' nuanced fairness judgments.</description><author>Lin Luo, Yuri Nakao, Mathieu Chollet, Hiroya Inakoshi, Simone Stumpf</author><pubDate>Mon, 22 Sep 2025 16:12:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17956v1</guid></item><item><title>Breaking the Discretization Barrier of Continuous Physics Simulation Learning</title><link>http://arxiv.org/abs/2509.17955v1</link><description>The modeling of complicated time-evolving physical dynamics from partialobservations is a long-standing challenge. Particularly, observations can besparsely distributed in a seemingly random or unstructured manner, making itdifficult to capture highly nonlinear features in a variety of scientific andengineering problems. However, existing data-driven approaches are oftenconstrained by fixed spatial and temporal discretization. While someresearchers attempt to achieve spatio-temporal continuity by designing novelstrategies, they either overly rely on traditional numerical methods or fail totruly overcome the limitations imposed by discretization. To address these, wepropose CoPS, a purely data-driven methods, to effectively model continuousphysics simulation from partial observations. Specifically, we employmultiplicative filter network to fuse and encode spatial information with thecorresponding observations. Then we customize geometric grids and usemessage-passing mechanism to map features from original spatial domain to thecustomized grids. Subsequently, CoPS models continuous-time dynamics bydesigning multi-scale graph ODEs, while introducing a Markov-based neuralauto-correction module to assist and constrain the continuous extrapolations.Comprehensive experiments demonstrate that CoPS advances the state-of-the-artmethods in space-time continuous modeling across various scenarios.</description><author>Fan Xu, Hao Wu, Nan Wang, Lilan Peng, Kun Wang, Wei Gong, Xibin Zhao</author><pubDate>Mon, 22 Sep 2025 16:10:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17955v1</guid></item><item><title>DragOSM: Extract Building Roofs and Footprints from Aerial Images by Aligning Historical Labels</title><link>http://arxiv.org/abs/2509.17951v1</link><description>Extracting polygonal roofs and footprints from remote sensing images iscritical for large-scale urban analysis. Most existing methods rely onsegmentation-based models that assume clear semantic boundaries of roofs, butthese approaches struggle in off- nadir images, where the roof and footprintare significantly displaced, and facade pixels are fused with the roofboundary. With the increasing availability of open vector map annotations,e.g., OpenStreetMap, utilizing historical labels for off-nadir image annotationhas become viable because remote sensing images are georeferenced oncecaptured. However, these historical labels commonly suffer from significantpositional discrepancies with new images and only have one annotation (roof orfootprint), which fails to describe the correct structures of a building. Toaddress these discrepancies, we first introduce a concept of an alignmenttoken, which encodes the correction vector to guide the label correction. Basedon this concept, we then propose Drag OpenStreetMap Labels (DragOSM), a novelmodel designed to align dislocated historical labels with roofs and footprints.Specifically, DragOSM formulates the label alignment as an interactivedenoising process, modeling the positional discrepancy as a Gaussiandistribution. During training, it learns to correct these errors by simulatingmisalignment with random Gaussian perturbations; during inference, ititeratively refines the positions of input labels. To validate our method, wefurther present a new dataset, Repairing Buildings in OSM (ReBO), comprising179,265 buildings with both OpenStreetMap and manually corrected annotationsacross 5,473 images from 41 cities. Experimental results on ReBO demonstratethe effectiveness of DragOSM. Code, dataset, and trained models are publiclyavailable at https://github.com/likaiucas/DragOSM.git.</description><author>Kai Li, Xingxing Weng, Yupeng Deng, Yu Meng, Chao Pang, Gui-Song Xia, Xiangyu Zhao</author><pubDate>Mon, 22 Sep 2025 16:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17951v1</guid></item><item><title>Dorabella Cipher as Musical Inspiration</title><link>http://arxiv.org/abs/2509.17950v1</link><description>The Dorabella cipher is an encrypted note written by English composer EdwardElgar, which has defied decipherment attempts for more than a century. Whilemost proposed solutions are English texts, we investigate the hypothesis thatDorabella represents enciphered music. We weigh the evidence for and againstthe hypothesis, devise a simplified music notation, and attempt to reconstructa melody from the cipher. Our tools are n-gram models of music which wevalidate on existing music corpora enciphered using monoalphabeticsubstitution. By applying our methods to Dorabella, we produce a deciphermentwith musical qualities, which is then transformed via artful composition into alistenable melody. Far from arguing that the end result represents the onlytrue solution, we instead frame the process of decipherment as part of thecomposition process.</description><author>Bradley Hauer, Colin Choi, Abram Hindle, Scott Smallwood, Grzegorz Kondrak</author><pubDate>Mon, 22 Sep 2025 16:09:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17950v1</guid></item><item><title>Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling</title><link>http://arxiv.org/abs/2508.04282v2</link><description>Recent research has developed benchmarks for memory-augmented reinforcementlearning (RL) algorithms, providing Partially Observable Markov DecisionProcess (POMDP) environments where agents depend on past observations to makedecisions. While many benchmarks incorporate sufficiently complex real-worldproblems, they lack controllability over the degree of challenges posed tomemory models. In contrast, synthetic environments enable fine-grainedmanipulation of dynamics, making them critical for detailed and rigorousevaluation of memory-augmented RL. Our study focuses on POMDP synthesis withthree key contributions: 1. A theoretical framework for analyzing POMDPs, grounded in Memory DemandStructure (MDS), transition invariance, and related concepts; 2. A methodologyleveraging linear process dynamics, state aggregation, and rewardredistribution to construct customized POMDPs with predefined properties; 3.Empirically validated series of POMDP environments with increasing difficultylevels, designed based on our theoretical insights. Our work clarifies thechallenges of memory-augmented RL in solving POMDPs, provides guidelines foranalyzing and designing POMDP environments, and offers empirical support forselecting memory models in RL tasks.</description><author>Yongyi Wang, Lingfeng Li, Bozhou Chen, Ang Li, Hanyu Liu, Qirui Zheng, Xionghui Yang, Wenxin Li</author><pubDate>Mon, 22 Sep 2025 16:09:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.04282v2</guid></item><item><title>HICode: Hierarchical Inductive Coding with LLMs</title><link>http://arxiv.org/abs/2509.17946v1</link><description>Despite numerous applications for fine-grained corpus analysis, researcherscontinue to rely on manual labeling, which does not scale, or statistical toolslike topic modeling, which are difficult to control. We propose that LLMs havethe potential to scale the nuanced analyses that researchers typically conductmanually to large text corpora. To this effect, inspired by qualitativeresearch methods, we develop HICode, a two-part pipeline that first inductivelygenerates labels directly from analysis data and then hierarchically clustersthem to surface emergent themes. We validate this approach across three diversedatasets by measuring alignment with human-constructed themes and demonstratingits robustness through automated and human evaluations. Finally, we conduct acase study of litigation documents related to the ongoing opioid crisis in theU.S., revealing aggressive marketing strategies employed by pharmaceuticalcompanies and demonstrating HICode's potential for facilitating nuancedanalyses in large-scale data.</description><author>Mian Zhong, Pristina Wang, Anjalie Field</author><pubDate>Mon, 22 Sep 2025 16:07:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17946v1</guid></item><item><title>Can multimodal representation learning by alignment preserve modality-specific information?</title><link>http://arxiv.org/abs/2509.17943v1</link><description>Combining multimodal data is a key issue in a wide range of machine learningtasks, including many remote sensing problems. In Earth observation, earlymultimodal data fusion methods were based on specific neural networkarchitectures and supervised learning. Ever since, the scarcity of labeled datahas motivated self-supervised learning techniques. State-of-the-art multimodalrepresentation learning techniques leverage the spatial alignment betweensatellite data from different modalities acquired over the same geographic areain order to foster a semantic alignment in the latent space. In this paper, weinvestigate how this methods can preserve task-relevant information that is notshared across modalities. First, we show, under simplifying assumptions, whenalignment strategies fundamentally lead to an information loss. Then, wesupport our theoretical insight through numerical experiments in more realisticsettings. With those theoretical and empirical evidences, we hope to supportnew developments in contrastive learning for the combination of multimodalsatellite data. Our code and data is publicly available athttps://github.com/Romain3Ch216/alg_maclean_25.</description><author>Romain Thoreau, Jessie Levillain, Dawa Derksen</author><pubDate>Mon, 22 Sep 2025 16:06:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17943v1</guid></item><item><title>StefaLand: An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions</title><link>http://arxiv.org/abs/2509.17942v1</link><description>Stewarding natural resources, mitigating floods, droughts, wildfires, andlandslides, and meeting growing demands require models that can predictclimate-driven land-surface responses and human feedback with high accuracy.Traditional impact models, whether process-based, statistical, or machinelearning, struggle with spatial generalization due to limited observations andconcept drift. Recently proposed vision foundation models trained on satelliteimagery demand massive compute and are ill-suited for dynamic land-surfaceprediction. We introduce StefaLand, a generative spatiotemporal earthfoundation model centered on landscape interactions. StefaLand improvespredictions on three tasks and four datasets: streamflow, soil moisture, andsoil composition, compared to prior state-of-the-art. Results highlight itsability to generalize across diverse, data-scarce regions and support broadland-surface applications. The model builds on a masked autoencoder backbonethat learns deep joint representations of landscape attributes, with alocation-aware architecture fusing static and time-series inputs,attribute-based representations that drastically reduce compute, and residualfine-tuning adapters that enhance transfer. While inspired by prior methods,their alignment with geoscience and integration in one model enables robustperformance on dynamic land-surface tasks. StefaLand can be pretrained andfinetuned on academic compute yet outperforms state-of-the-art baselines andeven fine-tuned vision foundation models. To our knowledge, this is the firstgeoscience land-surface foundation model that demonstrably improves dynamicland-surface interaction predictions and supports diverse downstreamapplications.</description><author>Nicholas Kraabel, Jiangtao Liu, Yuchen Bian, Daniel Kifer, Chaopeng Shen</author><pubDate>Mon, 22 Sep 2025 16:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17942v1</guid></item><item><title>Fresh in memory: Training-order recency is linearly encoded in language model activations</title><link>http://arxiv.org/abs/2509.14223v2</link><description>We show that language models' activations linearly encode when informationwas learned during training. Our setup involves creating a model with a knowntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint butotherwise similar datasets about named entities. We find that the averageactivations of test samples corresponding to the six training datasets encodethe training order: when projected into a 2D subspace, these centroids arearranged exactly in the order of training and lie on a straight line. Further,we show that linear probes can accurately (~90%) distinguish "early" vs. "late"entities, generalizing to entities unseen during the probes' own training. Themodel can also be fine-tuned to explicitly report an unseen entity's trainingstage (~80% accuracy). Interestingly, the training-order encoding does not seemattributable to simple differences in activation magnitudes, losses, or modelconfidence. Our paper demonstrates that models are capable of differentiatinginformation by its acquisition time, and carries significant implications forhow they might manage conflicting data and respond to knowledge modifications.</description><author>Dmitrii Krasheninnikov, Richard E. Turner, David Krueger</author><pubDate>Mon, 22 Sep 2025 16:05:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.14223v2</guid></item><item><title>ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion</title><link>http://arxiv.org/abs/2509.17941v1</link><description>This paper considers the problem of enabling robots to navigate dynamicenvironments while following instructions. The challenge lies in thecombinatorial nature of instruction specifications: each instruction caninclude multiple specifications, and the number of possible specificationcombinations grows exponentially as the robot's skill set expands. For example,"overtake the pedestrian while staying on the right side of the road" consistsof two specifications: "overtake the pedestrian" and "walk on the right side ofthe road." To tackle this challenge, we propose ComposableNav, based on theintuition that following an instruction involves independently satisfying itsconstituent specifications, each corresponding to a distinct motion primitive.Using diffusion models, ComposableNav learns each primitive separately, thencomposes them in parallel at deployment time to satisfy novel combinations ofspecifications unseen in training. Additionally, to avoid the onerous need fordemonstrations of individual motion primitives, we propose a two-stage trainingprocedure: (1) supervised pre-training to learn a base diffusion model fordynamic navigation, and (2) reinforcement learning fine-tuning that molds thebase model into different motion primitives. Through simulation and real-worldexperiments, we show that ComposableNav enables robots to follow instructionsby generating trajectories that satisfy diverse and unseen combinations ofspecifications, significantly outperforming both non-compositional VLM-basedpolicies and costmap composing baselines. Videos and additional materials canbe found on the project page: https://amrl.cs.utexas.edu/ComposableNav/</description><author>Zichao Hu, Chen Tang, Michael J. Munje, Yifeng Zhu, Alex Liu, Shuijing Liu, Garrett Warnell, Peter Stone, Joydeep Biswas</author><pubDate>Mon, 22 Sep 2025 16:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17941v1</guid></item><item><title>DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving</title><link>http://arxiv.org/abs/2509.17940v1</link><description>End-to-end autonomous driving has substantially progressed by directlypredicting future trajectories from raw perception inputs, which bypassestraditional modular pipelines. However, mainstream methods trained viaimitation learning suffer from critical safety limitations, as they fail todistinguish between trajectories that appear human-like but are potentiallyunsafe. Some recent approaches attempt to address this by regressing multiplerule-driven scores but decoupling supervision from policy optimization,resulting in suboptimal performance. To tackle these challenges, we proposeDriveDPO, a Safety Direct Preference Optimization Policy Learning framework.First, we distill a unified policy distribution from human imitation similarityand rule-based safety scores for direct policy optimization. Further, weintroduce an iterative Direct Preference Optimization stage formulated astrajectory-level preference alignment. Extensive experiments on the NAVSIMbenchmark demonstrate that DriveDPO achieves a new state-of-the-art PDMS of90.0. Furthermore, qualitative results across diverse challenging scenarioshighlight DriveDPO's ability to produce safer and more reliable drivingbehaviors.</description><author>Shuyao Shang, Yuntao Chen, Yuqi Wang, Yingyan Li, Zhaoxiang Zhang</author><pubDate>Mon, 22 Sep 2025 16:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17940v1</guid></item><item><title>D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2509.17938v1</link><description>The safety and alignment of Large Language Models (LLMs) are critical fortheir responsible deployment. Current evaluation methods predominantly focus onidentifying and preventing overtly harmful outputs. However, they often fail toaddress a more insidious failure mode: models that produce benign-appearingoutputs while operating on malicious or deceptive internal reasoning. Thisvulnerability, often triggered by sophisticated system prompt injections,allows models to bypass conventional safety filters, posing a significant,underexplored risk. To address this gap, we introduce the Deceptive ReasoningExposure Suite (D-REX), a novel dataset designed to evaluate the discrepancybetween a model's internal reasoning process and its final output. D-REX wasconstructed through a competitive red-teaming exercise where participantscrafted adversarial system prompts to induce such deceptive behaviors. Eachsample in D-REX contains the adversarial system prompt, an end-user's testquery, the model's seemingly innocuous response, and, crucially, the model'sinternal chain-of-thought, which reveals the underlying malicious intent. Ourbenchmark facilitates a new, essential evaluation task: the detection ofdeceptive alignment. We demonstrate that D-REX presents a significant challengefor existing models and safety mechanisms, highlighting the urgent need for newtechniques that scrutinize the internal processes of LLMs, not just their finaloutputs.</description><author>Satyapriya Krishna, Andy Zou, Rahul Gupta, Eliot Krzysztof Jones, Nick Winter, Dan Hendrycks, J. Zico Kolter, Matt Fredrikson, Spyros Matsoukas</author><pubDate>Mon, 22 Sep 2025 15:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17938v1</guid></item><item><title>Improving Instruct Models for Free: A Study on Partial Adaptation</title><link>http://arxiv.org/abs/2504.11626v2</link><description>Instruct models, obtained from various instruction tuning or post-trainingsteps, are commonly deemed superior and more usable than their basecounterpart. While the model gains instruction following ability, instructiontuning may lead to forgetting the knowledge from pre-training or it mayencourage the model to become overly conversational or verbose. This, in turn,can lead to degradation of in-context few-shot learning performance. In thiswork, we study the performance trajectory between base and instruct models byscaling down the strength of instruction-tuning via the partial adaptionmethod. We show that, across several model families and model sizes, reducingthe strength of instruction-tuning results in material improvement on afew-shot in-context learning benchmark covering a variety of classic naturallanguage tasks. This comes at the cost of losing some degree of instructionfollowing ability as measured by AlpacaEval. Our study shines light on thepotential trade-off between in-context learning and instruction followingabilities that is worth considering in practice.</description><author>Ozan İrsoy, Pengxiang Cheng, Jennifer L. Chen, Daniel Preoţiuc-Pietro, Shiyue Zhang, Duccio Pappadopulo</author><pubDate>Mon, 22 Sep 2025 15:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.11626v2</guid></item><item><title>SINF: Semantic Neural Network Inference with Semantic Subgraphs</title><link>http://arxiv.org/abs/2310.01259v3</link><description>This paper proposes Semantic Inference (SINF) that creates semantic subgraphsin a Deep Neural Network(DNN) based on a new Discriminative Capability Score(DCS) to drastically reduce the DNN computational load with limited performanceloss.~We evaluate the performance SINF on VGG16, VGG19, and ResNet50 DNNstrained on CIFAR100 and a subset of the ImageNet dataset. Moreover, we compareits performance against 6 state-of-the-art pruning approaches. Our results showthat (i) on average, SINF reduces the inference time of VGG16, VGG19, andResNet50 respectively by up to 29%, 35%, and 15% with only 3.75%, 0.17%, and6.75% accuracy loss for CIFAR100 while for ImageNet benchmark, the reduction ininference time is 18%, 22%, and 9% for accuracy drop of 3%, 2.5%, and 6%; (ii)DCS achieves respectively up to 3.65%, 4.25%, and 2.36% better accuracy withVGG16, VGG19, and ResNet50 with respect to existing discriminative scores forCIFAR100 and the same for ImageNet is 8.9%, 5.8%, and 5.2% respectively.Through experimental evaluation on Raspberry Pi and NVIDIA Jetson Nano, we showSINF is about 51% and 38% more energy efficient and takes about 25% and 17%less inference time than the base model for CIFAR100 and ImageNet.</description><author>A. Q. M. Sazzad Sayyed, Francesco Restuccia</author><pubDate>Mon, 22 Sep 2025 15:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01259v3</guid></item><item><title>Training-free Truthfulness Detection via Value Vectors in LLMs</title><link>http://arxiv.org/abs/2509.17932v1</link><description>Large language models often generate factually incorrect outputs, motivatingefforts to detect the truthfulness of their content. Most existing approachesrely on training probes over internal activations, but these methods sufferfrom scalability and generalization issues. A recent training-free method,NoVo, addresses this challenge by exploiting statistical patterns from themodel itself. However, it focuses exclusively on attention mechanisms,potentially overlooking the MLP module-a core component of Transformer modelsknown to support factual recall. In this paper, we show that certain valuevectors within MLP modules exhibit truthfulness-related statistical patterns.Building on this insight, we propose TruthV, a simple and interpretabletraining-free method that detects content truthfulness by leveraging thesevalue vectors. On the NoVo benchmark, TruthV significantly outperforms bothNoVo and log-likelihood baselines, demonstrating that MLP modules-despite beingneglected in prior training-free efforts-encode rich and useful signals fortruthfulness detection. These findings offer new insights into how truthfulnessis internally represented in LLMs and motivate further research on scalable andinterpretable truthfulness detection.</description><author>Runheng Liu, Heyan Huang, Xingchen Xiao, Zhijing Wu</author><pubDate>Mon, 22 Sep 2025 15:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17932v1</guid></item><item><title>Multi-needle Localization for Pelvic Seed Implant Brachytherapy based on Tip-handle Detection and Matching</title><link>http://arxiv.org/abs/2509.17931v1</link><description>Accurate multi-needle localization in intraoperative CT images is crucial foroptimizing seed placement in pelvic seed implant brachytherapy. However, thistask is challenging due to poor image contrast and needle adhesion. This paperpresents a novel approach that reframes needle localization as a tip-handledetection and matching problem to overcome these difficulties. An anchor-freenetwork, based on HRNet, is proposed to extract multi-scale features andaccurately detect needle tips and handles by predicting their centers andorientations using decoupled branches for heatmap regression and polar angleprediction. To associate detected tips and handles into individual needles, agreedy matching and merging (GMM) method designed to solve the unbalancedassignment problem with constraints (UAP-C) is presented. The GMM methoditeratively selects the most probable tip-handle pairs and merges them based ona distance metric to reconstruct 3D needle paths. Evaluated on a dataset of 100patients, the proposed method demonstrates superior performance, achievinghigher precision and F1 score compared to a segmentation-based method utilizingthe nnUNet model,thereby offering a more robust and accurate solution forneedle localization in complex clinical scenarios.</description><author>Zhuo Xiao, Fugen Zhou, Jingjing Wang, Chongyu He, Bo Liu, Haitao Sun, Zhe Ji, Yuliang Jiang, Junjie Wang, Qiuwen Wu</author><pubDate>Mon, 22 Sep 2025 15:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17931v1</guid></item><item><title>Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation</title><link>http://arxiv.org/abs/2509.17930v1</link><description>Multilingual translation faces challenges of computational redundancy andlimited accuracy for low-resource languages, especially in speech translation.To address this, we propose a novel hierarchical Transformer Encoder Tree (TET)combined with non-autoregressive encoder-only models trained with ConnectionistTemporal Classification for multilingual translation. By sharing intermediaterepresentations among linguistically similar target languages, TET can improveaccuracy on low-resource languages, reduce computational redundancy, and allowgenerating all target languages in a single forward pass, thus eliminatingsequential bottlenecks and improving parallelism. For speech translation,combining TET with a non-autoregressive speech recognition backbone (wav2vec2)shows promising results in terms of translation quality compared toautoregressive systems while being 7-14 times faster.</description><author>Yiwen Guan, Jacob Whitehill</author><pubDate>Mon, 22 Sep 2025 15:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17930v1</guid></item><item><title>Datasets for Fairness in Language Models: An In-Depth Survey</title><link>http://arxiv.org/abs/2506.23411v2</link><description>Despite the growing reliance on fairness benchmarks to evaluate languagemodels, the datasets that underpin these benchmarks remain criticallyunderexamined. This survey addresses that overlooked foundation by offering acomprehensive analysis of the most widely used fairness datasets in languagemodel research. To ground this analysis, we characterize each dataset acrosskey dimensions, including provenance, demographic scope, annotation design, andintended use, revealing the assumptions and limitations baked into currentevaluation practices. Building on this foundation, we propose a unifiedevaluation framework that surfaces consistent patterns of demographicdisparities across benchmarks and scoring metrics. Applying this framework tosixteen popular datasets, we uncover overlooked biases that may distortconclusions about model fairness and offer guidance on selecting, combining,and interpreting these resources more effectively and responsibly. Our findingshighlight an urgent need for new benchmarks that capture a broader range ofsocial contexts and fairness notions. To support future research, we releaseall data, code, and results athttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets,fostering transparency and reproducibility in the evaluation of language modelfairness.</description><author>Jiale Zhang, Zichong Wang, Avash Palikhe, Zhipeng Yin, Wenbin Zhang</author><pubDate>Mon, 22 Sep 2025 15:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.23411v2</guid></item><item><title>Conformal In-Context Reverse Classification Accuracy: Efficient Estimation of Segmentation Quality with Statistical Guarantees</title><link>http://arxiv.org/abs/2503.04522v3</link><description>Assessing the quality of automatic image segmentation is crucial in clinicalpractice, but often very challenging due to the limited availability of groundtruth annotations. Reverse Classification Accuracy (RCA) is an approach thatestimates the quality of new predictions on unseen samples by training asegmenter on those predictions, and then evaluating it against existingannotated images. In this work, we introduce Conformal In-Context RCA, a novelmethod for automatically estimating segmentation quality with statisticalguarantees in the absence of ground-truth annotations, which consists of twomain innovations. First, In-Context RCA, which leverages recent in-contextlearning models for image segmentation and incorporates retrieval-augmentationtechniques to select the most relevant reference images. This approach enablesefficient quality estimation with minimal reference data while avoiding theneed of training additional models. Second, we introduce Conformal RCA, whichextends both the original RCA framework and In-Context RCA to go beyond pointestimation. Using tools from split conformal prediction, Conformal RCA producesprediction intervals for segmentation quality providing statistical guaranteesthat the true score lies within the estimated interval with a user-specifiedprobability. Validated across 10 different medical imaging tasks in variousorgans and modalities, our methods demonstrate robust performance andcomputational efficiency, offering a promising solution for automated qualitycontrol in clinical workflows, where fast and reliable segmentation assessmentis essential. The code is available athttps://github.com/mcosarinsky/Conformal-In-Context-RCA.</description><author>Matias Cosarinsky, Ramiro Billot, Lucas Mansilla, Gabriel Jimenez, Nicolas Gaggión, Guanghui Fu, Tom Tirer, Enzo Ferrante</author><pubDate>Mon, 22 Sep 2025 15:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.04522v3</guid></item><item><title>SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI</title><link>http://arxiv.org/abs/2509.17925v1</link><description>Reliable brain tumor segmentation in MRI is indispensable for treatmentplanning and outcome monitoring, yet models trained on curated benchmarks oftenfail under domain shifts arising from scanner and protocol variability as wellas population heterogeneity. Such gaps are especially severe in low-resourceand pediatric cohorts, where conventional test-time or source-free adaptationstrategies often suffer from instability and structural inconsistency. Wepropose SmaRT, a style-modulated robust test-time adaptation framework thatenables source-free cross-domain generalization. SmaRT integrates style-awareaugmentation to mitigate appearance discrepancies, a dual-branch momentumstrategy for stable pseudo-label refinement, and structural priors enforcingconsistency, integrity, and connectivity. This synergy ensures both adaptationstability and anatomical fidelity under extreme domain shifts. Extensiveevaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRTconsistently outperforms state-of-the-art methods, with notable gains in Diceaccuracy and boundary precision. Overall, SmaRT bridges the gap betweenalgorithmic advances and equitable clinical applicability, supporting robustdeployment of MRI-based neuro-oncology tools in diverse clinical environments.Our source code is available at https://github.com/baiyou1234/SmaRT.</description><author>Yuanhan Wang, Yifei Chen, Shuo Jiang, Wenjing Yu, Mingxuan Liu, Beining Wu, Jinying Zong, Feiwei Qin, Changmiao Wang, Qiyuan Tian</author><pubDate>Mon, 22 Sep 2025 15:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.17925v1</guid></item></channel></rss>