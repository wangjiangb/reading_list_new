<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 26 Aug 2025 01:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>MV-RAG: Retrieval Augmented Multiview Diffusion</title><link>http://arxiv.org/abs/2508.16577v1</link><description>Text-to-3D generation approaches have advanced significantly by leveragingpretrained 2D diffusion priors, producing high-quality and 3D-consistentoutputs. However, they often fail to produce out-of-domain (OOD) or rareconcepts, yielding inconsistent or inaccurate results. To this end, we proposeMV-RAG, a novel text-to-3D pipeline that first retrieves relevant 2D imagesfrom a large in-the-wild 2D database and then conditions a multiview diffusionmodel on these images to synthesize consistent and accurate multiview outputs.Training such a retrieval-conditioned model is achieved via a novel hybridstrategy bridging structured multiview data and diverse 2D image collections.This involves training on multiview data using augmented conditioning viewsthat simulate retrieval variance for view-specific reconstruction, alongsidetraining on sets of retrieved real-world 2D images using a distinctive held-outview prediction objective: the model predicts the held-out view from the otherviews to infer 3D consistency from 2D data. To facilitate a rigorous OODevaluation, we introduce a new collection of challenging OOD prompts.Experiments against state-of-the-art text-to-3D, image-to-3D, andpersonalization baselines show that our approach significantly improves 3Dconsistency, photorealism, and text adherence for OOD/rare concepts, whilemaintaining competitive performance on standard benchmarks.</description><author>Yosef Dayani, Omer Benishu, Sagie Benaim</author><pubDate>Fri, 22 Aug 2025 17:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16577v1</guid></item><item><title>Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet</title><link>http://arxiv.org/abs/2508.16576v1</link><description>Despite advancements in ASR, child speech recognition remains challenging dueto acoustic variability and limited annotated data. While fine-tuning adult ASRmodels on child speech is common, comparisons with flat-start training remainunderexplored. We compare flat-start training across multiple datasets, SSLrepresentations (WavLM, XEUS), and decoder architectures. Our results show thatSSL representations are biased toward adult speech, with flat-start training onchild speech mitigating these biases. We also analyze model scaling, findingconsistent improvements up to 1B parameters, beyond which performance plateaus.Additionally, age-related ASR and speaker verification analysis highlights thelimitations of proprietary models like Whisper, emphasizing the need foropen-data models for reliable child speech research. All investigations areconducted using ESPnet, and our publicly available benchmark provides insightsinto training strategies for robust child speech processing.</description><author>Anyu Ying, Natarajan Balaji Shankar, Chyi-Jiunn Lin, Mohan Shi, Pu Wang, Hye-jin Shim, Siddhant Arora, Hugo Van hamme, Abeer Alwan, Shinji Watanabe</author><pubDate>Fri, 22 Aug 2025 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16576v1</guid></item><item><title>Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems</title><link>http://arxiv.org/abs/2508.16574v1</link><description>This paper presents a hierarchical decision-making framework for autonomousnavigation in four-wheel independent steering and driving (4WISD) systems. Theproposed approach integrates deep reinforcement learning (DRL) for high-levelnavigation with fuzzy logic for low-level control to ensure both taskperformance and physical feasibility. The DRL agent generates global motioncommands, while the fuzzy logic controller enforces kinematic constraints toprevent mechanical strain and wheel slippage. Simulation experimentsdemonstrate that the proposed framework outperforms traditional navigationmethods, offering enhanced training efficiency and stability and mitigatingerratic behaviors compared to purely DRL-based solutions. Real-worldvalidations further confirm the framework's ability to navigate safely andeffectively in dynamic industrial settings. Overall, this work provides ascalable and reliable solution for deploying 4WISD mobile robots in complex,real-world scenarios.</description><author>Yizhi Wang, Degang Xu, Yongfang Xie, Shuzhong Tan, Xianan Zhou, Peng Chen</author><pubDate>Fri, 22 Aug 2025 17:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16574v1</guid></item><item><title>Are LLM-Powered Social Media Bots Realistic?</title><link>http://arxiv.org/abs/2508.00998v2</link><description>As Large Language Models (LLMs) become more sophisticated, there is apossibility to harness LLMs to power social media bots. This work investigatesthe realism of generating LLM-Powered social media bot networks. Through acombination of manual effort, network science and LLMs, we create synthetic botagent personas, their tweets and their interactions, thereby simulating socialmedia networks. We compare the generated networks against empirical bot/humandata, observing that both network and linguistic properties of LLM-Powered Botsdiffer from Wild Bots/Humans. This has implications towards the detection andeffectiveness of LLM-Powered Bots.</description><author>Lynnette Hui Xian Ng, Kathleen M. Carley</author><pubDate>Fri, 22 Aug 2025 17:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.00998v2</guid></item><item><title>LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence</title><link>http://arxiv.org/abs/2508.16571v1</link><description>In this paper, we describe and benchmark a competitor-discovery componentused within an agentic AI system for fast drug asset due diligence. Acompetitor-discovery AI agent, given an indication, retrieves all drugscomprising the competitive landscape of that indication and extracts canonicalattributes for these drugs. The competitor definition is investor-specific, anddata is paywalled/licensed, fragmented across registries, ontology-mismatchedby indication, alias-heavy for drug names, multimodal, and rapidly changing.Although considered the best tool for this problem, the current LLM-based AIsystems aren't capable of reliably retrieving all competing drug names, andthere is no accepted public benchmark for this task. To address the lack ofevaluation, we use LLM-based agents to transform five years of multi-modal,unstructured diligence memos from a private biotech VC fund into a structuredevaluation corpus mapping indications to competitor drugs with normalizedattributes. We also introduce a competitor validating LLM-as-a-judge agent thatfilters out false positives from the list of predicted competitors to maximizeprecision and suppress hallucinations. On this benchmark, ourcompetitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research(65%) and Perplexity Labs (60%). The system is deployed in production withenterprise users; in a case study with a biotech VC investment fund, analystturnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for thecompetitive analysis.</description><author>Alisa Vinogradova, Vlad Vinogradov, Dmitrii Radkevich, Ilya Yasny, Dmitry Kobyzev, Ivan Izmailov, Katsiaryna Yanchanka, Andrey Doronichev</author><pubDate>Fri, 22 Aug 2025 17:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16571v1</guid></item><item><title>A Disease-Centric Vision-Language Foundation Model for Precision Oncology in Kidney Cancer</title><link>http://arxiv.org/abs/2508.16569v1</link><description>The non-invasive assessment of increasingly incidentally discovered renalmasses is a critical challenge in urologic oncology, where diagnosticuncertainty frequently leads to the overtreatment of benign or indolent tumors.In this study, we developed and validated RenalCLIP using a dataset of 27,866CT scans from 8,809 patients across nine Chinese medical centers and the publicTCIA cohort, a visual-language foundation model for characterization, diagnosisand prognosis of renal mass. The model was developed via a two-stagepre-training strategy that first enhances the image and text encoders withdomain-specific knowledge before aligning them through a contrastive learningobjective, to create robust representations for superior generalization anddiagnostic precision. RenalCLIP achieved better performance and superiorgeneralizability across 10 core tasks spanning the full clinical workflow ofkidney cancer, including anatomical assessment, diagnostic classification, andsurvival prediction, compared with other state-of-the-art general-purpose CTfoundation models. Especially, for complicated task like recurrence-freesurvival prediction in the TCIA cohort, RenalCLIP achieved a C-index of 0.726,representing a substantial improvement of approximately 20% over the leadingbaselines. Furthermore, RenalCLIP's pre-training imparted remarkable dataefficiency; in the diagnostic classification task, it only needs 20% trainingdata to achieve the peak performance of all baseline models even after theywere fully fine-tuned on 100% of the data. Additionally, it achieved superiorperformance in report generation, image-text retrieval and zero-shot diagnosistasks. Our findings establish that RenalCLIP provides a robust tool with thepotential to enhance diagnostic accuracy, refine prognostic stratification, andpersonalize the management of patients with kidney cancer.</description><author>Yuhui Tao, Zhongwei Zhao, Zilong Wang, Xufang Luo, Feng Chen, Kang Wang, Chuanfu Wu, Xue Zhang, Shaoting Zhang, Jiaxi Yao, Xingwei Jin, Xinyang Jiang, Yifan Yang, Dongsheng Li, Lili Qiu, Zhiqiang Shao, Jianming Guo, Nengwang Yu, Shuo Wang, Ying Xiong</author><pubDate>Fri, 22 Aug 2025 17:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16569v1</guid></item><item><title>Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation</title><link>http://arxiv.org/abs/2508.16568v1</link><description>Foundation models (FMs) exhibit remarkable generalization but requireadaptation to downstream tasks, particularly in privacy-sensitive applications.Due to data privacy regulations, cloud-based FMs cannot directly access privateedge data, limiting their adaptation. Federated learning (FL) provides aprivacy-aware alternative, but existing FL approaches overlook the constraintsimposed by edge devices -- namely, limited computational resources and thescarcity of labeled data. To address these challenges, we introduce PracticalSemi-Supervised Federated Learning (PSSFL), where edge devices hold onlyunlabeled, low-resolution data, while the server has limited labeled,high-resolution data. In this setting, we propose the Federated Mixture ofExperts (FedMox), a novel framework that enhances FM adaptation in FL. FedMoxtackles computational and resolution mismatch challenges via a sparseMixture-of-Experts architecture, employing a spatial router to align featuresacross resolutions and a Soft-Mixture strategy to stabilize semi-supervisedlearning. We take object detection as a case study, and experiments onreal-world autonomous driving datasets demonstrate that FedMox effectivelyadapts FMs under PSSFL, significantly improving performance with constrainedmemory costs on edge devices. Our work paves the way for scalable andprivacy-preserving FM adaptation in federated scenarios.</description><author>Guangyu Sun, Jingtao Li, Weiming Zhuang, Chen Chen, Chen Chen, Lingjuan Lyu</author><pubDate>Fri, 22 Aug 2025 17:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16568v1</guid></item><item><title>Explicit Correspondence Matching for Generalizable Neural Radiance Fields</title><link>http://arxiv.org/abs/2304.12294v2</link><description>We present a new generalizable NeRF method that is able to directlygeneralize to new unseen scenarios and perform novel view synthesis with as fewas two source views. The key to our approach lies in the explicitly modeledcorrespondence matching information, so as to provide the geometry prior to theprediction of NeRF color and density for volume rendering. The explicitcorrespondence matching is quantified with the cosine similarity between imagefeatures sampled at the 2D projections of a 3D point on different views, whichis able to provide reliable cues about the surface geometry. Unlike previousmethods where image features are extracted independently for each view, weconsider modeling the cross-view interactions via Transformer cross-attention,which greatly improves the feature matching quality. Our method achievesstate-of-the-art results on different evaluation settings, with the experimentsshowing a strong correlation between our learned cosine feature similarity andvolume density, demonstrating the effectiveness and superiority of our proposedmethod. The code and model are on our project page:https://donydchen.github.io/matchnerf</description><author>Yuedong Chen, Haofei Xu, Qianyi Wu, Chuanxia Zheng, Tat-Jen Cham, Jianfei Cai</author><pubDate>Fri, 22 Aug 2025 17:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12294v2</guid></item><item><title>Establishing Task Scaling Laws via Compute-Efficient Model Ladders</title><link>http://arxiv.org/abs/2412.04403v2</link><description>We develop task scaling laws and model ladders to predict the individual taskperformance of pretrained language models (LMs) in the overtrained setting.Standard power laws for language modeling loss cannot accurately model taskperformance. Therefore, we leverage a two-step prediction approach: (1) usemodel and data size to predict an intermediate loss, then (2) use it to predicttask performance. We train a set of small-scale "ladder" models, collect datapoints to fit the parameterized functions of the two prediction steps, and makepredictions for two target models: a 7B model trained to 4T tokens and a 13Bmodel trained to 5T tokens. Training the ladder models only costs 1% of thecompute used for the target models. On four multiple-choice tasks formatted asranked classification, we can predict the accuracy of both target models within2 points of absolute error. We find that tasks with higher prediction erroralso have higher variance in the metrics over model checkpoints. We alsocontrast multiple design choices for predicting accuracy, and presentrecommendations for extending our method to new models and tasks.</description><author>Akshita Bhagia, Jiacheng Liu, Alexander Wettig, David Heineman, Oyvind Tafjord, Ananya Harsh Jha, Luca Soldaini, Noah A. Smith, Dirk Groeneveld, Pang Wei Koh, Jesse Dodge, Hannaneh Hajishirzi</author><pubDate>Fri, 22 Aug 2025 17:27:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04403v2</guid></item><item><title>A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection</title><link>http://arxiv.org/abs/2402.17018v2</link><description>We experimented with front-end enhanced neural models where a differentiableand fully convolutional model with a skip connection is added before a frozenbackbone classifier. By training such composite models using a small learningrate for about one epoch, we obtained models that retained the accuracy of thebackbone classifier while being unusually resistant to gradientattacks-including APGD and FAB-T attacks from the AutoAttack package-which weattribute to gradient masking. Although gradient masking is not new, the degreewe observe is striking for fully differentiable models without obviousgradient-shattering-e.g., JPEG compression-or gradient-diminishing components. The training recipe to produce such models is also remarkably stable andreproducible: We applied it to three datasets (CIFAR10, CIFAR100, and ImageNet)and several modern architectures (including vision Transformers) without asingle failure case. While black-box attacks such as the SQUARE attack andzero-order PGD can partially overcome gradient masking, these attacks areeasily defeated by simple randomized ensembles. We estimate that theseensembles achieve near-SOTA AutoAttack accuracy on CIFAR10, CIFAR100, andImageNet (while retaining almost all clean accuracy of the originalclassifiers) despite having near-zero accuracy under adaptive attacks. Adversarially training the backbone further amplifies this front-end"robustness". On CIFAR10, the respective randomized ensemble achieved 90.8$\pm2.5\%$ (99\% CI) accuracy under the full AutoAttack while having only 18.2$\pm3.6\%$ accuracy under the adaptive attack ($\varepsilon=8/255$, $L^\infty$norm). We conclude the paper with a discussion of whether randomized ensemblingcan serve as a practical defense. Code and instructions to reproduce key results are available.https://github.com/searchivarius/curious_case_of_gradient_masking</description><author>Leonid Boytsov, Ameya Joshi, Filipe Condessa</author><pubDate>Fri, 22 Aug 2025 17:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17018v2</guid></item><item><title>Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders</title><link>http://arxiv.org/abs/2508.16560v1</link><description>Sparse Autoencoders (SAEs) extract features from LLM internal activations,meant to correspond to single concepts. A core SAE training hyperparameter isL0: how many features should fire per token on average. Existing work comparesSAE algorithms using sparsity--reconstruction tradeoff plots, implying L0 is afree parameter with no single correct value. In this work we study the effectof L0 on BatchTopK SAEs, and show that if L0 is not set precisely, the SAEfails to learn the underlying features of the LLM. If L0 is too low, the SAEwill mix correlated features to improve reconstruction. If L0 is too high, theSAE finds degenerate solutions that also mix features. Further, we demonstratea method to determine the correct L0 value for an SAE on a given trainingdistribution, which finds the true L0 in toy models and coincides with peaksparse probing performance in LLMs. We find that most commonly used SAEs havean L0 that is too low. Our work shows that, to train SAEs with correctfeatures, practitioners must set L0 correctly.</description><author>David Chanin, Adrià Garriga-Alonso</author><pubDate>Fri, 22 Aug 2025 17:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16560v1</guid></item><item><title>Time-Aware One Step Diffusion Network for Real-World Image Super-Resolution</title><link>http://arxiv.org/abs/2508.16557v1</link><description>Diffusion-based real-world image super-resolution (Real-ISR) methods havedemonstrated impressive performance. To achieve efficient Real-ISR, many worksemploy Variational Score Distillation (VSD) to distill pre-trainedstable-diffusion (SD) model for one-step SR with a fixed timestep. However, dueto the different noise injection timesteps, the SD will perform differentgenerative priors. Therefore, a fixed timestep is difficult for these methodsto fully leverage the generative priors in SD, leading to suboptimalperformance. To address this, we propose a Time-Aware one-step DiffusionNetwork for Real-ISR (TADSR). We first introduce a Time-Aware VAE Encoder,which projects the same image into different latent features based ontimesteps. Through joint dynamic variation of timesteps and latent features,the student model can better align with the input pattern distribution of thepre-trained SD, thereby enabling more effective utilization of SD's generativecapabilities. To better activate the generative prior of SD at differenttimesteps, we propose a Time-Aware VSD loss that bridges the timesteps of thestudent model and those of the teacher model, thereby producing more consistentgenerative prior guidance conditioned on timesteps. Additionally, thoughutilizing the generative prior in SD at different timesteps, our method cannaturally achieve controllable trade-offs between fidelity and realism bychanging the timestep condition. Experimental results demonstrate that ourmethod achieves both state-of-the-art performance and controllable SR resultswith only a single step.</description><author>Tainyi Zhang, Zheng-Peng Duan, Peng-Tao Jiang, Bo Li, Ming-Ming Cheng, Chun-Le Guo, Chongyi Li</author><pubDate>Fri, 22 Aug 2025 17:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16557v1</guid></item><item><title>Transfer Learning via Lexical Relatedness: A Sarcasm and Hate Speech Case Study</title><link>http://arxiv.org/abs/2508.16555v1</link><description>Detecting hate speech in non-direct forms, such as irony, sarcasm, andinnuendos, remains a persistent challenge for social networks. Although sarcasmand hate speech are regarded as distinct expressions, our work explores whetherintegrating sarcasm as a pre-training step improves implicit hate speechdetection and, by extension, explicit hate speech detection. Incorporatingsamples from ETHOS, Sarcasm on Reddit, and Implicit Hate Corpus, we devised twotraining strategies to compare the effectiveness of sarcasm pre-training on aCNN+LSTM and BERT+BiLSTM model. The first strategy is a single-step trainingapproach, where a model trained only on sarcasm is then tested on hate speech.The second strategy uses sequential transfer learning to fine-tune models forsarcasm, implicit hate, and explicit hate. Our results show that sarcasmpre-training improved the BERT+BiLSTM's recall by 9.7%, AUC by 7.8%, andF1-score by 6% on ETHOS. On the Implicit Hate Corpus, precision increased by7.8% when tested only on implicit samples. By incorporating sarcasm into thetraining process, we show that models can more effectively detect both implicitand explicit hate.</description><author>Angelly Cabrera, Linus Lei, Antonio Ortega</author><pubDate>Fri, 22 Aug 2025 17:23:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16555v1</guid></item><item><title>Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations</title><link>http://arxiv.org/abs/2508.16554v1</link><description>Time-dependent density functional theory (TDDFT) is a widely used method toinvestigate electron dynamics under external time-dependent perturbations suchas laser fields. In this work, we present a novel approach to accelerateelectron dynamics simulations based on real time TDDFT using autoregressiveneural operators as time-propagators for the electron density. By leveragingphysics-informed constraints and featurization, and high-resolution trainingdata, our model achieves superior accuracy and computational speed compared totraditional numerical solvers. We demonstrate the effectiveness of our model ona class of one-dimensional diatomic molecules under the influence of a range oflaser parameters. This method has potential in enabling real-time, on-the-flymodeling of laser-irradiated molecules and materials with varying experimentalparameters.</description><author>Karan Shah, Attila Cangi</author><pubDate>Fri, 22 Aug 2025 17:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16554v1</guid></item><item><title>TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine</title><link>http://arxiv.org/abs/2508.16553v1</link><description>In the context of industry 4.0, long-serving industrial machines can beretrofitted with process monitoring capabilities for future use in a smartfactory. One possible approach is the deployment of wireless monitoringsystems, which can benefit substantially from the TinyML paradigm. This workpresents a complete TinyML flow from dataset generation, to machine learningmodel development, up to implementation and evaluation of a full preprocessingand classification pipeline on a microcontroller. After a short review onTinyML in industrial process monitoring, the creation of the novel MillingVibesdataset is described. The feasibility of a TinyML system forstructure-integrated process quality monitoring could be shown by thedevelopment of an 8-bit-quantized convolutional neural network (CNN) model with12.59kiB parameter storage. A test accuracy of 100.0% could be reached at15.4ms inference time and 1.462mJ per quantized CNN inference on an ARM CortexM4F microcontroller, serving as a reference for future TinyML processmonitoring solutions.</description><author>Tim Langer, Matthias Widra, Volkhard Beyer</author><pubDate>Fri, 22 Aug 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16553v1</guid></item><item><title>Enhanced NIRMAL Optimizer With Damped Nesterov Acceleration: A Comparative Analysis</title><link>http://arxiv.org/abs/2508.16550v1</link><description>This study introduces the Enhanced NIRMAL (Novel Integrated RobustMulti-Adaptation Learning with Damped Nesterov Acceleration) optimizer, animproved version of the original NIRMAL optimizer. By incorporating an$(\alpha, r)$-damped Nesterov acceleration mechanism, Enhanced NIRMAL improvesconvergence stability while retaining chess-inspired strategies of gradientdescent, momentum, stochastic perturbations, adaptive learning rates, andnon-linear transformations. We evaluate Enhanced NIRMAL against Adam, SGD with Momentum, Nesterov, andthe original NIRMAL on four benchmark image classification datasets: MNIST,FashionMNIST, CIFAR-10, and CIFAR-100, using tailored convolutional neuralnetwork (CNN) architectures. Enhanced NIRMAL achieves a test accuracy of 46.06\% and the lowest test loss(1.960435) on CIFAR-100, surpassing the original NIRMAL (44.34\% accuracy) andclosely rivaling SGD with Momentum (46.43\% accuracy). These results underscoreEnhanced NIRMAL's superior generalization and stability, particularly oncomplex datasets.</description><author>Nirmal Gaud, Prasad Krishna Murthy, Mostaque Md. Morshedur Hassan, Abhijit Ganguly, Vinay Mali, Ms Lalita Bhagwat Randive, Abhaypratap Singh</author><pubDate>Fri, 22 Aug 2025 17:16:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16550v1</guid></item><item><title>RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs</title><link>http://arxiv.org/abs/2508.16546v1</link><description>Training large language models (LLMs) from scratch is increasinglyimpractical, making post-training methods such as supervised fine-tuning (SFT)and reinforcement-learning fine-tuning (RL-FT, e.g., PPO) central to modernpractice. Using an out-of-distribution (OOD) variant of the 24-point card gameand new spectrum-based diagnostics, we revisit how these two stages reshapemodel representation and OOD performance. Our key findings are- (1) RL-FT canrestore much of the OOD performance loss from SFT (e.g., Llama-11B 8.97% to15.38%, Qwen-7B 17.09% to 19.66%). But when SFT induces severe overfitting anda clear distribution shift, RL-FT cannot fully recover OOD performance. (2)Direction shifts of singular vectors matter more than singular valuemagnitudes. These shifts concentrate on directions linked to the largest andsmallest singular values, leaving the bulk spectrum intact. (3) Low-rank andshallow recovery is effective: restoring singular vector directions for the top20% of values or first 25% of layers recovers 70-80% of OOD performance. (4)Stronger SFT checkpoints enable better recovery by RL, while overfitted onesresist restoration. These results reconcile prior reports of RL superior OODperformance: RL primarily counteracts SFT-induced directional drift rather thanfinding new solutions. Our spectrum-aware analysis highlights inexpensiverecovery knobs low-rank UV merging and shallow-layer resets that practitionerscan use before costly RL fine-tuning.</description><author>Hangzhan Jin, Sicheng Lv, Sifan Wu, Mohammad Hamdaqa</author><pubDate>Fri, 22 Aug 2025 17:10:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16546v1</guid></item><item><title>Parameter-Free Logit Distillation via Sorting Mechanism</title><link>http://arxiv.org/abs/2508.16544v1</link><description>Knowledge distillation (KD) aims to distill the knowledge from the teacher(larger) to the student (smaller) model via soft-label for the efficient neuralnetwork. In general, the performance of a model is determined by accuracy,which is measured with labels. However, existing KD approaches usually use theteacher with its original distribution, neglecting the potential of incorrectprediction. This may contradict the motivation of hard-label learning throughcross-entropy loss, which may lead to sub-optimal knowledge distillation oncertain samples. To address this issue, we propose a novel logit processingscheme via a sorting mechanism. Specifically, our method has a two-fold goal:(1) fixing the incorrect prediction of the teacher based on the labels and (2)reordering the distribution in a natural way according to priority rank atonce. As an easy-to-use, plug-and-play pre-processing, our sort method can beeffectively applied to existing logit-based KD methods. Extensive experimentson the CIFAR-100 and ImageNet datasets demonstrate the effectiveness of ourmethod.</description><author>Stephen Ekaputra Limantoro</author><pubDate>Fri, 22 Aug 2025 17:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16544v1</guid></item><item><title>Explainable AI in Deep Learning-Based Prediction of Solar Storms</title><link>http://arxiv.org/abs/2508.16543v1</link><description>A deep learning model is often considered a black-box model, as its internalworkings tend to be opaque to the user. Because of the lack of transparency, itis challenging to understand the reasoning behind the model's predictions.Here, we present an approach to making a deep learning-based solar stormprediction model interpretable, where solar storms include solar flares andcoronal mass ejections (CMEs). This deep learning model, built based on a longshort-term memory (LSTM) network with an attention mechanism, aims to predictwhether an active region (AR) on the Sun's surface that produces a flare within24 hours will also produce a CME associated with the flare. The crux of ourapproach is to model data samples in an AR as time series and use the LSTMnetwork to capture the temporal dynamics of the data samples. To make themodel's predictions accountable and reliable, we leverage post hocmodel-agnostic techniques, which help elucidate the factors contributing to thepredicted output for an input sequence and provide insights into the model'sbehavior across multiple sequences within an AR. To our knowledge, this is thefirst time that interpretability has been added to an LSTM-based solar stormprediction model.</description><author>Adam O. Rawashdeh, Jason T. L. Wang, Katherine G. Herbert</author><pubDate>Fri, 22 Aug 2025 17:09:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16543v1</guid></item><item><title>Escaping Saddle Points via Curvature-Calibrated Perturbations: A Complete Analysis with Explicit Constants and Empirical Validation</title><link>http://arxiv.org/abs/2508.16540v1</link><description>We present a comprehensive theoretical analysis of first-order methods forescaping strict saddle points in smooth non-convex optimization. Our maincontribution is a Perturbed Saddle-escape Descent (PSD) algorithm with fullyexplicit constants and a rigorous separation between gradient-descent andsaddle-escape phases. For a function $f:\mathbb{R}^d\to\mathbb{R}$ with$\ell$-Lipschitz gradient and $\rho$-Lipschitz Hessian, we prove that PSD findsan $(\epsilon,\sqrt{\rho\epsilon})$-approximate second-order stationary pointwith high probability using at most $O(\ell\Delta_f/\epsilon^2)$ gradientevaluations for the descent phase plus$O((\ell/\sqrt{\rho\epsilon})\log(d/\delta))$ evaluations per escape episode,with at most $O(\ell\Delta_f/\epsilon^2)$ episodes needed. We validate ourtheoretical predictions through extensive experiments across both syntheticfunctions and practical machine learning tasks, confirming the logarithmicdimension dependence and the predicted per-episode function decrease. We alsoprovide complete algorithmic specifications including a finite-differencevariant (PSD-Probe) and a stochastic extension (PSGD) with robust mini-batchsizing.</description><author>Faruk Alpay, Hamdi Alakkad</author><pubDate>Fri, 22 Aug 2025 17:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16540v1</guid></item><item><title>General and Estimable Learning Bound Unifying Covariate and Concept Shifts</title><link>http://arxiv.org/abs/2506.12829v2</link><description>Generalization under distribution shift remains a core challenge in modernmachine learning, yet existing learning bound theory is limited to narrow,idealized settings and is non-estimable from samples. In this paper, we bridgethe gap between theory and practical applications. We first show that existingbounds become loose and non-estimable because their concept shift definitionbreaks when the source and target supports mismatch. Leveraging entropicoptimal transport, we propose new support-agnostic definitions for covariateand concept shifts, and derive a novel unified error bound that applies tobroad loss functions, label spaces, and stochastic labeling. We further developestimators for these shifts with concentration guarantees, and the DataShiftsalgorithm, which can quantify distribution shifts and estimate the error boundin most applications -- a rigorous and general tool for analyzing learningerror under distribution shift.</description><author>Hongbo Chen, Li Charlie Xia</author><pubDate>Fri, 22 Aug 2025 17:06:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.12829v2</guid></item><item><title>Can Large Language Models Simulate Human Responses? A Case Study of Stated Preference Experiments in the Context of Heating-related Choices</title><link>http://arxiv.org/abs/2503.10652v3</link><description>Stated preference (SP) surveys are a key method to research how individualsmake trade-offs in hypothetical, also futuristic, scenarios. In energy contextthis includes key decarbonisation enablement contexts, such as low-carbontechnologies, distributed renewable energy generation, and demand-side response[1,2]. However, they tend to be costly, time-consuming, and can be affected byrespondent fatigue and ethical constraints. Large language models (LLMs) havedemonstrated remarkable capabilities in generating human-like textualresponses, prompting growing interest in their application to survey research.This study investigates the use of LLMs to simulate consumer choices inenergy-related SP surveys and explores their integration into data analysisworkflows. A series of test scenarios were designed to systematically assessthe simulation performance of several LLMs (LLaMA 3.1, Mistral, GPT-3.5 andDeepSeek-R1) at both individual and aggregated levels, considering contextsfactors such as prompt design, in-context learning (ICL), chain-of-thought(CoT) reasoning, LLM types, integration with traditional choice models, andpotential biases. Cloud-based LLMs do not consistently outperform smaller localmodels. In this study, the reasoning model DeepSeek-R1 achieves the highestaverage accuracy (77%) and outperforms non-reasoning LLMs in accuracy, factoridentification, and choice distribution alignment. Across models, systematicbiases are observed against the gas boiler and no-retrofit options, with apreference for more energy-efficient alternatives. The findings suggest thatprevious SP choices are the most effective input factor, while longer promptswith additional factors and varied formats can cause LLMs to lose focus,reducing accuracy.</description><author>Han Wang, Jacek Pawlak, Aruna Sivakumar</author><pubDate>Fri, 22 Aug 2025 17:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.10652v3</guid></item><item><title>Quality control in sublinear time: a case study via random graphs</title><link>http://arxiv.org/abs/2508.16531v1</link><description>Many algorithms are designed to work well on average over inputs. Whenrunning such an algorithm on an arbitrary input, we must ask: Can we trust thealgorithm on this input? We identify a new class of algorithmic problemsaddressing this, which we call "Quality Control Problems." These problems arespecified by a (positive, real-valued) "quality function" $\rho$ and adistribution $D$ such that, with high probability, a sample drawn from $D$ is"high quality," meaning its $\rho$-value is near $1$. The goal is to acceptinputs $x \sim D$ and reject potentially adversarially generated inputs $x$with $\rho(x)$ far from $1$. The objective of quality control is thus weakerthan either component problem: testing for "$\rho(x) \approx 1$" or testing if$x \sim D$, and offers the possibility of more efficient algorithms. In this work, we consider the sublinear version of the quality controlproblem, where $D \in \Delta(\{0,1\}^N)$ and the goal is to solve the $(D,\rho)$-quality problem with $o(N)$ queries and time. As a case study, weconsider random graphs, i.e., $D = G_{n,p}$ (and $N = \binom{n}2$), and the$k$-clique count function $\rho_k := C_k(G)/\mathbb{E}_{G' \simG_{n,p}}[C_k(G')]$, where $C_k(G)$ is the number of $k$-cliques in $G$. Testingif $G \sim G_{n,p}$ with one sample, let alone with sublinear query access tothe sample, is of course impossible. Testing if $\rho_k(G)\approx 1$ requires$p^{-\Omega(k^2)}$ samples. In contrast, we show that the quality controlproblem for $G_{n,p}$ (with $n \geq p^{-ck}$ for some constant $c$) withrespect to $\rho_k$ can be tested with $p^{-O(k)}$ queries and time, showingquality control is provably superpolynomially more efficient in this setting.More generally, for a motif $H$ of maximum degree $\Delta(H)$, the respectivequality control problem can be solved with $p^{-O(\Delta(H))}$ queries andrunning time.</description><author>Cassandra Marcussen, Ronitt Rubinfeld, Madhu Sudan</author><pubDate>Fri, 22 Aug 2025 16:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16531v1</guid></item><item><title>Towards Open World Detection: A Survey</title><link>http://arxiv.org/abs/2508.16527v1</link><description>For decades, Computer Vision has aimed at enabling machines to perceive theexternal world. Initial limitations led to the development of highlyspecialized niches. As success in each task accrued and research progressed,increasingly complex perception tasks emerged. This survey charts theconvergence of these tasks and, in doing so, introduces Open World Detection(OWD), an umbrella term we propose to unify class-agnostic and generallyapplicable detection models in the vision domain. We start from the history offoundational vision subdomains and cover key concepts, methodologies anddatasets making up today's state-of-the-art landscape. This traverses topicsstarting from early saliency detection, foreground/background separation, outof distribution detection and leading up to open world object detection,zero-shot detection and Vision Large Language Models (VLLMs). We explore theoverlap between these subdomains, their increasing convergence, and theirpotential to unify into a singular domain in the future, perception.</description><author>Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan</author><pubDate>Fri, 22 Aug 2025 16:49:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16527v1</guid></item><item><title>A Simple "Try Again" Can Elicit Multi-Turn LLM Reasoning</title><link>http://arxiv.org/abs/2507.14295v2</link><description>Multi-turn problem solving is critical yet challenging for Large ReasoningModels (LRMs) to reflect on their reasoning and revise from feedback. ExistingReinforcement Learning (RL) methods train large reasoning models on asingle-turn paradigm with verifiable rewards. However, we observe that modelstrained with existing RL paradigms often lose their ability to solve problemsacross multiple turns and struggle to revise answers based on contextualfeedback, leading to repetitive responses. We ask: can LRMs learn to reflecttheir answers in a multi-turn context? In this work, we find that trainingmodels with multi-turn RL using only unary feedback (e.g., "Let's try again")after wrong answers can improve both single-turn performance and multi-turnreasoning. We introduce Unary Feedback as Observation (UFO) for reinforcementlearning, which uses minimal yet common unary user feedback during iterativeproblem solving. It can be easily applied to existing single-turn RL trainingsetups. Experimental results show that RL training with UFO keeps single-turnperformance and improves multi-turn reasoning accuracy by up to 14%, enablinglanguage models to better react to feedback in multi-turn problem solving. Tofurther minimize the number of turns needed for a correct answer whileencouraging diverse reasoning when mistakes occur, we design reward structuresthat guide models to produce careful and deliberate answers in each turn. Code:https://github.com/lichengliu03/unary-feedback</description><author>Licheng Liu, Zihan Wang, Linjie Li, Chenwei Xu, Yiping Lu, Han Liu, Avirup Sil, Manling Li</author><pubDate>Fri, 22 Aug 2025 16:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.14295v2</guid></item><item><title>Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning</title><link>http://arxiv.org/abs/2508.16524v1</link><description>Enabling neural networks to learn complex logical constraints and fulfillsymbolic reasoning is a critical challenge. Bridging this gap often requiresguiding the neural network's output distribution to move closer to the symbolicconstraints. While diffusion models have shown remarkable generative capabilityacross various domains, we employ the powerful architecture to performneuro-symbolic learning and solve logical puzzles. Our diffusion-based pipelineadopts a two-stage training strategy: the first stage focuses on cultivatingbasic reasoning abilities, while the second emphasizes systematic learning oflogical constraints. To impose hard constraints on neural outputs in the secondstage, we formulate the diffusion reasoner as a Markov decision process andinnovatively fine-tune it with an improved proximal policy optimizationalgorithm. We utilize a rule-based reward signal derived from the logicalconsistency of neural outputs and adopt a flexible strategy to optimize thediffusion reasoner's policy. We evaluate our methodology on some classicalsymbolic reasoning benchmarks, including Sudoku, Maze, pathfinding andpreference learning. Experimental results demonstrate that our approachachieves outstanding accuracy and logical consistency among neural networks.</description><author>Xuan Zhang, Zhijian Zhou, Weidi Xu, Yanting Miao, Chao Qu, Yuan Qi</author><pubDate>Fri, 22 Aug 2025 16:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16524v1</guid></item><item><title>Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation</title><link>http://arxiv.org/abs/2508.16521v1</link><description>Generating physically realistic 3D molecular structures remains a corechallenge in molecular generative modeling. While diffusion models equippedwith equivariant neural networks have made progress in capturing moleculargeometries, they often struggle to produce equilibrium structures that adhereto physical principles such as force field consistency. To bridge this gap, wepropose Reinforcement Learning with Physical Feedback (RLPF), a novel frameworkthat extends Denoising Diffusion Policy Optimization to 3D moleculargeneration. RLPF formulates the task as a Markov decision process and appliesproximal policy optimization to fine-tune equivariant diffusion models.Crucially, RLPF introduces reward functions derived from force-fieldevaluations, providing direct physical feedback to guide the generation towardenergetically stable and physically meaningful structures. Experiments on theQM9 and GEOM-drug datasets demonstrate that RLPF significantly improvesmolecular stability compared to existing methods. These results highlight thevalue of incorporating physics-based feedback into generative modeling. Thecode is available at: https://github.com/ZhijianZhou/RLPF/tree/verl_diffusion.</description><author>Zhijian Zhou, Junyi An, Zongkai Liu, Yunfei Shi, Xuan Zhang, Fenglei Cao, Chao Qu, Yuan Qi</author><pubDate>Fri, 22 Aug 2025 16:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16521v1</guid></item><item><title>Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments</title><link>http://arxiv.org/abs/2508.16515v1</link><description>The most crucial challenges for UAVs are planning paths and avoidingobstacles in their way. In recent years, a wide variety of path-planningalgorithms have been developed. These algorithms have successfully solvedpath-planning problems; however, they suffer from multiple challenges andlimitations. To test the effectiveness and efficiency of three widely usedalgorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paperconducts extensive experiments in 3D urban city environments cluttered withobstacles. Three experiments were designed with two scenarios each to test theaforementioned algorithms. These experiments consider different city map sizes,different altitudes, and varying obstacle densities and sizes in theenvironment. According to the experimental results, the A* algorithmoutperforms the others in both computation efficiency and path quality. PSO isespecially suitable for tight turns and dense environments, and RRT* offers abalance and works well across all experiments due to its randomized approach tofinding solutions.</description><author>Hichem Cheriet, Khellat Kihel Badra, Chouraqui Samira</author><pubDate>Fri, 22 Aug 2025 16:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16515v1</guid></item><item><title>FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline</title><link>http://arxiv.org/abs/2508.16514v1</link><description>Recent works improving LLM math reasoning with synthetic data have usedunique setups, making comparison of data synthesis strategies impractical. Thisleaves many unanswered questions about the roles of different factors in thesynthetic data pipeline, such as the impact of filtering low-quality problems.To address this gap, we introduce FLAMES, a Framework for LLM Assessment ofMath rEasoning Data Synthesis, and perform a systematic study of 10 existingdata synthesis strategies and multiple other factors impacting the performanceof synthetic math reasoning data. Our FLAMES experiments provide severalvaluable insights about the optimal balance of difficulty and diversity ofsynthetic data. First, data agents designed to increase problem complexity leadto best improvements on most math metrics. Second, with a fixed data generationbudget, keeping higher problem coverage is more important than keeping onlyproblems with reliable solutions. Third, GSM8K- and MATH-based synthetic datacan lead to improvements on competition-level benchmarks, showcasingeasy-to-hard generalization. Leveraging insights from our FLAMES experiments,we design two novel data synthesis strategies for improving out-of-domaingeneralization and robustness. Further, we develop the FLAMES dataset, aneffective blend of our novel and existing data synthesis strategies,outperforming public datasets on OlympiadBench (+15.7), CollegeMath (+4.5),GSMPlus (+6.5), and MATH (+3.1). Fine-tuning Qwen2.5-Math-7B on the FLAMESdataset achieves 81.4% on MATH, surpassing larger Llama3 405B, GPT-4o andClaude 3.5 Sonnet.</description><author>Parker Seegmiller, Kartik Mehta, Soumya Saha, Chenyang Tao, Shereen Oraby, Arpit Gupta, Tagyoung Chung, Mohit Bansal, Nanyun Peng</author><pubDate>Fri, 22 Aug 2025 16:37:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16514v1</guid></item><item><title>Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization</title><link>http://arxiv.org/abs/2508.04796v2</link><description>Tokenization is the first -- and often least scrutinized -- step of most NLPpipelines. Standard algorithms for learning tokenizers rely on frequency-basedobjectives, which favor languages dominant in the training data andconsequently leave lower-resource languages with tokenizations that aredisproportionately longer, morphologically implausible, or even riddled with&lt;UNK&gt; placeholders. This phenomenon ultimately amplifies computational andfinancial inequalities between users from different language backgrounds. Toremedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant ofthe widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizesthe compression gain of the currently worst-compressed language, trading asmall amount of global compression for cross-lingual parity. We findempirically that Parity-aware BPE leads to more equitable token counts acrosslanguages, with negligible impact on global compression rate and no substantialeffect on language-model performance in downstream tasks.</description><author>Negar Foroutan, Clara Meister, Debjit Paul, Joel Niklaus, Sina Ahmadi, Antoine Bosselut, Rico Sennrich</author><pubDate>Fri, 22 Aug 2025 16:36:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.04796v2</guid></item><item><title>Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation</title><link>http://arxiv.org/abs/2508.16512v1</link><description>Recent advancements in video generation have substantially improved visualquality and temporal coherence, making these models increasingly appealing forapplications such as autonomous driving, particularly in the context of drivingsimulation and so-called "world models". In this work, we investigate theeffects of existing fine-tuning video generation approaches on structureddriving datasets and uncover a potential trade-off: although visual fidelityimproves, spatial accuracy in modeling dynamic elements may degrade. Weattribute this degradation to a shift in the alignment between visual qualityand dynamic understanding objectives. In datasets with diverse scene structureswithin temporal space, where objects or perspective shift in varied ways, theseobjectives tend to highly correlated. However, the very regular and repetitivenature of driving scenes allows visual quality to improve by modeling dominantscene motion patterns, without necessarily preserving fine-grained dynamicbehavior. As a result, fine-tuning encourages the model to prioritizesurface-level realism over dynamic accuracy. To further examine thisphenomenon, we show that simple continual learning strategies, such as replayfrom diverse domains, can offer a balanced alternative by preserving spatialaccuracy while maintaining strong visual quality.</description><author>Chun-Peng Chang, Chen-Yu Wang, Julian Schmidt, Holger Caesar, Alain Pagani</author><pubDate>Fri, 22 Aug 2025 16:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16512v1</guid></item><item><title>ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks</title><link>http://arxiv.org/abs/2508.16509v1</link><description>The ability to quantify information transmission is crucial for the analysisand design of natural and engineered systems. The information transmission rateis the fundamental measure for systems with time-varying signals, yet computingit is extremely challenging. In particular, the rate cannot be obtaineddirectly from experimental time-series data without approximations, because ofthe high dimensionality of the signal trajectory space. Path Weight Sampling(PWS) is a computational technique that makes it possible to obtain theinformation rate exactly for any stochastic system. However, it requires amathematical model of the system of interest, be it described by a masterequation or a set of differential equations. Here, we present a technique thatemploys Machine Learning (ML) to develop a generative model from experimentaltime-series data, which is then combined with PWS to obtain the informationrate. We demonstrate the accuracy of this technique, called ML-PWS, bycomparing its results on synthetic time-series data generated from a non-linearmodel against ground-truth results obtained by applying PWS directly to thesame model. We illustrate the utility of ML-PWS by applying it to neuronaltime-series data.</description><author>Manuel Reinhardt, Gašper Tkačik, Pieter Rein ten Wolde</author><pubDate>Fri, 22 Aug 2025 16:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16509v1</guid></item><item><title>MuST2-Learn: Multi-view Spatial-Temporal-Type Learning for Heterogeneous Municipal Service Time Estimation</title><link>http://arxiv.org/abs/2508.16503v1</link><description>Non-emergency municipal services such as city 311 systems have been widelyimplemented across cities in Canada and the United States to enhance residents'quality of life. These systems enable residents to report issues, e.g., noisecomplaints, missed garbage collection, and potholes, via phone calls, mobileapplications, or webpages. However, residents are often given limitedinformation about when their service requests will be addressed, which canreduce transparency, lower resident satisfaction, and increase the number offollow-up inquiries. Predicting the service time for municipal service requestsis challenging due to several complex factors: dynamic spatial-temporalcorrelations, underlying interactions among heterogeneous service requesttypes, and high variation in service duration even within the same requestcategory. In this work, we propose MuST2-Learn: a Multi-viewSpatial-Temporal-Type Learning framework designed to address the aforementionedchallenges by jointly modeling spatial, temporal, and service type dimensions.In detail, it incorporates an inter-type encoder to capture relationships amongheterogeneous service request types and an intra-type variation encoder tomodel service time variation within homogeneous types. In addition, aspatiotemporal encoder is integrated to capture spatial and temporalcorrelations in each request type. The proposed framework is evaluated withextensive experiments using two real-world datasets. The results show thatMuST2-Learn reduces mean absolute error by at least 32.5%, which outperformsstate-of-the-art methods.</description><author>Nadia Asif, Zhiqing Hong, Shaogang Ren, Xiaonan Zhang, Xiaojun Shang, Yukun Yuan</author><pubDate>Fri, 22 Aug 2025 16:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16503v1</guid></item><item><title>Seamless Language Expansion: Enhancing Multilingual Mastery in Self-Supervised Models</title><link>http://arxiv.org/abs/2406.14092v2</link><description>Self-supervised (SSL) models have shown great performance in variousdownstream tasks. However, they are typically developed for limited languages,and may encounter new languages in real-world. Developing a SSL model for eachnew language is costly. Thus, it is vital to figure out how to efficientlyadapt existed SSL models to a new language without impairing its originalabilities. We propose adaptation methods which integrate LoRA to existed SSLmodels to extend new language. We also develop preservation strategies whichinclude data combination and re-clustering to retain abilities on existedlanguages. Applied to mHuBERT, we investigate their effectiveness on speechre-synthesis task. Experiments show that our adaptation methods enable mHuBERTto be applied to a new language (Mandarin) with MOS value increased about 1.6and the relative value of WER reduced up to 61.72%. Also, our preservationstrategies ensure that the performance on both existed and new languagesremains intact.</description><author>Jing Xu, Minglin Wu, Xixin Wu, Helen Meng</author><pubDate>Fri, 22 Aug 2025 16:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14092v2</guid></item><item><title>LearnLM: Improving Gemini for Learning</title><link>http://arxiv.org/abs/2412.16429v3</link><description>Today's generative AI systems are tuned to present information by default,rather than engage users in service of learning as a human tutor would. Toaddress the wide range of potential education use cases for these systems, wereframe the challenge of injecting pedagogical behavior as one of\textit{pedagogical instruction following}, where training and evaluationexamples include system-level instructions describing the specific pedagogyattributes present or desired in subsequent model turns. This framing avoidscommitting our models to any particular definition of pedagogy, and insteadallows teachers or developers to specify desired model behavior. It also clearsa path to improving Gemini models for learning -- by enabling the addition ofour pedagogical data to post-training mixtures -- alongside their rapidlyexpanding set of capabilities. Both represent important changes from ourinitial tech report. We show how training with pedagogical instructionfollowing produces a LearnLM model (available on Google AI Studio) that expertssubstantially prefer across a diverse set of learning scenarios, with averagepreference strengths of +31\% over GPT-4o, +11\% over Claude 3.5 Sonnet, and+13\% over the Gemini 1.5 Pro model on which LearnLM was based.</description><author>LearnLM Team, Abhinit Modi, Aditya Srikanth Veerubhotla, Aliya Rysbek, Andrea Huber, Brett Wiltshire, Brian Veprek, Daniel Gillick, Daniel Kasenberg, Derek Ahmed, Irina Jurenka, James Cohan, Jennifer She, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Lisa Wang, Markus Kunesch, Mike Schaekermann, Miruna Pîslar, Nikhil Joshi, Parsa Mahmoudieh, Paul Jhun, Sara Wiltberger, Shakir Mohamed, Shashank Agarwal, Shubham Milind Phal, Sun Jae Lee, Theofilos Strinopoulos, Wei-Jen Ko, Amy Wang, Ankit Anand, Avishkar Bhoopchand, Dan Wild, Divya Pandya, Filip Bar, Garth Graham, Holger Winnemoeller, Mahvish Nagda, Prateek Kolhar, Renee Schneider, Shaojian Zhu, Stephanie Chan, Steve Yadlowsky, Viknesh Sounderajah, Yannis Assael</author><pubDate>Fri, 22 Aug 2025 16:22:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16429v3</guid></item><item><title>On Zero-Shot Reinforcement Learning</title><link>http://arxiv.org/abs/2508.16496v1</link><description>Modern reinforcement learning (RL) systems capture deep truths about general,human problem-solving. In domains where new data can be simulated cheaply,these systems uncover sequential decision-making policies that far exceed theability of any human. Society faces many problems whose solutions require thisskill, but they are often in domains where new data cannot be cheaplysimulated. In such scenarios, we can learn simulators from existing data, butthese will only ever be approximately correct, and can be pathologicallyincorrect when queried outside of their training distribution. As a result, amisalignment between the environments in which we train our agents and thereal-world in which we wish to deploy our agents is inevitable. Dealing withthis misalignment is the primary concern of zero-shot reinforcement learning, aproblem setting where the agent must generalise to a new task or domain withzero practice shots. Whilst impressive progress has been made on methods thatperform zero-shot RL in idealised settings, new work is needed if these resultsare to be replicated in real-world settings. In this thesis, we argue thatdoing so requires us to navigate (at least) three constraints. First, the dataquality constraint: real-world datasets are small and homogeneous. Second, theobservability constraint: states, dynamics and rewards in the real-world areoften only partially observed. And third, the data availability constraint: apriori access to data cannot always be assumed. This work proposes a suite ofmethods that perform zero-shot RL subject to these constraints. In a series ofempirical studies we expose the failings of existing methods, and justify ourtechniques for remedying them. We believe these designs take us a step closerto RL methods that can be deployed to solve real-world problems.</description><author>Scott Jeen</author><pubDate>Fri, 22 Aug 2025 16:20:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16496v1</guid></item><item><title>Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement</title><link>http://arxiv.org/abs/2507.07908v2</link><description>Remote physiological measurement (RPM) has emerged as a promisingnon-invasive method for monitoring physiological signals using the non-contactdevice. Although various domain adaptation and generalization methods wereproposed to promote the adaptability of deep-based RPM models in unseendeployment environments, considerations in aspects such as privacy concerns andreal-time adaptation restrict their application in real-world deployment. Thus,we aim to propose a novel fully Test-Time Adaptation (TTA) strategy tailoredfor RPM tasks in this work. Specifically, based on prior knowledge inphysiology and our observations, we noticed not only there is spatio-temporalconsistency in the frequency domain of BVP signals, but also that inconsistencyin the time domain was significant. Given this, by leveraging both consistencyand inconsistency priors, we introduce an innovative expert knowledge-basedself-supervised\textbf{C}onsistency-\textbf{i}n\textbf{C}onsistency-\textbf{i}ntegration(\textbf{CiCi}) framework to enhances model adaptation during inference.Besides, our approach further incorporates a gradient dynamic control mechanismto mitigate potential conflicts between priors, ensuring stable adaptationacross instances. Through extensive experiments on five diverse datasets underthe TTA protocol, our method consistently outperforms existing techniques,presenting state-of-the-art performance in real-time self-supervised adaptationwithout accessing source data. The code will be released later.</description><author>Xiao Yang, Jiyao Wang, Yuxuan Fan, Can Liu, Houcheng Su, Weichen Guo, Zitong Yu, Dengbo He, Kaishun Wu</author><pubDate>Fri, 22 Aug 2025 16:20:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.07908v2</guid></item><item><title>Post Hoc Regression Refinement via Pairwise Rankings</title><link>http://arxiv.org/abs/2508.16495v1</link><description>Accurate prediction of continuous properties is essential to many scientificand engineering tasks. Although deep-learning regressors excel with abundantlabels, their accuracy deteriorates in data-scarce regimes. We introduceRankRefine, a model-agnostic, plug-and-play post hoc method that refinesregression with expert knowledge coming from pairwise rankings. Given a queryitem and a small reference set with known properties, RankRefine combines thebase regressor's output with a rank-based estimate via inverse varianceweighting, requiring no retraining. In molecular property prediction task,RankRefine achieves up to 10% relative reduction in mean absolute error usingonly 20 pairwise comparisons obtained through a general-purpose large languagemodel (LLM) with no finetuning. As rankings provided by human experts orgeneral-purpose LLMs are sufficient for improving regression across diversedomains, RankRefine offers practicality and broad applicability, especially inlow-data settings.</description><author>Kevin Tirta Wijaya, Michael Sun, Minghao Guo, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei</author><pubDate>Fri, 22 Aug 2025 16:17:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16495v1</guid></item><item><title>Overcoming classic challenges for artificial neural networks by providing incentives and practice</title><link>http://arxiv.org/abs/2410.10596v3</link><description>Since the earliest proposals for artificial neural network (ANN) models ofthe mind and brain, critics have pointed out key weaknesses in these modelscompared to human cognitive abilities. Here we review recent work that usesmetalearning to overcome several classic challenges, which we characterise asaddressing the Problem of Incentive and Practice -- that is, providing machineswith both incentives to improve specific skills and opportunities to practicethose skills. This explicit optimization contrasts with more conventionalapproaches that hope the desired behaviour will emerge through optimisingrelated but different objectives. We review applications of this principle toaddressing four classic challenges for ANNs: systematic generalisation,catastrophic forgetting, few-shot learning and multi-step reasoning. We alsodiscuss how large language models incorporate key aspects of this metalearningframework (namely, sequence prediction with feedback trained on diverse data),which helps to explain some of their successes on these classic challenges.Finally, we discuss the prospects for understanding aspects of humandevelopment through this framework, and whether natural environments providethe right incentives and practice for learning how to make challenginggeneralisations.</description><author>Kazuki Irie, Brenden M. Lake</author><pubDate>Fri, 22 Aug 2025 16:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10596v3</guid></item><item><title>AutoVerus: Automated Proof Generation for Rust Code</title><link>http://arxiv.org/abs/2409.13082v3</link><description>Generative AI has shown its values for many software engineering tasks. Stillin its infancy, large language model (LLM)-based proof generation lags behindLLM-based code generation. In this paper, we present AutoVerus. AutoVerus usesLLMs to automatically generate correctness proof for Rust code. AutoVerus isdesigned to match the unique features of Verus, a verification tool that canprove the correctness of Rust code using proofs and specifications also writtenin Rust. AutoVerus consists of a network of LLM agents that are crafted andorchestrated to mimic human experts' three phases of proof construction:preliminary proof generation, proof refinement guided by generic tips, andproof debugging guided by verification errors. To thoroughly evaluate AutoVerusand help foster future research in this direction, we have built a benchmarksuite of 150 non-trivial proof tasks, based on existing code-generationbenchmarks and verification benchmarks. Our evaluation shows that AutoVerus canautomatically generate correct proof for more than 90% of them, with more thanhalf of them tackled in less than 30 seconds or 3 LLM calls.</description><author>Chenyuan Yang, Xuheng Li, Md Rakib Hossain Misu, Jianan Yao, Weidong Cui, Yeyun Gong, Chris Hawblitzel, Shuvendu Lahiri, Jacob R. Lorch, Shuai Lu, Fan Yang, Ziqiao Zhou, Shan Lu</author><pubDate>Fri, 22 Aug 2025 16:12:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13082v3</guid></item><item><title>MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds</title><link>http://arxiv.org/abs/2508.14879v2</link><description>Reconstructing 3D objects into editable programs is pivotal for applicationslike reverse engineering and shape editing. However, existing methods oftenrely on limited domain-specific languages (DSLs) and small-scale datasets,restricting their ability to model complex geometries and structures. Toaddress these challenges, we introduce MeshCoder, a novel framework thatreconstructs complex 3D objects from point clouds into editable Blender Pythonscripts. We develop a comprehensive set of expressive Blender Python APIscapable of synthesizing intricate geometries. Leveraging these APIs, weconstruct a large-scale paired object-code dataset, where the code for eachobject is decomposed into distinct semantic parts. Subsequently, we train amultimodal large language model (LLM) that translates 3D point cloud intoexecutable Blender Python scripts. Our approach not only achieves superiorperformance in shape-to-code reconstruction tasks but also facilitatesintuitive geometric and topological editing through convenient codemodifications. Furthermore, our code-based representation enhances thereasoning capabilities of LLMs in 3D shape understanding tasks. Together, thesecontributions establish MeshCoder as a powerful and flexible solution forprogrammatic 3D shape reconstruction and understanding. The project homepage isavailable at \href{https://daibingquan.github.io/MeshCoder}{this link}.</description><author>Bingquan Dai, Li Ray Luo, Qihong Tang, Jie Wang, Xinyu Lian, Hao Xu, Minghan Qin, Xudong Xu, Bo Dai, Haoqian Wang, Zhaoyang Lyu, Jiangmiao Pang</author><pubDate>Fri, 22 Aug 2025 16:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.14879v2</guid></item><item><title>Ensembles of Neural Surrogates for Parametric Sensitivity in Ocean Modeling</title><link>http://arxiv.org/abs/2508.16489v1</link><description>Accurate simulations of the oceans are crucial in understanding the Earthsystem. Despite their efficiency, simulations at lower resolutions must rely onvarious uncertain parameterizations to account for unresolved processes.However, model sensitivity to parameterizations is difficult to quantify,making it challenging to tune these parameterizations to reproduceobservations. Deep learning surrogates have shown promise for efficientcomputation of the parametric sensitivities in the form of partial derivatives,but their reliability is difficult to evaluate without ground truthderivatives. In this work, we leverage large-scale hyperparameter search andensemble learning to improve both forward predictions, autoregressive rollout,and backward adjoint sensitivity estimation. Particularly, the ensemble methodprovides epistemic uncertainty of function value predictions and theirderivatives, providing improved reliability of the neural surrogates indecision making.</description><author>Yixuan Sun, Romain Egele, Sri Hari Krishna Narayana, Luke Van Roekel, Carmelo Gonzales, Steven Brus, Balu Nadiga, Sandeep Madireddy, Prasanna Balaprakash</author><pubDate>Fri, 22 Aug 2025 16:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16489v1</guid></item><item><title>Enhancing Code-switched Text-to-Speech Synthesis Capability in Large Language Models with only Monolingual Corpora</title><link>http://arxiv.org/abs/2409.10969v2</link><description>While Large Language Models (LLMs) have shown potential in speech generationand recognition, their applications are mainly confined to monolingualscenarios, with limited explorations in code-switched (CS) contexts. In thispaper, we propose a Code-Switched Large Language Model (CS-LLM) to enhance thecode-switched text-to-speech synthesis (CS TTS) capability in LLMs with onlymonolingual corpora. Specifically, we begin by enhancing the multilingualspeech processing ability of LLMs through multilingual speech recognition andsynthesis tasks. Then, we develop an effective code-switched (CS) dataconstruction strategy that splits and concatenates words from differentmonolingual speech corpora to equip LLMs with improved CS TTS ability.Experiments show that our approach outperforms baselines in CS TTS in terms ofnaturalness, speaker consistency and similarity even with limited data.Additionally, the constructed CS data further improves multilingual speechsynthesis and recognition.</description><author>Jing Xu, Daxin Tan, Jiaqi Wang, Xiao Chen</author><pubDate>Fri, 22 Aug 2025 16:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10969v2</guid></item><item><title>Zero-Shot Skeleton-based Action Recognition with Dual Visual-Text Alignment</title><link>http://arxiv.org/abs/2409.14336v2</link><description>Zero-shot action recognition, which addresses the issue of scalability andgeneralization in action recognition and allows the models to adapt to new andunseen actions dynamically, is an important research topic in computer visioncommunities. The key to zero-shot action recognition lies in aligning visualfeatures with semantic vectors representing action categories. Most existingmethods either directly project visual features onto the semantic space of textcategory or learn a shared embedding space between the two modalities. However,a direct projection cannot accurately align the two modalities, and learningrobust and discriminative embedding space between visual and textrepresentations is often difficult. To address these issues, we introduce DualVisual-Text Alignment (DVTA) for skeleton-based zero-shot action recognition.The DVTA consists of two alignment modules--Direct Alignment (DA) and AugmentedAlignment (AA)--along with a designed Semantic Description Enhancement (SDE).The DA module maps the skeleton features to the semantic space through aspecially designed visual projector, followed by the SDE, which is based oncross-attention to enhance the connection between skeleton and text, therebyreducing the gap between modalities. The AA module further strengthens thelearning of the embedding space by utilizing deep metric learning to learn thesimilarity between skeleton and text. Our approach achieves state-of-the-artperformances on several popular zero-shot skeleton-based action recognitionbenchmarks. The code is available at: https://github.com/jidongkuang/DVTA.</description><author>Jidong Kuang, Hongsong Wang, Chaolei Han, Yang Zhang, Jie Gui</author><pubDate>Fri, 22 Aug 2025 16:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.14336v2</guid></item><item><title>Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning</title><link>http://arxiv.org/abs/2508.10848v2</link><description>Amidst a shortage of qualified mental health professionals, the integrationof large language models (LLMs) into psychological applications offers apromising way to alleviate the growing burden of mental health disorders.Recent reasoning-augmented LLMs have achieved remarkable performance inmathematics and programming, while research in the psychological domain haspredominantly emphasized emotional support and empathetic dialogue, withlimited attention to reasoning mechanisms that are beneficial to generatingreliable responses. Therefore, in this paper, we propose Psyche-R1, the firstChinese psychological LLM that jointly integrates empathy, psychologicalexpertise, and reasoning, built upon a novel data curation pipeline.Specifically, we design a comprehensive data synthesis pipeline that producesover 75k high-quality psychological questions paired with detailed rationales,generated through chain-of-thought (CoT) reasoning and iterativeprompt-rationale optimization, along with 73k empathetic dialogues.Subsequently, we employ a hybrid training strategy wherein challenging samplesare identified through a multi-LLM cross-selection strategy for group relativepolicy optimization (GRPO) to improve reasoning ability, while the remainingdata is used for supervised fine-tuning (SFT) to enhance empathetic responsegeneration and psychological domain knowledge. Extensive experiment resultsdemonstrate the effectiveness of the Psyche-R1 across several psychologicalbenchmarks, where our 7B Psyche-R1 achieves comparable results to 671BDeepSeek-R1.</description><author>Chongyuan Dai, Jinpeng Hu, Hongchang Shi, Zhuo Li, Xun Yang, Meng Wang</author><pubDate>Fri, 22 Aug 2025 16:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.10848v2</guid></item><item><title>FLAIR: Frequency and Locality-Aware Implicit Neural Representations</title><link>http://arxiv.org/abs/2508.13544v2</link><description>Implicit Neural Representations (INRs) leverage neural networks to mapcoordinates to corresponding signals, enabling continuous and compactrepresentations. This paradigm has driven significant advances in variousvision tasks. However, existing INRs lack frequency selectivity, spatiallocalization, and sparse representations, leading to an over-reliance onredundant signal components. Consequently, they exhibit spectral bias, tendingto learn low-frequency components early while struggling to capture finehigh-frequency details. To address these issues, we propose FLAIR (Frequency-and Locality-Aware Implicit Neural Representations), which incorporates two keyinnovations. The first is RC-GAUSS, a novel activation designed for explicitfrequency selection and spatial localization under the constraints of thetime-frequency uncertainty principle (TFUP). The second isWavelet-Energy-Guided Encoding (WEGE), which leverages the discrete wavelettransform (DWT) to compute energy scores and explicitly guide frequencyinformation to the network. Our method consistently outperforms existing INRsin 2D image representation and restoration, as well as 3D reconstruction.</description><author>Sukhun Ko, Dahyeon Kye, Kyle Min, Chanho Eom, Jihyong Oh</author><pubDate>Fri, 22 Aug 2025 16:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13544v2</guid></item><item><title>Enhancing and Scaling Search Query Datasets for Recommendation Systems</title><link>http://arxiv.org/abs/2505.11176v2</link><description>This paper presents a deployed, production-grade system designed to enhanceand scale search query datasets for intent-based recommendation systems indigital banking. In real-world environments, the growing volume and complexityof user intents create substantial challenges for data management, resulting insuboptimal recommendations and delayed product onboarding. To overcome thesechallenges, our approach shifts the focus from model-centric enhancements toautomated, data-centric strategies. The proposed system integrates three coremodules: Synthetic Query Generation, Intent Disambiguation, and Intent GapAnalysis. Synthetic Query Generation produces diverse and realistic userqueries. Our experiments reveal no statistically significant difference whenusing synthetic data for Clinc150, while Banking77 and a proprietary datasetshow significant differences. We dig into the underlying factors driving thesevariations, demonstrating that our approach effectively alleviates the coldstart problem (i.e. the challenge of recommending new products with limitedhistorical data). Intent Disambiguation refines broad and overlapping intentcategories into precise subintents, achieving an F1 score of 0.863 $\pm$ 0.127against expert reannotations and leading to clearer differentiation and moreprecise recommendation mapping. Meanwhile, Intent Gap Analysis identifieslatent customer needs by extracting novel intents from unlabeled queries;recovery rates reach up to 71\% in controlled evaluations. Deployed in a livebanking environment, our system demonstrates significant improvements inrecommendation precision and operation agility, ultimately delivering enhanceduser experiences and strategic business benefits. This work underscores therole of high-quality, scalable data in modern AI-driven applications andadvocates a proactive approach to data enhancement as a key driver of value.</description><author>Aaron Rodrigues, Mahmood Hegazy, Azzam Naeem</author><pubDate>Fri, 22 Aug 2025 16:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.11176v2</guid></item><item><title>SafeSpace: An Integrated Web Application for Digital Safety and Emotional Well-being</title><link>http://arxiv.org/abs/2508.16488v1</link><description>In the digital era, individuals are increasingly exposed to online harms suchas toxicity, manipulation, and grooming, which often pose emotional and safetyrisks. Existing systems for detecting abusive content or issuing safety alertsoperate in isolation and rarely combine digital safety with emotionalwell-being. In this paper, we present SafeSpace, a unified web application thatintegrates three modules: (1) toxicity detection in chats and screenshots usingNLP models and Google's Perspective API, (2) a configurable safety ping systemthat issues emergency alerts with the user's live location (longitude andlatitude) via SMTP-based emails when check-ins are missed or SOS alerts aremanually triggered, and (3) a reflective questionnaire that evaluatesrelationship health and emotional resilience. The system employs Firebase foralert management and a modular architecture designed for usability, privacy,and scalability. The experimental evaluation shows 93% precision in toxicitydetection, 100% reliability in safety alerts under emulator tests, and 92%alignment between automated and manual questionnaire scoring. SafeSpace,implemented as a web application, demonstrates the feasibility of integratingdetection, protection, and reflection within a single platform, with futuredeployment envisioned as a mobile application for broader accessibility.</description><author>Kayenat Fatmi, Mohammad Abbas</author><pubDate>Fri, 22 Aug 2025 16:07:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16488v1</guid></item><item><title>FraPPE: Fast and Efficient Preference-based Pure Exploration</title><link>http://arxiv.org/abs/2508.16487v1</link><description>Preference-based Pure Exploration (PrePEx) aims to identify with a givenconfidence level the set of Pareto optimal arms in a vector-valued (akamulti-objective) bandit, where the reward vectors are ordered via a (given)preference cone $\mathcal{C}$. Though PrePEx and its variants are well-studied,there does not exist a computationally efficient algorithm that can optimallytrack the existing lower bound for arbitrary preference cones. We successfullyfill this gap by efficiently solving the minimisation and maximisation problemsin the lower bound. First, we derive three structural properties of the lowerbound that yield a computationally tractable reduction of the minimisationproblem. Then, we deploy a Frank-Wolfe optimiser to accelerate the maximisationproblem in the lower bound. Together, these techniques solve the maxminoptimisation problem in $\mathcal{O}(KL^{2})$ time for a bandit instance with$K$ arms and $L$ dimensional reward, which is a significant acceleration overthe literature. We further prove that our proposed PrePEx algorithm, FraPPE,asymptotically achieves the optimal sample complexity. Finally, we performnumerical experiments across synthetic and real datasets demonstrating thatFraPPE achieves the lowest sample complexities to identify the exact Pareto setamong the existing algorithms.</description><author>Udvas Das, Apurv Shukla, Debabrota Basu</author><pubDate>Fri, 22 Aug 2025 16:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16487v1</guid></item><item><title>Underdamped Langevin MCMC with third order convergence</title><link>http://arxiv.org/abs/2508.16485v1</link><description>In this paper, we propose a new numerical method for the underdamped Langevindiffusion (ULD) and present a non-asymptotic analysis of its sampling error inthe 2-Wasserstein distance when the $d$-dimensional target distribution$p(x)\propto e^{-f(x)}$ is strongly log-concave and has varying degrees ofsmoothness. Precisely, under the assumptions that the gradient and Hessian of$f$ are Lipschitz continuous, our algorithm achieves a 2-Wasserstein error of$\varepsilon$ in $\mathcal{O}(\sqrt{d}/\varepsilon)$ and$\mathcal{O}(\sqrt{d}/\sqrt{\varepsilon})$ steps respectively. Therefore, ouralgorithm has a similar complexity as other popular Langevin MCMC algorithmsunder matching assumptions. However, if we additionally assume that the thirdderivative of $f$ is Lipschitz continuous, then our algorithm achieves a2-Wasserstein error of $\varepsilon$ in$\mathcal{O}(\sqrt{d}/\varepsilon^{\frac{1}{3}})$ steps. To the best of ourknowledge, this is the first gradient-only method for ULD with third orderconvergence. To support our theory, we perform Bayesian logistic regressionacross a range of real-world datasets, where our algorithm achieves competitiveperformance compared to an existing underdamped Langevin MCMC algorithm and thepopular No U-Turn Sampler (NUTS).</description><author>Maximilian Scott, Dáire O'Kane, Andraž Jelinčič, James Foster</author><pubDate>Fri, 22 Aug 2025 16:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16485v1</guid></item><item><title>Is Small Language Model the Silver Bullet to Low-Resource Languages Machine Translation?</title><link>http://arxiv.org/abs/2503.24102v3</link><description>Low-resource languages (LRLs) lack sufficient linguistic resources and areunderrepresented in benchmark datasets, resulting in persistently lowertranslation quality than high-resource languages, especially inprivacy-sensitive and resource-limited contexts. Firstly, this studysystematically evaluates state-of-the-art smaller Large Language Models in 200languages using the FLORES-200 benchmark, highlighting persistent deficienciesand disparities in the translation of LRLs. To mitigate these limitations, weinvestigate knowledge distillation from large pre-trained teacher models toSmall Language Models (SLMs) through supervised fine-tuning. The results showsubstantial improvements; for example, the translation performance of Englishto Luxembourgish (EN to LB), measured by the LLM-as-a-Judge score, increasesfrom 0.36 to 0.89 in the validation set for Llama-3.2-3B. We furtherinvestigate various fine-tuning configurations and tasks to clarify thetrade-offs between data scale and training efficiency, verify that the modelretains its general capabilities without significant catastrophic forgettingafter training, and explore the distillation benefits to other LRLs on SLMs(Khasi, Assamese, and Ukrainian). In general, this work exposes the limitationsand fairness issues of current SLMs in LRL translation and systematicallyexplores the potential of using the distillation of knowledge from large tosmall models, offering practical, empirically grounded recommendations toimprove LRL translation systems</description><author>Yewei Song, Lujun Li, Cedric Lothritz, Saad Ezzini, Lama Sleem, Niccolo Gentile, Radu State, Tegawendé F. Bissyandé, Jacques Klein</author><pubDate>Fri, 22 Aug 2025 15:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.24102v3</guid></item><item><title>Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning</title><link>http://arxiv.org/abs/2508.12692v2</link><description>Class-incremental with repetition (CIR), where previously trained classesrepeatedly introduced in future tasks, is a more realistic scenario than thetraditional class incremental setup, which assumes that each task containsunseen classes. CIR assumes that we can easily access abundant unlabeled datafrom external sources, such as the Internet. Therefore, we propose twocomponents that efficiently use the unlabeled data to ensure the high stabilityand the plasticity of models trained in CIR setup. First, we introducemulti-level knowledge distillation (MLKD) that distills knowledge from multipleprevious models across multiple perspectives, including features and logits, sothe model can maintain much various previous knowledge. Moreover, we implementdynamic self-supervised loss (SSL) to utilize the unlabeled data thataccelerates the learning of new classes, while dynamic weighting of SSL keepsthe focus of training to the primary task. Both of our proposed componentssignificantly improve the performance in CIR setup, achieving 2nd place in theCVPR 5th CLVISION Challenge.</description><author>Taeheon Kim, San Kim, Minhyuk Seo, Dongjae Jeon, Wonje Jeung, Jonghyun Choi</author><pubDate>Fri, 22 Aug 2025 15:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.12692v2</guid></item><item><title>HAMSA: Hijacking Aligned Compact Models via Stealthy Automation</title><link>http://arxiv.org/abs/2508.16484v1</link><description>Large Language Models (LLMs), especially their compact efficiency-orientedvariants, remain susceptible to jailbreak attacks that can elicit harmfuloutputs despite extensive alignment efforts. Existing adversarial promptgeneration techniques often rely on manual engineering or rudimentaryobfuscation, producing low-quality or incoherent text that is easily flagged byperplexity-based filters. We present an automated red-teaming framework thatevolves semantically meaningful and stealthy jailbreak prompts for alignedcompact LLMs. The approach employs a multi-stage evolutionary search, wherecandidate prompts are iteratively refined using a population-based strategyaugmented with temperature-controlled variability to balance exploration andcoherence preservation. This enables the systematic discovery of promptscapable of bypassing alignment safeguards while maintaining natural languagefluency. We evaluate our method on benchmarks in English (In-The-Wild JailbreakPrompts on LLMs), and a newly curated Arabic one derived from In-The-WildJailbreak Prompts on LLMs and annotated by native Arabic linguists, enablingmultilingual assessment.</description><author>Alexey Krylov, Iskander Vagizov, Dmitrii Korzh, Maryam Douiba, Azidine Guezzaz, Vladimir Kokh, Sergey D. Erokhin, Elena V. Tutubalina, Oleg Y. Rogov</author><pubDate>Fri, 22 Aug 2025 15:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16484v1</guid></item><item><title>Flow Matching-Based Generative Modeling for Efficient and Scalable Data Assimilation</title><link>http://arxiv.org/abs/2508.13313v2</link><description>Data assimilation (DA) is the problem of sequentially estimating the state ofa dynamical system from noisy observations. Recent advances in generativemodeling have inspired new approaches to DA in high-dimensional nonlinearsettings, especially the ensemble score filter (EnSF). However, these come at asignificant computational burden due to slow sampling. In this paper, weintroduce a new filtering framework based on flow matching (FM) -- called theensemble flow filter (EnFF) -- to accelerate sampling and enable flexibledesign of probability paths. EnFF -- a training-free DA approach -- integratesMC estimators for the marginal FM vector field (VF) and a localized guidance toassimilate observations. EnFF has faster sampling and more flexibility in VFdesign compared to existing generative modeling for DA. Theoretically, we showthat EnFF encompasses classical filtering methods such as the bootstrapparticle filter and the ensemble Kalman filter as special cases. Experiments onhigh-dimensional filtering benchmarks demonstrate improved cost-accuracytradeoffs and the ability to leverage larger ensembles than prior methods. Ourresults highlight the promise of FM as a scalable tool for filtering inhigh-dimensional applications that enable the use of large ensembles.</description><author>Taos Transue, Bohan Chen, So Takao, Bao Wang</author><pubDate>Fri, 22 Aug 2025 15:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13313v2</guid></item><item><title>Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms</title><link>http://arxiv.org/abs/2508.16481v1</link><description>Ensuring the safe use of agentic systems requires a thorough understanding ofthe range of malicious behaviors these systems may exhibit when under attack.In this paper, we evaluate the robustness of LLM-based agentic systems againstattacks that aim to elicit harmful actions from agents. To this end, we proposea novel taxonomy of harms for agentic systems and a novel benchmark, BAD-ACTS,for studying the security of agentic systems with respect to a wide range ofharmful actions. BAD-ACTS consists of 4 implementations of agentic systems indistinct application environments, as well as a dataset of 188 high-qualityexamples of harmful actions. This enables a comprehensive study of therobustness of agentic systems across a wide range of categories of harmfulbehaviors, available tools, and inter-agent communication structures. Usingthis benchmark, we analyze the robustness of agentic systems against anattacker that controls one of the agents in the system and aims to manipulateother agents to execute a harmful target action. Our results show that theattack has a high success rate, demonstrating that even a single adversarialagent within the system can have a significant impact on the security. Thisattack remains effective even when agents use a simple prompting-based defensestrategy. However, we additionally propose a more effective defense based onmessage monitoring. We believe that this benchmark provides a diverse testbedfor the security research of agentic systems. The benchmark can be found atgithub.com/JNoether/BAD-ACTS</description><author>Jonathan Nöther, Adish Singla, Goran Radanovic</author><pubDate>Fri, 22 Aug 2025 15:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16481v1</guid></item><item><title>Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization</title><link>http://arxiv.org/abs/2508.16479v1</link><description>Histopathology remains the gold standard for cancer diagnosis and prognosis.With the advent of transcriptome profiling, multi-modal learning combiningtranscriptomics with histology offers more comprehensive information. However,existing multi-modal approaches are challenged by intrinsic multi-modalheterogeneity, insufficient multi-scale integration, and reliance on paireddata, restricting clinical applicability. To address these challenges, wepropose a disentangled multi-modal framework with four contributions: 1) Tomitigate multi-modal heterogeneity, we decompose WSIs and transcriptomes intotumor and microenvironment subspaces using a disentangled multi-modal fusionmodule, and introduce a confidence-guided gradient coordination strategy tobalance subspace optimization. 2) To enhance multi-scale integration, wepropose an inter-magnification gene-expression consistency strategy that alignstranscriptomic signals across WSI magnifications. 3) To reduce dependency onpaired data, we propose a subspace knowledge distillation strategy enablingtranscriptome-agnostic inference through a WSI-only student model. 4) Toimprove inference efficiency, we propose an informative token aggregationmodule that suppresses WSI redundancy while preserving subspace semantics.Extensive experiments on cancer diagnosis, prognosis, and survival predictiondemonstrate our superiority over state-of-the-art methods across multiplesettings. Code is available athttps://github.com/helenypzhang/Disentangled-Multimodal-Learning.</description><author>Yupei Zhang, Xiaofei Wang, Anran Liu, Lequan Yu, Chao Li</author><pubDate>Fri, 22 Aug 2025 15:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16479v1</guid></item><item><title>Source-Guided Flow Matching</title><link>http://arxiv.org/abs/2508.14807v2</link><description>Guidance of generative models is typically achieved by modifying theprobability flow vector field through the addition of a guidance field. In thispaper, we instead propose the Source-Guided Flow Matching (SGFM) framework,which modifies the source distribution directly while keeping the pre-trainedvector field intact. This reduces the guidance problem to a well-definedproblem of sampling from the source distribution. We theoretically show thatSGFM recovers the desired target distribution exactly. Furthermore, we providebounds on the Wasserstein error for the generated distribution when using anapproximate sampler of the source distribution and an approximate vector field.The key benefit of our approach is that it allows the user to flexibly choosethe sampling method depending on their specific problem. To illustrate this, wesystematically compare different sampling methods and discuss conditions forasymptotically exact guidance. Moreover, our framework integrates well withoptimal flow matching models since the straight transport map generated by thevector field is preserved. Experimental results on synthetic 2D benchmarks,physics-informed generative tasks, and imaging inverse problems demonstrate theeffectiveness and flexibility of the proposed framework.</description><author>Zifan Wang, Alice Harting, Matthieu Barreau, Michael M. Zavlanos, Karl H. Johansson</author><pubDate>Fri, 22 Aug 2025 15:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.14807v2</guid></item><item><title>LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models</title><link>http://arxiv.org/abs/2508.16478v1</link><description>The advent of Large Language Models (LLMs) has provided unprecedentedcapabilities for analyzing unstructured text data. However, deploying thesemodels as reliable, robust, and scalable classifiers in production environmentspresents significant methodological challenges. Standard fine-tuning approachescan be resource-intensive and often struggle with the dynamic nature ofreal-world data distributions, which is common in the industry. In this paper,we propose a comprehensive, semi-supervised framework that leverages the zero-and few-shot capabilities of LLMs for building hierarchical text classifiers asa framework for a solution to these industry-wide challenges. Our methodologyemphasizes an iterative, human-in-the-loop process that begins with domainknowledge elicitation and progresses through prompt refinement, hierarchicalexpansion, and multi-faceted validation. We introduce techniques for assessingand mitigating sequence-based biases and outline a protocol for continuousmonitoring and adaptation. This framework is designed to bridge the gap betweenthe raw power of LLMs and the practical need for accurate, interpretable, andmaintainable classification systems in industry applications.</description><author>Doohee You, Andy Parisi, Zach Vander Velden, Lara Dantas Inojosa</author><pubDate>Fri, 22 Aug 2025 15:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16478v1</guid></item><item><title>NOSTRA: A noise-resilient and sparse data framework for trust region based multi objective Bayesian optimization</title><link>http://arxiv.org/abs/2508.16476v1</link><description>Multi-objective Bayesian optimization (MOBO) struggles with sparse(non-space-filling), scarce (limited observations) datasets affected byexperimental uncertainty, where identical inputs can yield varying outputs.These challenges are common in physical and simulation experiments (e.g.,randomized medical trials and, molecular dynamics simulations) and aretherefore incompatible with conventional MOBO methods. As a result,experimental resources are inefficiently allocated, leading to suboptimaldesigns. To address this challenge, we introduce NOSTRA (Noisy and Sparse DataTrust Region-based Optimization Algorithm), a novel sampling framework thatintegrates prior knowledge of experimental uncertainty to construct moreaccurate surrogate models while employing trust regions to focus sampling onpromising areas of the design space. By strategically leveraging priorinformation and refining search regions, NOSTRA accelerates convergence to thePareto frontier, enhances data efficiency, and improves solution quality.Through two test functions with varying levels of experimental uncertainty, wedemonstrate that NOSTRA outperforms existing methods in handling noisy, sparse,and scarce data. Specifically, we illustrate that, NOSTRA effectivelyprioritizes regions where samples enhance the accuracy of the identified Paretofrontier, offering a resource-efficient algorithm that is practical inscenarios with limited experimental budgets while ensuring efficientperformance.</description><author>Maryam Ghasemzadeh, Anton van Beek</author><pubDate>Fri, 22 Aug 2025 15:43:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16476v1</guid></item><item><title>Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs)</title><link>http://arxiv.org/abs/2508.16474v1</link><description>This work presents a novel reinforcement learning (RL) algorithm based onY-wise Affine Neural Networks (YANNs). YANNs provide an interpretable neuralnetwork which can exactly represent known piecewise affine functions ofarbitrary input and output dimensions defined on any amount of polytopicsubdomains. One representative application of YANNs is to reformulate explicitsolutions of multi-parametric linear model predictive control. Built on this,we propose the use of YANNs to initialize RL actor and critic networks, whichenables the resulting YANN-RL control algorithm to start with the confidence oflinear optimal control. The YANN-actor is initialized by representing themulti-parametric control solutions obtained via offline computation using anapproximated linear system model. The YANN-critic represents the explicit formof the state-action value function for the linear system and the rewardfunction as the objective in an optimal control problem (OCP). Additionalnetwork layers are injected to extend YANNs for nonlinear expressions, whichcan be trained online by directly interacting with the true complex nonlinearsystem. In this way, both the policy and state-value functions exactlyrepresent a linear OCP initially and are able to eventually learn the solutionof a general nonlinear OCP. Continuous policy improvement is also implementedto provide heuristic confidence that the linear OCP solution serves as aneffective lower bound to the performance of RL policy. The YANN-RL algorithm isdemonstrated on a clipped pendulum and a safety-critical chemical-reactivesystem. Our results show that YANN-RL significantly outperforms the modern RLalgorithm using deep deterministic policy gradient, especially when consideringsafety constraints.</description><author>Austin Braniff, Yuhe Tian</author><pubDate>Fri, 22 Aug 2025 15:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16474v1</guid></item><item><title>PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting</title><link>http://arxiv.org/abs/2508.13773v2</link><description>Long-term time series forecasting (LTSF) is a fundamental task withwide-ranging applications. Although Transformer-based models have madesignificant breakthroughs in forecasting, their effectiveness for time seriesforecasting remains debatable. In this paper, we revisit the significance ofself-attention and propose a simple yet effective mechanism, Periodic-NestedGroup Attention, namely PENGUIN. Our approach highlights the importance ofexplicitly modeling periodic patterns and incorporating relative attention biasfor effective time series modeling. To this end, we introduce a periodic-nestedrelative attention bias that captures periodic structures directly. To handlemultiple coexisting periodicities (e.g., daily and weekly cycles), we design agrouped attention mechanism, where each group targets a specific periodicityusing a multi-query attention mechanism. Extensive experiments across diversebenchmarks demonstrate that PENGUIN consistently outperforms both MLP-based andTransformer-based models.</description><author>Tian Sun, Yuqi Chen, Weiwei Sun</author><pubDate>Fri, 22 Aug 2025 15:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13773v2</guid></item><item><title>Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS</title><link>http://arxiv.org/abs/2508.14313v2</link><description>Test-time scaling (TTS) for large language models (LLMs) has thus far falleninto two largely separate paradigms: (1) reinforcement learning (RL) methodsthat optimize sparse outcome-based rewards, yet suffer from instability and lowsample efficiency; and (2) search-based techniques guided by independentlytrained, static process reward models (PRMs), which require expensive human- orLLM-generated labels and often degrade under distribution shifts. In thispaper, we introduce AIRL-S, the first natural unification of RL-based andsearch-based TTS. Central to AIRL-S is the insight that the reward functionlearned during RL training inherently represents the ideal PRM for guidingdownstream search. Specifically, we leverage adversarial inverse reinforcementlearning (AIRL) combined with group relative policy optimization (GRPO) tolearn a dense, dynamic PRM directly from correct reasoning traces, entirelyeliminating the need for labeled intermediate process data. At inference, theresulting PRM simultaneously serves as the critic for RL rollouts and as aheuristic to effectively guide search procedures, facilitating robust reasoningchain extension, mitigating reward hacking, and enhancing cross-taskgeneralization. Experimental results across eight benchmarks, includingmathematics, scientific reasoning, and code generation, demonstrate that ourunified approach improves performance by 9 % on average over the base model,matching GPT-4o. Furthermore, when integrated into multiple search algorithms,our PRM consistently outperforms all baseline PRMs trained with labeled data.These results underscore that, indeed, your reward function for RL is your bestPRM for search, providing a robust and cost-effective solution to complexreasoning tasks in LLMs.</description><author>Can Jin, Yang Zhou, Qixin Zhang, Hongwu Peng, Di Zhang, Marco Pavone, Ligong Han, Zhang-Wei Hong, Tong Che, Dimitris N. Metaxas</author><pubDate>Fri, 22 Aug 2025 15:37:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.14313v2</guid></item><item><title>MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications</title><link>http://arxiv.org/abs/2508.10991v2</link><description>The integration of Large Language Models (LLMs) with external tools viaprotocols such as the Model Context Protocol (MCP) introduces critical securityvulnerabilities, including prompt injection, data exfiltration, and otherthreats. To counter these challenges, we propose MCP-Guard, a robust, layereddefense architecture designed for LLM--tool interactions. MCP-Guard employs athree-stage detection pipeline that balances efficiency with accuracy: itprogresses from lightweight static scanning for overt threats and a deep neuraldetector for semantic attacks, to our fine-tuned E5-based model achieves(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLMarbitrator synthesizes these signals to deliver the final decision whileminimizing false positives. To facilitate rigorous training and evaluation, wealso introduce MCP-AttackBench, a comprehensive benchmark of over 70,000samples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBenchsimulates diverse, real-world attack vectors in the MCP format, providing afoundation for future research into securing LLM-tool ecosystems.</description><author>Wenpeng Xing, Zhonghao Qi, Yupeng Qin, Yilin Li, Caini Chang, Jiahui Yu, Changting Lin, Zhenzhen Xie, Meng Han</author><pubDate>Fri, 22 Aug 2025 15:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.10991v2</guid></item><item><title>Joint Optimization of Energy Consumption and Completion Time in Federated Learning</title><link>http://arxiv.org/abs/2209.14900v3</link><description>Federated Learning (FL) is an intriguing distributed machine learningapproach due to its privacy-preserving characteristics. To balance thetrade-off between energy and execution latency, and thus accommodate differentdemands and application scenarios, we formulate an optimization problem tominimize a weighted sum of total energy consumption and completion time throughtwo weight parameters. The optimization variables include bandwidth,transmission power and CPU frequency of each device in the FL system, where alldevices are linked to a base station and train a global model collaboratively.Through decomposing the non-convex optimization problem into two subproblems,we devise a resource allocation algorithm to determine the bandwidthallocation, transmission power, and CPU frequency for each participatingdevice. We further present the convergence analysis and computationalcomplexity of the proposed algorithm. Numerical results show that our proposedalgorithm not only has better performance at different weight parameters (i.e.,different demands) but also outperforms the state of the art.</description><author>Xinyu Zhou, Jun Zhao, Huimei Han, Claude Guet</author><pubDate>Fri, 22 Aug 2025 15:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.14900v3</guid></item><item><title>Arbitrary-Scale 3D Gaussian Super-Resolution</title><link>http://arxiv.org/abs/2508.16467v1</link><description>Existing 3D Gaussian Splatting (3DGS) super-resolution methods typicallyperform high-resolution (HR) rendering of fixed scale factors, making themimpractical for resource-limited scenarios. Directly rendering arbitrary-scaleHR views with vanilla 3DGS introduces aliasing artifacts due to the lack ofscale-aware rendering ability, while adding a post-processing upsampler for3DGS complicates the framework and reduces rendering efficiency. To tacklethese issues, we build an integrated framework that incorporates scale-awarerendering, generative prior-guided optimization, and progressivesuper-resolving to enable 3D Gaussian super-resolution of arbitrary scalefactors with a single 3D model. Notably, our approach supports both integer andnon-integer scale rendering to provide more flexibility. Extensive experimentsdemonstrate the effectiveness of our model in rendering high-qualityarbitrary-scale HR views (6.59 dB PSNR gain over 3DGS) with a single model. Itpreserves structural consistency with LR views and across different scales,while maintaining real-time rendering speed (85 FPS at 1080p).</description><author>Huimin Zeng, Yue Bai, Yun Fu</author><pubDate>Fri, 22 Aug 2025 15:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16467v1</guid></item><item><title>HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images</title><link>http://arxiv.org/abs/2508.16465v1</link><description>Hand-object 3D reconstruction has become increasingly important forapplications in human-robot interaction and immersive AR/VR experiences. Acommon approach for object-agnostic hand-object reconstruction from RGBsequences involves a two-stage pipeline: hand-object 3D tracking followed bymulti-view 3D reconstruction. However, existing methods rely on keypointdetection techniques, such as Structure from Motion (SfM) and hand-keypointoptimization, which struggle with diverse object geometries, weak textures, andmutual hand-object occlusions, limiting scalability and generalization. As akey enabler to generic and seamless, non-intrusive applicability, we propose inthis work a robust, keypoint detector-free approach to estimating hand-object3D transformations from monocular motion video/images. We further integratethis with a multi-view reconstruction pipeline to accurately recoverhand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not relyon pre-scanned object templates or camera intrinsics, and reachesstate-of-the-art performance for the tasks of object-agnostic hand-object 3Dtransformation and shape estimation on the SHOWMe benchmark. We also experimenton sequences from the HO3D dataset, demonstrating generalization to unseenobject categories.</description><author>Anilkumar Swamy, Vincent Leroy, Philippe Weinzaepfel, Jean-Sébastien Franco, Grégory Rogez</author><pubDate>Fri, 22 Aug 2025 15:30:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16465v1</guid></item><item><title>What makes an entity salient in discourse?</title><link>http://arxiv.org/abs/2508.16464v1</link><description>Entities in discourse vary broadly in salience: main participants, objectsand locations are noticeable and memorable, while tangential ones are lessimportant and quickly forgotten, raising questions about how humans signal andinfer relative salience. Using a graded operationalization of salience based onsummary-worthiness in multiple summaries of a discourse, this paper exploresdata from 24 spoken and written genres of English to extract a multifactorialcomplex of overt and implicit linguistic cues, such as recurring subjecthood ordefiniteness, discourse relations and hierarchy across utterances, as well aspragmatic functional inferences based on genre and communicative intent.Tackling the question 'how is the degree of salience expressed for each andevery entity mentioned?' our results show that while previous approaches tosalience all correlate with our salience scores to some extent, no singlegeneralization is without exceptions, and the phenomenon cuts across all levelsof linguistic representation.</description><author>Amir Zeldes, Jessica Lin</author><pubDate>Fri, 22 Aug 2025 15:30:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16464v1</guid></item><item><title>PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN</title><link>http://arxiv.org/abs/2502.12207v4</link><description>Deep neural networks have demonstrated remarkable performance across variousdomains. However, they are vulnerable to adversarial examples, which can leadto erroneous predictions. Generative Adversarial Networks (GANs) can leveragethe generators and discriminators model to quickly produce high-qualityadversarial examples. Since both modules train in a competitive andsimultaneous manner, GAN-based algorithms like AdvGAN can generate adversarialexamples with better transferability compared to traditional methods. However,the generation of perturbations is usually limited to a single iteration,preventing these examples from fully exploiting the potential of the methods.To tackle this issue, we introduce a novel approach named ProgressiveAuto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressiveiteration mechanism within a progressive generation network to craftadversarial examples with enhanced attack capability. We thoroughly evaluateour PAR-AdvGAN method with a large-scale experiment, demonstrating its superiorperformance over various state-of-the-art black-box adversarial attacks, aswell as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates theadversarial example generation, i.e., achieving the speeds of up to 335.5frames per second on Inception-v3 model, outperforming the gradient-basedtransferable attack algorithms. Our code is available at:https://github.com/LMBTough/PAR</description><author>Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Silin Liao, Zhibo Jin, Flora D. Salim, Huaming Chen</author><pubDate>Fri, 22 Aug 2025 15:26:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12207v4</guid></item><item><title>Modular Embedding Recomposition for Incremental Learning</title><link>http://arxiv.org/abs/2508.16463v1</link><description>The advent of pre-trained Vision-Language Models (VLMs) has significantlytransformed Continual Learning (CL), mainly due to their zero-shotclassification abilities. Such proficiency makes VLMs well-suited forreal-world applications, enabling robust performance on novel unseen classeswithout requiring adaptation. However, fine-tuning remains essential whendownstream tasks deviate significantly from the pre-training domain. Prior CLapproaches primarily focus on preserving the zero-shot capabilities of VLMsduring incremental fine-tuning on a downstream task. We take a step further bydevising an approach that transforms preservation into enhancement of thezero-shot capabilities of VLMs. Our approach, named MoDular EmbeddingRecomposition (MoDER), introduces a modular framework that trains multipletextual experts, each specialized in a single seen class, and stores them in afoundational hub. At inference time, for each unseen class, we query the huband compose the retrieved experts to synthesize a refined prototype thatimproves classification. We show the effectiveness of our method across twopopular zero-shot incremental protocols, Class-IL and MTIL, comprising a totalof 14 datasets. The codebase is available athttps://github.com/aimagelab/mammoth.</description><author>Aniello Panariello, Emanuele Frascaroli, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara</author><pubDate>Fri, 22 Aug 2025 15:25:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16463v1</guid></item><item><title>Learning Noise-Robust Stable Koopman Operator for Control with Hankel DMD</title><link>http://arxiv.org/abs/2408.06607v6</link><description>We propose a noise-robust learning framework for the Koopman operator ofnonlinear dynamical systems, with guaranteed long-term stability and improvedmodel performance for better model-based predictive control tasks. Unlike someexisting approaches that rely on ad hoc observables or black-box neuralnetworks in extended dynamic mode decomposition (EDMD), our framework leveragesobservables generated by the system dynamics, when the system dynamics isknown, through a Hankel matrix, which shares similarities with discretePolyflow. When system dynamics is unknown, we approximate them with a neuralnetwork while maintaining structural similarities to discrete Polyflow. Toenhance noise robustness and ensure long-term stability, we developed a stableparameterization of the Koopman operator, along with a progressive learningstrategy for rollout loss. To further improve the performance of the model inthe phase space, a simple iterative data augmentation strategy was developed.Numerical experiments of prediction and control of classic nonlinear systemswith ablation study showed the effectiveness of the proposed techniques overseveral state-of-the-art practices.</description><author>Shahriar Akbar Sakib, Shaowu Pan</author><pubDate>Fri, 22 Aug 2025 15:22:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06607v6</guid></item><item><title>A Probabilistic Inference Scaling Theory for LLM Self-Correction</title><link>http://arxiv.org/abs/2508.16456v1</link><description>Large Language Models (LLMs) have demonstrated the capability to refine theirgenerated answers through self-correction, enabling continuous performanceimprovement over multiple rounds. However, the mechanisms underlying how andwhy accuracy evolves during this iterative process remain unexplored. To fillthis gap, we propose a probabilistic theory to model the dynamics of accuracychange and explain the performance improvements observed in multi-roundself-correction. Through mathematical derivation, we establish that theaccuracy after the $t^{th}$ round of self-correction is given by: $Acc_t = Upp- \alpha^t(Upp - Acc_0),$ where $Acc_0$ denotes the initial accuracy, $Upp$represents the upper bound of accuracy convergence, and $\alpha$ determines therate of convergence. Based on our theory, these parameters can be calculatedand the predicted accuracy curve then can be obtained through only a singleround of self-correction. Extensive experiments across diverse models anddatasets demonstrate that our theoretical predictions align closely withempirical accuracy curves, validating the effectiveness of the theory. Our workprovides a theoretical foundation for understanding LLM self-correction, thuspaving the way for further explorations.</description><author>Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui</author><pubDate>Fri, 22 Aug 2025 15:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16456v1</guid></item><item><title>Anti-establishment sentiment on TikTok: Implications for understanding influence(rs) and expertise on social media</title><link>http://arxiv.org/abs/2508.16453v1</link><description>Distrust of public serving institutions and anti-establishment views are onthe rise (especially in the U.S.). As people turn to social media forinformation, it is imperative to understand whether and how social mediaenvironments may be contributing to distrust of institutions. In social media,content creators, influencers, and other opinion leaders often positionthemselves as having expertise and authority on a range of topics from healthto politics, and in many cases devalue and dismiss institutional expertise tobuild a following and increase their own visibility. However, the extent towhich this content appears and whether such content increases engagement isunclear. This study analyzes the prevalence of anti-establishment sentiment(AES) on the social media platform TikTok. Despite its popularity as a sourceof information, TikTok remains relatively understudied and may provideimportant insights into how people form attitudes towards institutions. Weemploy a computational approach to label TikTok posts as containing AES or notacross topical domains where content creators tend to frame themselves asexperts: finance and wellness. As a comparison, we also consider the topic ofconspiracy theories, where AES is expected to be common. We find that AES ismost prevalent in conspiracy theory content, and relatively rare in contentrelated to the other two topics. However, we find that engagement patterns withsuch content varies by area, and that there may be platform incentives forusers to post content that expresses anti-establishment sentiment.</description><author>Tianliang Xu, Ariel Hasell, Sabina Tomkins</author><pubDate>Fri, 22 Aug 2025 15:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16453v1</guid></item><item><title>Blink-to-code: real-time Morse code communication via eye blink detection and classification</title><link>http://arxiv.org/abs/2508.09344v2</link><description>This study proposes a real-time system that translates voluntary eye blinksinto Morse code, enabling communication for individuals with severe motorimpairments. Using a standard webcam and computer vision, the system detectsand classifies blinks as short (dot) or long (dash), then decodes them intoalphanumeric characters. Experiments with five participants show 62% decodingaccuracy and 18-20 seconds response times, demonstrating a viable, low-costassistive communication method.</description><author>Anushka Bhatt</author><pubDate>Fri, 22 Aug 2025 15:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.09344v2</guid></item><item><title>Beyond Interpretability: Exploring the Comprehensibility of Adaptive Video Streaming through Large Language Models</title><link>http://arxiv.org/abs/2508.16448v1</link><description>Over the past decade, adaptive video streaming technology has witnessedsignificant advancements, particularly driven by the rapid evolution of deeplearning techniques. However, the black-box nature of deep learning algorithmspresents challenges for developers in understanding decision-making processesand optimizing for specific application scenarios. Although existing researchhas enhanced algorithm interpretability through decision tree conversion,interpretability does not directly equate to developers' subjectivecomprehensibility. To address this challenge, we introduce \texttt{ComTree},the first bitrate adaptation algorithm generation framework that considerscomprehensibility. The framework initially generates the complete set ofdecision trees that meet performance requirements, then leverages largelanguage models to evaluate these trees for developer comprehensibility,ultimately selecting solutions that best facilitate human understanding andenhancement. Experimental results demonstrate that \texttt{ComTree}significantly improves comprehensibility while maintaining competitiveperformance, showing potential for further advancement. The source code isavailable at https://github.com/thu-media/ComTree.</description><author>Lianchen Jia, Chaoyang Li, Ziqi Yuan, Jiahui Chen, Tianchi Huang, Jiangchuan Liu, Lifeng Sun</author><pubDate>Fri, 22 Aug 2025 15:05:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16448v1</guid></item><item><title>Boardwalk: Towards a Framework for Creating Board Games with LLMs</title><link>http://arxiv.org/abs/2508.16447v1</link><description>Implementing board games in code can be a time-consuming task. However, LargeLanguage Models (LLMs) have been proven effective at generating code fordomain-specific tasks with simple contextual information. We aim to investigatewhether LLMs can implement digital versions of board games from rules describedin natural language. This would be a step towards an LLM-assisted framework forquick board game code generation. We expect to determine the main challengesfor LLMs to implement the board games, and how different approaches and modelscompare to one another. We task three state-of-the-art LLMs (Claude, DeepSeekand ChatGPT) with coding a selection of 12 popular and obscure games infree-form and within Boardwalk, our proposed General Game Playing API. Weanonymize the games and components to avoid evoking pre-trained LLM knowledge.The implementations are tested for playability and rule compliance. We evaluatesuccess rate and common errors across LLMs and game popularity. Our approachproves viable, with the best performing model, Claude 3.7 Sonnet, yielding55.6\% of games without any errors. While compliance with the API increaseserror frequency, the severity of errors is more significantly dependent on theLLM. We outline future steps for creating a framework to integrate thisprocess, making the elaboration of board games more accessible.</description><author>Álvaro Guglielmin Becker, Gabriel Bauer de Oliveira, Lana Bertoldo Rossato, Anderson Rocha Tavares</author><pubDate>Fri, 22 Aug 2025 15:02:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16447v1</guid></item><item><title>Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework</title><link>http://arxiv.org/abs/2508.16440v1</link><description>Urban Air Mobility (UAM) envisions the widespread use of small aerialvehicles to transform transportation in dense urban environments. However, UAMfaces critical operational challenges, particularly the balance betweenminimizing noise exposure and maintaining safe separation in low-altitude urbanairspace, two objectives that are often addressed separately. We propose areinforcement learning (RL)-based air traffic management system that integratesboth noise and safety considerations within a unified, decentralized framework.Under this scalable air traffic coordination solution, agents operate in astructured, multi-layered airspace and learn altitude adjustment policies tojointly manage noise impact and separation constraints. The system demonstratesstrong performance across both objectives and reveals tradeoffs amongseparation, noise exposure, and energy efficiency under high traffic density.The findings highlight the potential of RL and multi-objective coordinationstrategies in enhancing the safety, quietness, and efficiency of UAMoperations.</description><author>Surya Murthy, Zhenyu Gao, John-Paul Clarke, Ufuk Topcu</author><pubDate>Fri, 22 Aug 2025 14:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16440v1</guid></item><item><title>GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling</title><link>http://arxiv.org/abs/2508.13653v2</link><description>Training modern neural networks on large datasets is computationally andenvironmentally costly. We introduce GRAFT, a scalable in-training subsetselection method that (i) extracts a low-rank feature representation for eachbatch, (ii) applies a Fast MaxVol sampler to select a small, diverse subsetthat spans the batch's dominant subspace, and (iii) dynamically adjusts thesubset size using a gradient-approximation criterion. By operating in low-ranksubspaces and training on carefully chosen examples instead of full batches,GRAFT preserves the training trajectory while reducing wall-clock time, energyconsumption, and $\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFTmatches or exceeds recent selection baselines in both accuracy and efficiency,providing a favorable trade-off between accuracy, efficiency, and emissions.</description><author>Ashish Jha, Anh huy Phan, Razan Dibo, Valentin Leplat</author><pubDate>Fri, 22 Aug 2025 14:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.13653v2</guid></item><item><title>PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark</title><link>http://arxiv.org/abs/2508.16439v1</link><description>Large language models (LLMs) and vision-augmented LLMs (VLMs) havesignificantly advanced medical informatics, diagnostics, and decision support.However, these models exhibit systematic biases, particularly age bias,compromising their reliability and equity. This is evident in their poorerperformance on pediatric-focused text and visual question-answering tasks. Thisbias reflects a broader imbalance in medical research, where pediatric studiesreceive less funding and representation despite the significant disease burdenin children. To address these issues, a new comprehensive multi-modal pediatricquestion-answering benchmark, PediatricsMQA, has been introduced. It consistsof 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatrictopics across seven developmental stages (prenatal to adolescent) and 2,067vision-based MCQs using 634 pediatric images from 67 imaging modalities and 256anatomical regions. The dataset was developed using a hybrid manual-automaticpipeline, incorporating peer-reviewed pediatric literature, validated questionbanks, existing benchmarks, and existing QA resources. Evaluatingstate-of-the-art open models, we find dramatic performance drops in youngercohorts, highlighting the need for age-aware methods to ensure equitable AIsupport in pediatric care.</description><author>Adil Bahaj, Mounir Ghogho</author><pubDate>Fri, 22 Aug 2025 14:50:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16439v1</guid></item><item><title>OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval</title><link>http://arxiv.org/abs/2508.16438v1</link><description>Recent advances in large language models (LLMs) and dense retrievers havedriven significant progress in retrieval-augmented generation (RAG). However,existing approaches face significant challenges in complex reasoning-orientedmulti-hop retrieval tasks: 1) Ineffective reasoning-oriented planning: Priormethods struggle to generate robust multi-step plans for complex queries, asrule-based decomposers perform poorly on out-of-template questions. 2)Suboptimal reasoning-driven retrieval: Related methods employ limited queryreformulation, leading to iterative retrieval loops that often fail to locategolden documents. 3) Insufficient reasoning-guided filtering: Prevailingmethods lack the fine-grained reasoning to effectively filter salientinformation from noisy results, hindering utilization of retrieved knowledge.Fundamentally, these limitations all stem from the weak coupling betweenretrieval and reasoning in current RAG architectures. We introduce theOrchestrated Planner-Executor Reasoning Architecture (OPERA), a novelreasoning-driven retrieval framework. OPERA's Goal Planning Module (GPM)decomposes questions into sub-goals, which are executed by a Reason-ExecuteModule (REM) with specialized components for precise reasoning and effectiveretrieval. To train OPERA, we propose Multi-Agents Progressive Group RelativePolicy Optimization (MAPGRPO), a novel variant of GRPO. Experiments on complexmulti-hop benchmarks show OPERA's superior performance, validating both theMAPGRPO method and OPERA's design. Code is available athttps://github.com/Ameame1/OPERA.</description><author>Yu Liu, Yanbing Liu, Fangfang Yuan, Cong Cao, Youbang Sun, Kun Peng, WeiZhuo Chen, Jianjun Li, Zhiyuan Ma</author><pubDate>Fri, 22 Aug 2025 14:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16438v1</guid></item><item><title>Coarse-to-Fine Process Reward Modeling for Mathematical Reasoning</title><link>http://arxiv.org/abs/2501.13622v4</link><description>The Process Reward Model (PRM) plays a crucial role in mathematical reasoningtasks, requiring high-quality supervised process data. However, we observe thatreasoning steps generated by Large Language Models (LLMs) often fail to exhibitstrictly incremental information, leading to redundancy that can hindereffective reasoning. To address this issue, we propose CFPRM, a simple yeteffective coarse-to-fine strategy. Instead of focusing on the detection ofredundant steps, our approach first establishes a coarse-grained window tomerge adjacent reasoning steps into unified, holistic steps. The window size isthen progressively reduced to extract fine-grained reasoning steps, enablingdata collection at multiple granularities for training. By leveraging thishierarchical refinement process, CFPRM mitigates redundancy while preservingessential fine-grained knowledge. Extensive experiments on two reasoningdatasets across three loss criteria validate the CFPRM's effectiveness andversatility.</description><author>Yulan Hu, Sheng Ouyang, Jinman Zhao, Yong Liu</author><pubDate>Fri, 22 Aug 2025 14:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13622v4</guid></item><item><title>Deep Intrinsic Coregionalization Multi-Output Gaussian Process Surrogate with Active Learning</title><link>http://arxiv.org/abs/2508.16434v1</link><description>Deep Gaussian Processes (DGPs) are powerful surrogate models known for theirflexibility and ability to capture complex functions. However, extending themto multi-output settings remains challenging due to the need for efficientdependency modeling. We propose the Deep Intrinsic CoregionalizationMulti-Output Gaussian Process (deepICMGP) surrogate for computer simulationexperiments involving multiple outputs, which extends the IntrinsicCoregionalization Model (ICM) by introducing hierarchical coregionalizationstructures across layers. This enables deepICMGP to effectively model nonlinearand structured dependencies between multiple outputs, addressing keylimitations of traditional multi-output GPs. We benchmark deepICMGP againststate-of-the-art models, demonstrating its competitive performance.Furthermore, we incorporate active learning strategies into deepICMGP tooptimize sequential design tasks, enhancing its ability to efficiently selectinformative input locations for multi-output systems.</description><author>Chun-Yi Chang, Chih-Li Sung</author><pubDate>Fri, 22 Aug 2025 14:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16434v1</guid></item><item><title>CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention</title><link>http://arxiv.org/abs/2505.17097v2</link><description>Multimodal in-context learning (ICL) is emerging as a key capability thatenables large vision-language models (LVLMs) to adapt to novel tasks withoutparameter updates, expanding their utility across various real-worldapplications. However, ICL remains unstable, even with well-matched in-contextdemonstrations (ICDs), suggesting that LVLMs struggle to fully utilize theprovided context. While existing efforts focus on prompt engineering orpost-hoc logit calibration, we instead investigate the underlying attentiondynamics to overcome LVLMs' inherent limitations. We identify two criticaldeficits in their self-attention that impair effective ICL. To bridge the gap,we propose \textbf{Context-Aware Modulated Attention} (CAMA), a plug-and-playand training-free method that dynamically modulates LVLM's attention logitsbased on the input in-context sequence. CAMA employs a two-stage attentionmodulation to address both identified deficits, enhancing the focus onsemantically significant tokens, particularly visual ones. Across four LVLMsand seven benchmarks, CAMA consistently outperforms vanilla models andbaselines, demonstrating great effectiveness and generalization. It can alsoactivate the desired effects of prompt engineering methods and remains robustunder diverse sequence configurations. Thus, CAMA paves the way for deeperexplorations of attention dynamics to advance multimodal reasoning.</description><author>Yanshu Li, Jianjiang Yang, Ziteng Yang, Bozheng Li, Hongyang He, Zhengtao Yao, Ligong Han, Yingjie Victor Chen, Songlin Fei, Dongfang Liu, Ruixiang Tang</author><pubDate>Fri, 22 Aug 2025 14:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17097v2</guid></item><item><title>HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction</title><link>http://arxiv.org/abs/2508.16433v1</link><description>Recovering the 3D geometry of a scene from a sparse set of uncalibratedimages is a long-standing problem in computer vision. While recentlearning-based approaches such as DUSt3R and MASt3R have demonstratedimpressive results by directly predicting dense scene geometry, they areprimarily trained on outdoor scenes with static environments and struggle tohandle human-centric scenarios. In this work, we introduce HAMSt3R, anextension of MASt3R for joint human and scene 3D reconstruction from sparse,uncalibrated multi-view images. First, we exploit DUNE, a strong image encoderobtained by distilling, among others, the encoders from MASt3R and from astate-of-the-art Human Mesh Recovery (HMR) model, multi-HMR, for a betterunderstanding of scene geometry and human bodies. Our method then incorporatesadditional network heads to segment people, estimate dense correspondences viaDensePose, and predict depth in human-centric environments, enabling a morecomprehensive 3D reconstruction. By leveraging the outputs of our differentheads, HAMSt3R produces a dense point map enriched with human semanticinformation in 3D. Unlike existing methods that rely on complex optimizationpipelines, our approach is fully feed-forward and efficient, making it suitablefor real-world applications. We evaluate our model on EgoHumans and EgoExo4D,two challenging benchmarks con taining diverse human-centric scenarios.Additionally, we validate its generalization to traditional multi-view stereoand multi-view pose regression tasks. Our results demonstrate that our methodcan reconstruct humans effectively while preserving strong performance ingeneral 3D reconstruction tasks, bridging the gap between human and sceneunderstanding in 3D vision.</description><author>Sara Rojas, Matthieu Armando, Bernard Ghamen, Philippe Weinzaepfel, Vincent Leroy, Gregory Rogez</author><pubDate>Fri, 22 Aug 2025 14:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16433v1</guid></item><item><title>Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish</title><link>http://arxiv.org/abs/2508.16431v1</link><description>We introduce Cetvel, a comprehensive benchmark designed to evaluate largelanguage models (LLMs) in Turkish. Existing Turkish benchmarks often lackeither task diversity or culturally relevant content, or both. Cetvel addressesthese gaps by combining a broad range of both discriminative and generativetasks ensuring content that reflects the linguistic and cultural richness ofTurkish language. Cetvel covers 23 tasks grouped into seven categories,including tasks such as grammatical error correction, machine translation, andquestion answering rooted in Turkish history and idiomatic language. Weevaluate 33 open-weight LLMs (up to 70B parameters) covering different modelfamilies and instruction paradigms. Our experiments reveal that Turkish-centricinstruction-tuned models generally underperform relative to multilingual orgeneral-purpose models (e.g. Llama 3 and Mistral), despite being tailored forthe language. Moreover, we show that tasks such as grammatical error correctionand extractive question answering are particularly discriminative indifferentiating model capabilities. Cetvel offers a comprehensive andculturally grounded evaluation suite for advancing the development andassessment of LLMs in Turkish.</description><author>Yakup Abrek Er, Ilker Kesen, Gözde Gül Şahin, Aykut Erdem</author><pubDate>Fri, 22 Aug 2025 14:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16431v1</guid></item><item><title>Bring Your Rear Cameras for Egocentric 3D Human Pose Estimation</title><link>http://arxiv.org/abs/2503.11652v2</link><description>Egocentric 3D human pose estimation has been actively studied using camerasinstalled in front of a head-mounted device (HMD). While frontal placement isthe optimal and the only option for some tasks, such as hand tracking, itremains unclear if the same holds for full-body tracking due to self-occlusionand limited field-of-view coverage. Notably, even the state-of-the-art methodsoften fail to estimate accurate 3D poses in many scenarios, such as when HMDusers tilt their heads upward -- a common motion in human activities. A keylimitation of existing HMD designs is their neglect of the back of the body,despite its potential to provide crucial 3D reconstruction cues. Hence, thispaper investigates the usefulness of rear cameras for full-body tracking. Wealso show that simply adding rear views to the frontal inputs is not optimalfor existing methods due to their dependence on individual 2D joint detectorswithout effective multi-view integration. To address this issue, we propose anew transformer-based method that refines 2D joint heatmap estimation withmulti-view information and heatmap uncertainty, thereby improving 3D posetracking. Also, we introduce two new large-scale datasets, Ego4View-Syn andEgo4View-RW, for a rear-view evaluation. Our experiments show that the newcamera configurations with back views provide superior support for 3D posetracking compared to only frontal placements. The proposed method achievessignificant improvement over the current state of the art (&gt;10% on MPJPE). Thesource code, trained models, and datasets are available on our project page athttps://4dqv.mpi-inf.mpg.de/EgoRear/.</description><author>Hiroyasu Akada, Jian Wang, Vladislav Golyanik, Christian Theobalt</author><pubDate>Fri, 22 Aug 2025 14:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.11652v2</guid></item><item><title>Decoding MGMT Methylation: A Step Towards Precision Medicine in Glioblastoma</title><link>http://arxiv.org/abs/2508.16424v1</link><description>Glioblastomas, constituting over 50% of malignant brain tumors, are highlyaggressive brain tumors that pose substantial treatment challenges due to theirrapid progression and resistance to standard therapies. The methylation statusof the O-6-Methylguanine-DNA Methyltransferase (MGMT) gene is a criticalbiomarker for predicting patient response to treatment, particularly with thealkylating agent temozolomide. However, accurately predicting MGMT methylationstatus using non-invasive imaging techniques remains challenging due to thecomplex and heterogeneous nature of glioblastomas, that includes, unevencontrast, variability within lesions, and irregular enhancement patterns. Thisstudy introduces the Convolutional Autoencoders for MGMT Methylation StatusPrediction (CAMP) framework, which is based on adaptive sparse penalties toenhance predictive accuracy. The CAMP framework operates in two phases: first,generating synthetic MRI slices through a tailored autoencoder that effectivelycaptures and preserves intricate tissue and tumor structures across differentMRI modalities; second, predicting MGMT methylation status using aconvolutional neural network enhanced by adaptive sparse penalties. Theadaptive sparse penalty dynamically adjusts to variations in the data, such ascontrast differences and tumor locations in MR images. Our method excels in MRIimage synthesis, preserving brain tissue, fat, and individual tumor structuresacross all MRI modalities. Validated on benchmark datasets, CAMP achieved anaccuracy of 0.97, specificity of 0.98, and sensitivity of 0.97, significantlyoutperforming existing methods. These results demonstrate the potential of theCAMP framework to improve the interpretation of MRI data and contribute to morepersonalized treatment strategies for glioblastoma patients.</description><author>Hafeez Ur Rehman, Sumaiya Fazal, Moutaz Alazab, Ali Baydoun</author><pubDate>Fri, 22 Aug 2025 14:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16424v1</guid></item><item><title>Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2508.16420v1</link><description>Offline reinforcement learning (RL) has achieved significant advances indomains such as robotic control, autonomous driving, and medicaldecision-making. Most existing methods primarily focus on training policiesthat maximize cumulative returns from a given dataset. However, many real-worldapplications require precise control over policy performance levels, ratherthan simply pursuing the best possible return. Reinforcement learning viasupervised learning (RvS) frames offline RL as a sequence modeling task,enabling the extraction of diverse policies by conditioning on differentdesired returns. Yet, existing RvS-based transformers, such as DecisionTransformer (DT), struggle to reliably align the actual achieved returns withspecified target returns, especially when interpolating within underrepresentedreturns or extrapolating beyond the dataset. To address this limitation, wepropose Doctor, a novel approach that Double Checks the Transformer with targetalignment for Offline RL. Doctor achieves superior target alignment both withinand beyond the dataset, while enabling accurate and flexible control overpolicy performance. Notably, on the dynamic treatment regime benchmark,EpiCare, our approach effectively modulates treatment policy aggressiveness,balancing therapeutic returns against adverse event risk.</description><author>Yue Pei, Hongming Zhang, Chao Gao, Martin Müller, Mengxiao Zhu, Hao Sheng, Haogang Zhu, Liang Lin</author><pubDate>Fri, 22 Aug 2025 14:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16420v1</guid></item><item><title>LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python</title><link>http://arxiv.org/abs/2508.16419v1</link><description>Large Language Models (LLMs) such as ChatGPT-4, Claude 3, and LLaMA 4 areincreasingly embedded in software/application development, supporting tasksfrom code generation to debugging. Yet, their real-world effectiveness indetecting diverse software bugs, particularly complex, security-relevantvulnerabilities, remains underexplored. This study presents a systematic,empirical evaluation of these three leading LLMs using a benchmark offoundational programming errors, classic security flaws, and advanced,production-grade bugs in C++ and Python. The dataset integrates real code fromSEED Labs, OpenSSL (via the Suresoft GLaDOS database), and PyBugHive, validatedthrough local compilation and testing pipelines. A novel multi-stage,context-aware prompting protocol simulates realistic debugging scenarios, whilea graded rubric measures detection accuracy, reasoning depth, and remediationquality. Our results show that all models excel at identifying syntactic andsemantic issues in well-scoped code, making them promising for educational useand as first-pass reviewers in automated code auditing. Performance diminishesin scenarios involving complex security vulnerabilities and large-scaleproduction code, with ChatGPT-4 and Claude 3 generally providing more nuancedcontextual analyses than LLaMA 4. This highlights both the promise and thepresent constraints of LLMs in serving as reliable code analysis tools.</description><author>Akshay Mhatre, Noujoud Nader, Patrick Diehl, Deepti Gupta</author><pubDate>Fri, 22 Aug 2025 14:30:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16419v1</guid></item><item><title>NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents</title><link>http://arxiv.org/abs/2508.16414v1</link><description>Understanding how prenatal exposure to psychoactive substances such ascannabis shapes adolescent brain organization remains a critical challenge,complicated by the complexity of multimodal neuroimaging data and thelimitations of conventional analytic methods. Existing approaches often fail tofully capture the complementary features embedded within structural andfunctional connectomes, constraining both biological insight and predictiveperformance. To address this, we introduced NeuroKoop, a novel graph neuralnetwork-based framework that integrates structural and functional brainnetworks utilizing neural Koopman operator-driven latent space fusion. Byleveraging Koopman theory, NeuroKoop unifies node embeddings derived fromsource-based morphometry (SBM) and functional network connectivity (FNC) basedbrain graphs, resulting in enhanced representation learning and more robustclassification of prenatal drug exposure (PDE) status. Applied to a largeadolescent cohort from the ABCD dataset, NeuroKoop outperformed relevantbaselines and revealed salient structural-functional connections, advancing ourunderstanding of the neurodevelopmental impact of PDE.</description><author>Badhan Mazumder, Aline Kotoski, Vince D. Calhoun, Dong Hye Ye</author><pubDate>Fri, 22 Aug 2025 14:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16414v1</guid></item><item><title>SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather</title><link>http://arxiv.org/abs/2508.16408v1</link><description>Multimodal sensor fusion is an essential capability for autonomous robots,enabling object detection and decision-making in the presence of failing oruncertain inputs. While recent fusion methods excel in normal environmentalconditions, these approaches fail in adverse weather, e.g., heavy fog, snow, orobstructions due to soiling. We introduce a novel multi-sensor fusion approachtailored to adverse weather conditions. In addition to fusing RGB and LiDARsensors, which are employed in recent autonomous driving literature, our sensorfusion stack is also capable of learning from NIR gated camera and radarmodalities to tackle low light and inclement weather. We fuse multimodal sensordata through attentive, depth-based blending schemes, with learned refinementon the Bird's Eye View (BEV) plane to combine image and range featureseffectively. Our detections are predicted by a transformer decoder that weighsmodalities based on distance and visibility. We demonstrate that our methodimproves the reliability of multimodal sensor fusion in autonomous vehiclesunder challenging weather conditions, bridging the gap between ideal conditionsand real-world edge cases. Our approach improves average precision by 17.2 APcompared to the next best method for vulnerable pedestrians in long distancesand challenging foggy scenes. Our project page is available athttps://light.princeton.edu/samfusion/</description><author>Edoardo Palladin, Roland Dietze, Praveen Narayanan, Mario Bijelic, Felix Heide</author><pubDate>Fri, 22 Aug 2025 14:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16408v1</guid></item><item><title>Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms</title><link>http://arxiv.org/abs/2506.09457v2</link><description>Direct Alignment Algorithms (DAAs), such as Direct Preference Optimization(DPO) and Simple Preference Optimization (SimPO), have emerged as efficientalternatives to Reinforcement Learning from Human Feedback (RLHF) algorithmsfor aligning large language models (LLMs) with human preferences. However, DAAssuffer from a fundamental limitation we identify as the "reward-generation gap"-- a misalignment between optimization objectives during training and actualgeneration performance during inference. In this paper, we find a contributorto the reward-generation gap is the mismatch between the inherent importance ofprefix tokens during the LLM generation process and how this importance isreflected in the implicit reward functions of DAAs. To bridge the gap, we adopta token-level MDP perspective of DAAs to analyze its limitations and introducea simple yet effective approach called Prefix-Oriented Equal-length Training(POET), which truncates both preferred and dispreferred responses to match theshorter one's length. Training with \mname, where both responses in each sampleare truncated to equal length, resulting in diverse truncated lengths acrosssamples, the optimization of DAAs objective is implicitly constrained toconverge across all timesteps of token-level MDP, thus paying more attention toprefix tokens than the standard DAAs. We conduct experiments with DPO andSimPO, two representative DAAs, demonstrating that POET improves over theirstandard implementations, achieving up to 15.6 points in AlpacaEval 2 andoverall improvements across downstream tasks. Our results highlight theimportance of addressing the misalignment between reward optimization andgeneration performance in DAAs.</description><author>Zeguan Xiao, Yun Chen, Guanhua Chen, Ke Tang</author><pubDate>Fri, 22 Aug 2025 14:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.09457v2</guid></item><item><title>Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models</title><link>http://arxiv.org/abs/2508.16406v1</link><description>Large Language Models (LLMs) remain vulnerable to jailbreak attacks, whichattempt to elicit harmful responses from LLMs. The evolving nature anddiversity of these attacks pose many challenges for defense systems, including(1) adaptation to counter emerging attack strategies without costly retraining,and (2) control of the trade-off between safety and utility. To address thesechallenges, we propose Retrieval-Augmented Defense (RAD), a novel framework forjailbreak detection that incorporates a database of known attack examples intoRetrieval-Augmented Generation, which is used to infer the underlying,malicious user query and jailbreak strategy used to attack the system. RADenables training-free updates for newly discovered jailbreak strategies andprovides a mechanism to balance safety and utility. Experiments on StrongREJECTshow that RAD substantially reduces the effectiveness of strong jailbreakattacks such as PAP and PAIR while maintaining low rejection rates for benignqueries. We propose a novel evaluation scheme and show that RAD achieves arobust safety-utility trade-off across a range of operating points in acontrollable manner.</description><author>Guangyu Yang, Jinghong Chen, Jingbiao Mei, Weizhe Lin, Bill Byrne</author><pubDate>Fri, 22 Aug 2025 14:13:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16406v1</guid></item><item><title>MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs</title><link>http://arxiv.org/abs/2504.02768v3</link><description>We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguisticminimal pairs, covering 101 languages and 2 types of subject-verb agreement,containing more than 128,000 minimal pairs. Our minimal pairs are created usinga fully automated pipeline, leveraging the large-scale linguistic resources ofUniversal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMsat an unprecedented multilingual scale, and highlights the shortcomings of thecurrent state-of-the-art in modelling low-resource languages.</description><author>Jaap Jumelet, Leonie Weissweiler, Joakim Nivre, Arianna Bisazza</author><pubDate>Fri, 22 Aug 2025 14:08:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.02768v3</guid></item><item><title>Fast and Accurate RFIC Performance Prediction via Pin Level Graph Neural Networks and Probabilistic Flow</title><link>http://arxiv.org/abs/2508.16403v1</link><description>Accurately predicting the performance of active radio frequency (RF) circuitsis essential for modern wireless systems but remains challenging due to highlynonlinear, layout-sensitive behavior and the high computational cost oftraditional simulation tools. Existing machine learning (ML) surrogates oftenrequire large datasets to generalize across various topologies or to accuratelymodel skewed and multi-modal performance metrics. In this work, a lightweight,data-efficient, and topology-aware graph neural network (GNN) model is proposedfor predicting key performance metrics of multiple topologies of active RFcircuits such as low noise amplifiers (LNAs), mixers, voltage-controlledoscillators (VCOs), and PAs. To capture transistor-level symmetry and preservefine-grained connectivity details, circuits are modeled at the device-terminallevel, enabling scalable message passing while reducing data requirements.Masked autoregressive flow (MAF) output heads are incorporated to improverobustness in modeling complex target distributions. Experiments on datasetsdemonstrate high prediction accuracy, with symmetric mean absolute percentageerror (sMAPE) and mean relative error (MRE) averaging 2.40% and 2.91%,respectively. Owing to the pin-level conversion of circuit to graph and MLarchitecture robust to modeling complex densities of RF metrics, the MRE isimproved by 3.14x while using 2.24x fewer training samples compared to priorwork, demonstrating the method's effectiveness for rapid and accurate RFcircuit design automation.</description><author>Anahita Asadi, Leonid Popryho, Inna Partin-Vaisband</author><pubDate>Fri, 22 Aug 2025 14:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16403v1</guid></item><item><title>AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions</title><link>http://arxiv.org/abs/2508.16402v1</link><description>Competitive programming has emerged as a critical benchmark for evaluatingthe reasoning and coding capabilities of Large Language Models (LLMs). Despiteimpressive progress on existing benchmarks, we argue that current evaluationsoverstate model proficiency, masking a substantial gap between LLMs and elitehuman programmers. This gap arises from two key limitations: insufficientdifficulty and scope of benchmark problems, and evaluation bias fromlow-quality test cases. To address these shortcomings, we present AetherCode, anew benchmark that draws problems from premier programming competitions such asIOI and ICPC, offering broader coverage and higher difficulty. AetherCodefurther incorporates comprehensive, expert-validated test suites built througha hybrid of automated generation and human curation, ensuring rigorous andreliable assessment. By combining challenging problem design with robustevaluation, AetherCode provides a more faithful measure of LLM capabilities andsets a new standard for future research in code reasoning.</description><author>Zihan Wang, Jiaze Chen, Zhicheng Liu, Markus Mak, Yidi Du, Geonsik Moon, Luoqi Xu, Aaron Tua, Kunshuo Peng, Jiayi Lu, Mingfei Xia, Boqian Zou, Chenyang Ran, Guang Tian, Shoutai Zhu, Yeheng Duan, Zhenghui Kang, Zhenxing Lin, Shangshu Li, Qiang Luo, Qingshen Long, Zhiyong Chen, Yihan Xiao, Yurong Wu, Daoguang Zan, Yuyi Fu, Mingxuan Wang, Ming Ding</author><pubDate>Fri, 22 Aug 2025 14:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16402v1</guid></item><item><title>Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars</title><link>http://arxiv.org/abs/2508.16401v1</link><description>Audio-driven facial animation presents an effective solution for animatingdigital avatars. In this paper, we detail the technical aspects of NVIDIAAudio2Face-3D, including data acquisition, network architecture, retargetingmethodology, evaluation metrics, and use cases. Audio2Face-3D system enablesreal-time interaction between human users and interactive avatars, facilitatingfacial animation authoring for game characters. To assist digital avatarcreators and game developers in generating realistic facial animations, we haveopen-sourced Audio2Face-3D networks, SDK, training framework, and exampledataset.</description><author>NVIDIA, :, Chaeyeon Chung, Ilya Fedorov, Michael Huang, Aleksey Karmanov, Dmitry Korobchenko, Roger Ribera, Yeongho Seol</author><pubDate>Fri, 22 Aug 2025 14:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16401v1</guid></item><item><title>A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection</title><link>http://arxiv.org/abs/2508.16397v1</link><description>Real-time surface defect detection is critical for maintaining productquality and production efficiency in the steel manufacturing industry. Despitepromising accuracy, existing deep learning methods often suffer from highcomputational complexity and slow inference speeds, which limit theirdeployment in resource-constrained industrial environments. Recent lightweightapproaches adopt multibranch architectures based on depthwise separableconvolution (DSConv) to capture multiscale contextual information. However,these methods often suffer from increased computational overhead and lackeffective cross-scale feature interaction, limiting their ability to fullyleverage multiscale representations. To address these challenges, we proposeGMBINet, a lightweight framework that enhances multiscale feature extractionand interaction through novel Group Multiscale Bidirectional Interactive (GMBI)modules. The GMBI adopts a group-wise strategy for multiscale featureextraction, ensuring scale-agnostic computational complexity. It furtherintegrates a Bidirectional Progressive Feature Interactor (BPFI) and aparameter-free Element-Wise Multiplication-Summation (EWMS) operation toenhance cross-scale interaction without introducing additional computationaloverhead. Experiments on SD-Saliency-900 and NRSD-MN datasets demonstrate thatGMBINet delivers competitive accuracy with real-time speeds of 1048 FPS on GPUand 16.53 FPS on CPU at 512 resolution, using only 0.19 M parameters.Additional evaluations on the NEU-CLS defect classification dataset furtherconfirm the strong generalization ability of our method, demonstrating itspotential for broader industrial vision applications beyond surface defectdetection. The dataset and code are publicly available at:https://github.com/zhangyongcode/GMBINet.</description><author>Yong Zhang, Cunjian Chen, Qiang Gao, Yi Wang, Bin Fang</author><pubDate>Fri, 22 Aug 2025 13:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16397v1</guid></item><item><title>Domain-aligned generative downscaling enhances projections of extreme climate events</title><link>http://arxiv.org/abs/2508.16396v1</link><description>Climate change is exacerbating extreme weather events globally, includinghigh temperatures, extreme precipitation, strong winds, and tropical cyclones,posing severe threats to human health, infrastructure, food security, andsocio-economic systems. Although existing global climate models (GCMs) provideessential tools for climate prediction, they face limitations such asinsufficient resolution and high computational costs when simulating extremeevents. To address these issues, this study proposes a spatiotemporaldownscaling model based on generative machine learning-the Domain AlignedClimate Downscaling model (DACD), designed to enhance the simulationcapabilities for extreme weather events. The proposed model employs domainadaptation tricks and a Flow Matching training framework to transform globallow-resolution climate data into high-resolution local-scale climateinformation while achieving precise simulation of multivariable and temporalscales. The results show that during the historical period (2005-2014), ourmodel outperformed existing methods in simulating high temperatures, extremeprecipitation, strong wind, and tropical cyclone tracks, significantly reducingerrors and improving the ability to capture extreme events. Under differentfuture scenarios (2015-2100), the model reveals a significant increasing trendin the frequency and intensity of extreme events, particularly under thehigh-emission scenario (SSP585). Compared to traditional methods, our modelmore accurately simulates the spatial distribution and dynamic changes ofextreme events, providing an essential tool for understanding the impacts ofclimate change. This study offers a new technological pathway forhigh-resolution climate analysis and extreme event prediction, providingscientific support for addressing future climate change and formulatingadaptation strategies.</description><author>Ruian Tie, Xiaohui Zhong, Zhengyu Shi, Hao Li, Jun Liu, Wu Libo</author><pubDate>Fri, 22 Aug 2025 13:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16396v1</guid></item><item><title>Collaborative Stance Detection via Small-Large Language Model Consistency Verification</title><link>http://arxiv.org/abs/2502.19954v2</link><description>Stance detection on social media aims to identify attitudes expressed intweets towards specific targets. Current studies prioritize Large LanguageModels (LLMs) over Small Language Models (SLMs) due to the overwhelmingperformance improving provided by LLMs. However, heavily relying on LLMs forstance detection, regardless of the cost, is impractical for real-world socialmedia monitoring systems that require vast data analysis. To this end, wepropose \textbf{\underline{Co}}llaborative Stance Detection via Small-LargeLanguage Model Consistency \textbf{\underline{Ver}}ification (\textbf{CoVer})framework, which enhances LLM utilization via context-shared batch reasoningand logical verification between LLM and SLM. Specifically, instead ofprocessing each text individually, CoVer processes texts batch-by-batch,obtaining stance predictions and corresponding explanations via LLM reasoningin a shared context. Then, to exclude the bias caused by context noises, CoVerintroduces the SLM for logical consistency verification. Finally, texts thatrepeatedly exhibit low logical consistency are classified usingconsistency-weighted aggregation of prior LLM stance predictions. Ourexperiments show that CoVer outperforms state-of-the-art methods acrossmultiple benchmarks in the zero-shot setting, achieving 0.54 LLM queries pertweet while significantly enhancing performance. Our CoVer offers a morepractical solution for LLM deploying for social media stance detection.</description><author>Yu Yan, Sheng Sun, Zixiang Tang, Teli Liu, Min Liu</author><pubDate>Fri, 22 Aug 2025 13:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.19954v2</guid></item><item><title>RoMedQA: The First Benchmark for Romanian Medical Question Answering</title><link>http://arxiv.org/abs/2508.16390v1</link><description>Question answering (QA) is an actively studied topic, being a core naturallanguage processing (NLP) task that needs to be addressed before achievingArtificial General Intelligence (AGI). However, the lack of QA datasets inspecific domains and languages hinders the development of robust AI models ableto generalize across various domains and languages. To this end, we introduceRoMedQA, the first Romanian QA benchmark for the medical domain, alongside acomprehensive evaluation of state-of-the-art large language models (LLMs). Weconstruct a high-quality and large-scale dataset comprising 102,646 QA pairsrelated to cancer patients. The questions regard medical case summaries of1,011 patients, requiring either keyword extraction or reasoning to be answeredcorrectly. RoMedQA is the result of a time-consuming manual annotation processcarried out by seven physicians specialized in oncology or radiotherapy, whospent a total of about 2,100 work hours to generate the QA pairs. We experimentwith four LLMs from distinct families of models on RoMedQA. Each model isemployed in two scenarios, namely one based on zero-shot prompting and onebased on supervised fine-tuning. Our results show that fine-tuned modelssignificantly outperform their zero-shot counterparts, clearly indicating thatpretrained models fail to generalize on RoMedQA. Our findings demonstrate theimportance of both domain-specific and language-specific fine-tuning forreliable clinical QA in Romanian. We publicly release our dataset and code athttps://github.com/ana-rogoz/RoMedQA.</description><author>Ana-Cristina Rogoz, Radu Tudor Ionescu, Alexandra-Valentina Anghel, Ionut-Lucian Antone-Iordache, Simona Coniac, Andreea Iuliana Ionescu</author><pubDate>Fri, 22 Aug 2025 13:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16390v1</guid></item></channel></rss>