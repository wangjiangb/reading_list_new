<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 13 May 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Linearizing Large Language Models</title><link>http://arxiv.org/abs/2405.06640v1</link><description>Linear transformers have emerged as a subquadratic-time alternative tosoftmax attention and have garnered significant interest due to theirfixed-size recurrent state that lowers inference cost. However, their originalformulation suffers from poor scaling and underperforms compute-matchedtransformers. Recent linear models such as RWKV and Mamba have attempted toaddress these shortcomings by proposing novel time-mixing and gatingarchitectures, but pre-training large language models requires significant dataand compute investments. Thus, the search for subquadratic architectures islimited by the availability of compute and quality pre-training datasets. As acost-effective alternative to pre-training linear transformers, we proposeScalable UPtraining for Recurrent Attention (SUPRA). We present a method touptrain existing large pre-trained transformers into Recurrent Neural Networks(RNNs) with a modest compute budget. This allows us to leverage the strongpre-training data and performance of existing transformer LLMs, while requiring5% of the training cost. We find that our linearization technique leads tocompetitive performance on standard benchmarks, but we identify persistentin-context learning and long-context modeling shortfalls for even the largestlinear models. Our code and models can be found athttps://github.com/TRI-ML/linear_open_lm.</description><author>Jean Mercat, Igor Vasiljevic, Sedrick Keh, Kushal Arora, Achal Dave, Adrien Gaidon, Thomas Kollar</author><pubDate>Fri, 10 May 2024 18:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06640v1</guid></item><item><title>Value Augmented Sampling for Language Model Alignment and Personalization</title><link>http://arxiv.org/abs/2405.06639v1</link><description>Aligning Large Language Models (LLMs) to cater to different humanpreferences, learning new skills, and unlearning harmful behavior is animportant problem. Search-based methods, such as Best-of-N or Monte-Carlo TreeSearch, are performant, but impractical for LLM adaptation due to their highinference cost. On the other hand, using Reinforcement Learning (RL) foradaptation is computationally efficient, but performs worse due to theoptimization challenges in co-training the value function and the policy. Wepresent a new framework for reward optimization, Value Augmented Sampling(VAS), that can maximize different reward functions using data sampled fromonly the initial, frozen LLM. VAS solves for the optimal reward-maximizingpolicy without co-training the policy and the value function, making theoptimization stable, outperforming established baselines, such as PPO and DPO,on standard benchmarks, and achieving comparable results to Best-of-128 withlower inference cost. Unlike existing RL methods that require changing theweights of the LLM, VAS does not require access to the weights of thepre-trained LLM. Thus, it can even adapt LLMs (e.g., ChatGPT), which areavailable only as APIs. In addition, our algorithm unlocks the new capabilityof composing several rewards and controlling the extent of each one duringdeployment time, paving the road ahead for the future of aligned, personalizedLLMs.</description><author>Seungwook Han, Idan Shenfeld, Akash Srivastava, Yoon Kim, Pulkit Agrawal</author><pubDate>Fri, 10 May 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06639v1</guid></item><item><title>Federated Document Visual Question Answering: A Pilot Study</title><link>http://arxiv.org/abs/2405.06636v1</link><description>An important handicap of document analysis research is that documents tend tobe copyrighted or contain private information, which prohibits their openpublication and the creation of centralised, large-scale document datasets.Instead, documents are scattered in private data silos, making extensivetraining over heterogeneous data a tedious task. In this work, we explore theuse of a federated learning (FL) scheme as a way to train a shared model ondecentralised private document data. We focus on the problem of Document VQA, atask particularly suited to this approach, as the type of reasoningcapabilities required from the model can be quite different in diverse domains.Enabling training over heterogeneous document datasets can thus substantiallyenrich DocVQA models. We assemble existing DocVQA datasets from diverse domainsto reflect the data heterogeneity in real-world applications. We explore theself-pretraining technique in this multi-modal setting, where the same data isused for both pretraining and finetuning, making it relevant for privacypreservation. We further propose combining self-pretraining with a FederatedDocVQA training method using centralized adaptive optimization that outperformsthe FedAvg baseline. With extensive experiments, we also present amulti-faceted analysis on training DocVQA models with FL, which providesinsights for future research on this task. We show that our pretrainingstrategies can effectively learn and scale up under federated training withdiverse DocVQA datasets and tuning hyperparameters is essential for practicaldocument tasks under federation.</description><author>Khanh Nguyen, Dimosthenis Karatzas</author><pubDate>Fri, 10 May 2024 18:53:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06636v1</guid></item><item><title>Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA Benchmark</title><link>http://arxiv.org/abs/2405.06634v1</link><description>We evaluate the zero-shot ability of GPT-4 and LLaVa to perform simple VisualNetwork Analysis (VNA) tasks on small-scale graphs. We evaluate the VisionLanguage Models (VLMs) on 5 tasks related to three foundational network scienceconcepts: identifying nodes of maximal degree on a rendered graph, identifyingwhether signed triads are balanced or unbalanced, and counting components. Thetasks are structured to be easy for a human who understands the underlyinggraph theoretic concepts, and can all be solved by counting the appropriateelements in graphs. We find that while GPT-4 consistently outperforms LLaVa,both models struggle with every visual network analysis task we propose. Wepublicly release the first benchmark for the evaluation of VLMs on foundationalVNA tasks.</description><author>Evan M. Williams, Kathleen M. Carley</author><pubDate>Fri, 10 May 2024 18:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06634v1</guid></item><item><title>Video ReCap: Recursive Captioning of Hour-Long Videos</title><link>http://arxiv.org/abs/2402.13250v5</link><description>Most video captioning models are designed to process short video clips of fewseconds and output text describing low-level visual concepts (e.g., objects,scenes, atomic actions). However, most real-world videos last for minutes orhours and have a complex hierarchical structure spanning different temporalgranularities. We propose Video ReCap, a recursive video captioning model thatcan process video inputs of dramatically different lengths (from 1 second to 2hours) and output video captions at multiple hierarchy levels. The recursivevideo-language architecture exploits the synergy between different videohierarchies and can process hour-long videos efficiently. We utilize acurriculum learning training scheme to learn the hierarchical structure ofvideos, starting from clip-level captions describing atomic actions, thenfocusing on segment-level descriptions, and concluding with generatingsummaries for hour-long videos. Furthermore, we introduce Ego4D-HCap dataset byaugmenting Ego4D with 8,267 manually collected long-range video summaries. Ourrecursive model can flexibly generate captions at different hierarchy levelswhile also being useful for other complex video understanding tasks, such asVideoQA on EgoSchema. Data, code, and models are available at:https://sites.google.com/view/vidrecap</description><author>Md Mohaiminul Islam, Ngan Ho, Xitong Yang, Tushar Nagarajan, Lorenzo Torresani, Gedas Bertasius</author><pubDate>Fri, 10 May 2024 18:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13250v5</guid></item><item><title>Lightweight Inference for Forward-Forward Algorithm</title><link>http://arxiv.org/abs/2404.05241v3</link><description>The human brain performs tasks with an outstanding energy-efficiency, i.e.,with approximately 20 Watts. The state-of-the-art Artificial/Deep NeuralNetworks (ANN/DNN), on the other hand, have recently been shown to consumemassive amounts of energy. The training of these ANNs/DNNs is done almostexclusively based on the back-propagation algorithm, which is known to bebiologically implausible. This has led to a new generation of forward-onlytechniques, including the Forward-Forward algorithm. In this paper, we proposea lightweight inference scheme specifically designed for DNNs trained using theForward-Forward algorithm. We have evaluated our proposed lightweight inferencescheme in the case of the MNIST and CIFAR datasets, as well as two real-worldapplications, namely, epileptic seizure detection and cardiac arrhythmiaclassification using wearable technologies, where complexity overheads/energyconsumption is a major constraint, and demonstrate its relevance.</description><author>Amin Aminifar, Baichuan Huang, Azra Abtahi, Amir Aminifar</author><pubDate>Fri, 10 May 2024 18:42:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05241v3</guid></item><item><title>Deep learning enhanced mixed integer optimization: Learning to reduce model dimensionality</title><link>http://arxiv.org/abs/2401.09556v2</link><description>This work introduces a framework to address the computational complexityinherent in Mixed-Integer Programming (MIP) models by harnessing the potentialof deep learning. By employing deep learning, we construct problem-specificheuristics that identify and exploit common structures across MIP instances. Wetrain deep learning models to estimate complicating binary variables for targetMIP problem instances. The resulting reduced MIP models are solved usingstandard off-the-shelf solvers. We present an algorithm for generatingsynthetic data enhancing the robustness and generalizability of our modelsacross diverse MIP instances. We compare the effectiveness of (a) feed-forwardneural networks (ANN) and (b) convolutional neural networks (CNN). To enhancethe framework's performance, we employ Bayesian optimization for hyperparametertuning, aiming to maximize the occurrence of global optimum solutions. We applythis framework to a flow-based facility location allocation MIP formulationthat describes long-term investment planning and medium-term tacticalscheduling in a personalized medicine supply chain.</description><author>Niki Triantafyllou, Maria M. Papathanasiou</author><pubDate>Fri, 10 May 2024 18:42:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09556v2</guid></item><item><title>Conformal Validity Guarantees Exist for Any Data Distribution</title><link>http://arxiv.org/abs/2405.06627v1</link><description>As machine learning (ML) gains widespread adoption, practitioners areincreasingly seeking means to quantify and control the risk these systemsincur. This challenge is especially salient when ML systems have autonomy tocollect their own data, such as in black-box optimization and active learning,where their actions induce sequential feedback-loop shifts in the datadistribution. Conformal prediction has emerged as a promising approach touncertainty and risk quantification, but existing variants either fail toaccommodate sequences of data-dependent shifts, or do not fully exploit thefact that agent-induced shift is under our control. In this work we prove thatconformal prediction can theoretically be extended to \textit{any} joint datadistribution, not just exchangeable or quasi-exchangeable ones, although it isexceedingly impractical to compute in the most general case. For practicalapplications, we outline a procedure for deriving specific conformal algorithmsfor any data distribution, and we use this procedure to derive tractablealgorithms for a series of agent-induced covariate shifts. We evaluate theproposed algorithms empirically on synthetic black-box optimization and activelearning tasks.</description><author>Drew Prinster, Samuel Stanton, Anqi Liu, Suchi Saria</author><pubDate>Fri, 10 May 2024 18:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06627v1</guid></item><item><title>Characterizing the Accuracy - Efficiency Trade-off of Low-rank Decomposition in Language Models</title><link>http://arxiv.org/abs/2405.06626v1</link><description>Large language models (LLMs) have emerged and presented their generalproblem-solving capabilities with one model. However, the model size hasincreased dramatically with billions of parameters to enable such broadproblem-solving capabilities. In addition, due to the dominance ofmatrix-matrix and matrix-vector multiplications in LLMs, the compute-to-modelsize ratio is significantly lower than that of CNNs. This shift pushes LLMsfrom a computation-bound regime to a memory-bound regime. Therefore, optimizingthe memory footprint and traffic is an important optimization direction forLLMs today. Model compression methods such as quantization and parameter pruning havebeen actively explored for achieving the memory footprint and trafficoptimization. However, the accuracy-efficiency trade-off of rank pruning forLLMs is not well-understood yet. Therefore, we characterize theaccuracy-efficiency trade-off of a low-rank decomposition method, specificallyTucker decomposition, on recent language models, including an open-source LLM,Llama 2. We formalize the low-rank decomposition design space and show that thedecomposition design space is enormous (e.g., O($2^{37}$) for Llama2-7B). Tonavigate such a vast design space, we formulate the design space and performthorough case studies of accuracy-efficiency trade-offs using six widely usedLLM benchmarks on BERT and Llama 2 models. Our results show that we can achievea 9\% model size reduction with minimal accuracy drops, which range from 4\%pto 10\%p, depending on the difficulty of the benchmark, without any retrainingto recover accuracy after decomposition. The results show that low-rankdecomposition can be a promising direction for LLM-based applications thatrequire real-time service in scale (e.g., AI agent assist and real-time codingassistant), where the latency is as important as the model accuracy.</description><author>Chakshu Moar, Michael Pellauer, Hyoukjun Kwon</author><pubDate>Fri, 10 May 2024 18:40:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06626v1</guid></item><item><title>Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems</title><link>http://arxiv.org/abs/2405.06624v1</link><description>Ensuring that AI systems reliably and robustly avoid harmful or dangerousbehaviours is a crucial challenge, especially for AI systems with a high degreeof autonomy and general intelligence, or systems used in safety-criticalcontexts. In this paper, we will introduce and define a family of approaches toAI safety, which we will refer to as guaranteed safe (GS) AI. The core featureof these approaches is that they aim to produce AI systems which are equippedwith high-assurance quantitative safety guarantees. This is achieved by theinterplay of three core components: a world model (which provides amathematical description of how the AI system affects the outside world), asafety specification (which is a mathematical description of what effects areacceptable), and a verifier (which provides an auditable proof certificate thatthe AI satisfies the safety specification relative to the world model). Weoutline a number of approaches for creating each of these three corecomponents, describe the main technical challenges, and suggest a number ofpotential solutions to them. We also argue for the necessity of this approachto AI safety, and for the inadequacy of the main alternative approaches.</description><author>David "davidad" Dalrymple, Joar Skalse, Yoshua Bengio, Stuart Russell, Max Tegmark, Sanjit Seshia, Steve Omohundro, Christian Szegedy, Ben Goldhaber, Nora Ammann, Alessandro Abate, Joe Halpern, Clark Barrett, Ding Zhao, Tan Zhi-Xuan, Jeannette Wing, Joshua Tenenbaum</author><pubDate>Fri, 10 May 2024 18:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06624v1</guid></item><item><title>Explaining Arguments' Strength: Unveiling the Role of Attacks and Supports (Technical Report)</title><link>http://arxiv.org/abs/2404.14304v2</link><description>Quantitatively explaining the strength of arguments under gradual semanticshas recently received increasing attention. Specifically, several works in theliterature provide quantitative explanations by computing the attributionscores of arguments. These works disregard the importance of attacks andsupports, even though they play an essential role when explaining arguments'strength. In this paper, we propose a novel theory of Relation AttributionExplanations (RAEs), adapting Shapley values from game theory to offerfine-grained insights into the role of attacks and supports in quantitativebipolar argumentation towards obtaining the arguments' strength. We show thatRAEs satisfy several desirable properties. We also propose a probabilisticalgorithm to approximate RAEs efficiently. Finally, we show the applicationvalue of RAEs in fraud detection and large language models case studies.</description><author>Xiang Yin, Potyka Nico, Francesca Toni</author><pubDate>Fri, 10 May 2024 18:37:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14304v2</guid></item><item><title>Analyzing the Roles of Language and Vision in Learning from Limited Data</title><link>http://arxiv.org/abs/2403.19669v2</link><description>Does language help make sense of the visual world? How important is it toactually see the world rather than having it described with words? These basicquestions about the nature of intelligence have been difficult to answerbecause we only had one example of an intelligent system -- humans -- andlimited access to cases that isolated language or vision. However, thedevelopment of sophisticated Vision-Language Models (VLMs) by artificialintelligence researchers offers us new opportunities to explore thecontributions that language and vision make to learning about the world. Weablate components from the cognitive architecture of these models to identifytheir contributions to learning new tasks from limited data. We find that alanguage model leveraging all components recovers a majority of a VLM'sperformance, despite its lack of visual input, and that language seems to allowthis by providing access to prior knowledge and reasoning.</description><author>Allison Chen, Ilia Sucholutsky, Olga Russakovsky, Thomas L. Griffiths</author><pubDate>Fri, 10 May 2024 18:33:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19669v2</guid></item><item><title>Dynamically Scaled Temperature in Self-Supervised Contrastive Learning</title><link>http://arxiv.org/abs/2308.01140v2</link><description>In contemporary self-supervised contrastive algorithms like SimCLR, MoCo,etc., the task of balancing attraction between two semantically similar samplesand repulsion between two samples of different classes is primarily affected bythe presence of hard negative samples. While the InfoNCE loss has been shown toimpose penalties based on hardness, the temperature hyper-parameter is the keyto regulating the penalties and the trade-off between uniformity and tolerance.In this work, we focus our attention on improving the performance of InfoNCEloss in self-supervised learning by proposing a novel cosine similaritydependent temperature scaling function to effectively optimize the distributionof the samples in the feature space. We also provide mathematical analyses tosupport the construction of such a dynamically scaled temperature function.Experimental evidence shows that the proposed framework outperforms thecontrastive loss-based SSL algorithms.</description><author>Siladittya Manna, Soumitri Chattopadhyay, Rakesh Dey, Saumik Bhattacharya, Umapada Pal</author><pubDate>Fri, 10 May 2024 18:26:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01140v2</guid></item><item><title>Logistic-beta processes for dependent random probabilities with beta marginals</title><link>http://arxiv.org/abs/2402.07048v2</link><description>The beta distribution serves as a canonical tool for modelling probabilitiesin statistics and machine learning. However, there is limited work on flexibleand computationally convenient stochastic process extensions for modellingdependent random probabilities. We propose a novel stochastic process calledthe logistic-beta process, whose logistic transformation yields a stochasticprocess with common beta marginals. Logistic-beta processes can modeldependence on both discrete and continuous domains, such as space or time, andhave a flexible dependence structure through correlation kernels. Moreover, itsnormal variance-mean mixture representation leads to effective posteriorinference algorithms. We illustrate the benefits through nonparametric binaryregression and conditional density estimation examples, both in simulationstudies and in a pregnancy outcome application.</description><author>Changwoo J. Lee, Alessandro Zito, Huiyan Sang, David B. Dunson</author><pubDate>Fri, 10 May 2024 18:17:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07048v2</guid></item><item><title>ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages</title><link>http://arxiv.org/abs/2403.17859v2</link><description>Question answering (QA) and Machine Reading Comprehension (MRC) tasks havesignificantly advanced in recent years due to the rapid development of deeplearning techniques and, more recently, large language models. At the sametime, many benchmark datasets have become available for QA and MRC tasks.However, most existing large-scale benchmark datasets have been createdpredominantly using synchronous document collections like Wikipedia or the Web.Archival document collections, such as historical newspapers, contain valuableinformation from the past that is still not widely used to train large languagemodels. To further contribute to advancing QA and MRC tasks and to overcome thelimitation of previous datasets, we introduce ChroniclingAmericaQA, alarge-scale temporal QA dataset with 487K question-answer pairs created basedon the historical newspaper collection Chronicling America. Our dataset isconstructed from a subset of the Chronicling America newspaper collectionspanning 120 years. One of the significant challenges for utilizing digitizedhistorical newspaper collections is the low quality of OCR text. Therefore, toenable realistic testing of QA models, our dataset can be used in threedifferent ways: answering questions from raw and noisy content, answeringquestions from cleaner, corrected version of the content, as well as answeringquestions from scanned images of newspaper pages. This and the fact thatChroniclingAmericaQA spans the longest time period among available QA datasetsmake it quite a unique and useful resource.</description><author>Bhawna Piryani, Jamshid Mozafari, Adam Jatowt</author><pubDate>Fri, 10 May 2024 18:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17859v2</guid></item><item><title>"We are at the mercy of others' opinion": Supporting Blind People in Recreational Window Shopping with AI-infused Technology</title><link>http://arxiv.org/abs/2405.06611v1</link><description>Engaging in recreational activities in public spaces poses challenges forblind people, often involving dependency on sighted help. Window shopping is akey recreational activity that remains inaccessible. In this paper, weinvestigate the information needs, challenges, and current approaches blindpeople have to recreational window shopping to inform the design of existingwayfinding and navigation technology for supporting blind shoppers inexploration and serendipitous discovery. We conduct a formative study with atotal of 18 blind participants that include both focus groups (N=8) andinterviews for requirements analysis (N=10). We find that there is a desire forpush notifications of promotional information and pull notifications aboutshops of interest such as the targeted audience of a brand. Information aboutobstacles and points-of-interest required customization depending on one'smobility aid as well as presence of a crowd, children, and wheelchair users. Wetranslate these findings into specific information modalities and rendering inthe context of two existing AI-infused assistive applications: NavCog (aturn-by-turn navigation app) and Cabot (a navigation robot).</description><author>Rie Kamikubo, Hernisa Kacorri, Chieko Asakawa</author><pubDate>Fri, 10 May 2024 18:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06611v1</guid></item><item><title>Calo-VQ: Vector-Quantized Two-Stage Generative Model in Calorimeter Simulation</title><link>http://arxiv.org/abs/2405.06605v1</link><description>We introduce a novel machine learning method developed for the fastsimulation of calorimeter detector response, adapting vector-quantizedvariational autoencoder (VQ-VAE). Our model adopts a two-stage generationstrategy: initially compressing geometry-aware calorimeter data into a discretelatent space, followed by the application of a sequence model to learn andgenerate the latent tokens. Extensive experimentation on the Calo-challengedataset underscores the efficiency of our approach, showcasing a remarkableimprovement in the generation speed compared with conventional method by afactor of 2000. Remarkably, our model achieves the generation of calorimetershowers within milliseconds. Furthermore, comprehensive quantitativeevaluations across various metrics are performed to validate physicsperformance of generation.</description><author>Qibin Liu, Chase Shimmin, Xiulong Liu, Eli Shlizerman, Shu Li, Shih-Chieh Hsu</author><pubDate>Fri, 10 May 2024 18:12:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06605v1</guid></item><item><title>Explaining Text Similarity in Transformer Models</title><link>http://arxiv.org/abs/2405.06604v1</link><description>As Transformers have become state-of-the-art models for natural languageprocessing (NLP) tasks, the need to understand and explain their predictions isincreasingly apparent. Especially in unsupervised applications, such asinformation retrieval tasks, similarity models built on top of foundation modelrepresentations have been widely applied. However, their inner predictionmechanisms have mostly remained opaque. Recent advances in explainable AI havemade it possible to mitigate these limitations by leveraging improvedexplanations for Transformers through layer-wise relevance propagation (LRP).Using BiLRP, an extension developed for computing second-order explanations inbilinear similarity models, we investigate which feature interactions drivesimilarity in NLP models. We validate the resulting explanations anddemonstrate their utility in three corpus-level use cases, analyzinggrammatical interactions, multilingual semantics, and biomedical textretrieval. Our findings contribute to a deeper understanding of differentsemantic similarity tasks and models, highlighting how novel explainable AImethods enable in-depth analyses and corpus-level insights.</description><author>Alexandros Vasileiou, Oliver Eberle</author><pubDate>Fri, 10 May 2024 18:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06604v1</guid></item><item><title>TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions</title><link>http://arxiv.org/abs/2403.18426v2</link><description>Nowadays, individuals tend to engage in dialogues with Large Language Models,seeking answers to their questions. In times when such answers are readilyaccessible to anyone, the stimulation and preservation of human's cognitiveabilities, as well as the assurance of maintaining good reasoning skills byhumans becomes crucial. This study addresses such needs by proposing hints(instead of final answers or before giving answers) as a viable solution. Weintroduce a framework for the automatic hint generation for factoid questions,employing it to construct TriviaHG, a novel large-scale dataset featuring160,230 hints corresponding to 16,645 questions from the TriviaQA dataset.Additionally, we present an automatic evaluation method that measures theConvergence and Familiarity quality attributes of hints. To evaluate theTriviaHG dataset and the proposed evaluation method, we enlisted 10 individualsto annotate 2,791 hints and tasked 6 humans with answering questions using theprovided hints. The effectiveness of hints varied, with success rates of 96%,78%, and 36% for questions with easy, medium, and hard answers, respectively.Moreover, the proposed automatic evaluation methods showed a robust correlationwith annotators' results. Conclusively, the findings highlight three keyinsights: the facilitative role of hints in resolving unknown questions, thedependence of hint quality on answer difficulty, and the feasibility ofemploying automatic evaluation methods for hint assessment.</description><author>Jamshid Mozafari, Anubhav Jangra, Adam Jatowt</author><pubDate>Fri, 10 May 2024 18:10:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18426v2</guid></item><item><title>CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous Underwater Cave Exploration</title><link>http://arxiv.org/abs/2309.11038v6</link><description>In this paper, we present CaveSeg - the first visual learning pipeline forsemantic segmentation and scene parsing for AUV navigation inside underwatercaves. We address the problem of scarce annotated training data by preparing acomprehensive dataset for semantic segmentation of underwater cave scenes. Itcontains pixel annotations for important navigation markers (e.g. caveline,arrows), obstacles (e.g. ground plane and overhead layers), scuba divers, andopen areas for servoing. Through comprehensive benchmark analyses on cavesystems in USA, Mexico, and Spain locations, we demonstrate that robust deepvisual models can be developed based on CaveSeg for fast semantic scene parsingof underwater cave environments. In particular, we formulate a noveltransformer-based model that is computationally light and offers near real-timeexecution in addition to achieving state-of-the-art performance. Finally, weexplore the design choices and implications of semantic segmentation for visualservoing by AUVs inside underwater caves. The proposed model and benchmarkdataset open up promising opportunities for future research in autonomousunderwater cave exploration and mapping.</description><author>A. Abdullah, T. Barua, R. Tibbetts, Z. Chen, M. J. Islam, I. Rekleitis</author><pubDate>Fri, 10 May 2024 18:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11038v6</guid></item><item><title>Rasterized Edge Gradients: Handling Discontinuities Differentiably</title><link>http://arxiv.org/abs/2405.02508v2</link><description>Computing the gradients of a rendering process is paramount for diverseapplications in computer vision and graphics. However, accurate computation ofthese gradients is challenging due to discontinuities and renderingapproximations, particularly for surface-based representations andrasterization-based rendering. We present a novel method for computinggradients at visibility discontinuities for rasterization-based differentiablerenderers. Our method elegantly simplifies the traditionally complex problemthrough a carefully designed approximation strategy, allowing for astraightforward, effective, and performant solution. We introduce a novelconcept of micro-edges, which allows us to treat the rasterized images asoutcomes of a differentiable, continuous process aligned with the inherentlynon-differentiable, discrete-pixel rasterization. This technique eliminates thenecessity for rendering approximations or other modifications to the forwardpass, preserving the integrity of the rendered image, which makes it applicableto rasterized masks, depth, and normals images where filtering is prohibitive.Utilizing micro-edges simplifies gradient interpretation at discontinuities andenables handling of geometry intersections, offering an advantage over theprior art. We showcase our method in dynamic human head scene reconstruction,demonstrating effective handling of camera images and segmentation masks.</description><author>Stanislav Pidhorskyi, Tomas Simon, Gabriel Schwartz, He Wen, Yaser Sheikh, Jason Saragih</author><pubDate>Fri, 10 May 2024 18:03:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02508v2</guid></item><item><title>Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2312.15099v2</link><description>Online hate is an escalating problem that negatively impacts the lives ofInternet users, and is also subject to rapid changes due to evolving events,resulting in new waves of online hate that pose a critical threat. Detectingand mitigating these new waves present two key challenges: it demandsreasoning-based complex decision-making to determine the presence of hatefulcontent, and the limited availability of training samples hinders updating thedetection model. To address this critical issue, we present a novel frameworkcalled HATEGUARD for effectively moderating new waves of online hate. HATEGUARDemploys a reasoning-based approach that leverages the recently introducedchain-of-thought (CoT) prompting technique, harnessing the capabilities oflarge language models (LLMs). HATEGUARD further achieves prompt-based zero-shotdetection by automatically generating and updating detection prompts with newderogatory terms and targets in new wave samples to effectively address newwaves of online hate. To demonstrate the effectiveness of our approach, wecompile a new dataset consisting of tweets related to three recently witnessednew waves: the 2022 Russian invasion of Ukraine, the 2021 insurrection of theUS Capitol, and the COVID-19 pandemic. Our studies reveal crucial longitudinalpatterns in these new waves concerning the evolution of events and the pressingneed for techniques to rapidly update existing moderation tools to counteractthem. Comparative evaluations against state-of-the-art tools illustrate thesuperiority of our framework, showcasing a substantial 22.22% to 83.33%improvement in detecting the three new waves of online hate. Our workhighlights the severe threat posed by the emergence of new waves of online hateand represents a paradigm shift in addressing this threat practically.</description><author>Nishant Vishwamitra, Keyan Guo, Farhan Tajwar Romit, Isabelle Ondracek, Long Cheng, Ziming Zhao, Hongxin Hu</author><pubDate>Fri, 10 May 2024 18:01:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15099v2</guid></item><item><title>Multi-Object Tracking in the Dark</title><link>http://arxiv.org/abs/2405.06600v1</link><description>Low-light scenes are prevalent in real-world applications (e.g. autonomousdriving and surveillance at night). Recently, multi-object tracking in variouspractical use cases have received much attention, but multi-object tracking indark scenes is rarely considered. In this paper, we focus on multi-objecttracking in dark scenes. To address the lack of datasets, we first build aLow-light Multi-Object Tracking (LMOT) dataset. LMOT provides well-alignedlow-light video pairs captured by our dual-camera system, and high-qualitymulti-object tracking annotations for all videos. Then, we propose a low-lightmulti-object tracking method, termed as LTrack. We introduce the adaptivelow-pass downsample module to enhance low-frequency components of imagesoutside the sensor noises. The degradation suppression learning strategyenables the model to learn invariant information under noise disturbance andimage quality degradation. These components improve the robustness ofmulti-object tracking in dark scenes. We conducted a comprehensive analysis ofour LMOT dataset and proposed LTrack. Experimental results demonstrate thesuperiority of the proposed method and its competitiveness in real nightlow-light scenes. Dataset and Code: https: //github.com/ying-fu/LMOT</description><author>Xinzhe Wang, Kang Ma, Qiankun Liu, Yunhao Zou, Ying Fu</author><pubDate>Fri, 10 May 2024 18:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06600v1</guid></item><item><title>A Lightweight Transformer for Remote Sensing Image Change Captioning</title><link>http://arxiv.org/abs/2405.06598v1</link><description>Remote sensing image change captioning (RSICC) aims to automatically generatesentences that describe content differences in remote sensing bitemporalimages. Recently, attention-based transformers have become a prevalent idea forcapturing the features of global change. However, existing transformer-basedRSICC methods face challenges, e.g., high parameters and high computationalcomplexity caused by the self-attention operation in the transformer encodercomponent. To alleviate these issues, this paper proposes a Sparse FocusTransformer (SFT) for the RSICC task. Specifically, the SFT network consists ofthree main components, i.e. a high-level features extractor based on aconvolutional neural network (CNN), a sparse focus attention mechanism-basedtransformer encoder network designed to locate and capture changing regions indual-temporal images, and a description decoder that embeds images and words togenerate sentences for captioning differences. The proposed SFT network canreduce the parameter number and computational complexity by incorporating asparse attention mechanism within the transformer encoder network. Experimentalresults on various datasets demonstrate that even with a reduction of over 90\%in parameters and computational complexity for the transformer encoder, ourproposed network can still obtain competitive performance compared to otherstate-of-the-art RSICC methods. The code can be available at</description><author>Dongwei Sun, Yajie Bao, Xiangyong Cao</author><pubDate>Fri, 10 May 2024 17:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06598v1</guid></item><item><title>Non-Uniform Spatial Alignment Errors in sUAS Imagery From Wide-Area Disasters</title><link>http://arxiv.org/abs/2405.06593v1</link><description>This work presents the first quantitative study of alignment errors betweensmall uncrewed aerial systems (sUAS) geospatial imagery and a priori buildingpolygons and finds that alignment errors are non-uniform and irregular. Thework also introduces a publicly available dataset of imagery, buildingpolygons, and human-generated and curated adjustments that can be used toevaluate existing strategies for aligning building polygons with sUAS imagery.There are no efforts that have aligned pre-existing spatial data with sUASimagery, and thus, there is no clear state of practice. However, this effortand analysis show that the translational alignment errors present in this typeof data, averaging 82px and an intersection over the union of 0.65, which wouldinduce further errors and biases in downstream machine learning systems unlessaddressed. This study identifies and analyzes the translational alignmenterrors of 21,619 building polygons in fifty-one orthomosaic images, covering16787.2 Acres (26.23 square miles), constructed from sUAS raw imagery from ninewide-area disasters (Hurricane Ian, Hurricane Harvey, Hurricane Michael,Hurricane Ida, Hurricane Idalia, Hurricane Laura, the Mayfield Tornado, theMusset Bayou Fire, and the Kilauea Eruption). The analysis finds no uniformityamong the angle and distance metrics of the building polygon alignments as theypresent an average degree variance of 0.4 and an average pixel distancevariance of 0.45. This work alerts the sUAS community to the problem of spatialalignment and that a simple linear transform, often used to align satelliteimagery, will not be sufficient to align spatial data in sUAS orthomosaicimagery.</description><author>Thomas Manzini, Priyankari Perali, Raisa Karnik, Mihir Godbole, Hasnat Abdullah, Robin Murphy</author><pubDate>Fri, 10 May 2024 17:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06593v1</guid></item><item><title>Decomposing weather forecasting into advection and convection with neural networks</title><link>http://arxiv.org/abs/2405.06590v1</link><description>Operational weather forecasting models have advanced for decades on both theexplicit numerical solvers and the empirical physical parameterization schemes.However, the involved high computational costs and uncertainties in theseexisting schemes are requiring potential improvements through alternativemachine learning methods. Previous works use a unified model to learn thedynamics and physics of the atmospheric model. Contrarily, we propose a simpleyet effective machine learning model that learns the horizontal movement in thedynamical core and vertical movement in the physical parameterizationseparately. By replacing the advection with a graph attention network and theconvection with a multi-layer perceptron, our model provides a new andefficient perspective to simulate the transition of variables in atmosphericmodels. We also assess the model's performance over a 5-day iterativeforecasting. Under the same input variables and training methods, our modeloutperforms existing data-driven methods with a significantly-reduced number ofparameters with a resolution of 5.625 deg. Overall, this work aims tocontribute to the ongoing efforts that leverage machine learning techniques forimproving both the accuracy and efficiency of global weather forecasting.</description><author>Mengxuan Chen, Ziqi Yuan, Jinxiao Zhang, Runmin Dong, Haohuan Fu</author><pubDate>Fri, 10 May 2024 17:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06590v1</guid></item><item><title>Enhancing Weakly Supervised Semantic Segmentation with Multi-modal Foundation Models: An End-to-End Approach</title><link>http://arxiv.org/abs/2405.06586v1</link><description>Semantic segmentation is a core computer vision problem, but the high costsof data annotation have hindered its wide application. Weakly-SupervisedSemantic Segmentation (WSSS) offers a cost-efficient workaround to extensivelabeling in comparison to fully-supervised methods by using partial orincomplete labels. Existing WSSS methods have difficulties in learning theboundaries of objects leading to poor segmentation results. We propose a noveland effective framework that addresses these issues by leveraging visualfoundation models inside the bounding box. Adopting a two-stage WSSS framework,our proposed network consists of a pseudo-label generation module and asegmentation module. The first stage leverages Segment Anything Model (SAM) togenerate high-quality pseudo-labels. To alleviate the problem of delineatingprecise boundaries, we adopt SAM inside the bounding box with the help ofanother pre-trained foundation model (e.g., Grounding-DINO). Furthermore, weeliminate the necessity of using the supervision of image labels, by employingCLIP in classification. Then in the second stage, the generated high-qualitypseudo-labels are used to train an off-the-shelf segmenter that achieves thestate-of-the-art performance on PASCAL VOC 2012 and MS COCO 2014.</description><author>Elham Ravanbakhsh, Cheng Niu, Yongqing Liang, J. Ramanujam, Xin Li</author><pubDate>Fri, 10 May 2024 17:42:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06586v1</guid></item><item><title>Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation</title><link>http://arxiv.org/abs/2404.09127v3</link><description>Uncertainty estimation is a significant issue for current large languagemodels (LLMs) that are generally poorly calibrated and over-confident,especially with reinforcement learning from human feedback (RLHF). Unlikehumans, whose decisions and confidences not only stem from intrinsic beliefsbut can also be adjusted through daily observations, existing calibrationmethods for LLMs focus on estimating or eliciting individual confidence withouttaking full advantage of the "Collective Wisdom": the interaction amongmultiple LLMs that can collectively improve both accuracy and calibration. Inthis work, we propose Collaborative Calibration, a post-hoc training-freecalibration strategy that leverages the collaborative and expressivecapabilities of multiple tool-augmented LLM agents in a simulated groupdeliberation process. We demonstrate the effectiveness of CollaborativeCalibration on generative QA tasks across various domains, showing itspotential in harnessing the rationalization of collectively calibratedconfidence assessments and improving the reliability of model predictions.</description><author>Ruixin Yang, Dheeraj Rajagopal, Shirley Anugrah Hayati, Bin Hu, Dongyeop Kang</author><pubDate>Fri, 10 May 2024 17:38:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09127v3</guid></item><item><title>The Role of Learning Algorithms in Collective Action</title><link>http://arxiv.org/abs/2405.06582v1</link><description>Collective action in Machine Learning is the study of the control that acoordinated group can have over machine learning algorithms. While previousresearch has concentrated on assessing the impact of collectives against Bayesoptimal classifiers, this perspective is limited, given that in reality,classifiers seldom achieve Bayes optimality and are influenced by the choice oflearning algorithms along with their inherent inductive biases. In this work,we initiate the study of how the choice of the learning algorithm plays a rolein the success of a collective in practical settings. Specifically, we focus ondistributionally robust algorithms (DRO), popular for improving a worst grouperror, and on the popular stochastic gradient descent (SGD), due to itsinductive bias for "simpler" functions. Our empirical results, supported by atheoretical foundation, show that the effective size and success of thecollective are highly dependent on properties of the learning algorithm. Thishighlights the necessity of taking the learning algorithm into account whenstudying the impact of collective action in Machine learning.</description><author>Omri Ben-Dov, Jake Fawkes, Samira Samadi, Amartya Sanyal</author><pubDate>Fri, 10 May 2024 17:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06582v1</guid></item><item><title>A Survey on Open Information Extraction from Rule-based Model to Large Language Model</title><link>http://arxiv.org/abs/2208.08690v6</link><description>Open Information Extraction (OpenIE) represents a crucial NLP task aimed atderiving structured information from unstructured text, unrestricted byrelation type or domain. This survey paper provides an overview of OpenIEtechnologies spanning from 2007 to 2024, emphasizing a chronologicalperspective absent in prior surveys. It examines the evolution of task settingsin OpenIE to align with the advances in recent technologies. The papercategorizes OpenIE approaches into rule-based, neural, and pre-trained largelanguage models, discussing each within a chronological framework.Additionally, it highlights prevalent datasets and evaluation metrics currentlyin use. Building on this extensive review, the paper outlines potential futuredirections in terms of datasets, information sources, output formats,methodologies, and evaluation metrics.</description><author>Pai Liu, Wenyang Gao, Wenjie Dong, Lin Ai, Ziwei Gong, Songfang Huang, Zongsheng Li, Ehsan Hoque, Julia Hirschberg, Yue Zhang</author><pubDate>Fri, 10 May 2024 17:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.08690v6</guid></item><item><title>No-Regret is not enough! Bandits with General Constraints through Adaptive Regret Minimization</title><link>http://arxiv.org/abs/2405.06575v1</link><description>In the bandits with knapsacks framework (BwK) the learner has $m$resource-consumption (packing) constraints. We focus on the generalization ofBwK in which the learner has a set of general long-term constraints. The goalof the learner is to maximize their cumulative reward, while at the same timeachieving small cumulative constraints violations. In this scenario, thereexist simple instances where conventional methods for BwK fail to yieldsublinear violations of constraints. We show that it is possible to circumventthis issue by requiring the primal and dual algorithm to be weakly adaptive.Indeed, even in absence on any information on the Slater's parameter $\rho$characterizing the problem, the interplay between weakly adaptive primal anddual regret minimizers yields a "self-bounding" property of dual variables. Inparticular, their norm remains suitably upper bounded across the entire timehorizon even without explicit projection steps. By exploiting this property, weprovide best-of-both-worlds guarantees for stochastic and adversarial inputs.In the first case, we show that the algorithm guarantees sublinear regret. Inthe latter case, we establish a tight competitive ratio of $\rho/(1+\rho)$. Inboth settings, constraints violations are guaranteed to be sublinear in time.Finally, this results allow us to obtain new result for the problem ofcontextual bandits with linear constraints, providing the firstno-$\alpha$-regret guarantees for adversarial contexts.</description><author>Martino Bernasconi, Matteo Castiglioni, Andrea Celli</author><pubDate>Fri, 10 May 2024 17:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06575v1</guid></item><item><title>Deep video representation learning: a survey</title><link>http://arxiv.org/abs/2405.06574v1</link><description>This paper provides a review on representation learning for videos. Weclassify recent spatiotemporal feature learning methods for sequential visualdata and compare their pros and cons for general video analysis. Buildingeffective features for videos is a fundamental problem in computer vision tasksinvolving video analysis and understanding. Existing features can be generallycategorized into spatial and temporal features. Their effectiveness undervariations of illumination, occlusion, view and background are discussed.Finally, we discuss the remaining challenges in existing deep videorepresentation learning studies.</description><author>Elham Ravanbakhsh, Yongqing Liang, J. Ramanujam, Xin Li</author><pubDate>Fri, 10 May 2024 17:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06574v1</guid></item><item><title>An Investigation of Incorporating Mamba for Speech Enhancement</title><link>http://arxiv.org/abs/2405.06573v1</link><description>This work aims to study a scalable state-space model (SSM), Mamba, for thespeech enhancement (SE) task. We exploit a Mamba-based regression model tocharacterize speech signals and build an SE system upon Mamba, termed SEMamba.We explore the properties of Mamba by integrating it as the core model in bothbasic and advanced SE systems, along with utilizing signal-level distances aswell as metric-oriented loss functions. SEMamba demonstrates promising resultsand attains a PESQ score of 3.55 on the VoiceBank-DEMAND dataset. When combinedwith the perceptual contrast stretching technique, the proposed SEMamba yieldsa new state-of-the-art PESQ score of 3.69.</description><author>Rong Chao, Wen-Huang Cheng, Moreno La Quatra, Sabato Marco Siniscalchi, Chao-Han Huck Yang, Szu-Wei Fu, Yu Tsao</author><pubDate>Fri, 10 May 2024 17:18:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06573v1</guid></item><item><title>Efficient Federated Low Rank Matrix Completion</title><link>http://arxiv.org/abs/2405.06569v1</link><description>In this work, we develop and analyze a Gradient Descent (GD) based solution,called Alternating GD and Minimization (AltGDmin), for efficiently solving thelow rank matrix completion (LRMC) in a federated setting. LRMC involvesrecovering an $n \times q$ rank-$r$ matrix $\Xstar$ from a subset of itsentries when $r \ll \min(n,q)$. Our theoretical guarantees (iteration andsample complexity bounds) imply that AltGDmin is the mostcommunication-efficient solution in a federated setting, is one of the fastest,and has the second best sample complexity among all iterative solutions toLRMC. In addition, we also prove two important corollaries. (a) We provide aguarantee for AltGDmin for solving the noisy LRMC problem. (b) We show how ourlemmas can be used to provide an improved sample complexity guarantee forAltMin, which is the fastest centralized solution.</description><author>Ahmed Ali Abbasi, Namrata Vaswani</author><pubDate>Fri, 10 May 2024 17:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06569v1</guid></item><item><title>What Can Natural Language Processing Do for Peer Review?</title><link>http://arxiv.org/abs/2405.06563v1</link><description>The number of scientific articles produced every year is growing rapidly.Providing quality control over them is crucial for scientists and, ultimately,for the public good. In modern science, this process is largely delegated topeer review -- a distributed procedure in which each submission is evaluated byseveral independent experts in the field. Peer review is widely used, yet it ishard, time-consuming, and prone to error. Since the artifacts involved in peerreview -- manuscripts, reviews, discussions -- are largely text-based, NaturalLanguage Processing has great potential to improve reviewing. As the emergenceof large language models (LLMs) has enabled NLP assistance for many new tasks,the discussion on machine-assisted peer review is picking up the pace. Yet,where exactly is help needed, where can NLP help, and where should it standaside? The goal of our paper is to provide a foundation for the future effortsin NLP for peer-reviewing assistance. We discuss peer review as a generalprocess, exemplified by reviewing at AI conferences. We detail each step of theprocess from manuscript submission to camera-ready revision, and discuss theassociated challenges and opportunities for NLP assistance, illustrated byexisting work. We then turn to the big challenges in NLP for peer review as awhole, including data acquisition and licensing, operationalization andexperimentation, and ethical issues. To help consolidate community efforts, wecreate a companion repository that aggregates key datasets pertaining to peerreview. Finally, we issue a detailed call for action for the scientificcommunity, NLP and AI researchers, policymakers, and funding bodies to helpbring the research in NLP for peer review forward. We hope that our work willhelp set the agenda for research in machine-assisted scientific quality controlin the age of AI, within the NLP community and beyond.</description><author>Ilia Kuznetsov, Osama Mohammed Afzal, Koen Dercksen, Nils Dycke, Alexander Goldberg, Tom Hope, Dirk Hovy, Jonathan K. Kummerfeld, Anne Lauscher, Kevin Leyton-Brown, Sheng Lu, Mausam, Margot Mieskes, Aurlie Nvol, Danish Pruthi, Lizhen Qu, Roy Schwartz, Noah A. Smith, Thamar Solorio, Jingyan Wang, Xiaodan Zhu, Anna Rogers, Nihar B. Shah, Iryna Gurevych</author><pubDate>Fri, 10 May 2024 17:06:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06563v1</guid></item><item><title>Reservoir Computing Benchmarks: a review, a taxonomy, some best practices</title><link>http://arxiv.org/abs/2405.06561v1</link><description>Reservoir Computing is an Unconventional Computation model to performcomputation on various different substrates, such as RNNs or physicalmaterials. The method takes a "black-box" approach, training only the outputsof the system it is built on. As such, evaluating the computational capacity ofthese systems can be challenging. We review and critique the evaluation methodsused in the field of Reservoir Computing. We introduce a categorisation ofbenchmark tasks. We review multiple examples of benchmarks from the literatureas applied to reservoir computing, and note their strengths and shortcomings.We suggest ways in which benchmarks and their uses may be improved to thebenefit of the reservoir computing community</description><author>Chester Wringe, Martin Trefzer, Susan Stepney</author><pubDate>Fri, 10 May 2024 17:02:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06561v1</guid></item><item><title>Random matrix theory improved Frchet mean of symmetric positive definite matrices</title><link>http://arxiv.org/abs/2405.06558v1</link><description>In this study, we consider the realm of covariance matrices in machinelearning, particularly focusing on computing Fr\'echet means on the manifold ofsymmetric positive definite matrices, commonly referred to as Karcher orgeometric means. Such means are leveraged in numerous machine-learning tasks.Relying on advanced statistical tools, we introduce a random matrixtheory-based method that estimates Fr\'echet means, which is particularlybeneficial when dealing with low sample support and a high number of matricesto average. Our experimental evaluation, involving both synthetic andreal-world EEG and hyperspectral datasets, shows that we largely outperformstate-of-the-art methods.</description><author>Florent Bouchard, Ammar Mian, Malik Tiomoko, Guillaume Ginolhac, Frdric Pascal</author><pubDate>Fri, 10 May 2024 17:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06558v1</guid></item><item><title>QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving</title><link>http://arxiv.org/abs/2405.04532v2</link><description>Quantization can accelerate large language model (LLM) inference. Goingbeyond INT8 quantization, the research community is actively exploring evenlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantizationtechniques only accelerate low-batch, edge LLM inference, failing to deliverperformance gains in large-batch, cloud-based LLM serving. We uncover acritical issue: existing INT4 quantization methods suffer from significantruntime overhead (20-90%) when dequantizing either weights or partial sums onGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantizationalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ standsfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implementedby the QServe inference library that achieves measured speedup. The key insightdriving QServe is that the efficiency of LLM serving on GPUs is criticallyinfluenced by operations on low-throughput CUDA cores. Building upon thisinsight, in QoQ algorithm, we introduce progressive quantization that can allowlow dequantization overhead in W4A8 GEMM. Additionally, we developSmoothAttention to effectively mitigate the accuracy degradation incurred by4-bit KV quantization. In the QServe system, we perform compute-aware weightreordering and take advantage of register-level parallelism to reducedequantization latency. We also make fused attention memory-bound, harnessingthe performance gain brought by KV4 quantization. As a result, QServe improvesthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4xon L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared toTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughputthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost ofLLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.</description><author>Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han</author><pubDate>Fri, 10 May 2024 16:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04532v2</guid></item><item><title>Free-Moving Object Reconstruction and Pose Estimation with Virtual Camera</title><link>http://arxiv.org/abs/2405.05858v2</link><description>We propose an approach for reconstructing free-moving object from a monocularRGB video. Most existing methods either assume scene prior, hand pose prior,object category pose prior, or rely on local optimization with multiplesequence segments. We propose a method that allows free interaction with theobject in front of a moving camera without relying on any prior, and optimizesthe sequence globally without any segments. We progressively optimize theobject shape and pose simultaneously based on an implicit neuralrepresentation. A key aspect of our method is a virtual camera system thatreduces the search space of the optimization significantly. We evaluate ourmethod on the standard HO3D dataset and a collection of egocentric RGBsequences captured with a head-mounted device. We demonstrate that our approachoutperforms most methods significantly, and is on par with recent techniquesthat assume prior information.</description><author>Haixin Shi, Yinlin Hu, Daniel Koguciuk, Juan-Ting Lin, Mathieu Salzmann, David Ferstl</author><pubDate>Fri, 10 May 2024 16:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05858v2</guid></item><item><title>Scalable Property Valuation Models via Graph-based Deep Learning</title><link>http://arxiv.org/abs/2405.06553v1</link><description>This paper aims to enrich the capabilities of existing deep learning-basedautomated valuation models through an efficient graph representation of peerdependencies, thus capturing intricate spatial relationships. In particular, wedevelop two novel graph neural network models that effectively identifysequences of neighboring houses with similar features, employing differentmessage passing algorithms. The first strategy consider standard spatial graphconvolutions, while the second one utilizes transformer graph convolutions.This approach confers scalability to the modeling process. The experimentalevaluation is conducted using a proprietary dataset comprising approximately200,000 houses located in Santiago, Chile. We show that employing tailoredgraph neural networks significantly improves the accuracy of house priceprediction, especially when utilizing transformer convolutional message passinglayers.</description><author>Enrique Riveros, Carla Vairetti, Christian Wegmann, Santiago Truffa, Sebastin Maldonado</author><pubDate>Fri, 10 May 2024 16:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06553v1</guid></item><item><title>ADSumm: Annotated Ground-truth Summary Datasets for Disaster Tweet Summarization</title><link>http://arxiv.org/abs/2405.06551v1</link><description>Online social media platforms, such as Twitter, provide valuable informationduring disaster events. Existing tweet disaster summarization approachesprovide a summary of these events to aid government agencies, humanitarianorganizations, etc., to ensure effective disaster response. In the literature,there are two types of approaches for disaster summarization, namely,supervised and unsupervised approaches. Although supervised approaches aretypically more effective, they necessitate a sizable number of disaster eventsummaries for testing and training. However, there is a lack of good number ofdisaster summary datasets for training and evaluation. This motivates us to addmore datasets to make supervised learning approaches more efficient. In thispaper, we present ADSumm, which adds annotated ground-truth summaries for eightdisaster events which consist of both natural and man-made disaster eventsbelonging to seven different countries. Our experimental analysis shows thatthe newly added datasets improve the performance of the supervisedsummarization approaches by 8-28% in terms of ROUGE-N F1-score. Moreover, innewly annotated dataset, we have added a category label for each input tweetwhich helps to ensure good coverage from different categories in summary.Additionally, we have added two other features relevance label and key-phrase,which provide information about the quality of a tweet and explanation aboutthe inclusion of the tweet into summary, respectively. For ground-truth summarycreation, we provide the annotation procedure adapted in detail, which has notbeen described in existing literature. Experimental analysis shows the qualityof ground-truth summary is very good with Coverage, Relevance and Diversity.</description><author>Piyush Kumar Garg, Roshni Chakraborty, Sourav Kumar Dandapat</author><pubDate>Fri, 10 May 2024 16:49:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06551v1</guid></item><item><title>Sampling the Swadesh List to Identify Similar Languages with Tree Spaces</title><link>http://arxiv.org/abs/2405.06549v1</link><description>Communication plays a vital role in human interaction. Studying language is aworthwhile task and more recently has become quantitative in nature withdevelopments of fields like quantitative comparative linguistics andlexicostatistics. With respect to the authors own native languages, theancestry of the English language and the Latin alphabet are of the primaryinterest. The Indo-European Tree traces many modern languages back to theProto-Indo-European root. Swadesh's cognates played a large role in developingthat historical perspective where some of the primary branches are Germanic,Celtic, Italic, and Balto-Slavic. This paper will use data analysis on openbooks where the simplest singular space is the 3-spider - a union T3 of threerays with their endpoints glued at a point 0 - which can represent these treespaces for language clustering. These trees are built using a single linkagemethod for clustering based on distances between samples from languages whichuse the Latin Script. Taking three languages at a time, the barycenter isdetermined. Some initial results have found both non-sticky and sticky samplemeans. If the mean exhibits non-sticky properties, then one language may comefrom a different ancestor than the other two. If the mean is considered sticky,then the languages may share a common ancestor or all languages may havedifferent ancestry.</description><author>Garett Ordway, Vic Patrangenaru</author><pubDate>Fri, 10 May 2024 16:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06549v1</guid></item><item><title>OneTo3D: One Image to Re-editable Dynamic 3D Model and Video Generation</title><link>http://arxiv.org/abs/2405.06547v1</link><description>One image to editable dynamic 3D model and video generation is noveldirection and change in the research area of single image to 3D representationor 3D reconstruction of image. Gaussian Splatting has demonstrated itsadvantages in implicit 3D reconstruction, compared with the original NeuralRadiance Fields. As the rapid development of technologies and principles,people tried to used the Stable Diffusion models to generate targeted modelswith text instructions. However, using the normal implicit machine learningmethods is hard to gain the precise motions and actions control, further more,it is difficult to generate a long content and semantic continuous 3D video. Toaddress this issue, we propose the OneTo3D, a method and theory to used onesingle image to generate the editable 3D model and generate the targetedsemantic continuous time-unlimited 3D video. We used a normal basic GaussianSplatting model to generate the 3D model from a single image, which requiresless volume of video memory and computer calculation ability. Subsequently, wedesigned an automatic generation and self-adaptive binding mechanism for theobject armature. Combined with the re-editable motions and actions analyzingand controlling algorithm we proposed, we can achieve a better performance thanthe SOTA projects in the area of building the 3D model precise motions andactions control, and generating a stable semantic continuous time-unlimited 3Dvideo with the input text instructions. Here we will analyze the detailedimplementation methods and theories analyses. Relative comparisons andconclusions will be presented. The project code is open source.</description><author>Jinwei Lin</author><pubDate>Fri, 10 May 2024 16:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06547v1</guid></item><item><title>Sharp analysis of out-of-distribution error for "importance-weighted" estimators in the overparameterized regime</title><link>http://arxiv.org/abs/2405.06546v1</link><description>Overparameterized models that achieve zero training error are observed togeneralize well on average, but degrade in performance when faced with datathat is under-represented in the training sample. In this work, we study anoverparameterized Gaussian mixture model imbued with a spurious feature, andsharply analyze the in-distribution and out-of-distribution test error of acost-sensitive interpolating solution that incorporates "importance weights".Compared to recent work Wang et al. (2021), Behnia et al. (2022), our analysisis sharp with matching upper and lower bounds, and significantly weakensrequired assumptions on data dimensionality. Our error characterizations alsoapply to any choice of importance weights and unveil a novel tradeoff betweenworst-case robustness to distribution shift and average accuracy as a functionof the importance weight magnitude.</description><author>Kuo-Wei Lai, Vidya Muthukumar</author><pubDate>Fri, 10 May 2024 16:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06546v1</guid></item><item><title>Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval</title><link>http://arxiv.org/abs/2405.06545v1</link><description>Large language models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, although their susceptibility to hallucination posessignificant challenges for their deployment in critical areas such ashealthcare. To address this issue, retrieving relevant facts from knowledgegraphs (KGs) is considered a promising method. Existing KG-augmented approachestend to be resource-intensive, requiring multiple rounds of retrieval andverification for each factoid, which impedes their application in real-worldscenarios. In this study, we propose Self-Refinement-Enhanced Knowledge Graph Retrieval(Re-KGR) to augment the factuality of LLMs' responses with less retrievalefforts in the medical field. Our approach leverages the attribution ofnext-token predictive probability distributions across different tokens, andvarious model layers to primarily identify tokens with a high potential forhallucination, reducing verification rounds by refining knowledge triplesassociated with these tokens. Moreover, we rectify inaccurate content usingretrieved knowledge in the post-processing stage, which improves thetruthfulness of generated responses. Experimental results on a medical datasetdemonstrate that our approach can enhance the factual capability of LLMs acrossvarious foundational models as evidenced by the highest scores on truthfulness.</description><author>Mengjia Niu, Hao Li, Jie Shi, Hamed Haddadi, Fan Mo</author><pubDate>Fri, 10 May 2024 16:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06545v1</guid></item><item><title>ATSumm: Auxiliary information enhanced approach for abstractive disaster Tweet Summarization with sparse training data</title><link>http://arxiv.org/abs/2405.06541v1</link><description>The abundance of situational information on Twitter poses a challenge forusers to manually discern vital and relevant information during disasters. Aconcise and human-interpretable overview of this information helpsdecision-makers in implementing efficient and quick disaster response. Existingabstractive summarization approaches can be categorized as sentence-based orkey-phrase-based approaches. This paper focuses on sentence-based approach,which is typically implemented as a dual-phase procedure in literature. Theinitial phase, known as the extractive phase, involves identifying the mostrelevant tweets. The subsequent phase, referred to as the abstractive phase,entails generating a more human-interpretable summary. In this study, we adoptthe methodology from prior research for the extractive phase. For theabstractive phase of summarization, most existing approaches employ deeplearning-based frameworks, which can either be pre-trained or require trainingfrom scratch. However, to achieve the appropriate level of performance, it isimperative to have substantial training data for both methods, which is notreadily available. This work presents an Abstractive Tweet Summarizer (ATSumm)that effectively addresses the issue of data sparsity by using auxiliaryinformation. We introduced the Auxiliary Pointer Generator Network (AuxPGN)model, which utilizes a unique attention mechanism called Key-phrase attention.This attention mechanism incorporates auxiliary information in the form ofkey-phrases and their corresponding importance scores from the input tweets. Weevaluate the proposed approach by comparing it with 10 state-of-the-artapproaches across 13 disaster datasets. The evaluation results indicate thatATSumm achieves superior performance compared to state-of-the-art approaches,with improvement of 4-80% in ROUGE-N F1-score.</description><author>Piyush Kumar Garg, Roshni Chakraborty, Sourav Kumar Dandapat</author><pubDate>Fri, 10 May 2024 16:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06541v1</guid></item><item><title>Mesh Denoising Transformer</title><link>http://arxiv.org/abs/2405.06536v1</link><description>Mesh denoising, aimed at removing noise from input meshes while preservingtheir feature structures, is a practical yet challenging task. Despite theremarkable progress in learning-based mesh denoising methodologies in recentyears, their network designs often encounter two principal drawbacks: adependence on single-modal geometric representations, which fall short incapturing the multifaceted attributes of meshes, and a lack of effective globalfeature aggregation, hindering their ability to fully understand the mesh'scomprehensive structure. To tackle these issues, we propose SurfaceFormer, apioneering Transformer-based mesh denoising framework. Our first contributionis the development of a new representation known as Local Surface Descriptor,which is crafted by establishing polar systems on each mesh face, followed bysampling points from adjacent surfaces using geodesics. The normals of thesepoints are organized into 2D patches, mimicking images to capture localgeometric intricacies, whereas the poles and vertex coordinates areconsolidated into a point cloud to embody spatial information. This advancementsurmounts the hurdles posed by the irregular and non-Euclidean characteristicsof mesh data, facilitating a smooth integration with Transformer architecture.Next, we propose a dual-stream structure consisting of a Geometric Encoderbranch and a Spatial Encoder branch, which jointly encode local geometrydetails and spatial information to fully explore multimodal information formesh denoising. A subsequent Denoising Transformer module receives themultimodal information and achieves efficient global feature aggregationthrough self-attention operators. Our experimental evaluations demonstrate thatthis novel approach outperforms existing state-of-the-art methods in bothobjective and subjective assessments, marking a significant leap forward inmesh denoising.</description><author>Wenbo Zhao, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji</author><pubDate>Fri, 10 May 2024 16:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06536v1</guid></item><item><title>Controllable Image Generation With Composed Parallel Token Prediction</title><link>http://arxiv.org/abs/2405.06535v1</link><description>Compositional image generation requires models to generalise well insituations where two or more input concepts do not necessarily appear togetherin training (compositional generalisation). Despite recent progress incompositional image generation via composing continuous sampling processes suchas diffusion and energy-based models, composing discrete generative processeshas remained an open challenge, with the promise of providing improvements inefficiency, interpretability and simplicity. To this end, we propose aformulation for controllable conditional generation of images via composing thelog-probability outputs of discrete generative models of the latent space. Ourapproach, when applied alongside VQ-VAE and VQ-GAN, achieves state-of-the-artgeneration accuracy in three distinct settings (FFHQ, Positional CLEVR andRelational CLEVR) while attaining competitive Fr\'echet Inception Distance(FID) scores. Our method attains an average generation accuracy of $80.71\%$across the studied settings. Our method also outperforms the next-best approach(ranked by accuracy) in terms of FID in seven out of nine experiments, with anaverage FID of $24.23$ (an average improvement of $-9.58$). Furthermore, ourmethod offers a $2.3\times$ to $12\times$ speedup over comparable continuouscompositional methods on our hardware. We find that our method can generaliseto combinations of input conditions that lie outside the training data (e.g.more objects per image) in addition to offering an interpretable dimension ofcontrollability via concept weighting. We further demonstrate that our approachcan be readily applied to an open pre-trained discrete text-to-image modelwithout any fine-tuning, allowing for fine-grained control of text-to-imagegeneration.</description><author>Jamie Stirling, Noura Al-Moubayed</author><pubDate>Fri, 10 May 2024 16:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06535v1</guid></item><item><title>CardioGenAI: A Machine Learning-Based Framework for Re-Engineering Drugs for Reduced hERG Liability</title><link>http://arxiv.org/abs/2403.07632v2</link><description>The link between in vitro hERG ion channel inhibition and subsequent in vivoQT interval prolongation, a critical risk factor for the development ofarrythmias such as Torsade de Pointes, is so well established that in vitrohERG activity alone is often sufficient to end the development of an otherwisepromising drug candidate. It is therefore of tremendous interest to developadvanced methods for identifying hERG-active compounds in the early stages ofdrug development, as well as for proposing redesigned compounds with reducedhERG liability and preserved on-target potency. In this work, we presentCardioGenAI, a machine learning-based framework for re-engineering bothdevelopmental and commercially available drugs for reduced hERG activity whilepreserving their pharmacological activity. The framework incorporates novelstate-of-the-art discriminative models for predicting hERG channel activity, aswell as activity against the voltage-gated NaV1.5 and CaV1.2 channels due totheir potential implications in modulating the arrhythmogenic potential inducedby hERG channel blockade. We applied the complete framework to pimozide, anFDA-approved antipsychotic agent that demonstrates high affinity to the hERGchannel, and generated 100 refined candidates. Remarkably, among the candidatesis fluspirilene, a compound which is of the same class of drugs(diphenylmethanes) as pimozide and therefore has similar pharmacologicalactivity, yet exhibits over 700-fold weaker binding to hERG. We envision thatthis method can effectively be applied to developmental compounds exhibitinghERG liabilities to provide a means of rescuing drug development programs thathave stalled due to hERG-related safety concerns. Additionally, thediscriminative models can also serve independently as effective components of avirtual screening pipeline. We have made all of our software open-source.</description><author>Gregory W. Kyro, Matthew T. Martin, Eric D. Watt, Victor S. Batista</author><pubDate>Fri, 10 May 2024 16:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07632v2</guid></item><item><title>Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation</title><link>http://arxiv.org/abs/2405.06525v1</link><description>Vanilla pixel-level classifiers for semantic segmentation are based on acertain paradigm, involving the inner product of fixed prototypes obtained fromthe training set and pixel features in the test image. This approach, however,encounters significant limitations, i.e., feature deviation in the semanticdomain and information loss in the spatial domain. The former struggles withlarge intra-class variance among pixel features from different images, whilethe latter fails to utilize the structured information of semantic objectseffectively. This leads to blurred mask boundaries as well as a deficiency offine-grained recognition capability. In this paper, we propose a novel Semanticand Spatial Adaptive (SSA) classifier to address the above challenges.Specifically, we employ the coarse masks obtained from the fixed prototypes asa guide to adjust the fixed prototype towards the center of the semantic andspatial domains in the test image. The adapted prototypes in semantic andspatial domains are then simultaneously considered to accomplish classificationdecisions. In addition, we propose an online multi-domain distillation learningstrategy to improve the adaption process. Experimental results on threepublicly available benchmarks show that the proposed SSA significantly improvesthe segmentation performance of the baseline models with only a minimalincrease in computational cost. Code is available athttps://github.com/xwmaxwma/SSA.</description><author>Xiaowen Ma, Zhenliang Ni, Xinghao Chen</author><pubDate>Fri, 10 May 2024 16:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06525v1</guid></item><item><title>Min-K%++: Improved Baseline for Detecting Pre-Training Data from Large Language Models</title><link>http://arxiv.org/abs/2404.02936v2</link><description>The problem of pre-training data detection for large language models (LLMs)has received growing attention due to its implications in critical issues likecopyright violation and test data contamination. A common intuition for thisproblem is to identify training data by checking if the input comes from a modeof the LLM's distribution. However, existing approaches, including thestate-of-the-art Min-K%, often use zeroth-order signals for detection, whichare less robust in determining local maxima than second-order statistics. Inthis work, we propose a novel methodology Min-K%++ for pre-training datadetection that measures how sharply peaked the likelihood is around the input,a measurement analogous to the curvature of continuous distribution. Our methodis theoretically motivated by the observation that maximum likelihood trainingimplicitly optimizes the trace of the Hessian matrix of likelihood throughscore matching. Empirically, the proposed method achieves new SOTA performanceacross multiple settings. On the WikiMIA benchmark, Min-K%++ outperforms therunner-up by 6.2% to 10.5% in detection AUROC averaged over five models. On themore challenging MIMIR benchmark, it consistently improves upon reference-freemethods while performing on par with reference-based method that requires anextra reference model.</description><author>Jingyang Zhang, Jingwei Sun, Eric Yeats, Yang Ouyang, Martin Kuo, Jianyi Zhang, Hao Frank Yang, Hai Li</author><pubDate>Fri, 10 May 2024 16:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02936v2</guid></item><item><title>Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts</title><link>http://arxiv.org/abs/2405.06524v1</link><description>Although Large Language Models (LLMs) are effective in performing various NLPtasks, they still struggle to handle tasks that require extensive, real-worldknowledge, especially when dealing with long-tail facts (facts related tolong-tail entities). This limitation highlights the need to supplement LLMswith non-parametric knowledge. To address this issue, we analysed the effectsof different types of non-parametric knowledge, including textual passage andknowledge graphs (KGs). Since LLMs have probably seen the majority of factualquestion-answering datasets already, to facilitate our analysis, we proposed afully automatic pipeline for creating a benchmark that requires knowledge oflong-tail facts for answering the involved questions. Using this pipeline, weintroduce the LTGen benchmark. We evaluate state-of-the-art LLMs in differentknowledge settings using the proposed benchmark. Our experiments show that LLMsalone struggle with answering these questions, especially when the long-taillevel is high or rich knowledge is required. Nonetheless, the performance ofthe same models improved significantly when they were prompted withnon-parametric knowledge. We observed that, in most cases, prompting LLMs withKG triples surpasses passage-based prompting using a state-of-the-artretriever. In addition, while prompting LLMs with both KG triples and documentsdoes not consistently improve knowledge coverage, it can dramatically reducehallucinations in the generated content.</description><author>Wenyu Huang, Guancheng Zhou, Mirella Lapata, Pavlos Vougiouklis, Sebastien Montella, Jeff Z. Pan</author><pubDate>Fri, 10 May 2024 16:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06524v1</guid></item><item><title>Learning from SAM: Harnessing a Foundation Model for Sim2Real Adaptation by Regularization</title><link>http://arxiv.org/abs/2309.15562v3</link><description>Domain adaptation is especially important for robotics applications, wheretarget domain training data is usually scarce and annotations are costly toobtain. We present a method for self-supervised domain adaptation for thescenario where annotated source domain data (e.g. from synthetic generation) isavailable, but the target domain data is completely unannotated. Our methodtargets the semantic segmentation task and leverages a segmentation foundationmodel (Segment Anything Model) to obtain segment information on unannotateddata. We take inspiration from recent advances in unsupervised local featurelearning and propose an invariance-variance loss over the detected segments forregularizing feature representations in the target domain. Crucially, this lossstructure and network architecture can handle overlapping segments andoversegmentation as produced by Segment Anything. We demonstrate the advantageof our method on the challenging YCB-Video and HomebrewedDB datasets and showthat it outperforms prior work and, on YCB-Video, even a network trained withreal annotations. Additionally, we provide insight through model ablations andshow applicability to a custom robotic application.</description><author>Mayara E. Bonani, Max Schwarz, Sven Behnke</author><pubDate>Fri, 10 May 2024 16:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15562v3</guid></item><item><title>Heterogeneous Graph Neural Networks with Loss-decrease-aware Curriculum Learning</title><link>http://arxiv.org/abs/2405.06522v1</link><description>In recent years, heterogeneous graph neural networks (HGNNs) have achievedexcellent performance in handling heterogeneous information networks (HINs).Curriculum learning is a machine learning strategy where training examples arepresented to a model in a structured order, starting with easy examples andgradually increasing difficulty, aiming to improve learning efficiency andgeneralization. To better exploit the rich information in HINs, previousmethods have started to explore the use of curriculum learning strategy totrain HGNNs. Specifically, these works utilize the absolute value of the lossat each training epoch to evaluate the learning difficulty of each trainingsample. However, the relative loss, rather than the absolute value of loss,reveals the learning difficulty. Therefore, we propose a novelloss-decrease-aware training schedule (LDTS). LDTS uses the trend of lossdecrease between each training epoch to better evaluating the difficulty oftraining samples, thereby enhancing the curriculum learning of HGNNs fordownstream tasks. Additionally, we propose a sampling strategy to alleviatetraining imbalance issues. Our method further demonstrate the efficacy ofcurriculum learning in enhancing HGNNs capabilities. We call our methodLoss-decrease-aware Heterogeneous Graph Neural Networks (LDHGNN). The code ispublic at https://github.com/wangyili00/LDHGNN.</description><author>Yili Wang</author><pubDate>Fri, 10 May 2024 16:06:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06522v1</guid></item><item><title>When Respondents Don't Care Anymore: Identifying the Onset of Careless Responding</title><link>http://arxiv.org/abs/2303.07167v2</link><description>Questionnaires in the behavioral and organizational sciences tend to belengthy: survey measures comprising hundreds of items are the norm rather thanthe exception. However, literature suggests that the longer a questionnairetakes, the higher the probability that participants lose interest and startresponding carelessly. Consequently, in long surveys a large number ofparticipants may engage in careless responding, posing a major threat tointernal validity. We propose a novel method for identifying the onset ofcareless responding (or an absence thereof) for each participant. It is basedon combined measurements of multiple dimensions in which carelessness maymanifest, such as inconsistency and invariability. Since a structural break ineither dimension is potentially indicative of carelessness, the proposed methodsearches for evidence for changepoints along the combined measurements. It ishighly flexible, based on machine learning, and provides statistical guaranteeson its performance. An empirical application on data from a seminal study onthe incidence of careless responding reveals that the reported incidence haslikely been substantially underestimated due to the presence of respondentsthat were careless for only parts of the questionnaire. In simulationexperiments, we find that the proposed method achieves high reliability incorrectly identifying carelessness onset, discriminates well between carelessand attentive respondents, and captures a variety of careless response types,even when a large number of careless respondents are present. Furthermore, weprovide freely available open source software to enhance accessibility andfacilitate adoption by empirical researchers.</description><author>Max Welz, Andreas Alfons</author><pubDate>Fri, 10 May 2024 16:02:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07167v2</guid></item><item><title>Taylor Videos for Action Recognition</title><link>http://arxiv.org/abs/2402.03019v4</link><description>Effectively extracting motions from video is a critical and long-standingproblem for action recognition. This problem is very challenging becausemotions (i) do not have an explicit form, (ii) have various concepts such asdisplacement, velocity, and acceleration, and (iii) often contain noise causedby unstable pixels. Addressing these challenges, we propose the Taylor video, anew video format that highlights the dominate motions (e.g., a waving hand) ineach of its frames named the Taylor frame. Taylor video is named after Taylorseries, which approximates a function at a given point using important terms.In the scenario of videos, we define an implicit motion-extraction functionwhich aims to extract motions from video temporal block. In this block, usingthe frames, the difference frames, and higher-order difference frames, weperform Taylor expansion to approximate this function at the starting frame. Weshow the summation of the higher-order terms in the Taylor series gives usdominant motion patterns, where static objects, small and unstable motions areremoved. Experimentally we show that Taylor videos are effective inputs topopular architectures including 2D CNNs, 3D CNNs, and transformers. When usedindividually, Taylor videos yield competitive action recognition accuracycompared to RGB videos and optical flow. When fused with RGB or optical flowvideos, further accuracy improvement is achieved. Additionally, we apply Taylorvideo computation to human skeleton sequences, resulting in Taylor skeletonsequences that outperform the use of original skeletons for skeleton-basedaction recognition.</description><author>Lei Wang, Xiuyuan Yuan, Tom Gedeon, Liang Zheng</author><pubDate>Fri, 10 May 2024 15:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03019v4</guid></item><item><title>UniDM: A Unified Framework for Data Manipulation with Large Language Models</title><link>http://arxiv.org/abs/2405.06510v1</link><description>Designing effective data manipulation methods is a long standing problem indata lakes. Traditional methods, which rely on rules or machine learningmodels, require extensive human efforts on training data collection and tuningmodels. Recent methods apply Large Language Models (LLMs) to resolve multipledata manipulation tasks. They exhibit bright benefits in terms of performancebut still require customized designs to fit each specific task. This is verycostly and can not catch up with the requirements of big data lake platforms.In this paper, inspired by the cross-task generality of LLMs on NLP tasks, wepave the first step to design an automatic and general solution to tackle withdata manipulation tasks. We propose UniDM, a unified framework whichestablishes a new paradigm to process data manipulation tasks using LLMs. UniDMformalizes a number of data manipulation tasks in a unified form and abstractsthree main general steps to solve each task. We develop an automatic contextretrieval to allow the LLMs to retrieve data from data lakes, potentiallycontaining evidence and factual information. For each step, we design effectiveprompts to guide LLMs to produce high quality results. By our comprehensiveevaluation on a variety of benchmarks, our UniDM exhibits great generality andstate-of-the-art performance on a wide variety of data manipulation tasks.</description><author>Yichen Qian, Yongyi He, Rong Zhu, Jintao Huang, Zhijian Ma, Haibin Wang, Yaohua Wang, Xiuyu Sun, Defu Lian, Bolin Ding, Jingren Zhou</author><pubDate>Fri, 10 May 2024 15:44:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06510v1</guid></item><item><title>Partially Stochastic Infinitely Deep Bayesian Neural Networks</title><link>http://arxiv.org/abs/2402.03495v2</link><description>In this paper, we present Partially Stochastic Infinitely Deep BayesianNeural Networks, a novel family of architectures that integrates partialstochasticity into the framework of infinitely deep neural networks. Our newclass of architectures is designed to improve the limitations of existingarchitectures around computational efficiency at training and inference time.To do this, we leverage the advantages of partial stochasticity in theinfinite-depth limit which include the benefits of full stochasticity e.g.robustness, uncertainty quantification, and memory efficiency, whilst improvingtheir limitations around computational complexity. We present a variety ofarchitectural configurations, offering flexibility in network design includingdifferent methods for weight partition. We also provide mathematical guaranteeson the expressivity of our models by establishing that our network familyqualifies as Universal Conditional Distribution Approximators. Lastly,empirical evaluations across multiple tasks show that our proposedarchitectures achieve better downstream task performance and uncertaintyquantification than their counterparts while being significantly moreefficient.</description><author>Sergio Calvo-Ordonez, Matthieu Meunier, Francesco Piatti, Yuantao Shi</author><pubDate>Fri, 10 May 2024 15:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03495v2</guid></item><item><title>Computational analysis of the language of pain: a systematic review</title><link>http://arxiv.org/abs/2404.16226v2</link><description>Objectives: This study aims to systematically review the literature on thecomputational processing of the language of pain, or pain narratives, whethergenerated by patients or physicians, identifying current trends and challenges.Methods: Following the PRISMA guidelines, a comprehensive literature search wasconducted to select relevant studies on the computational processing of thelanguage of pain and answer pre-defined research questions. Data extraction andsynthesis were performed to categorize selected studies according to theirprimary purpose and outcome, patient and pain population, textual data,computational methodology, and outcome targets. Results: Physician-generatedlanguage of pain, specifically from clinical notes, was the most used data.Tasks included patient diagnosis and triaging, identification of pain mentions,treatment response prediction, biomedical entity extraction, correlation oflinguistic features with clinical states, and lexico-semantic analysis of painnarratives. Only one study included previous linguistic knowledge on painutterances in their experimental setup. Most studies targeted their outcomesfor physicians, either directly as clinical tools or as indirect knowledge. Theleast targeted stage of clinical pain care was self-management, in whichpatients are most involved. Affective and sociocultural dimensions were theleast studied domains. Only one study measured how physician performance onclinical tasks improved with the inclusion of the proposed algorithm.Discussion: This review found that future research should focus on analyzingpatient-generated language of pain, developing patient-centered resources forself-management and patient-empowerment, exploring affective and socioculturalaspects of pain, and measuring improvements in physician performance when aidedby the proposed tools.</description><author>Diogo A. P. Nunes, Joana Ferreira-Gomes, Fani Neto, David Martins de Matos</author><pubDate>Fri, 10 May 2024 15:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16226v2</guid></item><item><title>Phylo2Vec: a vector representation for binary trees</title><link>http://arxiv.org/abs/2304.12693v3</link><description>Binary phylogenetic trees inferred from biological data are central tounderstanding the shared history among evolutionary units. However, inferringthe placement of latent nodes in a tree is NP-hard and thus computationallyexpensive. State-of-the-art methods rely on carefully designed heuristics fortree search. These methods use different data structures for easy manipulation(e.g., classes in object-oriented programming languages) and readablerepresentation of trees (e.g., Newick-format strings). Here, we presentPhylo2Vec, a parsimonious encoding for phylogenetic trees that serves as aunified approach for both manipulating and representing phylogenetic trees.Phylo2Vec maps any binary tree with $n$ leaves to a unique integer vector oflength $n-1$. The advantages of Phylo2Vec are fourfold: i) fast tree sampling,(ii) compressed tree representation compared to a Newick string, iii) quick andunambiguous verification if two binary trees are identical topologically, andiv) systematic ability to traverse tree space in very large or small jumps. Asa proof of concept, we use Phylo2Vec for maximum likelihood inference on fivereal-world datasets and show that a simple hill-climbing-based optimisationscheme can efficiently traverse the vastness of tree space from a random to anoptimal tree.</description><author>Matthew J Penn, Neil Scheidwasser, Mark P Khurana, David A Duchne, Christl A Donnelly, Samir Bhatt</author><pubDate>Fri, 10 May 2024 15:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12693v3</guid></item><item><title>Multi-Target Unsupervised Domain Adaptation for Semantic Segmentation without External Data</title><link>http://arxiv.org/abs/2405.06502v1</link><description>Multi-target unsupervised domain adaptation (UDA) aims to learn a unifiedmodel to address the domain shift between multiple target domains. Due to thedifficulty of obtaining annotations for dense predictions, it has recently beenintroduced into cross-domain semantic segmentation. However, most existingsolutions require labeled data from the source domain and unlabeled data frommultiple target domains concurrently during training. Collectively, we refer tothis data as "external". When faced with new unlabeled data from an unseentarget domain, these solutions either do not generalize well or requireretraining from scratch on all data. To address these challenges, we introducea new strategy called "multi-target UDA without external data" for semanticsegmentation. Specifically, the segmentation model is initially trained on theexternal data. Then, it is adapted to a new unseen target domain withoutaccessing any external data. This approach is thus more scalable than existingsolutions and remains applicable when external data is inaccessible. Wedemonstrate this strategy using a simple method that incorporatesself-distillation and adversarial learning, where knowledge acquired from theexternal data is preserved during adaptation through "one-way" adversariallearning. Extensive experiments in several synthetic-to-real and real-to-realadaptation settings on four benchmark urban driving datasets show that ourmethod significantly outperforms current state-of-the-art solutions, even inthe absence of external data. Our source code is available online(https://github.com/YonghaoXu/UT-KD).</description><author>Yonghao Xu, Pedram Ghamisi, Yannis Avrithis</author><pubDate>Fri, 10 May 2024 15:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06502v1</guid></item><item><title>Aspect-based Sentiment Evaluation of Chess Moves (ASSESS): an NLP-based Method for Evaluating Chess Strategies from Textbooks</title><link>http://arxiv.org/abs/2405.06499v1</link><description>The chess domain is well-suited for creating an artificial intelligence (AI)system that mimics real-world challenges, including decision-making. Throughoutthe years, minimal attention has been paid to investigating insights derivedfrom unstructured chess data sources. In this study, we examine the complicatedrelationships between multiple referenced moves in a chess-teaching textbook,and propose a novel method designed to encapsulate chess knowledge derived frommove-action phrases. This study investigates the feasibility of using amodified sentiment analysis method as a means for evaluating chess moves basedon text. Our proposed Aspect-Based Sentiment Analysis (ABSA) method representsan advancement in evaluating the sentiment associated with referenced chessmoves. By extracting insights from move-action phrases, our approach aims toprovide a more fine-grained and contextually aware `chess move'-based sentimentclassification. Through empirical experiments and analysis, we evaluate theperformance of our fine-tuned ABSA model, presenting results that confirm theefficiency of our approach in advancing aspect-based sentiment classificationwithin the chess domain. This research contributes to the area of game-playingby machines and shows the practical applicability of leveraging NLP techniquesto understand the context of strategic games.</description><author>Haifa Alrdahi, Riza Batista-Navarro</author><pubDate>Fri, 10 May 2024 15:23:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06499v1</guid></item><item><title>NeRFFaceSpeech: One-shot Audio-driven 3D Talking Head Synthesis via Generative Prior</title><link>http://arxiv.org/abs/2405.05749v2</link><description>Audio-driven talking head generation is advancing from 2D to 3D content.Notably, Neural Radiance Field (NeRF) is in the spotlight as a means tosynthesize high-quality 3D talking head outputs. Unfortunately, this NeRF-basedapproach typically requires a large number of paired audio-visual data for eachidentity, thereby limiting the scalability of the method. Although there havebeen attempts to generate audio-driven 3D talking head animations with a singleimage, the results are often unsatisfactory due to insufficient information onobscured regions in the image. In this paper, we mainly focus on addressing theoverlooked aspect of 3D consistency in the one-shot, audio-driven domain, wherefacial animations are synthesized primarily in front-facing perspectives. Wepropose a novel method, NeRFFaceSpeech, which enables to produce high-quality3D-aware talking head. Using prior knowledge of generative models combined withNeRF, our method can craft a 3D-consistent facial feature space correspondingto a single image. Our spatial synchronization method employs audio-correlatedvertex dynamics of a parametric face model to transform static image featuresinto dynamic visuals through ray deformation, ensuring realistic 3D facialmotion. Moreover, we introduce LipaintNet that can replenish the lackinginformation in the inner-mouth area, which can not be obtained from a givensingle image. The network is trained in a self-supervised manner by utilizingthe generative capabilities without additional data. The comprehensiveexperiments demonstrate the superiority of our method in generatingaudio-driven talking heads from a single image with enhanced 3D consistencycompared to previous approaches. In addition, we introduce a quantitative wayof measuring the robustness of a model against pose changes for the first time,which has been possible only qualitatively.</description><author>Gihoon Kim, Kwanggyoon Seo, Sihun Cha, Junyong Noh</author><pubDate>Fri, 10 May 2024 15:13:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05749v2</guid></item><item><title>A View on Out-of-Distribution Identification from a Statistical Testing Theory Perspective</title><link>http://arxiv.org/abs/2405.03052v3</link><description>We study the problem of efficiently detecting Out-of-Distribution (OOD)samples at test time in supervised and unsupervised learning contexts. While MLmodels are typically trained under the assumption that training and test datastem from the same distribution, this is often not the case in realisticsettings, thus reliably detecting distribution shifts is crucial at deployment.We re-formulate the OOD problem under the lenses of statistical testing andthen discuss conditions that render the OOD problem identifiable in statisticalterms. Building on this framework, we study convergence guarantees of an OODtest based on the Wasserstein distance, and provide a simple empiricalevaluation.</description><author>Alberto Caron, Chris Hicks, Vasilios Mavroudis</author><pubDate>Fri, 10 May 2024 15:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03052v3</guid></item><item><title>Improving Deep Learning Model Calibration for Cardiac Applications using Deterministic Uncertainty Networks and Uncertainty-aware Training</title><link>http://arxiv.org/abs/2405.06487v1</link><description>Improving calibration performance in deep learning (DL) classification modelsis important when planning the use of DL in a decision-support setting. In sucha scenario, a confident wrong prediction could lead to a lack of trust and/orharm in a high-risk application. We evaluate the impact on accuracy andcalibration of two types of approach that aim to improve DL classificationmodel calibration: deterministic uncertainty methods (DUM) anduncertainty-aware training. Specifically, we test the performance of three DUMsand two uncertainty-aware training approaches as well as their combinations. Toevaluate their utility, we use two realistic clinical applications from thefield of cardiac imaging: artefact detection from phase contrast cardiacmagnetic resonance (CMR) and disease diagnosis from the public ACDC CMRdataset. Our results indicate that both DUMs and uncertainty-aware training canimprove both accuracy and calibration in both of our applications, with DUMsgenerally offering the best improvements. We also investigate the combinationof the two approaches, resulting in a novel deterministic uncertainty-awaretraining approach. This provides further improvements for some combinations ofDUMs and uncertainty-aware training approaches.</description><author>Tareen Dawood, Bram Ruijsink, Reza Razavi, Andrew P. King, Esther Puyol-Antn</author><pubDate>Fri, 10 May 2024 15:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06487v1</guid></item><item><title>Solving Quantified Boolean Formulas with Few Existential Variables</title><link>http://arxiv.org/abs/2405.06485v1</link><description>The quantified Boolean formula (QBF) problem is an important decision problemgenerally viewed as the archetype for PSPACE-completeness. Many problems ofcentral interest in AI are in general not included in NP, e.g., planning, modelchecking, and non-monotonic reasoning, and for such problems QBF hassuccessfully been used as a modelling tool. However, solvers for QBF are not asadvanced as state of the art SAT solvers, which has prevented QBF from becominga universal modelling language for PSPACE-complete problems. A theoreticalexplanation is that QBF (as well as many other PSPACE-complete problems) lacksnatural parameters} guaranteeing fixed-parameter tractability (FPT). In this paper we tackle this problem and consider a simple but overlookedparameter: the number of existentially quantified variables. This naturalparameter is virtually unexplored in the literature which one might findsurprising given the general scarcity of FPT algorithms for QBF. Via thisparameterization we then develop a novel FPT algorithm applicable to QBFinstances in conjunctive normal form (CNF) of bounded clause length. Wecomplement this by a W[1]-hardness result for QBF in CNF of unbounded clauselength as well as sharper lower bounds for the bounded arity case under the(strong) exponential-time hypothesis.</description><author>Leif Eriksson, Victor Lagerkvist, George Osipov, Sebastian Ordyniak, Fahad Panolan, Mateusz Rychlicki</author><pubDate>Fri, 10 May 2024 15:07:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06485v1</guid></item><item><title>LyS at SemEval-2024 Task 3: An Early Prototype for End-to-End Multimodal Emotion Linking as Graph-Based Parsing</title><link>http://arxiv.org/abs/2405.06483v1</link><description>This paper describes our participation in SemEval 2024 Task 3, which focusedon Multimodal Emotion Cause Analysis in Conversations. We developed an earlyprototype for an end-to-end system that uses graph-based methods fromdependency parsing to identify causal emotion relations in multi-partyconversations. Our model comprises a neural transformer-based encoder forcontextualizing multimodal conversation data and a graph-based decoder forgenerating the adjacency matrix scores of the causal graph. We ranked 7th outof 15 valid and official submissions for Subtask 1, using textual inputs only.We also discuss our participation in Subtask 2 during post-evaluation usingmulti-modal inputs.</description><author>Ana Ezquerro, David Vilares</author><pubDate>Fri, 10 May 2024 15:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06483v1</guid></item><item><title>Progressive Evolution from Single-Point to Polygon for Scene Text</title><link>http://arxiv.org/abs/2312.13778v3</link><description>The advancement of text shape representations towards compactness hasenhanced text detection and spotting performance, but at a high annotationcost. Current models use single-point annotations to reduce costs, yet theylack sufficient localization information for downstream applications. Toovercome this limitation, we introduce Point2Polygon, which can efficientlytransform single-points into compact polygons. Our method uses a coarse-to-fineprocess, starting with creating and selecting anchor points based onrecognition confidence, then vertically and horizontally refining the polygonusing recognition information to optimize its shape. We demonstrate theaccuracy of the generated polygons through extensive experiments: 1) Bycreating polygons from ground truth points, we achieved an accuracy of 82.0% onICDAR 2015; 2) In training detectors with polygons generated by our method, weattained 86% of the accuracy relative to training with ground truth (GT); 3)Additionally, the proposed Point2Polygon can be seamlessly integrated toempower single-point spotters to generate polygons. This integration led to animpressive 82.5% accuracy for the generated polygons. It is worth mentioningthat our method relies solely on synthetic recognition information, eliminatingthe need for any manual annotation beyond single points.</description><author>Linger Deng, Mingxin Huang, Xudong Xie, Yuliang Liu, Lianwen Jin, Xiang Bai</author><pubDate>Fri, 10 May 2024 15:01:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13778v3</guid></item><item><title>Incentive-compatible Bandits: Importance Weighting No More</title><link>http://arxiv.org/abs/2405.06480v1</link><description>We study the problem of incentive-compatible online learning with banditfeedback. In this class of problems, the experts are self-interested agents whomight misrepresent their preferences with the goal of being selected mostoften. The goal is to devise algorithms which are simultaneouslyincentive-compatible, that is the experts are incentivised to report their truepreferences, and have no regret with respect to the preferences of the bestfixed expert in hindsight. \citet{freeman2020no} propose an algorithm in thefull information setting with optimal $O(\sqrt{T \log(K)})$ regret and$O(T^{2/3}(K\log(K))^{1/3})$ regret in the bandit setting. In this work we propose the first incentive-compatible algorithms that enjoy$O(\sqrt{KT})$ regret bounds. We further demonstrate how simple loss-biasingallows the algorithm proposed in Freeman et al. 2020 to enjoy $\tildeO(\sqrt{KT})$ regret. As a byproduct of our approach we obtain the first banditalgorithm with nearly optimal regret bounds in the adversarial setting whichworks entirely on the observed loss sequence without the need forimportance-weighted estimators. Finally, we provide an incentive-compatiblealgorithm that enjoys asymptotically optimal best-of-both-worlds regretguarantees, i.e., logarithmic regret in the stochastic regime as well asworst-case $O(\sqrt{KT})$ regret.</description><author>Julian Zimmert, Teodor V. Marinov</author><pubDate>Fri, 10 May 2024 14:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06480v1</guid></item><item><title>Informativeness of Weighted Conformal Prediction</title><link>http://arxiv.org/abs/2405.06479v1</link><description>Weighted conformal prediction (WCP), a recently proposed framework, providesuncertainty quantification with the flexibility to accommodate differentcovariate distributions between training and test data. However, it is pointedout in this paper that the effectiveness of WCP heavily relies on the overlapbetween covariate distributions; insufficient overlap can lead to uninformativeprediction intervals. To enhance the informativeness of WCP, we propose twomethods for scenarios involving multiple sources with varied covariatedistributions. We establish theoretical guarantees for our proposed methods anddemonstrate their efficacy through simulations.</description><author>Mufang Ying, Wenge Guo, Koulik Khamaru, Ying Hung</author><pubDate>Fri, 10 May 2024 14:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06479v1</guid></item><item><title>Attention is all they need: Cognitive science and the (techno)political economy of attention in humans and machines</title><link>http://arxiv.org/abs/2405.06478v1</link><description>This paper critically analyses the "attention economy" within the frameworkof cognitive science and techno-political economics, as applied to both humanand machine interactions. We explore how current business models, particularlyin digital platform capitalism, harness user engagement by strategicallyshaping attentional patterns. These platforms utilize advanced AI and massivedata analytics to enhance user engagement, creating a cycle of attentioncapture and data extraction. We review contemporary (neuro)cognitive theoriesof attention and platform engagement design techniques and criticize classicalcognitivist and behaviourist theories for their inadequacies in addressing thepotential harms of such engagement on user autonomy and wellbeing. 4Eapproaches to cognitive science, instead, emphasizing the embodied, extended,enactive, and ecological aspects of cognition, offer us an intrinsic normativestandpoint and a more integrated understanding of how attentional patterns areactively constituted by adaptive digital environments. By examining theprecarious nature of habit formation in digital contexts, we reveal thetechno-economic underpinnings that threaten personal autonomy by disaggregatinghabits away from the individual, into an AI managed collection of behaviouralpatterns. Our current predicament suggests the necessity of a paradigm shifttowards an ecology of attention. This shift aims to foster environments thatrespect and preserve human cognitive and social capacities, countering theexploitative tendencies of cognitive capitalism.</description><author>Pablo Gonzlez de la Torre, Marta Prez-Verdugo, Xabier E. Barandiaran</author><pubDate>Fri, 10 May 2024 14:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06478v1</guid></item><item><title>Efficient Reinforcement Learning via Decoupling Exploration and Utilization</title><link>http://arxiv.org/abs/2312.15965v4</link><description>Reinforcement Learning (RL), recognized as an efficient learning approach,has achieved remarkable success across multiple fields and applications,including gaming, robotics, and autonomous vehicles. Classical single-agentreinforcement learning grapples with the imbalance of exploration andexploitation as well as limited generalization abilities. This methodologyfrequently leads to algorithms settling for suboptimal solutions that aretailored only to specific datasets. In this work, our aim is to train agentwith efficient learning by decoupling exploration and utilization, so thatagent can escaping the conundrum of suboptimal Solutions. In reinforcementlearning, the previously imposed pessimistic punitive measures have deprivedthe model of its exploratory potential, resulting in diminished explorationcapabilities. To address this, we have introduced an additional optimisticActor to enhance the model's exploration ability, while employing a moreconstrained pessimistic Actor for performance evaluation. The above idea isimplemented in the proposed OPARL (Optimistic and Pessimistic ActorReinforcement Learning) algorithm. This unique amalgamation within thereinforcement learning paradigm fosters a more balanced and efficient approach.It facilitates the optimization of policies that concentrate on high-rewardactions via pessimistic exploitation strategies while concurrently ensuringextensive state coverage through optimistic exploration. Empirical andtheoretical investigations demonstrate that OPARL enhances agent capabilitiesin both utilization and exploration. In the most tasks of DMControl benchmarkand Mujoco environment, OPARL performed better than state-of-the-art methods.Our code has released on https://github.com/yydsok/OPARL</description><author>Jingpu Yang, Helin Wang, Qirui Zhao, Zhecheng Shi, Zirui Song, Miao Fang</author><pubDate>Fri, 10 May 2024 14:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15965v4</guid></item><item><title>From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers</title><link>http://arxiv.org/abs/2310.11984v3</link><description>In this paper, we investigate the inherent capabilities of transformer modelsin learning arithmetic algorithms, such as addition and parity. Throughexperiments and attention analysis, we identify a number of crucial factors forachieving optimal length generalization. We show that transformer models areable to generalize to long lengths with the help of targeted attention biasing.In particular, our solution solves the Parity task, a well-known andtheoretically proven failure mode for Transformers. We then introduce AttentionBias Calibration (ABC), a calibration stage that enables the model toautomatically learn the proper attention biases, which we show to be connectedto mechanisms in relative position encoding. We demonstrate that using ABC, thetransformer model can achieve unprecedented near-perfect length generalizationon certain arithmetic tasks. In addition, we show that ABC bears remarkablesimilarities to RPE and LoRA, which may indicate the potential for applicationsto more complex tasks.</description><author>Shaoxiong Duan, Yining Shi, Wei Xu</author><pubDate>Fri, 10 May 2024 14:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11984v3</guid></item><item><title>Autonomous Driving with a Deep Dual-Model Solution for Steering and Braking Control</title><link>http://arxiv.org/abs/2405.06473v1</link><description>The technology of autonomous driving is currently attracting a great deal ofinterest in both research and industry. In this paper, we present a deeplearning dual-model solution that uses two deep neural networks for combinedbraking and steering in autonomous vehicles. Steering control is achieved byapplying the NVIDIA's PilotNet model to predict the steering wheel angle, whilebraking control relies on the use of MobileNet SSD. Both models rely on asingle front-facing camera for image input. The MobileNet SSD model is suitablefor devices with constrained resources, whereas PilotNet struggles to operateefficiently on smaller devices with limited resources. To make it suitable forsuch devices, we modified the PilotNet model using our own original networkdesign and reduced the number of model parameters and its memory footprint byapproximately 60%. The inference latency has also been reduced, making themodel more suitable to operate on resource-constrained devices. The modifiedPilotNet model achieves similar loss and accuracy compared to the originalPilotNet model. When evaluated in a simulated environment, both autonomousdriving systems, one using the modified PilotNet model and the other using theoriginal PilotNet model for steering, show similar levels of autonomous drivingperformance.</description><author>Ana Petra Juki, Ana elek, Marija Seder, Ivana Podnar arko</author><pubDate>Fri, 10 May 2024 14:39:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06473v1</guid></item><item><title>Intrinsic Bayesian Cramr-Rao Bound with an Application to Covariance Matrix Estimation</title><link>http://arxiv.org/abs/2311.04748v2</link><description>This paper presents a new performance bound for estimation problems where theparameter to estimate lies in a Riemannian manifold (a smooth manifold endowedwith a Riemannian metric) and follows a given prior distribution. In thissetup, the chosen Riemannian metric induces a geometry for the parametermanifold, as well as an intrinsic notion of the estimation error measure.Performance bound for such error measure were previously obtained in thenon-Bayesian case (when the unknown parameter is assumed to deterministic), andreferred to as \textit{intrinsic} Cram\'er-Rao bound. The presented result thenappears either as: \textit{a}) an extension of the intrinsic Cram\'er-Rao boundto the Bayesian estimation framework; \textit{b}) a generalization of theVan-Trees inequality (Bayesian Cram\'er-Rao bound) that accounts for theaforementioned geometric structures. In a second part, we leverage thisformalism to study the problem of covariance matrix estimation when the datafollow a Gaussian distribution, and whose covariance matrix is drawn from aninverse Wishart distribution. Performance bounds for this problem are obtainedfor both the mean squared error (Euclidean metric) and the natural Riemanniandistance for Hermitian positive definite matrices (affine invariant metric).Numerical simulation illustrate that assessing the error with the affineinvariant metric is revealing of interesting properties of the maximum aposteriori and minimum mean square error estimator, which are not observed whenusing the Euclidean metric.</description><author>Florent Bouchard, Alexandre Renaux, Guillaume Ginolhac, Arnaud Breloy</author><pubDate>Fri, 10 May 2024 14:37:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04748v2</guid></item><item><title>Multimodal Active Measurement for Human Mesh Recovery in Close Proximity</title><link>http://arxiv.org/abs/2310.08116v2</link><description>For physical human-robot interactions (pHRI), a robot needs to estimate theaccurate body pose of a target person. However, in these pHRI scenarios, therobot cannot fully observe the target person's body with equipped camerasbecause the target person must be close to the robot for physical interaction.This closeness leads to severe truncation and occlusions and thus results inpoor accuracy of human pose estimation. For better accuracy in this challengingenvironment, we propose an active measurement and sensor fusion framework ofthe equipped cameras with touch and ranging sensors such as 2D LiDAR. Touch andranging sensor measurements are sparse, but reliable and informative cues forlocalizing human body parts. In our active measurement process, cameraviewpoints and sensor placements are dynamically optimized to measure bodyparts with higher estimation uncertainty, which is closely related totruncation or occlusion. In our sensor fusion process, assuming that themeasurements of touch and ranging sensors are more reliable than thecamera-based estimations, we fuse the sensor measurements to the camera-basedestimated pose by aligning the estimated pose towards the measured points. Ourproposed method outperformed previous methods on the standard occlusionbenchmark with simulated active measurement. Furthermore, our method reliablyestimated human poses using a real robot even with practical constraints suchas occlusion by blankets.</description><author>Takahiro Maeda, Keisuke Takeshita, Kazuhito Tanaka</author><pubDate>Fri, 10 May 2024 14:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08116v2</guid></item><item><title>Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification</title><link>http://arxiv.org/abs/2405.06468v1</link><description>The task of medical image recognition is notably complicated by the presenceof varied and multiple pathological indications, presenting a unique challengein multi-label classification with unseen labels. This complexity underlinesthe need for computer-aided diagnosis methods employing multi-label zero-shotlearning. Recent advancements in pre-trained vision-language models (VLMs) haveshowcased notable zero-shot classification abilities on medical images.However, these methods have limitations on leveraging extensive pre-trainedknowledge from broader image datasets, and often depend on manual promptconstruction by expert radiologists. By automating the process of prompttuning, prompt learning techniques have emerged as an efficient way to adaptVLMs to downstream tasks. Yet, existing CoOp-based strategies fall short inperforming class-specific prompts on unseen categories, limitinggeneralizability in fine-grained scenarios. To overcome these constraints, weintroduce a novel prompt generation approach inspirited by text generation innatural language processing (NLP). Our method, named Pseudo-Prompt Generating(PsPG), capitalizes on the priori knowledge of multi-modal features. Featuringa RNN-based decoder, PsPG autoregressively generates class-tailored embeddingvectors, i.e., pseudo-prompts. Comparative evaluations on various multi-labelchest radiograph datasets affirm the superiority of our approach againstleading medical vision-language and multi-label prompt learning methods. Thesource code is available at https://github.com/fallingnight/PsPG</description><author>Yaoqin Ye, Junjie Zhang, Hongwei Shi</author><pubDate>Fri, 10 May 2024 14:27:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06468v1</guid></item><item><title>Attend, Distill, Detect: Attention-aware Entropy Distillation for Anomaly Detection</title><link>http://arxiv.org/abs/2405.06467v1</link><description>Unsupervised anomaly detection encompasses diverse applications in industrialsettings where a high-throughput and precision is imperative. Early works werecentered around one-class-one-model paradigm, which poses significantchallenges in large-scale production environments. Knowledge-distillation basedmulti-class anomaly detection promises a low latency with a reasonably goodperformance but with a significant drop as compared to one-class version. Wepropose a DCAM (Distributed Convolutional Attention Module) which improves thedistillation process between teacher and student networks when there is a highvariance among multiple classes or objects. Integrated multi-scale featurematching strategy to utilise a mixture of multi-level knowledge from thefeature pyramid of the two networks, intuitively helping in detecting anomaliesof varying sizes which is also an inherent problem in the multi-class scenario.Briefly, our DCAM module consists of Convolutional Attention blocks distributedacross the feature maps of the student network, which essentially learns tomasks the irrelevant information during student learning alleviating the"cross-class interference" problem. This process is accompanied by minimizingthe relative entropy using KL-Divergence in Spatial dimension and aChannel-wise Cosine Similarity between the same feature maps of teacher andstudent. The losses enables to achieve scale-invariance and capture non-linearrelationships. We also highlight that the DCAM module would only be used duringtraining and not during inference as we only need the learned feature maps andlosses for anomaly scoring and hence, gaining a performance gain of 3.92% thanthe multi-class baseline with a preserved latency.</description><author>Sushovan Jena, Vishwas Saini, Ujjwal Shaw, Pavitra Jain, Abhay Singh Raihal, Anoushka Banerjee, Sharad Joshi, Ananth Ganesh, Arnav Bhavsar</author><pubDate>Fri, 10 May 2024 14:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06467v1</guid></item><item><title>PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation</title><link>http://arxiv.org/abs/2308.11440v2</link><description>Existing skeleton-based 3D human pose estimation methods only predict jointpositions. Although the yaw and pitch of bone rotations can be derived fromjoint positions, the roll around the bone axis remains unresolved. We presentPoseGraphNet++ (PGN++), a novel 2D-to-3D lifting Graph Convolution Network thatpredicts the complete human pose in 3D including joint positions and boneorientations. We employ both node and edge convolutions to utilize the jointand bone features. Our model is evaluated on multiple datasets using bothposition and rotation metrics. PGN++ performs on par with the state-of-the-art(SoA) on the Human3.6M benchmark. In generalization experiments, it achievesthe best results in position and matches the SoA in orientation, showcasing amore balanced performance than the current SoA. PGN++ exploits the mutualrelationship of joints and bones resulting in significantly \SB{improved}position predictions, as shown by our ablation results.</description><author>Soubarna Banik, Edvard Avagyan, Sayantan Auddy, Alejandro Mendoza Gracia, Alois Knoll</author><pubDate>Fri, 10 May 2024 14:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11440v2</guid></item><item><title>Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers</title><link>http://arxiv.org/abs/2405.06464v1</link><description>Despite the success of adaptive time-stepping in ODE simulation, it has sofar seen few applications for Stochastic Differential Equations (SDEs). Tosimulate SDEs adaptively, methods such as the Virtual Brownian Tree (VBT) havebeen developed, which can generate Brownian motion (BM) non-chronologically.However, in most applications, knowing only the values of Brownian motion isnot enough to achieve a high order of convergence; for that, we must computetime-integrals of BM such as $\int_s^t W_r \, dr$. With the aim of using highorder SDE solvers adaptively, we extend the VBT to generate these integrals ofBM in addition to the Brownian increments. A JAX-based implementation of ourconstruction is included in the popular Diffrax library(https://github.com/patrick-kidger/diffrax). Since the entire Brownian path produced by VBT is uniquely determined by asingle PRNG seed, previously generated samples need not be stored, whichresults in a constant memory footprint and enables experiment repeatability andstrong error estimation. Based on binary search, the VBT's time complexity islogarithmic in the tolerance parameter $\varepsilon$. Unlike the original VBTalgorithm, which was only precise at some dyadic times, we prove that ourconstruction exactly matches the joint distribution of the Brownian motion andits time integrals at any query times, provided they are at least $\varepsilon$apart. We present two applications of adaptive high order solvers enabled by our newVBT. Using adaptive solvers to simulate a high-volatility CIR model, we achievemore than twice the convergence order of constant stepping. We apply anadaptive third order underdamped or kinetic Langevin solver to an MCMC problem,where our approach outperforms the No U-Turn Sampler, while using only a tenthof its function evaluations.</description><author>Andra Jelini, James Foster, Patrick Kidger</author><pubDate>Fri, 10 May 2024 14:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06464v1</guid></item><item><title>MRSegmentator: Robust Multi-Modality Segmentation of 40 Classes in MRI and CT Sequences</title><link>http://arxiv.org/abs/2405.06463v1</link><description>Purpose: To introduce a deep learning model capable of multi-organsegmentation in MRI scans, offering a solution to the current limitations inMRI analysis due to challenges in resolution, standardized intensity values,and variability in sequences. Materials and Methods: he model was trained on 1,200 manually annotated MRIscans from the UK Biobank, 221 in-house MRI scans and 1228 CT scans, leveragingcross-modality transfer learning from CT segmentation models. Ahuman-in-the-loop annotation workflow was employed to efficiently createhigh-quality segmentations. The model's performance was evaluated on NAKO andthe AMOS22 dataset containing 600 and 60 MRI examinations. Dice SimilarityCoefficient (DSC) and Hausdorff Distance (HD) was used to assess segmentationaccuracy. The model will be open sourced. Results: The model showcased high accuracy in segmenting well-defined organs,achieving Dice Similarity Coefficient (DSC) scores of 0.97 for the right andleft lungs, and 0.95 for the heart. It also demonstrated robustness in organslike the liver (DSC: 0.96) and kidneys (DSC: 0.95 left, 0.95 right), whichpresent more variability. However, segmentation of smaller and complexstructures such as the portal and splenic veins (DSC: 0.54) and adrenal glands(DSC: 0.65 left, 0.61 right) revealed the need for further model optimization. Conclusion: The proposed model is a robust, tool for accurate segmentation of40 anatomical structures in MRI and CT images. By leveraging cross-modalitylearning and interactive annotation, the model achieves strong performance andgeneralizability across diverse datasets, making it a valuable resource forresearchers and clinicians. It is open source and can be downloaded fromhttps://github.com/hhaentze/MRSegmentator.</description><author>Hartmut Hntze, Lina Xu, Felix J. Dorfner, Leonhard Donle, Daniel Truhn, Hugo Aerts, Mathias Prokop, Bram van Ginneken, Alessa Hering, Lisa C. Adams, Keno K. Bressem</author><pubDate>Fri, 10 May 2024 14:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06463v1</guid></item><item><title>Are EEG-to-Text Models Working?</title><link>http://arxiv.org/abs/2405.06459v1</link><description>This work critically analyzes existing models for open-vocabulary EEG-to-Texttranslation. We identify a crucial limitation: previous studies often employedimplicit teacher-forcing during evaluation, artificially inflating performancemetrics. Additionally, they lacked a critical benchmark - comparing modelperformance on pure noise inputs. We propose a methodology to differentiatebetween models that truly learn from EEG signals and those that simply memorizetraining data. Our analysis reveals that model performance on noise data can becomparable to that on EEG data. These findings highlight the need for stricterevaluation practices in EEG-to-Text research, emphasizing transparent reportingand rigorous benchmarking with noise inputs. This approach will lead to morereliable assessments of model capabilities and pave the way for robustEEG-to-Text communication systems.</description><author>Hyejeong Jo, Yiqian Yang, Juhyeok Han, Yiqun Duan, Hui Xiong, Won Hee Lee</author><pubDate>Fri, 10 May 2024 14:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06459v1</guid></item><item><title>E2TP: Element to Tuple Prompting Improves Aspect Sentiment Tuple Prediction</title><link>http://arxiv.org/abs/2405.06454v1</link><description>Generative approaches have significantly influenced Aspect-Based SentimentAnalysis (ABSA), garnering considerable attention. However, existing studiesoften predict target text components monolithically, neglecting the benefits ofutilizing single elements for tuple prediction. In this paper, we introduceElement to Tuple Prompting (E2TP), employing a two-step architecture. Theformer step focuses on predicting single elements, while the latter stepcompletes the process by mapping these predicted elements to theircorresponding tuples. E2TP is inspired by human problem-solving, breaking downtasks into manageable parts, using the first step's output as a guide in thesecond step. Within this strategy, three types of paradigms, namelyE2TP($diet$), E2TP($f_1$), and E2TP($f_2$), are designed to facilitate thetraining process. Beyond in-domain task-specific experiments, our paperaddresses cross-domain scenarios, demonstrating the effectiveness andgeneralizability of the approach. By conducting a comprehensive analysis onvarious benchmarks, we show that E2TP achieves new state-of-the-art results innearly all cases.</description><author>Mohammad Ghiasvand Mohammadkhani, Niloofar Ranjbar, Saeedeh Momtazi</author><pubDate>Fri, 10 May 2024 14:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06454v1</guid></item><item><title>Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages</title><link>http://arxiv.org/abs/2405.04829v2</link><description>Named Entity Recognition (NER) is a useful component in Natural LanguageProcessing (NLP) applications. It is used in various tasks such as MachineTranslation, Summarization, Information Retrieval, and Question-Answeringsystems. The research on NER is centered around English and some other majorlanguages, whereas limited attention has been given to Indian languages. Weanalyze the challenges and propose techniques that can be tailored forMultilingual Named Entity Recognition for Indian Languages. We present a humanannotated named entity corpora of 40K sentences for 4 Indian languages from twoof the major Indian language families. Additionally,we present a multilingualmodel fine-tuned on our dataset, which achieves an F1 score of 0.80 on ourdataset on average. We achieve comparable performance on completely unseenbenchmark datasets for Indian languages which affirms the usability of ourmodel.</description><author>Sankalp Bahad, Pruthwik Mishra, Karunesh Arora, Rakesh Chandra Balabantaray, Dipti Misra Sharma, Parameswari Krishnamurthy</author><pubDate>Fri, 10 May 2024 13:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04829v2</guid></item><item><title>Invariant Learning via Probability of Sufficient and Necessary Causes</title><link>http://arxiv.org/abs/2309.12559v5</link><description>Out-of-distribution (OOD) generalization is indispensable for learning modelsin the wild, where testing distribution typically unknown and different fromthe training. Recent methods derived from causality have shown great potentialin achieving OOD generalization. However, existing methods mainly focus on theinvariance property of causes, while largely overlooking the property of\textit{sufficiency} and \textit{necessity} conditions. Namely, a necessary butinsufficient cause (feature) is invariant to distribution shift, yet it may nothave required accuracy. By contrast, a sufficient yet unnecessary cause(feature) tends to fit specific data well but may have a risk of adapting to anew domain. To capture the information of sufficient and necessary causes, weemploy a classical concept, the probability of sufficiency and necessary causes(PNS), which indicates the probability of whether one is the necessary andsufficient cause. To associate PNS with OOD generalization, we propose PNS riskand formulate an algorithm to learn representation with a high PNS value. Wetheoretically analyze and prove the generalizability of the PNS risk.Experiments on both synthetic and real-world benchmarks demonstrate theeffectiveness of the proposed method. The details of the implementation can befound at the GitHub repository: https://github.com/ymy4323460/CaSN.</description><author>Mengyue Yang, Zhen Fang, Yonggang Zhang, Yali Du, Furui Liu, Jean-Francois Ton, Jianhong Wang, Jun Wang</author><pubDate>Fri, 10 May 2024 13:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12559v5</guid></item><item><title>Residual-based Attention Physics-informed Neural Networks for Efficient Spatio-Temporal Lifetime Assessment of Transformers Operated in Renewable Power Plants</title><link>http://arxiv.org/abs/2405.06443v1</link><description>Transformers are vital assets for the reliable and efficient operation ofpower and energy systems. They support the integration of renewables to thegrid through improved grid stability and operation efficiency. Monitoring thehealth of transformers is essential to ensure grid reliability and efficiency.Thermal insulation ageing is a key transformer failure mode, which is generallytracked by monitoring the hotspot temperature (HST). However, HST measurementis complex and expensive and often estimated from indirect measurements.Existing computationally-efficient HST models focus on space-agnostic thermalmodels, providing worst-case HST estimates. This article introduces anefficient spatio-temporal model for transformer winding temperature and ageingestimation, which leverages physics-based partial differential equations (PDEs)with data-driven Neural Networks (NN) in a Physics Informed Neural Networks(PINNs) configuration to improve prediction accuracy and acquirespatio-temporal resolution. The computational efficiency of the PINN model isimproved through the implementation of the Residual-Based Attention scheme thataccelerates the PINN model convergence. PINN based oil temperature predictionsare used to estimate spatio-temporal transformer winding temperature values,which are validated through PDE resolution models and fiber optic sensormeasurements, respectively. Furthermore, the spatio-temporal transformer ageingmodel is inferred, aiding transformer health management decision-making andproviding insights into localized thermal ageing phenomena in the transformerinsulation. Results are validated with a distribution transformer operated on afloating photovoltaic power plant.</description><author>Ibai Ramirez, Joel Pino, David Pardo, Mikel Sanz, Luis del Rio, Alvaro Ortiz, Kateryna Morozovska, Jose I. Aizpurua</author><pubDate>Fri, 10 May 2024 13:48:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06443v1</guid></item><item><title>MasterWeaver: Taming Editability and Identity for Personalized Text-to-Image Generation</title><link>http://arxiv.org/abs/2405.05806v2</link><description>Text-to-image (T2I) diffusion models have shown significant success inpersonalized text-to-image generation, which aims to generate novel images withhuman identities indicated by the reference images. Despite promising identityfidelity has been achieved by several tuning-free methods, they usually sufferfrom overfitting issues. The learned identity tends to entangle with irrelevantinformation, resulting in unsatisfied text controllability, especially onfaces. In this work, we present MasterWeaver, a test-time tuning-free methoddesigned to generate personalized images with both faithful identity fidelityand flexible editability. Specifically, MasterWeaver adopts an encoder toextract identity features and steers the image generation through additionalintroduced cross attention. To improve editability while maintaining identityfidelity, we propose an editing direction loss for training, which aligns theediting directions of our MasterWeaver with those of the original T2I model.Additionally, a face-augmented dataset is constructed to facilitatedisentangled identity learning, and further improve the editability. Extensiveexperiments demonstrate that our MasterWeaver can not only generatepersonalized images with faithful identity, but also exhibit superiority intext controllability. Our code will be publicly available athttps://github.com/csyxwei/MasterWeaver.</description><author>Yuxiang Wei, Zhilong Ji, Jinfeng Bai, Hongzhi Zhang, Lei Zhang, Wangmeng Zuo</author><pubDate>Fri, 10 May 2024 13:43:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05806v2</guid></item><item><title>Uncertainty Quantification Metrics for Deep Regression</title><link>http://arxiv.org/abs/2405.04278v2</link><description>When deploying deep neural networks on robots or other physical systems, thelearned model should reliably quantify predictive uncertainty. A reliableuncertainty allows downstream modules to reason about the safety of itsactions. In this work, we address metrics for evaluating such an uncertainty.Specifically, we focus on regression tasks, and investigate Area UnderSparsification Error (AUSE), Calibration Error, Spearman's Rank Correlation,and Negative Log-Likelihood (NLL). Using synthetic regression datasets, we lookinto how those metrics behave under four typical types of uncertainty, theirstability regarding the size of the test set, and reveal their strengths andweaknesses. Our results indicate that Calibration Error is the most stable andinterpretable metric, but AUSE and NLL also have their respective use cases. Wediscourage the usage of Spearman's Rank Correlation for evaluatinguncertainties and recommend replacing it with AUSE.</description><author>Ziliang Xiong, Simon Kristoffersson Lind, Per-Erik Forssn, Volker Krger</author><pubDate>Fri, 10 May 2024 13:31:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04278v2</guid></item><item><title>Fair Mixed Effects Support Vector Machine</title><link>http://arxiv.org/abs/2405.06433v1</link><description>To ensure unbiased and ethical automated predictions, fairness must be a coreprinciple in machine learning applications. Fairness in machine learning aimsto mitigate biases present in the training data and model imperfections thatcould lead to discriminatory outcomes. This is achieved by preventing the modelfrom making decisions based on sensitive characteristics like ethnicity orsexual orientation. A fundamental assumption in machine learning is theindependence of observations. However, this assumption often does not hold truefor data describing social phenomena, where data points are often clusteredbased. Hence, if the machine learning models do not account for the clustercorrelations, the results may be biased. Especially high is the bias in caseswhere the cluster assignment is correlated to the variable of interest. Wepresent a fair mixed effects support vector machine algorithm that can handleboth problems simultaneously. With a reproducible simulation study wedemonstrate the impact of clustered data on the quality of fair machinelearning predictions.</description><author>Joo Vitor Pamplona, Jan Pablo Burgard</author><pubDate>Fri, 10 May 2024 13:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06433v1</guid></item><item><title>Koopman-Based Surrogate Modelling of Turbulent Rayleigh-Bnard Convection</title><link>http://arxiv.org/abs/2405.06425v1</link><description>Several related works have introduced Koopman-based Machine Learningarchitectures as a surrogate model for dynamical systems. These architecturesaim to learn non-linear measurements (also known as observables) of thesystem's state that evolve by a linear operator and are, therefore, amenable tomodel-based linear control techniques. So far, mainly simple systems have beentargeted, and Koopman architectures as reduced-order models for more complexdynamics have not been fully explored. Hence, we use a Koopman-inspiredarchitecture called the Linear Recurrent Autoencoder Network (LRAN) forlearning reduced-order dynamics in convection flows of a Rayleigh B\'enardConvection (RBC) system at different amounts of turbulence. The data isobtained from direct numerical simulations of the RBC system. A traditionalfluid dynamics method, the Kernel Dynamic Mode Decomposition (KDMD), is used tocompare the LRAN. For both methods, we performed hyperparameter sweeps toidentify optimal settings. We used a Normalized Sum of Square Error measure forthe quantitative evaluation of the models, and we also studied the modelpredictions qualitatively. We obtained more accurate predictions with the LRANthan with KDMD in the most turbulent setting. We conjecture that this is due tothe LRAN's flexibility in learning complicated observables from data, therebyserving as a viable surrogate model for the main structure of fluid dynamics inturbulent convection settings. In contrast, KDMD was more effective in lowerturbulence settings due to the repetitiveness of the convection flow. Thefeasibility of Koopman-based surrogate models for turbulent fluid flows openspossibilities for efficient model-based control techniques useful in a varietyof industrial settings.</description><author>Thorben Markmann, Michiel Straat, Barbara Hammer</author><pubDate>Fri, 10 May 2024 13:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06425v1</guid></item><item><title>Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation</title><link>http://arxiv.org/abs/2405.06424v1</link><description>Assessing response quality to instructions in language models is vital butchallenging due to the complexity of human language across different contexts.This complexity often results in ambiguous or inconsistent interpretations,making accurate assessment difficult. To address this issue, we propose a novelUncertainty-aware Reward Model (URM) that introduces a robust uncertaintyestimation for the quality of paired responses based on Bayesian approximation.Trained with preference datasets, our uncertainty-enabled proxy not only scoresrewards for responses but also evaluates their inherent uncertainty. Empiricalresults demonstrate significant benefits of incorporating the proposed proxyinto language model training. Our method boosts the instruction followingcapability of language models by refining data curation for training andimproving policy optimization objectives, thereby surpassing existing methodsby a large margin on benchmarks such as Vicuna and MT-bench. These findingshighlight that our proposed approach substantially advances language modeltraining and paves a new way of harnessing uncertainty within language models.</description><author>JoonHo Lee, Jae Oh Woo, Juree Seok, Parisa Hassanzadeh, Wooseok Jang, JuYoun Son, Sima Didari, Baruch Gutow, Heng Hao, Hankyu Moon, Wenjun Hu, Yeong-Dae Kwon, Taehee Lee, Seungjai Min</author><pubDate>Fri, 10 May 2024 13:14:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06424v1</guid></item><item><title>Contextual Affordances for Safe Exploration in Robotic Scenarios</title><link>http://arxiv.org/abs/2405.06422v1</link><description>Robotics has been a popular field of research in the past few decades, withmuch success in industrial applications such as manufacturing and logistics.This success is led by clearly defined use cases and controlled operatingenvironments. However, robotics has yet to make a large impact in domesticsettings. This is due in part to the difficulty and complexity of designingmass-manufactured robots that can succeed in the variety of homes andenvironments that humans live in and that can operate safely in close proximityto humans. This paper explores the use of contextual affordances to enable safeexploration and learning in robotic scenarios targeted in the home. Inparticular, we propose a simple state representation that allows us to extendcontextual affordances to larger state spaces and showcase how affordances canimprove the success and convergence rate of a reinforcement learning algorithmin simulation. Our results suggest that after further iterations, it ispossible to consider the implementation of this approach in a real robotmanipulator. Furthermore, in the long term, this work could be the foundationfor future explorations of human-robot interactions in complex domesticenvironments. This could be possible once state-of-the-art robot manipulatorsachieve the required level of dexterity for the described affordances in thispaper.</description><author>William Z. Ye, Eduardo B. Sandoval, Pamela Carreno-Medrano, Francisco Cru</author><pubDate>Fri, 10 May 2024 13:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06422v1</guid></item><item><title>Towards Comprehensive Multimodal Perception: Introducing the Touch-Language-Vision Dataset</title><link>http://arxiv.org/abs/2403.09813v2</link><description>Tactility provides crucial support and enhancement for the perception andinteraction capabilities of both humans and robots. Nevertheless, themultimodal research related to touch primarily focuses on visual and tactilemodalities, with limited exploration in the domain of language. Beyondvocabulary, sentence-level descriptions contain richer semantics. Based onthis, we construct a touch-language-vision dataset named TLV(Touch-Language-Vision) by human-machine cascade collaboration, featuringsentence-level descriptions for multimode alignment. The new dataset is used tofine-tune our proposed lightweight training framework, TLV-Link (Linking Touch,Language, and Vision through Alignment), achieving effective semantic alignmentwith minimal parameter adjustments (1%). Project Page:https://xiaoen0.github.io/touch.page/.</description><author>Ning Cheng, You Li, Jing Gao, Bin Fang, Jinan Xu, Wenjuan Han</author><pubDate>Fri, 10 May 2024 13:12:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09813v2</guid></item><item><title>360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model</title><link>http://arxiv.org/abs/2401.06578v2</link><description>Panorama video recently attracts more interest in both study and application,courtesy of its immersive experience. Due to the expensive cost of capturing360-degree panoramic videos, generating desirable panorama videos by prompts isurgently required. Lately, the emerging text-to-video (T2V) diffusion methodsdemonstrate notable effectiveness in standard video generation. However, due tothe significant gap in content and motion patterns between panoramic andstandard videos, these methods encounter challenges in yielding satisfactory360-degree panoramic videos. In this paper, we propose a pipeline named360-Degree Video Diffusion model (360DVD) for generating 360-degree panoramicvideos based on the given prompts and motion conditions. Specifically, weintroduce a lightweight 360-Adapter accompanied by 360 Enhancement Techniquesto transform pre-trained T2V models for panorama video generation. We furtherpropose a new panorama dataset named WEB360 consisting of panoramic video-textpairs for training 360DVD, addressing the absence of captioned panoramic videodatasets. Extensive experiments demonstrate the superiority and effectivenessof 360DVD for panorama video generation. Our project page is athttps://akaneqwq.github.io/360DVD/.</description><author>Qian Wang, Weiqi Li, Chong Mou, Xinhua Cheng, Jian Zhang</author><pubDate>Fri, 10 May 2024 13:11:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06578v2</guid></item><item><title>Time Evidence Fusion Network: Multi-source View in Long-Term Time Series Forecasting</title><link>http://arxiv.org/abs/2405.06419v1</link><description>In real-world scenarios, time series forecasting often demands timeliness,making research on model backbones a perennially hot topic. To meet theseperformance demands, we propose a novel backbone from the perspective ofinformation fusion. Introducing the Basic Probability Assignment (BPA) Moduleand the Time Evidence Fusion Network (TEFN), based on evidence theory, allowsus to achieve superior performance. On the other hand, the perspective ofmulti-source information fusion effectively improves the accuracy offorecasting. Due to the fact that BPA is generated by fuzzy theory, TEFN alsohas considerable interpretability. In real data experiments, the TEFN partiallyachieved state-of-the-art, with low errors comparable to PatchTST, andoperating efficiency surpass performance models such as Dlinear. Meanwhile,TEFN has high robustness and small error fluctuations in the randomhyperparameter selection. TEFN is not a model that achieves the ultimate insingle aspect, but a model that balances performance, accuracy, stability, andinterpretability.</description><author>Tianxiang Zhan, Yuanpeng He, Zhen Li, Yong Deng</author><pubDate>Fri, 10 May 2024 13:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06419v1</guid></item><item><title>PAC-Bayesian Generalization Bounds for Knowledge Graph Representation Learning</title><link>http://arxiv.org/abs/2405.06418v1</link><description>While a number of knowledge graph representation learning (KGRL) methods havebeen proposed over the past decade, very few theoretical analyses have beenconducted on them. In this paper, we present the first PAC-Bayesiangeneralization bounds for KGRL methods. To analyze a broad class of KGRLmodels, we propose a generic framework named ReED (Relation-awareEncoder-Decoder), which consists of a relation-aware message passing encoderand a triplet classification decoder. Our ReED framework can express at least15 different existing KGRL models, including not only graph neuralnetwork-based models such as R-GCN and CompGCN but also shallow-architecturemodels such as RotatE and ANALOGY. Our generalization bounds for the ReEDframework provide theoretical grounds for the commonly used tricks in KGRL,e.g., parameter-sharing and weight normalization schemes, and guide desirabledesign choices for practical KGRL methods. We empirically show that thecritical factors in our generalization bounds can explain actual generalizationerrors on three real-world knowledge graphs.</description><author>Jaejun Lee, Minsung Hwang, Joyce Jiyoung Whang</author><pubDate>Fri, 10 May 2024 13:03:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06418v1</guid></item><item><title>CaloQVAE : Simulating high-energy particle-calorimeter interactions using hybrid quantum-classical generative models</title><link>http://arxiv.org/abs/2312.03179v3</link><description>The Large Hadron Collider's high luminosity era presents major computationalchallenges in the analysis of collision events. Large amounts of Monte Carlo(MC) simulation will be required to constrain the statistical uncertainties ofthe simulated datasets below these of the experimental data. Modelling ofhigh-energy particles propagating through the calorimeter section of thedetector is the most computationally intensive MC simulation task. We introducea technique combining recent advancements in generative models and quantumannealing for fast and efficient simulation of high-energy particle-calorimeterinteractions.</description><author>Sehmimul Hoque, Hao Jia, Abhishek Abhishek, Mojde Fadaie, J. Quetzalcoatl Toledo-Marn, Tiago Vale, Roger G. Melko, Maximilian Swiatlowski, Wojciech T. Fedorko</author><pubDate>Fri, 10 May 2024 13:02:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03179v3</guid></item><item><title>Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides</title><link>http://arxiv.org/abs/2402.17531v2</link><description>Effective incident management is pivotal for the smooth operation ofenterprises-level cloud services. In order to expedite incident mitigation,service teams compile troubleshooting knowledge into Troubleshooting Guides(TSGs) accessible to on-call engineers (OCEs). While automated pipelines areenabled to resolve the most frequent and easy incidents, there still existcomplex incidents that require OCEs' intervention. However, TSGs are oftenunstructured and incomplete, which requires manual interpretation by OCEs,leading to on-call fatigue and decreased productivity, especially amongnew-hire OCEs. In this work, we propose Nissist which leverages TSGs andincident mitigation histories to provide proactive suggestions, reducing humanintervention. Leveraging Large Language Models (LLM), Nissist extracts insightsfrom unstructured TSGs and historical incident mitigation discussions, forminga comprehensive knowledge base. Its multi-agent system design enhancesproficiency in precisely discerning user queries, retrieving relevantinformation, and delivering systematic plans consecutively. Through our usercase and experiment, we demonstrate that Nissist significant reduce Time toMitigate (TTM) in incident mitigation, alleviating operational burdens on OCEsand improving service reliability. Our demo is available athttps://aka.ms/nissist_demo.</description><author>Kaikai An, Fangkai Yang, Junting Lu, Liqun Li, Zhixing Ren, Hao Huang, Lu Wang, Pu Zhao, Yu Kang, Hua Ding, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</author><pubDate>Fri, 10 May 2024 12:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17531v2</guid></item><item><title>Generalization analysis with deep ReLU networks for metric and similarity learning</title><link>http://arxiv.org/abs/2405.06415v1</link><description>While considerable theoretical progress has been devoted to the study ofmetric and similarity learning, the generalization mystery is still missing. Inthis paper, we study the generalization performance of metric and similaritylearning by leveraging the specific structure of the true metric (the targetfunction). Specifically, by deriving the explicit form of the true metric formetric and similarity learning with the hinge loss, we construct a structureddeep ReLU neural network as an approximation of the true metric, whoseapproximation ability relies on the network complexity. Here, the networkcomplexity corresponds to the depth, the number of nonzero weights and thecomputation units of the network. Consider the hypothesis space which consistsof the structured deep ReLU networks, we develop the excess generalizationerror bounds for a metric and similarity learning problem by estimating theapproximation error and the estimation error carefully. An optimal excess riskrate is derived by choosing the proper capacity of the constructed hypothesisspace. To the best of our knowledge, this is the first-ever-knowngeneralization analysis providing the excess generalization error for metricand similarity learning. In addition, we investigate the properties of the truemetric of metric and similarity learning with general losses.</description><author>Junyu Zhou, Puyu Wang, Ding-Xuan Zhou</author><pubDate>Fri, 10 May 2024 12:55:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06415v1</guid></item><item><title>Can Large Language Models Replicate ITS Feedback on Open-Ended Math Questions?</title><link>http://arxiv.org/abs/2405.06414v1</link><description>Intelligent Tutoring Systems (ITSs) often contain an automated feedbackcomponent, which provides a predefined feedback message to students when theydetect a predefined error. To such a feedback component, we often resort totemplate-based approaches. These approaches require significant effort fromhuman experts to detect a limited number of possible student errors and providecorresponding feedback. This limitation is exemplified in open-ended mathquestions, where there can be a large number of different incorrect errors. Inour work, we examine the capabilities of large language models (LLMs) togenerate feedback for open-ended math questions, similar to that of anestablished ITS that uses a template-based approach. We fine-tune bothopen-source and proprietary LLMs on real student responses and correspondingITS-provided feedback. We measure the quality of the generated feedback usingtext similarity metrics. We find that open-source and proprietary models bothshow promise in replicating the feedback they see during training, but do notgeneralize well to previously unseen student errors. These results suggest thatdespite being able to learn the formatting of feedback, LLMs are not able tofully understand mathematical errors made by students.</description><author>Hunter McNichols, Jaewook Lee, Stephen Fancsali, Steve Ritter, Andrew Lan</author><pubDate>Fri, 10 May 2024 12:53:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06414v1</guid></item></channel></rss>