<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 03 Oct 2025 13:00:11 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity</title><link>http://arxiv.org/abs/2510.02315v1</link><description>Text-to-image (T2I) models excel on single-entity prompts but struggle withmulti-subject descriptions, often showing attribute leakage, identityentanglement, and subject omissions. We introduce the first theoreticalframework with a principled, optimizable objective for steering samplingdynamics toward multi-subject fidelity. Viewing flow matching (FM) throughstochastic optimal control (SOC), we formulate subject disentanglement ascontrol over a trained FM sampler. This yields two architecture-agnosticalgorithms: (i) a training-free test-time controller that perturbs the basevelocity with a single-pass update, and (ii) Adjoint Matching, a lightweightfine-tuning rule that regresses a control network to a backward adjoint signalwhile preserving base-model capabilities. The same formulation unifies priorattention heuristics, extends to diffusion models via a flow-diffusioncorrespondence, and provides the first fine-tuning route explicitly designedfor multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, andStable Diffusion XL, both algorithms consistently improve multi-subjectalignment while maintaining base-model style. Test-time control runsefficiently on commodity GPUs, and fine-tuned controllers trained on limitedprompts generalize to unseen ones. We further highlight FOCUS (Flow OptimalControl for Unentangled Subjects), which achieves state-of-the-artmulti-subject fidelity across models.</description><author>Eric Tillmann Bill, Enis Simsar, Thomas Hofmann</author><pubDate>Thu, 02 Oct 2025 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02315v1</guid></item><item><title>StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions</title><link>http://arxiv.org/abs/2510.02314v1</link><description>3D scene representation methods like Neural Radiance Fields (NeRF) and 3DGaussian Splatting (3DGS) have significantly advanced novel view synthesis. Asthese methods become prevalent, addressing their vulnerabilities becomescritical. We analyze 3DGS robustness against image-level poisoning attacks andpropose a novel density-guided poisoning method. Our method strategicallyinjects Gaussian points into low-density regions identified via Kernel DensityEstimation (KDE), embedding viewpoint-dependent illusory objects clearlyvisible from poisoned views while minimally affecting innocent views.Additionally, we introduce an adaptive noise strategy to disrupt multi-viewconsistency, further enhancing attack effectiveness. We propose a KDE-basedevaluation protocol to assess attack difficulty systematically, enablingobjective benchmarking for future research. Extensive experiments demonstrateour method's superior performance compared to state-of-the-art techniques.Project page: https://hentci.github.io/stealthattack/</description><author>Bo-Hsu Ke, You-Zhe Xie, Yu-Lun Liu, Wei-Chen Chiu</author><pubDate>Thu, 02 Oct 2025 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02314v1</guid></item><item><title>Differential Information Distribution: A Bayesian Perspective on Direct Preference Optimization</title><link>http://arxiv.org/abs/2505.23761v2</link><description>Direct Preference Optimization (DPO) has been widely used for aligninglanguage models with human preferences in a supervised manner. However, severalkey questions remain unresolved: the rationale behind its log-ratio reward, howthe statistical structure of preference datasets shapes its training dynamics,and how those dynamics impact downstream capabilities. We approach thesequestions from a Bayesian perspective, interpreting the goal of preferenceoptimization as learning the differential information required to update areference policy into a target policy. To formalize this view, we introduce theDifferential Information Distribution (DID), defined as the distribution oversamples that carry the Bayesian evidence required to update policies. Weintroduce three complementary insights by viewing preference optimizationthrough the DID. First, we find that DPO's log-ratio reward is uniquelyjustified when preferences encode the Differential Information needed to updatea reference policy into the target policy. Second, we discuss how commonlyobserved training dynamics in DPO, including changes in log-likelihood andpolicy exploration, stem from a power-law DID relationship. Finally, we analyzehow training dynamics influence downstream performance using the entropy ofDID, a principled measure of uncertainty in the learned information. We observethat learning high-entropy DID improves open-ended instruction-following, whilelow-entropy DID benefits knowledge-intensive QA. Taken together, our resultsshow that DPO's reward design, training dynamics, and downstream capabilitiesall emerge as natural consequences of learning Differential Information,offering both a principled theoretical foundation and practical guidance forpreference-based alignment.</description><author>Yunjae Won, Hyunji Lee, Hyeonbin Hwang, Minjoon Seo</author><pubDate>Thu, 02 Oct 2025 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.23761v2</guid></item><item><title>Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions</title><link>http://arxiv.org/abs/2510.02313v1</link><description>Can a model distinguish between the sound of a spoon hitting a hardwood floorversus a carpeted one? Everyday object interactions produce sounds unique tothe objects involved. We introduce the sounding object detection task toevaluate a model's ability to link these sounds to the objects directlyinvolved. Inspired by human perception, our multimodal object-aware frameworklearns from in-the-wild egocentric videos. To encourage an object-centricapproach, we first develop an automatic pipeline to compute segmentation masksof the objects involved to guide the model's focus during training towards themost informative regions of the interaction. A slot attention visual encoder isused to further enforce an object prior. We demonstrate state of the artperformance on our new task along with existing multimodal action understandingtasks.</description><author>Mengyu Yang, Yiming Chen, Haozheng Pei, Siddhant Agarwal, Arun Balajee Vasudevan, James Hays</author><pubDate>Thu, 02 Oct 2025 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02313v1</guid></item><item><title>KaVa: Latent Reasoning via Compressed KV-Cache Distillation</title><link>http://arxiv.org/abs/2510.02312v1</link><description>Large Language Models (LLMs) excel at multi-step reasoning problems withexplicit chain-of-thought (CoT), but verbose traces incur significantcomputational costs and memory overhead, and often carry redundant, stylisticartifacts. Latent reasoning has emerged as an efficient alternative thatinternalizes the thought process, but it suffers from a critical lack ofsupervision, limiting its effectiveness on complex, natural-language reasoningtraces. In this work, we propose KaVa, the first framework that bridges thisgap by distilling knowledge directly from a compressed KV-cache of the teacherinto a latent-reasoning student via self-distillation, leveraging therepresentational flexibility of continuous latent tokens to align stepwise KVtrajectories. We show that the abstract, unstructured knowledge withincompressed KV-cache, which lacks direct token correspondence, can serve as arich supervisory signal for a latent reasoning student. Empirically, theapproach consistently outperforms strong latent baselines, exhibits markedlysmaller degradation from equation-only to natural-language traces, and scalesto larger backbones while preserving efficiency. These results establishcompressed KV-cache distillation as a scalable supervision signal for latentreasoning, combining the accuracy of CoT-trained teachers with the efficiencyand deployability of latent inference.</description><author>Anna Kuzina, Maciej Pioro, Paul N. Whatmough, Babak Ehteshami Bejnordi</author><pubDate>Thu, 02 Oct 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02312v1</guid></item><item><title>Inferring Dynamic Physical Properties from Video Foundation Models</title><link>http://arxiv.org/abs/2510.02311v1</link><description>We study the task of predicting dynamic physical properties from videos. Morespecifically, we consider physical properties that require temporal informationto be inferred: elasticity of a bouncing object, viscosity of a flowing liquid,and dynamic friction of an object sliding on a surface. To this end, we makethe following contributions: (i) We collect a new video dataset for eachphysical property, consisting of synthetic training and testing splits, as wellas a real split for real world evaluation. (ii) We explore three ways to inferthe physical property from videos: (a) an oracle method where we supply thevisual cues that intrinsically reflect the property using classical computervision techniques; (b) a simple read out mechanism using a visual prompt andtrainable prompt vector for cross-attention on pre-trained video generative andself-supervised models; and (c) prompt strategies for Multi-modal LargeLanguage Models (MLLMs). (iii) We show that video foundation models trained ina generative or self-supervised manner achieve a similar performance, thoughbehind that of the oracle, and MLLMs are currently inferior to the othermodels, though their performance can be improved through suitable prompting.</description><author>Guanqi Zhan, Xianzheng Ma, Weidi Xie, Andrew Zisserman</author><pubDate>Thu, 02 Oct 2025 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02311v1</guid></item><item><title>Robust Tangent Space Estimation via Laplacian Eigenvector Gradient Orthogonalization</title><link>http://arxiv.org/abs/2510.02308v1</link><description>Estimating the tangent spaces of a data manifold is a fundamental problem indata analysis. The standard approach, Local Principal Component Analysis(LPCA), struggles in high-noise settings due to a critical trade-off inchoosing the neighborhood size. Selecting an optimal size requires priorknowledge of the geometric and noise characteristics of the data that are oftenunavailable. In this paper, we propose a spectral method, Laplacian EigenvectorGradient Orthogonalization (LEGO), that utilizes the global structure of thedata to guide local tangent space estimation. Instead of relying solely onlocal neighborhoods, LEGO estimates the tangent space at each data point byorthogonalizing the gradients of low-frequency eigenvectors of the graphLaplacian. We provide two theoretical justifications of our method. First, adifferential geometric analysis on a tubular neighborhood of a manifold showsthat gradients of the low-frequency Laplacian eigenfunctions of the tube alignclosely with the manifold's tangent bundle, while an eigenfunction with highgradient in directions orthogonal to the manifold lie deeper in the spectrum.Second, a random matrix theoretic analysis also demonstrates that low-frequencyeigenvectors are robust to sub-Gaussian noise. Through comprehensiveexperiments, we demonstrate that LEGO yields tangent space estimates that aresignificantly more robust to noise than those from LPCA, resulting in markedimprovements in downstream tasks such as manifold learning, boundary detection,and local intrinsic dimension estimation.</description><author>Dhruv Kohli, Sawyer J. Robertson, Gal Mishne, Alexander Cloninger</author><pubDate>Thu, 02 Oct 2025 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02308v1</guid></item><item><title>NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation</title><link>http://arxiv.org/abs/2510.02307v1</link><description>Text-to-image diffusion models trained on a fixed set of resolutions oftenfail to generalize, even when asked to generate images at lower resolutionsthan those seen during training. High-resolution text-to-image generators arecurrently unable to easily offer an out-of-the-box budget-efficient alternativeto their users who might not need high-resolution images. We identify a keytechnical insight in diffusion models that when addressed can help tackle thislimitation: Noise schedulers have unequal perceptual effects acrossresolutions. The same level of noise removes disproportionately more signalfrom lower-resolution images than from high-resolution images, leading to atrain-test mismatch. We propose NoiseShift, a training-free method thatrecalibrates the noise level of the denoiser conditioned on resolution size.NoiseShift requires no changes to model architecture or sampling schedule andis compatible with existing models. When applied to Stable Diffusion 3, StableDiffusion 3.5, and Flux-Dev, quality at low resolutions is significantlyimproved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, andFlux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These resultsdemonstrate the effectiveness of NoiseShift in mitigating resolution-dependentartifacts and enhancing the quality of low-resolution image generation.</description><author>Ruozhen He, Moayed Haji-Ali, Ziyan Yang, Vicente Ordonez</author><pubDate>Thu, 02 Oct 2025 17:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02307v1</guid></item><item><title>Drawing Conclusions from Draws: Rethinking Preference Semantics in Arena-Style LLM Evaluation</title><link>http://arxiv.org/abs/2510.02306v1</link><description>In arena-style evaluation of large language models (LLMs), two LLMs respondto a user query, and the user chooses the winning response or deems the"battle" a draw, resulting in an adjustment to the ratings of both models. Theprevailing approach for modeling these rating dynamics is to view battles astwo-player game matches, as in chess, and apply the Elo rating system and itsderivatives. In this paper, we critically examine this paradigm. Specifically,we question whether a draw genuinely means that the two models are equal andhence whether their ratings should be equalized. Instead, we conjecture thatdraws are more indicative of query difficulty: if the query is too easy, thenboth models are more likely to succeed equally. On three real-world arenadatasets, we show that ignoring rating updates for draws yields a 1-3% relativeincrease in battle outcome prediction accuracy (which includes draws) for allfour rating systems studied. Further analyses suggest that draws occur more forqueries rated as very easy and those as highly objective, with risk ratios of1.37 and 1.35, respectively. We recommend future rating systems to reconsiderexisting draw semantics and to account for query properties in rating updates.</description><author>Raphael Tang, Crystina Zhang, Wenyan Li, Carmen Lai, Pontus Stenetorp, Yao Lu</author><pubDate>Thu, 02 Oct 2025 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02306v1</guid></item><item><title>Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is Geometry Adaptive</title><link>http://arxiv.org/abs/2510.02305v1</link><description>Diffusion models have achieved state-of-the-art performance, demonstratingremarkable generalisation capabilities across diverse domains. However, themechanisms underpinning these strong capabilities remain only partiallyunderstood. A leading conjecture, based on the manifold hypothesis, attributesthis success to their ability to adapt to low-dimensional geometric structurewithin the data. This work provides evidence for this conjecture, focusing onhow such phenomena could result from the formulation of the learning problemthrough score matching. We inspect the role of implicit regularisation byinvestigating the effect of smoothing minimisers of the empirical scorematching objective. Our theoretical and empirical results confirm thatsmoothing the score function -- or equivalently, smoothing in the log-densitydomain -- produces smoothing tangential to the data manifold. In addition, weshow that the manifold along which the diffusion model generalises can becontrolled by choosing an appropriate smoothing.</description><author>Tyler Farghly, Peter Potaptchik, Samuel Howard, George Deligiannidis, Jakiw Pidstrigach</author><pubDate>Thu, 02 Oct 2025 17:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02305v1</guid></item><item><title>Learning to Reason for Hallucination Span Detection</title><link>http://arxiv.org/abs/2510.02173v1</link><description>Large language models (LLMs) often generate hallucinations -- unsupportedcontent that undermines reliability. While most prior works frame hallucinationdetection as a binary task, many real-world applications require identifyinghallucinated spans, which is a multi-step decision making process. Thisnaturally raises the question of whether explicit reasoning can help thecomplex task of detecting hallucination spans. To answer this question, wefirst evaluate pretrained models with and without Chain-of-Thought (CoT)reasoning, and show that CoT reasoning has the potential to generate at leastone correct answer when sampled multiple times. Motivated by this, we proposeRL4HS, a reinforcement learning framework that incentivizes reasoning with aspan-level reward function. RL4HS builds on Group Relative Policy Optimizationand introduces Class-Aware Policy Optimization to mitigate reward imbalanceissue. Experiments on the RAGTruth benchmark (summarization, questionanswering, data-to-text) show that RL4HS surpasses pretrained reasoning modelsand supervised fine-tuning, demonstrating the necessity of reinforcementlearning with span-level rewards for detecting hallucination spans.</description><author>Hsuan Su, Ting-Yao Hu, Hema Swetha Koppula, Kundan Krishna, Hadi Pouransari, Cheng-Yu Hsieh, Cem Koc, Joseph Yitan Cheng, Oncel Tuzel, Raviteja Vemulapalli</author><pubDate>Thu, 02 Oct 2025 16:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02173v1</guid></item><item><title>RESTRAIN: From Spurious Votes to Signals -- Self-Driven RL with Self-Penalization</title><link>http://arxiv.org/abs/2510.02172v1</link><description>Reinforcement learning with human-annotated data has boosted chain-of-thoughtreasoning in large reasoning models, but these gains come at high costs inlabeled data while faltering on harder tasks. A natural next step isexperience-driven learning, where models improve without curated labels byadapting to unlabeled data. We introduce RESTRAIN (REinforcement learning withSelf-restraint), a self-penalizing RL framework that converts the absence ofgold labels into a useful learning signal. Instead of overcommitting tospurious majority votes, RESTRAIN exploits signals from the model's entireanswer distribution: penalizing overconfident rollouts and low-consistencyexamples while preserving promising reasoning chains. The self-penalizationmechanism integrates seamlessly into policy optimization methods such as GRPO,enabling continual self-improvement without supervision. On challengingreasoning benchmarks, RESTRAIN delivers large gains using only unlabeled data.With Qwen3-4B-Base and OctoThinker Hybrid-8B-Base, it improves Pass@1 by up to+140.7 percent on AIME25, +36.2 percent on MMLU_STEM, and +19.6 percent onGPQA-Diamond, nearly matching gold-label training while using no gold labels.These results demonstrate that RESTRAIN establishes a scalable path towardstronger reasoning without gold labels.</description><author>Zhaoning Yu, Will Su, Leitian Tao, Haozhu Wang, Aashu Singh, Hanchao Yu, Jianyu Wang, Hongyang Gao, Weizhe Yuan, Jason Weston, Ping Yu, Jing Xu</author><pubDate>Thu, 02 Oct 2025 16:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02172v1</guid></item><item><title>Go witheFlow: Real-time Emotion Driven Audio Effects Modulation</title><link>http://arxiv.org/abs/2510.02171v1</link><description>Music performance is a distinctly human activity, intrinsically linked to theperformer's ability to convey, evoke, or express emotion. Machines cannotperform music in the human sense; they can produce, reproduce, execute, orsynthesize music, but they lack the capacity for affective or emotionalexperience. As such, music performance is an ideal candidate through which toexplore aspects of collaboration between humans and machines. In this paper, weintroduce the witheFlow system, designed to enhance real-time music performanceby automatically modulating audio effects based on features extracted from bothbiosignals and the audio itself. The system, currently in a proof-of-conceptphase, is designed to be lightweight, able to run locally on a laptop, and isopen-source given the availability of a compatible Digital Audio Workstationand sensors.</description><author>Edmund Dervakos, Spyridon Kantarelis, Vassilis Lyberatos, Jason Liartis, Giorgos Stamou</author><pubDate>Thu, 02 Oct 2025 16:23:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02171v1</guid></item><item><title>A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection</title><link>http://arxiv.org/abs/2505.12586v5</link><description>Deep neural networks (DNNs) are highly susceptible to adversarialexamples--subtle, imperceptible perturbations that can lead to incorrectpredictions. While detection-based defenses offer a practical alternative toadversarial training, many existing methods depend on external models, complexarchitectures, or adversarial data, limiting their efficiency andgeneralizability. We introduce a lightweight, plug-in detection framework thatleverages internal layer-wise inconsistencies within the target model itself,requiring only benign data for calibration. Our approach is grounded in the AFew Large Shifts Assumption, which posits that adversarial perturbations inducelarge, localized violations of layer-wise Lipschitz continuity in a smallsubset of layers. Building on this, we propose two complementarystrategies--Recovery Testing (RT) and Logit-layer Testing (LT)--to empiricallymeasure these violations and expose internal disruptions caused by adversaries.Evaluated on CIFAR-10, CIFAR-100, and ImageNet under both standard and adaptivethreat models, our method achieves state-of-the-art detection performance withnegligible computational overhead. Furthermore, our system-level analysisprovides a practical method for selecting a detection threshold with a formallower-bound guarantee on accuracy. The code is available here:https://github.com/c0510gy/AFLS-AED.</description><author>Sanggeon Yun, Ryozo Masukawa, Hyunwoo Oh, Nathaniel D. Bastian, Mohsen Imani</author><pubDate>Thu, 02 Oct 2025 16:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12586v5</guid></item><item><title>Initialization using Update Approximation is a Silver Bullet for Extremely Efficient Low-Rank Fine-Tuning</title><link>http://arxiv.org/abs/2411.19557v4</link><description>Low-rank adapters have become standard for efficiently fine-tuning largelanguage models, but they often fall short of achieving the performance of fullfine-tuning. We propose a method, LoRA Silver Bullet or LoRA-SB, thatapproximates full fine-tuning within low-rank subspaces using a carefullydesigned initialization strategy. We theoretically demonstrate that thearchitecture of LoRA-XS, which inserts a learnable r x r matrix between B and Awhile keeping other matrices fixed, provides the precise conditions needed forthis approximation. We leverage its constrained update space to achieve optimalscaling for high-rank gradient updates while removing the need for scalingfactor tuning. We prove that our initialization offers an optimal low-rankapproximation of the initial gradient and preserves update directionsthroughout training. Extensive experiments across mathematical reasoning,commonsense reasoning, and language understanding tasks demonstrate that ourapproach exceeds the performance of LoRA (and baselines) while using 27-90times fewer learnable parameters, and comprehensively outperforms LoRA-XS. Ourfindings establish that it is possible to simulate full fine-tuning in low-ranksubspaces, and achieve significant parameter efficiency gains withoutsacrificing performance. Our code is publicly available at:https://github.com/CERT-Lab/lora-sb.</description><author>Kaustubh Ponkshe, Raghav Singhal, Eduard Gorbunov, Alexey Tumanov, Samuel Horvath, Praneeth Vepakomma</author><pubDate>Thu, 02 Oct 2025 16:20:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.19557v4</guid></item><item><title>Enhancing Corpus Callosum Segmentation in Fetal MRI via Pathology-Informed Domain Randomization</title><link>http://arxiv.org/abs/2508.20475v2</link><description>Accurate fetal brain segmentation is crucial for extracting biomarkers andassessing neurodevelopment, especially in conditions such as corpus callosumdysgenesis (CCD), which can induce drastic anatomical changes. However, therarity of CCD severely limits annotated data, hindering the generalization ofdeep learning models. To address this, we propose a pathology-informed domainrandomization strategy that embeds prior knowledge of CCD manifestations into asynthetic data generation pipeline. By simulating diverse brain alterationsfrom healthy data alone, our approach enables robust segmentation withoutrequiring pathological annotations. We validate our method on a cohort comprising 248 healthy fetuses, 26 withCCD, and 47 with other brain pathologies, achieving substantial improvements onCCD cases while maintaining performance on both healthy fetuses and those withother pathologies. From the predicted segmentations, we derive clinicallyrelevant biomarkers, such as corpus callosum length (LCC) and volume, and showtheir utility in distinguishing CCD subtypes. Our pathology-informedaugmentation reduces the LCC estimation error from 1.89 mm to 0.80 mm inhealthy cases and from 10.9 mm to 0.7 mm in CCD cases. Beyond thesequantitative gains, our approach yields segmentations with improved topologicalconsistency relative to available ground truth, enabling more reliableshape-based analyses. Overall, this work demonstrates that incorporatingdomain-specific anatomical priors into synthetic data pipelines can effectivelymitigate data scarcity and enhance analysis of rare but clinically significantmalformations.</description><author>Marina Grifell i Plana, Vladyslav Zalevskyi, Léa Schmidt, Yvan Gomez, Thomas Sanchez, Vincent Dunet, Mériam Koob, Vanessa Siffredi, Meritxell Bach Cuadra</author><pubDate>Thu, 02 Oct 2025 16:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.20475v2</guid></item><item><title>Machine learning for accuracy in density functional approximations</title><link>http://arxiv.org/abs/2311.00196v2</link><description>Machine learning techniques have found their way into computational chemistryas indispensable tools to accelerate atomistic simulations and materialsdesign. In addition, machine learning approaches hold the potential to boostthe predictive power of computationally efficient electronic structure methods,such as density functional theory, to chemical accuracy and to correct forfundamental errors in density functional approaches. Here, recent progress inapplying machine learning to improve the accuracy of density functional andrelated approximations is reviewed. Promises and challenges in devising machinelearning models transferable between different chemistries and materialsclasses are discussed with the help of examples applying promising models tosystems far outside their training sets.</description><author>Johannes Voss</author><pubDate>Thu, 02 Oct 2025 16:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00196v2</guid></item><item><title>One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation</title><link>http://arxiv.org/abs/2503.13358v3</link><description>Diffusion models for super-resolution (SR) produce high-quality visualresults but require expensive computational costs. Despite the development ofseveral methods to accelerate diffusion-based SR models, some (e.g., SinSR)fail to produce realistic perceptual details, while others (e.g., OSEDiff) mayhallucinate non-existent structures. To overcome these issues, we present RSD,a new distillation method for ResShift, one of the top diffusion-based SRmodels. Our method is based on training the student network to produce suchimages that a new fake ResShift model trained on them will coincide with theteacher model. RSD achieves single-step restoration and outperforms the teacherby a large margin. We show that our distillation method can surpass the otherdistillation-based method for ResShift - SinSR - making it on par withstate-of-the-art diffusion-based SR distillation methods. Compared to SRmethods based on pre-trained text-to-image models, RSD produces competitiveperceptual quality, provides images with better alignment to degraded inputimages, and requires fewer parameters and GPU memory. We provide experimentalresults on various real-world and synthetic datasets, including RealSR,RealSet65, DRealSR, ImageNet, and DIV2K.</description><author>Daniil Selikhanovych, David Li, Aleksei Leonov, Nikita Gushchin, Sergei Kushneriuk, Alexander Filippov, Evgeny Burnaev, Iaroslav Koshelev, Alexander Korotin</author><pubDate>Thu, 02 Oct 2025 16:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.13358v3</guid></item><item><title>Superficial Safety Alignment Hypothesis</title><link>http://arxiv.org/abs/2410.10862v2</link><description>As large language models (LLMs) are overwhelmingly more and more integratedinto various applications, ensuring they generate safe responses is a pressingneed. Previous studies on alignment have largely focused on generalinstruction-following but have often overlooked the distinct properties ofsafety alignment, such as the brittleness of safety mechanisms. To bridge thegap, we propose the Superficial Safety Alignment Hypothesis (SSAH), whichposits that safety alignment teaches an otherwise unsafe model to choose thecorrect reasoning direction - fulfill or refuse users' requests - interpretedas an implicit binary classification task. Through SSAH, we hypothesize thatonly a few essential components can establish safety guardrails in LLMs. Wesuccessfully identify four types of attribute-critical components: SafetyCritical Unit (SCU), Utility Critical Unit (UCU), Complex Unit (CU), andRedundant Unit (RU). Our findings show that freezing certain safety-criticalcomponents during fine-tuning allows the model to retain its safety attributeswhile adapting to new tasks. Similarly, we show that leveraging redundant unitsin the pre-trained model as an "alignment budget" can effectively minimize thealignment tax while achieving the alignment goal. All considered, this paperconcludes that the atomic functional unit for safety in LLMs is at the neuronlevel and underscores that safety alignment should not be complicated.</description><author>Jianwei Li, Jung-Eun Kim</author><pubDate>Thu, 02 Oct 2025 16:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10862v2</guid></item><item><title>SIEVE: Towards Verifiable Certification for Code-datasets</title><link>http://arxiv.org/abs/2510.02166v1</link><description>Code agents and empirical software engineering rely on public code datasets,yet these datasets lack verifiable quality guarantees. Static 'dataset cards'inform, but they are neither auditable nor do they offer statisticalguarantees, making it difficult to attest to dataset quality. Teams buildisolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. Wepresent SIEVE, a community-driven framework. It turns per-property checks intoConfidence Cards-machine-readable, verifiable certificates with anytime-validstatistical bounds. We outline a research plan to bring SIEVE to maturity,replacing narrative cards with anytime-verifiable certification. This shift isexpected to lower quality-assurance costs and increase trust in code-datasets.</description><author>Fatou Ndiaye Mbodji, El-hacen Diallo, Jordan Samhi, Kui Liu, Jacques Klein, Tegawendé F. Bissyande</author><pubDate>Thu, 02 Oct 2025 16:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02166v1</guid></item><item><title>What if I ask in \textit{alia lingua}? Measuring Functional Similarity Across Languages</title><link>http://arxiv.org/abs/2509.04032v2</link><description>How similar are model outputs across languages? In this work, we study thisquestion using a recently proposed model similarity metric $\kappa_p$ appliedto 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that amodel's responses become increasingly consistent across languages as its sizeand capability grow. Interestingly, models exhibit greater cross-lingualconsistency within themselves than agreement with other models prompted in thesame language. These results highlight not only the value of $\kappa_p$ as apractical tool for evaluating multilingual reliability, but also its potentialto guide the development of more consistent multilingual systems.</description><author>Debangan Mishra, Arihant Rastogi, Agyeya Negi, Shashwat Goel, Ponnurangam Kumaraguru</author><pubDate>Thu, 02 Oct 2025 16:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.04032v2</guid></item><item><title>NoMod: A Non-modular Attack on Module Learning With Errors</title><link>http://arxiv.org/abs/2510.02162v1</link><description>The advent of quantum computing threatens classical public-key cryptography,motivating NIST's adoption of post-quantum schemes such as those based on theModule Learning With Errors (Module-LWE) problem. We present NoMod ML-Attack, ahybrid white-box cryptanalytic method that circumvents the challenge ofmodeling modular reduction by treating wrap-arounds as statistical corruptionand casting secret recovery as robust linear estimation. Our approach combinesoptimized lattice preprocessing--including reduced-vector saving and algebraicamplification--with robust estimators trained via Tukey's Biweight loss.Experiments show NoMod achieves full recovery of binary secrets for dimension$n = 350$, recovery of sparse binomial secrets for $n = 256$, and successfulrecovery of sparse secrets in CRYSTALS-Kyber settings with parameters $(n, k) =(128, 3)$ and $(256, 2)$. We release our implementation in an anonymousrepository https://anonymous.4open.science/r/NoMod-3BD4.</description><author>Cristian Bassotto, Ermes Franch, Marina Krček, Stjepan Picek</author><pubDate>Thu, 02 Oct 2025 16:12:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02162v1</guid></item><item><title>Comparing Contrastive and Triplet Loss in Audio-Visual Embedding: Intra-Class Variance and Greediness Analysis</title><link>http://arxiv.org/abs/2510.02161v1</link><description>Contrastive loss and triplet loss are widely used objectives in deep metriclearning, yet their effects on representation quality remain insufficientlyunderstood. We present a theoretical and empirical comparison of these losses,focusing on intra- and inter-class variance and optimization behavior (e.g.,greedy updates). Through task-specific experiments with consistent settings onsynthetic data and real datasets-MNIST, CIFAR-10-it is shown that triplet losspreserves greater variance within and across classes, supporting finer-graineddistinctions in the learned representations. In contrast, contrastive losstends to compact intra-class embeddings, which may obscure subtle semanticdifferences. To better understand their optimization dynamics, By examiningloss-decay rate, active ratio, and gradient norm, we find that contrastive lossdrives many small updates early on, while triplet loss produces fewer butstronger updates that sustain learning on hard examples. Finally, across bothclassification and retrieval tasks on MNIST, CIFAR-10, CUB-200, and CARS196datasets, our results consistently show that triplet loss yields superiorperformance, which suggests using triplet loss for detail retention andhard-sample focus, and contrastive loss for smoother, broad-based embeddingrefinement.</description><author>Donghuo Zeng</author><pubDate>Thu, 02 Oct 2025 16:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02161v1</guid></item><item><title>Consistent End-to-End Estimation for Counterfactual Fairness</title><link>http://arxiv.org/abs/2310.17687v2</link><description>Fairness in predictions is of direct importance in practice due to legal,ethical, and societal reasons. This is often accomplished throughcounterfactual fairness, which ensures that the prediction for an individual isthe same as that in a counterfactual world under a different sensitiveattribute. However, achieving counterfactual fairness is challenging ascounterfactuals are unobservable, and, because of that, existing baselines forcounterfactual fairness do not have theoretical guarantees. In this paper, wepropose a novel counterfactual fairness predictor for making predictions undercounterfactual fairness. Here, we follow the standard counterfactual fairnesssetting and directly learn the counterfactual distribution of the descendantsof the sensitive attribute via tailored neural networks, which we then use toenforce fair predictions through a novel counterfactual mediatorregularization. Unique to our work is that we provide theoretical guaranteesthat our method is effective in ensuring the notion of counterfactual fairness.We further compare the performance across various datasets, where our methodachieves state-of-the-art performance.</description><author>Yuchen Ma, Valentyn Melnychuk, Dennis Frauen, Stefan Feuerriegel</author><pubDate>Thu, 02 Oct 2025 16:11:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17687v2</guid></item><item><title>CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning</title><link>http://arxiv.org/abs/2506.00750v2</link><description>Understanding and reasoning about code semantics is essential for enhancingcode LLMs' abilities to solve real-world software engineering (SE) tasks.Although several code reasoning benchmarks exist, most rely on syntheticdatasets or educational coding problems and focus on coarse-grained reasoningtasks such as input/output prediction, limiting their effectiveness inevaluating LLMs in practical SE contexts. To bridge this gap, we proposeCodeSense, the first benchmark that makes available a spectrum of fine-grainedcode reasoning tasks concerned with the software engineering of real-worldcode. We collected Python, C and Java software projects from real-worldrepositories. We executed tests from these repositories, collected theirexecution traces, and constructed a ground truth dataset for fine-grainedsemantic reasoning tasks. We then performed comprehensive evaluations onstate-of-the-art LLMs. Our results show a clear performance gap for the modelsto handle fine-grained reasoning tasks. Although prompting techniques such aschain-of-thought and in-context learning helped, the lack of code semantics inLLMs fundamentally limit models' capabilities of code reasoning. Besidesdataset, benchmark and evaluation, our work produced an execution tracingframework and tool set that make it easy to collect ground truth forfine-grained SE reasoning tasks, offering a strong basis for future benchmarkconstruction and model post training. Our code and data are located athttps://codesense-bench.github.io/.</description><author>Monoshi Kumar Roy, Simin Chen, Benjamin Steenhoek, Jinjun Peng, Gail Kaiser, Baishakhi Ray, Wei Le</author><pubDate>Thu, 02 Oct 2025 16:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.00750v2</guid></item><item><title>Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting</title><link>http://arxiv.org/abs/2510.02155v1</link><description>Prompting has emerged as a practical way to adapt frozen vision-languagemodels (VLMs) for video anomaly detection (VAD). Yet, existing prompts areoften overly abstract, overlooking the fine-grained human-object interactionsor action semantics that define complex anomalies in surveillance videos. Wepropose ASK-Hint, a structured prompting framework that leveragesaction-centric knowledge to elicit more accurate and interpretable reasoningfrom frozen VLMs. Our approach organizes prompts into semantically coherentgroups (e.g. violence, property crimes, public safety) and formulatesfine-grained guiding questions that align model predictions with discriminativevisual cues. Extensive experiments on UCF-Crime and XD-Violence show thatASK-Hint consistently improves AUC over prior baselines, achievingstate-of-the-art performance compared to both fine-tuned and training-freemethods. Beyond accuracy, our framework provides interpretable reasoning tracestowards anomaly and demonstrates strong generalization across datasets and VLMbackbones. These results highlight the critical role of prompt granularity andestablish ASK-Hint as a new training-free and generalizable solution forexplainable video anomaly detection.</description><author>Shu Zou, Xinyu Tian, Lukas Wesemann, Fabian Waschkowski, Zhaoyuan Yang, Jing Zhang</author><pubDate>Thu, 02 Oct 2025 16:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02155v1</guid></item><item><title>Human-Robo-advisor collaboration in decision-making: Evidence from a multiphase mixed methods experimental study</title><link>http://arxiv.org/abs/2510.02153v1</link><description>Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to humanfinancial advisors, yet adoption remains limited. While prior research hasexamined user interactions with RAs, less is known about how individualsinterpret RA roles and integrate their advice into decision-making. To addressthis gap, this study employs a multiphase mixed methods design integrating abehavioral experiment (N = 334), thematic analysis, and follow-up quantitativetesting. Findings suggest that people tend to rely on RAs, with reliance shapedby information about RA performance and the framing of advice as gains orlosses. Thematic analysis reveals three RA roles in decision-making and fouruser types, each reflecting distinct patterns of advice integration. Inaddition, a 2 x 2 typology categorizes antecedents of acceptance into enablersand inhibitors at both the individual and algorithmic levels. By combiningbehavioral, interpretive, and confirmatory evidence, this study advancesunderstanding of human-RA collaboration and provides actionable insights fordesigning more trustworthy and adaptive RA systems.</description><author>Hasan Mahmud, Najmul Islam, Satish Krishnan</author><pubDate>Thu, 02 Oct 2025 16:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02153v1</guid></item><item><title>A Family of Kernelized Matrix Costs for Multiple-Output Mixture Neural Networks</title><link>http://arxiv.org/abs/2509.24076v3</link><description>Pairwise distance-based costs are crucial for self-supervised and contrastivefeature learning. Mixture Density Networks (MDNs) are a widely used approachfor generative models and density approximation, using neural networks toproduce multiple centers that define a Gaussian mixture. By combining MDNs withcontrastive costs, this paper proposes data density approximation using fourtypes of kernelized matrix costs: the scalar cost, the vector-matrix cost, thematrix-matrix cost (the trace of Schur complement), and the SVD cost (thenuclear norm), for learning multiple centers required to define a mixturedensity.</description><author>Bo Hu, José C. Príncipe</author><pubDate>Thu, 02 Oct 2025 16:02:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24076v3</guid></item><item><title>Reinforcement Learning with Action-Triggered Observations</title><link>http://arxiv.org/abs/2510.02149v1</link><description>We study reinforcement learning problems where state observations arestochastically triggered by actions, a constraint common in many real-worldapplications. This framework is formulated as Action-Triggered SporadicallyTraceable Markov Decision Processes (ATST-MDPs), where each action has aspecified probability of triggering a state observation. We derive tailoredBellman optimality equations for this framework and introduce theaction-sequence learning paradigm in which agents commit to executing asequence of actions until the next observation arrives. Under the linear MDPassumption, value-functions are shown to admit linear representations in aninduced action-sequence feature map. Leveraging this structure, we proposeoff-policy estimators with statistical error guarantees for such feature mapsand introduce ST-LSVI-UCB, a variant of LSVI-UCB adapted for action-triggeredsettings. ST-LSVI-UCB achieves regret $\widetildeO(\sqrt{Kd^3(1-\gamma)^{-3}})$, where $K$ is the number of episodes, $d$ thefeature dimension, and $\gamma$ the discount factor (per-step episodenon-termination probability). Crucially, this work establishes the theoreticalfoundation for learning with sporadic, action-triggered observations whiledemonstrating that efficient learning remains feasible under such observationconstraints.</description><author>Alexander Ryabchenko, Wenlong Mou</author><pubDate>Thu, 02 Oct 2025 16:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02149v1</guid></item><item><title>Policy Gradient Guidance Enables Test Time Control</title><link>http://arxiv.org/abs/2510.02148v1</link><description>We introduce Policy Gradient Guidance (PGG), a simple extension ofclassifier-free guidance from diffusion models to classical policy gradientmethods. PGG augments the policy gradient with an unconditional branch andinterpolates conditional and unconditional branches, yielding a test-timecontrol knob that modulates behavior without retraining. We provide atheoretical derivation showing that the additional normalization term vanishesunder advantage estimation, leading to a clean guided policy gradient update.Empirically, we evaluate PGG on discrete and continuous control benchmarks. Wefind that conditioning dropout-central to diffusion guidance-offers gains insimple discrete tasks and low sample regimes, but dropout destabilizescontinuous control. Training with modestly larger guidance ($\gamma&gt;1$)consistently improves stability, sample efficiency, and controllability. Ourresults show that guidance, previously confined to diffusion policies, can beadapted to standard on-policy methods, opening new directions for controllableonline reinforcement learning.</description><author>Jianing Qi, Hao Tang, Zhigang Zhu</author><pubDate>Thu, 02 Oct 2025 16:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02148v1</guid></item><item><title>When Disagreements Elicit Robustness: Investigating Self-Repair Capabilities under LLM Multi-Agent Disagreements</title><link>http://arxiv.org/abs/2502.15153v2</link><description>Recent advances in Large Language Models (LLMs) have upgraded them fromsophisticated text generators to autonomous agents capable of cooperation andtool use in multi-agent systems (MAS). However, it remains unclear howdisagreements shape collective decision-making. In this paper, we revisit therole of disagreement and argue that general, partially overlappingdisagreements prevent premature consensus and expand the explored solutionspace, while disagreements on task-critical steps can derail collaborationdepending on the topology of solution paths. We investigate two collaborativesettings with distinct path structures: collaborative reasoning (CounterFact,MQuAKE-cf), which typically follows a single evidential chain, whereascollaborative programming (HumanEval, GAIA) often adopts multiple validimplementations. Disagreements are instantiated as general heterogeneity amongagents and as task-critical counterfactual knowledge edits injected intocontext or parameters. Experiments reveal that general disagreementsconsistently improve success by encouraging complementary exploration. Bycontrast, task-critical disagreements substantially reduce success onsingle-path reasoning, yet have a limited impact on programming, where agentscan choose alternative solutions. Trace analyses show that MAS frequentlybypasses the edited facts in programming but rarely does so in reasoning,revealing an emergent self-repair capability that depends on solution-pathrather than scale alone. Our code is available athttps://github.com/wbw625/MultiAgentRobustness.</description><author>Tianjie Ju, Bowen Wang, Hao Fei, Mong-Li Lee, Wynne Hsu, Yun Li, Qianren Wang, Pengzhou Cheng, Zongru Wu, Haodong Zhao, Zhuosheng Zhang, Gongshen Liu</author><pubDate>Thu, 02 Oct 2025 15:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.15153v2</guid></item><item><title>MissionHD: Hyperdimensional Refinement of Distribution-Deficient Reasoning Graphs for Video Anomaly Detection</title><link>http://arxiv.org/abs/2508.14746v3</link><description>LLM-generated reasoning graphs, referred to as mission-specific graphs(MSGs), are increasingly used for video anomaly detection (VAD) and recognition(VAR). These MSGs are novel artifacts: they often exhibit skewed connectivityand lack large-scale datasets for pre-training, which makes existing graphstructure refinement (GSR) methods ineffective. To address this challenge, wepropose HDC-constrained Graph Structure Refinement (HDC-GSR), a paradigm thatleverages hyperdimensional computing (HDC) to optimize decodable graphrepresentations without relying on structural-distribution learning. Buildingon this paradigm, we introduce MissionHD, an HDC framework that encodes graphswith constrained graph-neural operations, aligns them directly with downstreamtask loss, and decodes refined structures. Experiments on VAD/VAR benchmarksdemonstrate that MissionHD-refined graphs consistently improve performance,establishing HDC-GSR as an effective pre-processing step for structuredreasoning in video anomaly tasks.</description><author>Sanggeon Yun, Raheeb Hassan, Ryozo Masukawa, Nathaniel D. Bastian, Mohsen Imani</author><pubDate>Thu, 02 Oct 2025 15:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.14746v3</guid></item><item><title>How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of Scientific Impact Beyond Peer Review</title><link>http://arxiv.org/abs/2510.02143v1</link><description>Peer review in academic research aims not only to ensure factual correctnessbut also to identify work of high scientific potential that can shape futureresearch directions. This task is especially critical in fast-moving fieldssuch as artificial intelligence (AI), yet it has become increasingly difficultgiven the rapid growth of submissions. In this paper, we investigate anunderexplored measure for identifying high-impact research: authors' ownrankings of their multiple submissions to the same AI conference. Grounded ingame-theoretic reasoning, we hypothesize that self-rankings are informativebecause authors possess unique understanding of their work's conceptual depthand long-term promise. To test this hypothesis, we conducted a large-scaleexperiment at a leading AI conference, where 1,342 researchers self-rankedtheir 2,592 submissions by perceived quality. Tracking outcomes over more thana year, we found that papers ranked highest by their authors received twice asmany citations as their lowest-ranked counterparts; self-rankings wereespecially effective at identifying highly cited papers (those with over 150citations). Moreover, we showed that self-rankings outperformed peer reviewscores in predicting future citation counts. Our results remained robust afteraccounting for confounders such as preprint posting time and self-citations.Together, these findings demonstrate that authors' self-rankings provide areliable and valuable complement to peer review for identifying and elevatinghigh-impact research in AI.</description><author>Buxin Su, Natalie Collina, Garrett Wen, Didong Li, Kyunghyun Cho, Jianqing Fan, Bingxin Zhao, Weijie Su</author><pubDate>Thu, 02 Oct 2025 15:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02143v1</guid></item><item><title>Catalyst GFlowNet for electrocatalyst design: A hydrogen evolution reaction case study</title><link>http://arxiv.org/abs/2510.02142v1</link><description>Efficient and inexpensive energy storage is essential for accelerating theadoption of renewable energy and ensuring a stable supply, despite fluctuationsin sources such as wind and solar. Electrocatalysts play a key role in hydrogenenergy storage (HES), allowing the energy to be stored as hydrogen. However,the development of affordable and high-performance catalysts for this processremains a significant challenge. We introduce Catalyst GFlowNet, a generativemodel that leverages machine learning-based predictors of formation andadsorption energy to design crystal surfaces that act as efficient catalysts.We demonstrate the performance of the model through a proof-of-conceptapplication to the hydrogen evolution reaction, a key reaction in HES, forwhich we successfully identified platinum as the most efficient known catalyst.In future work, we aim to extend this approach to the oxygen evolutionreaction, where current optimal catalysts are expensive metal oxides, and openthe search space to discover new materials. This generative modeling frameworkoffers a promising pathway for accelerating the search for novel and efficientcatalysts.</description><author>Lena Podina, Christina Humer, Alexandre Duval, Victor Schmidt, Ali Ramlaoui, Shahana Chatterjee, Yoshua Bengio, Alex Hernandez-Garcia, David Rolnick, Félix Therrien</author><pubDate>Thu, 02 Oct 2025 15:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02142v1</guid></item><item><title>BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic Bioinformatics</title><link>http://arxiv.org/abs/2510.02139v1</link><description>Bioinformatics tools are essential for complex computational biology tasks,yet their integration with emerging AI-agent frameworks is hindered byincompatible interfaces, heterogeneous input-output formats, and inconsistentparameter conventions. The Model Context Protocol (MCP) provides a standardizedframework for tool-AI communication, but manually converting hundreds ofexisting and rapidly growing specialized bioinformatics tools intoMCP-compliant servers is labor-intensive and unsustainable. Here, we presentBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,which automatically generates robust MCP servers from tool documentation usinglarge language models, and BioinfoMCP Benchmark, which systematically validatesthe reliability and versatility of converted tools across diverse computationaltasks. We present a platform of 38 MCP-converted bioinformatics tools,extensively validated to show that 94.7% successfully executed complexworkflows across three widely used AI-agent platforms. By removing technicalbarriers to AI automation, BioinfoMCP enables natural-language interaction withsophisticated bioinformatics analyses without requiring extensive programmingexpertise, offering a scalable path to intelligent, interoperable computationalbiology.</description><author>Florensia Widjaja, Zhangtianyi Chen, Juexiao Zhou</author><pubDate>Thu, 02 Oct 2025 15:47:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02139v1</guid></item><item><title>Automated Model Evaluation for Object Detection via Prediction Consistency and Reliability</title><link>http://arxiv.org/abs/2508.12082v2</link><description>Recent advances in computer vision have made training object detectors moreefficient and effective; however, assessing their performance in real-worldapplications still relies on costly manual annotation. To address thislimitation, we develop an automated model evaluation (AutoEval) framework forobject detection. We propose Prediction Consistency and Reliability (PCR),which leverages the multiple candidate bounding boxes that conventionaldetectors generate before non-maximum suppression (NMS). PCR estimatesdetection performance without ground-truth labels by jointly measuring 1) thespatial consistency between boxes before and after NMS, and 2) the reliabilityof the retained boxes via the confidence scores of overlapping boxes. For amore realistic and scalable evaluation, we construct a meta-dataset by applyingimage corruptions of varying severity. Experimental results demonstrate thatPCR yields more accurate performance estimates than existing AutoEval methods,and the proposed meta-dataset covers a wider range of detection performance.The code is available at https://github.com/YonseiML/autoeval-det.</description><author>Seungju Yoo, Hyuk Kwon, Joong-Won Hwang, Kibok Lee</author><pubDate>Thu, 02 Oct 2025 15:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.12082v2</guid></item><item><title>FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic Documents for Training Document Understanding Models</title><link>http://arxiv.org/abs/2510.02133v1</link><description>Developing document understanding models at enterprise scale requires large,diverse, and well-annotated datasets spanning a wide range of document types.However, collecting such data is prohibitively expensive due to privacyconstraints, legal restrictions, and the sheer volume of manual annotationneeded - costs that can scale into millions of dollars. We introduce FlexDoc, ascalable synthetic data generation framework that combines Stochastic Schemasand Parameterized Sampling to produce realistic, multilingual semi-structureddocuments with rich annotations. By probabilistically modeling layout patterns,visual structure, and content variability, FlexDoc enables the controlledgeneration of diverse document variants at scale. Experiments on KeyInformation Extraction (KIE) tasks demonstrate that FlexDoc-generated dataimproves the absolute F1 Score by up to 11% when used to augment real datasets,while reducing annotation effort by over 90% compared to traditionalhard-template methods. The solution is in active deployment, where it hasaccelerated the development of enterprise-grade document understanding modelswhile significantly reducing data acquisition and annotation costs.</description><author>Karan Dua, Hitesh Laxmichand Patel, Puneet Mittal, Ranjeet Gupta, Amit Agarwal, Praneet Pabolu, Srikant Panda, Hansa Meghwani, Graham Horwood, Fahad Shah</author><pubDate>Thu, 02 Oct 2025 15:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02133v1</guid></item><item><title>The Disparate Impacts of Speculative Decoding</title><link>http://arxiv.org/abs/2510.02128v1</link><description>The practice of speculative decoding, whereby inference is probabilisticallysupported by a smaller, cheaper, ``drafter'' model, has become a standardtechnique for systematically reducing the decoding time of large languagemodels. This paper conducts an analysis of speculative decoding through thelens of its potential disparate speed-up rates across tasks. Crucially, thepaper shows that speed-up gained from speculative decoding is not uniformlydistributed across tasks, consistently diminishing for under-fit, and oftenunderrepresented tasks. To better understand this phenomenon, we derive ananalysis to quantify this observed ``unfairness'' and draw attention to thefactors that motivate such disparate speed-ups to emerge. Further, guided bythese insights, the paper proposes a mitigation strategy designed to reducespeed-up disparities and validates the approach across several model pairs,revealing on average a 12% improvement in our fairness metric.</description><author>Jameson Sandler, Ahmet Üstün, Marco Romanelli, Sara Hooker, Ferdinando Fioretto</author><pubDate>Thu, 02 Oct 2025 15:38:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02128v1</guid></item><item><title>Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation</title><link>http://arxiv.org/abs/2509.24798v2</link><description>We present Causal-Adapter, a modular framework that adapts frozentext-to-image diffusion backbones for counterfactual image generation. Ourmethod enables causal interventions on target attributes, consistentlypropagating their effects to causal dependents without altering the coreidentity of the image. In contrast to prior approaches that rely on promptengineering without explicit causal structure, Causal-Adapter leveragesstructural causal modeling augmented with two attribute regularizationstrategies: prompt-aligned injection, which aligns causal attributes withtextual embeddings for precise semantic control, and a conditioned tokencontrastive loss to disentangle attribute factors and reduce spuriouscorrelations. Causal-Adapter achieves state-of-the-art performance on bothsynthetic and real-world datasets, with up to 91% MAE reduction on Pendulum foraccurate attribute control and 87% FID reduction on ADNI for high-fidelity MRIimage generation. These results show that our approach enables robust,generalizable counterfactual editing with faithful attribute modification andstrong identity preservation.</description><author>Lei Tong, Zhihua Liu, Chaochao Lu, Dino Oglic, Tom Diethe, Philip Teare, Sotirios A. Tsaftaris, Chen Jin</author><pubDate>Thu, 02 Oct 2025 15:36:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24798v2</guid></item><item><title>Do AI Models Perform Human-like Abstract Reasoning Across Modalities?</title><link>http://arxiv.org/abs/2510.02125v1</link><description>OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGIbenchmark, but does that mean state-of-the-art models recognize and reason withthe abstractions that the task creators intended? We investigate models'abstraction abilities on ConceptARC. We evaluate models under settings thatvary the input modality (textual vs. visual), whether the model is permitted touse external Python tools, and, for reasoning models, the amount of reasoningeffort. In addition to measuring output accuracy, we perform fine-grainedevaluation of the natural-language rules that models generate to explain theirsolutions. This dual evaluation lets us assess whether models solve tasks usingthe abstractions ConceptARC was designed to elicit, rather than relying onsurface-level patterns. Our results show that, while some models usingtext-based representations match human output accuracy, the best models' rulesare often based on surface-level ``shortcuts'' and capture intendedabstractions far less often than humans. Thus their capabilities for generalabstract reasoning may be overestimated by evaluations based on accuracy alone.In the visual modality, AI models' output accuracy drops sharply, yet ourrule-level analysis reveals that models might be underestimated, as they stillexhibit a substantial share of rules that capture intended abstractions, butare often unable to correctly apply these rules. In short, our results showthat models still lag humans in abstract reasoning, and that using accuracyalone to evaluate abstract reasoning on ARC-like tasks may overestimateabstract-reasoning capabilities in textual modalities and underestimate it invisual modalities. We believe that our evaluation framework offers a morefaithful picture of multimodal models' abstract reasoning abilities and a moreprincipled way to track progress toward human-like, abstraction-centeredintelligence.</description><author>Claas Beger, Ryan Yi, Shuhao Fu, Arseny Moskvichev, Sarah W. Tsai, Sivasankaran Rajamanickam, Melanie Mitchell</author><pubDate>Thu, 02 Oct 2025 15:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02125v1</guid></item><item><title>Beyond Outliers: A Study of Optimizers Under Quantization</title><link>http://arxiv.org/abs/2509.23500v2</link><description>As new optimizers gain traction and model quantization becomes standard forefficient deployment, a key question arises: how does the choice of optimizeraffect model performance in the presence of quantization? Despite progress inboth areas, systematic evidence on optimizer-quantization interactions remainslimited. To fill this gap, we study the impact of optimizer choice on modelrobustness under quantization, considering both post-training quantization(PTQ), and quantization-aware training (QAT). We first train full-precisionmodels, ranging from 50M to 1.5B parameters, with six optimizers, to explorethe hyperparameter landscape, and establish well-tuned baselines. We then applyPTQ to evaluate how model performance degrades when trained with differentoptimizers. We find that outlier-related metrics, such as the max-to-mean ratio(MMR) and Kurtosis, fail to predict the PTQ performance across differentoptimizers. We show analytically that this is due to the MMR capturing onlyisolated layer errors, while ignoring how quantization errors accumulate andpropagate through the network. To study the QAT degradation, we train quantizedmodels from scratch and compare them to our original-precision baselines. Wefind that optimizers performing well in the original pretraining setup may notremain optimal under QAT, and that models trained with Shampoo show the lowestaccuracy degradation. Finally, we derive scaling laws for quantization-awaretraining under different optimizers, showing that Shampoo achieves the highestparameter efficiency of all tested optimizers.</description><author>Georgios Vlassis, Saleh Ashkboos, Alexandra Volkova, Torsten Hoefler, Dan Alistarh</author><pubDate>Thu, 02 Oct 2025 15:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23500v2</guid></item><item><title>LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios</title><link>http://arxiv.org/abs/2509.09926v3</link><description>Long-tailed learning has garnered increasing attention due to its wideapplicability in real-world scenarios. Among existing approaches, Long-TailedSemi-Supervised Learning (LTSSL) has emerged as an effective solution byincorporating a large amount of unlabeled data into the imbalanced labeleddataset. However, most prior LTSSL methods are designed to train models fromscratch, which often leads to issues such as overconfidence and low-qualitypseudo-labels. To address these challenges, we extend LTSSL into the foundationmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailedsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstratethat fine-tuned foundation models can generate more reliable pseudolabels,thereby benefiting imbalanced learning. Furthermore, we explore a morepractical setting by investigating semi-supervised learning under open-worldconditions, where the unlabeled data may include out-of-distribution (OOD)samples. To handle this problem, we propose LoFT-OW (LoFT under Open-Worldscenarios) to improve the discriminative ability. Experimental results onmultiple benchmarks demonstrate that our method achieves superior performancecompared to previous approaches, even when utilizing only 1\% of the unlabeleddata compared with previous works.</description><author>Zhiyuan Huang, Jiahao Chen, Yurou Liu, Bing Su</author><pubDate>Thu, 02 Oct 2025 15:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.09926v3</guid></item><item><title>Sketching Low-Rank Plus Diagonal Matrices</title><link>http://arxiv.org/abs/2509.23587v2</link><description>Many relevant machine learning and scientific computing tasks involvehigh-dimensional linear operators accessible only via costly matrix-vectorproducts. In this context, recent advances in sketched methods have enabled theconstruction of *either* low-rank *or* diagonal approximations from fewmatrix-vector products. This provides great speedup and scalability, butapproximation errors arise due to the assumed simpler structure. This workintroduces SKETCHLORD, a method that simultaneously estimates both low-rank*and* diagonal components, targeting the broader class of Low-Rank *plus*Diagonal (LoRD) linear operators. We demonstrate theoretically and empiricallythat this joint estimation is superior also to any sequential variant(diagonal-then-low-rank or low-rank-then-diagonal). Then, we cast SKETCHLORD asa convex optimization problem, leading to a scalable algorithm. Comprehensiveexperiments on synthetic (approximate) LoRD matrices confirm SKETCHLORD'sperformance in accurately recovering these structures. This positions it as avaluable addition to the structured approximation toolkit, particularly whenhigh-fidelity approximations are desired for large-scale operators, such as thedeep learning Hessian.</description><author>Andres Fernandez, Felix Dangel, Philipp Hennig, Frank Schneider</author><pubDate>Thu, 02 Oct 2025 15:30:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23587v2</guid></item><item><title>VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI</title><link>http://arxiv.org/abs/2510.02120v1</link><description>Accounting for inter-individual variability in brain function is key toprecision medicine. Here, by considering functional inter-individualvariability as meaningful data rather than noise, we introduce VarCoNet, anenhanced self-supervised framework for robust functional connectome (FC)extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employsself-supervised contrastive learning to exploit inherent functionalinter-individual variability, serving as a brain function encoder thatgenerates FC embeddings readily applicable to downstream tasks even in theabsence of labeled data. Contrastive learning is facilitated by a novelaugmentation strategy based on segmenting rs-fMRI signals. At its core,VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-seriesprocessing, enhanced with a robust Bayesian hyperparameter optimization. OurVarCoNet framework is evaluated on two downstream tasks: (i) subjectfingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)autism spectrum disorder (ASD) classification, using rs-fMRI data from theABIDE I and ABIDE II datasets. Using different brain parcellations, ourextensive testing against state-of-the-art methods, including 13 deep learningmethods, demonstrates VarCoNet's superiority, robustness, interpretability, andgeneralizability. Overall, VarCoNet provides a versatile and robust frameworkfor FC analysis in rs-fMRI.</description><author>Charalampos Lamprou, Aamna Alshehhi, Leontios J. Hadjileontiadis, Mohamed L. Seghier</author><pubDate>Thu, 02 Oct 2025 15:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02120v1</guid></item><item><title>Non-Asymptotic Analysis of Data Augmentation for Precision Matrix Estimation</title><link>http://arxiv.org/abs/2510.02119v1</link><description>This paper addresses the problem of inverse covariance (also known asprecision matrix) estimation in high-dimensional settings. Specifically, wefocus on two classes of estimators: linear shrinkage estimators with a targetproportional to the identity matrix, and estimators derived from dataaugmentation (DA). Here, DA refers to the common practice of enriching adataset with artificial samples--typically generated via a generative model orthrough random transformations of the original data--prior to model fitting.For both classes of estimators, we derive estimators and provide concentrationbounds for their quadratic error. This allows for both method comparison andhyperparameter tuning, such as selecting the optimal proportion of artificialsamples. On the technical side, our analysis relies on tools from random matrixtheory. We introduce a novel deterministic equivalent for generalized resolventmatrices, accommodating dependent samples with specific structure. We supportour theoretical results with numerical experiments.</description><author>Lucas Morisset, Adrien Hardy, Alain Durmus</author><pubDate>Thu, 02 Oct 2025 15:28:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02119v1</guid></item><item><title>Equivariant Splitting: Self-supervised learning from incomplete data</title><link>http://arxiv.org/abs/2510.00929v2</link><description>Self-supervised learning for inverse problems allows to train areconstruction network from noise and/or incomplete data alone. These methodshave the potential of enabling learning-based solutions when obtainingground-truth references for training is expensive or even impossible. In thispaper, we propose a new self-supervised learning strategy devised for thechallenging setting where measurements are observed via a single incompleteobservation model. We introduce a new definition of equivariance in the contextof reconstruction networks, and show that the combination of self-supervisedsplitting losses and equivariant reconstruction networks results in the sameminimizer in expectation as the one of a supervised loss. Through a series ofexperiments on image inpainting, accelerated magnetic resonance imaging, andcompressive sensing, we demonstrate that the proposed loss achievesstate-of-the-art performance in settings with highly rank-deficient forwardmodels.</description><author>Victor Sechaud, Jérémy Scanvic, Quentin Barthélemy, Patrice Abry, Julián Tachella</author><pubDate>Thu, 02 Oct 2025 15:27:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00929v2</guid></item><item><title>Mafoko: Structuring and Building Open Multilingual Terminologies for South African NLP</title><link>http://arxiv.org/abs/2508.03529v2</link><description>The critical lack of structured terminological data for South Africa'sofficial languages hampers progress in multilingual NLP, despite the existenceof numerous government and academic terminology lists. These valuable assetsremain fragmented and locked in non-machine-readable formats, rendering themunusable for computational research and development. \emph{Mafoko} addressesthis challenge by systematically aggregating, cleaning, and standardising thesescattered resources into open, interoperable datasets. We introduce thefoundational \emph{Mafoko} dataset, released under the equitable,Africa-centered NOODL framework. To demonstrate its immediate utility, weintegrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.Experiments show substantial improvements in the accuracy and domain-specificconsistency of English-to-Tshivenda machine translation for large languagemodels. \emph{Mafoko} provides a scalable foundation for developing robust andequitable NLP technologies, ensuring South Africa's rich linguistic diversityis represented in the digital age.</description><author>Vukosi Marivate, Isheanesu Dzingirai, Fiskani Banda, Richard Lastrucci, Thapelo Sindane, Keabetswe Madumo, Kayode Olaleye, Abiodun Modupe, Unarine Netshifhefhe, Herkulaas Combrink, Mohlatlego Nakeng, Matome Ledwaba</author><pubDate>Thu, 02 Oct 2025 15:26:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.03529v2</guid></item><item><title>Morphlux: Transforming Torus Fabrics for Efficient Multi-tenant ML</title><link>http://arxiv.org/abs/2508.03674v2</link><description>We develop Morphlux, a server-scale programmable photonic fabric tointerconnect accelerators within servers. We show that augmentingstate-of-the-art torus-based ML data-centers with Morphlux can improve thebandwidth of tenant compute allocations by up to 66%, reduce computefragmentation by up to 70%, and minimize the blast radius of chip failures. Wedevelop a novel end-to-end hardware prototype of Morphlux to demonstrate theseperformance benefits which translate to 1.72X improvement in trainingthroughput of ML models. By rapidly programming the server-scale fabric in ourhardware testbed, Morphlux can replace a failed accelerator chip with a healthyone in 1.2 seconds.</description><author>Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Rachee Singh</author><pubDate>Thu, 02 Oct 2025 15:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.03674v2</guid></item><item><title>Interpretable Text Embeddings and Text Similarity Explanation: A Survey</title><link>http://arxiv.org/abs/2502.14862v2</link><description>Text embeddings are a fundamental component in many NLP tasks, includingclassification, regression, clustering, and semantic search. However, despitetheir ubiquitous application, challenges persist in interpreting embeddings andexplaining similarities between them. In this work, we provide a structuredoverview of methods specializing in inherently interpretable text embeddingsand text similarity explanation, an underexplored research area. Wecharacterize the main ideas, approaches, and trade-offs. We compare means ofevaluation, discuss overarching lessons learned and finally identifyopportunities and open challenges for future research.</description><author>Juri Opitz, Lucas Möller, Andrianos Michail, Sebastian Padó, Simon Clematide</author><pubDate>Thu, 02 Oct 2025 15:24:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.14862v2</guid></item><item><title>DAG DECORation: Continuous Optimization for Structure Learning under Hidden Confounding</title><link>http://arxiv.org/abs/2510.02117v1</link><description>We study structure learning for linear Gaussian SEMs in the presence oflatent confounding. Existing continuous methods excel when errors areindependent, while deconfounding-first pipelines rely on pervasive factorstructure or nonlinearity. We propose \textsc{DECOR}, a single likelihood-basedand fully differentiable estimator that jointly learns a DAG and a correlatednoise model. Our theory gives simple sufficient conditions for global parameteridentifiability: if the mixed graph is bow free and the noise covariance has auniform eigenvalue margin, then the map from $(\B,\OmegaMat)$ to theobservational covariance is injective, so both the directed structure and thenoise are uniquely determined. The estimator alternates a smooth-acyclic graphupdate with a convex noise update and can include a light bow complementaritypenalty or a post hoc reconciliation step. On synthetic benchmarks that varyconfounding density, graph density, latent rank, and dimension with $n&lt;p$,\textsc{DECOR} matches or outperforms strong baselines and is especially robustwhen confounding is non-pervasive, while remaining competitive underpervasiveness.</description><author>Samhita Pal, James O'quinn, Kaveh Aryan, Heather Pua, James P. Long, Amir Asiaee</author><pubDate>Thu, 02 Oct 2025 15:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02117v1</guid></item><item><title>Ensemble Threshold Calibration for Stable Sensitivity Control</title><link>http://arxiv.org/abs/2510.02116v1</link><description>Precise recall control is critical in large-scale spatial conflation andentity-matching tasks, where missing even a few true matches can breakdownstream analytics, while excessive manual review inflates cost. Classicalconfidence-interval cuts such as Clopper-Pearson or Wilson provide lower boundson recall, but they routinely overshoot the target by several percentage pointsand exhibit high run-to-run variance under skewed score distributions. Wepresent an end-to-end framework that achieves exact recall with sub-percentvariance over tens of millions of geometry pairs, while remaining TPU-friendly.Our pipeline starts with an equigrid bounding-box filter and compressed sparserow (CSR) candidate representation, reducing pair enumeration by two orders ofmagnitude. A deterministic xxHash bootstrap sample trains a lightweight neuralranker; its scores are propagated to all remaining pairs via a single forwardpass and used to construct a reproducible, score-decile-stratified calibrationset. Four complementary threshold estimators - Clopper-Pearson, Jeffreys,Wilson, and an exact quantile - are aggregated via inverse-variance weighting,then fused across nine independent subsamples. This ensemble reduces thresholdvariance compared to any single method. Evaluated on two real cadastraldatasets (approximately 6.31M and 67.34M pairs), our approach consistently hitsa recall target within a small error, decreases redundant verificationsrelative to other calibrations, and runs end-to-end on a single TPU v3 core.</description><author>John N. Daras</author><pubDate>Thu, 02 Oct 2025 15:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02116v1</guid></item><item><title>Hybrid Deep Learning Modeling Approach to Predict Natural Gas Consumption of Home Subscribers on Limited Data</title><link>http://arxiv.org/abs/2510.02115v1</link><description>Today, natural gas, as a clean fuel and the best alternative to crude oil,covers a significant part of global demand. Iran is one of the largestcountries with energy resources and in terms of gas is the second-largestcountry in the world. But, due to the increase in population and energyconsumption, it faces problems such as pressure drops and gas outages yearly incold seasons and therefore it is necessary to control gas consumption,especially in the residential sector, which has the largest share in Iran. Thisstudy aims to analyze and predict gas consumption for residential customers inZanjan province, Iran, using machine learning models, including LSTM, GRU, anda hybrid BiLSTM-XGBoost model. The dataset consists of gas consumption andmeteorology data collected over six years, from 2017 to 2022. The models weretrained and evaluated based on their ability to accurately predict consumptionpatterns. The results indicate that the hybrid BiLSTM-XGBoost modeloutperformed the other models in terms of accuracy, with lower Root MeanSquared Error (RMSE), Mean Absolute Percentage Error (MAPE) values, and MeanPercentage Error (MPE). Additionally, the Hybrid model demonstrated robustperformance, particularly in scenarios with limited data. The findings suggestthat machine learning approaches, particularly hybrid models, can beeffectively utilized to manage and predict gas consumption, contributing tomore efficient resource management and reducing seasonal shortages. This studyhighlights the importance of incorporating geographical and climatic factors inpredictive modeling, as these significantly influence gas usage acrossdifferent regions.</description><author>Milad Firoozeh, Nader Dashti, Mohammad Ali Hatefi</author><pubDate>Thu, 02 Oct 2025 15:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02115v1</guid></item><item><title>FRIEREN: Federated Learning with Vision-Language Regularization for Segmentation</title><link>http://arxiv.org/abs/2510.02114v1</link><description>Federeated Learning (FL) offers a privacy-preserving solution for SemanticSegmentation (SS) tasks to adapt to new domains, but faces significantchallenges from these domain shifts, particularly when client data isunlabeled. However, most existing FL methods unrealistically assume access tolabeled data on remote clients or fail to leverage the power of modern VisionFoundation Models (VFMs). Here, we propose a novel and challenging task,FFREEDG, in which a model is pretrained on a server's labeled source datasetand subsequently trained across clients using only their unlabeled data,without ever re-accessing the source. To solve FFREEDG, we propose FRIEREN, aframework that leverages the knowledge of a VFM by integrating vision andlanguage modalities. Our approach employs a Vision-Language decoder guided byCLIP-based text embeddings to improve semantic disambiguation and uses aweak-to-strong consistency learning strategy for robust local training onpseudo-labels. Our experiments on synthetic-to-real andclear-to-adverse-weather benchmarks demonstrate that our framework effectivelytackles this new task, achieving competitive performance against establisheddomain generalization and adaptation methods and setting a strong baseline forfuture research.</description><author>Ding-Ruei Shen</author><pubDate>Thu, 02 Oct 2025 15:21:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02114v1</guid></item><item><title>Interior Object Geometry via Fitted Frames</title><link>http://arxiv.org/abs/2407.14357v3</link><description>We propose a means of computing fitted frames on the boundary and in theinterior of objects and using them to provide the basis for producing geometricfeatures from them that are not only alignment-free but most importantly can bemade to correspond locally across a population of objects. We describe arepresentation targeted for anatomic objects which is designed to enable thisstrong locational correspondence within object populations and thus to providepowerful object statistics. It accomplishes this by understanding an object asthe diffeomorphic deformation of the closure of the interior of an ellipsoidand by using a skeletal representation fitted throughout the deformation toproduce a model of the target object, where the object is provided initially inthe form of a boundary mesh. Via classification performance on hippocampi shapebetween individuals with a disorder vs. others, we compare our method to twostate-of-theart methods for producing object representations that are intendedto capture geometric correspondence across a population of objects and to yieldgeometric features useful for statistics, and we show notably improvedclassification performance by this new representation, which we call theevolutionary s-rep. The geometric features that are derived from each of therepresentations, especially via fitted frames, are discussed.</description><author>Stephen M. Pizer, Zhiyuan Liu, Junjie Zhao, Nicholas Tapp-Hughes, James Damon, Miaomiao Zhang, JS Marron, Mohsen Taheri, Jared Vicory</author><pubDate>Thu, 02 Oct 2025 15:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14357v3</guid></item><item><title>L4P: Towards Unified Low-Level 4D Vision Perception</title><link>http://arxiv.org/abs/2502.13078v3</link><description>The spatio-temporal relationship between the pixels of a video carriescritical information for low-level 4D perception tasks. A single model thatreasons about it should be able to solve several such tasks well. Yet, moststate-of-the-art methods rely on architectures specialized for the task athand. We present L4P, a feedforward, general-purpose architecture that solveslow-level 4D perception tasks in a unified framework. L4P leverages apre-trained ViT-based video encoder and combines it with per-task heads thatare lightweight and therefore do not require extensive training. Despite itsgeneral and feedforward formulation, our method is competitive with existingspecialized methods on both dense tasks, such as depth or optical flowestimation, and sparse tasks, such as 2D/3D tracking. Moreover, it solves alltasks at once in a time comparable to that of single-task methods.</description><author>Abhishek Badki, Hang Su, Bowen Wen, Orazio Gallo</author><pubDate>Thu, 02 Oct 2025 15:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.13078v3</guid></item><item><title>Scaling Laws for Optimal Data Mixtures</title><link>http://arxiv.org/abs/2507.09404v2</link><description>Large foundation models are typically trained on data from multiple domains,with the data mixture--the proportion of each domain used--playing a criticalrole in model performance. The standard approach to selecting this mixturerelies on trial and error, which becomes impractical for large-scalepretraining. We propose a systematic method to determine the optimal datamixture for any target domain using scaling laws. Our approach accuratelypredicts the loss of a model of size $N$ trained with $D$ tokens and a specificdomain weight vector $h$. We validate the universality of these scaling laws bydemonstrating their predictive power in three distinct and large-scalesettings: large language model (LLM), native multimodal model (NMM), and largevision models (LVM) pretraining. We further show that these scaling laws canextrapolate to new data mixtures and across scales: their parameters can beaccurately estimated using a few small-scale training runs, and used toestimate the performance at larger scales and unseen domain weights. Thescaling laws allow to derive the optimal domain weights for any target domainunder a given training budget ($N$,$D$), providing a principled alternative tocostly trial-and-error methods.</description><author>Mustafa Shukor, Louis Bethune, Dan Busbridge, David Grangier, Enrico Fini, Alaaeldin El-Nouby, Pierre Ablin</author><pubDate>Thu, 02 Oct 2025 15:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.09404v2</guid></item><item><title>SoundReactor: Frame-level Online Video-to-Audio Generation</title><link>http://arxiv.org/abs/2510.02110v1</link><description>Prevailing Video-to-Audio (V2A) generation models operate offline, assumingan entire video sequence or chunks of frames are available beforehand. Thiscritically limits their use in interactive applications such as live contentcreation and emerging generative world models. To address this gap, weintroduce the novel task of frame-level online V2A generation, where a modelautoregressively generates audio from video without access to future videoframes. Furthermore, we propose SoundReactor, which, to the best of ourknowledge, is the first simple yet effective framework explicitly tailored forthis task. Our design enforces end-to-end causality and targets low per-framelatency with audio-visual synchronization. Our model's backbone is adecoder-only causal transformer over continuous audio latents. For visionconditioning, it leverages grid (patch) features extracted from the smallestvariant of the DINOv2 vision encoder, which are aggregated into a single tokenper frame to maintain end-to-end causality and efficiency. The model is trainedthrough a diffusion pre-training followed by consistency fine-tuning toaccelerate the diffusion head decoding. On a benchmark of diverse gameplayvideos from AAA titles, our model successfully generates semantically andtemporally aligned, high-quality full-band stereo audio, validated by bothobjective and human evaluations. Furthermore, our model achieves low per-framewaveform-level latency (26.3ms with the head NFE=1, 31.5ms with NFE=4) on30FPS, 480p videos using a single H100. Demo samples are available athttps://koichi-saito-sony.github.io/soundreactor/.</description><author>Koichi Saito, Julian Tanke, Christian Simon, Masato Ishii, Kazuki Shimada, Zachary Novack, Zhi Zhong, Akio Hayakawa, Takashi Shibuya, Yuki Mitsufuji</author><pubDate>Thu, 02 Oct 2025 15:18:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02110v1</guid></item><item><title>On Predictability of Reinforcement Learning Dynamics for Large Language Models</title><link>http://arxiv.org/abs/2510.00553v2</link><description>Recent advances in reasoning capabilities of large language models (LLMs) arelargely driven by reinforcement learning (RL), yet the underlying parameterdynamics during RL training remain poorly understood. This work identifies twofundamental properties of RL-induced parameter updates in LLMs: (1) Rank-1Dominance, where the top singular subspace of the parameter update matrixnearly fully determines reasoning improvements, recovering over 99\% ofperformance gains; and (2) Rank-1 Linear Dynamics, where this dominant subspaceevolves linearly throughout training, enabling accurate prediction from earlycheckpoints. Extensive experiments across 8 LLMs and 7 algorithms validate thegeneralizability of these properties. More importantly, based on thesefindings, we propose AlphaRL, a plug-in acceleration framework thatextrapolates the final parameter update using a short early training window,achieving up to 2.5 speedup while retaining \textgreater 96\% of reasoningperformance without extra modules or hyperparameter tuning. This positions ourfinding as a versatile and practical tool for large-scale RL, opening a pathtoward principled, interpretable, and efficient training paradigm for LLMs.</description><author>Yuchen Cai, Ding Cao, Xin Xu, Zijun Yao, Yuqing Huang, Zhenyu Tan, Benyi Zhang, Guiquan Liu, Junfeng Fang</author><pubDate>Thu, 02 Oct 2025 15:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00553v2</guid></item><item><title>SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world Breast MRI Classification</title><link>http://arxiv.org/abs/2510.02109v1</link><description>Deep neural networks (DNNs) have demonstrated remarkable success in medicalimaging, yet their real-world deployment remains challenging due to spuriouscorrelations, where models can learn non-clinical features instead ofmeaningful medical patterns. Existing medical imaging datasets are not designedto systematically study this issue, largely due to restrictive licensing andlimited supplementary patient data. To address this gap, we introduceSpurBreast, a curated breast MRI dataset that intentionally incorporatesspurious correlations to evaluate their impact on model performance. Analyzingover 100 features involving patient, device, and imaging protocol, we identifytwo dominant spurious signals: magnetic field strength (a global featureinfluencing the entire image) and image orientation (a local feature affectingspatial alignment). Through controlled dataset splits, we demonstrate that DNNscan exploit these non-clinical signals, achieving high validation accuracywhile failing to generalize to unbiased test data. Alongside these two datasetscontaining spurious correlations, we also provide benchmark datasets withoutspurious correlations, allowing researchers to systematically investigateclinically relevant and irrelevant features, uncertainty estimation,adversarial robustness, and generalization strategies. Models and datasets areavailable at https://github.com/utkuozbulak/spurbreast.</description><author>Jong Bum Won, Wesley De Neve, Joris Vankerschaver, Utku Ozbulak</author><pubDate>Thu, 02 Oct 2025 15:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02109v1</guid></item><item><title>Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network</title><link>http://arxiv.org/abs/2510.02108v1</link><description>Although symbol-level precoding (SLP) based on constructive interference (CI)exploitation offers performance gains, its high complexity remains abottleneck. This paper addresses this challenge with an end-to-end deeplearning (DL) framework with low inference complexity that leverages thestructure of the optimal SLP solution in the closed-form and its inherenttensor equivariance (TE), where TE denotes that a permutation of the inputinduces the corresponding permutation of the output. Building upon thecomputationally efficient model-based formulations, as well as their knownclosed-form solutions, we analyze their relationship with linear precoding (LP)and investigate the corresponding optimality condition. We then construct amapping from the problem formulation to the solution and prove its TE, based onwhich the designed networks reveal a specific parameter-sharing pattern thatdelivers low computational complexity and strong generalization. Leveragingthese, we propose the backbone of the framework with an attention-based TEmodule, achieving linear computational complexity. Furthermore, we demonstratethat such a framework is also applicable to imperfect CSI scenarios, where wedesign a TE-based network to map the CSI, statistics, and symbols to auxiliaryvariables. Simulation results show that the proposed framework capturessubstantial performance gains of optimal SLP, while achieving an approximately80-times speedup over conventional methods and maintaining stronggeneralization across user numbers and symbol block lengths.</description><author>Jinshuo Zhang, Yafei Wang, Xinping Yi, Wenjin Wang, Shi Jin, Symeon Chatzinotas, Björn Ottersten</author><pubDate>Thu, 02 Oct 2025 15:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02108v1</guid></item><item><title>Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract Works (LRMoo F1 to schema.org)</title><link>http://arxiv.org/abs/2508.00827v4</link><description>Building upon a formal, event-centric model for the diachronic evolution oflegal norms grounded in the IFLA Library Reference Model (LRMoo), this paperaddresses the essential first step of publishing this model's foundationalentity-the abstract legal Work (F1)-on the Semantic Web. We propose a detailed,property-by-property mapping of the LRMoo F1 Work to the widely adoptedschema.org/Legislation vocabulary. Using Brazilian federal legislation from theNormas.leg.br portal as a practical case study, we demonstrate how to createinteroperable, machine-readable descriptions via JSON-LD, focusing on stableURN identifiers, core metadata, and norm relationships. This structured mappingestablishes a stable, URI-addressable anchor for each legal norm, creating averifiable "ground truth". It provides the essential, interoperable foundationupon which subsequent layers of the model, such as temporal versions(Expressions) and internal components, can be built. By bridging formalontology with web-native standards, this work paves the way for buildingdeterministic and reliable Legal Knowledge Graphs (LKGs), overcoming thelimitations of purely probabilistic models.</description><author>Hudson de Martim</author><pubDate>Thu, 02 Oct 2025 15:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.00827v4</guid></item><item><title>Post-hoc Probabilistic Vision-Language Models</title><link>http://arxiv.org/abs/2412.06014v4</link><description>Vision-language models (VLMs), such as CLIP and SigLIP, have found remarkablesuccess in classification, retrieval, and generative tasks. For this, VLMsdeterministically map images and text descriptions to a joint latent space inwhich their similarity is assessed using the cosine similarity. However, adeterministic mapping of inputs fails to capture uncertainties over conceptsarising from domain shifts when used in downstream tasks. In this work, wepropose post-hoc uncertainty estimation in VLMs that does not requireadditional training. Our method leverages a Bayesian posterior approximationover the last layers in VLMs and analytically quantifies uncertainties overcosine similarities. We demonstrate its effectiveness for uncertaintyquantification and support set selection in active learning. Compared tobaselines, we obtain improved and well-calibrated predictive uncertainties,interpretable uncertainty estimates, and sample-efficient active learning. Ourresults show promise for safety-critical applications of large-scale models.</description><author>Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp</author><pubDate>Thu, 02 Oct 2025 15:13:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06014v4</guid></item><item><title>PENEX: AdaBoost-Inspired Neural Network Regularization</title><link>http://arxiv.org/abs/2510.02107v1</link><description>AdaBoost sequentially fits so-called weak learners to minimize an exponentialloss, which penalizes mislabeled data points more severely than other lossfunctions like cross-entropy. Paradoxically, AdaBoost generalizes well inpractice as the number of weak learners grows. In the present work, weintroduce Penalized Exponential Loss (PENEX), a new formulation of themulti-class exponential loss that is theoretically grounded and, in contrast tothe existing formulation, amenable to optimization via first-order methods. Wedemonstrate both empirically and theoretically that PENEX implicitly maximizesmargins of data points. Also, we show that gradient increments on PENEXimplicitly parameterize weak learners in the boosting framework. Acrosscomputer vision and language tasks, we show that PENEX exhibits a regularizingeffect often better than established methods with similar computational cost.Our results highlight PENEX's potential as an AdaBoost-inspired alternative foreffective training and fine-tuning of deep neural networks.</description><author>Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach</author><pubDate>Thu, 02 Oct 2025 15:13:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02107v1</guid></item><item><title>When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based Tracking in Surgical Videos</title><link>http://arxiv.org/abs/2510.02100v1</link><description>Video object segmentation (VOS) models such as SAM2 offer promising zero-shottracking capabilities for surgical videos using minimal user input. Among theavailable input types, point-based tracking offers an efficient and low-costalternative, yet its reliability and failure cases in complex surgicalenvironments are not well understood. In this work, we systematically analyzethe failure modes of point-based tracking in laparoscopic cholecystectomyvideos. Focusing on three surgical targets, the gallbladder, grasper, andL-hook electrocautery, we compare the performance of point-based tracking withsegmentation mask initialization. Our results show that point-based tracking iscompetitive for surgical tools but consistently underperforms for anatomicaltargets, where tissue similarity and ambiguous boundaries lead to failure.Through qualitative analysis, we reveal key factors influencing trackingoutcomes and provide several actionable recommendations for selecting andplacing tracking points to improve performance in surgical video analysis.</description><author>Woowon Jang, Jiwon Im, Juseung Choi, Niki Rashidian, Wesley De Neve, Utku Ozbulak</author><pubDate>Thu, 02 Oct 2025 15:06:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02100v1</guid></item><item><title>Neural Network Parameter-optimization of Gaussian pmDAGs</title><link>http://arxiv.org/abs/2309.14073v4</link><description>Finding the parameters of a latent variable causal model is central to causalinference and causal identification. In this article, we show that existinggraphical structures that are used in causal inference are not stable undermarginalization of Gaussian Bayesian networks, and present a graphicalstructure that faithfully represent margins of Gaussian Bayesian networks. Wepresent the first duality between parameter optimization of a latent variablemodel and training a feed-forward neural network in the parameter space of theassumed family of distributions. Based on this observation, we develop analgorithm for parameter optimization of these graphical structures based on agiven observational distribution. Then, we provide conditions for causal effectidentifiability in the Gaussian setting. We propose an meta-algorithm thatchecks whether a causal effect is identifiable or not. Moreover, we lay agrounding for generalizing the duality between a neural network and a causalmodel from the Gaussian to other distributions.</description><author>Mehrzad Saremi</author><pubDate>Thu, 02 Oct 2025 15:06:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14073v4</guid></item><item><title>Multiplier-free In-Memory Vector-Matrix Multiplication Using Distributed Arithmetic</title><link>http://arxiv.org/abs/2510.02099v1</link><description>Vector-Matrix Multiplication (VMM) is the fundamental and frequently requiredcomputation in inference of Neural Networks (NN). Due to the large datamovement required during inference, VMM can benefit greatly from in-memorycomputing. However, ADC/DACs required for in-memory VMM consume significantpower and area. `Distributed Arithmetic (DA)', a technique in computerarchitecture prevalent in 1980s was used to achieve inner product or dotproduct of two vectors without using a hard-wired multiplier when one of thevectors is a constant. In this work, we extend the DA technique to multiply aninput vector with a constant matrix. By storing the sum of the weights inmemory, DA achieves VMM using shift-and-add circuits in the periphery of ReRAMmemory. We verify functional and also estimate non-functional properties(latency, energy, area) by performing transistor-level simulations. Usingenergy-efficient sensing and fine grained pipelining, our approach achieves 4.5x less latency and 12 x less energy than VMM performed in memory conventionallyby bit slicing. Furthermore, DA completely eliminated the need for power-hungryADCs which are the main source of area and energy consumption in the currentVMM implementations in memory.</description><author>Felix Zeller, John Reuben, Dietmar Fey</author><pubDate>Thu, 02 Oct 2025 15:06:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02099v1</guid></item><item><title>Mapping Historic Urban Footprints in France: Balancing Quality, Scalability and AI Techniques</title><link>http://arxiv.org/abs/2510.02097v1</link><description>Quantitative analysis of historical urban sprawl in France before the 1970sis hindered by the lack of nationwide digital urban footprint data. This studybridges this gap by developing a scalable deep learning pipeline to extracturban areas from the Scan Histo historical map series (1925-1950), whichproduces the first open-access, national-scale urban footprint dataset for thispivotal period. Our key innovation is a dual-pass U-Net approach designed tohandle the high radiometric and stylistic complexity of historical maps. Thefirst pass, trained on an initial dataset, generates a preliminary map thatidentifies areas of confusion, such as text and roads, to guide targeted dataaugmentation. The second pass uses a refined dataset and the binarized outputof the first model to minimize radiometric noise, which significantly reducesfalse positives. Deployed on a high-performance computing cluster, our methodprocesses 941 high-resolution tiles covering the entirety of metropolitanFrance. The final mosaic achieves an overall accuracy of 73%, effectivelycapturing diverse urban patterns while overcoming common artifacts like labelsand contour lines. We openly release the code, training datasets, and theresulting nationwide urban raster to support future research in long-termurbanization dynamics.</description><author>Walid Rabehi, Marion Le Texier, Rémi Lemoy</author><pubDate>Thu, 02 Oct 2025 15:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02097v1</guid></item><item><title>Learning Model Representations Using Publicly Available Model Hubs</title><link>http://arxiv.org/abs/2510.02096v1</link><description>The weights of neural networks have emerged as a novel data modality, givingrise to the field of weight space learning. A central challenge in this area isthat learning meaningful representations of weights typically requires large,carefully constructed collections of trained models, typically referred to asmodel zoos. These model zoos are often trained ad-hoc, requiring largecomputational resources, constraining the learned weight space representationsin scale and flexibility. In this work, we drop this requirement by training aweight space learning backbone on arbitrary models downloaded from large,unstructured model repositories such as Hugging Face. Unlike curated modelzoos, these repositories contain highly heterogeneous models: they vary inarchitecture and dataset, and are largely undocumented. To address themethodological challenges posed by such heterogeneity, we propose a new weightspace backbone designed to handle unstructured model populations. Wedemonstrate that weight space representations trained on models from HuggingFace achieve strong performance, often outperforming backbones trained onlaboratory-generated model zoos. Finally, we show that the diversity of themodel weights in our training set allows our weight space model to generalizeto unseen data modalities. By demonstrating that high-quality weight spacerepresentations can be learned in the wild, we show that curated model zoos arenot indispensable, thereby overcoming a strong limitation currently faced bythe weight space learning community.</description><author>Damian Falk, Konstantin Schürholt, Konstantinos Tzevelekakis, Léo Meynent, Damian Borth</author><pubDate>Thu, 02 Oct 2025 15:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02096v1</guid></item><item><title>Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning</title><link>http://arxiv.org/abs/2510.02091v1</link><description>Recent studies suggest that the deeper layers of Large Language Models (LLMs)contribute little to representation learning and can often be removed withoutsignificant performance loss. However, such claims are typically drawn fromnarrow evaluations and may overlook important aspects of model behavior. Inthis work, we present a systematic study of depth utilization across diversedimensions, including evaluation protocols, task categories, and modelarchitectures. Our analysis confirms that very deep layers are generally lesseffective than earlier ones, but their contributions vary substantially withthe evaluation setting. Under likelihood-based metrics without generation,pruning most layers preserves performance, with only the initial few beingcritical. By contrast, generation-based evaluation uncovers indispensable rolesfor middle and deeper layers in enabling reasoning and maintaining long-rangecoherence. We further find that knowledge and retrieval are concentrated inshallow components, whereas reasoning accuracy relies heavily on deeper layers-- yet can be reshaped through distillation. These results highlight that depthusage in LLMs is highly heterogeneous and context-dependent, underscoring theneed for task-, metric-, and model-aware perspectives in both interpreting andcompressing large models.</description><author>Xinyuan Song, Keyu Wang, PengXiang Li, Lu Yin, Shiwei Liu</author><pubDate>Thu, 02 Oct 2025 14:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02091v1</guid></item><item><title>Break the ID-Language Barrier: An Adaption Framework for LLM-based Sequential Recommendation</title><link>http://arxiv.org/abs/2411.18262v3</link><description>The recent breakthrough of large language models (LLMs) in natural languageprocessing has sparked exploration in recommendation systems, however, theirlimited domain-specific knowledge remains a critical bottleneck. Specifically,LLMs lack key pieces of information crucial for sequential recommendations,such as user behavior patterns. To address this critical gap, we proposeIDLE-Adapter, a novel framework that integrates pre-trained ID embeddings, richin domain-specific knowledge, into LLMs to improve recommendation accuracy.IDLE-Adapter acts as a bridge, transforming sparse user-item interaction datainto dense, LLM-compatible representations through a Pre-trained ID SequentialModel, Dimensionality Alignment, Layer-wise Embedding Refinement, andLayer-wise Distribution Alignment. Furthermore, IDLE-Adapter demonstratesremarkable flexibility by seamlessly integrating ID embeddings from diverseID-based sequential models and LLM architectures. Extensive experiments acrossvarious datasets demonstrate the superiority of IDLE-Adapter, achieving over10\% and 20\% improvements in HitRate@5 and NDCG@5 metrics, respectively,compared to state-of-the-art methods.</description><author>Xiaohan Yu, Li Zhang, Xin Zhao, Yue Wang</author><pubDate>Thu, 02 Oct 2025 14:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.18262v3</guid></item><item><title>VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation</title><link>http://arxiv.org/abs/2510.02086v1</link><description>Accurate detection and segmentation of brain tumors from magnetic resonanceimaging (MRI) are essential for diagnosis, treatment planning, and clinicalmonitoring. While convolutional architectures such as U-Net have long been thebackbone of medical image segmentation, their limited capacity to capturelong-range dependencies constrains performance on complex tumor structures.Recent advances in diffusion models have demonstrated strong potential forgenerating high-fidelity medical images and refining segmentation boundaries. In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain TumorDetection and Segmentation framework, a transformer-driven diffusion frameworkfor brain tumor detection and segmentation. By embedding a vision transformerat the core of the diffusion process, the model leverages global contextualreasoning together with iterative denoising to enhance both volumetric accuracyand boundary precision. The transformer backbone enables more effectivemodeling of spatial relationships across entire MRI volumes, while diffusionrefinement mitigates voxel-level errors and recovers fine-grained tumordetails. This hybrid design provides a pathway toward improved robustness andscalability in neuro-oncology, moving beyond conventional U-Net baselines.Experimental validation on MRI brain tumor datasets demonstrates consistentgains in Dice similarity and Hausdorff distance, underscoring the potential oftransformer-guided diffusion models to advance the state of the art in tumorsegmentation.</description><author>Arman Behnam</author><pubDate>Thu, 02 Oct 2025 14:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02086v1</guid></item><item><title>KAIROS: Unified Training for Universal Non-Autoregressive Time Series Forecasting</title><link>http://arxiv.org/abs/2510.02084v1</link><description>In the World Wide Web, reliable time series forecasts provide theforward-looking signals that drive resource planning, cache placement, andanomaly response, enabling platforms to operate efficiently as user behaviorand content distributions evolve. Compared with other domains, time seriesforecasting for Web applications requires much faster responsiveness to supportreal-time decision making. We present KAIROS, a non-autoregressive time seriesforecasting framework that directly models segment-level multi-peakdistributions. Unlike autoregressive approaches, KAIROS avoids erroraccumulation and achieves just-in-time inference, while improving over existingnon-autoregressive models that collapse to over-smoothed predictions. Trainedon the large-scale corpus, KAIROS demonstrates strong zero-shot generalizationon six widely used benchmarks, delivering forecasting performance comparable tostate-of-the-art foundation models with similar scale, at a fraction of theirinference cost. Beyond empirical results, KAIROS highlights the importance ofnon-autoregressive design as a scalable paradigm for foundation models in timeseries.</description><author>Kuiye Ding, Fanda Fan, Zheya Wang, Hongxiao Li, Yifan Wang, Lei Wang, Chunjie Luo, Jianfeng Zhan</author><pubDate>Thu, 02 Oct 2025 14:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02084v1</guid></item><item><title>Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions</title><link>http://arxiv.org/abs/2510.02081v1</link><description>Flow Matching (FM) algorithm achieves remarkable results in generative tasksespecially in robotic manipulation. Building upon the foundations of diffusionmodels, the simulation-free paradigm of FM enables simple and efficienttraining, but inherently introduces a train-inference gap. Specifically, wecannot assess the model's output during the training phase. In contrast, othergenerative models including Variational Autoencoder (VAE), Normalizing Flow andGenerative Adversarial Networks (GANs) directly optimize on the reconstructionloss. Such a gap is particularly evident in scenarios that demand highprecision, such as robotic manipulation. Moreover, we show that FM'sover-pursuit of straight predefined paths may introduce some serious problemssuch as stiffness into the system. These motivate us to fine-tune FM viaMaximum Likelihood Estimation of reconstructions - an approach made feasible byFM's underlying smooth ODE formulation, in contrast to the stochasticdifferential equations (SDEs) used in diffusion models. This paper firsttheoretically analyzes the relation between training loss and inference errorin FM. Then we propose a method of fine-tuning FM via Maximum LikelihoodEstimation of reconstructions, which includes both straightforward fine-tuningand residual-based fine-tuning approaches. Furthermore, through specificallydesigned architectures, the residual-based fine-tuning can incorporate thecontraction property into the model, which is crucial for the model'srobustness and interpretability. Experimental results in image generation androbotic manipulation verify that our method reliably improves the inferenceperformance of FM.</description><author>Zhaoyi Li, Jingtao Ding, Yong Li, Shihua Li</author><pubDate>Thu, 02 Oct 2025 14:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02081v1</guid></item><item><title>Momentum-SAM: Sharpness Aware Minimization without Computational Overhead</title><link>http://arxiv.org/abs/2401.12033v3</link><description>The recently proposed optimization algorithm for deep neural networksSharpness Aware Minimization (SAM) suggests perturbing parameters beforegradient calculation by a gradient ascent step to guide the optimization intoparameter space regions of flat loss. While significant generalizationimprovements and thus reduction of overfitting could be demonstrated, thecomputational costs are doubled due to the additionally needed gradientcalculation, making SAM unfeasible in case of limited computationallycapacities. Motivated by Nesterov Accelerated Gradient (NAG) we proposeMomentum-SAM (MSAM), which perturbs parameters in the direction of theaccumulated momentum vector to achieve low sharpness without significantcomputational overhead or memory demands over SGD or Adam. We evaluate MSAM indetail and reveal insights on separable mechanisms of NAG, SAM and MSAMregarding training optimization and generalization. Code is available athttps://github.com/MarlonBecker/MSAM.</description><author>Marlon Becker, Frederick Altrock, Benjamin Risse</author><pubDate>Thu, 02 Oct 2025 14:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12033v3</guid></item><item><title>TrimTokenator: Towards Adaptive Visual Token Pruning for Large Multimodal Models</title><link>http://arxiv.org/abs/2509.00320v2</link><description>Large Multimodal Models (LMMs) have achieved significant success acrossvarious tasks. These models usually encode visual inputs into dense tokensequences, which are then concatenated with textual tokens and jointlyprocessed by a language model. However, the increased token count substantiallyraises computational and memory costs during inference. Token pruning hasemerged as a promising approach to address this issue. Existing token pruningmethods often rely on costly calibration or suboptimal importance metrics,leading to redundant retained tokens. In this paper, we analyze the redundancydifferences between visual and textual tokens and propose pruning exclusivelyon visual tokens. Based on this, we propose a visual token pruning strategythat explicitly preserves both cross-modal alignment and intra-modalinformational diversity. We introduce a mutual information-based token pruningstrategy that removes visual tokens semantically misaligned with textualtokens, effectively preserving the alignment between the visual and textualmodalities. To further improve the representational quality of the retainedtokens, we additionally prune redundant visual tokens by maximizing theexpected pairwise distances in the embedding space, which is solved efficientlywith a greedy algorithm. Extensive experiments demonstrate that our methodmaintains strong performance while reducing tokens by 88.9% on models such asLLaVA-1.5-7B and LLaVA-NEXT-7B, resulting in a 56.7% improvement in inferencespeed.</description><author>Hao Zhang, Mengsi Lyu, Chenrui He, Yulong Ao, Yonghua Lin</author><pubDate>Thu, 02 Oct 2025 14:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.00320v2</guid></item><item><title>DiCache: Let Diffusion Model Determine Its Own Cache</title><link>http://arxiv.org/abs/2508.17356v2</link><description>Recent years have witnessed the rapid development of acceleration techniquesfor diffusion models, especially caching-based acceleration methods. Thesestudies seek to answer two fundamental questions: "When to cache" and "How touse cache", typically relying on predefined empirical laws or dataset-levelpriors to determine caching timings and adopting handcrafted rules formulti-step cache utilization. However, given the highly dynamic nature of thediffusion process, they often exhibit limited generalizability and fail to copewith diverse samples. In this paper, a strong sample-specific correlation isrevealed between the variation patterns of the shallow-layer featuredifferences in the diffusion model and those of deep-layer features. Moreover,we have observed that the features from different model layers form similartrajectories. Based on these observations, we present DiCache, a noveltraining-free adaptive caching strategy for accelerating diffusion models atruntime, answering both when and how to cache within a unified framework.Specifically, DiCache is composed of two principal components: (1) Online ProbeProfiling Scheme leverages a shallow-layer online probe to obtain an on-the-flyindicator for the caching error in real time, enabling the model to dynamicallycustomize the caching schedule for each sample. (2) Dynamic Cache TrajectoryAlignment adaptively approximates the deep-layer feature output from multi-stephistorical caches based on the shallow-layer feature trajectory, facilitatinghigher visual quality. Extensive experiments validate DiCache's capability inachieving higher efficiency and improved fidelity over state-of-the-artapproaches on various leading diffusion models including WAN 2.1, HunyuanVideoand Flux.</description><author>Jiazi Bu, Pengyang Ling, Yujie Zhou, Yibin Wang, Yuhang Zang, Dahua Lin, Jiaqi Wang</author><pubDate>Thu, 02 Oct 2025 14:42:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.17356v2</guid></item><item><title>UltraUPConvNet: A UPerNet- and ConvNeXt-Based Multi-Task Network for Ultrasound Tissue Segmentation and Disease Prediction</title><link>http://arxiv.org/abs/2509.11108v2</link><description>Ultrasound imaging is widely used in clinical practice due to itscost-effectiveness, mobility, and safety. However, current AI research oftentreats disease prediction and tissue segmentation as two separate tasks andtheir model requires substantial computational overhead. In such a situation,we introduce UltraUPConvNet, a computationally efficient universal frameworkdesigned for both ultrasound image classification and segmentation. Trained ona large-scale dataset containing more than 9,700 annotations across sevendifferent anatomical regions, our model achieves state-of-the-art performanceon certain datasets with lower computational overhead. Our model weights andcodes are available at https://github.com/yyxl123/UltraUPConvNet</description><author>Zhi Chen, Le Zhang</author><pubDate>Thu, 02 Oct 2025 14:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.11108v2</guid></item><item><title>Differentially Private Federated Learning: A Systematic Review</title><link>http://arxiv.org/abs/2405.08299v4</link><description>In recent years, privacy and security concerns in machine learning havepromoted trusted federated learning to the forefront of research. Differentialprivacy has emerged as the de facto standard for privacy protection infederated learning due to its rigorous mathematical foundation and provableguarantee. Despite extensive research on algorithms that incorporatedifferential privacy within federated learning, there remains an evidentdeficiency in systematic reviews that categorize and synthesize these studies.Our work presents a systematic overview of the differentially private federatedlearning. Existing taxonomies have not adequately considered objects and levelof privacy protection provided by various differential privacy models infederated learning. To rectify this gap, we propose a new taxonomy ofdifferentially private federated learning based on definition and guarantee ofvarious differential privacy models and federated scenarios. Our classificationallows for a clear delineation of the protected objects across variousdifferential privacy models and their respective neighborhood levels withinfederated learning environments. Furthermore, we explore the applications ofdifferential privacy in federated learning scenarios. Our work provide valuableinsights into privacy-preserving federated learning and suggest practicaldirections for future research.</description><author>Jie Fu, Yuan Hong, Xinpeng Ling, Leixia Wang, Xun Ran, Zhiyu Sun, Wendy Hui Wang, Zhili Chen, Yang Cao</author><pubDate>Thu, 02 Oct 2025 14:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08299v4</guid></item><item><title>Inferring Optical Tissue Properties from Photoplethysmography using Hybrid Amortized Inference</title><link>http://arxiv.org/abs/2510.02073v1</link><description>Smart wearables enable continuous tracking of established biomarkers such asheart rate, heart rate variability, and blood oxygen saturation viaphotoplethysmography (PPG). Beyond these metrics, PPG waveforms contain richerphysiological information, as recent deep learning (DL) studies demonstrate.However, DL models often rely on features with unclear physiological meaning,creating a tension between predictive power, clinical interpretability, andsensor design. We address this gap by introducing PPGen, a biophysical modelthat relates PPG signals to interpretable physiological and optical parameters.Building on PPGen, we propose hybrid amortized inference (HAI), enabling fast,robust, and scalable estimation of relevant physiological parameters from PPGsignals while correcting for model misspecification. In extensive in-silicoexperiments, we show that HAI can accurately infer physiological parametersunder diverse noise and sensor conditions. Our results illustrate a path towardPPG models that retain the fidelity needed for DL-based features whilesupporting clinical interpretation and informed hardware design.</description><author>Jens Behrmann, Maria R. Cervera, Antoine Wehenkel, Andrew C. Miller, Albert Cerussi, Pranay Jain, Vivek Venugopal, Shijie Yan, Guillermo Sapiro, Luca Pegolotti, Jörn-Henrik Jacobsen</author><pubDate>Thu, 02 Oct 2025 14:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02073v1</guid></item><item><title>Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects</title><link>http://arxiv.org/abs/2510.02069v1</link><description>Accurate reconstruction and relighting of glossy objects remain alongstanding challenge, as object shape, material properties, and illuminationare inherently difficult to disentangle. Existing neural rendering approachesoften rely on simplified BRDF models or parameterizations that couple diffuseand specular components, which restricts faithful material recovery and limitsrelighting fidelity. We propose a relightable framework that integrates amicrofacet BRDF with the specular-glossiness parameterization into 2D GaussianSplatting with deferred shading. This formulation enables more physicallyconsistent material decomposition, while diffusion-based priors for surfacenormals and diffuse color guide early-stage optimization and mitigateambiguity. A coarse-to-fine optimization of the environment map acceleratesconvergence and preserves high-dynamic-range specular reflections. Extensiveexperiments on complex, glossy scenes demonstrate that our method achieveshigh-quality geometry and material reconstruction, delivering substantiallymore realistic and consistent relighting under novel illumination compared toexisting Gaussian splatting methods.</description><author>Georgios Kouros, Minye Wu, Tinne Tuytelaars</author><pubDate>Thu, 02 Oct 2025 14:34:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02069v1</guid></item><item><title>Adaptive Kernel Selection for Stein Variational Gradient Descent</title><link>http://arxiv.org/abs/2510.02067v1</link><description>A central challenge in Bayesian inference is efficiently approximatingposterior distributions. Stein Variational Gradient Descent (SVGD) is a popularvariational inference method which transports a set of particles to approximatea target distribution. The SVGD dynamics are governed by a reproducing kernelHilbert space (RKHS) and are highly sensitive to the choice of the kernelfunction, which directly influences both convergence and approximation quality.The commonly used median heuristic offers a simple approach for setting kernelbandwidths but lacks flexibility and often performs poorly, particularly inhigh-dimensional settings. In this work, we propose an alternative strategy foradaptively choosing kernel parameters over an abstract family of kernels.Recent convergence analyses based on the kernelized Stein discrepancy (KSD)suggest that optimizing the kernel parameters by maximizing the KSD can improveperformance. Building on this insight, we introduce Adaptive SVGD (Ad-SVGD), amethod that alternates between updating the particles via SVGD and adaptivelytuning kernel bandwidths through gradient ascent on the KSD. We provide asimplified theoretical analysis that extends existing results on minimizing theKSD for fixed kernels to our adaptive setting, showing convergence propertiesfor the maximal KSD over our kernel class. Our empirical results furthersupport this intuition: Ad-SVGD consistently outperforms standard heuristics ina variety of tasks.</description><author>Moritz Melcher, Simon Weissmann, Ashia C. Wilson, Jakob Zech</author><pubDate>Thu, 02 Oct 2025 14:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02067v1</guid></item><item><title>Chain-of-Thought Reasoning in Streaming Full-Duplex End-to-End Spoken Dialogue Systems</title><link>http://arxiv.org/abs/2510.02066v1</link><description>Most end-to-end (E2E) spoken dialogue systems (SDS) rely on voice activitydetection (VAD) for turn-taking, but VAD fails to distinguish between pausesand turn completions. Duplex SDS models address this by predicting outputcontinuously, including silence tokens, thus removing the need for explicitVAD. However, they often have complex dual-channel architecture and lag behindcascaded models in semantic reasoning. To overcome these challenges, we proposeSCoT: a Streaming Chain-of-Thought (CoT) framework for Duplex SDS, alternatingbetween processing fixed-duration user input and generating responses in ablockwise manner. Using frame-level alignments, we create intermediatetargets-aligned user transcripts and system responses for each block.Experiments show that our approach produces more coherent and interpretableresponses than existing duplex methods while supporting lower-latency andoverlapping interactions compared to turn-by-turn systems.</description><author>Siddhant Arora, Jinchuan Tian, Hayato Futami, Jiatong Shi, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe</author><pubDate>Thu, 02 Oct 2025 14:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02066v1</guid></item><item><title>ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection</title><link>http://arxiv.org/abs/2510.02060v1</link><description>In tabular anomaly detection (AD), textual semantics often carry criticalsignals, as the definition of an anomaly is closely tied to domain-specificcontext. However, existing benchmarks provide only raw data points withoutsemantic context, overlooking rich textual metadata such as featuredescriptions and domain knowledge that experts rely on in practice. Thislimitation restricts research flexibility and prevents models from fullyleveraging domain knowledge for detection. ReTabAD addresses this gap byrestoring textual semantics to enable context-aware tabular AD research. Weprovide (1) 20 carefully curated tabular datasets enriched with structuredtextual metadata, together with implementations of state-of-the-art ADalgorithms including classical, deep learning, and LLM-based approaches, and(2) a zero-shot LLM framework that leverages semantic context withouttask-specific training, establishing a strong baseline for future research.Furthermore, this work provides insights into the role and utility of textualmetadata in AD through experiments and analysis. Results show that semanticcontext improves detection performance and enhances interpretability bysupporting domain-aware reasoning. These findings establish ReTabAD as abenchmark for systematic exploration of context-aware AD.</description><author>Sanghyu Yoon, Dongmin Kim, Suhee Yoon, Ye Seul Sim, Seungdong Yoa, Hye-Seung Cho, Soonyoung Lee, Hankook Lee, Woohyung Lim</author><pubDate>Thu, 02 Oct 2025 14:28:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02060v1</guid></item><item><title>Adaptive Heterogeneous Mixtures of Normalising Flows for Robust Variational Inference</title><link>http://arxiv.org/abs/2510.02056v1</link><description>Normalising-flow variational inference (VI) can approximate complexposteriors, yet single-flow models often behave inconsistently acrossqualitatively different distributions. We propose Adaptive Mixture FlowVariational Inference (AMF-VI), a heterogeneous mixture of complementary flows(MAF, RealNVP, RBIG) trained in two stages: (i) sequential expert training ofindividual flows, and (ii) adaptive global weight estimation vialikelihood-driven updates, without per-sample gating or architectural changes.Evaluated on six canonical posterior families of banana, X-shape, two-moons,rings, a bimodal, and a five-mode mixture, AMF-VI achieves consistently lowernegative log-likelihood than each single-flow baseline and delivers stablegains in transport metrics (Wasserstein-2) and maximum mean discrepancy (MDD),indicating improved robustness across shapes and modalities. The procedure isefficient and architecture-agnostic, incurring minimal overhead relative tostandard flow training, and demonstrates that adaptive mixtures of diverseflows provide a reliable route to robust VI across diverse posterior familieswhilst preserving each expert's inductive bias.</description><author>Benjamin Wiriyapong, Oktay Karakuş, Kirill Sidorov</author><pubDate>Thu, 02 Oct 2025 14:25:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02056v1</guid></item><item><title>Multidata Causal Discovery for Statistical Hurricane Intensity Forecasting</title><link>http://arxiv.org/abs/2510.02050v1</link><description>Improving statistical forecasts of Atlantic hurricane intensity is limited bycomplex nonlinear interactions and difficulty in identifying relevantpredictors. Conventional methods prioritize correlation or fit, oftenoverlooking confounding variables and limiting generalizability to unseentropical storms. To address this, we leverage a multidata causal discoveryframework with a replicated dataset based on Statistical Hurricane IntensityPrediction Scheme (SHIPS) using ERA5 meteorological reanalysis. We conductmultiple experiments to identify and select predictors causally linked tohurricane intensity changes. We train multiple linear regression models tocompare causal feature selection with no selection, correlation, and randomforest feature importance across five forecast lead times from 1 to 5 days (24to 120 hours). Causal feature selection consistently outperforms on unseen testcases, especially for lead times shorter than 3 days. The causal featuresprimarily include vertical shear, mid-tropospheric potential vorticity andsurface moisture conditions, which are physically significant yet oftenunderutilized in hurricane intensity predictions. Further, we build an extendedpredictor set (SHIPS+) by adding selected features to the standard SHIPSpredictors. SHIPS+ yields increased short-term predictive skill at lead timesof 24, 48, and 72 hours. Adding nonlinearity using multilayer perceptronfurther extends skill to longer lead times, despite our framework being purelyregional and not requiring global forecast data. Operational SHIPS testsconfirm that three of the six added causally discovered predictors improveforecasts, with the largest gains at longer lead times. Our results demonstratethat causal discovery improves hurricane intensity prediction and pave the waytoward more empirical forecasts.</description><author>Saranya Ganesh S., Frederick Iat-Hin Tam, Milton S. Gomez, Marie McGraw, Mark DeMaria, Kate Musgrave, Jakob Runge, Tom Beucler</author><pubDate>Thu, 02 Oct 2025 14:23:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02050v1</guid></item><item><title>Mathematical Modeling and Convergence Analysis of Deep Neural Networks with Dense Layer Connectivities in Deep Learning</title><link>http://arxiv.org/abs/2510.02049v1</link><description>In deep learning, dense layer connectivity has become a key design principlein deep neural networks (DNNs), enabling efficient information flow and strongperformance across a range of applications. In this work, we model denselyconnected DNNs mathematically and analyze their learning problems in thedeep-layer limit. For a broad applicability, we present our analysis in aframework setting of DNNs with densely connected layers and general non-localfeature transformations (with local feature transformations as special cases)within layers, which is called dense non-local (DNL) framework and includesstandard DenseNets and variants as special examples. In this formulation, thedensely connected networks are modeled as nonlinear integral equations, incontrast to the ordinary differential equation viewpoint commonly adopted inprior works. We study the associated training problems from an optimal controlperspective and prove convergence results from the network learning problem toits continuous-time counterpart. In particular, we show the convergence ofoptimal values and the subsequence convergence of minimizers, using a piecewiselinear extension and $\Gamma$-convergence analysis. Our results provide amathematical foundation for understanding densely connected DNNs and furthersuggest that such architectures can offer stability of training deep models.</description><author>Jinshu Huang, Haibin Su, Xue-Cheng Tai, Chunlin Wu</author><pubDate>Thu, 02 Oct 2025 14:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02049v1</guid></item><item><title>Variational Secret Common Randomness Extraction</title><link>http://arxiv.org/abs/2510.02048v1</link><description>This paper studies the problem of extracting common randomness (CR) or secretkeys from correlated random sources observed by two legitimate parties, Aliceand Bob, through public discussion in the presence of an eavesdropper, Eve. Wepropose a practical two-stage CR extraction framework. In the first stage, thevariational probabilistic quantization (VPQ) step is introduced, where Aliceand Bob employ probabilistic neural network (NN) encoders to map theirobservations into discrete, nearly uniform random variables (RVs) with highagreement probability while minimizing information leakage to Eve. This isrealized through a variational learning objective combined with adversarialtraining. In the second stage, a secure sketch using code-offset constructionreconciles the encoder outputs into identical secret keys, whose secrecy isguaranteed by the VPQ objective. As a representative application, we studyphysical layer key (PLK) generation. Beyond the traditional methods, which relyon the channel reciprocity principle and require two-way channel probing, thussuffering from large protocol overhead and being unsuitable in high mobilityscenarios, we propose a sensing-based PLK generation method for integratedsensing and communications (ISAC) systems, where paired range-angle (RA) mapsmeasured at Alice and Bob serve as correlated sources. The idea is verifiedthrough both end-to-end simulations and real-world software-defined radio (SDR)measurements, including scenarios where Eve has partial knowledge about Bob'sposition. The results demonstrate the feasibility and convincing performance ofboth the proposed CR extraction framework and sensing-based PLK generationmethod.</description><author>Xinyang Li, Vlad C. Andrei, Peter J. Gu, Yiqi Chen, Ullrich J. Mönich, Holger Boche</author><pubDate>Thu, 02 Oct 2025 14:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02048v1</guid></item><item><title>Stream RAG: Instant and Accurate Spoken Dialogue Systems with Streaming Tool Usage</title><link>http://arxiv.org/abs/2510.02044v1</link><description>End-to-end speech-in speech-out dialogue systems are emerging as a powerfulalternative to traditional ASR-LLM-TTS pipelines, generating more natural,expressive responses with significantly lower latency. However, these systemsremain prone to hallucinations due to limited factual grounding. Whiletext-based dialogue systems address this challenge by integrating tools such asweb search and knowledge graph APIs, we introduce the first approach to extendtool use directly into speech-in speech-out systems. A key challenge is thattool integration substantially increases response latency, disruptingconversational flow. To mitigate this, we propose Streaming Retrieval-AugmentedGeneration (Streaming RAG), a novel framework that reduces user-perceivedlatency by predicting tool queries in parallel with user speech, even beforethe user finishes speaking. Specifically, we develop a post-training pipelinethat teaches the model when to issue tool calls during ongoing speech and howto generate spoken summaries that fuse audio queries with retrieved textresults, thereby improving both accuracy and responsiveness. To evaluate ourapproach, we construct AudioCRAG, a benchmark created by converting queriesfrom the publicly available CRAG dataset into speech form. Experimental resultsdemonstrate that our streaming RAG approach increases QA accuracy by up to 200%relative (from 11.1% to 34.2% absolute) and further enhances user experience byreducing tool use latency by 20%. Importantly, our streaming RAG approach ismodality-agnostic and can be applied equally to typed input, paving the way formore agentic, real-time AI assistants.</description><author>Siddhant Arora, Haidar Khan, Kai Sun, Xin Luna Dong, Sajal Choudhary, Seungwhan Moon, Xinyuan Zhang, Adithya Sagar, Surya Teja Appini, Kaushik Patnaik, Sanat Sharma, Shinji Watanabe, Anuj Kumar, Ahmed Aly, Yue Liu, Florian Metze, Zhaojiang Lin</author><pubDate>Thu, 02 Oct 2025 14:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02044v1</guid></item><item><title>Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers</title><link>http://arxiv.org/abs/2510.02043v1</link><description>Pose estimation refers to tracking a human's full body posture, includingtheir head, torso, arms, and legs. The problem is challenging in practicalsettings where the number of body sensors are limited. Past work has shownpromising results using conditional diffusion models, where the pose predictionis conditioned on both &lt;location, rotation&gt; measurements from the sensors.Unfortunately, nearly all these approaches generalize poorly across users,primarly because location measurements are highly influenced by the body sizeof the user. In this paper, we formulate pose estimation as an inverse problemand design an algorithm capable of zero-shot generalization. Our idea utilizesa pre-trained diffusion model and conditions it on rotational measurementsalone; the priors from this model are then guided by a likelihood term, derivedfrom the measured locations. Thus, given any user, our proposed InPose methodgeneratively estimates the highly likely sequence of poses that best explainsthe sparse on-body measurements.</description><author>Sahil Bhandary Karnoor, Romit Roy Choudhury</author><pubDate>Thu, 02 Oct 2025 14:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02043v1</guid></item><item><title>Large Language Models Inference Engines based on Spiking Neural Networks</title><link>http://arxiv.org/abs/2510.00133v2</link><description>Foundational models based on the transformer architecture are currently thestate-of-the-art in general language modeling, as well as in scientific areassuch as material science and climate. However, training and deploying thesemodels is computationally challenging as the time and space complexity has aquadratic relation to the input sequence length. Several efforts exploringefficient computational paradigms and model architectures to address theselimitations have been made. In this work, we explore spiking neural networks(SNNs) to design transformer models. A challenge in training large-scale SNNs,using existing surrogate learning methods is inefficient and time-consuming. Onthe other hand, techniques to convert existing transformer-based models totheir SNN equivalent are not scalable, as achieving optimal performance comesat the cost of a large number of spike time-steps, i.e. increased latency. Toaddress this, we propose NeurTransformer, a methodology for designingtransformer-based SNN for inference using a supervised fine-tuning approachwith existing conversion methods. The proposed methodology works by: (1)replacing the self-attention mechanism with a spike-based self-attention (SSA),(2) converting the feed-forward block of the trained transformer model to itsequivalent SNN, and (3) fine-tuning the SSA block using SNN-based surrogatelearning algorithms. We benchmark the proposed methodology and demonstrate itsaccuracy and scalability using three variants of the GPT-2 model of increasingmodel size. We observe that the converted GPT-2 small models demonstrate a5-12% loss in cosine similarity and a 9.7% reduction in perplexity. Finally, wedemonstrate the energy efficiency of the SSA block compared to the ASA blockand show between 64.71% and 85.28% reductions in estimated energy consumptionwhen implementing the self-attention mechanism on a digital hardware.</description><author>Adarsha Balaji, Sandeep Madireddy</author><pubDate>Thu, 02 Oct 2025 14:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00133v2</guid></item><item><title>Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness</title><link>http://arxiv.org/abs/2506.05735v3</link><description>Machine unlearning techniques aim to mitigate unintended memorization inlarge language models (LLMs). However, existing approaches predominantly focuson the explicit removal of isolated facts, often overlooking latent inferentialdependencies and the non-deterministic nature of knowledge within LLMs.Consequently, facts presumed forgotten may persist implicitly throughcorrelated information. To address these challenges, we propose a knowledgeunlearning evaluation framework that more accurately captures the implicitstructure of real-world knowledge by representing relevant factual contexts asknowledge graphs with associated confidence scores. We further develop aninference-based evaluation protocol leveraging powerful LLMs as judges; thesejudges reason over the extracted knowledge subgraph to determine unlearningsuccess. Our LLM judges utilize carefully designed prompts and are calibratedagainst human evaluations to ensure their trustworthiness and stability.Extensive experiments on our newly constructed benchmark demonstrate that ourframework provides a more realistic and rigorous assessment of unlearningperformance. Moreover, our findings reveal that current evaluation strategiestend to overestimate unlearning effectiveness. Our code is publicly availableat https://github.com/Graph-COM/Knowledge_Unlearning.git.</description><author>Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chien, Kamalika Chaudhuri, Olgica Milenkovic, Pan Li</author><pubDate>Thu, 02 Oct 2025 14:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05735v3</guid></item><item><title>Push the Limit of Multi-modal Emotion Recognition by Prompting LLMs with Receptive-Field-Aware Attention Weighting</title><link>http://arxiv.org/abs/2411.17674v2</link><description>Understanding the emotions in a dialogue usually requires external knowledgeto accurately understand the contents. As the LLMs become more and morepowerful, we do not want to settle on the limited ability of the pre-trainedlanguage model. However, the LLMs either can only process text modality or aretoo expensive to process the multimedia information. We aim to utilize both thepower of LLMs and the supplementary features from the multimedia modalities. Inthis paper, we present a framework, Lantern, that can improve the performanceof a certain vanilla model by prompting large language models withreceptive-field-aware attention weighting. This framework trained a multi-taskvanilla model to produce probabilities of emotion classes and dimension scores.These predictions are fed into the LLMs as references to adjust the predictedprobabilities of each emotion class with its external knowledge and contextualunderstanding. We slice the dialogue into different receptive fields, and eachsample is included in exactly t receptive fields. Finally, the predictions ofLLMs are merged with a receptive-field-aware attention-driven weighting module.In the experiments, vanilla models CORECT and SDT are deployed in Lantern withGPT-4 or Llama-3.1-405B. The experiments in IEMOCAP with 4-way and 6-waysettings demonstrated that the Lantern can significantly improve theperformance of current vanilla models by up to 1.23% and 1.80%.</description><author>Han Zhang, Yu Lu, Liyun Zhang, Dian Ding, Dinghua Zhao, Yi-Chao Chen, Ye Wu, Guangtao Xue</author><pubDate>Thu, 02 Oct 2025 14:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.17674v2</guid></item><item><title>Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models</title><link>http://arxiv.org/abs/2509.12960v2</link><description>Parameter-efficient methods like LoRA have revolutionised large languagemodel (LLM) fine-tuning. ReLoRA extends this idea to pretraining by repeatedlymerging and reinitialising low-rank adapters, increasing cumulative rank whilekeeping updates cheap. This aligns well with observations that high-capacitymodels learn through locally low-rank trajectories that expand over time. Bycontrast, recent work suggests that small language models (SLMs) exhibit rankdeficiencies and under-utilise their available dimensionality. This raises anatural question: can ReLoRA's rank-expanding update rule \textit{steer} SLMstoward healthier learning dynamics, mitigating rank bottlenecks in acapacity-constrained regime? We argue SLMs are an ideal testbed: they trainquickly, enable controlled ablations, and make rank phenomena more measurable.We present the first systematic study of ReLoRA in SLMs (11M-66M parameters),evaluating both performance and learning dynamics. Across loss, Palomaperplexity, and BLiMP, we find that ReLoRA underperforms full-rank training,with gaps widening at larger scales. Analysis of proportional effective rankand condition numbers shows that ReLoRA amplifies existing rank deficienciesand induces ill-conditioned updates early in training. Our results suggest thatwhile ReLoRA's merge-and-restart strategy can expand ranks in larger models, itdoes not straightforwardly translate to capacity-limited SLMs, motivatingadaptive-rank or hybrid-rank approaches for low-compute pretraining.</description><author>Yuval Weiss, David Demitri Africa, Paula Buttery, Richard Diehl Martinez</author><pubDate>Thu, 02 Oct 2025 14:09:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.12960v2</guid></item><item><title>A Multicentric Dataset for Training and Benchmarking Breast Cancer Segmentation in H&amp;E Slides</title><link>http://arxiv.org/abs/2510.02037v1</link><description>Automated semantic segmentation of whole-slide images (WSIs) stained withhematoxylin and eosin (H&amp;E) is essential for large-scale artificialintelligence-based biomarker analysis in breast cancer. However, existingpublic datasets for breast cancer segmentation lack the morphological diversityneeded to support model generalizability and robust biomarker validation acrossheterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogysEgmentation (BEETLE), a dataset for multiclass semantic segmentation ofH&amp;E-stained breast cancer WSIs. It consists of 587 biopsies and resections fromthree collaborating clinical centers and two public datasets, digitized usingseven scanners, and covers all molecular subtypes and histological grades.Using diverse annotation strategies, we collected annotations across fourclasses - invasive epithelium, non-invasive epithelium, necrosis, and other -with particular focus on morphologies underrepresented in existing datasets,such as ductal carcinoma in situ and dispersed lobular tumor cells. Thedataset's diversity and relevance to the rapidly growing field of automatedbiomarker quantification in breast cancer ensure its high potential for reuse.Finally, we provide a well-curated, multicentric external evaluation set toenable standardized benchmarking of breast cancer segmentation models.</description><author>Carlijn Lems, Leslie Tessier, John-Melle Bokhorst, Mart van Rijthoven, Witali Aswolinskiy, Matteo Pozzi, Natalie Klubickova, Suzanne Dintzis, Michela Campora, Maschenka Balkenhol, Peter Bult, Joey Spronck, Thomas Detone, Mattia Barbareschi, Enrico Munari, Giuseppe Bogina, Jelle Wesseling, Esther H. Lips, Francesco Ciompi, Frédérique Meeuwsen, Jeroen van der Laak</author><pubDate>Thu, 02 Oct 2025 14:09:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02037v1</guid></item><item><title>The Current State of AI Bias Bounties: An Overview of Existing Programmes and Research</title><link>http://arxiv.org/abs/2510.02036v1</link><description>Current bias evaluation methods rarely engage with communities impacted by AIsystems. Inspired by bug bounties, bias bounties have been proposed as areward-based method that involves communities in AI bias detection by askingusers of AI systems to report biases they encounter when interacting with suchsystems. In the absence of a state-of-the-art review, this survey aimed toidentify and analyse existing AI bias bounty programmes and to present academicliterature on bias bounties. Google, Google Scholar, PhilPapers, and IEEEXplore were searched, and five bias bounty programmes, as well as five researchpublications, were identified. All bias bounties were organised by U.S.-basedorganisations as time-limited contests, with public participation in fourprogrammes and prize pools ranging from 7,000 to 24,000 USD. The five researchpublications included a report on the application of bug bounties toalgorithmic harms, an article addressing Twitter's bias bounty, a proposal forbias bounties as an institutional mechanism to increase AI scrutiny, a workshopdiscussing bias bounties from queer perspectives, and an algorithmic frameworkfor bias bounties. We argue that reducing the technical requirements to enterbounty programmes is important to include those without coding experience.Given the limited adoption of bias bounties, future efforts should explore thetransferability of the best practices from bug bounties and examine how suchprogrammes can be designed to be sensitive to underrepresented groups whilelowering adoption barriers for organisations.</description><author>Sergej Kucenko, Nathaniel Dennler, Fengxiang He</author><pubDate>Thu, 02 Oct 2025 14:09:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02036v1</guid></item><item><title>QSpec: Speculative Decoding with Complementary Quantization Schemes</title><link>http://arxiv.org/abs/2410.11305v3</link><description>Quantization is widely adopted to accelerate inference and reduce memoryconsumption in large language models (LLMs). While activation-weight jointquantization enables efficient low-precision decoding, it suffers fromsubstantial performance degradation on multi-step reasoning tasks. We proposeQSpec, a novel quantization paradigm that decouples efficiency from quality byintegrating two complementary schemes via speculative decoding: low-precisionjoint quantization for fast drafting and high-precision weight-onlyquantization for accurate verification. QSpec reuses both weights and KV cacheacross stages, enabling near-zero-cost switching without retraining orauxiliary models. Compared to high-precision baselines, QSpec achieves up to1.64x speedup without quality degradation, and outperforms state-of-the-artspeculative decoding methods by up to 1.55x in batched settings. Furthermore,QSpec supports plug-and-play deployment and generalizes well across modelscales, quantization methods, and workloads. These properties make QSpec apractical and scalable solution for high-fidelity quantized LLM serving undermemory-constrained scenarios. Our code is available athttps://github.com/hku-netexplo-lab/QSpec.</description><author>Juntao Zhao, Wenhao Lu, Sheng Wang, Lingpeng Kong, Chuan Wu</author><pubDate>Thu, 02 Oct 2025 14:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11305v3</guid></item><item><title>GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing</title><link>http://arxiv.org/abs/2510.02034v1</link><description>We introduce GaussianMorphing, a novel framework for semantic-aware 3D shapeand texture morphing from multi-view images. Previous approaches usually relyon point clouds or require pre-defined homeomorphic mappings for untextureddata. Our method overcomes these limitations by leveraging mesh-guided 3DGaussian Splatting (3DGS) for high-fidelity geometry and appearance modeling.The core of our framework is a unified deformation strategy that anchors3DGaussians to reconstructed mesh patches, ensuring geometrically consistenttransformations while preserving texture fidelity through topology-awareconstraints. In parallel, our framework establishes unsupervised semanticcorrespondence by using the mesh topology as a geometric prior and maintainsstructural integrity via physically plausible point trajectories. Thisintegrated approach preserves both local detail and global semantic coherencethroughout the morphing process with out requiring labeled data. On ourproposed TexMorph benchmark, GaussianMorphing substantially outperforms prior2D/3D methods, reducing color consistency error ($\Delta E$) by 22.2% and EI by26.2%. Project page: https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/</description><author>Mengtian Li, Yunshu Bai, Yimin Chu, Yijun Shen, Zhongmei Li, Weifeng Ge, Zhifeng Xie, Chaofeng Chen</author><pubDate>Thu, 02 Oct 2025 14:07:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02034v1</guid></item><item><title>Flexible Feature Distillation for Large Language Models</title><link>http://arxiv.org/abs/2507.10155v2</link><description>Knowledge distillation (KD) has become a cornerstone for compressing largelanguage models (LLMs). However, existing LLM-KD methods have primarily focusedon logit-based approaches, which achieve good performance but overlook the richinternal representations of LLMs. Feature-level KD could leverage thisstructure to provide complementary benefits, yet it remains underexploredbecause current feature-KD approaches typically assume identicalteacher-student hidden sizes, a restrictive and unrealistic assumption. Acommon workaround is to train a linear projector to align their feature spaces;however, this introduces additional parameters, distorts teacher embeddings,and often degrades downstream performance, especially in generative tasks. Wepropose Flex-KD, a parameter-free framework for task-driven featuredistillation for LLMs. Instead of projecting the entire teacher representation,Flex-KD uses gradient-based scores to identify the most task-relevantdimensions of the teacher's hidden states and distills only this subspace intothe student. This ensures that the student's limited capacity is allocated toinformative components, while avoiding projector-induced distortion and extraparameters. Flex-KD integrates seamlessly with existing KD pipelines andsupports differing teacher-student hidden sizes. Extensive experiments acrossboth classification and generative tasks, i.e., instruction-following andsummarization, show that Flex-KD consistently boosts student performance,achieving up to a 3.75 percent performance gain over the linear projectionbaseline.</description><author>Khouloud Saadi, Di Wang</author><pubDate>Thu, 02 Oct 2025 14:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.10155v2</guid></item><item><title>CrediBench: Building Web-Scale Network Datasets for Information Integrity</title><link>http://arxiv.org/abs/2509.23340v3</link><description>Online misinformation poses an escalating threat, amplified by the Internet'sopen nature and increasingly capable LLMs that generate persuasive yetdeceptive content. Existing misinformation detection methods typically focus oneither textual content or network structure in isolation, failing to leveragethe rich, dynamic interplay between website content and hyperlink relationshipsthat characterizes real-world misinformation ecosystems. We introduceCrediBench: a large-scale data processing pipeline for constructing temporalweb graphs that jointly model textual content and hyperlink structure formisinformation detection. Unlike prior work, our approach captures the dynamicevolution of general misinformation domains, including changes in both contentand inter-site references over time. Our processed one-month snapshot extractedfrom the Common Crawl archive in December 2024 contains 45 million nodes and 1billion edges, representing the largest web graph dataset made publiclyavailable for misinformation research to date. From our experiments on thisgraph snapshot, we demonstrate the strength of both structural and webpagecontent signals for learning credibility scores, which measure sourcereliability. The pipeline and experimentation code are all available here, andthe dataset is in this folder.</description><author>Emma Kondrup, Sebastian Sabry, Hussein Abdallah, Zachary Yang, James Zhou, Kellin Pelrine, Jean-François Godbout, Michael M. Bronstein, Reihaneh Rabbany, Shenyang Huang</author><pubDate>Thu, 02 Oct 2025 14:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.23340v3</guid></item><item><title>kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring</title><link>http://arxiv.org/abs/2510.02030v1</link><description>A comprehensive understanding of animal behavior ecology depends on scalableapproaches to quantify and interpret complex, multidimensional behavioralpatterns. Traditional field observations are often limited in scope,time-consuming, and labor-intensive, hindering the assessment of behavioralresponses across landscapes. To address this, we present kabr-tools (KenyanAnimal Behavior Recognition Tools), an open-source package for automatedmulti-species behavioral monitoring. This framework integrates drone-basedvideo with machine learning systems to extract behavioral, social, and spatialmetrics from wildlife footage. Our pipeline leverages object detection,tracking, and behavioral classification systems to generate key metrics,including time budgets, behavioral transitions, social interactions, habitatassociations, and group composition dynamics. Compared to ground-based methods,drone-based observations significantly improved behavioral granularity,reducing visibility loss by 15% and capturing more transitions with higheraccuracy and continuity. We validate kabr-tools through three case studies,analyzing 969 behavioral sequences, surpassing the capacity of traditionalmethods for data capture and annotation. We found that, like Plains zebras,vigilance in Grevy's zebras decreases with herd size, but, unlike Plainszebras, habitat has a negligible impact. Plains and Grevy's zebras exhibitstrong behavioral inertia, with rare transitions to alert behaviors andobserved spatial segregation between Grevy's zebras, Plains zebras, andgiraffes in mixed-species herds. By enabling automated behavioral monitoring atscale, kabr-tools offers a powerful tool for ecosystem-wide studies, advancingconservation, biodiversity research, and ecological monitoring.</description><author>Jenna Kline, Maksim Kholiavchenko, Samuel Stevens, Nina van Tiel, Alison Zhong, Namrata Banerji, Alec Sheets, Sowbaranika Balasubramaniam, Isla Duporge, Matthew Thompson, Elizabeth Campolongo, Jackson Miliko, Neil Rosser, Tanya Berger-Wolf, Charles V. Stewart, Daniel I. Rubenstein</author><pubDate>Thu, 02 Oct 2025 14:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.02030v1</guid></item></channel></rss>