<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 12 Nov 2025 12:07:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics</title><link>https://arxiv.org/pdf/2511.08544v1</link><description>Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&amp;D. We present a comprehensive theory of JEPAs and instantiate it in {\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\href{git@github.com:rbalestr-lab/lejepa.git}{GitHub repo}).</description><author>Randall Balestriero, Yann LeCun</author><pubDate>Wed, 12 Nov 2025 02:04:02 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.08544v1</guid></item><item><title>DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry</title><link>https://arxiv.org/pdf/2510.22340v2</link><description>Solid geometry problem solving demands spatial mathematical reasoning that integrates spatial intelligence and symbolic reasoning. However, most existing multimodal mathematical reasoning benchmarks focus primarily on 2D plane geometry, rely on static datasets prone to data contamination and memorization, and evaluate models solely by final answers, overlooking the reasoning process. To address these limitations, we introduce DynaSolidGeo, the first dynamic benchmark for evaluating genuine spatial reasoning in Vision-Language Models (VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo contains 503 expert-curated seed questions that can, in principle, dynamically generate an unbounded number of diverse multimodal text-visual instances. Beyond answer accuracy, we incorporate process evaluation based on expert-annotated reasoning chains to measure logical validity and causal coherence. Experiments across representative open-source and closed-source VLMs reveal large performance gaps, severe degradation in dynamic settings, and poor performance on tasks requiring high-level spatial intelligence, such as mental rotation and visualization. The code and dataset are available at \href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.</description><author>Changti Wu, Shijie Lian, Zihao Liu, Lei Zhang, Laurence Tianruo Yang, Kai Chen</author><pubDate>Wed, 12 Nov 2025 01:54:21 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2510.22340v2</guid></item><item><title>On the Convergence and Stability of Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning, and Online Decision Transformers</title><link>https://arxiv.org/pdf/2502.05672v2</link><description>This article provides a rigorous analysis of convergence and stability of Episodic Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning and Online Decision Transformers. These algorithms performed competitively across various benchmarks, from games to robotic tasks, but their theoretical understanding is limited to specific environmental conditions. This work initiates a theoretical foundation for algorithms that build on the broad paradigm of approaching reinforcement learning through supervised learning or sequence modeling. At the core of this investigation lies the analysis of conditions on the underlying environment, under which the algorithms can identify optimal solutions. We also assess whether emerging solutions remain stable in situations where the environment is subject to tiny levels of noise. Specifically, we study the continuity and asymptotic convergence of command-conditioned policies, values and the goal-reaching objective depending on the transition kernel of the underlying Markov Decision Process. We demonstrate that near-optimal behavior is achieved if the transition kernel is located in a sufficiently small neighborhood of a deterministic kernel. The mentioned quantities are continuous (with respect to a specific topology) at deterministic kernels, both asymptotically and after a finite number of learning cycles. The developed methods allow us to present the first explicit estimates on the convergence and stability of policies and values in terms of the underlying transition kernels. On the theoretical side we introduce a number of new concepts to reinforcement learning, like working in segment spaces, studying continuity in quotient topologies and the application of the fixed-point theory of dynamical systems. The theoretical study is accompanied by a detailed investigation of example environments and numerical experiments.</description><author>Miroslav Štrupl, Oleg Szehr, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar Srivastava, Jürgen Schmidhuber</author><pubDate>Wed, 12 Nov 2025 01:52:32 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2502.05672v2</guid></item><item><title>ViPRA: Video Prediction for Robot Actions</title><link>https://arxiv.org/pdf/2511.07732v1</link><description>Can we turn a video prediction model into a robot policy? Videos, including those of humans or teleoperated robots, capture rich physical interactions. However, most of them lack labeled actions, which limits their use in robot learning. We present Video Prediction for Robot Actions (ViPRA), a simple pretraining-finetuning framework that learns continuous robot control from these actionless videos. Instead of directly predicting actions, we train a video-language model to predict both future visual observations and motion-centric latent actions, which serve as intermediate representations of scene dynamics. We train these latent actions using perceptual losses and optical flow consistency to ensure they reflect physically grounded behavior. For downstream control, we introduce a chunked flow matching decoder that maps latent actions to robot-specific continuous action sequences, using only 100 to 200 teleoperated demonstrations. This approach avoids expensive action annotation, supports generalization across embodiments, and enables smooth, high-frequency continuous control upto 22 Hz via chunked action decoding. Unlike prior latent action works that treat pretraining as autoregressive policy learning, explicitly models both what changes and how. Our method outperforms strong baselines, with a 16% gain on the SIMPLER benchmark and a 13% improvement across real world manipulation tasks. We will release models and code at https://vipra-project.github.io</description><author>Sandeep Routray, Hengkai Pan, Unnat Jain, Shikhar Bahl, Deepak Pathak</author><pubDate>Wed, 12 Nov 2025 01:13:32 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.07732v1</guid></item><item><title>Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors</title><link>https://arxiv.org/pdf/2505.11770v2</link><description>Interpretability research now offers a variety of techniques for identifying abstract internal mechanisms in neural networks. Can such techniques be used to predict how models will behave on out-of-distribution examples? In this work, we provide a positive answer to this question. Through a diverse set of language modeling tasks--including symbol manipulation, knowledge retrieval, and instruction following--we show that the most robust features for correctness prediction are those that play a distinctive causal role in the model's behavior. Specifically, we propose two methods that leverage causal mechanisms to predict the correctness of model outputs: counterfactual simulation (checking whether key causal variables are realized) and value probing (using the values of those variables to make predictions). Both achieve high AUC-ROC in distribution and outperform methods that rely on causal-agnostic features in out-of-distribution settings, where predicting model behaviors is more crucial. Our work thus highlights a novel and significant application for internal causal analysis of language models.</description><author>Jing Huang, Junyi Tao, Thomas Icard, Diyi Yang, Christopher Potts</author><pubDate>Wed, 12 Nov 2025 01:11:10 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2505.11770v2</guid></item><item><title>GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding</title><link>https://arxiv.org/pdf/2511.00810v2</link><description>Graphical user interface (GUI) grounding is a key function of computer-use agents, which maps natural-language instructions to actionable screen regions. Existing approaches based on Multimodal Large Language Models (MLLMs) typically formulate it as a text-based coordinate generation task, yet directly generating precise coordinates from visual inputs remains challenging and computationally intensive. An intuitive way to implement GUI grounding is to first select visual patches relevant to the instructions and then determine the precise click location within those patches. Based on the observations that general MLLMs have some native grounding capability, nested within their attentions, we propose GUI-AIMA, an attention-based and coordinate-free supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns the intrinsic multimodal attention of MLLMs with patch-wise grounding signals. These signals are calculated adaptively for diverse user instructions by multi-head aggregation on simplified query-visual attention matrices. Besides, its coordinate-free manner can easily integrate a plug-and-play zoom-in stage. GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional data efficiency and verifying that light training can trigger the native grounding capability of MLLMs. It achieves state-of-the-art performance among 3B models, attaining an average accuracy of 59.6% on ScreenSpot-Pro, 63.8% on OSWorld-G and 91.5% on ScreenSpot-v2. Project page: https://github.com/sjz5202/GUI-AIMA</description><author>Shijie Zhou, Viet Dac Lai, Hao Tan, Jihyung Kil, Wanrong Zhu, Changyou Chen, Ruiyi Zhang</author><pubDate>Wed, 12 Nov 2025 01:06:10 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.00810v2</guid></item><item><title>LLM Output Drift: Cross-Provider Validation &amp; Mitigation for Financial Workflows</title><link>https://arxiv.org/pdf/2511.07585v1</link><description>Financial institutions deploy Large Language Models (LLMs) for reconciliations, regulatory reporting, and client communications, but nondeterministic outputs (output drift) undermine auditability and trust. We quantify drift across five model architectures (7B-120B parameters) on regulated financial tasks, revealing a stark inverse relationship: smaller models (Granite-3-8B, Qwen2.5-7B) achieve 100% output consistency at T=0.0, while GPT-OSS-120B exhibits only 12.5% consistency (95% CI: 3.5-36.0%) regardless of configuration (p&lt;0.0001, Fisher's exact test). This finding challenges conventional assumptions that larger models are universally superior for production deployment. Our contributions include: (i) a finance-calibrated deterministic test harness combining greedy decoding (T=0.0), fixed seeds, and SEC 10-K structure-aware retrieval ordering; (ii) task-specific invariant checking for RAG, JSON, and SQL outputs using finance-calibrated materiality thresholds (plus or minus 5%) and SEC citation validation; (iii) a three-tier model classification system enabling risk-appropriate deployment decisions; and (iv) an audit-ready attestation system with dual-provider validation. We evaluated five models (Qwen2.5-7B via Ollama, Granite-3-8B via IBM watsonx.ai, Llama-3.3-70B, Mistral-Medium-2505, and GPT-OSS-120B) across three regulated financial tasks. Across 480 runs (n=16 per condition), structured tasks (SQL) remain stable even at T=0.2, while RAG tasks show drift (25-75%), revealing task-dependent sensitivity. Cross-provider validation confirms deterministic behavior transfers between local and cloud deployments. We map our framework to Financial Stability Board (FSB), Bank for International Settlements (BIS), and Commodity Futures Trading Commission (CFTC) requirements, demonstrating practical pathways for compliance-ready AI deployments.</description><author>Raffi Khatchadourian, Rolando Franco</author><pubDate>Wed, 12 Nov 2025 01:05:38 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.07585v1</guid></item><item><title>Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models</title><link>https://arxiv.org/pdf/2511.07496v1</link><description>Diffusion models, though successful, are known to suffer from hallucinations that create incoherent or unrealistic samples. Recent works have attributed this to the phenomenon of mode interpolation and score smoothening, but they lack a method to prevent their generation during sampling. In this paper, we propose a post-hoc adjustment to the score function during inference that leverages the Laplacian (or sharpness) of the score to reduce mode interpolation hallucination in unconditional diffusion models across 1D, 2D, and high-dimensional image data. We derive an efficient Laplacian approximation for higher dimensions using a finite-difference variant of the Hutchinson trace estimator. We show that this correction significantly reduces the rate of hallucinated samples across toy 1D/2D distributions and a high- dimensional image dataset. Furthermore, our analysis explores the relationship between the Laplacian and uncertainty in the score.</description><author>Barath Chandran. C, Srinivas Anumasa, Dianbo Liu</author><pubDate>Wed, 12 Nov 2025 01:01:41 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.07496v1</guid></item><item><title>Understanding Forgetting in LLM Supervised Fine-Tuning and Preference Learning -- A Convex Optimization Perspective</title><link>https://arxiv.org/pdf/2410.15483v4</link><description>The post-training of LLMs, which typically consists of the supervised fine-tuning (SFT) stage and the preference learning stage (RLHF or DPO), is crucial to effective and safe LLM applications. The widely adopted approach in post-training popular open-source LLMs is to sequentially perform SFT and RLHF/DPO. However, this is suboptimal in terms of SFT and RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training when undergoing the second stage's training. This sequential paradigm persists largely due to its simplicity and modularity, which make it easier to implement and manage at scale despite its limitations. We theoretically prove the sub-optimality of sequential post-training and propose a practical joint post-training framework which has theoretical convergence guarantees and empirically outperforms sequential post-training framework, with up to 23% overall performance improvement across multiple LLM evaluation benchmarks, while having minimal computational overhead. Our code is available at https://github.com/heshandevaka/XRIGHT.</description><author>Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen</author><pubDate>Tue, 11 Nov 2025 17:20:07 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2410.15483v4</guid></item><item><title>Language Generation with Infinite Contamination</title><link>https://arxiv.org/pdf/2511.07417v1</link><description>We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality. Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise). We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples. Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.</description><author>Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou</author><pubDate>Tue, 11 Nov 2025 02:54:00 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.07417v1</guid></item><item><title>SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards</title><link>https://arxiv.org/pdf/2511.07403v1</link><description>Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.</description><author>Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark</author><pubDate>Tue, 11 Nov 2025 02:53:36 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.07403v1</guid></item><item><title>Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper</title><link>https://arxiv.org/pdf/2511.04583v2</link><description>Understanding the current capabilities and risks of AI Scientist systems is essential for ensuring trustworthy and sustainable AI-driven scientific progress while preserving the integrity of the academic ecosystem. To this end, we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system that mimics the core research workflow of a novice student researcher: Given the baseline paper from the human mentor, it analyzes its limitations, formulates novel hypotheses for improvement, and iteratively conducts experiments until improvements are realized, and writes a paper with the results. Unlike previous approaches that assume full automation or operate on small-scale code, Jr. AI Scientist follows a well-defined research workflow and leverages modern coding agents to handle complex, multi-file implementations, leading to scientifically valuable contributions. Through our experiments, the Jr. AI Scientist successfully generated new research papers that build upon real NeurIPS, IJCV, and ICLR works by proposing and implementing novel methods. For evaluation, we conducted automated assessments using AI Reviewers, author-led evaluations, and submissions to Agents4Science, a venue dedicated to AI-driven scientific contributions. The findings demonstrate that Jr. AI Scientist generates papers receiving higher review scores than existing fully automated systems. Nevertheless, we identify important limitations from both the author evaluation and the Agents4Science reviews, indicating the potential risks of directly applying current AI Scientist systems and key challenges for future research. Finally, we comprehensively report various risks identified during development. We believe this study clarifies the current role and limitations of AI Scientist systems, offering insights into the areas that still require human expertise and the risks that may emerge as these systems evolve.</description><author>Atsuyuki Miyai, Mashiro Toyooka, Takashi Otonari, Zaiying Zhao, Kiyoharu Aizawa</author><pubDate>Tue, 11 Nov 2025 02:41:26 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.04583v2</guid></item><item><title>Explaining Bayesian Neural Networks</title><link>https://arxiv.org/pdf/2108.10346v2</link><description>To advance the transparency of learning machines such as Deep Neural Networks (DNNs), the field of Explainable AI (XAI) was established to provide interpretations of DNNs' predictions. While different explanation techniques exist, a popular approach is given in the form of attribution maps, which illustrate, given a particular data point, the relevant patterns the model has used for making its prediction. Although Bayesian models such as Bayesian Neural Networks (BNNs) have a limited form of transparency built-in through their prior weight distribution, they lack explanations of their predictions for given instances. In this work, we take a step toward combining these two perspectives by examining how local attributions can be extended to BNNs. Within the Bayesian framework, network weights follow a probability distribution; hence, the standard point explanation extends naturally to an explanation distribution. Viewing explanations probabilistically, we aggregate and analyze multiple local attributions drawn from an approximate posterior to explore variability in explanation patterns. The diversity of explanations offers a way to further explore how predictive rationales may vary across posterior samples. Quantitative and qualitative experiments on toy and benchmark data, as well as on a real-world pathology dataset, illustrate that our framework enriches standard explanations with uncertainty information and may support the visualization of explanation stability.</description><author>Kirill Bykov, Marina M. -C. Höhne, Adelaida Creosteanu, Klaus-Robert Müller, Frederick Klauschen, Shinichi Nakajima, Marius Kloft</author><pubDate>Tue, 11 Nov 2025 02:31:41 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2108.10346v2</guid></item><item><title>TabRAG: Tabular Document Retrieval via Structured Language Representations</title><link>https://arxiv.org/pdf/2511.06582v1</link><description>Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.</description><author>Jacob Si, Mike Qu, Michelle Lee, Yingzhen Li</author><pubDate>Tue, 11 Nov 2025 02:07:17 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2511.06582v1</guid></item><item><title>When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework</title><link>https://arxiv.org/pdf/2507.13659v2</link><description>Recent researchers have proposed using event cameras for person re-identification (ReID) due to their promising performance and better balance in terms of privacy protection, event camera-based person ReID has attracted significant attention. Currently, mainstream event-based person ReID algorithms primarily focus on fusing visible light and event stream, as well as preserving privacy. Although significant progress has been made, these methods are typically trained and evaluated on small-scale or simulated event camera datasets, making it difficult to assess their real identification performance and generalization ability. To address the issue of data scarcity, this paper introduces a large-scale RGB-event based person ReID dataset, called EvReID. The dataset contains 118,988 image pairs and covers 1200 pedestrian identities, with data collected across multiple seasons, scenes, and lighting conditions. We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid foundation for future research in terms of both data and benchmarking. Based on our newly constructed dataset, this paper further proposes a pedestrian attribute-guided contrastive learning framework to enhance feature learning for person re-identification, termed TriPro-ReID. This framework not only effectively explores the visual features from both RGB frames and event streams, but also fully utilizes pedestrian attributes as mid-level semantic features. Extensive experiments on the EvReID dataset and MARS datasets fully validated the effectiveness of our proposed RGB-Event person ReID framework. The benchmark dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID</description><author>Xiao Wang, Qian Zhu, Shujuan Wu, Bo Jiang, Shiliang Zhang</author><pubDate>Tue, 11 Nov 2025 01:57:44 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2507.13659v2</guid></item><item><title>Quriosity: Analyzing Human Questioning Behavior and Causal Inquiry through Curiosity-Driven Queries</title><link>https://arxiv.org/pdf/2405.20318v4</link><description>Recent progress in Large Language Model (LLM) technology has changed our role in interacting with these models. Instead of primarily testing these models with questions we already know answers to, we are now using them for queries where the answers are unknown to us, driven by human curiosity. This shift highlights the growing need to understand curiosity-driven human questions - those that are more complex, open-ended, and reflective of real-world needs. To this end, we present Quriosity, a collection of 13.5K naturally occurring questions from three diverse sources: human-to-search-engine queries, human-to-human interactions, and human-to-LLM conversations. Our comprehensive collection enables a rich understanding of human curiosity across various domains and contexts. Our analysis reveals a significant presence of causal questions (up to 42%) in the dataset, for which we develop an iterative prompt improvement framework to identify all causal queries and examine their unique linguistic properties, cognitive complexity and source distribution. Our paper paves the way for future work on causal question identification and open-ended chatbot interactions. Our code and data are at https://github.com/roberto-ceraolo/quriosity.</description><author>Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Amélie Reymond, Punya Syon Pandey, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan, Zhijing Jin</author><pubDate>Tue, 11 Nov 2025 01:56:03 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2405.20318v4</guid></item><item><title>ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness</title><link>https://arxiv.org/pdf/2504.10514v3</link><description>Color plays an important role in human perception and usually provides critical clues in visual reasoning. However, it is unclear whether and how vision-language models (VLMs) can perceive, understand, and leverage color as humans. This paper introduces ColorBench, an innovative benchmark meticulously crafted to assess the capabilities of VLMs in color understanding, including color perception, reasoning, and robustness. By curating a suite of diverse test scenarios, with grounding in real applications, ColorBench evaluates how these models perceive colors, infer meanings from color-based cues, and maintain consistent performance under varying color transformations. Through an extensive evaluation of 32 VLMs with varying language models and vision encoders, our paper reveals some undiscovered findings: (i) The scaling law (larger models are better) still holds on ColorBench, while the language model plays a more important role than the vision encoder. (ii) However, the performance gaps across models are relatively small, indicating that color understanding has been largely neglected by existing VLMs. (iii) CoT reasoning improves color understanding accuracies and robustness, though they are vision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on ColorBench but they can also mislead models in some tasks. These findings highlight the critical limitations of current VLMs and underscore the need to enhance color comprehension. Our ColorBenchcan serve as a foundational tool for advancing the study of human-level color understanding of multimodal AI.</description><author>Yijun Liang, Ming Li, Chenrui Fan, Ziyue Li, Dang Nguyen, Kwesi Cobbina, Shweta Bhardwaj, Jiuhai Chen, Fuxiao Liu, Tianyi Zhou</author><pubDate>Tue, 11 Nov 2025 01:40:53 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/pdf/2504.10514v3</guid></item><item><title>Routing Manifold Alignment Improves Generalization of Mixture-of-Experts LLMs</title><link>http://arxiv.org/abs/2511.07419v1</link><description>Sparse Mixture-of-Experts (MoE) have been widely adopted in recent largelanguage models since it can efficiently scale up the model capability withoutincreasing the inference cost. However, evaluations on broad downstream tasksreveal a consistent suboptimality of the routers in existing MoE LLMs, whichresults in a severe performance gap (e.g., 10-20% in accuracy) to the optimalrouting. In this paper, we show that aligning the manifold of routing weightswith that of task embedding can effectively reduce the gap and improve MoELLMs' generalization performance. Our method, "Routing Manifold Alignment(RoMA)", introduces an additional manifold regularization term in thepost-training objective and only requires lightweight finetuning of routers(with other parameters frozen). Specifically, the regularization encourages therouting weights of each sample to be close to those of its successful neighbors(whose routing weights lead to correct answers) in a task embedding space.Consequently, samples targeting similar tasks will share similar expert choicesacross layers. Building such bindings between tasks and experts over differentsamples is essential to achieve better generalization. Moreover, RoMAdemonstrates the advantage of unifying the task understanding (by embeddingmodels) with solution generation (by MoE LLMs). In experiments, we finetunerouters in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diversebenchmarks and extensive comparisons with baselines show the substantialimprovement brought by RoMA.</description><author>Zhongyang Li, Ziyue Li, Tianyi Zhou</author><pubDate>Mon, 10 Nov 2025 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07419v1</guid></item><item><title>Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields</title><link>http://arxiv.org/abs/2511.07418v1</link><description>Despite years of research, real-time diverse grasp synthesis for dexteroushands remains an unsolved core challenge in robotics and computer graphics. Wepresent Lightning Grasp, a novel high-performance procedural grasp synthesisalgorithm that achieves orders-of-magnitude speedups over state-of-the-artapproaches, while enabling unsupervised grasp generation for irregular,tool-like objects. The method avoids many limitations of prior approaches, suchas the need for carefully tuned energy functions and sensitive initialization.This breakthrough is driven by a key insight: decoupling complex geometriccomputation from the search process via a simple, efficient data structure -the Contact Field. This abstraction collapses the problem complexity, enablinga procedural search at unprecedented speeds. We open-source our system topropel further innovation in robotic manipulation.</description><author>Zhao-Heng Yin, Pieter Abbeel</author><pubDate>Mon, 10 Nov 2025 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07418v1</guid></item><item><title>Language Generation with Infinite Contamination</title><link>http://arxiv.org/abs/2511.07417v1</link><description>We study language generation in the limit, where an algorithm observes anadversarial enumeration of strings from an unknown target language $K$ and musteventually generate new, unseen strings from $K$. Kleinberg and Mullainathan[KM24] proved that generation is achievable in surprisingly general settings.But their generator suffers from ``mode collapse,'' producing from anever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]require the generator's output to be ``dense'' in the target language. Theyshowed that generation with density, surprisingly, remains achievable at thesame generality. Both results assume perfect data: no noisy insertions and no omissions. Thisraises a central question: how much contamination can generation tolerate?Recent works made partial progress on this question by studying (non-dense)generation with either finite amounts of noise (but no omissions) or omissions(but no noise). We characterize robustness under contaminated enumerations: 1. Generationunder Contamination: Language generation in the limit is achievable for allcountable collections iff the fraction of contaminated examples converges tozero. When this fails, we characterize which collections are generable. 2.Dense Generation under Contamination: Dense generation is strictly less robustto contamination than generation. As a byproduct, we resolve an open questionof Raman and Raman [ICML25] by showing that generation is possible with onlymembership oracle access under finitely many contaminated examples. Finally, we introduce a beyond-worst-case model inspired by curriculumlearning and prove that dense generation is achievable even with infinitecontamination provided the fraction of contaminated examples converges to zero.This suggests curriculum learning may be crucial for learning from noisy webdata.</description><author>Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou</author><pubDate>Mon, 10 Nov 2025 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07417v1</guid></item><item><title>Robot Learning from a Physical World Model</title><link>http://arxiv.org/abs/2511.07416v1</link><description>We introduce PhysWorld, a framework that enables robot learning from videogeneration through physical world modeling. Recent video generation models cansynthesize photorealistic visual demonstrations from language commands andimages, offering a powerful yet underexplored source of training signals forrobotics. However, directly retargeting pixel motions from generated videos torobots neglects physics, often resulting in inaccurate manipulations. PhysWorldaddresses this limitation by coupling video generation with physical worldreconstruction. Given a single image and a task command, our method generatestask-conditioned videos and reconstructs the underlying physical world from thevideos, and the generated video motions are grounded into physically accurateactions through object-centric residual reinforcement learning with thephysical world model. This synergy transforms implicit visual guidance intophysically executable robotic trajectories, eliminating the need for real robotdata collection and enabling zero-shot generalizable robotic manipulation.Experiments on diverse real-world tasks demonstrate that PhysWorldsubstantially improves manipulation accuracy compared to previous approaches.Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}for details.</description><author>Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang</author><pubDate>Mon, 10 Nov 2025 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07416v1</guid></item><item><title>Wasserstein-Cramér-Rao Theory of Unbiased Estimation</title><link>http://arxiv.org/abs/2511.07414v1</link><description>The quantity of interest in the classical Cram\'er-Rao theory of unbiasedestimation (e.g., the Cram\'er-Rao lower bound, its exact attainment forexponential families, and asymptotic efficiency of maximum likelihoodestimation) is the variance, which represents the instability of an estimatorwhen its value is compared to the value for an independently-sampled data setfrom the same distribution. In this paper we are interested in a quantity whichrepresents the instability of an estimator when its value is compared to thevalue for an infinitesimal additive perturbation of the original data set; werefer to this as the "sensitivity" of an estimator. The resulting theory ofsensitivity is based on the Wasserstein geometry in the same way that theclassical theory of variance is based on the Fisher-Rao (equivalently,Hellinger) geometry, and this insight allows us to determine a collection ofresults which are analogous to the classical case: a Wasserstein-Cram\'er-Raolower bound for the sensitivity of any unbiased estimator, a characterizationof models in which there exist unbiased estimators achieving the lower boundexactly, and some concrete results that show that the Wasserstein projectionestimator achieves the lower bound asymptotically. We use these results totreat many statistical examples, sometimes revealing new optimality propertiesfor existing estimators and other times revealing entirely new estimators.</description><author>Nicolás García Trillos, Adam Quinn Jaffe, Bodhisattva Sen</author><pubDate>Mon, 10 Nov 2025 18:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07414v1</guid></item><item><title>DigiData: Training and Evaluating General-Purpose Mobile Control Agents</title><link>http://arxiv.org/abs/2511.07413v1</link><description>AI agents capable of controlling user interfaces have the potential totransform human interaction with digital devices. To accelerate thistransformation, two fundamental building blocks are essential: high-qualitydatasets that enable agents to achieve complex and human-relevant goals, androbust evaluation methods that allow researchers and practitioners to rapidlyenhance agent performance. In this paper, we introduce DigiData, a large-scale,high-quality, diverse, multi-modal dataset designed for training mobile controlagents. Unlike existing datasets, which derive goals from unstructuredinteractions, DigiData is meticulously constructed through comprehensiveexploration of app features, resulting in greater diversity and higher goalcomplexity. Additionally, we present DigiData-Bench, a benchmark for evaluatingmobile control agents on real-world complex tasks. We demonstrate that thecommonly used step-accuracy metric falls short in reliably assessing mobilecontrol agents and, to address this, we propose dynamic evaluation protocolsand AI-powered evaluations as rigorous alternatives for agent assessment. Ourcontributions aim to significantly advance the development of mobile controlagents, paving the way for more intuitive and effective human-deviceinteractions.</description><author>Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe</author><pubDate>Mon, 10 Nov 2025 18:57:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07413v1</guid></item><item><title>TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research</title><link>http://arxiv.org/abs/2511.07412v1</link><description>Developing embodied AI for intelligent surgical systems requires safe,controllable environments for continual learning and evaluation. However,safety regulations and operational constraints in operating rooms (ORs) limitembodied agents from freely perceiving and interacting in realistic settings.Digital twins provide high-fidelity, risk-free environments for exploration andtraining. How we may create photorealistic and dynamic digital representationsof ORs that capture relevant spatial, visual, and behavioral complexity remainsunclear. We introduce TwinOR, a framework for constructing photorealistic,dynamic digital twins of ORs for embodied AI research. The system reconstructsstatic geometry from pre-scan videos and continuously models human andequipment motion through multi-view perception of OR activities. The static anddynamic components are fused into an immersive 3D environment that supportscontrollable simulation and embodied exploration. The proposed frameworkreconstructs complete OR geometry with centimeter level accuracy whilepreserving dynamic interaction across surgical workflows, enabling realisticrenderings and a virtual playground for embodied AI systems. In ourexperiments, TwinOR simulates stereo and monocular sensor streams for geometryunderstanding and visual localization tasks. Models such as FoundationStereoand ORB-SLAM3 on TwinOR-synthesized data achieve performance within theirreported accuracy on real indoor datasets, demonstrating that TwinOR providessensor-level realism sufficient for perception and localization challenges. Byestablishing a real-to-sim pipeline for constructing dynamic, photorealisticdigital twins of OR environments, TwinOR enables the safe, scalable, anddata-efficient development and benchmarking of embodied AI, ultimatelyaccelerating the deployment of embodied AI from sim-to-real.</description><author>Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath</author><pubDate>Mon, 10 Nov 2025 18:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07412v1</guid></item><item><title>Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective</title><link>http://arxiv.org/abs/2511.07410v1</link><description>Large Language Models (LLMs) and Vision Language Models (VLMs) have beenwidely used for embodied symbolic planning. Yet, how to effectively use thesemodels for closed-loop symbolic planning remains largely unexplored. Becausethey operate as black boxes, LLMs and VLMs can produce unpredictable or costlyerrors, making their use in high-level robotic planning especially challenging.In this work, we investigate how to use VLMs as closed-loop symbolic plannersfor robotic applications from a control-theoretic perspective. Concretely, westudy how the control horizon and warm-starting impact the performance of VLMsymbolic planners. We design and conduct controlled experiments to gaininsights that are broadly applicable to utilizing VLMs as closed-loop symbolicplanners, and we discuss recommendations that can help improve the performanceof VLM symbolic planners.</description><author>Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal</author><pubDate>Mon, 10 Nov 2025 18:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07410v1</guid></item><item><title>DIMO: Diverse 3D Motion Generation for Arbitrary Objects</title><link>http://arxiv.org/abs/2511.07409v1</link><description>We present DIMO, a generative approach capable of generating diverse 3Dmotions for arbitrary objects from a single image. The core idea of our work isto leverage the rich priors in well-trained video models to extract the commonmotion patterns and then embed them into a shared low-dimensional latent space.Specifically, we first generate multiple videos of the same object with diversemotions. We then embed each motion into a latent vector and train a sharedmotion decoder to learn the distribution of motions represented by a structuredand compact motion representation, i.e., neural key point trajectories. Thecanonical 3D Gaussians are then driven by these key points and fused to modelthe geometry and appearance. During inference time with learned latent space,we can instantly sample diverse 3D motions in a single-forward pass and supportseveral interesting applications including 3D motion interpolation andlanguage-guided motion generation. Our project page is available athttps://linzhanm.github.io/dimo.</description><author>Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis</author><pubDate>Mon, 10 Nov 2025 18:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07409v1</guid></item><item><title>Entangled Schrödinger Bridge Matching</title><link>http://arxiv.org/abs/2511.07406v1</link><description>Simulating trajectories of multi-particle systems on complex energylandscapes is a central task in molecular dynamics (MD) and drug discovery, butremains challenging at scale due to computationally expensive and longsimulations. Previous approaches leverage techniques such as flow orSchr\"odinger bridge matching to implicitly learn joint trajectories throughdata snapshots. However, many systems, including biomolecular systems andheterogeneous cell populations, undergo dynamic interactions that evolve overtheir trajectory and cannot be captured through static snapshots. To close thisgap, we introduce Entangled Schr\"odinger Bridge Matching (EntangledSBM), aframework that learns the first- and second-order stochastic dynamics ofinteracting, multi-particle systems where the direction and magnitude of eachparticle's path depend dynamically on the paths of the other particles. Wedefine the Entangled Schr\"odinger Bridge (EntangledSB) problem as solving acoupled system of bias forces that entangle particle velocities. We show thatour framework accurately simulates heterogeneous cell populations underperturbations and rare transitions in high-dimensional biomolecular systems.</description><author>Sophia Tang, Yinuo Zhang, Pranam Chatterjee</author><pubDate>Mon, 10 Nov 2025 18:55:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07406v1</guid></item><item><title>SPOT: An Annotated French Corpus and Benchmark for Detecting Critical Interventions in Online Conversations</title><link>http://arxiv.org/abs/2511.07405v1</link><description>We introduce SPOT (Stopping Points in Online Threads), the first annotatedcorpus translating the sociological concept of stopping point into areproducible NLP task. Stopping points are ordinary critical interventions thatpause or redirect online discussions through a range of forms (irony, subtledoubt or fragmentary arguments) that frameworks like counterspeech or socialcorrection often overlook. We operationalize this concept as a binaryclassification task and provide reliable annotation guidelines. The corpuscontains 43,305 manually annotated French Facebook comments linked to URLsflagged as false information by social media users, enriched with contextualmetadata (article, post, parent comment, page or group, and source). Webenchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMsunder various prompting strategies. Results show that fine-tuned encodersoutperform prompted LLMs in F1 score by more than 10 percentage points,confirming the importance of supervised learning for emerging non-Englishsocial media tasks. Incorporating contextual metadata further improves encodermodels F1 scores from 0.75 to 0.78. We release the anonymized dataset, alongwith the annotation guidelines and code in our code repository, to fostertransparency and reproducible research.</description><author>Manon Berriche, Célia Nouri, Chloé Clavel, Jean-Philippe Cointet</author><pubDate>Mon, 10 Nov 2025 18:54:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07405v1</guid></item><item><title>SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards</title><link>http://arxiv.org/abs/2511.07403v1</link><description>Multimodal large language models (MLLMs) have achieved remarkable progress invision-language tasks, but they continue to struggle with spatialunderstanding. Existing spatial MLLMs often rely on explicit 3D inputs orarchitecture-specific modifications, and remain constrained by large-scaledatasets or sparse supervision. To address these limitations, we introduceSpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatialgrounding with multi-step reasoning. The model simulates human-like spatialperception by constructing a scene graph of task-relevant objects and spatialrelations, and reasoning towards an answer via dense spatial rewards.SpatialThinker consists of two key contributions: (1) a data synthesis pipelinethat generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RLwith a multi-objective dense spatial reward enforcing spatial grounding.SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baselineon spatial understanding and real-world VQA benchmarks, nearly doubling thebase-model gain compared to sparse RL, and surpassing GPT-4o. These resultsshowcase the effectiveness of combining spatial supervision with reward-alignedreasoning in enabling robust 3D spatial understanding with limited data andadvancing MLLMs towards human-level visual reasoning.</description><author>Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark</author><pubDate>Mon, 10 Nov 2025 18:52:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07403v1</guid></item><item><title>StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation</title><link>http://arxiv.org/abs/2511.07399v1</link><description>Generative models are reshaping the live-streaming industry by redefining howcontent is created, styled, and delivered. Previous image-based streamingdiffusion models have powered efficient and creative live streaming productsbut have hit limits on temporal consistency due to the foundation ofimage-based designs. Recent advances in video diffusion have markedly improvedtemporal consistency and sampling efficiency for offline generation. However,offline generation systems primarily optimize throughput by batching largeworkloads. In contrast, live online streaming operates under strictservice-level objectives (SLOs): time-to-first-frame must be minimal, and everyframe must meet a per-frame deadline with low jitter. Besides, scalablemulti-GPU serving for real-time streams remains largely unresolved so far. Toaddress this, we present StreamDiffusionV2, a training-free pipeline forinteractive live streaming with video diffusion models. StreamDiffusionV2integrates an SLO-aware batching scheduler and a block scheduler, together witha sink-token--guided rolling KV cache, a motion-aware noise controller, andother system-level optimizations. Moreover, we introduce a scalable pipelineorchestration that parallelizes the diffusion process across denoising stepsand network layers, achieving near-linear FPS scaling without violating latencyguarantees. The system scales seamlessly across heterogeneous GPU environmentsand supports flexible denoising steps (e.g., 1--4), enabling bothultra-low-latency and higher-quality modes. Without TensorRT or quantization,StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPSwith a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on fourH100 GPUs, making state-of-the-art generative live streaming practical andaccessible--from individual creators to enterprise-scale platforms.</description><author>Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu</author><pubDate>Mon, 10 Nov 2025 18:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07399v1</guid></item><item><title>Solving bilevel optimization via sequential minimax optimization</title><link>http://arxiv.org/abs/2511.07398v1</link><description>In this paper we propose a sequential minimax optimization (SMO) method forsolving a class of constrained bilevel optimization problems in which thelower-level part is a possibly nonsmooth convex optimization problem, while theupper-level part is a possibly nonconvex optimization problem. Specifically,SMO applies a first-order method to solve a sequence of minimax subproblems,which are obtained by employing a hybrid of modified augmented Lagrangian andpenalty schemes on the bilevel optimization problems. Under suitableassumptions, we establish an operation complexity of$O(\varepsilon^{-7}\log\varepsilon^{-1})$ and$O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamentaloperations, for SMO in finding an $\varepsilon$-KKT solution of the bileveloptimization problems with merely convex and strongly convex lower-levelobjective functions, respectively. The latter result improves the previousbest-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminarynumerical results demonstrate significantly superior computational performancecompared to the recently developed first-order penalty method.</description><author>Zhaosong Lu, Sanyou Mei</author><pubDate>Mon, 10 Nov 2025 18:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07398v1</guid></item><item><title>ConvFill: Model Collaboration for Responsive Conversational Voice Agents</title><link>http://arxiv.org/abs/2511.07397v1</link><description>Deploying conversational voice agents with large language models faces acritical challenge: cloud-based foundation models provide deep reasoning anddomain knowledge but introduce latency that disrupts natural conversation,while on-device models respond immediately but lack sophistication. We proposeconversational infill, a task where a lightweight on-device model generatescontextually appropriate dialogue while seamlessly incorporating streamingknowledge from a powerful backend model. This approach decouples responselatency from model capability, enabling systems that feel responsive whileaccessing the full power of large-scale models. We present ConvFill, a 360Mparameter model trained on synthetic multi-domain conversations. Evaluationacross multiple backend models shows that conversational infill can besuccessfully learned, with ConvFill achieving accuracy improvements of 36-42%over standalone small models of the same size while consistently retainingsub-200ms response latencies. Our results demonstrate the promise of thisapproach for building on-device conversational agents that are both immediatelyresponsive and knowledgeable.</description><author>Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer</author><pubDate>Mon, 10 Nov 2025 18:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07397v1</guid></item><item><title>C3PO: Optimized Large Language Model Cascades with Probabilistic Cost Constraints for Reasoning</title><link>http://arxiv.org/abs/2511.07396v1</link><description>Large language models (LLMs) have achieved impressive results on complexreasoning tasks, but their high inference cost remains a major barrier toreal-world deployment. A promising solution is to use cascaded inference, wheresmall, cheap models handle easy queries, and only the hardest examples areescalated to more powerful models. However, existing cascade methods typicallyrely on supervised training with labeled data, offer no theoreticalgeneralization guarantees, and provide limited control over test-timecomputational cost. We introduce C3PO (Cost Controlled Cascaded PredictionOptimization), a self-supervised framework for optimizing LLM cascades underprobabilistic cost constraints. By focusing on minimizing regret with respectto the most powerful model (MPM), C3PO avoids the need for labeled data byconstructing a cascade using only unlabeled model outputs. It leveragesconformal prediction to bound the probability that inference cost exceeds auser-specified budget. We provide theoretical guarantees on both cost controland generalization error, and show that our optimization procedure is effectiveeven with small calibration sets. Empirically, C3PO achieves state-of-the-artperformance across a diverse set of reasoning benchmarks including GSM8K,MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselinesin both accuracy and cost-efficiency. Our results demonstrate that principled,label-free cascade optimization can enable scalable LLM deployment.</description><author>Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang, Mark Coates</author><pubDate>Mon, 10 Nov 2025 18:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07396v1</guid></item><item><title>Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction</title><link>http://arxiv.org/abs/2511.07392v1</link><description>In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged inthe procedure, making it difficult to access and manipulate multimodal patientdata without interruption. We propose a voice-directed Surgical AgentOrchestrator Platform (SAOP) built on a hierarchical multi-agent framework,consisting of an orchestration agent and three task-specific agents driven byLarge Language Models (LLMs). These LLM-based agents autonomously plan, refine,validate, and reason to map voice commands into specific tasks such asretrieving clinical information, manipulating CT scans, or navigating 3Danatomical models on the surgical video. We also introduce a Multi-levelOrchestration Evaluation Metric (MOEM) to comprehensively assess theperformance and robustness from command-level and category-level perspectives.The SAOP achieves high accuracy and success rates across 240 voice commands,while LLM-based agents improve robustness against speech recognition errors anddiverse or ambiguous free-form commands, demonstrating strong potential tosupport minimally invasive da Vinci robotic surgery.</description><author>Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim</author><pubDate>Mon, 10 Nov 2025 18:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07392v1</guid></item><item><title>A Diffusion Model to Shrink Proteins While Maintaining Their Function</title><link>http://arxiv.org/abs/2511.07390v1</link><description>Many proteins useful in modern medicine or bioengineering are challenging tomake in the lab, fuse with other proteins in cells, or deliver to tissues inthe body, because their sequences are too long. Shortening these sequencestypically involves costly, time-consuming experimental campaigns. Ideally, wecould instead use modern models of massive databases of sequences from natureto learn how to propose shrunken proteins that resemble sequences found innature. Unfortunately, these models struggle to efficiently search thecombinatorial space of all deletions, and are not trained with inductive biasesto learn how to delete. To address this gap, we propose SCISOR, a noveldiscrete diffusion model that deletes letters from sequences to generateprotein samples that resemble those found in nature. To do so, SCISOR trains ade-noiser to reverse a forward noising process that adds random insertions tonatural sequences. As a generative model, SCISOR fits evolutionary sequencedata competitively with previous large models. In evaluation, SCISOR achievesstate-of-the-art predictions of the functional effects of deletions onProteinGym. Finally, we use the SCISOR de-noiser to shrink long proteinsequences, and show that its suggested deletions result in significantly morerealistic proteins and more often preserve functional motifs than previousmodels of evolutionary sequences.</description><author>Ethan Baron, Alan N. Amin, Ruben Weitzman, Debora Marks, Andrew Gordon Wilson</author><pubDate>Mon, 10 Nov 2025 18:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07390v1</guid></item><item><title>Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence</title><link>http://arxiv.org/abs/2511.07384v1</link><description>Recent advances in depth-recurrent language models show that recurrence candecouple train-time compute and parameter count from test-time compute. In thiswork, we study how to convert existing pretrained non-recurrent language modelsinto depth-recurrent models. We find that using a curriculum of recurrences toincrease the effective depth of the model over the course of training preservesperformance while reducing total computational cost. In our experiments, onmathematics, we observe that converting pretrained models to recurrent onesresults in better performance at a given compute budget than simplypost-training the original non-recurrent language model.</description><author>Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum</author><pubDate>Mon, 10 Nov 2025 18:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07384v1</guid></item><item><title>Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for Bangla-to-Python Code Generation</title><link>http://arxiv.org/abs/2511.07382v1</link><description>Large Language Models (LLMs) have advanced the automated generation of codefrom natural language prompts. However, low-resource languages (LRLs) likeBangla remain underrepresented due to the limited availability ofinstruction-to-code datasets and evaluation benchmarks. To address this, theBLP Workshop at IJCNLP-AACL 2025 introduced a shared task on "Code Generationin Bangla". In this work, we propose a method that combines instructionprompting with a test-driven, feedback-guided iterative refinement processusing a fine-tuned Qwen2.5-14B model. The model generates code from Banglainstructions, tests it against unit tests, and iteratively refines any failingoutputs through three evaluation passes, using test feedback to guide eachstep. This approach helped our team "Retriv" to secure 2nd place in the sharedtask with a Pass@1 score of 0.934. The analysis highlights challenges in Banglainstruction understanding and Python code generation, emphasizing the need fortargeted methods in LRLs. We made experimental scripts publicly available forthe community.</description><author>K M Nafi Asib, Sourav Saha, Mohammed Moshiul Hoque</author><pubDate>Mon, 10 Nov 2025 18:41:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07382v1</guid></item><item><title>Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource Domains</title><link>http://arxiv.org/abs/2511.07380v1</link><description>Large language models (LLMs) have achieved remarkable success acrosswidespread tasks, yet their application in low-resource domains remains asignificant challenge due to data scarcity and the high risk of overfitting.While in-domain data is limited, there exist vast amounts of similargeneral-domain data, and our initial findings reveal that they couldpotentially serve as auxiliary supervision for domain enhancement. Thisobservation leads us to our central research question: \textbf{\textit{how toeffectively select the most valuable auxiliary data to maximize domain-specificperformance}}, particularly when traditional methods are inapplicable due to alack of large in-domain data pools or validation sets. To address this, wepropose \textbf{NTK-Selector}, a principled and efficient framework forselecting general-domain auxiliary data to enhance domain-specific performancevia neural tangent kernels (NTK). Our method tackles two challenges of directlyapplying NTK to LLMs, theoretical assumptions and prohibitive computationalcost, by empirically demonstrating a stable NTK-like behavior in LLMs duringLoRA fine-tuning and proposing a Jacobian-free approximation method. Extensiveexperiments across four low-resource domains (medical, financial, legal, andpsychological) demonstrate that NTK-Selector consistently improves downstreamperformance. Specifically, fine-tuning on 1,000 in-domain samples alone onlyyielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. Incontrast, enriching with 9,000 auxiliary samples selected by NTK-Selector ledto substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a\textbf{10.9x and 5.7x improvement} over the domain-only setting.</description><author>Pingjie Wang, Hongcheng Liu, Yusheng Liao, Ziqing Fan, Yaxin Du, Shuo Tang, Yanfeng Wang, Yu Wang</author><pubDate>Mon, 10 Nov 2025 18:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07380v1</guid></item><item><title>LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs</title><link>http://arxiv.org/abs/2511.07379v1</link><description>Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakesdomains, such as financial forecasting, recommendation systems, and frauddetection. However, their susceptibility to poisoning attacks poses a criticalsecurity risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), anovel adversarial framework on Continuous-Time Dynamic Graphs, which degradesTGNN performance by an average of 29.47% across 4 widely benchmark datasets and4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stageapproach: (1) sparsify the graph by removing high-impact edges using any of the16 tested temporal importance metrics, (2) strategically replace removed edgeswith adversarial negatives via LoReTTA's novel degree-preserving negativesampling algorithm. Our plug-and-play design eliminates the need for expensivesurrogate models while adhering to realistic unnoticeability constraints.LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remainsundetectable to 4 leading anomaly detection systems, and is robust to 4 SotAadversarial defense training methods, establishing its effectiveness,unnoticeability, and robustness.</description><author>Himanshu Pal, Venkata Sai Pranav Bachina, Ankit Gangwal, Charu Sharma</author><pubDate>Mon, 10 Nov 2025 18:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07379v1</guid></item><item><title>Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization</title><link>http://arxiv.org/abs/2511.07378v1</link><description>The ability to reason lies at the core of artificial intelligence (AI), andchallenging problems usually call for deeper and longer reasoning to tackle. Acrucial question about AI reasoning is whether models can extrapolate learnedreasoning patterns to solve harder tasks with longer chain-of-thought (CoT). Inthis work, we present a theoretical analysis of transformers learning onsynthetic state-tracking tasks with gradient descent. We mathematically provehow the algebraic structure of state-tracking problems governs the degree ofextrapolation of the learned CoT. Specifically, our theory characterizes thelength generalization of transformers through the mechanism of attentionconcentration, linking the retrieval robustness of the attention layer to thestate-tracking task structure of long-context reasoning. Moreover, fortransformers with limited reasoning length, we prove that a recursiveself-training scheme can progressively extend the range of solvable problemlengths. To our knowledge, we provide the first optimization guarantee thatconstant-depth transformers provably learn $\mathsf{NC}^1$-complete problemswith CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.Finally, we present a broad set of experiments supporting our theoreticalresults, confirming the length generalization behaviors and the mechanism ofattention concentration.</description><author>Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen</author><pubDate>Mon, 10 Nov 2025 18:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07378v1</guid></item><item><title>Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion</title><link>http://arxiv.org/abs/2511.07377v1</link><description>LiDAR super-resolution addresses the challenge of achieving high-quality 3Dperception from cost-effective, low-resolution sensors. While recenttransformer-based approaches like TULIP show promise, they remain limited tospatial-domain processing with restricted receptive fields. We introduce FLASH(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), anovel framework that overcomes these limitations through dual-domainprocessing. FLASH integrates two key innovations: (i) Frequency-Aware WindowAttention that combines local spatial attention with global frequency-domainanalysis via FFT, capturing both fine-grained geometry and periodic scanningpatterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion thatreplaces conventional skip connections with learned position-specific featureaggregation, enhanced by CBAM attention for dynamic feature selection.Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-artperformance across all evaluation metrics, surpassing even uncertainty-enhancedbaselines that require multiple forward passes. Notably, FLASH outperformsTULIP with Monte Carlo Dropout while maintaining single-pass efficiency, whichenables real-time deployment. The consistent superiority across all distanceranges validates that our dual-domain approach effectively handles uncertaintythrough architectural design rather than computationally expensive stochasticinference, making it practical for autonomous systems.</description><author>June Moh Goo, Zichao Zeng, Jan Boehm</author><pubDate>Mon, 10 Nov 2025 18:38:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07377v1</guid></item><item><title>Explaining Human Choice Probabilities with Simple Vector Representations</title><link>http://arxiv.org/abs/2511.03643v2</link><description>When people pursue rewards in stochastic environments, they often match theirchoice frequencies to the observed target frequencies, even when this policy isdemonstrably sub-optimal. We used a ``hide and seek'' task to evaluate thisbehavior under conditions where pursuit (seeking) could be toggled to avoidance(hiding), while leaving the probability distribution fixed, or varyingcomplexity by changing the number of possible choices. We developed a model forparticipant choice built from choice frequency histograms treated as vectors.We posited the existence of a probability antimatching strategy for avoidance(hiding) rounds, and formalized this as a vector reflection of probabilitymatching. We found that only two basis policies: matching/antimatching andmaximizing/minimizing were sufficient to account for participant choices acrossa range of room numbers and opponent probability distributions. This schemarequires only that people have the ability to remember the relative frequencyof the different outcomes. With this knowledge simple operations can constructthe maximizing and minimizing policies as well as matching and antimatchingstrategies. A mixture of these two policies captures human choice patterns in astochastic environment.</description><author>Peter DiBerardino, Britt Anderson</author><pubDate>Mon, 10 Nov 2025 18:36:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03643v2</guid></item><item><title>Mixed Signals: Understanding Model Disagreement in Multimodal Empathy Detection</title><link>http://arxiv.org/abs/2505.13979v2</link><description>Multimodal models play a key role in empathy detection, but their performancecan suffer when modalities provide conflicting cues. To understand thesefailures, we examine cases where unimodal and multimodal predictions diverge.Using fine-tuned models for text, audio, and video, along with a gated fusionmodel, we find that such disagreements often reflect underlying ambiguity, asevidenced by annotator uncertainty. Our analysis shows that dominant signals inone modality can mislead fusion when unsupported by others. We also observethat humans, like models, do not consistently benefit from multimodal input.These insights position disagreement as a useful diagnostic signal foridentifying challenging examples and improving empathy system robustness.</description><author>Maya Srikanth, Run Chen, Julia Hirschberg</author><pubDate>Mon, 10 Nov 2025 18:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.13979v2</guid></item><item><title>Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training</title><link>http://arxiv.org/abs/2511.07372v1</link><description>Recent curriculum techniques in the post-training stage of LLMs have beenwidely observed to outperform non-curriculum approaches in enhancing reasoningperformance, yet a principled understanding of why and to what extent they workremains elusive. To address this gap, we develop a theoretical frameworkgrounded in the intuition that progressively learning through manageable stepsis more efficient than directly tackling a hard reasoning task, provided eachstage stays within the model's effective competence. Under mild complexityconditions linking consecutive curriculum stages, we show that curriculumpost-training avoids the exponential complexity bottleneck. To substantiate this result, drawing insights from the Chain-of-Thoughts(CoTs) solving mathematical problems such as Countdown and parity, we model CoTgeneration as a states-conditioned autoregressive reasoning tree, define auniform-branching base model to capture pretrained behavior, and formalizecurriculum stages as either depth-increasing (longer reasoning chains) orhint-decreasing (shorter prefixes) subtasks. Our analysis shows that, underoutcome-only reward signals, reinforcement learning finetuning achieves highaccuracy with polynomial sample complexity, whereas direct learning suffersfrom an exponential bottleneck. We further establish analogous guarantees fortest-time scaling, where curriculum-aware querying reduces both reward oraclecalls and sampling cost from exponential to polynomial order.</description><author>Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Hau-San Wong, Qingfu Zhang, Taiji Suzuki</author><pubDate>Mon, 10 Nov 2025 18:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07372v1</guid></item><item><title>Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning</title><link>http://arxiv.org/abs/2511.07368v1</link><description>Foundation models exhibit broad knowledge but limited task-specificreasoning, motivating post-training strategies such as RLVR and inferencescaling with outcome or process reward models (ORM/PRM). While recent workhighlights the role of exploration and entropy stability in improving pass@K,empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforceexisting tree-like reasoning paths rather than expanding the reasoning scope,raising the question of why exploration helps at all if no new patterns emerge. To reconcile this paradox, we adopt the perspective of Kim et al. (2025),viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering asymmetry) reasoning steps as low- versus high-probability Markov transitions,and formalize post-training dynamics through Multi-task Tree-structured MarkovChains (TMC). In this tractable model, pretraining corresponds to treeexpansion, while post-training corresponds to chain-of-thought reweighting. Weshow that several phenomena recently observed in empirical studies arisenaturally in this setting: (1) RLVR induces a squeezing effect, reducingreasoning entropy and forgetting some correct paths; (2) population rewards ofORM/PRM encourage consistency rather than accuracy, thereby favoring commonpatterns; and (3) certain rare, high-uncertainty reasoning paths by the basemodel are responsible for solving hard problem instances. Together, these explain why exploration -- even when confined to the basemodel's reasoning scope -- remains essential: it preserves access to rare butcrucial reasoning traces needed for difficult cases, which are squeezed out byRLVR or unfavored by inference scaling. Building on this, we further show thatexploration strategies such as rejecting easy instances and KL regularizationhelp preserve rare reasoning traces. Empirical simulations corroborate ourtheoretical results.</description><author>Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, Taiji Suzuki</author><pubDate>Mon, 10 Nov 2025 18:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07368v1</guid></item><item><title>Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics</title><link>http://arxiv.org/abs/2510.06367v2</link><description>Neural ODEs are a widely used, powerful machine learning technique inparticular for physics. However, not every solution is physical in that it isan Euler-Lagrange equation. We present Helmholtz metrics to quantify thisresemblance for a given ODE and demonstrate their capabilities on severalfundamental systems with noise. We combine them with a second order neural ODEto form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equationsin a direct fashion and with zero additional inference cost. We demonstratethat, using only positional data, they can distinguish Lagrangian andnon-Lagrangian systems and improve the neural ODE solutions.</description><author>Luca Wolf, Tobias Buck, Bjoern Malte Schaefer</author><pubDate>Mon, 10 Nov 2025 18:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.06367v2</guid></item><item><title>Machine-Learning Accelerated Calculations of Reduced Density Matrices</title><link>http://arxiv.org/abs/2511.07367v1</link><description>$n$-particle reduced density matrices ($n$-RDMs) play a central role inunderstanding correlated phases of matter. Yet the calculation of $n$-RDMs isoften computationally inefficient for strongly-correlated states, particularlywhen the system sizes are large. In this work, we propose to use neural network(NN) architectures to accelerate the calculation of, and even predict, the$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs areoften smooth functions over the Brillouin zone (BZ) (certainly true for gappedstates) and are thus interpolable, allowing NNs trained on small-size $n$-RDMsto predict large-size ones. Building on this intuition, we devise two NNs: (i)a self-attention NN that maps random RDMs to physical ones, and (ii) aSinusoidal Representation Network (SIREN) that directly maps momentum-spacecoordinates to RDM values. We test the NNs in three 2D models: the pair-paircorrelation functions of the Richardson model of superconductivity, thetranslationally-invariant 1-RDM in a four-band model with short-rangerepulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the$18\times 18$ pair-pair correlation function with a relative accuracy of$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can providehigh-quality initial guesses for $50\times 50$ translation-invariantHartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,reducing the number of iterations required for convergence by up to $91.63\%$and $92.78\%$, respectively, compared to random initializations. Our resultsillustrate the potential of using NN-based methods for interpolable $n$-RDMs,which might open a new avenue for future research on strongly correlatedphases.</description><author>Awwab A. Azam, Lexu Zhao, Jiabin Yu</author><pubDate>Mon, 10 Nov 2025 18:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07367v1</guid></item><item><title>UAV-Assisted Resilience in 6G and Beyond Network Energy Saving: A Multi-Agent DRL Approach</title><link>http://arxiv.org/abs/2511.07366v1</link><description>This paper investigates the unmanned aerial vehicle (UAV)-assisted resilienceperspective in the 6G network energy saving (NES) scenario. More specifically,we consider multiple ground base stations (GBSs) and each GBS has threedifferent sectors/cells in the terrestrial networks, and multiple cells areturned off due to NES or incidents, e.g., disasters, hardware failures, oroutages. To address this, we propose a Multi-Agent Deep Deterministic PolicyGradient (MADDPG) framework to enable UAV-assisted communication by jointlyoptimizing UAV trajectories, transmission power, and user-UAV association undera sleeping ground base station (GBS) strategy. This framework aims to ensurethe resilience of active users in the network and the long-term operability ofUAVs. Specifically, it maximizes service coverage for users during poweroutages or NES zones, while minimizing the energy consumption of UAVs.Simulation results demonstrate that the proposed MADDPG policy consistentlyachieves high coverage ratio across different testing episodes, outperformingother baselines. Moreover, the MADDPG framework attains the lowest total energyconsumption, with a reduction of approximately 24\% compared to theconventional all GBS ON configuration, while maintaining a comparable userservice rate. These results confirm the effectiveness of the proposed approachin achieving a superior trade-off between energy efficiency and serviceperformance, supporting the development of sustainable and resilientUAV-assisted cellular networks.</description><author>Dao Lan Vy Dinh, Anh Nguyen Thi Mai, Hung Tran, Giang Quynh Le Vu, Tu Dac Ho, Zhenni Pan, Vo Nhan Van, Symeon Chatzinotas, Dinh-Hieu Tran</author><pubDate>Mon, 10 Nov 2025 18:23:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07366v1</guid></item><item><title>Private Sketches for Linear Regression</title><link>http://arxiv.org/abs/2511.07365v1</link><description>Linear regression is frequently applied in a variety of domains. In order toimprove the efficiency of these methods, various methods have been developedthat compute summaries or \emph{sketches} of the datasets. Certain domains,however, contain sensitive data which necessitates that the application ofthese statistical methods does not reveal private information. Differentiallyprivate (DP) linear regression methods have been developed for mitigating thisproblem. These techniques typically involve estimating a noisy version of theparameter vector. Instead, we propose releasing private sketches of thedatasets. We present differentially private sketches for the problems of leastsquares regression, as well as least absolute deviations regression. Theavailability of these private sketches facilitates the application of commonlyavailable solvers for regression, without the risk of privacy leakage.</description><author>Shrutimoy Das, Debanuj Nayak, Anirban Dasgupta</author><pubDate>Mon, 10 Nov 2025 18:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07365v1</guid></item><item><title>Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection</title><link>http://arxiv.org/abs/2511.07364v1</link><description>Reliability and failure detection of large language models (LLMs) is criticalfor their deployment in high-stakes, multi-step reasoning tasks. Prior workexplores confidence estimation for self-evaluating LLM-scorer systems, withconfidence scorers estimating the likelihood of errors in LLM responses.However, most methods focus on single-step outputs and overlook the challengesof multi-step reasoning. In this work, we extend self-evaluation techniques tomulti-step tasks, testing two intuitive approaches: holistic scoring andstep-by-step scoring. Using two multi-step benchmark datasets, we show thatstepwise evaluation generally outperforms holistic scoring in detectingpotential errors, with up to 15% relative increase in AUC-ROC. Our findingsdemonstrate that self-evaluating LLM systems provide meaningful confidenceestimates in complex reasoning, improving their trustworthiness and providing apractical framework for failure detection.</description><author>Vaibhav Mavi, Shubh Jaroria, Weiqi Sun</author><pubDate>Mon, 10 Nov 2025 18:19:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07364v1</guid></item><item><title>Inference-Time Scaling of Diffusion Models for Infrared Data Generation</title><link>http://arxiv.org/abs/2511.07362v1</link><description>Infrared imagery enables temperature-based scene understanding using passivesensors, particularly under conditions of low visibility where traditional RGBimaging fails. Yet, developing downstream vision models for infraredapplications is hindered by the scarcity of high-quality annotated data, due tothe specialized expertise required for infrared annotation. While syntheticinfrared image generation has the potential to accelerate model development byproviding large-scale, diverse training data, training foundation-levelgenerative diffusion models in the infrared domain has remained elusive due tolimited datasets. In light of such data constraints, we explore aninference-time scaling approach using a domain-adapted CLIP-based verifier forenhanced infrared image generation quality. We adapt FLUX.1-dev, astate-of-the-art text-to-image diffusion model, to the infrared domain byfinetuning it on a small sample of infrared images using parameter-efficienttechniques. The trained verifier is then employed during inference to guide thediffusion sampling process toward higher quality infrared generations thatbetter align with input text prompts. Empirically, we find that our approachleads to consistent improvements in generation quality, reducing FID scores onthe KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% comparedto unguided baseline samples. Our results suggest that inference-time guidanceoffers a promising direction for bridging the domain gap in low-data infraredsettings.</description><author>Kai A. Horstmann, Maxim Clouser, Kia Khezeli</author><pubDate>Mon, 10 Nov 2025 18:18:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07362v1</guid></item><item><title>Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning</title><link>http://arxiv.org/abs/2508.00024v2</link><description>Quantum Support Vector Machines face scalability challenges due tohigh-dimensional quantum states and hardware limitations. We propose anembedding-aware quantum-classical pipeline combining class-balanced k-meansdistillation with pretrained Vision Transformer embeddings. Our key finding:ViT embeddings uniquely enable quantum advantage, achieving up to 8.02%accuracy improvements over classical SVMs on Fashion-MNIST and 4.42% on MNIST,while CNN features show performance degradation. Using 16-qubit tensor networksimulation via cuTensorNet, we provide the first systematic evidence thatquantum kernel advantage depends critically on embedding choice, revealingfundamental synergy between transformer attention and quantum feature spaces.This provides a practical pathway for scalable quantum machine learning thatleverages modern neural architectures.</description><author>Sebastián Andrés Cajas Ordóñez, Luis Fernando Torres Torres, Mario Bifulco, Carlos Andrés Durán, Cristian Bosch, Ricardo Simón Carbajo</author><pubDate>Mon, 10 Nov 2025 18:08:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.00024v2</guid></item><item><title>Sensitivity Analysis for Climate Science with Generative Flow Models</title><link>http://arxiv.org/abs/2511.00663v2</link><description>Sensitivity analysis is a cornerstone of climate science, essential forunderstanding phenomena ranging from storm intensity to long-term climatefeedbacks. However, computing these sensitivities using traditional physicalmodels is often prohibitively expensive in terms of both computation anddevelopment time. While modern AI-based generative models are orders ofmagnitude faster to evaluate, computing sensitivities with them remains asignificant bottleneck. This work addresses this challenge by applying theadjoint state method for calculating gradients in generative flow models. Weapply this method to the cBottle generative model, trained on ERA5 and ICONdata, to perform sensitivity analysis of any atmospheric variable with respectto sea surface temperatures. We quantitatively validate the computedsensitivities against the model's own outputs. Our results provide initialevidence that this approach can produce reliable gradients, reducing thecomputational cost of sensitivity analysis from weeks on a supercomputer with aphysical model to hours on a GPU, thereby simplifying a critical workflow inclimate science. The code can be found athttps://github.com/Kwartzl8/cbottle_adjoint_sensitivity.</description><author>Alex Dobra, Jakiw Pidstrigach, Tim Reichelt, Christian Schroeder de Witt, Philip Torr, Philip Stier</author><pubDate>Mon, 10 Nov 2025 18:07:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.00663v2</guid></item><item><title>Graph-Conditional Flow Matching for Relational Data Generation</title><link>http://arxiv.org/abs/2505.15668v2</link><description>Data synthesis is gaining momentum as a privacy-enhancing technology. Whilesingle-table tabular data generation has seen considerable progress, currentmethods for multi-table data often lack the flexibility and expressivenessneeded to capture complex relational structures. In particular, they strugglewith long-range dependencies and complex foreign-key relationships, such astables with multiple parent tables or multiple types of links between the samepair of tables. We propose a generative model for relational data thatgenerates the content of a relational dataset given the graph formed by theforeign-key relationships. We do this by learning a deep generative model ofthe content of the whole relational database by flow matching, where the neuralnetwork trained to denoise records leverages a graph neural network to obtaininformation from connected records. Our method is flexible, as it can supportrelational datasets with complex structures, and expressive, as the generationof each record can be influenced by any other record within the same connectedcomponent. We evaluate our method on several benchmark datasets and show thatit achieves state-of-the-art performance in terms of synthetic data fidelity.</description><author>Davide Scassola, Sebastiano Saccani, Luca Bortolussi</author><pubDate>Mon, 10 Nov 2025 18:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15668v2</guid></item><item><title>NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers</title><link>http://arxiv.org/abs/2511.02481v3</link><description>Partial differential equations (PDEs) underpin quantitative descriptionsacross the physical sciences and engineering, yet high-fidelity simulationremains a major computational bottleneck for many-query, real-time, and designtasks. Data-driven surrogates can be strikingly fast but are often unreliablewhen applied outside their training distribution. Here we introduce NeuralOperator Warm Starts (NOWS), a hybrid strategy that harnesses learned solutionoperators to accelerate classical iterative solvers by producing high-qualityinitial guesses for Krylov methods such as conjugate gradient and GMRES. NOWSleaves existing discretizations and solver infrastructures intact, integratingseamlessly with finite-difference, finite-element, isogeometric analysis,finite volume method, etc. Across our benchmarks, the learned initializationconsistently reduces iteration counts and end-to-end runtime, resulting in areduction of the computational time of up to 90 %, while preserving thestability and convergence guarantees of the underlying numerical algorithms. Bycombining the rapid inference of neural operators with the rigor of traditionalsolvers, NOWS provides a practical and trustworthy approach to acceleratehigh-fidelity PDE simulations.</description><author>Mohammad Sadegh Eshaghi, Cosmin Anitescu, Navid Valizadeh, Yizheng Wang, Xiaoying Zhuang, Timon Rabczuk</author><pubDate>Mon, 10 Nov 2025 17:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02481v3</guid></item><item><title>Estimation of aboveground biomass in a tropical dry forest: An intercomparison of airborne, unmanned, and space laser scanning</title><link>http://arxiv.org/abs/2510.27408v4</link><description>According to the Paris Climate Change Agreement, all nations are required tosubmit reports on their greenhouse gas emissions and absorption every two yearsby 2024. Consequently, forests play a crucial role in reducing carbonemissions, which is essential for meeting these obligations. Recognizing thesignificance of forest conservation in the global battle against climatechange, Article 5 of the Paris Agreement emphasizes the need for high-qualityforest data. This study focuses on enhancing methods for mapping abovegroundbiomass in tropical dry forests. Tropical dry forests are considered one of theleast understood tropical forest environments; therefore, there is a need foraccurate approaches to estimate carbon pools. We employ a comparative analysisof AGB estimates, utilizing different discrete and full-waveform laser scanningdatasets in conjunction with Ordinary Least Squares and Bayesian approachesSVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanningwere used as independent variables for extracting forest metrics. Variableselection, SVM regression tuning, and cross-validation via a machine-learningapproach were applied to account for overfitting and underfitting. The resultsindicate that six key variables primarily related to tree height:Elev\.minimum, Elev\.L3, lev\.MAD\.mode, Elev\.mode, Elev\.MAD\.median, andElev\.skewness, are important for AGB estimation using ALSD and ULSD, whileLeaf Area Index, canopy coverage and height, terrain elevation, andfull-waveform signal energy emerged as the most vital variables. AGB valuesestimated from ten permanent tropical dry forest plots in Costa Rica Guanacasteprovince ranged from 26.02 Mg/ha to 175.43 Mg/ha. The SVM regressionsdemonstrated a 17.89 error across all laser scanning systems, with SLSF Wexhibiting the lowest error 17.07 in estimating total biomass per plot.</description><author>Nelson Mattié, Arturo Sanchez-Azofeifa, Pablo Crespo-Peremarch, Juan-Ygnacio López-Hernández</author><pubDate>Mon, 10 Nov 2025 17:53:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.27408v4</guid></item><item><title>CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training</title><link>http://arxiv.org/abs/2510.18784v2</link><description>Despite significant work on low-bit quantization-aware training (QAT), thereis still an accuracy gap between such techniques and native training. Toaddress this, we introduce CAGE (Curvature-Aware Gradient Estimation), a newQAT method that augments the straight-through estimator (STE) gradient with acurvature-aware correction designed to counteract the loss increase induced byquantization. CAGE is derived from a multi-objective view of QAT that balancesloss minimization with the quantization constraints, yielding a principledcorrection term that depends on local curvature information. On the theoreticalside, we introduce the notion of Pareto-optimal solutions for quantizedoptimization, and establish that CAGE yields strong convergence guarantees inthe smooth non-convex setting. In terms of implementation, our approach isoptimizer-agnostic, but we provide a highly-efficient implementation thatleverages Adam statistics. CAGE significantly improves upon the priorstate-of-the-art methods in terms of accuracy, for similar computational cost:for QAT fine-tuning, it halves the compression accuracy loss relative to theprior best method, while for QAT pre-training of Llama models, its accuracy for3-bit weights-and-activations (W3A3) matches the accuracy achieved at 4-bits(W4A4) with the prior best method. The official implementation can be foundover https://github.com/IST-DASLab/CAGE .</description><author>Soroush Tabesh, Mher Safaryan, Andrei Panferov, Alexandra Volkova, Dan Alistarh</author><pubDate>Mon, 10 Nov 2025 17:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18784v2</guid></item><item><title>Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous Coefficients</title><link>http://arxiv.org/abs/2511.07347v1</link><description>Neural operators have emerged as powerful tools for learning solutionoperators of partial differential equations (PDEs). However, standard spectralmethods based on Fourier transforms struggle with problems involvingdiscontinuous coefficients due to the Gibbs phenomenon and poor representationof sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wavefunctions naturally suited for piecewise constant fields-combined withlearnable spectral weights that transform low-sequency Walsh coefficients tocapture global dependencies efficiently. We validate WHNO on three problems:steady-state Darcy flow (preliminary validation), heat conduction withdiscontinuous thermal conductivity, and the 2D Burgers equation withdiscontinuous initial conditions. In controlled comparisons with Fourier NeuralOperators (FNO) under identical conditions, WHNO demonstrates superior accuracywith better preservation of sharp solution features at material interfaces.Critically, we discover that weighted ensemble combinations of WHNO and FNOachieve substantial improvements over either model alone: for both heatconduction and Burgers equation, optimal ensembles reduce mean squared error by35-40 percent and maximum error by up to 25 percent compared to individualmodels. This demonstrates that Walsh-Hadamard and Fourier representationscapture complementary aspects of discontinuous PDE solutions, with WHNOexcelling at sharp interfaces while FNO captures smooth features effectively.</description><author>Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli</author><pubDate>Mon, 10 Nov 2025 17:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07347v1</guid></item><item><title>TNT: Improving Chunkwise Training for Test-Time Memorization</title><link>http://arxiv.org/abs/2511.07343v1</link><description>Recurrent neural networks (RNNs) with deep test-time memorization modules,such as Titans and TTT, represent a promising, linearly-scaling paradigmdistinct from Transformers. While these expressive models do not yet match thepeak performance of state-of-the-art Transformers, their potential has beenlargely untapped due to prohibitively slow training and low hardwareutilization. Existing parallelization methods force a fundamental conflictgoverned by the chunksize hyperparameter: large chunks boost speed but degradeperformance, necessitating a fixed, suboptimal compromise. To solve thischallenge, we introduce TNT, a novel training paradigm that decouples trainingefficiency from inference performance through a two-stage process. Stage one isan efficiency-focused pre-training phase utilizing a hierarchical memory. Aglobal module processes large, hardware-friendly chunks for long-range context,while multiple parallel local modules handle fine-grained details. Crucially,by periodically resetting local memory states, we break sequential dependenciesto enable massive context parallelization. Stage two is a brief fine-tuningphase where only the local memory modules are adapted to a smaller,high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluatedon Titans and TTT models, TNT achieves a substantial acceleration in trainingspeed-up to 17 times faster than the most accurate baseline configuration -while simultaneously improving model accuracy. This improvement removes acritical scalability barrier, establishing a practical foundation fordeveloping expressive RNNs and facilitating future work to close theperformance gap with Transformers.</description><author>Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi Karami, Meisam Razaviyayn, Vahab Mirrokni</author><pubDate>Mon, 10 Nov 2025 17:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07343v1</guid></item><item><title>Adaptive Group Robust Ensemble Knowledge Distillation</title><link>http://arxiv.org/abs/2411.14984v2</link><description>Neural networks can learn spurious correlations in the data, often leading toperformance degradation for underrepresented subgroups. Studies havedemonstrated that the disparity is amplified when knowledge is distilled from acomplex teacher model to a relatively ``simple'' student model. Prior work hasshown that ensemble deep learning methods can improve the performance of theworst-case subgroups; however, it is unclear if this advantage carries overwhen distilling knowledge from an ensemble of teachers, especially when theteacher models are debiased. This study demonstrates that traditional ensembleknowledge distillation can significantly drop the performance of the worst-casesubgroups in the distilled student model even when the teacher models aredebiased. To overcome this, we propose Adaptive Group Robust Ensemble KnowledgeDistillation (AGRE-KD), a simple ensembling strategy to ensure that the studentmodel receives knowledge beneficial for unknown underrepresented subgroups.Leveraging an additional biased model, our method selectively chooses teacherswhose knowledge would better improve the worst-performing subgroups byupweighting the teachers with gradient directions deviating from the biasedmodel. Our experiments on several datasets demonstrate the superiority of theproposed ensemble distillation technique and show that it can even outperformclassic model ensembles based on majority voting. Our source code is availableat https://github.com/patrikken/AGRE-KD</description><author>Patrik Kenfack, Ulrich Aïvodji, Samira Ebrahimi Kahou</author><pubDate>Mon, 10 Nov 2025 17:42:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.14984v2</guid></item><item><title>DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas</title><link>http://arxiv.org/abs/2511.07338v1</link><description>Simulating human profiles by instilling personas into large language models(LLMs) is rapidly transforming research in agentic behavioral simulation, LLMpersonalization, and human-AI alignment. However, most existing syntheticpersonas remain shallow and simplistic, capturing minimal attributes andfailing to reflect the rich complexity and diversity of real human identities.We introduce DEEPPERSONA, a scalable generative engine for synthesizingnarrative-complete synthetic personas through a two-stage, taxonomy-guidedmethod. First, we algorithmically construct the largest-ever human-attributetaxonomy, comprising over hundreds of hierarchically organized attributes, bymining thousands of real user-ChatGPT conversations. Second, we progressivelysample attributes from this taxonomy, conditionally generating coherent andrealistic personas that average hundreds of structured attributes and roughly 1MB of narrative text, two orders of magnitude deeper than prior works.Intrinsic evaluations confirm significant improvements in attribute diversity(32 percent higher coverage) and profile uniqueness (44 percent greater)compared to state-of-the-art baselines. Extrinsically, our personas enhanceGPT-4.1-mini's personalized question answering accuracy by 11.6 percent onaverage across ten metrics and substantially narrow (by 31.7 percent) the gapbetween simulated LLM citizens and authentic human responses in social surveys.Our generated national citizens reduced the performance gap on the Big Fivepersonality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONAthus provides a rigorous, scalable, and privacy-free platform for high-fidelityhuman simulation and personalized AI research.</description><author>Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man Yao, Luoshang Pan</author><pubDate>Mon, 10 Nov 2025 17:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07338v1</guid></item><item><title>Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for VLM Hallucination Mitigation</title><link>http://arxiv.org/abs/2510.22067v2</link><description>Vision language models (VLMs) often generate hallucination, i.e., contentthat cannot be substantiated by either textual or visual inputs. Prior workprimarily attributes this to over-reliance on linguistic prior knowledge ratherthan visual inputs. Some methods attempt to mitigate hallucination byamplifying visual token attention proportionally to their attention scores.However, these methods overlook the visual attention sink problem, whereattention is frequently misallocated to task-irrelevant visual regions, andneglect cross-modal fusion balance by enhancing only visual attention withoutadjusting attention to the user query. This can result in amplifying incorrectareas while failing to properly interpret the user query. To address thesechallenges, we propose a simple yet effective method called Gaze Shift-GuidedCross-modal Fusion Enhancement (GIFT). GIFT pre-computes a holistic visualsaliency map by tracking positive changes in visual attention, or "gazeshifts", during user query comprehension, and leverages this map to amplifyattention to both salient visual information and the user query at eachdecoding step. This reduces the impact of visual attention sink, as irrelevanttokens exhibit minimal shifts, while ensuring balanced cross-modal fusion forwell-integrated representation. Extensive experiments show that GIFTeffectively mitigates hallucination in VLMs across both generative andclassification tasks, achieving up to 20.7% improvement over greedy decoding,while maintaining general vision-language performance with low computationaloverhead.</description><author>Zheng Qi, Chao Shang, Evangelia Spiliopoulou, Nikolaos Pappas</author><pubDate>Mon, 10 Nov 2025 17:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.22067v2</guid></item><item><title>Grounding Computer Use Agents on Human Demonstrations</title><link>http://arxiv.org/abs/2511.07332v1</link><description>Building reliable computer-use agents requires grounding: accuratelyconnecting natural language instructions to the correct on-screen elements.While large datasets exist for web and mobile interactions, high-qualityresources for desktop environments are limited. To address this gap, weintroduce GroundCUA, a large-scale desktop grounding dataset built from experthuman demonstrations. It covers 87 applications across 12 categories andincludes 56K screenshots, with every on-screen element carefully annotated fora total of over 3.56M human-verified annotations. From these demonstrations, wegenerate diverse instructions that capture a wide range of real-world tasks,providing high-quality data for model training. Using GroundCUA, we develop theGroundNext family of models that map instructions to their target UI elements.At both 3B and 7B scales, GroundNext achieves state-of-the-art results acrossfive benchmarks using supervised fine-tuning, while requiring less thanone-tenth the training data of prior work. Reinforcement learning post-trainingfurther improves performance, and when evaluated in an agentic setting on theOSWorld benchmark using o3 as planner, GroundNext attains comparable orsuperior results to models trained with substantially more data,. These resultsdemonstrate the critical role of high-quality, expert-driven datasets inadvancing general-purpose computer-use agents.</description><author>Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar</author><pubDate>Mon, 10 Nov 2025 17:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07332v1</guid></item><item><title>Which Similarity-Sensitive Entropy?</title><link>http://arxiv.org/abs/2511.03849v2</link><description>A canonical step in quantifying a system is to measure its entropy. Shannonentropy and other traditional entropy measures capture only the informationencoded in the frequencies of a system's elements. Recently, Leinster, Cobbold,and Reeve (LCR) introduced a method that also captures the rich informationencoded in the similarities and differences among elements, yieldingsimilarity-sensitive entropy. More recently, the Vendi score (VS) wasintroduced as an alternative, raising the question of how LCR and VS compare,and which is preferable. Here we address these questions conceptually,analytically, and experimentally, using 53 machine-learning datasets. We showthat LCR and VS can differ by orders of magnitude and can capture complementaryinformation about a system, except in limiting cases. We demonstrate that bothLCR and VS depend on how similarities are scaled and introduce the concept of``half distance'' to parameterize this dependence. We prove that VS provides anupper bound on LCR for several values of the R\'enyi-Hill order parameter andconjecture that this bound holds for all values. We conclude that VS ispreferable only when interpreting elements as linear combinations of a morefundamental set of ``ur-elements'' or when the system or dataset possesses aquantum-mechanical character. In the broader circumstance where one seekssimply to capture the rich information encoded by similarity, LCR is favored;nevertheless, for certain half-distances the two methods can complement eachother.</description><author>Phuc Nguyen, Josiah Couch, Rahul Bansal, Alexandra Morgan, Chris Tam, Miao Li, Rima Arnaout, Ramy Arnaout</author><pubDate>Mon, 10 Nov 2025 17:32:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03849v2</guid></item><item><title>Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis</title><link>http://arxiv.org/abs/2511.07329v1</link><description>It introduces FractalNet, a fractal-inspired computational architectures foradvanced large language model analysis that mainly challenges model diversityon a large scale in an efficient manner. The new set-up involves atemplate-driven generator, runner, and evaluation framework that, throughsystematic permutations of convolutional, normalization, activation, anddropout layers, can create more than 1,200 variants of neural networks. Fractaltemplates allow for structural recursion and multi-column pathways, thus,models become deeper and wider in a balanced way. Training utilizes PyTorch,Automatic Mixed Precision (AMP), and gradient checkpointing and is carried outon the CIFAR-10 dataset for five epochs. The outcomes show that fractal-basedarchitectures are capable of strong performance and are computationallyefficient. The paper positions fractal design as a feasible andresource-efficient method of automated architecture exploration.</description><author>Yash Mittal, Dmitry Ignatov, Radu Timofte</author><pubDate>Mon, 10 Nov 2025 17:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07329v1</guid></item><item><title>Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training</title><link>http://arxiv.org/abs/2511.07328v1</link><description>Retrieval-Augmented Generation (RAG) methods enhance LLM performance byefficiently filtering relevant context for LLMs, reducing hallucinations andinference cost. However, most existing RAG methods focus on single-stepretrieval, which is often insufficient for answering complex questions thatrequire multi-step search. Recently, multi-step retrieval approaches haveemerged, typically involving the fine-tuning of small LLMs to performmulti-step retrieval. This type of fine-tuning is highly resource-intensive anddoes not enable the use of larger LLMs. In this work, we propose Q-RAG, a novelapproach that fine-tunes the Embedder model for multi-step retrieval usingreinforcement learning (RL). Q-RAG offers a competitive, resource-efficientalternative to existing multi-step retrieval methods for open-domain questionanswering and achieves state-of-the-art results on the popular long-contextbenchmarks Babilong and RULER for contexts up to 10M tokens.</description><author>Artyom Sorokin, Nazar Buzun, Alexander Anokhin, Oleg Inozemcev, Egor Vedernikov, Petr Anokhin, Mikhail Burtsev, Trushkov Alexey, Yin Wenshuai, Evgeny Burnaev</author><pubDate>Mon, 10 Nov 2025 17:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07328v1</guid></item><item><title>IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction</title><link>http://arxiv.org/abs/2511.07327v1</link><description>Recent advances in deep-research agents have shown promise for autonomousknowledge construction through dynamic reasoning over external sources.However, existing approaches rely on a mono-contextual paradigm thataccumulates all information in a single, expanding context window, leading tocontext suffocation and noise contamination that limit their effectiveness onlong-horizon tasks. We introduce IterResearch, a novel iterative deep-researchparadigm that reformulates long-horizon research as a Markov Decision Processwith strategic workspace reconstruction. By maintaining an evolving report asmemory and periodically synthesizing insights, our approach preservesconsistent reasoning capacity across arbitrary exploration depths. We furtherdevelop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learningframework that incentivizes efficient exploration through geometric rewarddiscounting and enables stable distributed training via adaptive downsampling.Extensive experiments demonstrate that IterResearch achieves substantialimprovements over existing open-source agents with average +14.5pp across sixbenchmarks and narrows the gap with frontier proprietary systems. Remarkably,our paradigm exhibits unprecedented interaction scaling, extending to 2048interactions with dramatic performance gains (from 3.5\% to 42.5\%), and servesas an effective prompting strategy, improving frontier models by up to 19.2ppover ReAct on long-horizon tasks. These findings position IterResearch as aversatile solution for long-horizon reasoning, effective both as a trainedagent and as a prompting paradigm for frontier models.</description><author>Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</author><pubDate>Mon, 10 Nov 2025 17:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07327v1</guid></item><item><title>Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions</title><link>http://arxiv.org/abs/2511.04665v2</link><description>Robotic manipulation policies are advancing rapidly, but their directevaluation in the real world remains costly, time-consuming, and difficult toreproduce, particularly for tasks involving deformable objects. Simulationprovides a scalable and systematic alternative, yet existing simulators oftenfail to capture the coupled visual and physical complexity of soft-bodyinteractions. We present a real-to-sim policy evaluation framework thatconstructs soft-body digital twins from real-world videos and renders robots,objects, and environments with photorealistic fidelity using 3D GaussianSplatting. We validate our approach on representative deformable manipulationtasks, including plush toy packing, rope routing, and T-block pushing,demonstrating that simulated rollouts correlate strongly with real-worldexecution performance and reveal key behavioral patterns of learned policies.Our results suggest that combining physics-informed reconstruction withhigh-quality rendering enables reproducible, scalable, and accurate evaluationof robotic manipulation policies. Website: https://real2sim-eval.github.io/</description><author>Kaifeng Zhang, Shuo Sha, Hanxiao Jiang, Matthew Loper, Hyunjong Song, Guangyan Cai, Zhuo Xu, Xiaochen Hu, Changxi Zheng, Yunzhu Li</author><pubDate>Mon, 10 Nov 2025 17:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.04665v2</guid></item><item><title>Garbage Vulnerable Point Monitoring using IoT and Computer Vision</title><link>http://arxiv.org/abs/2511.07325v1</link><description>This paper proposes a smart way to manage municipal solid waste by using theInternet of Things (IoT) and computer vision (CV) to monitor illegal wastedumping at garbage vulnerable points (GVPs) in urban areas. The system canquickly detect and monitor dumped waste using a street-level camera and objectdetection algorithm. Data was collected from the Sangareddy district inTelangana, India. A series of comprehensive experiments was carried out usingthe proposed dataset to assess the accuracy and overall performance of variousobject detection models. Specifically, we performed an in-depth evaluation ofYOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,YOLO11m achieved the highest accuracy of 92.39\% in waste detection,demonstrating its effectiveness in detecting waste. Additionally, it attains anmAP@50 of 0.91, highlighting its high precision. These findings confirm thatthe object detection model is well-suited for monitoring and tracking wastedumping events at GVP locations. Furthermore, the system effectively captureswaste disposal patterns, including hourly, daily, and weekly dumping trends,ensuring comprehensive daily and nightly monitoring.</description><author>R. Kumar, A. Lall, S. Chaudhari, M. Kale, A. Vattem</author><pubDate>Mon, 10 Nov 2025 17:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07325v1</guid></item><item><title>FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation</title><link>http://arxiv.org/abs/2511.07322v1</link><description>While LLMs have shown great success in financial tasks like stock predictionand question answering, their application in fully automating Equity ResearchReport generation remains uncharted territory. In this paper, we formulate theEquity Research Report (ERR) Generation task for the first time. To address thedata scarcity and the evaluation metrics absence, we present an open-sourceevaluation benchmark for ERR generation - FinRpt. We frame a DatasetConstruction Pipeline that integrates 7 financial data types and produces ahigh-quality ERR dataset automatically, which could be used for model trainingand evaluation. We also introduce a comprehensive evaluation system including11 metrics to assess the generated ERRs. Moreover, we propose a multi-agentframework specifically tailored to address this task, named FinRpt-Gen, andtrain several LLM-based agents on the proposed datasets using SupervisedFine-Tuning and Reinforcement Learning. Experimental results indicate the dataquality and metrics effectiveness of the benchmark FinRpt and the strongperformance of FinRpt-Gen, showcasing their potential to drive innovation inthe ERR generation field. All code and datasets are publicly available.</description><author>Song Jin, Shuqi Li, Shukun Zhang, Rui Yan</author><pubDate>Mon, 10 Nov 2025 17:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07322v1</guid></item><item><title>YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2511.07321v1</link><description>Fast and flexible 3D scene reconstruction from unstructured image collectionsremains a significant challenge. We present YoNoSplat, a feedforward model thatreconstructs high-quality 3D Gaussian Splatting representations from anarbitrary number of images. Our model is highly versatile, operatingeffectively with both posed and unposed, calibrated and uncalibrated inputs.YoNoSplat predicts local Gaussians and camera poses for each view, which areaggregated into a global representation using either predicted or providedposes. To overcome the inherent difficulty of jointly learning 3D Gaussians andcamera parameters, we introduce a novel mixing training strategy. This approachmitigates the entanglement between the two tasks by initially usingground-truth poses to aggregate local Gaussians and gradually transitioning toa mix of predicted and ground-truth poses, which prevents both traininginstability and exposure bias. We further resolve the scale ambiguity problemby a novel pairwise camera-distance normalization scheme and by embeddingcamera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsicparameters, making it feasible for uncalibrated inputs. YoNoSplat demonstratesexceptional efficiency, reconstructing a scene from 100 views (at 280x518resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achievesstate-of-the-art performance on standard benchmarks in both pose-free andpose-dependent settings. Our project page is athttps://botaoye.github.io/yonosplat/.</description><author>Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys</author><pubDate>Mon, 10 Nov 2025 17:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07321v1</guid></item><item><title>When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs</title><link>http://arxiv.org/abs/2511.07318v1</link><description>Despite substantial advances, large language models (LLMs) continue toexhibit hallucinations, generating plausible yet incorrect responses. In thispaper, we highlight a critical yet previously underexplored class ofhallucinations driven by spurious correlations -- superficial but statisticallyprominent associations between features (e.g., surnames) and attributes (e.g.,nationality) present in the training data. We demonstrate that these spuriouscorrelations induce hallucinations that are confidently generated, immune tomodel scaling, evade current detection methods, and persist even after refusalfine-tuning. Through systematically controlled synthetic experiments andempirical evaluations on state-of-the-art open-source and proprietary LLMs(including GPT-5), we show that existing hallucination detection methods, suchas confidence-based filtering and inner-state probing, fundamentally fail inthe presence of spurious correlations. Our theoretical analysis furtherelucidates why these statistical biases intrinsically undermineconfidence-based detection techniques. Our findings thus emphasize the urgentneed for new approaches explicitly designed to address hallucinations caused byspurious correlations.</description><author>Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li</author><pubDate>Mon, 10 Nov 2025 17:19:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07318v1</guid></item><item><title>Bridging Weakly-Supervised Learning and VLM Distillation: Noisy Partial Label Learning for Efficient Downstream Adaptation</title><link>http://arxiv.org/abs/2506.03229v2</link><description>In the context of noisy partial label learning (NPLL), each training sampleis associated with a set of candidate labels annotated by multiple noisyannotators. With the emergence of high-performance pre-trained vision-languagemodels (VLMs) such as CLIP, LLaVA and GPT-4V, the direction of using thesemodels to replace time-consuming manual annotation workflows and achieve``manual-annotation-free" training for downstream tasks has become a highlypromising research avenue. This paper focuses on learning from noisy partiallabels annotated by pre-trained VLMs and proposes an innovative collaborativeconsistency regularization (Co-Reg) method. Unlike the symmetric noiseprimarily addressed in traditional noisy label learning, the noise generated bypre-trained models is instance-dependent, embodying the underlying patterns ofthe pre-trained models themselves, which significantly increases the learningdifficulty for the model. To address this, we simultaneously train two neuralnetworks that implement collaborative purification of training labels through a``Co-Pseudo-Labeling" mechanism, while enforcing consistency regularizationconstraints in both the label space and feature representation space.Specifically, we construct multiple anti-overfitting mechanisms thatefficiently mine latent information from noisy partially labeled samplesincluding alternating optimization of contrastive feature representations andpseudo-labels, as well as maintaining prototypical class vectors in the sharedfeature space.</description><author>Qian-Wei Wang, Yuqiu Xie, Letian Zhang, Zimo Liu, Shu-Tao Xia</author><pubDate>Mon, 10 Nov 2025 17:19:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.03229v2</guid></item><item><title>RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments</title><link>http://arxiv.org/abs/2511.07317v1</link><description>We introduce Reinforcement Learning (RL) with Adaptive VerifiableEnvironments (RLVE), an approach using verifiable environments thatprocedurally generate problems and provide algorithmically verifiable rewards,to scale up RL for language models (LMs). RLVE enables each verifiableenvironment to dynamically adapt its problem difficulty distribution to thepolicy model's capabilities as training progresses. In contrast, static datadistributions often lead to vanishing learning signals when problems are eithertoo easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, alarge-scale suite of 400 verifiable environments carefully developed throughmanual environment engineering. Using RLVE-Gym, we show that environmentscaling, i.e., expanding the collection of training environments, consistentlyimproves generalizable reasoning capabilities. RLVE with joint training acrossall 400 environments in RLVE-Gym yields a 3.37% absolute average improvementacross six reasoning benchmarks, starting from one of the strongest 1.5Breasoning LMs. By comparison, continuing this LM's original RL training yieldsonly a 0.49% average absolute gain despite using over 3x more compute. Werelease our code publicly.</description><author>Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei Koh, Hannaneh Hajishirzi</author><pubDate>Mon, 10 Nov 2025 17:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07317v1</guid></item><item><title>De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures Geometry</title><link>http://arxiv.org/abs/2511.07313v1</link><description>Functional connectivity has been widely investigated to understand braindisease in clinical studies and imaging-based neuroscience, and analyzingchanges in functional connectivity has proven to be valuable for understandingand computationally evaluating the effects on brain function caused by diseasesor experimental stimuli. By using Mahalanobis data whitening prior to the useof dimensionality reduction algorithms, we are able to distill meaningfulinformation from fMRI signals about subjects and the experimental stimuli usedto prompt them. Furthermore, we offer an interpretation of Mahalanobiswhitening as a two-stage de-individualization of data which is motivated bysimilarity as captured by the Bures distance, which is connected to quantummechanics. These methods have potential to aid discoveries about the mechanismsthat link brain function with cognition and behavior and may improve theaccuracy and consistency of Alzheimer's diagnosis, especially in thepreclinical stage of disease progression.</description><author>Aaron Jacobson, Tingting Dan, Martin Styner, Guorong Wu, Shahar Kovalsky, Caroline Moosmueller</author><pubDate>Mon, 10 Nov 2025 17:14:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07313v1</guid></item><item><title>Revisiting Stochastic Approximation and Stochastic Gradient Descent</title><link>http://arxiv.org/abs/2505.11343v3</link><description>In this paper, we introduce a new approach to proving the convergence of theStochastic Approximation (SA) and the Stochastic Gradient Descent (SGD)algorithms. The new approach is based on a concept called GSLLN (GeneralizedStrong Law of Large Numbers), which extends the traditional SLLN. Using thisconcept, we provide sufficient conditions for convergence, which effectivelydecouple the properties of the function whose zero we are trying to find, fromthe properties of the measurement errors (noise sequence). The new approachprovides an alternative to the two widely used approaches, namely the ODEapproach and the martingale approach, and also permits a wider class of noisesignals than either of the two known approaches. In particular, the ``noise''or measurement error \textit{need not} have a finite second moment, and undersuitable conditions, not even a finite mean. By adapting this method of proof,we also derive sufficient conditions for the convergence of zero-order SGD,wherein the stochastic gradient is computed using $2d$ function evaluations,but no gradient computations. The sufficient conditions derived here are theweakest to date, thus leading to a considerable expansion of the applicabilityof SA and SGD theory.</description><author>Rajeeva Laxman Karandikar, Bhamidi Visweswara Rao, Mathukumalli Vidyasagar</author><pubDate>Mon, 10 Nov 2025 17:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.11343v3</guid></item><item><title>Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search</title><link>http://arxiv.org/abs/2511.07312v1</link><description>Few classical games have been regarded as such significant benchmarks ofartificial intelligence as to have justified training costs in the millions ofdollars. Among these, Stratego -- a board wargame exemplifying the challenge ofstrategic decision making under massive amounts of hidden information -- standsapart as a case where such efforts failed to produce performance at the levelof top humans. This work establishes a step change in both performance and costfor Stratego, showing that it is now possible not only to reach the level oftop humans, but to achieve vastly superhuman level -- and that doing sorequires not an industrial budget, but merely a few thousand dollars. Weachieved this result by developing general approaches for self-playreinforcement learning and test-time search under imperfect information.</description><author>Samuel Sokota, Eugene Vinitsky, Hengyuan Hu, J. Zico Kolter, Gabriele Farina</author><pubDate>Mon, 10 Nov 2025 17:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07312v1</guid></item><item><title>When Bias Helps Learning: Bridging Initial Prejudice and Trainability</title><link>http://arxiv.org/abs/2505.12096v3</link><description>Understanding the statistical properties of deep neural networks (DNNs) atinitialization is crucial for elucidating both their trainability and theintrinsic architectural biases they encode prior to data exposure. Mean-field(MF) analyses have demonstrated that the parameter distribution in randomlyinitialized networks dictates whether gradients vanish or explode. Recent workhas shown that untrained DNNs exhibit an initial-guessing bias (IGB), in whichlarge regions of the input space are assigned to a single class. In this work,we provide a theoretical proof linking IGB to MF analyses, establishing that anetwork predisposition toward specific classes is intrinsically tied to theconditions for efficient learning. This connection leads to a counterintuitiveconclusion: the initialization that optimizes trainability is systematicallybiased rather than neutral. We validate our theory through experiments acrossmultiple architectures and datasets.</description><author>Alberto Bassi, Marco Baity-Jesi, Aurelien Lucchi, Carlo Albert, Emanuele Francazi</author><pubDate>Mon, 10 Nov 2025 17:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12096v3</guid></item><item><title>ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding</title><link>http://arxiv.org/abs/2511.07311v1</link><description>Automatic ICD coding, the task of assigning disease and procedure codes toelectronic medical records, is crucial for clinical documentation and billing.While existing methods primarily enhance model understanding of codehierarchies and synonyms, they often overlook the pervasive use of medicalacronyms in clinical notes, a key factor in ICD code inference. To address thisgap, we propose a novel effective data augmentation technique that leverageslarge language models to expand medical acronyms, allowing models to be trainedon their full form representations. Moreover, we incorporate consistencytraining to regularize predictions by enforcing agreement between the originaland augmented documents. Extensive experiments on the MIMIC-III datasetdemonstrate that our approach, ACE-ICD establishes new state-of-the-artperformance across multiple settings, including common codes, rare codes, andfull-code assignments. Our code is publicly available.</description><author>Tuan-Dung Le, Shohreh Haddadan, Thanh Q. Thieu</author><pubDate>Mon, 10 Nov 2025 17:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07311v1</guid></item><item><title>Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the Thermodynamics of an Ideal Gas?</title><link>http://arxiv.org/abs/2511.07308v1</link><description>Understanding the training dynamics of deep neural networks remains a majoropen problem, with physics-inspired approaches offering promising insights.Building on this perspective, we develop a thermodynamic framework to describethe stationary distributions of stochastic gradient descent (SGD) with weightdecay for scale-invariant neural networks, a setting that both reflectspractical architectures with normalization layers and permits theoreticalanalysis. We establish analogies between training hyperparameters (e.g.,learning rate, weight decay) and thermodynamic variables such as temperature,pressure, and volume. Starting with a simplified isotropic noise model, weuncover a close correspondence between SGD dynamics and ideal gas behavior,validated through theory and simulation. Extending to training of neuralnetworks, we show that key predictions of the framework, including the behaviorof stationary entropy, align closely with experimental observations. Thisframework provides a principled foundation for interpreting training dynamicsand may guide future work on hyperparameter tuning and the design of learningrate schedulers.</description><author>Ildus Sadrtdinov, Ekaterina Lobacheva, Ivan Klimov, Mikhail I. Katsnelson, Dmitry Vetrov</author><pubDate>Mon, 10 Nov 2025 17:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07308v1</guid></item><item><title>Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning Approach for Bangla Hate Speech Identification</title><link>http://arxiv.org/abs/2511.07304v1</link><description>This paper addresses the problem of Bangla hate speech identification, asocially impactful yet linguistically challenging task. As part of the "BanglaMulti-task Hate Speech Identification" shared task at the BLP Workshop,IJCNLP-AACL 2025, our team "Retriv" participated in all three subtasks: (1A)hate type classification, (1B) target group identification, and (1C) jointdetection of type, severity, and target. For subtasks 1A and 1B, we employed asoft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2).For subtask 1C, we trained three multitask variants and aggregated theirpredictions through a weighted voting ensemble. Our systems achieved micro-f1scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62%(1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7thpositions, respectively. These results highlight the promise of transformerensembles and weighted multitask frameworks for advancing Bangla hate speechdetection in low-resource contexts. We made experimental scripts publiclyavailable for the community.</description><author>Sourav Saha, K M Nafi Asib, Mohammed Moshiul Hoque</author><pubDate>Mon, 10 Nov 2025 17:07:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07304v1</guid></item><item><title>Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection</title><link>http://arxiv.org/abs/2511.07301v1</link><description>Source-Free Object Detection (SFOD) aims to adapt a source-pretrained objectdetector to a target domain without access to source data. However, existingSFOD methods predominantly rely on internal knowledge from the source model,which limits their capacity to generalize across domains and often results inbiased pseudo-labels, thereby hindering both transferability anddiscriminability. In contrast, Vision Foundation Models (VFMs), pretrained onmassive and diverse data, exhibit strong perception capabilities and broadgeneralization, yet their potential remains largely untapped in the SFODsetting. In this paper, we propose a novel SFOD framework that leverages VFMsas external knowledge sources to jointly enhance feature alignment and labelquality. Specifically, we design three VFM-based modules: (1) Patch-weightedGlobal Feature Alignment (PGFA) distills global features from VFMs usingpatch-similarity-based weighting to enhance global feature transferability; (2)Prototype-based Instance Feature Alignment (PIFA) performs instance-levelcontrastive learning guided by momentum-updated VFM prototypes; and (3)Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions fromdetection VFMs and teacher models via an entropy-aware strategy to yield morereliable supervision. Extensive experiments on six benchmarks demonstrate thatour method achieves state-of-the-art SFOD performance, validating theeffectiveness of integrating VFMs to simultaneously improve transferability anddiscriminability.</description><author>Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong</author><pubDate>Mon, 10 Nov 2025 17:06:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07301v1</guid></item><item><title>Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network</title><link>http://arxiv.org/abs/2507.20765v2</link><description>Hyperspectral imagers on satellites obtain the fine spectral signaturesessential for distinguishing one material from another at the expense oflimited spatial resolution. Enhancing the latter is thus a desirablepreprocessing step in order to further improve the detection capabilitiesoffered by hyperspectral images on downstream tasks. At the same time, there isa growing interest towards deploying inference methods directly onboard ofsatellites, which calls for lightweight image super-resolution methods that canbe run on the payload in real time. In this paper, we present a novel neuralnetwork design, called Deep Pushbroom Super-Resolution (DPSR) that matches thepushbroom acquisition of hyperspectral sensors by processing an image line byline in the along-track direction with a causal memory mechanism to exploitpreviously acquired lines. This design greatly limits memory requirements andcomputational complexity, achieving onboard real-time performance, i.e., theability to super-resolve a line in the time it takes to acquire the next one,on low-power hardware. Experiments show that the quality of the super-resolvedimages is competitive or even outperforms state-of-the-art methods that aresignificantly more complex.</description><author>Davide Piccinini, Diego Valsesia, Enrico Magli</author><pubDate>Mon, 10 Nov 2025 17:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.20765v2</guid></item><item><title>Multiple Streams of Knowledge Retrieval: Enriching and Recalling in Transformers</title><link>http://arxiv.org/abs/2506.20746v2</link><description>When an LLM learns a new fact during finetuning (e.g., new movie releases,newly elected pope, etc.), where does this information go? Are entitiesenriched with relation information, or do models recall informationjust-in-time before a prediction? Or, are ``all of the above'' true with LLMsimplementing multiple redundant heuristics? Existing localization approaches(e.g., activation patching) are ill-suited for this analysis because theyusually \textit{replace} parts of the residual stream, thus overriding previousinformation. To fill this gap, we propose \emph{dynamic weight grafting}, atechnique that selectively grafts weights from a finetuned model onto apretrained model. Using this technique, we show two separate pathways forretrieving finetuned relation information: 1) ``enriching" the residual streamwith relation information while processing the tokens that correspond to anentity (e.g., ``Zendaya'' in ``Zendaya co-starred with John David Washington'')and 2) ``recalling" this information at the final token position beforegenerating a target fact. In some cases, models need information from both ofthese pathways to correctly generate finetuned facts while, in other cases,either the ``enrichment" or ``recall" pathway alone is sufficient. We localizethe ``recall'' pathway to model components -- finding that ``recall" occurs viaboth task-specific attention mechanisms and an entity-specific extraction stepin the feedforward networks of the final layers before the target prediction.By targeting model components and parameters, as opposed to just activations,we are able to understand the \textit{mechanisms} by which finetuned knowledgeis retrieved during generation.</description><author>Todd Nief, David Reber, Sean Richardson, Ari Holtzman</author><pubDate>Mon, 10 Nov 2025 17:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.20746v2</guid></item><item><title>From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching</title><link>http://arxiv.org/abs/2505.24843v2</link><description>Models that learn spurious correlations from training data often fail whendeployed in new environments. While many methods aim to learn invariantrepresentations to address this, they often underperform standard empiricalrisk minimization (ERM). We propose a data-centric alternative that shifts thefocus from learning invariant representations to leveraging invariant datapairs -- pairs of samples that should have the same prediction. We prove thatcertain counterfactuals naturally satisfy this invariance property. Based onthis, we introduce Noisy Counterfactual Matching (NCM), a simpleconstraint-based method that improves robustness by leveraging even a smallnumber of \emph{noisy} counterfactual pairs -- improving upon prior works thatdo not explicitly consider noise. For linear causal models, we prove that NCM'stest-domain error is bounded by its in-domain error plus a term dependent onthe counterfactuals' quality and diversity. Experiments on synthetic datavalidate our theory, and we demonstrate NCM's effectiveness on real-worlddatasets.</description><author>Ruqi Bai, Yao Ji, Zeyu Zhou, David I. Inouye</author><pubDate>Mon, 10 Nov 2025 16:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.24843v2</guid></item><item><title>LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging</title><link>http://arxiv.org/abs/2511.07298v1</link><description>Low-dose computed tomography (CT) represents a significant improvement inpatient safety through lower radiation doses, but increased noise, blur, andcontrast loss can diminish diagnostic quality. Therefore, consistency androbustness in image quality assessment become essential for clinicalapplications. In this study, we propose an LLM-based quality assessment systemthat generates both numerical scores and textual descriptions of degradationssuch as noise, blur, and contrast loss. Furthermore, various inferencestrategies - from the zero-shot approach to metadata integration and errorfeedback - are systematically examined, demonstrating the progressivecontribution of each method to overall performance. The resultant assessmentsyield not only highly correlated scores but also interpretable output, therebyadding value to clinical workflows. The source codes of our study are availableat https://github.com/itu-biai/lmms_ldct_iqa.</description><author>Kagan Celik, Mehmet Ozan Unal, Metin Ertas, Isa Yildirim</author><pubDate>Mon, 10 Nov 2025 16:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07298v1</guid></item><item><title>VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models</title><link>http://arxiv.org/abs/2511.07299v1</link><description>Video anomaly understanding (VAU) aims to provide detailed interpretation andsemantic comprehension of anomalous events within videos, addressinglimitations of traditional methods that focus solely on detecting andlocalizing anomalies. However, existing approaches often neglect the deepercausal relationships and interactions between objects, which are critical forunderstanding anomalous behaviors. In this paper, we propose VADER, anLLM-driven framework for Video Anomaly unDErstanding, which integrates keyframeobject Relation features with visual cues to enhance anomaly comprehension fromvideo. Specifically, VADER first applies an Anomaly Scorer to assign per-frameanomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capturethe causal context of each anomalous event. A Relation Feature Extractor and aCOntrastive Relation Encoder (CORE) jointly model dynamic object interactions,producing compact relational representations for downstream reasoning. Thesevisual and relational cues are integrated with LLMs to generate detailed,causally grounded descriptions and support robust anomaly-related questionanswering. Experiments on multiple real-world VAU benchmarks demonstrate thatVADER achieves strong results across anomaly description, explanation, andcausal reasoning tasks, advancing the frontier of explainable video anomalyanalysis.</description><author>Ying Cheng, Yu-Ho Lin, Min-Hung Chen, Fu-En Yang, Shang-Hong Lai</author><pubDate>Mon, 10 Nov 2025 16:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07299v1</guid></item><item><title>Who Is the Story About? Protagonist Entity Recognition in News</title><link>http://arxiv.org/abs/2511.07296v1</link><description>News articles often reference numerous organizations, but traditional NamedEntity Recognition (NER) treats all mentions equally, obscuring which entitiesgenuinely drive the narrative. This limits downstream tasks that rely onunderstanding event salience, influence, or narrative focus. We introduceProtagonist Entity Recognition (PER), a task that identifies the organizationsthat anchor a news story and shape its main developments. To validate PER, wecompare he predictions of Large Language Models (LLMs) against annotations fromfour expert annotators over a gold corpus, establishing both inter-annotatorconsistency and human-LLM agreement. Leveraging these findings, we usestate-of-the-art LLMs to automatically label large-scale news collectionsthrough NER-guided prompting, generating scalable, high-quality supervision. Wethen evaluate whether other LLMs, given reduced context and without explicitcandidate guidance, can still infer the correct protagonists. Our resultsdemonstrate that PER is a feasible and meaningful extension tonarrative-centered information extraction, and that guided LLMs can approximatehuman judgments of narrative importance at scale.</description><author>Jorge Gabín, M. Eduardo Ares, Javier Parapar</author><pubDate>Mon, 10 Nov 2025 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07296v1</guid></item><item><title>VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized Inference</title><link>http://arxiv.org/abs/2509.24257v3</link><description>Decentralized inference provides a scalable and resilient paradigm forserving large language models (LLMs), enabling distributed resource utilizationand reducing reliance on centralized providers. However, in a permissionlessenvironment without trusted nodes, ensuring the correctness of model outputsremains a core challenge. We introduce VeriLLM, a publicly verifiable protocolfor decentralized LLM inference that achieves security under aone-honest-verifier assumption while maintaining practical efficiency. VeriLLMcombines lightweight empirical rerunning with cryptographic commitments,allowing verifiers to validate results at approximately 1% of the underlyinginference cost. To prevent verification bottlenecks, we design an isomorphicinference-verification architecture that multiplexes both inference andverification roles across the same GPU workers. This design (i) improves GPUutilization and overall throughput, (ii) enlarges the effective validator set,enhancing robustness and liveness, and (iii) enforces task indistinguishabilityto prevent node-specific optimizations or selective behavior. Throughtheoretical analysis and system-level evaluation, we show that VeriLLM achievesreliable public verifiability with minimal overhead, offering a practicalfoundation for trustworthy and scalable decentralized LLM inference.</description><author>Ke Wang, Zishuo Zhao, Xinyuan Song, Bill Shi, Libin Xia, Chris Tong, Lynn Ai, Felix Qu, Eric Yang</author><pubDate>Mon, 10 Nov 2025 16:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24257v3</guid></item><item><title>Universal Spectral Tokenization via Self-Supervised Panchromatic Representation Learning</title><link>http://arxiv.org/abs/2510.17959v2</link><description>Sequential scientific data span many resolutions and domains, and unifyingthem into a common representation is a key step toward developing foundationmodels for the sciences. Astronomical spectra exemplify this challenge: massivesurveys have collected millions of spectra across a wide range of wavelengthsand resolutions, yet analyses remain fragmented across spectral domains (e.g.,optical vs. infrared) and object types (e.g., stars vs. galaxies), limiting theability to pool information across datasets. We present a deep learning modelthat jointly learns from heterogeneous spectra in a self-supervised manner. Ouruniversal spectral tokenizer processes spectra from a variety of object typesand resolutions directly on their native wavelength grids, producingintrinsically aligned, homogeneous, and physically meaningful representationsthat can be efficiently adapted to achieve competitive performance across arange of downstream tasks. For the first time, we demonstrate that a singlemodel can unify spectral data across resolutions and domains, suggesting thatour model can serve as a powerful building block for foundation models inastronomy -- and potentially extend to other scientific domains withheterogeneous sequential data, such as climate and healthcare.</description><author>Jeff Shen, Francois Lanusse, Liam Holden Parker, Ollie Liu, Tom Hehir, Leopoldo Sarra, Lucas Meyer, Micah Bowles, Sebastian Wagner-Carena, Sebastian Wagner-Carena, Helen Qu, Siavash Golkar, Alberto Bietti, Hatim Bourfoune, Nathan Cassereau, Pierre Cornette, Keiya Hirashima, Geraud Krawezik, Ruben Ohana, Nicholas Lourie, Michael McCabe, Rudy Morel, Payel Mukhopadhyay, Mariel Pettee, Bruno Régaldo-Saint Blancard, Kyunghyun Cho, Miles Cranmer, Shirley Ho</author><pubDate>Mon, 10 Nov 2025 16:51:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.17959v2</guid></item><item><title>Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender Systems via Large Language Models</title><link>http://arxiv.org/abs/2511.07295v1</link><description>Implicit feedback, employed in training recommender systems, unavoidablyconfronts noise due to factors such as misclicks and position bias. Previousstudies have attempted to identify noisy samples through their diverged datapatterns, such as higher loss values, and mitigate their influence throughsample dropping or reweighting. However, we observed that noisy samples andhard samples display similar patterns, leading to hard-noisy confusion issue.Such confusion is problematic as hard samples are vital for modeling userpreferences. To solve this problem, we propose LLMHNI framework, leveraging twoauxiliary user-item relevance signals generated by Large Language Models (LLMs)to differentiate hard and noisy samples. LLMHNI obtains user-item semanticrelevance from LLM-encoded embeddings, which is used in negative sampling toselect hard negatives while filtering out noisy false negatives. An objectivealignment strategy is proposed to project LLM-encoded embeddings, originallyfor general language tasks, into a representation space optimized for user-itemrelevance modeling. LLMHNI also exploits LLM-inferred logical relevance withinuser-item interactions to identify hard and noisy samples. These LLM-inferredinteractions are integrated into the interaction graph and guide denoising withcross-graph contrastive alignment. To eliminate the impact of unreliableinteractions induced by LLM hallucination, we propose a graph contrastivelearning strategy that aligns representations from randomly edge-dropped viewsto suppress unreliable edges. Empirical results demonstrate that LLMHNIsignificantly improves denoising and recommendation performance.</description><author>Tianrui Song, Wen-Shuo Chao, Hao Liu</author><pubDate>Mon, 10 Nov 2025 16:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07295v1</guid></item><item><title>HyperSHAP: Shapley Values and Interactions for Explaining Hyperparameter Optimization</title><link>http://arxiv.org/abs/2502.01276v2</link><description>Hyperparameter optimization (HPO) is a crucial step in achieving strongpredictive performance. Yet, the impact of individual hyperparameters on modelgeneralization is highly context-dependent, prohibiting a one-size-fits-allsolution and requiring opaque HPO methods to find optimal configurations.However, the black-box nature of most HPO methods undermines user trust anddiscourages adoption. To address this, we propose a game-theoreticexplainability framework for HPO based on Shapley values and interactions. Ourapproach provides an additive decomposition of a performance measure acrosshyperparameters, enabling local and global explanations of hyperparameters'contributions and their interactions. The framework, named HyperSHAP, offersinsights into ablation studies, the tunability of learning algorithms, andoptimizer behavior across different hyperparameter spaces. We demonstrateHyperSHAP's capabilities on various HPO benchmarks to analyze the interactionstructure of the corresponding HPO problems, demonstrating its broadapplicability and actionable insights for improving HPO.</description><author>Marcel Wever, Maximilian Muschalik, Fabian Fumagalli, Marius Lindauer</author><pubDate>Mon, 10 Nov 2025 16:43:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01276v2</guid></item><item><title>Verifying rich robustness properties for neural networks</title><link>http://arxiv.org/abs/2511.07293v1</link><description>Robustness is a important problem in AI alignment and safety, with modelssuch as neural networks being increasingly used in safety-critical systems. Inthe last decade, a large body of work has emerged on local robustness, i.e.,checking if the decision of a neural network remains unchanged when the inputis slightly perturbed. However, many of these approaches require specializedencoding and often ignore the confidence of a neural network on its output. Inthis paper, our goal is to build a generalized framework to specify and verifyvariants of robustness in neural network verification. We propose aspecification framework using a simple grammar, which is flexible enough tocapture most existing variants. This allows us to introduce new variants ofrobustness that take into account the confidence of the neural network in itsoutputs. Next, we develop a novel and powerful unified technique to verify allsuch variants in a homogeneous way, viz., by adding a few additional layers tothe neural network. This enables us to use any state-of-the-art neural networkverification tool, without having to tinker with the encoding within, whileincurring an approximation error that we show is bounded. We perform anextensive experimental evaluation over a large suite of 8870 benchmarks having138M parameters in a largest network, and show that we are able to capture awide set of robustness variants and outperform direct encoding approaches by asignificant margin.</description><author>Mohammad Afzal, S. Akshay, Ashutosh Gupta</author><pubDate>Mon, 10 Nov 2025 16:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07293v1</guid></item><item><title>PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving</title><link>http://arxiv.org/abs/2511.07292v1</link><description>Most recent work in autonomous driving has prioritized benchmark performanceand methodological innovation over in-depth analysis of model failures, biases,and shortcut learning. This has led to incremental improvements without a deepunderstanding of the current failures. While it is straightforward to look atsituations where the model fails, it is hard to understand the underlyingreason. This motivates us to conduct a systematic study, where inputs to themodel are perturbed and the predictions observed. We introduce PlanT 2.0, alightweight, object-centric planning transformer designed for autonomousdriving research in CARLA. The object-level representation enables controlledanalysis, as the input can be easily perturbed (e.g., by changing the locationor adding or removing certain objects), in contrast to sensor-based models. Totackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,we introduce multiple upgrades to PlanT, achieving state-of-the-art performanceon Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysisexposes insightful failures, such as a lack of scene understanding caused bylow obstacle diversity, rigid expert behaviors leading to exploitableshortcuts, and overfitting to a fixed set of expert trajectories. Based onthese findings, we argue for a shift toward data-centric development, with afocus on richer, more robust, and less biased datasets. We open-source our codeand model at https://github.com/autonomousvision/plant2.</description><author>Simon Gerstenecker, Andreas Geiger, Katrin Renz</author><pubDate>Mon, 10 Nov 2025 16:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07292v1</guid></item><item><title>CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video</title><link>http://arxiv.org/abs/2511.07290v1</link><description>The prevalence of user-generated content (UGC) on platforms such as YouTubeand TikTok has rendered no-reference (NR) perceptual video quality assessment(VQA) vital for optimizing video delivery. Nonetheless, the characteristics ofnon-professional acquisition and the subsequent transcoding of UGC video onsharing platforms present significant challenges for NR-VQA. Although NR-VQAmodels attempt to infer mean opinion scores (MOS), their modeling of subjectivescores for compressed content remains limited due to the absence offine-grained perceptual annotations of artifact types. To address thesechallenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits thesemantic understanding capabilities of large vision-language models. Ourapproach introduces a quality-aware prompting mechanism that integrates videometadata (e.g., resolution, frame rate, bitrate) with key fragments extractedfrom inter-frame variations to guide the BLIP-2 pretraining approach ingenerating fine-grained quality captions. A unified architecture has beendesigned to model perceptual quality across three dimensions: semanticalignment, temporal characteristics, and spatial characteristics. Thesemultimodal features are extracted and fused, then regressed to video qualityscores. Extensive experiments on a wide variety of UGC datasets demonstratethat our model consistently outperforms existing NR-VQA methods, achievingimproved accuracy without the need for costly manual fine-grained annotations.Our method achieves the best performance in terms of average rank and linearcorrelation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods.The source code and trained models, along with a user-friendly demo, areavailable at: https://github.com/xinyiW915/CAMP-VQA.</description><author>Xinyi Wang, Angeliki Katsenou, Junxiao Shen, David Bull</author><pubDate>Mon, 10 Nov 2025 16:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07290v1</guid></item><item><title>FedAdamW: A Communication-Efficient Optimizer with Convergence and Generalization Guarantees for Federated Large Models</title><link>http://arxiv.org/abs/2510.27486v2</link><description>AdamW has become one of the most effective optimizers for traininglarge-scale models. We have also observed its effectiveness in the context offederated learning (FL). However, directly applying AdamW in federated learningsettings poses significant challenges: (1) due to data heterogeneity, AdamWoften yields high variance in the second-moment estimate $\boldsymbol{v}$; (2)the local overfitting of AdamW may cause client drift; and (3) Reinitializingmoment estimates ($\boldsymbol{v}$, $\boldsymbol{m}$) at each round slows downconvergence. To address these challenges, we propose the first\underline{Fed}erated \underline{AdamW} algorithm, called \texttt{FedAdamW},for training and fine-tuning various large models. \texttt{FedAdamW} alignslocal updates with the global update using both a \textbf{local correctionmechanism} and decoupled weight decay to mitigate local overfitting.\texttt{FedAdamW} efficiently aggregates the \texttt{mean} of the second-momentestimates to reduce their variance and reinitialize them. Theoretically, weprove that \texttt{FedAdamW} achieves a linear speedup convergence rate of$\mathcal{O}(\sqrt{(L \Delta \sigma_l^2)/(S K R \epsilon^2)}+(L \Delta)/R)$without \textbf{heterogeneity assumption}, where $S$ is the number ofparticipating clients per round, $K$ is the number of local iterations, and $R$is the total number of communication rounds. We also employ PAC-Bayesiangeneralization analysis to explain the effectiveness of decoupled weight decayin local training. Empirically, we validate the effectiveness of\texttt{FedAdamW} on language and vision Transformer models. Compared toseveral baselines, \texttt{FedAdamW} significantly reduces communication roundsand improves test accuracy. The code is available inhttps://github.com/junkangLiu0/FedAdamW.</description><author>Junkang Liu, Fanhua Shang, Kewen Zhu, Hongying Liu, Yuanyuan Liu, Jin Liu</author><pubDate>Mon, 10 Nov 2025 16:37:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.27486v2</guid></item><item><title>Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch</title><link>http://arxiv.org/abs/2511.01934v2</link><description>Training tool-augmented LLMs has emerged as a promising approach to enhancinglanguage models' capabilities for complex tasks. The current supervisedfine-tuning paradigm relies on constructing extensive domain-specific datasetsto train models. However, this approach often struggles to generalizeeffectively to unfamiliar or intricate tool-use scenarios. Recently,reinforcement learning (RL) paradigm can endow LLMs with superior reasoning andgeneralization abilities. In this work, we address a key question: Can the pureRL be used to effectively elicit a model's intrinsic reasoning capabilities andenhance the tool-agnostic generalization? We propose a dynamicgeneralization-guided reward design for rule-based RL, which progressivelyshifts rewards from exploratory to exploitative tool-use patterns. Based onthis design, we introduce the Tool-Zero series models. These models are trainedto enable LLMs to autonomously utilize general tools by directly scaling up RLfrom Zero models (i.e., base models without post-training). Experimentalresults demonstrate that our models achieve over 7% performance improvementcompared to both SFT and RL-with-SFT models under the same experimentalsettings. These gains are consistently replicated across cross-dataset andintra-dataset evaluations, validating the effectiveness and robustness of ourmethods.</description><author>Yirong Zeng, Xiao Ding, Yutai Hou, Yuxian Wang, Li Du, Juyi Dai, Qiuyang Ding, Duyu Tang, Dandan Tu, Weiwen Liu, Bing Qin, Ting Liu</author><pubDate>Mon, 10 Nov 2025 16:36:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.01934v2</guid></item><item><title>Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization</title><link>http://arxiv.org/abs/2511.07288v1</link><description>Learning complex policies with Reinforcement Learning (RL) is often hinderedby instability and slow convergence, a problem exacerbated by the difficulty ofreward engineering. Imitation Learning (IL) from expert demonstrations bypassesthis reliance on rewards. However, state-of-the-art IL methods, exemplified byGenerative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severesample inefficiency. This is a direct consequence of their foundationalon-policy algorithms, such as TRPO Schulman et.al. In this work, we introducean adversarial imitation learning algorithm that incorporates off-policylearning to improve sample efficiency. By combining an off-policy frameworkwith auxiliary techniques specifically, double Q network based stabilizationand value learning without reward function inference we demonstrate a reductionin the samples required to robustly match expert behavior.</description><author>Sayambhu Sen, Shalabh Bhatnagar</author><pubDate>Mon, 10 Nov 2025 16:35:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07288v1</guid></item><item><title>Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation</title><link>http://arxiv.org/abs/2511.07286v1</link><description>We present Glioma C6, a new open dataset for instance segmentation of gliomaC6 cells, designed as both a benchmark and a training resource for deeplearning models. The dataset comprises 75 high-resolution phase-contrastmicroscopy images with over 12,000 annotated cells, providing a realistictestbed for biomedical image analysis. It includes soma annotations andmorphological cell categorization provided by biologists. Additionalcategorization of cells, based on morphology, aims to enhance the utilizationof image data for cancer cell research. Glioma C6 consists of two parts: thefirst is curated with controlled parameters for benchmarking, while the secondsupports generalization testing under varying conditions. We evaluate theperformance of several generalist segmentation models, highlighting theirlimitations on our dataset. Our experiments demonstrate that training on GliomaC6 significantly enhances segmentation performance, reinforcing its value fordeveloping robust and generalizable models. The dataset is publicly availablefor researchers.</description><author>Roman Malashin, Svetlana Pashkevich, Daniil Ilyukhin, Arseniy Volkov, Valeria Yachnaya, Andrey Denisov, Maria Mikhalkova</author><pubDate>Mon, 10 Nov 2025 16:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.07286v1</guid></item><item><title>Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks</title><link>http://arxiv.org/abs/2507.02735v2</link><description>Prompt injection attack has been listed as the top-1 security threat toLLM-integrated applications, which interact with external environment data forcomplex tasks. The untrusted data may contain an injected prompt trying toarbitrarily manipulate the system. Model-level prompt injection defenses haveshown strong effectiveness, but are currently deployed into commercial-grademodels in a closed-source manner. We believe open-source secure models areneeded by the AI security community, where co-development of attacks anddefenses through open research drives scientific progress in mitigating promptinjection attacks. To this end, we develop Meta SecAlign, the first fullyopen-source LLM with built-in model-level defense that achievescommercial-grade performance, powerful enough for complex agentic tasks. Weprovide complete details of our training recipe, an improved version of theSOTA SecAlign defense. We perform the most comprehensive evaluation to date on9 utility benchmarks and 7 security benchmarks on general knowledge,instruction following, and agentic workflows. Results show that Meta SecAlign,despite being trained on generic instruction-tuning samples only, surprisinglyconfers security in unseen downstream tasks, including tool-calling andweb-navigation, in addition to general instruction-following. Our best model --Meta-SecAlign-70B -- establishes a new frontier of utility-security trade-offfor open-source LLMs. Even compared to closed-course commercial models such asGPT-5, our model is much securer than most of them. Below are links for thecode (https://github.com/facebookresearch/Meta_SecAlign),Meta-SecAlign-70B(https://huggingface.co/facebook/Meta-SecAlign-70B), andMeta-SecAlign-8B(https://huggingface.co/facebook/Meta-SecAlign-8B) models.</description><author>Sizhe Chen, Arman Zharmagambetov, David Wagner, Chuan Guo</author><pubDate>Mon, 10 Nov 2025 16:30:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.02735v2</guid></item></channel></rss>