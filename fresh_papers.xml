<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 07 Nov 2025 05:39:11 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition</title><link>http://arxiv.org/abs/2511.03725v1</link><description>Effective explanations of video action recognition models should disentanglehow movements unfold over time from the surrounding spatial context. However,existing methods based on saliency produce entangled explanations, making itunclear whether predictions rely on motion or spatial context. Language-basedapproaches offer structure but often fail to explain motions due to their tacitnature -- intuitively understood but difficult to verbalize. To address thesechallenges, we propose Disentangled Action aNd Context concept-basedExplainable (DANCE) video action recognition, a framework that predicts actionsthrough disentangled concept types: motion dynamics, objects, and scenes. Wedefine motion dynamics concepts as human pose sequences. We employ a largelanguage model to automatically extract object and scene concepts. Built on anante-hoc concept bottleneck design, DANCE enforces prediction through theseconcepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101-- demonstrate that DANCE significantly improves explanation clarity withcompetitive performance. We validate the superior interpretability of DANCEthrough a user study. Experimental results also show that DANCE is beneficialfor model debugging, editing, and failure analysis.</description><author>Jongseo Lee, Wooil Lee, Gyeong-Moon Park, Seong Tae Kim, Jinwoo Choi</author><pubDate>Wed, 05 Nov 2025 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03725v1</guid></item><item><title>Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning</title><link>http://arxiv.org/abs/2511.03724v1</link><description>AI researchers have long focused on poker-like games as a testbed forenvironments characterized by multi-player dynamics, imperfect information, andreasoning under uncertainty. While recent breakthroughs have matched elitehuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:most hands converge quickly with only two players engaged through multiplerounds of bidding. In this paper, we present Solly, the first AI agent toachieve elite human play in reduced-format Liar's Poker, a game characterizedby extensive multi-player engagement. We trained Solly using self-play with amodel-free, actor-critic, deep reinforcement learning algorithm. Solly playedat an elite human level as measured by win rate (won over 50% of hands) andequity (money won) in heads-up and multi-player Liar's Poker. Solly alsooutperformed large language models (LLMs), including those with reasoningabilities, on the same metrics. Solly developed novel bidding strategies,randomized play effectively, and was not easily exploitable by world-classhuman players.</description><author>Richard Dewey, Janos Botyanszki, Ciamac C. Moallemi, Andrew T. Zheng</author><pubDate>Wed, 05 Nov 2025 18:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03724v1</guid></item><item><title>Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask</title><link>http://arxiv.org/abs/2511.03718v1</link><description>Collaborative dialogue relies on participants incrementally establishingcommon ground, yet in asymmetric settings they may believe they agree whilereferring to different entities. We introduce a perspectivist annotation schemefor the HCRC MapTask corpus (Anderson et al., 1991) that separately capturesspeaker and addressee grounded interpretations for each reference expression,enabling us to trace how understanding emerges, diverges, and repairs overtime. Using a scheme-constrained LLM annotation pipeline, we obtain 13kannotated reference expressions with reliability estimates and analyze theresulting understanding states. The results show that full misunderstandingsare rare once lexical variants are unified, but multiplicity discrepanciessystematically induce divergences, revealing how apparent grounding can maskreferential misalignment. Our framework provides both a resource and ananalytic lens for studying grounded misunderstanding and for evaluating(V)LLMs' capacity to model perspective-dependent grounding in collaborativedialogue.</description><author>Nan Li, Albert Gatt, Massimo Poesio</author><pubDate>Wed, 05 Nov 2025 18:52:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03718v1</guid></item><item><title>Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games</title><link>http://arxiv.org/abs/2511.01852v2</link><description>Learning and computation of equilibria are central problems in game theory,theory of computation, and artificial intelligence. In this work, we introduceproximal regret, a new notion of regret based on proximal operators that liesstrictly between external and swap regret. When every player employs ano-proximal-regret algorithm in a general convex game, the empiricaldistribution of play converges to proximal correlated equilibria (PCE), arefinement of coarse correlated equilibria. Our framework unifies severalemerging notions in online learning and game theory-such as gradientequilibrium and semicoarse correlated equilibrium-and introduces new ones. Ourmain result shows that the classic Online Gradient Descent (GD) algorithmachieves an optimal $O(\sqrt{T})$ bound on proximal regret, revealing that GD,without modification, minimizes a stronger regret notion than external regret.This provides a new explanation for the empirically superior performance ofgradient descent in online learning and games. We further extend our analysisto Mirror Descent in the Bregman setting and to Optimistic Gradient Descent,which yields faster convergence in smooth convex games.</description><author>Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</author><pubDate>Wed, 05 Nov 2025 18:50:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.01852v2</guid></item><item><title>Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards</title><link>http://arxiv.org/abs/2511.03710v1</link><description>Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as apowerful paradigm for post-training large reasoning models (LRMs) usingpolicy-gradient methods such as GRPO. To stabilize training, these methodstypically center trajectory rewards by subtracting the empirical mean for eachprompt. Statistically, this centering acts as a control variate (or baseline),reducing the variance of the policy-gradient estimator. Typically, the mean reward is estimated using per-prompt empirical averagesfor each prompt in a batch. Drawing inspiration from Stein's paradox, wepropose using shrinkage estimators that combine per-prompt and across-promptmeans to improve the overall per-prompt mean estimation accuracy --particularly in the low-generation regime typical of RLVR. Theoretically, weconstruct a shrinkage-based baseline that provably yields lower-variancepolicy-gradient estimators across algorithms. Our proposed baseline serves as adrop-in replacement for existing per-prompt mean baselines, requiring noadditional hyper-parameters or computation. Empirically, shrinkage baselinesconsistently outperform standard empirical-mean baselines, leading tolower-variance gradient updates and improved training stability.</description><author>Guanning Zeng, Zhaoyi Zhou, Daman Arora, Andrea Zanette</author><pubDate>Wed, 05 Nov 2025 18:43:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03710v1</guid></item><item><title>The Adaptivity Barrier in Batched Nonparametric Bandits: Sharp Characterization of the Price of Unknown Margin</title><link>http://arxiv.org/abs/2511.03708v1</link><description>We study batched nonparametric contextual bandits under a margin conditionwhen the margin parameter $\alpha$ is unknown. To capture the statistical priceof this ignorance, we introduce the regret inflation criterion, defined as theratio between the regret of an adaptive algorithm and that of an oracle knowing$\alpha$. We show that the optimal regret inflation grows polynomial with thehorizon $T$, with exponent precisely given by the value of a convexoptimization problem involving the dimension, smoothness, and batch budget.Moreover, the minimizers of this optimization problem directly prescribe thebatch allocation and exploration strategy of a rate-optimal algorithm. Buildingon this principle, we develop RoBIN (RObust batched algorithm with adaptiveBINning), which achieves the optimal regret inflation up to logarithmicfactors. These results reveal a new adaptivity barrier: under batching,adaptation to an unknown margin parameter inevitably incurs a polynomialpenalty, sharply characterized by a variational problem. Remarkably, thisbarrier vanishes when the number of batches exceeds $\log \log T$; with only adoubly logarithmic number of updates, one can recover the oracle regret rate upto polylogarithmic factors.</description><author>Rong Jiang, Cong Ma</author><pubDate>Wed, 05 Nov 2025 18:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03708v1</guid></item><item><title>GDS Agent for Graph Algorithmic Reasoning</title><link>http://arxiv.org/abs/2508.20637v2</link><description>Large language models (LLMs) have shown remarkable multimodal informationprocessing and reasoning ability. When equipped with tools through functioncalling and enhanced with retrieval-augmented techniques, compound LLM-basedsystems can access closed data sources and answer questions about them.However, they still struggle to process and reason over large-scalegraph-structure data. We introduce the GDS (Graph Data Science) agent in thistechnical report. The GDS agent introduces a comprehensive set of graphalgorithms as tools, together with preprocessing (retrieval) and postprocessingof algorithm results, in a model context protocol (MCP) server. The server canbe used with any modern LLM out-of-the-box. GDS agent allows users to ask anyquestion that implicitly and intrinsically requires graph algorithmic reasoningabout their data, and quickly obtain accurate and grounded answers. Weintroduce new benchmarks that evaluate intermediate tool calls as well as finalresponses. The results indicate that GDS agent is able to solve a wide spectrumof graph tasks. We also provide detailed case studies for more open-ended tasksand study scenarios where the agent struggles. Finally, we discuss theremaining challenges and the future roadmap.</description><author>Borun Shi, Ioannis Panagiotas</author><pubDate>Wed, 05 Nov 2025 18:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.20637v2</guid></item><item><title>Compliance Minimization via Physics-Informed Gaussian Processes</title><link>http://arxiv.org/abs/2507.09968v2</link><description>Machine learning (ML) techniques have recently gained significant attentionfor solving compliance minimization (CM) problems. However, these methodstypically provide poor feature boundaries, are very expensive, and lack asystematic mechanism to control the design complexity. Herein, we address theselimitations by proposing a mesh-free and simultaneous framework based onphysics-informed Gaussian processes (GPs). In our approach, we parameterize thedesign and state variables with GP priors which have independent kernels butshare a multi-output neural network (NN) as their mean function. Thearchitecture of this NN is based on Parametric Grid Convolutional AttentionNetworks (PGCANs) which not only mitigate spectral bias issues, but alsoprovide an interpretable mechanism to control design complexity. We estimateall the parameters of our GP-based representations by simultaneously minimizingthe compliance, total potential energy, and residual of volume fractionconstraint. Importantly, our loss function exclude all data-based residuals asGPs automatically satisfy them. We also develop computational schemes based oncurriculum training and numerical integration to increase the efficiency androbustness of our approach which is shown to (1) produce super-resolutiontopologies with fast convergence, (2) achieve comparable compliance and lessgray area fraction compared to traditional numerical methods, (3) providecontrol over fine-scale features, and (4) outperform competing ML-basedmethods.</description><author>Xiangyu Sun, Amin Yousefpour, Shirin Hosseinmardi, Ramin Bostanabad</author><pubDate>Wed, 05 Nov 2025 18:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.09968v2</guid></item><item><title>Uniform-in-time propagation of chaos for mean field Langevin dynamics</title><link>http://arxiv.org/abs/2212.03050v4</link><description>We study the mean field Langevin dynamics and the associated particle system.By assuming the functional convexity of the energy, we obtain the$L^p$-convergence of the marginal distributions towards the unique invariantmeasure for the mean field dynamics. Furthermore, we prove the uniform-in-timepropagation of chaos in both the $L^2$-Wasserstein metric and relative entropy.</description><author>Fan Chen, Zhenjie Ren, Songbo Wang</author><pubDate>Wed, 05 Nov 2025 18:30:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03050v4</guid></item><item><title>Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models</title><link>http://arxiv.org/abs/2511.03699v1</link><description>In this paper, we investigate whether Large Language Models (LLMs) exhibitconspiratorial tendencies, whether they display sociodemographic biases in thisdomain, and how easily they can be conditioned into adopting conspiratorialperspectives. Conspiracy beliefs play a central role in the spread ofmisinformation and in shaping distrust toward institutions, making them acritical testbed for evaluating the social fidelity of LLMs. LLMs areincreasingly used as proxies for studying human behavior, yet little is knownabout whether they reproduce higher-order psychological constructs such as aconspiratorial mindset. To bridge this research gap, we administer validatedpsychometric surveys measuring conspiracy mindset to multiple models underdifferent prompting and conditioning strategies. Our findings reveal that LLMsshow partial agreement with elements of conspiracy belief, and conditioningwith socio-demographic attributes produces uneven effects, exposing latentdemographic biases. Moreover, targeted prompts can easily shift model responsestoward conspiratorial directions, underscoring both the susceptibility of LLMsto manipulation and the potential risks of their deployment in sensitivecontexts. These results highlight the importance of critically evaluating thepsychological dimensions embedded in LLMs, both to advance computational socialscience and to inform possible mitigation strategies against harmful uses.</description><author>Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales</author><pubDate>Wed, 05 Nov 2025 18:28:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03699v1</guid></item><item><title>Kosmos: An AI Scientist for Autonomous Discovery</title><link>http://arxiv.org/abs/2511.02824v2</link><description>Data-driven scientific discovery requires iterative cycles of literaturesearch, hypothesis generation, and data analysis. Substantial progress has beenmade towards AI agents that can automate scientific research, but all suchagents remain limited in the number of actions they can take before losingcoherence, thus limiting the depth of their findings. Here we present Kosmos,an AI scientist that automates data-driven discovery. Given an open-endedobjective and a dataset, Kosmos runs for up to 12 hours performing cycles ofparallel data analysis, literature search, and hypothesis generation beforesynthesizing discoveries into scientific reports. Unlike prior systems, Kosmosuses a structured world model to share information between a data analysisagent and a literature search agent. The world model enables Kosmos tocoherently pursue the specified objective over 200 agent rollouts, collectivelyexecuting an average of 42,000 lines of code and reading 1,500 papers per run.Kosmos cites all statements in its reports with code or primary literature,ensuring its reasoning is traceable. Independent scientists found 79.4% ofstatements in Kosmos reports to be accurate, and collaborators reported that asingle 20-cycle Kosmos run performed the equivalent of 6 months of their ownresearch time on average. Furthermore, collaborators reported that the numberof valuable scientific findings generated scales linearly with Kosmos cycles(tested up to 20 cycles). We highlight seven discoveries made by Kosmos thatspan metabolomics, materials science, neuroscience, and statistical genetics.Three discoveries independently reproduce findings from preprinted orunpublished manuscripts that were not accessed by Kosmos at runtime, while fourmake novel contributions to the scientific literature.</description><author>Ludovico Mitchener, Angela Yiu, Benjamin Chang, Mathieu Bourdenx, Tyler Nadolski, Arvis Sulovari, Eric C. Landsness, Daniel L. Barabasi, Siddharth Narayanan, Nicky Evans, Shriya Reddy, Martha Foiani, Aizad Kamal, Leah P. Shriver, Fang Cao, Asmamaw T. Wassie, Jon M. Laurent, Edwin Melville-Green, Mayk Caldas, Albert Bou, Kaleigh F. Roberts, Sladjana Zagorac, Timothy C. Orr, Miranda E. Orr, Kevin J. Zwezdaryk, Ali E. Ghareeb, Laurie McCoy, Bruna Gomes, Euan A. Ashley, Karen E. Duff, Tonio Buonassisi, Tom Rainforth, Randall J. Bateman, Michael Skarlinski, Samuel G. Rodriques, Michaela M. Hinks, Andrew D. White</author><pubDate>Wed, 05 Nov 2025 18:26:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02824v2</guid></item><item><title>AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing</title><link>http://arxiv.org/abs/2511.03697v1</link><description>Analog/mixed-signal circuits are key for interfacing electronics with thephysical world. Their design, however, remains a largely handcrafted process,resulting in long and error-prone design cycles. While the recent rise ofAI-based reinforcement learning and generative AI has created new techniques toautomate this task, the need for many time-consuming simulations is a criticalbottleneck hindering the overall efficiency. Furthermore, the lack ofexplainability of the resulting design solutions hampers widespread adoption ofthe tools. To address these issues, a novel agentic AI framework forsample-efficient and explainable analog circuit sizing is presented. It employsa multi-agent workflow where specialized Large Language Model (LLM)-basedagents collaborate to interpret the circuit topology, to understand the designgoals, and to iteratively refine the circuit's design parameters towards thetarget goals with human-interpretable reasoning. The adaptive simulationstrategy creates an intelligent control that yields a high sample efficiency.The AnaFlow framework is demonstrated for two circuits of varying complexityand is able to complete the sizing task fully automatically, differently frompure Bayesian optimization and reinforcement learning approaches. The systemlearns from its optimization history to avoid past mistakes and to accelerateconvergence. The inherent explainability makes this a powerful tool for analogdesign space exploration and a new paradigm in analog EDA, where AI agentsserve as transparent design assistants.</description><author>Mohsen Ahmadzadeh, Kaichang Chen, Georges Gielen</author><pubDate>Wed, 05 Nov 2025 18:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03697v1</guid></item><item><title>Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off</title><link>http://arxiv.org/abs/2508.04825v2</link><description>Virtual try-on aims to synthesize a realistic image of a person wearing atarget garment, but accurately modeling garment-body correspondence remains apersistent challenge, especially under pose and appearance variation. In thispaper, we propose Voost - a unified and scalable framework that jointly learnsvirtual try-on and try-off with a single diffusion transformer. By modelingboth tasks jointly, Voost enables each garment-person pair to supervise bothdirections and supports flexible conditioning over generation direction andgarment category, enhancing garment-body relational reasoning withouttask-specific networks, auxiliary losses, or additional labels. In addition, weintroduce two inference-time techniques: attention temperature scaling forrobustness to resolution or mask variation, and self-corrective sampling thatleverages bidirectional consistency between tasks. Extensive experimentsdemonstrate that Voost achieves state-of-the-art results on both try-on andtry-off benchmarks, consistently outperforming strong baselines in alignmentaccuracy, visual fidelity, and generalization.</description><author>Seungyong Lee, Jeong-gi Kwak</author><pubDate>Wed, 05 Nov 2025 18:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.04825v2</guid></item><item><title>Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL</title><link>http://arxiv.org/abs/2511.03695v1</link><description>Offline reinforcement learning (RL) enables training from fixed data withoutonline interaction, but policies learned offline often struggle when deployedin dynamic environments due to distributional shift and unreliable valueestimates on unseen state-action pairs. We introduce Behavior-AdaptiveQ-Learning (BAQ), a framework designed to enable a smooth and reliabletransition from offline to online RL. The key idea is to leverage an implicitbehavioral model derived from offline data to provide a behavior-consistencysignal during online fine-tuning. BAQ incorporates a dual-objective loss that(i) aligns the online policy toward the offline behavior when uncertainty ishigh, and (ii) gradually relaxes this constraint as more confident onlineexperience is accumulated. This adaptive mechanism reduces error propagationfrom out-of-distribution estimates, stabilizes early online updates, andaccelerates adaptation to new scenarios. Across standard benchmarks, BAQconsistently outperforms prior offline-to-online RL approaches, achievingfaster recovery, improved robustness, and higher overall performance. Ourresults demonstrate that implicit behavior adaptation is a principled andpractical solution for reliable real-world policy deployment.</description><author>Lipeng Zu, Hansong Zhou, Xiaonan Zhang</author><pubDate>Wed, 05 Nov 2025 18:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03695v1</guid></item><item><title>Colorectal Cancer Histopathological Grading using Multi-Scale Federated Learning</title><link>http://arxiv.org/abs/2511.03693v1</link><description>Colorectal cancer (CRC) grading is a critical prognostic factor but remainshampered by inter-observer variability and the privacy constraints ofmulti-institutional data sharing. While deep learning offers a path toautomation, centralized training models conflict with data governanceregulations and neglect the diagnostic importance of multi-scale analysis. Inthis work, we propose a scalable, privacy-preserving federated learning (FL)framework for CRC histopathological grading that integrates multi-scale featurelearning within a distributed training paradigm. Our approach employs adual-stream ResNetRS50 backbone to concurrently capture fine-grained nucleardetail and broader tissue-level context. This architecture is integrated into arobust FL system stabilized using FedProx to mitigate client drift acrossheterogeneous data distributions from multiple hospitals. Extensive evaluationon the CRC-HGD dataset demonstrates that our framework achieves an overallaccuracy of 83.5%, outperforming a comparable centralized model (81.6%).Crucially, the system excels in identifying the most aggressive Grade IIItumors with a high recall of 87.5%, a key clinical priority to preventdangerous false negatives. Performance further improves with highermagnification, reaching 88.0% accuracy at 40x. These results validate that ourfederated multi-scale approach not only preserves patient privacy but alsoenhances model performance and generalization. The proposed modular pipeline,with built-in preprocessing, checkpointing, and error handling, establishes afoundational step toward deployable, privacy-aware clinical AI for digitalpathology.</description><author>Md Ahasanul Arafath, Abhijit Kumar Ghosh, Md Rony Ahmed, Sabrin Afroz, Minhazul Hosen, Md Hasan Moon, Md Tanzim Reza, Md Ashad Alam</author><pubDate>Wed, 05 Nov 2025 18:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03693v1</guid></item><item><title>The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents</title><link>http://arxiv.org/abs/2511.03690v1</link><description>Agents are now used widely in the process of software development, butbuilding production-ready software engineering agents is a complex task.Deploying software agents effectively requires flexibility in implementationand experimentation, reliable and secure execution, and interfaces for users tointeract with agents. In this paper, we present the OpenHands Software AgentSDK, a toolkit for implementing software development agents that satisfy thesedesiderata. This toolkit is a complete architectural redesign of the agentcomponents of the popular OpenHands framework for software development agents,which has 64k+ GitHub stars. To achieve flexibility, we design a simpleinterface for implementing agents that requires only a few lines of code in thedefault case, but is easily extensible to more complex, full-featured agentswith features such as custom tools, memory management, and more. For securityand reliability, it delivers seamless local-to-remote execution portability,integrated REST/WebSocket services. For interaction with human users, it canconnect directly to a variety of interfaces, such as visual workspaces (VSCode, VNC, browser), command-line interfaces, and APIs. Compared with existingSDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates nativesandboxed execution, lifecycle control, model-agnostic multi-LLM routing, andbuilt-in security analysis. Empirical results on SWE-Bench Verified and GAIAbenchmarks demonstrate strong performance. Put together, these elements allowthe OpenHands Software Agent SDK to provide a practical foundation forprototyping, unlocking new classes of custom applications, and reliablydeploying agents at scale.</description><author>Xingyao Wang, Simon Rosenberg, Juan Michelini, Calvin Smith, Hoang Tran, Engel Nyst, Rohit Malhotra, Xuhui Zhou, Valerie Chen, Robert Brennan, Graham Neubig</author><pubDate>Wed, 05 Nov 2025 18:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03690v1</guid></item><item><title>Data-Driven Probabilistic Air-Sea Flux Parameterization</title><link>http://arxiv.org/abs/2503.03990v2</link><description>Accurately quantifying air-sea fluxes is important for understanding air-seainteractions and improving coupled weather and climate systems. This studyintroduces a probabilistic framework to represent the highly variable nature ofair-sea fluxes, which is missing in deterministic bulk algorithms. AssumingGaussian distributions conditioned on the input variables, we use artificialneural networks and eddy-covariance measurement data to estimate the mean andvariance by minimizing negative log-likelihood loss. The trained neuralnetworks provide alternative mean flux estimates to existing bulk algorithms,and quantify the uncertainty around the mean estimates. Stochasticparameterization of air-sea turbulent fluxes can be constructed by samplingfrom the predicted distributions. Tests in a single-column forced upper-oceanmodel suggest that changes in flux algorithms influence sea surface temperatureand mixed layer depth seasonally. The ensemble spread in stochastic runs ismost pronounced during spring restratification.</description><author>Jiarong Wu, Pavel Perezhogin, David John Gagne, Brandon Reichl, Aneesh C. Subramanian, Elizabeth Thompson, Laure Zanna</author><pubDate>Wed, 05 Nov 2025 18:16:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.03990v2</guid></item><item><title>Structured Matrix Scaling for Multi-Class Calibration</title><link>http://arxiv.org/abs/2511.03685v1</link><description>Post-hoc recalibration methods are widely used to ensure that classifiersprovide faithful probability estimates. We argue that parametric recalibrationfunctions based on logistic regression can be motivated from a simpletheoretical setting for both binary and multiclass classification. This insightmotivates the use of more expressive calibration methods beyond standardtemperature scaling. For multi-class calibration however, a key challenge liesin the increasing number of parameters introduced by more complex models, oftencoupled with limited calibration data, which can lead to overfitting. Throughextensive experiments, we demonstrate that the resulting bias-variance tradeoffcan be effectively managed by structured regularization, robust preprocessingand efficient optimization. The resulting methods lead to substantial gainsover existing logistic-based calibration techniques. We provide efficient andeasy-to-use open-source implementations of our methods, making them anattractive alternative to common temperature, vector, and matrix scalingimplementations.</description><author>Eugène Berta, David Holzmüller, Michael I. Jordan, Francis Bach</author><pubDate>Wed, 05 Nov 2025 18:09:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03685v1</guid></item><item><title>Does Synthetic Data Help Named Entity Recognition for Low-Resource Languages?</title><link>http://arxiv.org/abs/2505.16814v3</link><description>Named Entity Recognition(NER) for low-resource languages aims to producerobust systems for languages where there is limited labeled training dataavailable, and has been an area of increasing interest within NLP. Dataaugmentation for increasing the amount of low-resource labeled data is a commonpractice. In this paper, we explore the role of synthetic data in the contextof multilingual, low-resource NER, considering 11 languages from diverselanguage families. Our results suggest that synthetic data does in fact holdpromise for low-resource language NER, though we see significant variationbetween languages.</description><author>Gaurav Kamath, Sowmya Vajjala</author><pubDate>Wed, 05 Nov 2025 18:06:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.16814v3</guid></item><item><title>Generative View Stitching</title><link>http://arxiv.org/abs/2510.24718v2</link><description>Autoregressive video diffusion models are capable of long rollouts that arestable and consistent with history, but they are unable to guide the currentgeneration with conditioning from the future. In camera-guided video generationwith a predefined camera trajectory, this limitation leads to collisions withthe generated scene, after which autoregression quickly collapses. To addressthis, we propose Generative View Stitching (GVS), which samples the entiresequence in parallel such that the generated scene is faithful to every part ofthe predefined camera trajectory. Our main contribution is a sampling algorithmthat extends prior work on diffusion stitching for robot planning to videogeneration. While such stitching methods usually require a specially trainedmodel, GVS is compatible with any off-the-shelf video model trained withDiffusion Forcing, a prevalent sequence diffusion framework that we showalready provides the affordances necessary for stitching. We then introduceOmni Guidance, a technique that enhances the temporal consistency in stitchingby conditioning on both the past and future, and that enables our proposedloop-closing mechanism for delivering long-range coherence. Overall, GVSachieves camera-guided video generation that is stable, collision-free,frame-to-frame consistent, and closes loops for a variety of predefined camerapaths, including Oscar Reutersv\"ard's Impossible Staircase. Results are bestviewed as videos at https://andrewsonga.github.io/gvs.</description><author>Chonghyuk Song, Michal Stary, Boyuan Chen, George Kopanas, Vincent Sitzmann</author><pubDate>Wed, 05 Nov 2025 17:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.24718v2</guid></item><item><title>PDE-SHARP: PDE Solver Hybrids through Analysis and Refinement Passes</title><link>http://arxiv.org/abs/2511.00183v2</link><description>Current LLM-driven approaches using test-time computing to generate PDEsolvers execute a large number of solver samples to identify high-accuracysolvers. These paradigms are especially costly for complex PDEs requiringsubstantial computational resources for numerical evaluation. We introducePDE-SHARP, a framework to reduce computational costs by replacing expensivescientific computation by cheaper LLM inference that achieves superior solveraccuracy with 60-75% fewer computational evaluations. PDE-SHARP employs threestages: (1) Analysis: mathematical chain-of-thought analysis including PDEclassification, solution type detection, and stability analysis; (2) Genesis:solver generation based on mathematical insights from the previous stage; and(3) Synthesis: collaborative selection-hybridization tournaments in which LLMjudges iteratively refine implementations through flexible performancefeedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13solver evaluations on average compared to 30+ for baseline methods, improvingaccuracy uniformly across tested PDEs by $4\times$ on average, and demonstratesrobust performance across LLM architectures, from general-purpose tospecialized reasoning models.</description><author>Shaghayegh Fazliani, Madeleine Udell</author><pubDate>Wed, 05 Nov 2025 17:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.00183v2</guid></item><item><title>MAROON: A Framework for the Joint Characterization of Near-Field High-Resolution Radar and Optical Depth Imaging Techniques</title><link>http://arxiv.org/abs/2411.00527v3</link><description>Utilizing the complementary strengths of wavelength-specific range or depthsensors is crucial for robust computer-assisted tasks such as autonomousdriving. Despite this, there is still little research done at the intersectionof optical depth sensors and radars operating close range, where the target isdecimeters away from the sensors. Together with a growing interest inhigh-resolution imaging radars operating in the near field, the question ariseshow these sensors behave in comparison to their traditional opticalcounterparts. In this work, we take on the unique challenge of jointly characterizing depthimagers from both, the optical and radio-frequency domain using a multimodalspatial calibration. We collect data from four depth imagers, with threeoptical sensors of varying operation principle and an imaging radar. We providea comprehensive evaluation of their depth measurements with respect to distinctobject materials, geometries, and object-to-sensor distances. Specifically, wereveal scattering effects of partially transmissive materials and investigatethe response of radio-frequency signals. All object measurements will be madepublic in form of a multimodal dataset, called MAROON.</description><author>Vanessa Wirth, Johanna Bräunig, Nikolai Hofmann, Martin Vossiek, Tim Weyrich, Marc Stamminger</author><pubDate>Wed, 05 Nov 2025 17:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00527v3</guid></item><item><title>Using latent representations to link disjoint longitudinal data for mixed-effects regression</title><link>http://arxiv.org/abs/2510.25531v2</link><description>Many rare diseases offer limited established treatment options, leadingpatients to switch therapies when new medications emerge. To analyze the impactof such treatment switches within the low sample size limitations of raredisease trials, it is important to use all available data sources. This,however, is complicated when usage of measurement instruments change during theobservation period, for example when instruments are adapted to specific ageranges. The resulting disjoint longitudinal data trajectories, complicate theapplication of traditional modeling approaches like mixed-effects regression.We tackle this by mapping observations of each instrument to a alignedlow-dimensional temporal trajectory, enabling longitudinal modeling acrossinstruments. Specifically, we employ a set of variational autoencoderarchitectures to embed item values into a shared latent space for each timepoint. Temporal disease dynamics and treatment switch effects are then capturedthrough a mixed-effects regression model applied to latent representations. Toenable statistical inference, we present a novel statistical testing approachthat accounts for the joint parameter estimation of mixed-effects regressionand variational autoencoders. The methodology is applied to quantify the impactof treatment switches for patients with spinal muscular atrophy. Here, ourapproach aligns motor performance items from different measurement instrumentsfor mixed-effects regression and maps estimated effects back to the observeditem level to quantify the treatment switch effect. Our approach allows formodel selection as well as for assessing effects of treatment switching. Theresults highlight the potential of modeling in joint latent representations foraddressing small data challenges.</description><author>Clemens Schächter, Maren Hackenberg, Michelle Pfaffenlehner, Félix B. Tambe-Ndonfack, Thorsten Schmidt, Astrid Pechmann, Janbernd Kirschner, Jan Hasenauer, Harald Binder</author><pubDate>Wed, 05 Nov 2025 17:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.25531v2</guid></item><item><title>Whisper Leak: a side-channel attack on Large Language Models</title><link>http://arxiv.org/abs/2511.03675v1</link><description>Large Language Models (LLMs) are increasingly deployed in sensitive domainsincluding healthcare, legal services, and confidential communications, whereprivacy is paramount. This paper introduces Whisper Leak, a side-channel attackthat infers user prompt topics from encrypted LLM traffic by analyzing packetsize and timing patterns in streaming responses. Despite TLS encryptionprotecting content, these metadata patterns leak sufficient information toenable topic classification. We demonstrate the attack across 28 popular LLMsfrom major providers, achieving near-perfect classification (often &gt;98% AUPRC)and high precision even at extreme class imbalance (10,000:1 noise-to-targetratio). For many models, we achieve 100% precision in identifying sensitivetopics like "money laundering" while recovering 5-20% of target conversations.This industry-wide vulnerability poses significant risks for users undernetwork surveillance by ISPs, governments, or local adversaries. We evaluatethree mitigation strategies - random padding, token batching, and packetinjection - finding that while each reduces attack effectiveness, none providescomplete protection. Through responsible disclosure, we have collaborated withproviders to implement initial countermeasures. Our findings underscore theneed for LLM providers to address metadata leakage as AI systems handleincreasingly sensitive information.</description><author>Geoff McDonald, Jonathan Bar Or</author><pubDate>Wed, 05 Nov 2025 17:47:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03675v1</guid></item><item><title>Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation</title><link>http://arxiv.org/abs/2411.16638v4</link><description>Modern LLMs can now produce highly readable abstractive summaries, to thepoint that traditional automated metrics for evaluating summary quality, suchas ROUGE, have saturated. However, LLMs still sometimes introduce inaccuraciesinto summaries, i.e., information inconsistent with or unsupported by thecorresponding source. Measuring the occurrence of these often subtle factualinconsistencies automatically has proved challenging. This in turn hasmotivated development of metrics intended to measure the factual consistency ofgenerated summaries against sources. But are these approaches measuring whatthey purport to? Or are they mostly exploiting artifacts? In this work, westress test a range of automatic factuality metrics, including specializedmodels and LLM-based prompting methods, to probe what they actually capture.Using a shallow classifier to separate ``easy'' examples for factual evaluationwhere surface features suffice from ``hard'' cases requiring deeper reasoning,we find that all metrics show substantial performance drops on the latter.Furthermore, some metrics are more sensitive to benign, fact-preserving editsthan to factual corrections. Building on this observation, we demonstrate thatmost automatic factuality metrics can be gamed, i.e., their scores can beartificially inflated by appending innocuous, content-free sentences tosummaries. Among the metrics tested, the prompt based ChatGPT-DA approach isthe most robust and reliable. However, this comes with a notable caveat:Prompting LLMs to assess factuality may overly rely on their parametricknowledge rather than the provided reference when making judgments. Takentogether, our findings call into question the reliability of current factualitymetrics and prompt a broader reflection on what these metrics are trulymeasuring.</description><author>Sanjana Ramprasad, Byron C. Wallace</author><pubDate>Wed, 05 Nov 2025 17:42:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.16638v4</guid></item><item><title>Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs</title><link>http://arxiv.org/abs/2410.16593v5</link><description>Graph Neural Networks (GNNs) excel in many graph machine learning tasks butface challenges when scaling to large networks. GNN transferability allowstraining on smaller graphs and applying the model to larger ones, but existingmethods often rely on random subsampling, leading to disconnected subgraphs andreduced model expressivity. We propose a novel graph sampling algorithm thatleverages feature homophily to preserve graph structure. By minimizing thetrace of the data correlation matrix, our method better preserves the graphLaplacian trace -- a proxy for the graph connectivity -- than random sampling,while achieving lower complexity than spectral methods. Experiments on citationnetworks show improved performance in preserving Laplacian trace and GNNtransferability compared to random sampling.</description><author>Haolin Li, Haoyu Wang, Luana Ruiz</author><pubDate>Wed, 05 Nov 2025 17:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16593v5</guid></item><item><title>Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</title><link>http://arxiv.org/abs/2510.26723v2</link><description>The goal of policy learning is to train a policy function that recommends atreatment given covariates to maximize population welfare. There are two majorapproaches in policy learning: the empirical welfare maximization (EWM)approach and the plug-in approach. The EWM approach is analogous to aclassification problem, where one first builds an estimator of the populationwelfare, which is a functional of policy functions, and then trains a policy bymaximizing the estimated welfare. In contrast, the plug-in approach is based onregression, where one first estimates the conditional average treatment effect(CATE) and then recommends the treatment with the highest estimated outcome.This study bridges the gap between the two approaches by showing that both arebased on essentially the same optimization problem. In particular, we prove anexact equivalence between EWM and least squares over a reparameterization ofthe policy class. As a consequence, the two approaches are interchangeable inseveral respects and share the same theoretical guarantees under commonconditions. Leveraging this equivalence, we propose a regularization method forpolicy learning. The reduction to least squares yields a smooth surrogate thatis typically easier to optimize in practice. At the same time, for many naturalpolicy classes the inherent combinatorial hardness of exact EWM generallyremains, so the reduction should be viewed as an optimization aid rather than auniversal bypass of NP-hardness.</description><author>Masahiro Kato</author><pubDate>Wed, 05 Nov 2025 17:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.26723v2</guid></item><item><title>TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models</title><link>http://arxiv.org/abs/2511.02802v2</link><description>Tabular foundation models represent a growing paradigm in structured datalearning, extending the benefits of large-scale pretraining to tabular domains.However, their adoption remains limited due to heterogeneous preprocessingpipelines, fragmented APIs, inconsistent fine-tuning procedures, and theabsence of standardized evaluation for deployment-oriented metrics such ascalibration and fairness. We present TabTune, a unified library thatstandardizes the complete workflow for tabular foundation models through asingle interface. TabTune provides consistent access to seven state-of-the-artmodels supporting multiple adaptation strategies, including zero-shotinference, meta-learning, supervised fine-tuning (SFT), and parameter-efficientfine-tuning (PEFT). The framework automates model-aware preprocessing, managesarchitectural heterogeneity internally, and integrates evaluation modules forperformance, calibration, and fairness. Designed for extensibility andreproducibility, TabTune enables consistent benchmarking of adaptationstrategies of tabular foundation models.</description><author>Aditya Tanna, Pratinav Seth, Mohamed Bouadi, Utsav Avaiya, Vinay Kumar Sankarapu</author><pubDate>Wed, 05 Nov 2025 17:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02802v2</guid></item><item><title>DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay</title><link>http://arxiv.org/abs/2511.03670v1</link><description>We present a detailed study of Deep Q-Networks in finite environments,emphasizing the impact of epsilon-greedy exploration schedules and prioritizedexperience replay. Through systematic experimentation, we evaluate howvariations in epsilon decay schedules affect learning efficiency, convergencebehavior, and reward optimization. We investigate how prioritized experiencereplay leads to faster convergence and higher returns and show empiricalresults comparing uniform, no replay, and prioritized strategies acrossmultiple simulations. Our findings illuminate the trade-offs and interactionsbetween exploration strategies and memory management in DQN training, offeringpractical recommendations for robust reinforcement learning inresource-constrained settings.</description><author>Daniel Perkins, Oscar J. Escobar, Luke Green</author><pubDate>Wed, 05 Nov 2025 17:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03670v1</guid></item><item><title>Addressing prior dependence in hierarchical Bayesian modeling for PTA data analysis I: Methodology and implementation</title><link>http://arxiv.org/abs/2511.03667v1</link><description>Complex inference tasks, such as those encountered in Pulsar Timing Array(PTA) data analysis, rely on Bayesian frameworks. The high-dimensionalparameter space and the strong interdependencies among astrophysical, pulsarnoise, and nuisance parameters introduce significant challenges for efficientlearning and robust inference. These challenges are emblematic of broaderissues in decision science, where model over-parameterization and priorsensitivity can compromise both computational tractability and the reliabilityof the results. We address these issues in the framework of hierarchicalBayesian modeling by introducing a reparameterization strategy. Our approachemploys Normalizing Flows (NFs) to decorrelate the parameters governinghierarchical priors from those of astrophysical interest. The use of NF-basedmappings provides both the flexibility to realize the reparametrization and thetractability to preserve proper probability densities. We further adopti-nessai, a flow-guided nested sampler, to accelerate exploration of complexposteriors. This unified use of NFs improves statistical robustness andcomputational efficiency, providing a principled methodology for addressinghierarchical Bayesian inference in PTA analysis.</description><author>Luigi D'amico, Eleonora Villa, Fatima Modica Bittordo, Aldo Barca, Francesco Alì, Massimo Meneghetti, Luca Naso</author><pubDate>Wed, 05 Nov 2025 17:33:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03667v1</guid></item><item><title>Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs</title><link>http://arxiv.org/abs/2410.20749v3</link><description>Despite the impressive generative abilities of black-box large languagemodels (LLMs), their inherent opacity hinders further advancements incapabilities such as reasoning, planning, and personalization. Existing worksaim to enhance LLM capabilities via domain-specific adaptation, which requireadditional training on accessible model parameters, an infeasible option forblack-box LLMs. To address this challenge, we introduce Matryoshka Pilot(M-Pilot), a lightweight white-box LLM controller that guides a large-scaleblack-box LLM generator by decomposing complex tasks into a series ofintermediate outputs. Specifically, we consider the black-box LLM as anenvironment, with M-Pilot serving as a policy to provide intermediate guidancethrough prompts for driving the black-box LLM. M-Pilot is trained to pivot theoutputs of the black-box LLM aligning with preferences during iterativeinteraction, which enables controllable multi-turn generation andself-improvement in optimizing intermediate guidance. Empirical evaluations ondiverse tasks demonstrate that our method effectively enhances the capabilitiesof black-box LLMs in complex, long-horizon tasks. Our code is publiclyavailable at: https://github.com/lichangh20/Matryoshka.</description><author>Changhao Li, Yuchen Zhuang, Rushi Qiang, Haotian Sun, Hanjun Dai, Chao Zhang, Bo Dai</author><pubDate>Wed, 05 Nov 2025 17:33:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20749v3</guid></item><item><title>Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection</title><link>http://arxiv.org/abs/2511.03666v1</link><description>Social interactions often emerge from subtle, fine-grained cues such asfacial expressions, gaze, and gestures. However, existing methods for socialinteraction detection overlook such nuanced cues and primarily rely on holisticrepresentations of individuals. Moreover, they directly detect social groupswithout explicitly modeling the underlying interactions between individuals.These drawbacks limit their ability to capture localized social signals andintroduce ambiguity when group configurations should be inferred from socialinteractions grounded in nuanced cues. In this work, we propose a part-awarebottom-up group reasoning framework for fine-grained social interactiondetection. The proposed method infers social groups and their interactionsusing body part features and their interpersonal relations. Our model firstdetects individuals and enhances their features using part-aware cues, and theninfers group configuration by associating individuals via similarity-basedreasoning, which considers not only spatial relations but also subtle socialcues that signal interactions, leading to more accurate group inference.Experiments on the NVI dataset demonstrate that our method outperforms priormethods, achieving the new state of the art.</description><author>Dongkeun Kim, Minsu Cho, Suha Kwak</author><pubDate>Wed, 05 Nov 2025 17:33:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03666v1</guid></item><item><title>A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential</title><link>http://arxiv.org/abs/2511.03665v1</link><description>This paper presents a lightweight three-dimensional convolutional neuralnetwork (3DCNN) for human activity recognition (HAR) using event-based visiondata. Privacy preservation is a key challenge in human monitoring systems, asconventional frame-based cameras capture identifiable personal information. Incontrast, event cameras record only changes in pixel intensity, providing aninherently privacy-preserving sensing modality. The proposed networkeffectively models both spatial and temporal dynamics while maintaining acompact design suitable for edge deployment. To address class imbalance andenhance generalization, focal loss with class reweighting and targeted dataaugmentation strategies are employed. The model is trained and evaluated on acomposite dataset derived from the Toyota Smart Home and ETRI datasets.Experimental results demonstrate an F1-score of 0.9415 and an overall accuracyof 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,and MC3_18 by up to 3%. These results highlight the potential of event-baseddeep learning for developing accurate, efficient, and privacy-aware humanaction recognition systems suitable for real-world edge applications.</description><author>Mehdi Sefidgar Dilmaghani, Francis Fowley, Peter Corcoran</author><pubDate>Wed, 05 Nov 2025 17:30:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03665v1</guid></item><item><title>PLUTO-4: Frontier Pathology Foundation Models</title><link>http://arxiv.org/abs/2511.02826v2</link><description>Foundation models trained on large-scale pathology image corpora havedemonstrated strong transfer capabilities across diverse histopathology tasks.Building on this progress, we introduce PLUTO-4, our next generation ofpathology foundation models that extend the Pathology-Universal Transformer(PLUTO) to frontier scale. We share two complementary Vision Transformerarchitectures in the PLUTO-4 family: a compact and efficient PLUTO-4S modeloptimized for multi-scale deployment using a FlexiViT setup with 2D-RoPEembeddings, and a frontier-scale PLUTO-4G model trained with a single patchsize to maximize representation capacity and stability. Both models arepretrained using a self-supervised objective derived from DINOv2 on a largemulti-institutional corpus containing 551,164 WSIs from 137,144 patients acrossover 50 institutions, spanning over 60 disease types and over 100 stains.Comprehensive evaluation across public and internal benchmarks demonstratesthat PLUTO-4 achieves state-of-the-art performance on tasks requiring varyingspatial and biological context, including patch-level classification,segmentation, and slide-level diagnosis. The compact PLUTO-4S provideshigh-throughput and robust performance for practical deployment, while PLUTO-4Gestablishes new performance frontiers across multiple pathology benchmarks,including an 11% improvement in dermatopathology diagnosis. These diverseimprovements underscore PLUTO-4's potential to transform real-worldapplications as a backbone for translational research and diagnostic use cases.</description><author>Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti, Ryun Han, Andrew Walker, Judy Shen, Chintan Shah, Blake Martin, Aashish Sood, Elliot Miller, Ben Glass, Andy Beck, Harsha Pokkalla, Syed Ashar Javed</author><pubDate>Wed, 05 Nov 2025 17:25:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02826v2</guid></item><item><title>Beyond Covariance Matrix: The Statistical Complexity of Private Linear Regression</title><link>http://arxiv.org/abs/2502.13115v2</link><description>We study the statistical complexity of private linear regression under anunknown, potentially ill-conditioned covariate distribution. Somewhatsurprisingly, under privacy constraints the intrinsic complexity is \emph{not}captured by the usual covariance matrix but rather its $L_1$ analogues.Building on this insight, we establish minimax convergence rates for both thecentral and local privacy models and introduce an Information-WeightedRegression method that attains the optimal rates. As application, in private linear contextual bandits, we propose an efficientalgorithm that achieves rate-optimal regret bounds of order$\sqrt{T}+\frac{1}{\alpha}$ and $\sqrt{T}/\alpha$ under joint and local$\alpha$-privacy models, respectively. Notably, our results demonstrate thatjoint privacy comes at almost no additional cost, addressing the open problemsposed by Azize and Basu (2024).</description><author>Fan Chen, Jiachun Li, Alexander Rakhlin, David Simchi-Levi</author><pubDate>Wed, 05 Nov 2025 17:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.13115v2</guid></item><item><title>Why Isn't Relational Learning Taking Over the World?</title><link>http://arxiv.org/abs/2507.13558v5</link><description>Artificial intelligence seems to be taking over the world with systems thatmodel pixels, words, and phonemes. The world is arguably made up, not ofpixels, words, and phonemes but of entities (objects, things, including events)with properties and relations among them. Surely we should model these, not theperception or description of them. You might suspect that concentrating onmodeling words and pixels is because all of the (valuable) data in the world isin terms of text and images. If you look into almost any company you will findtheir most valuable data is in spreadsheets, databases and other relationalformats. These are not the form that are studied in introductory machinelearning, but are full of product numbers, student numbers, transaction numbersand other identifiers that can't be interpreted naively as numbers. The fieldthat studies this sort of data has various names including relational learning,statistical relational AI, and many others. This paper explains why relationallearning is not taking over the world -- except in a few cases with restrictedrelations -- and what needs to be done to bring it to it's rightful prominence.</description><author>David Poole</author><pubDate>Wed, 05 Nov 2025 17:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.13558v5</guid></item><item><title>SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</title><link>http://arxiv.org/abs/2511.03661v1</link><description>The integration of IoT devices in healthcare introduces significant securityand reliability challenges, increasing susceptibility to cyber threats andoperational anomalies. This study proposes a machine learning-driven frameworkfor (1) detecting malicious cyberattacks and (2) identifying faulty deviceanomalies, leveraging a dataset of 200,000 records. Eight machine learningmodels are evaluated across three learning approaches: supervised learning(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (GenerativeAdversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervisedlearning (One-Class Support Vector Machine (SVM), Isolation Forest, GraphNeural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). Thecomprehensive evaluation was conducted across multiple metrics like F1-score,precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoostachieved 99\% accuracy with minimal computational overhead (0.04s) for anomalydetection, while Isolation Forest balanced precision and recall effectively.LSTM Autoencoders underperformed with lower accuracy and higher latency. Forattack detection, KNN achieved near-perfect precision, recall, and F1-scorewith the lowest computational cost (0.05s), followed by VAE at 97% accuracy.GAN showed the highest computational cost with lowest accuracy and ROC-AUC.These findings enhance IoT-enabled healthcare security through effectiveanomaly detection strategies. By improving early detection of cyber threats anddevice failures, this framework has the potential to prevent data breaches,minimize system downtime, and ensure the continuous and safe operation ofmedical devices, ultimately safeguarding patient health and trust in IoT-drivenhealthcare solutions.</description><author>Mahek Desai, Apoorva Rumale, Marjan Asadinia</author><pubDate>Wed, 05 Nov 2025 17:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03661v1</guid></item><item><title>Disentanglement with Factor Quantized Variational Autoencoders</title><link>http://arxiv.org/abs/2409.14851v3</link><description>Disentangled representation learning aims to represent the underlyinggenerative factors of a dataset in a latent representation independently of oneanother. In our work, we propose a discrete variational autoencoder (VAE) basedmodel where the ground truth information about the generative factors are notprovided to the model. We demonstrate the advantages of learning discreterepresentations over learning continuous representations in facilitatingdisentanglement. Furthermore, we propose incorporating an inductive bias intothe model to further enhance disentanglement. Precisely, we propose scalarquantization of the latent variables in a latent representation with scalarvalues from a global codebook, and we add a total correlation term to theoptimization as an inductive bias. Our method called FactorQVAE combinesoptimization based disentanglement approaches with discrete representationlearning, and it outperforms the former disentanglement methods in terms of twodisentanglement metrics (DCI and InfoMEC) while improving the reconstructionperformance. Our code can be found athttps://github.com/ituvisionlab/FactorQVAE.</description><author>Gulcin Baykal, Melih Kandemir, Gozde Unal</author><pubDate>Wed, 05 Nov 2025 17:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.14851v3</guid></item><item><title>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</title><link>http://arxiv.org/abs/2511.03656v1</link><description>With the rapid advancement of natural language processing (NLP) technologies,the demand for high-quality Chinese document question-answering datasets issteadily growing. To address this issue, we present the Chinese Multi-DocumentQuestion Answering Dataset(ChiMDQA), specifically designed for downstreambusiness scenarios across prevalent domains including academic, education,finance, law, medical treatment, and news. ChiMDQA encompasses long-formdocuments from six distinct fields, consisting of 6,068 rigorously curated,high-quality question-answer (QA) pairs further classified into tenfine-grained categories. Through meticulous document screening and a systematicquestion-design methodology, the dataset guarantees both diversity and highquality, rendering it applicable to various NLP tasks such as documentcomprehension, knowledge extraction, and intelligent QA systems. Additionally,this paper offers a comprehensive overview of the dataset's design objectives,construction methodologies, and fine-grained evaluation system, supplying asubstantial foundation for future research and practical applications inChinese QA. The code and data are available at:https://anonymous.4open.science/r/Foxit-CHiMDQA/.</description><author>Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng</author><pubDate>Wed, 05 Nov 2025 17:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03656v1</guid></item><item><title>RoboRAN: A Unified Robotics Framework for Reinforcement Learning-Based Autonomous Navigation</title><link>http://arxiv.org/abs/2505.14526v2</link><description>Autonomous robots must navigate and operate in diverse environments, fromterrestrial and aquatic settings to aerial and space domains. WhileReinforcement Learning (RL) has shown promise in training policies for specificautonomous robots, existing frameworks and benchmarks are often constrained tounique platforms, limiting generalization and fair comparisons across differentmobility systems. In this paper, we present a multi-domain framework fortraining, evaluating and deploying RL-based navigation policies across diverserobotic platforms and operational environments. Our work presents four keycontributions: (1) a scalable and modular framework, facilitating seamlessrobot-task interchangeability and reproducible training pipelines; (2)sim-to-real transfer demonstrated through real-world experiments with multiplerobots, including a satellite robotic simulator, an unmanned surface vessel,and a wheeled ground vehicle; (3) the release of the first open-source API fordeploying Isaac Lab-trained policies to real robots, enabling lightweightinference and rapid field validation; and (4) uniform tasks and metrics forcross-medium evaluation, through a unified evaluation testbed to assessperformance of navigation tasks in diverse operational conditions (aquatic,terrestrial and space). By ensuring consistency between simulation andreal-world deployment, RoboRAN lowers the barrier to developing adaptableRL-based navigation strategies. Its modular design enables straightforwardintegration of new robots and tasks through predefined templates, fosteringreproducibility and extension to diverse domains. To support the community, werelease RoboRAN as open-source.</description><author>Matteo El-Hariry, Antoine Richard, Ricard M. Castan, Luis F. W. Batista, Matthieu Geist, Cedric Pradalier, Miguel Olivares-Mendez</author><pubDate>Wed, 05 Nov 2025 17:12:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.14526v2</guid></item><item><title>Efficient Testing Implies Structured Symmetry</title><link>http://arxiv.org/abs/2511.03653v1</link><description>Given a small random sample of $n$-bit strings labeled by an unknown Booleanfunction, which properties of this function can be tested computationallyefficiently? We show an equivalence between properties that are efficientlytestable from few samples and properties with structured symmetry, which dependonly on the function's average values on parts of a low-complexity partition ofthe domain. Without the efficiency constraint, a similar characterization interms of unstructured symmetry was obtained by Blais and Yoshida (2019). Ourmain technical tool is supersimulation, which builds on methods from thealgorithmic fairness literature to approximate arbitrarily complex functions bysmall-circuit simulators that fool significantly larger distinguishers. We extend the characterization along other axes as well. We show thatallowing parts to overlap exponentially reduces their required number,broadening the scope of the construction from properties testable with $O(\logn)$ samples to properties testable with $O(n)$ samples. For larger samplesizes, we show that any efficient tester is essentially checking forindistinguishability from a bounded collection of small circuits, in the spiritof a characterization of testable graph properties. Finally, we show that ourresults for Boolean function testing generalize to high-entropy distributiontesting on arbitrary domains.</description><author>Cynthia Dwork, Pranay Tankala</author><pubDate>Wed, 05 Nov 2025 17:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03653v1</guid></item><item><title>Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural</title><link>http://arxiv.org/abs/2511.03651v1</link><description>This paper presents the innovative design and successful deployment of apioneering autonomous unmanned aerial system developed for executing theworld's largest mural painted by a drone. Addressing the dual challenges ofmaintaining artistic precision and operational reliability under adverseoutdoor conditions such as wind and direct sunlight, our work introduces arobust system capable of navigating and painting outdoors with unprecedentedaccuracy. Key to our approach is a novel navigation system that combines aninfrared (IR) motion capture camera and LiDAR technology, enabling preciselocation tracking tailored specifically for largescale artistic applications.We employ a unique control architecture that uses different regulation intangential and normal directions relative to the planned path, enabling precisetrajectory tracking and stable line rendering. We also present algorithms fortrajectory planning and path optimization, allowing for complex curve drawingand area filling. The system includes a custom-designed paint sprayingmechanism, specifically engineered to function effectively amidst the turbulentairflow generated by the drone's propellers, which also protects the drone'scritical components from paint-related damage, ensuring longevity andconsistent performance. Experimental results demonstrate the system'srobustness and precision in varied conditions, showcasing its potential forautonomous large-scale art creation and expanding the functional applicationsof robotics in creative fields.</description><author>Andrei A. Korigodskii, Oleg D. Kalachev, Artem E. Vasiunik, Matvei V. Urvantsev, Georgii E. Bondar</author><pubDate>Wed, 05 Nov 2025 17:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03651v1</guid></item><item><title>Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals</title><link>http://arxiv.org/abs/2511.03645v1</link><description>Localisation tasks in biomedical data often require models to learnmeaningful spatial or temporal relationships from signals with complexintensity distributions. A common strategy, exemplified by CoordConv layers, isto append coordinate channels to convolutional inputs, enabling networks tolearn absolute positions. In this work, we propose a signal intensity-weightedcoordinate representation that replaces the pure coordinate channels withchannels scaled by local signal intensity. This modification embeds anintensity-position coupling directly in the input representation, introducing asimple and modality-agnostic inductive bias. We evaluate the approach on twodistinct localisation problems: (i) predicting the time of morphologicaltransition in 20-second, two-lead ECG signals, and (ii) regressing thecoordinates of nuclear centres in cytological images from the SiPaKMeD dataset.In both cases, the proposed representation yields faster convergence and highergeneralisation performance relative to conventional coordinate-channelapproaches, demonstrating its effectiveness across both one-dimensional andtwo-dimensional biomedical signals.</description><author>Vittal L. Rao</author><pubDate>Wed, 05 Nov 2025 17:06:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03645v1</guid></item><item><title>Post Persona Alignment for Multi-Session Dialogue Generation</title><link>http://arxiv.org/abs/2506.11857v2</link><description>Multi-session persona-based dialogue generation presents challenges inmaintaining long-term consistency and generating diverse, personalizedresponses. While large language models (LLMs) excel in single-sessiondialogues, they struggle to preserve persona fidelity and conversationalcoherence across extended interactions. Existing methods typically retrievepersona information before response generation, which can constrain diversityand result in generic outputs. We propose Post Persona Alignment (PPA), a noveltwo-stage framework that reverses this process. PPA first generates a generalresponse based solely on dialogue context, then retrieves relevant personamemories using the response as a query, and finally refines the response toalign with the speaker's persona. This post-hoc alignment strategy promotesnaturalness and diversity while preserving consistency and personalization.Experiments on multi-session LLM-generated dialogue data demonstrate that PPAsignificantly outperforms prior approaches in consistency, diversity, andpersona relevance, offering a more flexible and effective paradigm forlong-term personalized dialogue generation.</description><author>Yi-Pei Chen, Noriki Nishida, Hideki Nakayama, Yuji Matsumoto</author><pubDate>Wed, 05 Nov 2025 17:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.11857v2</guid></item><item><title>HAFixAgent: History-Aware Automated Program Repair Agent</title><link>http://arxiv.org/abs/2511.01047v2</link><description>Automated program repair (APR) has recently shifted toward large languagemodels and agent-based systems, yet most systems rely on local snapshotcontext, overlooking repository history. Prior work shows that repositoryhistory helps repair single-line bugs, since the last commit touching the buggyline is often the bug-introducing one. In this paper, we investigate whetherrepository history can also improve agentic APR systems at scale, especiallyfor complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-FixingAgent that injects blame-derived repository heuristics into its repair loop. Apreliminary study of all 854 real-world bugs from Defects4J motivates ourdesign, showing that bug-relevant history is both widely available and highlyconcentrated. Empirical comparison of HAFixAgent with two state-of-the-artbaselines shows: (1) Effectiveness: HAFixAgent significantly improves over theagent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)Efficiency: history does not significantly increase agent steps and keeps tokencosts comparable, with notably lower median costs for complexmulti-file-multi-hunk bugs. (3) Practicality: combining different historicalheuristics repairs more bugs, offering a clear cost-benefit trade-off.HAFixAgent offers a practical recipe for history-aware agentic APR: ground theagent in version control history, prioritize diff-based historical context, andintegrate complementary heuristics when needed.</description><author>Yu Shi, Hao Li, Bram Adams, Ahmed E. Hassan</author><pubDate>Wed, 05 Nov 2025 17:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.01047v2</guid></item><item><title>Explaining Human Choice Probabilities with Simple Vector Representations</title><link>http://arxiv.org/abs/2511.03643v1</link><description>When people pursue rewards in stochastic environments, they often match theirchoice frequencies to the observed target frequencies, even when this policy isdemonstrably sub-optimal. We used a ``hide and seek'' task to evaluate thisbehavior under conditions where pursuit (seeking) could be toggled to avoidance(hiding), while leaving the probability distribution fixed, or varyingcomplexity by changing the number of possible choices. We developed a model forparticipant choice built from choice frequency histograms treated as vectors.We posited the existence of a probability antimatching strategy for avoidance(hiding) rounds, and formalized this as a vector reflection of probabilitymatching. We found that only two basis policies: matching/antimatching andmaximizing/minimizing were sufficient to account for participant choices acrossa range of room numbers and opponent probability distributions. This schemarequires only that people have the ability to remember the relative frequencyof the different outcomes. With this knowledge simple operations can constructthe maximizing and minimizing policies as well as matching and antimatchingstrategies. A mixture of these two policies captures human choice patterns in astochastic environment.</description><author>Peter DiBerardino, Britt Anderson</author><pubDate>Wed, 05 Nov 2025 17:03:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03643v1</guid></item><item><title>Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology</title><link>http://arxiv.org/abs/2511.03641v1</link><description>To foster trustworthy Artificial Intelligence (AI) within the European Union,the AI Act requires providers to mark and detect the outputs of theirgeneral-purpose models. The Article 50 and Recital 133 call for marking methodsthat are ''sufficiently reliable, interoperable, effective and robust''. Yet,the rapidly evolving and heterogeneous landscape of watermarks for LargeLanguage Models (LLMs) makes it difficult to determine how these four standardscan be translated into concrete and measurable evaluations. Our paper addressesthis challenge, anchoring the normativity of European requirements in themultiplicity of watermarking techniques. Introducing clear and distinctconcepts on LLM watermarking, our contribution is threefold. (1) WatermarkingCategorisation: We propose an accessible taxonomy of watermarking methodsaccording to the stage of the LLM lifecycle at which they are applied - before,during, or after training, and during next-token distribution or sampling. (2)Watermarking Evaluation: We interpret the EU AI Act's requirements by mappingeach criterion with state-of-the-art evaluations on robustness anddetectability of the watermark, and of quality of the LLM. Sinceinteroperability remains largely untheorised in LLM watermarking research, wepropose three normative dimensions to frame its assessment. (3) WatermarkingComparison: We compare current watermarking methods for LLMs against theoperationalised European criteria and show that no approach yet satisfies allfour standards. Encouraged by emerging empirical tests, we recommend furtherresearch into watermarking directly embedded within the low-level architectureof LLMs.</description><author>Thomas Souverain</author><pubDate>Wed, 05 Nov 2025 17:00:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03641v1</guid></item><item><title>Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning</title><link>http://arxiv.org/abs/2509.05193v2</link><description>Low-rank structure is a common implicit assumption in many modernreinforcement learning (RL) algorithms. For instance, reward-free andgoal-conditioned RL methods often presume that the successor measure admits alow-rank representation. In this work, we challenge this assumption by firstremarking that the successor measure itself is not approximately low-rank.Instead, we demonstrate that a low-rank structure naturally emerges in theshifted successor measure, which captures the system dynamics after bypassing afew initial transitions. We provide finite-sample performance guarantees forthe entry-wise estimation of a low-rank approximation of the shifted successormeasure from sampled entries. Our analysis reveals that both the approximationand estimation errors are primarily governed by a newly introduced quantitity:the spectral recoverability of the corresponding matrix. To bound thisparameter, we derive a new class of functional inequalities for Markov chainsthat we call Type II Poincar\'e inequalities and from which we can quantify theamount of shift needed for effective low-rank approximation and estimation.This analysis shows in particular that the required shift depends on decay ofthe high-order singular values of the shifted successor measure and is hencetypically small in practice. Additionally, we establish a connection betweenthe necessary shift and the local mixing properties of the underlying dynamicalsystem, which provides a natural way of selecting the shift. Finally, wevalidate our theoretical findings with experiments, and demonstrate thatshifting the successor measure indeed leads to improved performance ingoal-conditioned RL.</description><author>Bastien Dubail, Stefan Stojanovic, Alexandre Proutière</author><pubDate>Wed, 05 Nov 2025 17:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.05193v2</guid></item><item><title>OrdShap: Feature Position Importance for Sequential Black-Box Models</title><link>http://arxiv.org/abs/2507.11855v2</link><description>Sequential deep learning models excel in domains with temporal or sequentialdependencies, but their complexity necessitates post-hoc feature attributionmethods for understanding their predictions. While existing techniques quantifyfeature importance, they inherently assume fixed feature ordering - conflatingthe effects of (1) feature values and (2) their positions within inputsequences. To address this gap, we introduce OrdShap, a novel attributionmethod that disentangles these effects by quantifying how a model's predictionschange in response to permuting feature position. We establish a game-theoreticconnection between OrdShap and Sanchez-Berganti\~nos values, providing atheoretically grounded approach to position-sensitive attribution. Empiricalresults from health, natural language, and synthetic datasets highlightOrdShap's effectiveness in capturing feature value and feature positionattributions, and provide deeper insight into model behavior.</description><author>Davin Hill, Brian L. Hill, Aria Masoomi, Vijay S. Nori, Robert E. Tillman, Jennifer Dy</author><pubDate>Wed, 05 Nov 2025 16:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.11855v2</guid></item><item><title>"Accessibility people, you go work on that thing of yours over there": Addressing Disability Inclusion in AI Product Organizations</title><link>http://arxiv.org/abs/2508.16607v2</link><description>The rapid emergence of generative AI has changed the way that technology isdesigned, constructed, maintained, and evaluated. Decisions made when creatingAI-powered systems may impact some users disproportionately, such as peoplewith disabilities. In this paper, we report on an interview study with 25 AIpractitioners across multiple roles (engineering, research, UX, and responsibleAI) about how their work processes and artifacts may impact end users withdisabilities. We found that practitioners experienced friction when triagingproblems at the intersection of responsible AI and accessibility practices,navigated contradictions between accessibility and responsible AI guidelines,identified gaps in data about users with disabilities, and gathered support foraddressing the needs of disabled stakeholders by leveraging informal volunteerand community groups within their company. Based on these findings, we offersuggestions for new resources and process changes to better support people withdisabilities as end users of AI.</description><author>Sanika Moharana, Cynthia L. Bennett, Erin Buehler, Michael Madaio, Vinita Tibdewal, Shaun K. Kane</author><pubDate>Wed, 05 Nov 2025 16:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16607v2</guid></item><item><title>Quantifying Weighted Morphological Content of Large-Scale Structures via Simulation-Based Inference</title><link>http://arxiv.org/abs/2511.03636v1</link><description>In this work, we perform a simulation-based forecasting analysis to comparethe constraining power of two higher-order summary statistics of thelarge-scale structure (LSS), the Minkowski Functionals (MFs) and theConditional Moments of Derivative (CMD), with a particular focus on theirsensitivity to nonlinear and anisotropic features in redshift-space. Ouranalysis relies on halo catalogs from the Big Sobol Sequence(BSQ) simulationsat redshift $z=0.5$, employing a likelihood-free inference frameworkimplemented via neural posterior estimation. At the fiducial cosmology of theQuijote simulations $(\Omega_{m}=0.3175,\,\sigma_{8}=0.834)$, and for thesmoothing scale $R=15\,h^{-1}$Mpc, we find that the CMD yields tighterforecasts for $(\Omega_{m}},\,\sigma_{8})$ than the zeroth- to third-order MFscomponents, improving the constraint precision by ${\sim}(44\%,\,52\%)$,${\sim}(30\%,\,45\%)$, ${\sim}(27\%,\,17\%)$, and ${\sim}(26\%,\,17\%)$,respectively. A joint configuration combining the MFs and CMD further enhancesthe precision by approximately ${\sim}27\%$ compared to the standard MFs alone,highlighting the complementary anisotropy-sensitive information captured by theCMD in contrast to the scalar morphological content encapsulated by the MFs. Wefurther extend the forecasting analysis to a continuous range of cosmologicalparameter values and multiple smoothing scales. Our results show that, althoughthe absolute forecast uncertainty for each component of summary statisticsdepends on the underlying parameter values and the adopted smoothing scale, therelative constraining power among the summary statistics remains nearlyconstant throughout.</description><author>M. H. Jalali Kanafi, S. M. S. Movahed</author><pubDate>Wed, 05 Nov 2025 16:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03636v1</guid></item><item><title>Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability</title><link>http://arxiv.org/abs/2511.03635v1</link><description>Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post towardunseen targets. Existing research using contrastive, meta-learning, or dataaugmentation suffers from generalizability issues or lack of coherence betweentext and target. Recent works leveraging large language models (LLMs) for ZSSDfocus either on improving unseen target-specific knowledge or generatingexplanations for stance analysis. However, most of these works are limited bytheir over-reliance on explicit reasoning, provide coarse explanations thatlack nuance, and do not explicitly model the reasoning process, making itdifficult to interpret the model's predictions. To address these issues, in ourstudy, we develop a novel interpretable ZSSD framework, IRIS. We provide aninterpretable understanding of the attitude of the input towards the targetimplicitly based on sequences within the text (implicit rationales) andexplicitly based on linguistic measures (explicit rationales). IRIS considersstance detection as an information retrieval ranking task, understanding therelevance of implicit rationales for different stances to guide the modeltowards correct predictions without requiring the ground-truth of rationales,thus providing inherent interpretability. In addition, explicit rationalesbased on communicative features help decode the emotional and cognitivedimensions of stance, offering an interpretable understanding of the author'sattitude towards the given target. Extensive experiments on the benchmarkdatasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%training data prove the generalizability of our model, benefiting from theproposed architecture and interpretable design.</description><author>Apoorva Upadhyaya, Wolfgang Nejdl, Marco Fisichella</author><pubDate>Wed, 05 Nov 2025 16:54:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03635v1</guid></item><item><title>Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs</title><link>http://arxiv.org/abs/2505.23845v2</link><description>We study the source of uncertainty in DeepSeek R1-32B by analyzing itsself-reported verbal confidence on question answering (QA) tasks. In thedefault answer-then-confidence setting, the model is regularly over-confident,whereas semantic entropy - obtained by sampling many responses - remainsreliable. We hypothesize that this is because of semantic entropy's largertest-time compute, which lets us explore the model's predictive distribution.We show that granting DeepSeek the budget to explore its distribution byforcing a long chain-of-thought before the final answer greatly improves itsverbal score effectiveness, even on simple fact-retrieval questions thatnormally require no reasoning. Furthermore, a separate reader model that seesonly the chain can reconstruct very similar confidences, indicating the verbalscore might be merely a statistic of the alternatives surfaced duringreasoning. Our analysis concludes that reliable uncertainty estimation requiresexplicit exploration of the generative space, and self-reported confidence istrustworthy only after such exploration.</description><author>Jakub Podolak, Rajeev Verma</author><pubDate>Wed, 05 Nov 2025 16:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.23845v2</guid></item><item><title>nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN</title><link>http://arxiv.org/abs/2511.03634v1</link><description>Tabular foundation models such as TabPFN have revolutionized predictivemachine learning for tabular data. At the same time, the driving factors ofthis revolution are hard to understand. Existing open-source tabular foundationmodels are implemented in complicated pipelines boasting over 10,000 lines ofcode, lack architecture documentation or code quality. In short, theimplementations are hard to understand, not beginner-friendly, and complicatedto adapt for new experiments. We introduce nanoTabPFN, a simplified andlightweight implementation of the TabPFN v2 architecture and a correspondingtraining loop that uses pre-generated training data. nanoTabPFN makes tabularfoundation models more accessible to students and researchers alike. Forexample, restricted to a small data setting it achieves a performancecomparable to traditional machine learning baselines within one minute ofpre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). Thiseliminated requirement of large computational resources makes pre-trainingtabular foundation models accessible for educational purposes. Our code isavailable at https://github.com/automl/nanoTabPFN.</description><author>Alexander Pfefferle, Johannes Hog, Lennart Purucker, Frank Hutter</author><pubDate>Wed, 05 Nov 2025 16:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03634v1</guid></item><item><title>Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility Environments</title><link>http://arxiv.org/abs/2511.03632v1</link><description>Beamforming has significance for enhancing spectral efficiency and mitigatinginterference in multi-antenna wireless systems, facilitating spatialmultiplexing and diversity in dense and high mobility scenarios. Traditionalbeamforming techniques such as zero-forcing beamforming (ZFBF) and minimum meansquare error (MMSE) beamforming experience performance deterioration underadverse channel conditions. Deep learning-based beamforming offers analternative with nonlinear mappings from channel state information (CSI) tobeamforming weights by improving robustness against dynamic channelenvironments. Transformer-based models are particularly effective due to theirability to model long-range dependencies across time and frequency. However,their quadratic attention complexity limits scalability in large OFDM grids.Recent studies address this issue through sparse attention mechanisms thatreduce complexity while maintaining expressiveness, yet often employ patternsthat disregard channel dynamics, as they are not specifically designed forwireless communication scenarios. In this work, we propose a Doppler-awareSparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model thatincorporates a channel-adaptive sparse attention mechanism in a multi-usersingle-input multiple-output (MU-SIMO) setting. The proposed sparsity structureis configurable along 2D time-frequency axes based on channel dynamics and istheoretically proven to ensure full connectivity within p hops, where p is thenumber of attention heads. Simulation results under urban macro (UMa) channelconditions show that Doppler-aware Sparse NNBF significantly outperforms both afixed-pattern baseline, referred to as Standard Sparse NNBF, and conventionalbeamforming techniques ZFBF and MMSE beamforming in high mobility scenarios,while maintaining structured sparsity with a controlled number of attended keysper query.</description><author>Cemil Vahapoglu, Timothy J. O'Shea, Wan Liu, Sennur Ulukus</author><pubDate>Wed, 05 Nov 2025 16:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03632v1</guid></item><item><title>A Polynomial-Time Algorithm for Variational Inequalities under the Minty Condition</title><link>http://arxiv.org/abs/2504.03432v2</link><description>Solving variational inequalities (SVIs) is a foundational problem at theheart of optimization. However, this expressivity comes at the cost ofcomputational hardness. As a result, most research has focused on carving outspecific subclasses that elude those intractability barriers. A classicalproperty that goes back to the 1960s is the Minty condition, which postulatesthat the Minty VI (MVI) problem admits a solution. In this paper, we establish the first polynomial-time algorithm -- that is,with complexity growing polynomially in the dimension $d$ and$\log(1/\epsilon)$ -- for solving $\epsilon$-SVIs for Lipschitz continuousmappings under the Minty condition. Prior approaches either incurred anexponentially worse dependence on $1/\epsilon$ or made restrictive assumptions.To do so, we introduce a new variant of the ellipsoid algorithm wherebyseparating hyperplanes are obtained after taking a gradient descent step fromthe center of the ellipsoid. It succeeds even though the set of SVIs can benonconvex and not fully dimensional. Moreover, when our algorithm is applied toan instance with no MVI solution and fails to identify an SVI solution, itproduces a succinct certificate of MVI infeasibility. We also show thatdeciding whether the Minty condition holds is $\mathsf{coNP}$-complete, therebyestablishing that the disjunction of those two problems is polynomial-timesolvable even though each problem is individually intractable. We provide several extensions and new applications of our main results. Mostnotably, we obtain the first polynomial-time algorithms for i) globallyminimizing a (potentially nonsmooth) quasar-convex function, and ii) computingNash equilibria in multi-player harmonic games. Finally, in two-playergeneral-sum concave games, we give the first polynomial-time algorithm thatoutputs either a Nash equilibrium or a strict coarse correlated equilibrium.</description><author>Ioannis Anagnostides, Gabriele Farina, Tuomas Sandholm, Brian Hu Zhang</author><pubDate>Wed, 05 Nov 2025 16:50:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.03432v2</guid></item><item><title>Financial Management System for SMEs: Real-World Deployment of Accounts Receivable and Cash Flow Prediction</title><link>http://arxiv.org/abs/2511.03631v1</link><description>Small and Medium Enterprises (SMEs), particularly freelancers and early-stagebusinesses, face unique financial management challenges due to limitedresources, small customer bases, and constrained data availability. This paperpresents the development and deployment of an integrated financial predictionsystem that combines accounts receivable prediction and cash flow forecastingspecifically designed for SME operational constraints. Our system addresses thegap between enterprise-focused financial tools and the practical needs offreelancers and small businesses. The solution integrates two key components: abinary classification model for predicting invoice payment delays, and amulti-module cash flow forecasting model that handles incomplete and limitedhistorical data. A prototype system has been implemented and deployed as a webapplication with integration into Cluee's platform, a startup providingfinancial management tools for freelancers, demonstrating practical feasibilityfor real-world SME financial management.</description><author>Bartłomiej Małkus, Szymon Bobek, Grzegorz J. Nalepa</author><pubDate>Wed, 05 Nov 2025 16:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03631v1</guid></item><item><title>LiveTradeBench: Seeking Real-World Alpha with Large Language Models</title><link>http://arxiv.org/abs/2511.03628v1</link><description>Large language models (LLMs) achieve strong performance acrossbenchmarks--from knowledge quizzes and math reasoning to web-agent tasks--butthese tests occur in static settings, lacking real dynamics and uncertainty.Consequently, they evaluate isolated reasoning or problem-solving rather thandecision-making under uncertainty. To address this, we introduceLiveTradeBench, a live trading environment for evaluating LLM agents inrealistic and evolving markets. LiveTradeBench follows three design principles:(i) Live data streaming of market prices and news, eliminating dependence onoffline backtesting and preventing information leakage while capturingreal-time uncertainty; (ii) a portfolio-management abstraction that extendscontrol from single-asset actions to multi-asset allocation, integrating riskmanagement and cross-asset reasoning; and (iii) multi-market evaluation acrossstructurally distinct environments--U.S. stocks and Polymarket predictionmarkets--differing in volatility, liquidity, and information flow. At eachstep, an agent observes prices, news, and its portfolio, then outputspercentage allocations that balance risk and return. Using LiveTradeBench, werun 50-day live evaluations of 21 LLMs across families. Results show that (1)high LMArena scores do not imply superior trading outcomes; (2) models displaydistinct portfolio styles reflecting risk appetite and reasoning dynamics; and(3) some LLMs effectively leverage live signals to adapt decisions. Thesefindings expose a gap between static evaluation and real-world competence,motivating benchmarks that test sequential decision making and consistencyunder live uncertainty.</description><author>Haofei Yu, Fenghai Li, Jiaxuan You</author><pubDate>Wed, 05 Nov 2025 16:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03628v1</guid></item><item><title>SecRepoBench: Benchmarking Code Agents for Secure Code Completion in Real-World Repositories</title><link>http://arxiv.org/abs/2504.21205v2</link><description>This paper introduces SecRepoBench, a benchmark to evaluate code agents onsecure code completion in real-world repositories. SecRepoBench has 318 codecompletion tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 28standalone LLMs and 13 code agents across 3 state-of-the-art agent frameworksusing our benchmark. We find that state-of-the-art LLMs struggle withgenerating correct and secure code completions. However, code agentssignificantly outperform standalone LLMs. We show that SecRepoBench is moredifficult than the prior state-of-the-art benchmark. Finally, our comprehensiveanalysis provides insights into potential directions for enhancing the abilityof code agents to write correct and secure code in real-world repositories.</description><author>Chihao Shen, Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen</author><pubDate>Wed, 05 Nov 2025 16:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.21205v2</guid></item><item><title>The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise</title><link>http://arxiv.org/abs/2401.07844v7</link><description>Stochastic approximation is a class of algorithms that update a vectoriteratively, incrementally, and stochastically, including, e.g., stochasticgradient descent and temporal difference learning. One fundamental challenge inanalyzing a stochastic approximation algorithm is to establish its stability,i.e., to show that the stochastic vector iterates are bounded almost surely. Inthis paper, we extend the celebrated Borkar-Meyn theorem for stability from theMartingale difference noise setting to the Markovian noise setting, whichgreatly improves its applicability in reinforcement learning, especially inthose off-policy reinforcement learning algorithms with linear functionapproximation and eligibility traces. Central to our analysis is thediminishing asymptotic rate of change of a few functions, which is implied byboth a form of the strong law of large numbers and a form of the law of theiterated logarithm.</description><author>Shuze Daniel Liu, Shuhang Chen, Shangtong Zhang</author><pubDate>Wed, 05 Nov 2025 16:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07844v7</guid></item><item><title>Fast weight programming and linear transformers: from machine learning to neurobiology</title><link>http://arxiv.org/abs/2508.08435v2</link><description>Recent advances in artificial neural networks for machine learning, andlanguage modeling in particular, have established a family of recurrent neuralnetwork (RNN) architectures that, unlike conventional RNNs with vector-formhidden states, use two-dimensional (2D) matrix-form hidden states. Such2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as aneural network whose synaptic weights (called fast weights) dynamically changeover time as a function of input observations, and serve as short-term memorystorage; corresponding synaptic weight modifications are controlled orprogrammed by another network (the programmer) whose parameters are trained(e.g., by gradient descent). In this Primer, we review the technicalfoundations of FWPs, their computational characteristics, and their connectionsto transformers and state space models. We also discuss connections betweenFWPs and models of synaptic plasticity in the brain, suggesting a convergenceof natural and artificial intelligence.</description><author>Kazuki Irie, Samuel J. Gershman</author><pubDate>Wed, 05 Nov 2025 16:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.08435v2</guid></item><item><title>R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing</title><link>http://arxiv.org/abs/2505.21600v2</link><description>Large Language Models (LLMs) achieve impressive reasoning capabilities at thecost of substantial inference overhead, posing substantial deploymentchallenges. Although distilled Small Language Models (SLMs) significantlyenhance efficiency, their performance suffers as they fail to follow LLMs'reasoning paths. Luckily, we reveal that only a small fraction of tokensgenuinely diverge reasoning paths between LLMs and SLMs. Most generated tokensare either identical or exhibit neutral differences, such as minor variationsin abbreviations or expressions. Leveraging this insight, we introduce **Roadsto Rome (R2R)**, a neural token routing method that selectively utilizes LLMsonly for these critical, path-divergent tokens, while leaving the majority oftoken generation to the SLM. We also develop an automatic data generationpipeline that identifies divergent tokens and generates token-level routinglabels to train the lightweight router. We apply R2R to combine R1-1.5B andR1-32B models from the DeepSeek family, and evaluate on challenging math,coding, and QA benchmarks. With an average activated parameter size of 5.6B,R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even theR1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup withcomparable performance, advancing the Pareto frontier of test-time scalingefficiency. Our code is available at https://github.com/thu-nics/R2R.</description><author>Tianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang</author><pubDate>Wed, 05 Nov 2025 16:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.21600v2</guid></item><item><title>CLAX: Fast and Flexible Neural Click Models in JAX</title><link>http://arxiv.org/abs/2511.03620v1</link><description>CLAX is a JAX-based library that implements classic click models using moderngradient-based optimization. While neural click models have emerged over thepast decade, complex click models based on probabilistic graphical models(PGMs) have not systematically adopted gradient-based optimization, preventingpractitioners from leveraging modern deep learning frameworks while preservingthe interpretability of classic models. CLAX addresses this gap by replacingEM-based optimization with direct gradient-based optimization in a numericallystable manner. The framework's modular design enables the integration of anycomponent, from embeddings and deep networks to custom modules, into classicclick models for end-to-end optimization. We demonstrate CLAX's efficiency byrunning experiments on the full Baidu-ULTR dataset comprising over a billionuser sessions in $\approx$ 2 hours on a single GPU, orders of magnitude fasterthan traditional EM approaches. CLAX implements ten classic click models,serving both industry practitioners seeking to understand user behavior andimprove ranking performance at scale and researchers developing new clickmodels. CLAX is available at: https://github.com/philipphager/clax</description><author>Philipp Hager, Onno Zoeter, Maarten de Rijke</author><pubDate>Wed, 05 Nov 2025 16:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03620v1</guid></item><item><title>Towards Formalizing Reinforcement Learning Theory</title><link>http://arxiv.org/abs/2511.03618v1</link><description>In this paper, we formalize the almost sure convergence of $Q$-learning andlinear temporal difference (TD) learning with Markovian samples using the Lean4 theorem prover based on the Mathlib library. $Q$-learning and linear TD areamong the earliest and most influential reinforcement learning (RL) algorithms.The investigation of their convergence properties is not only a major researchtopic during the early development of the RL field but also receives increasingattention nowadays. This paper formally verifies their almost sure convergencein a unified framework based on the Robbins-Siegmund theorem. The frameworkdeveloped in this work can be easily extended to convergence rates and othermodes of convergence. This work thus makes an important step towards fullyformalizing convergent RL results. The code is available athttps://github.com/ShangtongZhang/rl-theory-in-lean.</description><author>Shangtong Zhang</author><pubDate>Wed, 05 Nov 2025 16:35:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03618v1</guid></item><item><title>Visualization Biases MLLM's Decision Making in Network Data Tasks</title><link>http://arxiv.org/abs/2511.03617v1</link><description>We evaluate how visualizations can influence the judgment of MLLMs about thepresence or absence of bridges in a network. We show that the inclusion ofvisualization improves confidence over a structured text-based input that couldtheoretically be helpful for answering the question. On the other hand, weobserve that standard visualization techniques create a strong bias towardsaccepting or refuting the presence of a bridge -- independently of whether ornot a bridge actually exists in the network. While our results indicate thatthe inclusion of visualization techniques can effectively influence the MLLM'sjudgment without compromising its self-reported confidence, they also implythat practitioners must be careful of allowing users to include visualizationsin generative AI applications so as to avoid undesired hallucinations.</description><author>Timo Brand, Henry Förster, Stephen G. Kobourov, Jacob Miller</author><pubDate>Wed, 05 Nov 2025 16:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03617v1</guid></item><item><title>TABLET: A Large-Scale Dataset for Robust Visual Table Understanding</title><link>http://arxiv.org/abs/2509.21205v2</link><description>While table understanding increasingly relies on pixel-only settings wheretables are processed as visual representations, current benchmarkspredominantly use synthetic renderings that lack the complexity and visualdiversity of real-world tables. Additionally, existing visual tableunderstanding (VTU) datasets offer fixed examples with single visualizationsand pre-defined instructions, providing no access to underlying serialized datafor reformulation. We introduce TABLET, a large-scale VTU dataset with 4million examples across 20 tasks, grounded in 2 million unique tables where 88%preserve original visualizations. Each example includes paired image-HTMLrepresentations, comprehensive metadata, and provenance information linkingback to the source datasets. Fine-tuning vision-language models likeQwen2.5-VL-7B on TABLET improves performance on seen and unseen VTU tasks whileincreasing robustness on real-world table visualizations. By preservingoriginal visualizations and maintaining example traceability in a unifiedlarge-scale collection, TABLET establishes a foundation for robust training andextensible evaluation of future VTU models.</description><author>Iñigo Alonso, Imanol Miranda, Eneko Agirre, Mirella Lapata</author><pubDate>Wed, 05 Nov 2025 16:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21205v2</guid></item><item><title>Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning</title><link>http://arxiv.org/abs/2511.03616v1</link><description>Imitation learning traditionally requires complete state-actiondemonstrations from optimal or near-optimal experts. These requirementsseverely limit practical applicability, as many real-world scenarios provideonly state observations without corresponding actions and expert performance isoften suboptimal. In this paper we introduce a deep implicit imitationreinforcement learning framework that addresses both limitations by combiningdeep reinforcement learning with implicit imitation learning fromobservation-only datasets. Our main algorithm, Deep Implicit ImitationQ-Network (DIIQN), employs an action inference mechanism that reconstructsexpert actions through online exploration and integrates a dynamic confidencemechanism that adaptively balances expert-guided and self-directed learning.This enables the agent to leverage expert guidance for accelerated trainingwhile maintaining capacity to surpass suboptimal expert performance. We furtherextend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm totackle scenarios where expert and agent possess different action sets, achallenge previously unaddressed in the implicit imitation learning literature.HA-DIIQN introduces an infeasibility detection mechanism and a bridgingprocedure identifying alternative pathways connecting agent capabilities toexpert guidance when direct action replication is impossible. Our experimentalresults demonstrate that DIIQN achieves up to 130% higher episodic returnscompared to standard DQN, while consistently outperforming existing implicitimitation methods that cannot exceed expert performance. In heterogeneousaction settings, HA-DIIQN learns up to 64% faster than baselines, leveragingexpert datasets unusable by conventional approaches. Extensive parametersensitivity analysis reveals the framework's robustness across varying datasetsizes and hyperparameter configurations.</description><author>Iason Chrysomallis, Georgios Chalkiadakis</author><pubDate>Wed, 05 Nov 2025 16:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03616v1</guid></item><item><title>A systematic review of relation extraction task since the emergence of Transformers</title><link>http://arxiv.org/abs/2511.03610v1</link><description>This article presents a systematic review of relation extraction (RE)research since the advent of Transformer-based models. Using an automatedframework to collect and annotate publications, we analyze 34 surveys, 64datasets, and 104 models published between 2019 and 2024. The review highlightsmethodological advances, benchmark resources, and the integration of semanticweb technologies. By consolidating results across multiple dimensions, thestudy identifies current trends, limitations, and open challenges, offeringresearchers and practitioners a comprehensive reference for understanding theevolution and future directions of RE.</description><author>Ringwald Celian, Gandon, Fabien, Faron Catherine, Michel Franck, Abi Akl Hanna</author><pubDate>Wed, 05 Nov 2025 16:28:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03610v1</guid></item><item><title>Vector-valued self-normalized concentration inequalities beyond sub-Gaussianity</title><link>http://arxiv.org/abs/2511.03606v1</link><description>The study of self-normalized processes plays a crucial role in a wide rangeof applications, from sequential decision-making to econometrics. While thebehavior of self-normalized concentration has been widely investigated forscalar-valued processes, vector-valued processes remain comparativelyunderexplored, especially outside of the sub-Gaussian framework. In thiscontribution, we provide concentration bounds for self-normalized processeswith light tails beyond sub-Gaussianity (such as Bennett or Bernstein bounds).We illustrate the relevance of our results in the context of online linearregression, with applications in (kernelized) linear bandits.</description><author>Diego Martinez-Taboada, Tomas Gonzalez, Aaditya Ramdas</author><pubDate>Wed, 05 Nov 2025 16:27:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03606v1</guid></item><item><title>Token Perturbation Guidance for Diffusion Models</title><link>http://arxiv.org/abs/2506.10036v2</link><description>Classifier-free guidance (CFG) has become an essential component of moderndiffusion models to enhance both generation quality and alignment with inputconditions. However, CFG requires specific training procedures and is limitedto conditional generation. To address these limitations, we propose TokenPerturbation Guidance (TPG), a novel method that applies perturbation matricesdirectly to intermediate token representations within the diffusion network.TPG employs a norm-preserving shuffling operation to provide effective andstable guidance signals that improve generation quality without architecturalchanges. As a result, TPG is training-free and agnostic to input conditions,making it readily applicable to both conditional and unconditional generation.We further analyze the guidance term provided by TPG and show that its effecton sampling more closely resembles CFG compared to existing training-freeguidance techniques. Extensive experiments on SDXL and Stable Diffusion 2.1show that TPG achieves nearly a 2$\times$ improvement in FID for unconditionalgeneration over the SDXL baseline, while closely matching CFG in promptalignment. These results establish TPG as a general, condition-agnosticguidance method that brings CFG-like benefits to a broader class of diffusionmodels.</description><author>Javad Rajabi, Soroush Mehraban, Seyedmorteza Sadat, Babak Taati</author><pubDate>Wed, 05 Nov 2025 16:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.10036v2</guid></item><item><title>Step-Audio-EditX Technical Report</title><link>http://arxiv.org/abs/2511.03601v1</link><description>We present Step-Audio-EditX, the first open-source LLM-based audio modelexcelling at expressive and iterative audio editing encompassing emotion,speaking style, and paralinguistics alongside robust zero-shot text-to-speech(TTS) capabilities.Our core innovation lies in leveraging only large-marginsynthetic data, which circumvents the need for embedding-based priors orauxiliary modules. This large-margin learning approach enables both iterativecontrol and high expressivity across voices, and represents a fundamental pivotfrom the conventional focus on representation-level disentanglement. Evaluationresults demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd andDoubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.</description><author>Chao Yan, Boyong Wu, Peng Yang, Pengfei Tan, Guoqiang Hu, Yuxin Zhang, Xiangyu, Zhang, Fei Tian, Xuerui Yang, Xiangyu Zhang, Daxin Jiang, Gang Yu</author><pubDate>Wed, 05 Nov 2025 16:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03601v1</guid></item><item><title>Harmonious Color Pairings: Insights from Human Preference and Natural Hue Statistics</title><link>http://arxiv.org/abs/2508.15777v2</link><description>While color harmony has long been studied in art and design, a clearconsensus remains elusive, as most models are grounded in qualitative insightsor limited datasets. In this work, we present a quantitative, data-driven studyof color pairing preferences using controlled hue-based palettes in the HSLcolor space. Participants evaluated combinations of thirteen distinct hues,enabling us to construct a preference matrix and define a combinability indexfor each color. Our results reveal that preferences are highly hue dependent,challenging the assumption of universal harmony rules proposed in theliterature. Yet, when averaged over hues, statistically meaningful patterns ofaesthetic preference emerge, with certain hue separations perceived as moreharmonious. Strikingly, these patterns align with hue distributions found innatural landscapes, pointing to a statistical correspondence between humancolor preferences and the structure of color in nature. Finally, we analyze ourcolor-pairing score matrix through principal component analysis, which uncoverstwo complementary hue groups whose interplay underlies the global structure ofcolor-pairing preferences. Together, these findings offer a quantitativeframework for studying color harmony and its potential perceptual andecological underpinnings.</description><author>Ortensia Forni, Alexandre Darmon, Michael Benzaquen</author><pubDate>Wed, 05 Nov 2025 16:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.15777v2</guid></item><item><title>Tensor-Efficient High-Dimensional Q-learning</title><link>http://arxiv.org/abs/2511.03595v1</link><description>High-dimensional reinforcement learning faces challenges with complexcalculations and low sample efficiency in large state-action spaces. Q-learningalgorithms struggle particularly with the curse of dimensionality, where thenumber of state-action pairs grows exponentially with problem size. Whileneural network-based approaches like Deep Q-Networks have shown success, recenttensor-based methods using low-rank decomposition offer moreparameter-efficient alternatives. Building upon existing tensor-based methods,we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensordecomposition via improved block coordinate descent on discretized state-actionspaces, incorporating novel exploration and regularization mechanisms. The keyinnovation is an exploration strategy that combines approximation error withvisit count-based upper confidence bound to prioritize actions with highuncertainty, avoiding wasteful random exploration. Additionally, we incorporatea frequency-based penalty term in the objective function to encourageexploration of less-visited state-action pairs and reduce overfitting tofrequently visited regions. Empirical results on classic control tasksdemonstrate that TEQL outperforms conventional matrix-based methods and deep RLapproaches in both sample efficiency and total rewards, making it suitable forresource-constrained applications, such as space and healthcare where samplingcosts are high.</description><author>Junyi Wu, Dan Li</author><pubDate>Wed, 05 Nov 2025 16:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03595v1</guid></item><item><title>Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents</title><link>http://arxiv.org/abs/2503.16711v2</link><description>Autonomous agents that rely purely on perception to make real-time controldecisions require efficient and robust architectures. In this work, wedemonstrate that augmenting RGB input with depth information significantlyenhances our agents' ability to predict steering commands compared to using RGBalone. We benchmark lightweight recurrent controllers that leverage the fusedRGB-D features for sequential decision-making. To train our models, we collecthigh-quality data using a small-scale autonomous car controlled by an expertdriver via a physical steering wheel, capturing varying levels of steeringdifficulty. Our models were successfully deployed on real hardware andinherently avoided dynamic and static obstacles, under out-of-distributionconditions. Specifically, our findings reveal that the early fusion of depthdata results in a highly robust controller, which remains effective even withframe drops and increased noise levels, without compromising the network'sfocus on the task.</description><author>Mihaela-Larisa Clement, Mónika Farsang, Felix Resch, Mihai-Teodor Stanusoiu, Radu Grosu</author><pubDate>Wed, 05 Nov 2025 16:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.16711v2</guid></item><item><title>Dense SAE Latents Are Features, Not Bugs</title><link>http://arxiv.org/abs/2506.15679v2</link><description>Sparse autoencoders (SAEs) are designed to extract interpretable featuresfrom language models by enforcing a sparsity constraint. Ideally, training anSAE would yield latents that are both sparse and semantically meaningful.However, many SAE latents activate frequently (i.e., are \emph{dense}), raisingconcerns that they may be undesirable artifacts of the training procedure. Inthis work, we systematically investigate the geometry, function, and origin ofdense latents and show that they are not only persistent but often reflectmeaningful model representations. We first demonstrate that dense latents tendto form antipodal pairs that reconstruct specific directions in the residualstream, and that ablating their subspace suppresses the emergence of new densefeatures in retrained SAEs -- suggesting that high density features are anintrinsic property of the residual space. We then introduce a taxonomy of denselatents, identifying classes tied to position tracking, context binding,entropy regulation, letter-specific output signals, part-of-speech, andprincipal component reconstruction. Finally, we analyze how these featuresevolve across layers, revealing a shift from structural features in earlylayers, to semantic features in mid layers, and finally to output-orientedsignals in the last layers of the model. Our findings indicate that denselatents serve functional roles in language model computation and should not bedismissed as training noise.</description><author>Xiaoqing Sun, Alessandro Stolfo, Joshua Engels, Ben Wu, Senthooran Rajamanoharan, Mrinmaya Sachan, Max Tegmark</author><pubDate>Wed, 05 Nov 2025 16:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.15679v2</guid></item><item><title>Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation</title><link>http://arxiv.org/abs/2511.01450v2</link><description>Recent studies have identified Direct Preference Optimization (DPO) as anefficient and reward-free approach to improving video generation quality.However, existing methods largely follow image-domain paradigms and are mainlydeveloped on small-scale models (approximately 2B parameters), limiting theirability to address the unique challenges of video tasks, such as costly dataconstruction, unstable training, and heavy memory consumption. To overcomethese limitations, we introduce a GT-Pair that automatically buildshigh-quality preference pairs by using real videos as positives andmodel-generated videos as negatives, eliminating the need for any externalannotation. We further present Reg-DPO, which incorporates the SFT loss as aregularization term into the DPO loss to enhance training stability andgeneration fidelity. Additionally, by combining the FSDP framework withmultiple memory optimization techniques, our approach achieves nearly threetimes higher training capacity than using FSDP alone. Extensive experiments onboth I2V and T2V tasks across multiple datasets demonstrate that our methodconsistently outperforms existing approaches, delivering superior videogeneration quality.</description><author>Jie Du, Xinyu Gong, Qingshan Tan, Wen Li, Yangming Cheng, Weitao Wang, Chenlu Zhan, Suhui Wu, Hao Zhang, Jun Zhang</author><pubDate>Wed, 05 Nov 2025 16:11:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.01450v2</guid></item><item><title>Human Mesh Modeling for Anny Body</title><link>http://arxiv.org/abs/2511.03589v1</link><description>Parametric body models are central to many human-centric tasks, yet existingmodels often rely on costly 3D scans and learned shape spaces that areproprietary and demographically narrow. We introduce Anny, a simple, fullydifferentiable, and scan-free human body model grounded in anthropometricknowledge from the MakeHuman community. Anny defines a continuous,interpretable shape space, where phenotype parameters (e.g. gender, age,height, weight) control blendshapes spanning a wide range of human forms --across ages (from infants to elders), body types, and proportions. Calibratedusing WHO population statistics, it provides realistic and demographicallygrounded human shape variation within a single unified model. Thanks to itsopenness and semantic control, Anny serves as a versatile foundation for 3Dhuman modeling -- supporting millimeter-accurate scan fitting, controlledsynthetic data generation, and Human Mesh Recovery (HMR). We further introduceAnny-One, a collection of 800k photorealistic humans generated with Anny,showing that despite its simplicity, HMR models trained with Anny can match theperformance of those trained with scan-based body models, while remaininginterpretable and broadly representative. The Anny body model and its code arereleased under the Apache 2.0 license, making Anny an accessible foundation forhuman-centric 3D modeling.</description><author>Romain Brégier, Guénolé Fiche, Laura Bravo-Sánchez, Thomas Lucas, Matthieu Armando, Philippe Weinzaepfel, Grégory Rogez, Fabien Baradel</author><pubDate>Wed, 05 Nov 2025 16:10:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03589v1</guid></item><item><title>SME-TEAM: Leveraging Trust and Ethics for Secure and Responsible Use of AI and LLMs in SMEs</title><link>http://arxiv.org/abs/2509.10594v2</link><description>Artificial Intelligence (AI) and Large Language Models (LLMs) arerevolutionizing today's business practices; however, their adoption withinsmall and medium-sized enterprises (SMEs) raises serious trust, ethical, andtechnical issues. In this perspective paper, we introduce a structured,multi-phased framework, "SME-TEAM" for the secure and responsible use of thesetechnologies in SMEs. Based on a conceptual structure of four key pillars,i.e., Data, Algorithms, Human Oversight, and Model Architecture, SME-TEAMbridges theoretical ethical principles with operational practice, enhancing AIcapabilities across a wide range of applications in SMEs. Ultimately, thispaper provides a structured roadmap for the adoption of these emergingtechnologies, positioning trust and ethics as a driving force for resilience,competitiveness, and sustainable innovation within the area of businessanalytics and SMEs.</description><author>Iqbal H. Sarker, Helge Janicke, Ahmad Mohsin, Leandros Maglaras</author><pubDate>Wed, 05 Nov 2025 16:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.10594v2</guid></item><item><title>PerfDojo: Automated ML Library Generation for Heterogeneous Architectures</title><link>http://arxiv.org/abs/2511.03586v1</link><description>The increasing complexity of machine learning models and the proliferation ofdiverse hardware architectures (CPUs, GPUs, accelerators) make achievingoptimal performance a significant challenge. Heterogeneity in instruction sets,specialized kernel requirements for different data types and model features(e.g., sparsity, quantization), and architecture-specific optimizationscomplicate performance tuning. Manual optimization is resource-intensive, whileexisting automatic approaches often rely on complex hardware-specificheuristics and uninterpretable intermediate representations, hinderingperformance portability. We introduce PerfLLM, a novel automatic optimizationmethodology leveraging Large Language Models (LLMs) and Reinforcement Learning(RL). Central to this is PerfDojo, an environment framing optimization as an RLgame using a human-readable, mathematically-inspired code representation thatguarantees semantic validity through transformations. This allows effectiveoptimization without prior hardware knowledge, facilitating both human analysisand RL agent training. We demonstrate PerfLLM's ability to achieve significantperformance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.</description><author>Andrei Ivanov, Siyuan Shen, Gioele Gottardo, Marcin Chrapek, Afif Boudaoud, Timo Schneider, Luca Benini, Torsten Hoefler</author><pubDate>Wed, 05 Nov 2025 16:05:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03586v1</guid></item><item><title>Interpretable Tile-Based Classification of Paclitaxel Exposure</title><link>http://arxiv.org/abs/2510.23363v2</link><description>Medical image analysis is central to drug discovery and preclinicalevaluation, where scalable, objective readouts can accelerate decision-making.We address classification of paclitaxel (Taxol) exposure from phase-contrastmicroscopy of C6 glioma cells -- a task with subtle dose differences thatchallenges full-image models. We propose a simple tiling-and-aggregationpipeline that operates on local patches and combines tile outputs into an imagelabel, achieving state-of-the-art accuracy on the benchmark dataset andimproving over the published baseline by around 20 percentage points, withtrends confirmed by cross-validation. To understand why tiling is effective, wefurther apply Grad-CAM and Score-CAM and attention analyses, which enhancemodel interpretability and point toward robustness-oriented directions forfuture medical image research. Code is released to facilitate reproduction andextension.</description><author>Sean Fletcher, Gabby Scott, Douglas Currie, Xin Zhang, Yuqi Song, Bruce MacLeod</author><pubDate>Wed, 05 Nov 2025 16:02:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.23363v2</guid></item><item><title>Learning Under Laws: A Constraint-Projected Neural PDE Solver that Eliminates Hallucinations</title><link>http://arxiv.org/abs/2511.03578v1</link><description>Neural networks can approximate solutions to partial differential equations,but they often break the very laws they are meant to model-creating mass fromnowhere, drifting shocks, or violating conservation and entropy. We addressthis by training within the laws of physics rather than beside them. Ourframework, called Constraint-Projected Learning (CPL), keeps every updatephysically admissible by projecting network outputs onto the intersection ofconstraint sets defined by conservation, Rankine-Hugoniot balance, entropy, andpositivity. The projection is differentiable and adds only about 10%computational overhead, making it fully compatible with back-propagation. Wefurther stabilize training with total-variation damping (TVD) to suppress smalloscillations and a rollout curriculum that enforces consistency over longprediction horizons. Together, these mechanisms eliminate both hard and softviolations: conservation holds at machine precision, total-variation growthvanishes, and entropy and error remain bounded. On Burgers and Euler systems,CPL produces stable, physically lawful solutions without loss of accuracy.Instead of hoping neural solvers will respect physics, CPL makes that behavioran intrinsic property of the learning process.</description><author>Mainak Singha</author><pubDate>Wed, 05 Nov 2025 16:01:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03578v1</guid></item><item><title>Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution</title><link>http://arxiv.org/abs/2511.03576v1</link><description>While personalisation in Human-Robot Interaction (HRI) has advancedsignificantly, most existing approaches focus on single-user adaptation,overlooking scenarios involving multiple stakeholders with potentiallyconflicting preferences. To address this, we propose the Multi-User PreferencesQuantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-userpersonalisation framework based on Quantitative Bipolar ArgumentationFrameworks (QBAFs) that explicitly models and resolves multi-user preferenceconflicts. Unlike prior work in Argumentation Frameworks, which typicallyassumes static inputs, our approach is tailored to robotics: it incorporatesboth users' arguments and the robot's dynamic observations of the environment,allowing the system to adapt over time and respond to changing contexts.Preferences, both positive and negative, are represented as arguments whosestrength is recalculated iteratively based on new information. The framework'sproperties and capabilities are presented and validated through a realisticcase study, where an assistive robot mediates between the conflictingpreferences of a caregiver and a care recipient during a frailty assessmenttask. This evaluation further includes a sensitivity analysis of argument basescores, demonstrating how preference outcomes can be shaped by user input andcontextual observations. By offering a transparent, structured, andcontext-sensitive approach to resolving competing user preferences, this workadvances the field of multi-user HRI. It provides a principled alternative todata-driven methods, enabling robots to navigate conflicts in real-worldenvironments.</description><author>Aniol Civit, Antonio Andriella, Carles Sierra, Guillem Alenyà</author><pubDate>Wed, 05 Nov 2025 15:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03576v1</guid></item><item><title>Dynamical loss functions shape landscape topography and improve learning in artificial neural networks</title><link>http://arxiv.org/abs/2410.10690v3</link><description>Dynamical loss functions are derived from standard loss functions used insupervised classification tasks, but are modified so that the contribution fromeach class periodically increases and decreases. These oscillations globallyalter the loss landscape without affecting the global minima. In this paper, wedemonstrate how to transform cross-entropy and mean squared error intodynamical loss functions. We begin by discussing the impact of increasing thesize of the neural network or the learning rate on the depth and sharpness ofthe minima that the system explores. Building on this intuition, we proposeseveral versions of dynamical loss functions and use a simple classificationproblem where we can show how they significantly improve validation accuracyfor networks of varying sizes. Finally, we explore how the landscape of thesedynamical loss functions evolves during training, highlighting the emergence ofinstabilities that may be linked to edge-of-instability minimization.</description><author>Eduardo Lavin Pallero, Miguel Ruiz-Garcia</author><pubDate>Wed, 05 Nov 2025 15:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10690v3</guid></item><item><title>Decision-aware training of spatiotemporal forecasting models to select a top K subset of sites for intervention</title><link>http://arxiv.org/abs/2503.05622v3</link><description>Optimal allocation of scarce resources is a common problem for decisionmakers faced with choosing a limited number of locations for intervention.Spatiotemporal prediction models could make such decisions data-driven. Arecent performance metric called fraction of best possible reach (BPR) measuresthe impact of using a model's recommended size K subset of sites compared tothe best possible top-K in hindsight. We tackle two open problems related toBPR. First, we explore how to rank all sites numerically given a probabilisticmodel that predicts event counts jointly across sites. Ranking via the per-sitemean is suboptimal for BPR. Instead, we offer a better ranking for BPR backedby decision theory. Second, we explore how to train a probabilistic model'sparameters to maximize BPR. Discrete selection of K sites implies all-zeroparameter gradients which prevent standard gradient training. We overcome thisbarrier via advances in perturbed optimizers. We further suggest a trainingobjective that combines likelihood with a decision-aware BPR constraint todeliver high-quality top-K rankings as well as good forecasts for all sites. Wedemonstrate our approach on two where-to-intervene applications: mitigatingopioid-related fatal overdoses for public health and monitoring endangeredwildlife.</description><author>Kyle Heuton, F. Samuel Muench, Shikhar Shrestha, Thomas J. Stopka, Michael C. Hughes</author><pubDate>Wed, 05 Nov 2025 15:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.05622v3</guid></item><item><title>OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera</title><link>http://arxiv.org/abs/2511.03571v1</link><description>Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet mostsemantic scene completion (SSC) systems target wheeled platforms withforward-facing sensors. We present OneOcc, a vision-only panoramic SSCframework designed for gait-introduced body jitter and 360{\deg} continuity.OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annularpanorama and its equirectangular unfolding, preserving 360{\deg} continuity andgrid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian andcylindrical-polar spaces, reducing discretization bias and sharpeningfree/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3Dfor dynamic multi-scale fusion and better long-range/occlusion reasoning; and(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-levelmotion correction without extra sensors. We also release two panoramicoccupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) andHuman360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semanticoccupancy; standardized within-/cross-city splits). OneOcc sets newstate-of-the-art (SOTA): on QuadOcc it beats strong vision baselines andpopular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08(cross-city). Modules are lightweight, enabling deployable full-surroundperception for legged/humanoid robots. Datasets and code will be publiclyavailable at https://github.com/MasterHow/OneOcc.</description><author>Hao Shi, Ze Wang, Shangwei Guo, Mengfei Duan, Song Wang, Teng Chen, Kailun Yang, Lin Wang, Kaiwei Wang</author><pubDate>Wed, 05 Nov 2025 15:51:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03571v1</guid></item><item><title>Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination</title><link>http://arxiv.org/abs/2508.08826v3</link><description>Real-time rendering with global illumination is crucial to afford the userrealistic experience in virtual environments. We present a learning-basedestimator to predict diffuse indirect illumination in screen space, which thenis combined with direct illumination to synthesize globally-illuminated highdynamic range (HDR) results. Our approach tackles the challenges of capturinglong-range/long-distance indirect illumination when employing neural networksand is generalized to handle complex lighting and scenarios. From the neural network thinking of the solver to the rendering equation, wepresent a novel network architecture to predict indirect illumination. Ournetwork is equipped with a modified attention mechanism that aggregates globalinformation guided by spacial geometry features, as well as a monochromaticdesign that encodes each color channel individually. We conducted extensive evaluations, and the experimental results demonstrateour superiority over previous learning-based techniques. Our approach excels athandling complex lighting such as varying-colored lighting and environmentlighting. It can successfully capture distant indirect illumination andsimulates the interreflections between textured surfaces well (i.e., colorbleeding effects); it can also effectively handle new scenes that are notpresent in the training dataset.</description><author>Meng Gai, Guoping Wang, Sheng Li</author><pubDate>Wed, 05 Nov 2025 15:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.08826v3</guid></item><item><title>TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval</title><link>http://arxiv.org/abs/2511.03570v1</link><description>We study LLMs for tabular prediction with mixed text, numeric, andcategorical fields. We introduce TabGemma, a schema-agnostic in-context learnerthat treats rows as sequences and tackles two practical hurdles when adaptingpretrained LLMs for tabular predictions: unstable numeric tokenization andlimited context size. We propose to canonicalize numbers via signed scientificnotation and continue pretraining of a 12B Gemma 3 model with a targetimputation objective using a large-scale real world dataset. For inference, weuse a compact n-gram-based retrieval to select informative exemplars that fitwithin a 128k-token window. On semantically rich benchmarks, TabGemma establishes a new state of the arton classification across low- and high-data regimes and improves monotonicallywith more context rows. For regression, it is competitive at small sample sizesbut trails conventional approaches as data grows. Our results show that LLMscan be effective tabular in-context learners on highly semantic tasks whenpaired with dedicated numeric handling and context retrieval, while motivatingfurther advances in numeric modeling and long-context scaling.</description><author>Günther Schindler, Maximilian Schambach, Michael Medek, Sam Thelin</author><pubDate>Wed, 05 Nov 2025 15:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03570v1</guid></item><item><title>Navigating High Dimensional Concept Space with Metalearning</title><link>http://arxiv.org/abs/2508.01948v3</link><description>Rapidly learning abstract concepts from limited examples is a hallmark ofhuman intelligence. This work investigates whether gradient-based meta-learningcan equip neural networks with inductive biases for efficient few-shotacquisition of discrete concepts. I compare meta-learning methods against asupervised learning baseline on Boolean concepts (logical statements) generatedby a probabilistic context-free grammar (PCFG). By systematically varyingconcept dimensionality (number of features) and recursive compositionality(depth of grammar recursion), I delineate between complexity regimes in whichmeta-learning robustly improves few-shot concept learning and regimes in whichit does not. Meta-learners are much better able to handle compositionalcomplexity than featural complexity. I highlight some reasons for this with arepresentational analysis of the weights of meta-learners and a loss landscapeanalysis demonstrating how featural complexity increases the roughness of losstrajectories, allowing curvature-aware optimization to be more effective thanfirst-order methods. I find improvements in out-of-distribution generalizationon complex concepts by increasing the number of adaptation steps in meta-SGD,where adaptation acts as a way of encouraging exploration of rougher lossbasins. Overall, this work highlights the intricacies of learning compositionalversus featural complexity in high dimensional concept spaces and provides aroad to understanding the role of 2nd order methods and extended gradientadaptation in few-shot concept learning.</description><author>Max Gupta</author><pubDate>Wed, 05 Nov 2025 15:50:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.01948v3</guid></item><item><title>Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances</title><link>http://arxiv.org/abs/2511.03565v1</link><description>Imitation learning (IL) enables agents to acquire skills by observing andreplicating the behavior of one or multiple experts. In recent years, advancesin deep learning have significantly expanded the capabilities and scalabilityof imitation learning across a range of domains, where expert data can rangefrom full state-action trajectories to partial observations or unlabeledsequences. Alongside this growth, novel approaches have emerged, with newmethodologies being developed to address longstanding challenges such asgeneralization, covariate shift, and demonstration quality. In this survey, wereview the latest advances in imitation learning research, highlighting recenttrends, methodological innovations, and practical applications. We propose anovel taxonomy that is distinct from existing categorizations to better reflectthe current state of the IL research stratum and its trends. Throughout thesurvey, we critically examine the strengths, limitations, and evaluationpractices of representative works, and we outline key challenges and opendirections for future research.</description><author>Iason Chrysomallis, Georgios Chalkiadakis</author><pubDate>Wed, 05 Nov 2025 15:47:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03565v1</guid></item><item><title>Text-guided Fine-Grained Video Anomaly Detection</title><link>http://arxiv.org/abs/2511.00524v2</link><description>Video Anomaly Detection (VAD) aims to identify anomalous events within videosegments. In scenarios such as surveillance or industrial process monitoring,anomaly detection is of critical importance. While existing approaches aresemi-automated, requiring human assessment for anomaly detection, traditionalVADs offer limited output as either normal or anomalous. We propose Text-guidedFine-Grained Video Anomaly Detection (T-VAD), a framework built upon LargeVision-Language Model (LVLM). T-VAD introduces an Anomaly Heatmap Decoder (AHD)that performs pixel-wise visual-textual feature alignment to generatefine-grained anomaly heatmaps. Furthermore, we design a Region-aware AnomalyEncoder (RAE) that transforms the heatmaps into learnable textual embeddings,guiding the LVLM to accurately identify and localize anomalous events invideos. This significantly enhances both the granularity and interactivity ofanomaly detection. The proposed method achieving SOTA performance bydemonstrating 94.8% Area Under the Curve (AUC, specifically micro-AUC) and67.8%/76.7% accuracy in anomaly heatmaps (RBDC/TBDC) on the UBnormal dataset,and subjectively verified more preferable textual description on theShanghaiTech-based dataset (BLEU-4: 62.67 for targets, 88.84 for trajectories;Yes/No accuracy: 97.67%), and on the UBnormal dataset (BLEU-4: 50.32 fortargets, 78.10 for trajectories; Yes/No accuracy: 89.73%).</description><author>Jihao Gu, Kun Li, He Wang, Kaan Akşit</author><pubDate>Wed, 05 Nov 2025 15:46:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.00524v2</guid></item><item><title>ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation</title><link>http://arxiv.org/abs/2511.03563v1</link><description>In this study, we explore the fine-tuning of Large Language Models (LLMs) tobetter support policymakers in their crucial work of understanding, analyzing,and crafting legal regulations. To equip the model with a deep understanding oflegal texts, we curated a supervised dataset tailored to the specific needs ofthe legal domain. Additionally, we integrated the Retrieval-AugmentedGeneration (RAG) method, enabling the LLM to access and incorporate up-to-datelegal knowledge from external sources. This combination of fine-tuning andRAG-based augmentation results in a tool that not only processes legalinformation but actively assists policymakers in interpreting regulations anddrafting new ones that align with current needs. The results demonstrate thatthis approach can significantly enhance the effectiveness of legal research andregulation development, offering a valuable resource in the ever-evolving fieldof law.</description><author>One Octadion, Bondan Sapta Prakoso, Nanang Yudi Setiawan, Novanto Yudistira</author><pubDate>Wed, 05 Nov 2025 15:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03563v1</guid></item><item><title>AILA--First Experiments with Localist Language Models</title><link>http://arxiv.org/abs/2511.03559v1</link><description>This paper presents the first empirical demonstration of controllablelocality in transformer language models, a novel architectural framework thatenables continuous control over the degree of representation localizationthrough a tunable locality dial parameter. Unlike traditional language modelsthat rely exclusively on distributed representations, our approach allowsdynamic interpolation between highly interpretable localist encodings andefficient distributed representations without requiring model retraining. Weconducted experiments on the WikiText corpus using a two-layer transformerarchitecture, systematically varying the locality parameter {\lambda} acrossthe full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Ourresults demonstrate that localist configurations achieve dramatically lowerattention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18bits at {\lambda} = 0.0, while maintaining substantially higher pointerfidelity scores reflecting stronger alignment with rule-specified targets.Prediction experiments reveal that intermediate locality values optimize thetradeoff between interpretability and performance, with {\lambda} = 0.6achieving test perplexity of 4.65 and accuracy of 84.7%. These findingsestablish that localist language models provide a practical framework forapplications in regulated domains requiring both transparency and capability,offering precise mathematical control over the interpretability-performancespectrum through explicit penalty thresholds and information-theoretic designprinciples.</description><author>Joachim Diederich</author><pubDate>Wed, 05 Nov 2025 15:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03559v1</guid></item><item><title>Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty</title><link>http://arxiv.org/abs/2508.05659v3</link><description>Causal loop diagrams (CLDs) are widely used in health and environmentalresearch to represent hypothesized causal structures underlying complexproblems. However, as qualitative and static representations, CLDs are limitedin their ability to support dynamic analysis and inform interventionstrategies. We propose Diagrams-to-Dynamics (D2D), a method for converting CLDsinto exploratory system dynamics models (SDMs) in the absence of empiricaldata. With minimal user input - following a protocol to label variables asstocks, flows or auxiliaries, and constants - D2D leverages the structuralinformation already encoded in CLDs, namely, link existence and polarity, tosimulate hypothetical interventions and explore potential leverage points underuncertainty. Results suggest that D2D helps distinguish between high- andlow-ranked leverage points. We compare D2D to a data-driven SDM constructedfrom the same CLD and variable labels. D2D showed greater consistency with thedata-driven model compared to static network centrality analysis, whileproviding uncertainty estimates and guidance for future data collection. TheD2D method is implemented in an open-source Python package and a web-basedapplication to support further testing and lower the barrier to dynamicmodeling for researchers working with CLDs. We expect that additionalvalidation studies will further establish the approach's utility across a broadrange of cases and domains.</description><author>Jeroen F. Uleman, Loes Crielaard, Leonie K. Elsenburg, Guido A. Veldhuis, Naja Hulvej Rod, Rick Quax, Vítor V. Vasconcelos</author><pubDate>Wed, 05 Nov 2025 15:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.05659v3</guid></item><item><title>The Structure of Cross-Validation Error: Stability, Covariance, and Minimax Limits</title><link>http://arxiv.org/abs/2511.03554v1</link><description>Despite ongoing theoretical research on cross-validation (CV), manytheoretical questions about CV remain widely open. This motivates ourinvestigation into how properties of algorithm-distribution pairs can affectthe choice for the number of folds in $k$-fold cross-validation. Our results consist of a novel decomposition of the mean-squared error ofcross-validation for risk estimation, which explicitly captures thecorrelations of error estimates across overlapping folds and includes a novelalgorithmic stability notion, squared loss stability, that is considerablyweaker than the typically required hypothesis stability in other comparableworks. Furthermore, we prove: 1. For every learning algorithm that minimizes empirical error, a minimaxlower bound on the mean-squared error of $k$-fold CV estimating the populationrisk $L_\mathcal{D}$: \[ \min_{k \mid n}\; \max_{\mathcal{D}}\;\mathbb{E}\!\left[\big(\widehat{L}_{\mathrm{CV}}^{(k)} -L_{\mathcal{D}}\big)^{2}\right] \;=\; \Omega\!\big(\sqrt{k}/n\big), \] where$n$ is the sample size and $k$ the number of folds. This shows that even underidealized conditions, for large values of $k$, CV cannot attain the optimum oforder $1/n$ achievable by a validation set of size $n$, reflecting an inherentpenalty caused by dependence between folds. 2. Complementing this, we exhibit learning rules for which \[ \max_{\mathcal{D}}\; \mathbb{E}\!\left[\big(\widehat{L}_{\mathrm{CV}}^{(k)} -L_{\mathcal{D}}\big)^{2}\right] \;=\; \Omega(k/n), \] matching (up toconstants) the accuracy of a hold-out estimator of a single fold of size $n/k$. Together these results delineate the fundamental trade-off inresampling-based risk estimation: CV cannot fully exploit all $n$ samples forunbiased risk evaluation, and its minimax performance is pinned between the$k/n$ and $\sqrt{k}/n$ regimes.</description><author>Ido Nachum, Rüdiger Urbanke, Thomas Weinberger</author><pubDate>Wed, 05 Nov 2025 15:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03554v1</guid></item><item><title>Trustworthy Representation Learning via Information Funnels and Bottlenecks</title><link>http://arxiv.org/abs/2211.01446v2</link><description>Ensuring trustworthiness in machine learning -- by balancing utility,fairness, and privacy -- remains a critical challenge, particularly inrepresentation learning. In this work, we investigate a family of closelyrelated information-theoretic objectives, including information funnels andbottlenecks, designed to extract invariant representations from data. Weintroduce the Conditional Privacy Funnel with Side-information (CPFSI), a novelformulation within this family, applicable in both fully and semi-supervisedsettings. Given the intractability of these objectives, we deriveneural-network-based approximations via amortized variational inference. Wesystematically analyze the trade-offs between utility, invariance, andrepresentation fidelity, offering new insights into the Pareto frontiers ofthese methods. Our results demonstrate that CPFSI effectively balances thesecompeting objectives and frequently outperforms existing approaches.Furthermore, we show that by intervening on sensitive attributes in CPFSI'spredictive posterior enhances fairness while maintaining predictiveperformance. Finally, we focus on the real-world applicability of theseapproaches, particularly for learning robust and fair representations fromtabular datasets in data scarce-environments -- a modality where these methodsare often especially relevant.</description><author>João Machado de Freitas, Bernhard C. Geiger</author><pubDate>Wed, 05 Nov 2025 15:35:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01446v2</guid></item><item><title>Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning Large Language Models</title><link>http://arxiv.org/abs/2503.07329v2</link><description>The impact of random seeds in fine-tuning large language models (LLMs) hasbeen largely overlooked despite its potential influence on model performance.Inthis study, we systematically evaluate the effects of random seeds on LLMsusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impactthrough traditional metrics like accuracy and F1, calculating their mean andvariance to quantify performance fluctuations. To capture the micro-leveleffects, we introduce a novel metric, consistency, measuring the stability ofindividual predictions across runs. Our experiments reveal significant varianceat both macro and micro levels, underscoring the need for careful considerationof random seeds in fine-tuning and evaluation.</description><author>Nghia Bui, Guergana Savova, Lijing Wang</author><pubDate>Wed, 05 Nov 2025 15:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.07329v2</guid></item><item><title>Intelligent Computing Social Modeling and Methodological Innovations in Political Science in the Era of Large Language Models</title><link>http://arxiv.org/abs/2410.16301v2</link><description>The recent wave of artificial intelligence, epitomized by large languagemodels (LLMs),has presented opportunities and challenges for methodologicalinnovation in political science,sparking discussions on a potential paradigmshift in the social sciences. However, how can weunderstand the impact of LLMson knowledge production and paradigm transformation in thesocial sciences froma comprehensive perspective that integrates technology and methodology? Whatare LLMs' specific applications and representative innovative methods inpolitical scienceresearch? These questions, particularly from a practicalmethodological standpoint, remainunderexplored. This paper proposes the"Intelligent Computing Social Modeling" (ICSM) methodto address these issues byclarifying the critical mechanisms of LLMs. ICSM leverages thestrengths of LLMsin idea synthesis and action simulation, advancing intellectual explorationinpolitical science through "simulated social construction" and "simulationvalidation." Bysimulating the U.S. presidential election, this studyempirically demonstrates the operationalpathways and methodological advantagesof ICSM. By integrating traditional social scienceparadigms, ICSM not onlyenhances the quantitative paradigm's capability to apply big data toassess theimpact of factors but also provides qualitative paradigms with evidence forsocialmechanism discovery at the individual level, offering a powerful toolthat balances interpretabilityand predictability in social science research.The findings suggest that LLMs will drivemethodological innovation in politicalscience through integration and improvement rather thandirect substitution.</description><author>Zhenyu Wang, Dequan Wang, Yi Xu, Lingfeng Zhou, Yiqi Zhou</author><pubDate>Wed, 05 Nov 2025 15:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16301v2</guid></item><item><title>MultiZebraLogic: A Multilingual Logical Reasoning Benchmark</title><link>http://arxiv.org/abs/2511.03553v1</link><description>Measuring the full abilities of large language models (LLMs) requiresbenchmarks representing multiple tasks. We aim to create large, high-qualitydatasets for comparison of logical reasoning skills across several languagesand of suitable difficulty for LLMs of various reasoning ability. We exploremultiple ways of increasing difficulty. We generate zebra puzzles in multiplelanguages, themes, sizes and including 14 different clue types and 8 redherring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 aresufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (areasoning model), respectively. Including 5 red herrings decreases o3-minipuzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5puzzles are not significantly affected by use of English vs. Danish or thecommon houses theme vs. the country-specific smoerrebroed theme. We find nocorrelation between difficulty and the selected clue types. Datasets of128+1024 puzzles are published as MultiZebraLogic in each of nine Germaniclanguages for sizes 2x3 and 4x5. We publish code for puzzle generation,designed for adaptablity into more languages and themes.</description><author>Sofie Helene Bruun, Dan Saattrup Smart</author><pubDate>Wed, 05 Nov 2025 15:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.03553v1</guid></item><item><title>Autonomous Robotic Drilling System for Mice Cranial Window Creation</title><link>http://arxiv.org/abs/2406.14135v2</link><description>Robotic assistance for experimental manipulation in the life sciences isexpected to enable favorable outcomes, regardless of the skill of thescientist. Experimental specimens in the life sciences are subject toindividual variability and hence require intricate algorithms for successfulautonomous robotic control. As a use case, we are studying the cranial windowcreation in mice. This operation requires the removal of an 8-mm circular patchof the skull, which is approximately 300 um thick, but the shape and thicknessof the mouse skull significantly varies depending on the strain of the mouse,sex, and age. In this work, we develop an autonomous robotic drilling systemwith no offline planning, consisting of a trajectory planner withexecution-time feedback with drilling completion level recognition based onimage and force information. In the experiments, we first evaluate theimage-and-force-based drilling completion level recognition by comparing itwith other state-of-the-art deep learning image processing methods and conductan ablation study in eggshell drilling to evaluate the impact of each module onsystem performance. Finally, the system performance is further evaluated inpostmortem mice, achieving a success rate of 70% (14/20 trials) with an averagedrilling time of 9.3 min.</description><author>Enduo Zhao, Murilo M. Marinho, Kanako Harada</author><pubDate>Wed, 05 Nov 2025 15:33:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14135v2</guid></item><item><title>Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything</title><link>http://arxiv.org/abs/2511.02834v1</link><description>Multimodal large language models (MLLMs) have shown strong capabilities butremain limited to fixed modality pairs and require costly fine-tuning withlarge aligned datasets. Building fully omni-capable models that can integratetext, images, audio, and video remains impractical and lacks robust reasoningsupport. In this paper, we propose an Agent-Omni framework that coordinatesexisting foundation models through a master-agent system, enabling flexiblemultimodal reasoning without retraining. The master agent interprets userintent, delegates subtasks to modality-specific agents, and integrates theiroutputs into coherent responses. Extensive experiments across text, image,audio, video, and omni benchmarks show that Agent-Omni consistently achievesstate-of-the-art performance, particularly on tasks requiring complexcross-modal reasoning. Its agent-based design enables seamless integration ofspecialized foundation models, ensuring adaptability to diverse inputs whilemaintaining transparency and interpretability. In addition, the framework ismodular and easily extensible, allowing future improvements as stronger modelsbecome available. %We release an open-source implementation to supportcontinued research on scalable and reliable omni-modal reasoning.</description><author>Huawei Lin, Yunzhi Shi, Tong Geng, Weijie Zhao, Wei Wang, Ravender Pal Singh</author><pubDate>Tue, 04 Nov 2025 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2511.02834v1</guid></item></channel></rss>