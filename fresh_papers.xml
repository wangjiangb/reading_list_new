<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 16 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Octopus: Embodied Vision-Language Programmer from Environmental Feedback</title><link>http://arxiv.org/abs/2310.08588v1</link><description>Large vision-language models (VLMs) have achieved substantial progress inmultimodal perception and reasoning. Furthermore, when seamlessly integratedinto an embodied agent, it signifies a crucial stride towards the creation ofautonomous and context-aware systems capable of formulating plans and executingcommands with precision. In this paper, we introduce Octopus, a novel VLMdesigned to proficiently decipher an agent's vision and textual task objectivesand to formulate intricate action sequences and generate executable code. Ourdesign allows the agent to adeptly handle a wide spectrum of tasks, rangingfrom mundane daily chores in simulators to sophisticated interactions incomplex video games. Octopus is trained by leveraging GPT-4 to control anexplorative agent to generate training data, i.e., action blueprints and thecorresponding executable code, within our experimental environment calledOctoVerse. We also collect the feedback that allows the enhanced trainingscheme of Reinforcement Learning with Environmental Feedback (RLEF). Through aseries of experiments, we illuminate Octopus's functionality and presentcompelling results, and the proposed RLEF turns out to refine the agent'sdecision-making. By open-sourcing our model architecture, simulator, anddataset, we aspire to ignite further innovation and foster collaborativeapplications within the broader embodied AI community.</description><author>Jingkang Yang, Yuhao Dong, Shuai Liu, Bo Li, Ziyue Wang, Chencheng Jiang, Haoran Tan, Jiamu Kang, Yuanhan Zhang, Kaiyang Zhou, Ziwei Liu</author><pubDate>Thu, 12 Oct 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08588v1</guid></item><item><title>Is Generalized Dynamic Novel View Synthesis from Monocular Videos Possible Today?</title><link>http://arxiv.org/abs/2310.08587v1</link><description>Rendering scenes observed in a monocular video from novel viewpoints is achallenging problem. For static scenes the community has studied bothscene-specific optimization techniques, which optimize on every test scene, andgeneralized techniques, which only run a deep net forward pass on a test scene.In contrast, for dynamic scenes, scene-specific optimization techniques exist,but, to our best knowledge, there is currently no generalized method fordynamic novel view synthesis from a given monocular video. To answer whethergeneralized dynamic novel view synthesis from monocular videos is possibletoday, we establish an analysis framework based on existing techniques and worktoward the generalized approach. We find a pseudo-generalized process withoutscene-specific appearance optimization is possible, but geometrically andtemporally consistent depth estimates are needed. Despite no scene-specificappearance optimization, the pseudo-generalized approach improves upon somescene-specific methods.</description><author>Xiaoming Zhao, Alex Colburn, Fangchang Ma, Miguel Angel Bautista, Joshua M. Susskind, Alexander G. Schwing</author><pubDate>Thu, 12 Oct 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08587v1</guid></item><item><title>Im4D: High-Fidelity and Real-Time Novel View Synthesis for Dynamic Scenes</title><link>http://arxiv.org/abs/2310.08585v1</link><description>This paper aims to tackle the challenge of dynamic view synthesis frommulti-view videos. The key observation is that while previous grid-basedmethods offer consistent rendering, they fall short in capturing appearancedetails of a complex dynamic scene, a domain where multi-view image-basedrendering methods demonstrate the opposite properties. To combine the best oftwo worlds, we introduce Im4D, a hybrid scene representation that consists of agrid-based geometry representation and a multi-view image-based appearancerepresentation. Specifically, the dynamic geometry is encoded as a 4D densityfunction composed of spatiotemporal feature planes and a small MLP network,which globally models the scene structure and facilitates the renderingconsistency. We represent the scene appearance by the original multi-viewvideos and a network that learns to predict the color of a 3D point from imagefeatures, instead of memorizing detailed appearance totally with networks,thereby naturally making the learning of networks easier. Our method isevaluated on five dynamic view synthesis datasets including DyNeRF, ZJU-MoCap,NHR, DNA-Rendering and ENeRF-Outdoor datasets. The results show that Im4Dexhibits state-of-the-art performance in rendering quality and can be trainedefficiently, while realizing real-time rendering with a speed of 79.8 FPS for512x512 images, on a single RTX 3090 GPU.</description><author>Haotong Lin, Sida Peng, Zhen Xu, Tao Xie, Xingyi He, Hujun Bao, Xiaowei Zhou</author><pubDate>Thu, 12 Oct 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08585v1</guid></item><item><title>PonderV2: Pave the Way for 3D Foundataion Model with A Universal Pre-training Paradigm</title><link>http://arxiv.org/abs/2310.08586v1</link><description>In contrast to numerous NLP and 2D computer vision foundational models, thelearning of a robust and highly generalized 3D foundational model posesconsiderably greater challenges. This is primarily due to the inherent datavariability and the diversity of downstream tasks. In this paper, we introducea comprehensive 3D pre-training framework designed to facilitate theacquisition of efficient 3D representations, thereby establishing a pathway to3D foundational models. Motivated by the fact that informative 3D featuresshould be able to encode rich geometry and appearance cues that can be utilizedto render realistic images, we propose a novel universal paradigm to learnpoint cloud representations by differentiable neural rendering, serving as abridge between 3D and 2D worlds. We train a point cloud encoder within adevised volumetric neural renderer by comparing the rendered images with thereal images. Notably, our approach demonstrates the seamless integration of thelearned 3D encoder into diverse downstream tasks. These tasks encompass notonly high-level challenges such as 3D detection and segmentation but alsolow-level objectives like 3D reconstruction and image synthesis, spanning bothindoor and outdoor scenarios. Besides, we also illustrate the capability ofpre-training a 2D backbone using the proposed universal methodology, surpassingconventional pre-training methods by a large margin. For the first time,\sexyname achieves state-of-the-art performance on 11 indoor and outdoorbenchmarks. The consistent improvements in various settings imply theeffectiveness of the proposed method. Code and models will be made available athttps://github.com/Pointcept/Pointcept.</description><author>Haoyi Zhu, Honghui Yang, Xiaoyang Wu, Di Huang, Sha Zhang, Xianglong He, Tong He, Hengshuang Zhao, Chunhua Shen, Yu Qiao, Wanli Ouyang</author><pubDate>Thu, 12 Oct 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08586v1</guid></item><item><title>Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video</title><link>http://arxiv.org/abs/2310.08584v1</link><description>Self-supervised learning has unlocked the potential of scaling up pretrainingto billions of images, since annotation is unnecessary. But are we making thebest use of data? How more economical can we be? In this work, we attempt toanswer this question by making two contributions. First, we investigatefirst-person videos and introduce a "Walking Tours" dataset. These videos arehigh-resolution, hours-long, captured in a single uninterrupted take, depictinga large number of objects and actions with natural scene transitions. They areunlabeled and uncurated, thus realistic for self-supervision and comparablewith human learning. Second, we introduce a novel self-supervised image pretraining methodtailored for learning from continuous videos. Existing methods typically adaptimage-based pretraining approaches to incorporate more frames. Instead, weadvocate a "tracking to learn to recognize" approach. Our method called DoRA,leads to attention maps that Discover and tRAck objects over time in anend-to-end manner, using transformer cross-attention. We derive multiple viewsfrom the tracks and use them in a classical self-supervised distillation loss.Using our novel approach, a single Walking Tours video remarkably becomes astrong competitor to ImageNet for several image and video downstream tasks.</description><author>Shashanka Venkataramanan, Mamshad Nayeem Rizve, João Carreira, Yuki M. Asano, Yannis Avrithis</author><pubDate>Thu, 12 Oct 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08584v1</guid></item><item><title>Tree-Planner: Efficient Close-loop Task Planning with Large Language Models</title><link>http://arxiv.org/abs/2310.08582v1</link><description>This paper studies close-loop task planning, which refers to the process ofgenerating a sequence of skills (a plan) to accomplish a specific goal whileadapting the plan based on real-time observations. Recently, prompting LargeLanguage Models (LLMs) to generate actions iteratively has become a prevalentparadigm due to its superior performance and user-friendliness. However, thisparadigm is plagued by two inefficiencies: high token consumption and redundanterror correction, both of which hinder its scalability for large-scale testingand applications. To address these issues, we propose Tree-Planner, whichreframes task planning with LLMs into three distinct phases: plan sampling,action tree construction, and grounded deciding. Tree-Planner starts by usingan LLM to sample a set of potential plans before execution, followed by theaggregation of them to form an action tree. Finally, the LLM performs atop-down decision-making process on the tree, taking into account real-timeenvironmental information. Experiments show that Tree-Planner achievesstate-of-the-art performance while maintaining high efficiency. By decomposingLLM queries into a single plan-sampling call and multiple grounded-decidingcalls, a considerable part of the prompt are less likely to be repeatedlyconsumed. As a result, token consumption is reduced by 92.2% compared to thepreviously best-performing model. Additionally, by enabling backtracking on theaction tree as needed, the correction process becomes more flexible, leading toa 40.5% decrease in error corrections. Project page:https://tree-planner.github.io/</description><author>Mengkang Hu, Yao Mu, Xinmiao Yu, Mingyu Ding, Shiguang Wu, Wenqi Shao, Qiguang Chen, Bin Wang, Yu Qiao, Ping Luo</author><pubDate>Thu, 12 Oct 2023 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08582v1</guid></item><item><title>Universal Visual Decomposer: Long-Horizon Manipulation Made Easy</title><link>http://arxiv.org/abs/2310.08581v1</link><description>Real-world robotic tasks stretch over extended horizons and encompassmultiple stages. Learning long-horizon manipulation tasks, however, is along-standing challenge, and demands decomposing the overarching task intoseveral manageable subtasks to facilitate policy learning and generalization tounseen tasks. Prior task decomposition methods require task-specific knowledge,are computationally intensive, and cannot readily be applied to new tasks. Toaddress these shortcomings, we propose Universal Visual Decomposer (UVD), anoff-the-shelf task decomposition method for visual long horizon manipulationusing pre-trained visual representations designed for robotic control. At ahigh level, UVD discovers subgoals by detecting phase shifts in the embeddingspace of the pre-trained representation. Operating purely on visualdemonstrations without auxiliary information, UVD can effectively extractvisual subgoals embedded in the videos, while incurring zero additionaltraining cost on top of standard visuomotor policy training. Goal-conditionedpolicies learned with UVD-discovered subgoals exhibit significantly improvedcompositional generalization at test time to unseen tasks. Furthermore,UVD-discovered subgoals can be used to construct goal-based reward shaping thatjump-starts temporally extended exploration for reinforcement learning. Weextensively evaluate UVD on both simulation and real-world tasks, and in allcases, UVD substantially outperforms baselines across imitation andreinforcement learning settings on in-domain and out-of-domain task sequencesalike, validating the clear advantage of automated visual task decompositionwithin the simple, compact UVD framework.</description><author>Zichen Zhang, Yunshuang Li, Osbert Bastani, Abhishek Gupta, Dinesh Jayaraman, Yecheng Jason Ma, Luca Weihs</author><pubDate>Thu, 12 Oct 2023 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08581v1</guid></item><item><title>OmniControl: Control Any Joint at Any Time for Human Motion Generation</title><link>http://arxiv.org/abs/2310.08580v1</link><description>We present a novel approach named OmniControl for incorporating flexiblespatial control signals into a text-conditioned human motion generation modelbased on the diffusion process. Unlike previous methods that can only controlthe pelvis trajectory, OmniControl can incorporate flexible spatial controlsignals over different joints at different times with only one model.Specifically, we propose analytic spatial guidance that ensures the generatedmotion can tightly conform to the input control signals. At the same time,realism guidance is introduced to refine all the joints to generate morecoherent motion. Both the spatial and realism guidance are essential and theyare highly complementary for balancing control accuracy and motion realism. Bycombining them, OmniControl generates motions that are realistic, coherent, andconsistent with the spatial constraints. Experiments on HumanML3D and KIT-MLdatasets show that OmniControl not only achieves significant improvement overstate-of-the-art methods on pelvis control but also shows promising resultswhen incorporating the constraints over other joints.</description><author>Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, Huaizu Jiang</author><pubDate>Thu, 12 Oct 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08580v1</guid></item><item><title>HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion</title><link>http://arxiv.org/abs/2310.08579v1</link><description>Despite significant advances in large-scale text-to-image models, achievinghyper-realistic human image generation remains a desirable yet unsolved task.Existing models like Stable Diffusion and DALL-E 2 tend to generate humanimages with incoherent parts or unnatural poses. To tackle these challenges,our key insight is that human image is inherently structural over multiplegranularities, from the coarse-level body skeleton to fine-grained spatialgeometry. Therefore, capturing such correlations between the explicitappearance and latent structure in one model is essential to generate coherentand natural human images. To this end, we propose a unified framework,HyperHuman, that generates in-the-wild human images of high realism and diverselayouts. Specifically, 1) we first build a large-scale human-centric dataset,named HumanVerse, which consists of 340M images with comprehensive annotationslike human pose, depth, and surface normal. 2) Next, we propose a LatentStructural Diffusion Model that simultaneously denoises the depth and surfacenormal along with the synthesized RGB image. Our model enforces the jointlearning of image appearance, spatial relationship, and geometry in a unifiednetwork, where each branch in the model complements to each other with bothstructural awareness and textural richness. 3) Finally, to further boost thevisual quality, we propose a Structure-Guided Refiner to compose the predictedconditions for more detailed generation of higher resolution. Extensiveexperiments demonstrate that our framework yields the state-of-the-artperformance, generating hyper-realistic human images under diverse scenarios.Project Page: https://snap-research.github.io/HyperHuman/</description><author>Xian Liu, Jian Ren, Aliaksandr Siarohin, Ivan Skorokhodov, Yanyu Li, Dahua Lin, Xihui Liu, Ziwei Liu, Sergey Tulyakov</author><pubDate>Thu, 12 Oct 2023 18:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08579v1</guid></item><item><title>Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models</title><link>http://arxiv.org/abs/2310.08577v1</link><description>Recent advances in the development of vision-language models (VLMs) areyielding remarkable success in recognizing visual semantic content, includingimpressive instances of compositional image understanding. Here, we introducethe novel task of \textit{Visual Data-Type Identification}, a basic perceptualskill with implications for data curation (e.g., noisy data-removal from largedatasets, domain-specific retrieval) and autonomous vision (e.g.,distinguishing changing weather conditions from camera lens staining). Wedevelop two datasets consisting of animal images altered across a diverse setof 27 visual \textit{data-types}, spanning four broad categories. An extensivezero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows anuanced performance landscape. While VLMs are reasonably good at identifyingcertain stylistic \textit{data-types}, such as cartoons and sketches, theystruggle with simpler \textit{data-types} arising from basic manipulations likeimage rotations or additive noise. Our findings reveal that (i) model scalingalone yields marginal gains for contrastively-trained models like CLIP, and(ii) there is a pronounced drop in performance for the largestauto-regressively trained VLMs like OpenFlamingo. This finding points to ablind spot in current frontier VLMs: they excel in recognizing semantic contentbut fail to acquire an understanding of visual \textit{data-types} throughscaling. By analyzing the pre-training distributions of these models andincorporating \textit{data-type} information into the captions duringfine-tuning, we achieve a significant enhancement in performance. By exploringthis previously uncharted task, we aim to set the stage for further advancingVLMs to equip them with visual data-type understanding. Code and datasets arereleased \href{https://github.com/bethgelab/DataTypeIdentification}{here}.</description><author>Vishaal Udandarao, Max F. Burg, Samuel Albanie, Matthias Bethge</author><pubDate>Thu, 12 Oct 2023 18:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08577v1</guid></item><item><title>Learning to Act from Actionless Videos through Dense Correspondences</title><link>http://arxiv.org/abs/2310.08576v1</link><description>In this work, we present an approach to construct a video-based robot policycapable of reliably executing diverse tasks across different robots andenvironments from few video demonstrations without using any actionannotations. Our method leverages images as a task-agnostic representation,encoding both the state and action information, and text as a generalrepresentation for specifying robot goals. By synthesizing videos that``hallucinate'' robot executing actions and in combination with densecorrespondences between frames, our approach can infer the closed-formed actionto execute to an environment without the need of any explicit action labels.This unique capability allows us to train the policy solely based on RGB videosand deploy learned policies to various robotic tasks. We demonstrate theefficacy of our approach in learning policies on table-top manipulation andnavigation tasks. Additionally, we contribute an open-source framework forefficient video modeling, enabling the training of high-fidelity policy modelswith four GPUs within a single day.</description><author>Po-Chen Ko, Jiayuan Mao, Yilun Du, Shao-Hua Sun, Joshua B. Tenenbaum</author><pubDate>Thu, 12 Oct 2023 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08576v1</guid></item><item><title>Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information</title><link>http://arxiv.org/abs/2209.07481v2</link><description>Markov Chain Monte Carlo methods for sampling from complex distributions andestimating normalization constants often simulate samples from a sequence ofintermediate distributions along an annealing path, which bridges between atractable initial distribution and a target density of interest. Prior work hasconstructed annealing paths using quasi-arithmetic means, and interpreted theresulting intermediate densities as minimizing an expected divergence to theendpoints. We provide a comprehensive analysis of this 'centroid' propertyusing Bregman divergences under a monotonic embedding of the density function,thereby associating common divergences such as Amari's and Renyi's${\alpha}$-divergences, ${(\alpha,\beta)}$-divergences, and the Jensen-Shannondivergence with intermediate densities along an annealing path. Our analysishighlights the interplay between parametric families, quasi-arithmetic means,and divergence functions using the rho-tau Bregman divergence framework ofZhang 2004,2013.</description><author>Rob Brekelmans, Frank Nielsen</author><pubDate>Thu, 12 Oct 2023 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07481v2</guid></item><item><title>Jigsaw: Supporting Designers in Prototyping Multimodal Applications by Assembling AI Foundation Models</title><link>http://arxiv.org/abs/2310.08574v1</link><description>Recent advancements in AI foundation models have made it possible for them tobe utilized off-the-shelf for creative tasks, including ideating designconcepts or generating visual prototypes. However, integrating these modelsinto the creative process can be challenging as they often exist as standaloneapplications tailored to specific tasks. To address this challenge, weintroduce Jigsaw, a prototype system that employs puzzle pieces as metaphors torepresent foundation models. Jigsaw allows designers to combine differentfoundation model capabilities across various modalities by assemblingcompatible puzzle pieces. To inform the design of Jigsaw, we interviewed tendesigners and distilled design goals. In a user study, we showed that Jigsawenhanced designers' understanding of available foundation model capabilities,provided guidance on combining capabilities across different modalities andtasks, and served as a canvas to support design exploration, prototyping, anddocumentation.</description><author>David Chuan-En Lin, Nikolas Martelaro</author><pubDate>Thu, 12 Oct 2023 18:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08574v1</guid></item><item><title>Soundify: Matching Sound Effects to Video</title><link>http://arxiv.org/abs/2112.09726v2</link><description>In the art of video editing, sound helps add character to an object andimmerse the viewer within a space. Through formative interviews withprofessional editors (N=10), we found that the task of adding sounds to videocan be challenging. This paper presents Soundify, a system that assists editorsin matching sounds to video. Given a video, Soundify identifies matchingsounds, synchronizes the sounds to the video, and dynamically adjusts panningand volume to create spatial audio. In a human evaluation study (N=889), weshow that Soundify is capable of matching sounds to video out-of-the-box for adiverse range of audio categories. In a within-subjects expert study (N=12), wedemonstrate the usefulness of Soundify in helping video editors match sounds tovideo with lighter workload, reduced task completion time, and improvedusability.</description><author>David Chuan-En Lin, Anastasis Germanidis, Cristóbal Valenzuela, Yining Shi, Nikolas Martelaro</author><pubDate>Thu, 12 Oct 2023 18:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.09726v2</guid></item><item><title>Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders</title><link>http://arxiv.org/abs/2310.08571v1</link><description>Machine Learning as a Service (MLaaS) APIs provide ready-to-use andhigh-utility encoders that generate vector representations for given inputs.Since these encoders are very costly to train, they become lucrative targetsfor model stealing attacks during which an adversary leverages query access tothe API to replicate the encoder locally at a fraction of the original trainingcosts. We propose Bucks for Buckets (B4B), the first active defense thatprevents stealing while the attack is happening without degradingrepresentation quality for legitimate API users. Our defense relies on theobservation that the representations returned to adversaries who try to stealthe encoder's functionality cover a significantly larger fraction of theembedding space than representations of legitimate users who utilize theencoder to solve a particular downstream task.vB4B leverages this to adaptivelyadjust the utility of the returned representations according to a user'scoverage of the embedding space. To prevent adaptive adversaries from eludingour defense by simply creating multiple user accounts (sybils), B4B alsoindividually transforms each user's representations. This prevents theadversary from directly aggregating representations over multiple accounts tocreate their stolen encoder copy. Our active defense opens a new path towardssecurely sharing and democratizing encoders over public APIs.</description><author>Jan Dubiński, Stanisław Pawlak, Franziska Boenisch, Tomasz Trzciński, Adam Dziedzic</author><pubDate>Thu, 12 Oct 2023 18:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08571v1</guid></item><item><title>A Lightweight Calibrated Simulation Enabling Efficient Offline Learning for Optimal Control of Real Buildings</title><link>http://arxiv.org/abs/2310.08569v1</link><description>Modern commercial Heating, Ventilation, and Air Conditioning (HVAC) devicesform a complex and interconnected thermodynamic system with the building andoutside weather conditions, and current setpoint control policies are not fullyoptimized for minimizing energy use and carbon emission. Given a suitabletraining environment, a Reinforcement Learning (RL) model is able to improveupon these policies, but training such a model, especially in a way that scalesto thousands of buildings, presents many real world challenges. We propose anovel simulation-based approach, where a customized simulator is used to trainthe agent for each building. Our open-source simulator (available online:https://github.com/google/sbsim) is lightweight and calibrated via telemetryfrom the building to reach a higher level of fidelity. On a two-story, 68,000square foot building, with 127 devices, we were able to calibrate our simulatorto have just over half a degree of drift from the real world over a six-hourinterval. This approach is an important step toward having a real-world RLcontrol system that can be scaled to many buildings, allowing for greaterefficiency and resulting in reduced energy consumption and carbon emissions.</description><author>Judah Goldfeder, John Sipple</author><pubDate>Thu, 12 Oct 2023 18:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08569v1</guid></item><item><title>Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining</title><link>http://arxiv.org/abs/2310.08566v1</link><description>Large transformer models pretrained on offline reinforcement learningdatasets have demonstrated remarkable in-context reinforcement learning (ICRL)capabilities, where they can make good decisions when prompted with interactiontrajectories from unseen environments. However, when and how transformers canbe trained to perform ICRL have not been theoretically well-understood. Inparticular, it is unclear which reinforcement-learning algorithms transformerscan perform in context, and how distribution mismatch in offline training dataaffects the learned algorithms. This paper provides a theoretical frameworkthat analyzes supervised pretraining for ICRL. This includes two recentlyproposed training methods -- algorithm distillation and decision-pretrainedtransformers. First, assuming model realizability, we prove thesupervised-pretrained transformer will imitate the conditional expectation ofthe expert algorithm given the observed trajectory. The generalization errorwill scale with model capacity and a distribution divergence factor between theexpert and offline algorithms. Second, we show transformers with ReLU attentioncan efficiently approximate near-optimal online reinforcement learningalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, andUCB-VI for tabular Markov decision processes. This provides the firstquantitative analysis of the ICRL capabilities of transformers pretrained fromoffline trajectories.</description><author>Licong Lin, Yu Bai, Song Mei</author><pubDate>Thu, 12 Oct 2023 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08566v1</guid></item><item><title>Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities</title><link>http://arxiv.org/abs/2310.08565v1</link><description>Robotics and Artificial Intelligence (AI) have been inextricably intertwinedsince their inception. Today, AI-Robotics systems have become an integral partof our daily lives, from robotic vacuum cleaners to semi-autonomous cars. Thesesystems are built upon three fundamental architectural elements: perception,navigation and planning, and control. However, while the integration ofAI-Robotics systems has enhanced the quality our lives, it has also presented aserious problem - these systems are vulnerable to security attacks. Thephysical components, algorithms, and data that make up AI-Robotics systems canbe exploited by malicious actors, potentially leading to dire consequences.Motivated by the need to address the security concerns in AI-Robotics systems,this paper presents a comprehensive survey and taxonomy across threedimensions: attack surfaces, ethical and legal concerns, and Human-RobotInteraction (HRI) security. Our goal is to provide users, developers and otherstakeholders with a holistic understanding of these areas to enhance theoverall AI-Robotics system security. We begin by surveying potential attacksurfaces and provide mitigating defensive strategies. We then delve intoethical issues, such as dependency and psychological impact, as well as thelegal concerns regarding accountability for these systems. Besides, emergingtrends such as HRI are discussed, considering privacy, integrity, safety,trustworthiness, and explainability concerns. Finally, we present our visionfor future research directions in this dynamic and promising field.</description><author>Subash Neupane, Shaswata Mitra, Ivan A. Fernandez, Swayamjit Saha, Sudip Mittal, Jingdao Chen, Nisha Pillai, Shahram Rahimi</author><pubDate>Thu, 12 Oct 2023 18:54:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08565v1</guid></item><item><title>MemGPT: Towards LLMs as Operating Systems</title><link>http://arxiv.org/abs/2310.08560v1</link><description>Large language models (LLMs) have revolutionized AI, but are constrained bylimited context windows, hindering their utility in tasks like extendedconversations and document analysis. To enable using context beyond limitedcontext windows, we propose virtual context management, a technique drawinginspiration from hierarchical memory systems in traditional operating systemsthat provide the appearance of large memory resources through data movementbetween fast and slow memory. Using this technique, we introduce MemGPT(Memory-GPT), a system that intelligently manages different memory tiers inorder to effectively provide extended context within the LLM's limited contextwindow, and utilizes interrupts to manage control flow between itself and theuser. We evaluate our OS-inspired design in two domains where the limitedcontext windows of modern LLMs severely handicaps their performance: documentanalysis, where MemGPT is able to analyze large documents that far exceed theunderlying LLM's context window, and multi-session chat, where MemGPT cancreate conversational agents that remember, reflect, and evolve dynamicallythrough long-term interactions with their users. We release MemGPT code anddata for our experiments at https://memgpt.ai.</description><author>Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, Joseph E. Gonzalez</author><pubDate>Thu, 12 Oct 2023 18:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08560v1</guid></item><item><title>Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement</title><link>http://arxiv.org/abs/2310.08559v1</link><description>The ability to derive underlying principles from a handful of observationsand then generalize to novel situations -- known as inductive reasoning -- iscentral to human intelligence. Prior work suggests that language models (LMs)often fall short on inductive reasoning, despite achieving impressive successon research benchmarks. In this work, we conduct a systematic study of theinductive reasoning capabilities of LMs through iterative hypothesisrefinement, a technique that more closely mirrors the human inductive processthan standard input-output prompting. Iterative hypothesis refinement employs athree-step process: proposing, selecting, and refining hypotheses in the formof textual rules. By examining the intermediate rules, we observe that LMs arephenomenal hypothesis proposers (i.e., generating candidate rules), and whencoupled with a (task-specific) symbolic interpreter that is able tosystematically filter the proposed set of rules, this hybrid approach achievesstrong results across inductive reasoning benchmarks that require inducingcausal relations, language-like instructions, and symbolic concepts. However,they also behave as puzzling inductive reasoners, showing notable performancegaps in rule induction (i.e., identifying plausible rules) and rule application(i.e., applying proposed rules to instances), suggesting that LMs are proposinghypotheses without being able to actually apply the rules. Through empiricaland human analyses, we further reveal several discrepancies between theinductive reasoning processes of LMs and humans, shedding light on both thepotentials and limitations of using LMs in inductive reasoning tasks.</description><author>Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, Xiang Ren</author><pubDate>Thu, 12 Oct 2023 18:51:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08559v1</guid></item><item><title>StoryBench: A Multifaceted Benchmark for Continuous Story Visualization</title><link>http://arxiv.org/abs/2308.11606v2</link><description>Generating video stories from text prompts is a complex task. In addition tohaving high visual quality, videos need to realistically adhere to a sequenceof text prompts whilst being consistent throughout the frames. Creating abenchmark for video generation requires data annotated over time, whichcontrasts with the single caption used often in video datasets. To fill thisgap, we collect comprehensive human annotations on three existing datasets, andintroduce StoryBench: a new, challenging multi-task benchmark to reliablyevaluate forthcoming text-to-video models. Our benchmark includes three videogeneration tasks of increasing difficulty: action execution, where the nextaction must be generated starting from a conditioning video; storycontinuation, where a sequence of actions must be executed starting from aconditioning video; and story generation, where a video must be generated fromonly text prompts. We evaluate small yet strong text-to-video baselines, andshow the benefits of training on story-like data algorithmically generated fromexisting video captions. Finally, we establish guidelines for human evaluationof video stories, and reaffirm the need of better automatic metrics for videogeneration. StoryBench aims at encouraging future research efforts in thisexciting new area.</description><author>Emanuele Bugliarello, Hernan Moraldo, Ruben Villegas, Mohammad Babaeizadeh, Mohammad Taghi Saffar, Han Zhang, Dumitru Erhan, Vittorio Ferrari, Pieter-Jan Kindermans, Paul Voigtlaender</author><pubDate>Thu, 12 Oct 2023 18:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11606v2</guid></item><item><title>Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks</title><link>http://arxiv.org/abs/2310.02244v5</link><description>By classifying infinite-width neural networks and identifying the *optimal*limit, Tensor Programs IV and V demonstrated a universal way, called $\mu$P,for *widthwise hyperparameter transfer*, i.e., predicting optimalhyperparameters of wide neural networks from narrow ones. Here we investigatethe analogous classification for *depthwise parametrizations* of deep residualnetworks (resnets). We classify depthwise parametrizations of block multiplierand learning rate by their infinite-width-then-depth limits. In resnets whereeach block has only one layer, we identify a unique optimal parametrization,called Depth-$\mu$P that extends $\mu$P and show empirically it admitsdepthwise hyperparameter transfer. We identify *feature diversity* as a crucialfactor in deep networks, and Depth-$\mu$P can be characterized as maximizingboth feature learning and feature diversity. Exploiting this, we find thatabsolute value, among all homogeneous nonlinearities, maximizes featurediversity and indeed empirically leads to significantly better performance.However, if each block is deeper (such as modern transformers), then we findfundamental limitations in all possible infinite-depth limits of suchparametrizations, which we illustrate both theoretically and empirically onsimple networks as well as Megatron transformer trained on Common Crawl.</description><author>Greg Yang, Dingli Yu, Chen Zhu, Soufiane Hayou</author><pubDate>Thu, 12 Oct 2023 18:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02244v5</guid></item><item><title>Offline Retraining for Online RL: Decoupled Policy Learning to Mitigate Exploration Bias</title><link>http://arxiv.org/abs/2310.08558v1</link><description>It is desirable for policies to optimistically explore new states andbehaviors during online reinforcement learning (RL) or fine-tuning, especiallywhen prior offline data does not provide enough state coverage. However,exploration bonuses can bias the learned policy, and our experiments find thatnaive, yet standard use of such bonuses can fail to recover a performantpolicy. Concurrently, pessimistic training in offline RL has enabled recoveryof performant policies from static datasets. Can we leverage offline RL torecover better policies from online interaction? We make a simple observationthat a policy can be trained from scratch on all interaction data withpessimistic objectives, thereby decoupling the policies used for datacollection and for evaluation. Specifically, we propose offline retraining, apolicy extraction step at the end of online fine-tuning in ourOffline-to-Online-to-Offline (OOO) framework for reinforcement learning (RL).An optimistic (exploration) policy is used to interact with the environment,and a separate pessimistic (exploitation) policy is trained on all the observeddata for evaluation. Such decoupling can reduce any bias from onlineinteraction (intrinsic rewards, primacy bias) in the evaluation policy, and canallow more exploratory behaviors during online interaction which in turn cangenerate better data for exploitation. OOO is complementary to severaloffline-to-online RL and online RL methods, and improves their averageperformance by 14% to 26% in our fine-tuning experiments, achievesstate-of-the-art performance on several environments in the D4RL benchmarks,and improves online RL performance by 165% on two OpenAI gym environments.Further, OOO can enable fine-tuning from incomplete offline datasets whereprior methods can fail to recover a performant policy. Implementation:https://github.com/MaxSobolMark/OOO</description><author>Max Sobol Mark, Archit Sharma, Fahim Tajwar, Rafael Rafailov, Sergey Levine, Chelsea Finn</author><pubDate>Thu, 12 Oct 2023 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08558v1</guid></item><item><title>Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control</title><link>http://arxiv.org/abs/2309.04370v2</link><description>Seeing-eye robots are very useful tools for guiding visually impaired people,potentially producing a huge societal impact given the low availability andhigh cost of real guide dogs. Although a few seeing-eye robot systems havealready been demonstrated, none considered external tugs from humans, whichfrequently occur in a real guide dog setting. In this paper, we simultaneouslytrain a locomotion controller that is robust to external tugging forces viaReinforcement Learning (RL), and an external force estimator via supervisedlearning. The controller ensures stable walking, and the force estimatorenables the robot to respond to the external forces from the human. Theseforces are used to guide the robot to the global goal, which is unknown to therobot, while the robot guides the human around nearby obstacles via a localplanner. Experimental results in simulation and on hardware show that ourcontroller is robust to external forces, and our seeing-eye system canaccurately detect force direction. We demonstrate our full seeing-eye robotsystem on a real quadruped robot with a blindfolded human. The video can beseen at our project page: https://bu-air-lab.github.io/guide_dog/</description><author>David DeFazio, Eisuke Hirota, Shiqi Zhang</author><pubDate>Thu, 12 Oct 2023 18:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04370v2</guid></item><item><title>Cross-Episodic Curriculum for Transformer Agents</title><link>http://arxiv.org/abs/2310.08549v1</link><description>We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost thelearning efficiency and generalization of Transformer agents. Central to CEC isthe placement of cross-episodic experiences into a Transformer's context, whichforms the basis of a curriculum. By sequentially structuring online learningtrials and mixed-quality demonstrations, CEC constructs curricula thatencapsulate learning progression and proficiency increase across episodes. Suchsynergy combined with the potent pattern recognition capabilities ofTransformer models delivers a powerful cross-episodic attention mechanism. Theeffectiveness of CEC is demonstrated under two representative scenarios: oneinvolving multi-task reinforcement learning with discrete control, such as inDeepMind Lab, where the curriculum captures the learning progression in bothindividual and progressively complex settings; and the other involvingimitation learning with mixed-quality data for continuous control, as seen inRoboMimic, where the curriculum captures the improvement in demonstrators'expertise. In all instances, policies resulting from CEC exhibit superiorperformance and strong generalization. Code is open-sourced athttps://cec-agent.github.io/ to facilitate research on Transformer agentlearning.</description><author>Lucy Xiaoyang Shi, Yunfan Jiang, Jake Grigsby, Linxi "Jim" Fan, Yuke Zhu</author><pubDate>Thu, 12 Oct 2023 18:45:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08549v1</guid></item><item><title>Stronger Coreset Bounds for Kernel Density Estimators via Chaining</title><link>http://arxiv.org/abs/2310.08548v1</link><description>We apply the discrepancy method and a chaining approach to give improvedbounds on the coreset complexity of a wide class of kernel functions. Ourresults give randomized polynomial time algorithms to produce coresets of size$O\big(\frac{\sqrt{d}}{\varepsilon}\sqrt{\log\log \frac{1}{\varepsilon}}\big)$for the Gaussian and Laplacian kernels in the case that the data set isuniformly bounded, an improvement that was not possible with previoustechniques. We also obtain coresets of size$O\big(\frac{1}{\varepsilon}\sqrt{\log\log \frac{1}{\varepsilon}}\big)$ for theLaplacian kernel for $d$ constant. Finally, we give the best known bounds of$O\big(\frac{\sqrt{d}}{\varepsilon}\sqrt{\log(2\max\{1,\alpha\})}\big)$ on thecoreset complexity of the exponential, Hellinger, and JS Kernels, where$1/\alpha$ is the bandwidth parameter of the kernel.</description><author>Rainie Bozzai, Thomas Rothvoss</author><pubDate>Thu, 12 Oct 2023 18:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08548v1</guid></item><item><title>GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models</title><link>http://arxiv.org/abs/2310.00737v2</link><description>Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)are marvels of technology; celebrated for their prowess in natural languageprocessing and multimodal content generation, they promise a transformativefuture. But as with all powerful tools, they come with their shadows. Pictureliving in a world where deepfakes are indistinguishable from reality, wheresynthetic identities orchestrate malicious campaigns, and where targetedmisinformation or scams are crafted with unparalleled precision. Welcome to thedarker side of GenAI applications. This article is not just a journey throughthe meanders of potential misuse of GenAI and LLMs, but also a call torecognize the urgency of the challenges ahead. As we navigate the seas ofmisinformation campaigns, malicious content generation, and the eerie creationof sophisticated malware, we'll uncover the societal implications that ripplethrough the GenAI revolution we are witnessing. From AI-powered botnets onsocial media platforms to the unnerving potential of AI to generate fabricatedidentities, or alibis made of synthetic realities, the stakes have never beenhigher. The lines between the virtual and the real worlds are blurring, and theconsequences of potential GenAI's nefarious applications impact us all. Thisarticle serves both as a synthesis of rigorous research presented on the risksof GenAI and misuse of LLMs and as a thought-provoking vision of the differenttypes of harmful GenAI applications we might encounter in the near future, andsome ways we can prepare for them.</description><author>Emilio Ferrara</author><pubDate>Thu, 12 Oct 2023 18:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00737v2</guid></item><item><title>Idea2Img: Iterative Self-Refinement with GPT-4V(ision) for Automatic Image Design and Generation</title><link>http://arxiv.org/abs/2310.08541v1</link><description>We introduce ``Idea to Image,'' a system that enables multimodal iterativeself-refinement with GPT-4V(ision) for automatic image design and generation.Humans can quickly identify the characteristics of different text-to-image(T2I) models via iterative explorations. This enables them to efficientlyconvert their high-level generation ideas into effective T2I prompts that canproduce good images. We investigate if systems based on large multimodal models(LMMs) can develop analogous multimodal self-refinement abilities that enableexploring unknown models or environments via self-refining tries. Idea2Imgcyclically generates revised T2I prompts to synthesize draft images, andprovides directional feedback for prompt revision, both conditioned on itsmemory of the probed T2I model's characteristics. The iterative self-refinementbrings Idea2Img various advantages over vanilla T2I models. Notably, Idea2Imgcan process input ideas with interleaved image-text sequences, follow ideaswith design instructions, and generate images of better semantic and visualqualities. The user preference study validates the efficacy of multimodaliterative self-refinement on automatic image design and generation.</description><author>Zhengyuan Yang, Jianfeng Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang</author><pubDate>Thu, 12 Oct 2023 18:34:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08541v1</guid></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>http://arxiv.org/abs/2306.07951v2</link><description>As large language models increase in capability, researchers have started toconduct surveys of all kinds on these models with varying scientificmotivations. In this work, we examine what we can learn from language models'survey responses on the basis of the well-established American Community Survey(ACS) by the U.S. Census Bureau. Using a de-facto standard multiple-choiceprompting technique and evaluating 40 different language models, hundreds ofthousands of times each on questions from the ACS, we systematically establishtwo dominant patterns. First, models have significant position and labelingbiases, for example, towards survey responses labeled with the letter "A".Second, when adjusting for labeling biases through randomized answer ordering,models across the board trend towards uniformly random survey responses. Infact, binary classifiers can almost perfectly differentiate between models'responses to the ACS and the responses of the US census. Taken together, ourfindings suggest caution in treating survey responses from language models asequivalent to those of human populations at present time.</description><author>Ricardo Dominguez-Olmedo, Moritz Hardt, Celestine Mendler-Dünner</author><pubDate>Thu, 12 Oct 2023 18:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07951v2</guid></item><item><title>Do pretrained Transformers Really Learn In-context by Gradient Descent?</title><link>http://arxiv.org/abs/2310.08540v1</link><description>Is In-Context Learning (ICL) implicitly equivalent to Gradient Descent (GD)?Several recent works draw analogies between the dynamics of GD and the emergentbehavior of ICL in large language models. However, these works make assumptionsfar from the realistic natural language setting in which language models aretrained. Such discrepancies between theory and practice, therefore, necessitatefurther investigation to validate their applicability. We start by highlighting the weaknesses in prior works that constructTransformer weights to simulate gradient descent. Their experiments withtraining Transformers on ICL objective, inconsistencies in the ordersensitivity of ICL and GD, sparsity of the constructed weights, and sensitivityto parameter changes are some examples of a mismatch from the real-worldsetting. Furthermore, we probe and compare the ICL vs. GD hypothesis in a naturalsetting. We conduct comprehensive empirical analyses on language modelspretrained on natural data (LLaMa-7B). Our comparisons on various performancemetrics highlight the inconsistent behavior of ICL and GD as a function ofvarious factors such as datasets, models, and number of demonstrations. Weobserve that ICL and GD adapt the output distribution of language modelsdifferently. These results indicate that the equivalence between ICL and GD isan open hypothesis, requires nuanced considerations and calls for furtherstudies.</description><author>Lingfeng Shen, Aayush Mishra, Daniel Khashabi</author><pubDate>Thu, 12 Oct 2023 18:32:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08540v1</guid></item><item><title>Image2PCI -- A Multitask Learning Framework for Estimating Pavement Condition Indices Directly from Images</title><link>http://arxiv.org/abs/2310.08538v1</link><description>The Pavement Condition Index (PCI) is a widely used metric for evaluatingpavement performance based on the type, extent and severity of distressesdetected on a pavement surface. In recent times, significant progress has beenmade in utilizing deep-learning approaches to automate PCI estimation process.However, the current approaches rely on at least two separate models toestimate PCI values -- one model dedicated to determining the type and extentand another for estimating their severity. This approach presents severalchallenges, including complexities, high computational resource demands, andmaintenance burdens that necessitate careful consideration and resolution. Toovercome these challenges, the current study develops a unified multi-taskingmodel that predicts the PCI directly from a top-down pavement image. Theproposed architecture is a multi-task model composed of one encoder for featureextraction and four decoders to handle specific tasks: two detection heads, onesegmentation head and one PCI estimation head. By multitasking, we are able toextract features from the detection and segmentation heads for automaticallyestimating the PCI directly from the images. The model performs very well onour benchmarked and open pavement distress dataset that is annotated formultitask learning (the first of its kind). To our best knowledge, this is thefirst work that can estimate PCI directly from an image at real time speedswhile maintaining excellent accuracy on all related tasks for crack detectionand segmentation.</description><author>Neema Jakisa Owor, Hang Du, Abdulateef Daud, Armstrong Aboah, Yaw Adu-Gyamfi</author><pubDate>Thu, 12 Oct 2023 18:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08538v1</guid></item><item><title>Dynamic Subgoal-based Exploration via Bayesian Optimization</title><link>http://arxiv.org/abs/1910.09143v5</link><description>Reinforcement learning in sparse-reward navigation environments withexpensive and limited interactions is challenging and poses a need foreffective exploration. Motivated by complex navigation tasks that requirereal-world training (when cheap simulators are not available), we consider anagent that faces an unknown distribution of environments and must decide on anexploration strategy. It may leverage a series of training environments toimprove its policy before it is evaluated in a test environment drawn from thesame environment distribution. Most existing approaches focus on fixedexploration strategies, while the few that view exploration as ameta-optimization problem tend to ignore the need for cost-efficientexploration. We propose a cost-aware Bayesian optimization approach thatefficiently searches over a class of dynamic subgoal-based explorationstrategies. The algorithm adjusts a variety of levers -- the locations of thesubgoals, the length of each episode, and the number of replications per trial-- in order to overcome the challenges of sparse rewards, expensiveinteractions, and noise. An experimental evaluation demonstrates that the newapproach outperforms existing baselines across a number of problem domains. Wealso provide a theoretical foundation and prove that the method asymptoticallyidentifies a near-optimal subgoal design.</description><author>Yijia Wang, Matthias Poloczek, Daniel R. Jiang</author><pubDate>Thu, 12 Oct 2023 18:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.09143v5</guid></item><item><title>XAI Benchmark for Visual Explanation</title><link>http://arxiv.org/abs/2310.08537v1</link><description>The rise of deep learning algorithms has led to significant advancements incomputer vision tasks, but their "black box" nature has raised concernsregarding interpretability. Explainable AI (XAI) has emerged as a critical areaof research aiming to open this "black box", and shed light on thedecision-making process of AI models. Visual explanations, as a subset ofExplainable Artificial Intelligence (XAI), provide intuitive insights into thedecision-making processes of AI models handling visual data by highlightinginfluential areas in an input image. Despite extensive research conducted onvisual explanations, most evaluations are model-centered since the availabilityof corresponding real-world datasets with ground truth explanations is scarcein the context of image data. To bridge this gap, we introduce an XAI Benchmarkcomprising a dataset collection from diverse topics that provide both classlabels and corresponding explanation annotations for images. We have processeddata from diverse domains to align with our unified visual explanationframework. We introduce a comprehensive Visual Explanation pipeline, whichintegrates data loading, preprocessing, experimental setup, and modelevaluation processes. This structure enables researchers to conduct faircomparisons of various visual explanation techniques. In addition, we provide acomprehensive review of over 10 evaluation methods for visual explanation toassist researchers in effectively utilizing our dataset collection. To furtherassess the performance of existing visual explanation methods, we conductexperiments on selected datasets using various model-centered and groundtruth-centered evaluation metrics. We envision this benchmark could facilitatethe advancement of visual explanation models. The XAI dataset collection andeasy-to-use code for evaluation are publicly accessible athttps://xaidataset.github.io.</description><author>Yifei Zhang, Siyi Gu, James Song, Bo Pan, Liang Zhao</author><pubDate>Thu, 12 Oct 2023 18:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08537v1</guid></item><item><title>DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning</title><link>http://arxiv.org/abs/2309.05173v2</link><description>Prompt tuning (PT), where a small amount of trainable soft (continuous)prompt vectors is affixed to the input of language models (LM), has shownpromising results across various tasks and models for parameter-efficientfine-tuning (PEFT). PT stands out from other PEFT approaches because itmaintains competitive performance with fewer trainable parameters and does notdrastically scale up its parameters as the model size expands. However, PTintroduces additional soft prompt tokens, leading to longer input sequences,which significantly impacts training and inference time and memory usage due tothe Transformer's quadratic complexity. Particularly concerning for LargeLanguage Models (LLMs) that face heavy daily querying. To address this issue,we propose Decomposed Prompt Tuning (DePT), which decomposes the soft promptinto a shorter soft prompt and a pair of low-rank matrices that are thenoptimised with two different learning rates. This allows DePT to achieve betterperformance while saving over 20% memory and time costs compared to vanilla PTand its variants, without changing trainable parameter sizes. Through extensiveexperiments on 23 natural language processing (NLP) and vision-language (VL)tasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches,including the full fine-tuning baseline in some scenarios. Additionally, weempirically show that DEPT grows more efficient as the model size increases.Our further study reveals that DePT integrates seamlessly withparameter-efficient transfer learning in the few-shot learning setting andhighlights its adaptability to various model architectures and sizes.</description><author>Zhengxiang Shi, Aldo Lipani</author><pubDate>Thu, 12 Oct 2023 18:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05173v2</guid></item><item><title>CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images</title><link>http://arxiv.org/abs/2307.03293v2</link><description>The development of successful artificial intelligence models for chest X-rayanalysis relies on large, diverse datasets with high-quality annotations. Whileseveral databases of chest X-ray images have been released, most includedisease diagnosis labels but lack detailed pixel-level anatomical segmentationlabels. To address this gap, we introduce an extensive chest X-ray multi-centersegmentation dataset with uniform and fine-grain anatomical annotations forimages coming from six well-known publicly available databases: CANDID-PTX,ChestX-ray8, Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in676,803 segmentation masks. Our methodology utilizes the HybridGNet model toensure consistent and high-quality segmentations across all datasets. Rigorousvalidation, including expert physician evaluation and automatic qualitycontrol, was conducted to validate the resulting masks. Additionally, weprovide individualized quality indices per mask and an overall qualityestimation per dataset. This dataset serves as a valuable resource for thebroader scientific community, streamlining the development and assessment ofinnovative methodologies in chest X-ray analysis. The CheXmask dataset ispublicly available at:https://physionet.org/content/chexmask-cxr-segmentation-data/</description><author>Nicolás Gaggion, Candelaria Mosquera, Lucas Mansilla, Martina Aineseder, Diego H. Milone, Enzo Ferrante</author><pubDate>Thu, 12 Oct 2023 18:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03293v2</guid></item><item><title>Formally Specifying the High-Level Behavior of LLM-Based Agents</title><link>http://arxiv.org/abs/2310.08535v1</link><description>LLM-based agents have recently emerged as promising tools for solvingchallenging problems without the need for task-specific finetuned models thatcan be expensive to procure. Currently, the design and implementation of suchagents is ad hoc, as the wide variety of tasks that LLM-based agents may beapplied to naturally means there can be no one-size-fits-all approach to agentdesign. In this work we aim to alleviate the difficulty of designing andimplementing new agents by proposing a minimalistic, high-level generationframework that simplifies the process of building agents. The framework weintroduce allows the user to specify desired agent behaviors in Linear TemporalLogic (LTL). The declarative LTL specification is then used to construct aconstrained decoder that guarantees the LLM will produce an output exhibitingthe desired behavior. By designing our framework in this way, we obtain severalbenefits, including the ability to enforce complex agent behavior, the abilityto formally validate prompt examples, and the ability to seamlessly incorporatecontent-focused logical constraints into generation. In particular, ourdeclarative approach, in which the desired behavior is simply described withoutconcern for how it should be implemented or enforced, enables rapid design,implementation and experimentation with different LLM-based agents. Wedemonstrate how the proposed framework can be used to implement recentLLM-based agents, and show how the guardrails our approach provides can lead toimprovements in agent performance. In addition, we release our code for generaluse.</description><author>Maxwell Crouse, Ibrahim Abdelaziz, Kinjal Basu, Soham Dan, Sadhana Kumaravel, Achille Fokoue, Pavan Kapanipathi, Luis Lastras</author><pubDate>Thu, 12 Oct 2023 18:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08535v1</guid></item><item><title>Animating Street View</title><link>http://arxiv.org/abs/2310.08534v1</link><description>We present a system that automatically brings street view imagery to life bypopulating it with naturally behaving, animated pedestrians and vehicles. Ourapproach is to remove existing people and vehicles from the input image, insertmoving objects with proper scale, angle, motion, and appearance, plan paths andtraffic behavior, as well as render the scene with plausible occlusion andshadowing effects. The system achieves these by reconstructing the still imagestreet scene, simulating crowd behavior, and rendering with consistentlighting, visibility, occlusions, and shadows. We demonstrate results on adiverse range of street scenes including regular still images and panoramas.</description><author>Mengyi Shan, Brian Curless, Ira Kemelmacher-Shlizerman, Steve Seitz</author><pubDate>Thu, 12 Oct 2023 18:24:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08534v1</guid></item><item><title>Speculative Decoding with Big Little Decoder</title><link>http://arxiv.org/abs/2302.07863v4</link><description>The recent emergence of Large Language Models based on the Transformerarchitecture has enabled dramatic advancements in the field of Natural LanguageProcessing. However, these models have long inference latency, which limitstheir deployment and makes them prohibitively expensive for various real-timeapplications. The inference latency is further exacerbated by autoregressivegenerative tasks, as models need to run iteratively to generate tokenssequentially without leveraging token-level parallelization. To address this,we propose Big Little Decoder (BiLD), a framework that can improve inferenceefficiency and latency for a wide range of text generation applications. TheBiLD framework contains two models with different sizes that collaborativelygenerate text. The small model runs autoregressively to generate text with alow inference cost, and the large model is only invoked occasionally to refinethe small model's inaccurate predictions in a non-autoregressive manner. Tocoordinate the small and large models, BiLD introduces two simple yet effectivepolicies: (1) the fallback policy that determines when to hand control over tothe large model; and (2) the rollback policy that determines when the largemodel needs to correct the small model's inaccurate predictions. To evaluateour framework across different tasks and models, we apply BiLD to various textgeneration scenarios encompassing machine translation on IWSLT 2017 De-En andWMT 2014 De-En, and summarization on XSUM and CNN/DailyMail. On an NVIDIA T4GPU, our framework achieves a speedup of up to 2.12x speedup with minimalgeneration quality degradation. Furthermore, our framework is fullyplug-and-play and can be applied without any modifications in the trainingprocess or model architecture. Our code is open-sourced</description><author>Sehoon Kim, Karttikeya Mangalam, Suhong Moon, Jitendra Malik, Michael W. Mahoney, Amir Gholami, Kurt Keutzer</author><pubDate>Thu, 12 Oct 2023 18:23:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07863v4</guid></item><item><title>UniPose: Detecting Any Keypoints</title><link>http://arxiv.org/abs/2310.08530v1</link><description>This work proposes a unified framework called UniPose to detect keypoints ofany articulated (e.g., human and animal), rigid, and soft objects via visual ortextual prompts for fine-grained vision understanding and manipulation.Keypoint is a structure-aware, pixel-level, and compact representation of anyobject, especially articulated objects. Existing fine-grained promptable tasksmainly focus on object instance detection and segmentation but often fail toidentify fine-grained granularity and structured information of image andinstance, such as eyes, leg, paw, etc. Meanwhile, prompt-based keypointdetection is still under-explored. To bridge the gap, we make the first attemptto develop an end-to-end prompt-based keypoint detection framework calledUniPose to detect keypoints of any objects. As keypoint detection tasks areunified in this framework, we can leverage 13 keypoint detection datasets with338 keypoints across 1,237 categories over 400K instances to train a generickeypoint detection model. UniPose can effectively align text-to-keypoint andimage-to-keypoint due to the mutual enhancement of textual and visual promptsbased on the cross-modality contrastive learning optimization objectives. Ourexperimental results show that UniPose has strong fine-grained localization andgeneralization abilities across image styles, categories, and poses. Based onUniPose as a generalist keypoint detector, we hope it could serve fine-grainedvisual perception, understanding, and generation.</description><author>Jie Yang, Ailing Zeng, Ruimao Zhang, Lei Zhang</author><pubDate>Thu, 12 Oct 2023 18:22:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08530v1</guid></item><item><title>GaussianDreamer: Fast Generation from Text to 3D Gaussian Splatting with Point Cloud Priors</title><link>http://arxiv.org/abs/2310.08529v1</link><description>In recent times, the generation of 3D assets from text prompts has shownimpressive results. Both 2D and 3D diffusion models can generate decent 3Dobjects based on prompts. 3D diffusion models have good 3D consistency, buttheir quality and generalization are limited as trainable 3D data is expensiveand hard to obtain. 2D diffusion models enjoy strong abilities ofgeneralization and fine generation, but the 3D consistency is hard toguarantee. This paper attempts to bridge the power from the two types ofdiffusion models via the recent explicit and efficient 3D Gaussian splattingrepresentation. A fast 3D generation framework, named as \name, is proposed,where the 3D diffusion model provides point cloud priors for initialization andthe 2D diffusion model enriches the geometry and appearance. Operations ofnoisy point growing and color perturbation are introduced to enhance theinitialized Gaussians. Our \name can generate a high-quality 3D instance within25 minutes on one GPU, much faster than previous methods, while the generatedinstances can be directly rendered in real time. Demos and code are availableat https://taoranyi.com/gaussiandreamer/.</description><author>Taoran Yi, Jiemin Fang, Guanjun Wu, Lingxi Xie, Xiaopeng Zhang, Wenyu Liu, Qi Tian, Xinggang Wang</author><pubDate>Thu, 12 Oct 2023 18:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08529v1</guid></item><item><title>4D Gaussian Splatting for Real-Time Dynamic Scene Rendering</title><link>http://arxiv.org/abs/2310.08528v1</link><description>Representing and rendering dynamic scenes has been an important butchallenging task. Especially, to accurately model complex motions, highefficiency is usually hard to maintain. We introduce the 4D Gaussian Splatting(4D-GS) to achieve real-time dynamic scene rendering while also enjoying hightraining and storage efficiency. An efficient deformation field is constructedto model both Gaussian motions and shape deformations. Different adjacentGaussians are connected via a HexPlane to produce more accurate position andshape deformations. Our 4D-GS method achieves real-time rendering under highresolutions, 70 FPS at a 800$\times$800 resolution on an RTX 3090 GPU, whilemaintaining comparable or higher quality than previous state-of-the-artmethods. More demos and code are available athttps://guanjunwu.github.io/4dgs/.</description><author>Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Qi Tian, Xinggang Wang</author><pubDate>Thu, 12 Oct 2023 18:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08528v1</guid></item><item><title>L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes</title><link>http://arxiv.org/abs/1908.04628v3</link><description>Many real-world prediction tasks have outcome variables that havecharacteristic heavy-tail distributions. Examples include copies of books sold,auction prices of art pieces, demand for commodities in warehouses, etc. Bylearning heavy-tailed distributions, "big and rare" instances (e.g., thebest-sellers) will have accurate predictions. Most existing approaches are notdedicated to learning heavy-tailed distribution; thus, they heavilyunder-predict such instances. To tackle this problem, we introduce Learning toPlace (L2P), which exploits the pairwise relationships between instances forlearning. In its training phase, L2P learns a pairwise preference classifier:is instance A &gt; instance B? In its placing phase, L2P obtains a prediction byplacing the new instance among the known instances. Based on its placement, thenew instance is then assigned a value for its outcome variable. Experiments onreal data show that L2P outperforms competing approaches in terms of accuracyand ability to reproduce heavy-tailed outcome distribution. In addition, L2Pprovides an interpretable model by placing each predicted instance in relationto its comparable neighbors. Interpretable models are highly desirable whenlives and treasure are at stake.</description><author>Xindi Wang, Onur Varol, Tina Eliassi-Rad</author><pubDate>Thu, 12 Oct 2023 18:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1908.04628v3</guid></item><item><title>LLM-augmented Preference Learning from Natural Language</title><link>http://arxiv.org/abs/2310.08523v1</link><description>Finding preferences expressed in natural language is an important butchallenging task. State-of-the-art(SotA) methods leverage transformer-basedmodels such as BERT, RoBERTa, etc. and graph neural architectures such as graphattention networks. Since Large Language Models (LLMs) are equipped to dealwith larger context lengths and have much larger model sizes than thetransformer-based model, we investigate their ability to classify comparativetext directly. This work aims to serve as a first step towards using LLMs forthe CPC task. We design and conduct a set of experiments that format theclassification task into an input prompt for the LLM and a methodology to get afixed-format response that can be automatically evaluated. Comparingperformances with existing methods, we see that pre-trained LLMs are able tooutperform the previous SotA models with no fine-tuning involved. Our resultsshow that the LLMs can consistently outperform the SotA when the target text islarge -- i.e. composed of multiple sentences --, and are still comparable tothe SotA performance in shorter text. We also find that few-shot learningyields better performance than zero-shot learning.</description><author>Inwon Kang, Sikai Ruan, Tyler Ho, Jui-Chien Lin, Farhad Mohsin, Oshani Seneviratne, Lirong Xia</author><pubDate>Thu, 12 Oct 2023 18:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08523v1</guid></item><item><title>Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts</title><link>http://arxiv.org/abs/2310.05898v2</link><description>Lion (Evolved Sign Momentum), a new optimizer discovered through programsearch, has shown promising results in training large AI models. It performscomparably or favorably to AdamW but with greater memory efficiency. As we canexpect from the results of a random search program, Lion incorporates elementsfrom several existing algorithms, including signed momentum, decoupled weightdecay, Polak, and Nesterov momentum, but does not fit into any existingcategory of theoretically grounded optimizers. Thus, even though Lion appearsto perform well as a general-purpose optimizer for a wide range of tasks, itstheoretical basis remains uncertain. This lack of theoretical clarity limitsopportunities to further enhance and expand Lion's efficacy. This work aims to demystify Lion. Based on both continuous-time anddiscrete-time analysis, we demonstrate that Lion is a theoretically novel andprincipled approach for minimizing a general loss function $f(x)$ whileenforcing a bound constraint $\|x\|_\infty \leq 1/\lambda$. Lion achieves thisthrough the incorporation of decoupled weight decay, where $\lambda$ representsthe weight decay coefficient. Our analysis is made possible by the developmentof a new Lyapunov function for the Lion updates. It applies to a broader familyof Lion-$\kappa$ algorithms, where the $\text{sign}(\cdot)$ operator in Lion isreplaced by the subgradient of a convex function $\kappa$, leading to thesolution of a general composite optimization problem of $\min_x f(x) +\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lionand pave the way for further improvements and extensions of Lion-relatedalgorithms.</description><author>Lizhang Chen, Bo Liu, Kaizhao Liang, Qiang Liu</author><pubDate>Thu, 12 Oct 2023 18:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05898v2</guid></item><item><title>How connectivity structure shapes rich and lazy learning in neural circuits</title><link>http://arxiv.org/abs/2310.08513v1</link><description>In theoretical neuroscience, recent work leverages deep learning tools toexplore how some network attributes critically influence its learning dynamics.Notably, initial weight distributions with small (resp. large) variance mayyield a rich (resp. lazy) regime, where significant (resp. minor) changes tonetwork states and representation are observed over the course of learning.However, in biology, neural circuit connectivity generally has a low-rankstructure and therefore differs markedly from the random initializationsgenerally used for these studies. As such, here we investigate how thestructure of the initial weights, in particular their effective rank,influences the network learning regime. Through both empirical and theoreticalanalyses, we discover that high-rank initializations typically yield smallernetwork changes indicative of lazier learning, a finding we also confirm withexperimentally-driven initial connectivity in recurrent neural networks.Conversely, low-rank initialization biases learning towards richer learning.Importantly, however, as an exception to this rule, we find lazier learning canstill occur with a low-rank initialization that aligns with task and datastatistics. Our research highlights the pivotal role of initial weightstructures in shaping learning regimes, with implications for metabolic costsof plasticity and risks of catastrophic forgetting.</description><author>Yuhan Helena Liu, Aristide Baratin, Jonathan Cornford, Stefan Mihalas, Eric Shea-Brown, Guillaume Lajoie</author><pubDate>Thu, 12 Oct 2023 18:08:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08513v1</guid></item><item><title>mGPT: Few-Shot Learners Go Multilingual</title><link>http://arxiv.org/abs/2204.07580v2</link><description>Recent studies report that autoregressive language models can successfullysolve many NLP tasks via zero- and few-shot learning paradigms, which opens upnew possibilities for using the pre-trained language models. This paperintroduces two autoregressive GPT-like models with 1.3 billion and 13 billionparameters trained on 60 languages from 25 language families using Wikipediaand Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture usingGPT-2 sources and the sparse attention mechanism; Deepspeed and Megatronframeworks allow us to parallelize the training and inference stepseffectively. The resulting models show performance on par with the recentlyreleased XGLM models by Facebook, covering more languages and enhancing NLPpossibilities for low resource languages of CIS countries and Russian smallnations. We detail the motivation for the choices of the architecture design,thoroughly describe the data preparation pipeline, and train five smallversions of the model to choose the most optimal multilingual tokenizationstrategy. We measure the model perplexity in all covered languages and evaluateit on the wide spectre of multilingual tasks, including classification,generative, sequence labeling and knowledge probing. The models were evaluatedwith the zero-shot and few-shot methods. Furthermore, we compared theclassification tasks with the state-of-the-art multilingual model XGLM. sourcecode and the mGPT XL model are publicly released.</description><author>Oleh Shliazhko, Alena Fenogenova, Maria Tikhonova, Vladislav Mikhailov, Anastasia Kozlova, Tatiana Shavrina</author><pubDate>Thu, 12 Oct 2023 18:07:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.07580v2</guid></item><item><title>Multimodal Graph Learning for Generative Tasks</title><link>http://arxiv.org/abs/2310.07478v2</link><description>Multimodal learning combines multiple data modalities, broadening the typesand complexity of data our models can utilize: for example, from plain text toimage-caption pairs. Most multimodal learning algorithms focus on modelingsimple one-to-one pairs of data from two modalities, such as image-captionpairs, or audio-text pairs. However, in most real-world settings, entities ofdifferent modalities interact with each other in more complex and multifacetedways, going beyond one-to-one mappings. We propose to represent these complexrelationships as graphs, allowing us to capture data with any number ofmodalities, and with complex relationships between modalities that can flexiblyvary from one sample to another. Toward this goal, we propose Multimodal GraphLearning (MMGL), a general and systematic framework for capturing informationfrom multiple multimodal neighbors with relational structures among them. Inparticular, we focus on MMGL for generative tasks, building upon pretrainedLanguage Models (LMs), aiming to augment their text generation with multimodalneighbor contexts. We study three research questions raised by MMGL: (1) howcan we infuse multiple neighbor information into the pretrained LMs, whileavoiding scalability issues? (2) how can we infuse the graph structureinformation among multimodal neighbors into the LMs? and (3) how can wefinetune the pretrained LMs to learn from the neighbor context in aparameter-efficient manner? We conduct extensive experiments to answer thesethree questions on MMGL and analyze the empirical results to pave the way forfuture MMGL research.</description><author>Minji Yoon, Jing Yu Koh, Bryan Hooi, Ruslan Salakhutdinov</author><pubDate>Thu, 12 Oct 2023 18:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07478v2</guid></item><item><title>HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science</title><link>http://arxiv.org/abs/2310.08511v1</link><description>We propose an instruction-based process for trustworthy data curation inmaterials science (MatSci-Instruct), which we then apply to finetune aLLaMa-based language model targeted for materials science (HoneyBee).MatSci-Instruct helps alleviate the scarcity of relevant, high-qualitymaterials science textual data available in the open literature, and HoneyBeeis the first billion-parameter language model specialized to materials science.In MatSci-Instruct we improve the trustworthiness of generated data byprompting multiple commercially available large language models for generationwith an Instructor module (e.g. Chat-GPT) and verification from an independentVerifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset ofmultiple tasks and measure the quality of our dataset along multipledimensions, including accuracy against known facts, relevance to materialsscience, as well as completeness and reasonableness of the data. Moreover, weiteratively generate more targeted instructions and instruction-data in afinetuning-evaluation-feedback loop leading to progressively better performancefor our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmarkshows HoneyBee's outperformance of existing language models on materialsscience tasks and iterative improvement in successive stages ofinstruction-data refinement. We study the quality of HoneyBee's languagemodeling through automatic evaluation and analyze case studies to furtherunderstand the model's capabilities and limitations. Our code and relevantdatasets are publicly available at\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee}.</description><author>Yu Song, Santiago Miret, Huan Zhang, Bang Liu</author><pubDate>Thu, 12 Oct 2023 18:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08511v1</guid></item><item><title>GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models</title><link>http://arxiv.org/abs/2310.06225v2</link><description>Large language models (LLMs) have demonstrated remarkable capabilities innatural language understanding across various domains, including healthcare andfinance. For some tasks, LLMs achieve similar or better performance thantrained human beings, therefore it is reasonable to employ human exams (e.g.,certification tests) to assess the performance of LLMs. We present acomprehensive evaluation of popular LLMs, such as Llama 2 and GPT, on theirability to answer agriculture-related questions. In our evaluation, we alsoemploy RAG (Retrieval-Augmented Generation) and ER (Ensemble Refinement)techniques, which combine information retrieval, generation capabilities, andprompting strategies to improve the LLMs' performance. To demonstrate thecapabilities of LLMs, we selected agriculture exams and benchmark datasets fromthree of the largest agriculture producer countries: Brazil, India, and theUSA. Our analysis highlights GPT-4's ability to achieve a passing score onexams to earn credits for renewing agronomist certifications, answering 93% ofthe questions correctly and outperforming earlier general-purpose models, whichachieved 88% accuracy. On one of our experiments, GPT-4 obtained the highestperformance when compared to human subjects. This performance suggests thatGPT-4 could potentially pass on major graduate education admission tests oreven earn credits for renewing agronomy certificates. We also explore themodels' capacity to address general agriculture-related questions and generatecrop management guidelines for Brazilian and Indian farmers, utilizing robustdatasets from the Brazilian Agency of Agriculture (Embrapa) and graduateprogram exams from India. The results suggest that GPT-4, ER, and RAG cancontribute meaningfully to agricultural education, assessment, and cropmanagement practice, offering valuable insights to farmers and agriculturalprofessionals.</description><author>Bruno Silva, Leonardo Nunes, Roberto Estevão, Vijay Aski, Ranveer Chandra</author><pubDate>Thu, 12 Oct 2023 18:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06225v2</guid></item><item><title>Axiomatic Aggregations of Abductive Explanations</title><link>http://arxiv.org/abs/2310.03131v3</link><description>The recent criticisms of the robustness of post hoc model approximationexplanation methods (like LIME and SHAP) have led to the rise of model-preciseabductive explanations. For each data point, abductive explanations provide aminimal subset of features that are sufficient to generate the outcome. Whiletheoretically sound and rigorous, abductive explanations suffer from a majorissue -- there can be several valid abductive explanations for the same datapoint. In such cases, providing a single abductive explanation can beinsufficient; on the other hand, providing all valid abductive explanations canbe incomprehensible due to their size. In this work, we solve this issue byaggregating the many possible abductive explanations into feature importancescores. We propose three aggregation methods: two based on power indices fromcooperative game theory and a third based on a well-known measure of causalstrength. We characterize these three methods axiomatically, showing that eachof them uniquely satisfies a set of desirable properties. We also evaluate themon multiple datasets and show that these explanations are robust to the attacksthat fool SHAP and LIME.</description><author>Gagan Biradar, Yacine Izza, Elita Lobo, Vignesh Viswanathan, Yair Zick</author><pubDate>Thu, 12 Oct 2023 18:02:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03131v3</guid></item><item><title>Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images</title><link>http://arxiv.org/abs/2310.08501v1</link><description>Segmentation of objects in microscopy images is required for many biomedicalapplications. We introduce object-centric embeddings (OCEs), which embed imagepatches such that the spatial offsets between patches cropped from the sameobject are preserved. Those learnt embeddings can be used to delineateindividual objects and thus obtain instance segmentations. Here, we showtheoretically that, under assumptions commonly found in microscopy images, OCEscan be learnt through a self-supervised task that predicts the spatial offsetbetween image patches. Together, this forms an unsupervised cell instancesegmentation method which we evaluate on nine diverse large-scale microscopydatasets. Segmentations obtained with our method lead to substantially improvedresults, compared to state-of-the-art baselines on six out of nine datasets,and perform on par on the remaining three datasets. If ground-truth annotationsare available, our method serves as an excellent starting point for supervisedtraining, reducing the required amount of ground-truth needed by one order ofmagnitude, thus substantially increasing the practical applicability of ourmethod. Source code is available at https://github.com/funkelab/cellulus.</description><author>Steffen Wolf, Manan Lalit, Henry Westmacott, Katie McDole, Jan Funke</author><pubDate>Thu, 12 Oct 2023 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08501v1</guid></item><item><title>Impact of time and note duration tokenizations on deep learning symbolic music modeling</title><link>http://arxiv.org/abs/2310.08497v1</link><description>Symbolic music is widely used in various deep learning tasks, includinggeneration, transcription, synthesis, and Music Information Retrieval (MIR). Itis mostly employed with discrete models like Transformers, which require musicto be tokenized, i.e., formatted into sequences of distinct elements calledtokens. Tokenization can be performed in different ways. As Transformer canstruggle at reasoning, but capture more easily explicit information, it isimportant to study how the way the information is represented for such modelimpact their performances. In this work, we analyze the common tokenizationmethods and experiment with time and note duration representations. We comparethe performances of these two impactful criteria on several tasks, includingcomposer and emotion classification, music generation, and sequencerepresentation learning. We demonstrate that explicit information leads tobetter results depending on the task.</description><author>Nathan Fradet, Nicolas Gutowski, Fabien Chhel, Jean-Pierre Briot</author><pubDate>Thu, 12 Oct 2023 17:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08497v1</guid></item><item><title>The Uncertainty-based Retrieval Framework for Ancient Chinese CWS and POS</title><link>http://arxiv.org/abs/2310.08496v1</link><description>Automatic analysis for modern Chinese has greatly improved the accuracy oftext mining in related fields, but the study of ancient Chinese is stillrelatively rare. Ancient text division and lexical annotation are importantparts of classical literature comprehension, and previous studies have tried toconstruct auxiliary dictionary and other fused knowledge to improve theperformance. In this paper, we propose a framework for ancient Chinese WordSegmentation and Part-of-Speech Tagging that makes a twofold effort: on the onehand, we try to capture the wordhood semantics; on the other hand, were-predict the uncertain samples of baseline model by introducing externalknowledge. The performance of our architecture outperforms pre-trained BERTwith CRF and existing tools such as Jiayan.</description><author>Pengyu Wang, Zhichen Ren</author><pubDate>Thu, 12 Oct 2023 17:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08496v1</guid></item><item><title>Characterizing climate pathways using feature importance on echo state networks</title><link>http://arxiv.org/abs/2310.08495v1</link><description>The 2022 National Defense Strategy of the United States listed climate changeas a serious threat to national security. Climate intervention methods, such asstratospheric aerosol injection, have been proposed as mitigation strategies,but the downstream effects of such actions on a complex climate system are notwell understood. The development of algorithmic techniques for quantifyingrelationships between source and impact variables related to a climate event(i.e., a climate pathway) would help inform policy decisions. Data-driven deeplearning models have become powerful tools for modeling highly nonlinearrelationships and may provide a route to characterize climate variablerelationships. In this paper, we explore the use of an echo state network (ESN)for characterizing climate pathways. ESNs are a computationally efficientneural network variation designed for temporal data, and recent work proposesESNs as a useful tool for forecasting spatio-temporal climate data. Like otherneural networks, ESNs are non-interpretable black-box models, which poses ahurdle for understanding variable relationships. We address this issue bydeveloping feature importance methods for ESNs in the context ofspatio-temporal data to quantify variable relationships captured by the model.We conduct a simulation study to assess and compare the feature importancetechniques, and we demonstrate the approach on reanalysis climate data. In theclimate application, we select a time period that includes the 1991 volcaniceruption of Mount Pinatubo. This event was a significant stratospheric aerosolinjection, which we use as a proxy for an artificial stratospheric aerosolinjection. Using the proposed approach, we are able to characterizerelationships between pathway variables associated with this event.</description><author>Katherine Goode, Daniel Ries, Kellie McClernon</author><pubDate>Thu, 12 Oct 2023 17:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08495v1</guid></item><item><title>Prometheus: Inducing Fine-grained Evaluation Capability in Language Models</title><link>http://arxiv.org/abs/2310.08491v1</link><description>Recently, using a powerful proprietary Large Language Model (LLM) (e.g.,GPT-4) as an evaluator for long-form responses has become the de factostandard. However, for practitioners with large-scale evaluation tasks andcustom criteria in consideration (e.g., child-readability), using proprietaryLLMs as an evaluator is unreliable due to the closed-source nature,uncontrolled versioning, and prohibitive costs. In this work, we proposePrometheus, a fully open-source LLM that is on par with GPT-4's evaluationcapabilities when the appropriate reference materials (reference answer, scorerubric) are accompanied. We first construct the Feedback Collection, a newdataset that consists of 1K fine-grained score rubrics, 20K instructions, and100K responses and language feedback generated by GPT-4. Using the FeedbackCollection, we train Prometheus, a 13B evaluator LLM that can assess any givenlong-form text based on customized score rubric provided by the user.Experimental results show that Prometheus scores a Pearson correlation of 0.897with human evaluators when evaluating with 45 customized score rubrics, whichis on par with GPT-4 (0.882), and greatly outperforms ChatGPT (0.392).Furthermore, measuring correlation with GPT-4 with 1222 customized scorerubrics across four benchmarks (MT Bench, Vicuna Bench, Feedback Bench, FlaskEval) shows similar trends, bolstering Prometheus's capability as an evaluatorLLM. Lastly, Prometheus achieves the highest accuracy on two human preferencebenchmarks (HHH Alignment &amp; MT Bench Human Judgment) compared to open-sourcedreward models explicitly trained on human preference datasets, highlighting itspotential as an universal reward model. We open-source our code, dataset, andmodel at https://github.com/kaistAI/Prometheus.</description><author>Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, Minjoon Seo</author><pubDate>Thu, 12 Oct 2023 17:50:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08491v1</guid></item><item><title>GraphextQA: A Benchmark for Evaluating Graph-Enhanced Large Language Models</title><link>http://arxiv.org/abs/2310.08487v1</link><description>While multi-modal models have successfully integrated information from image,video, and audio modalities, integrating graph modality into large languagemodels (LLMs) remains unexplored. This discrepancy largely stems from theinherent divergence between structured graph data and unstructured text data.Incorporating graph knowledge provides a reliable source of information,enabling potential solutions to address issues in text generation, e.g.,hallucination, and lack of domain knowledge. To evaluate the integration ofgraph knowledge into language models, a dedicated dataset is needed. However,there is currently no benchmark dataset specifically designed for multimodalgraph-language models. To address this gap, we propose GraphextQA, a questionanswering dataset with paired subgraphs, retrieved from Wikidata, to facilitatethe evaluation and future development of graph-language models. Additionally,we introduce a baseline model called CrossGNN, which conditions answergeneration on the paired graphs by cross-attending question-aware graphfeatures at decoding. The proposed dataset is designed to evaluategraph-language models' ability to understand graphs and make use of it foranswer generation. We perform experiments with language-only models and theproposed graph-language model to validate the usefulness of the paired graphsand to demonstrate the difficulty of the task.</description><author>Yuanchun Shen, Ruotong Liao, Zhen Han, Yunpu Ma, Volker Tresp</author><pubDate>Thu, 12 Oct 2023 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08487v1</guid></item><item><title>NECO: NEural Collapse Based Out-of-distribution detection</title><link>http://arxiv.org/abs/2310.06823v2</link><description>Detecting out-of-distribution (OOD) data is a critical challenge in machinelearning due to model overconfidence, often without awareness of theirepistemological limits. We hypothesize that ``neural collapse'', a phenomenonaffecting in-distribution data for models trained beyond loss convergence, alsoinfluences OOD data. To benefit from this interplay, we introduce NECO, a novelpost-hoc method for OOD detection, which leverages the geometric properties of``neural collapse'' and of principal component spaces to identify OOD data. Ourextensive experiments demonstrate that NECO achieves state-of-the-art resultson both small and large-scale OOD detection tasks while exhibiting stronggeneralization capabilities across different network architectures.Furthermore, we provide a theoretical explanation for the effectiveness of ourmethod in OOD detection. We plan to release the code after the anonymityperiod.</description><author>Mouïn Ben Ammar, Nacim Belkhir, Sebastian Popescu, Antoine Manzanera, Gianni Franchi</author><pubDate>Thu, 12 Oct 2023 17:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06823v2</guid></item><item><title>Understanding the Humans Behind Online Misinformation: An Observational Study Through the Lens of the COVID-19 Pandemic</title><link>http://arxiv.org/abs/2310.08483v1</link><description>The proliferation of online misinformation has emerged as one of the biggestthreats to society. Considerable efforts have focused on buildingmisinformation detection models, still the perils of misinformation remainabound. Mitigating online misinformation and its ramifications requires aholistic approach that encompasses not only an understanding of its intricatelandscape in relation to the complex issue and topic-rich information ecosystemonline, but also the psychological drivers of individuals behind it. Adopting atime series analytic technique and robust causal inference-based design, weconduct a large-scale observational study analyzing over 32 million COVID-19tweets and 16 million historical timeline tweets. We focus on understanding thebehavior and psychology of users disseminating misinformation during COVID-19and its relationship with the historical inclinations towards sharingmisinformation on Non-COVID topics before the pandemic. Our analysisunderscores the intricacies inherent to cross-topic misinformation, andhighlights that users' historical inclination toward sharing misinformation ispositively associated with their present behavior pertaining to misinformationsharing on emergent topics and beyond. This work may serve as a valuablefoundation for designing user-centric inoculation strategies andecologically-grounded agile interventions for effectively tackling onlinemisinformation.</description><author>Mohit Chandra, Anush Mattapalli, Munmun De Choudhury</author><pubDate>Thu, 12 Oct 2023 17:42:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08483v1</guid></item><item><title>Personalised dynamic super learning: an application in predicting hemodiafiltration's convection volumes</title><link>http://arxiv.org/abs/2310.08479v1</link><description>Obtaining continuously updated predictions is a major challenge forpersonalised medicine. Leveraging combinations of parametric regressions andmachine learning approaches, the personalised online super learner (POSL) canachieve such dynamic and personalised predictions. We adapt POSL to predict arepeated continuous outcome dynamically and propose a new way to validate suchpersonalised or dynamic prediction models. We illustrate its performance bypredicting the convection volume of patients undergoing hemodiafiltration. POSLoutperformed its candidate learners with respect to median absolute error,calibration-in-the-large, discrimination, and net benefit. We finally discussthe choices and challenges underlying the use of POSL.</description><author>Arthur Chatton, Michèle Bally, Renée Lévesque, Ivana Malenica, Robert W. Platt, Mireille E. Schnitzer</author><pubDate>Thu, 12 Oct 2023 17:36:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08479v1</guid></item><item><title>Can We Edit Multimodal Large Language Models?</title><link>http://arxiv.org/abs/2310.08475v1</link><description>In this paper, we focus on editing Multimodal Large Language Models (MLLMs).Compared to editing single-modal LLMs, multimodal model editing is morechallenging, which demands a higher level of scrutiny and careful considerationin the editing process. To facilitate research in this area, we construct a newbenchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suiteof innovative metrics for evaluation. We conduct comprehensive experimentsinvolving various model editing baselines and analyze the impact of editingdifferent components for multimodal LLMs. Empirically, we notice that previousbaselines can implement editing multimodal LLMs to some extent, but the effectis still barely satisfactory, indicating the potential difficulty of this task.We hope that our work can provide the NLP community with insights\footnote{Codeand dataset are available in https://github.com/zjunlp/EasyEdit.</description><author>Siyuan Cheng, Bozhong Tian, Qingbin Liu, Xi Chen, Yongheng Wang, Huajun Chen, Ningyu Zhang</author><pubDate>Thu, 12 Oct 2023 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08475v1</guid></item><item><title>Strategies and impact of learning curve estimation for CNN-based image classification</title><link>http://arxiv.org/abs/2310.08470v1</link><description>Learning curves are a measure for how the performance of machine learningmodels improves given a certain volume of training data. Over a wide variety ofapplications and models it was observed that learning curves follow -- to alarge extent -- a power law behavior. This makes the performance of differentmodels for a given task somewhat predictable and opens the opportunity toreduce the training time for practitioners, who are exploring the space ofpossible models and hyperparameters for the problem at hand. By estimating thelearning curve of a model from training on small subsets of data only the bestmodels need to be considered for training on the full dataset. How to choosesubset sizes and how often to sample models on these to obtain estimates ishowever not researched. Given that the goal is to reduce overall training timestrategies are needed that sample the performance in a time-efficient way andyet leads to accurate learning curve estimates. In this paper we formulate theframework for these strategies and propose several strategies. Further weevaluate the strategies for simulated learning curves and in experiments withpopular datasets and models for image classification tasks.</description><author>Laura Didyk, Brayden Yarish, Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry</author><pubDate>Thu, 12 Oct 2023 17:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08470v1</guid></item><item><title>Belief formation and the persistence of biased beliefs</title><link>http://arxiv.org/abs/2310.08466v1</link><description>We propose a belief-formation model where agents attempt to discriminatebetween two theories, and where the asymmetry in strength between confirmingand disconfirming evidence tilts beliefs in favor of theories that generatestrong (and possibly rare) confirming evidence and weak (and frequent)disconfirming evidence. In our model, limitations on information processingprovide incentives to censor weak evidence, with the consequence that for somediscrimination problems, evidence may become mostly one-sided, independently ofthe true underlying theory. Sophisticated agents who know the characteristicsof the censored data-generating process are not lured by this accumulation of``evidence'', but less sophisticated ones end up with biased beliefs.</description><author>Olivier Compte</author><pubDate>Thu, 12 Oct 2023 17:27:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08466v1</guid></item><item><title>MotionDirector: Motion Customization of Text-to-Video Diffusion Models</title><link>http://arxiv.org/abs/2310.08465v1</link><description>Large-scale pre-trained diffusion models have exhibited remarkablecapabilities in diverse video generations. Given a set of video clips of thesame motion concept, the task of Motion Customization is to adapt existingtext-to-video diffusion models to generate videos with this motion. Forexample, generating a video with a car moving in a prescribed manner underspecific camera movements to make a movie, or a video illustrating how a bearwould lift weights to inspire creators. Adaptation methods have been developedfor customizing appearance like subject or style, yet unexplored for motion. Itis straightforward to extend mainstream adaption methods for motioncustomization, including full model tuning, parameter-efficient tuning ofadditional layers, and Low-Rank Adaptions (LoRAs). However, the motion conceptlearned by these methods is often coupled with the limited appearances in thetraining videos, making it difficult to generalize the customized motion toother appearances. To overcome this challenge, we propose MotionDirector, witha dual-path LoRAs architecture to decouple the learning of appearance andmotion. Further, we design a novel appearance-debiased temporal loss tomitigate the influence of appearance on the temporal training objective.Experimental results show the proposed method can generate videos of diverseappearances for the customized motions. Our method also supports variousdownstream applications, such as the mixing of different videos with theirappearance and motion respectively, and animating a single image withcustomized motions. Our code and model weights will be released.</description><author>Rui Zhao, Yuchao Gu, Jay Zhangjie Wu, David Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, Mike Zheng Shou</author><pubDate>Thu, 12 Oct 2023 17:26:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08465v1</guid></item><item><title>DistillSpec: Improving Speculative Decoding via Knowledge Distillation</title><link>http://arxiv.org/abs/2310.08461v1</link><description>Speculative decoding (SD) accelerates large language model inference byemploying a faster draft model for generating multiple tokens, which are thenverified in parallel by the larger target model, resulting in the textgenerated according to the target model distribution. However, identifying acompact draft model that is well-aligned with the target model is challenging.To tackle this issue, we propose DistillSpec that uses knowledge distillationto better align the draft model with the target model, before applying SD.DistillSpec makes two key design choices, which we demonstrate via systematicstudy to be crucial to improving the draft and target alignment: utilizingon-policy data generation from the draft model, and tailoring the divergencefunction to the task and decoding strategy. Notably, DistillSpec yieldsimpressive 10 - 45% speedups over standard SD on a range of standardbenchmarks, using both greedy and non-greedy sampling. Furthermore, we combineDistillSpec with lossy SD to achieve fine-grained control over the latency vs.task performance trade-off. Finally, in practical scenarios with models ofvarying sizes, first using distillation to boost the performance of the targetmodel and then applying DistillSpec to train a well-aligned draft model canreduce decoding latency by 6-10x with minimal performance drop, compared tostandard decoding without distillation.</description><author>Yongchao Zhou, Kaifeng Lyu, Ankit Singh Rawat, Aditya Krishna Menon, Afshin Rostamizadeh, Sanjiv Kumar, Jean-François Kagy, Rishabh Agarwal</author><pubDate>Thu, 12 Oct 2023 17:21:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08461v1</guid></item><item><title>A Survey on Heterogeneous Transfer Learning</title><link>http://arxiv.org/abs/2310.08459v1</link><description>The application of transfer learning, an approach utilizing knowledge from asource domain to enhance model performance in a target domain, has seen atremendous rise in recent years, underpinning many real-world scenarios. Thekey to its success lies in the shared common knowledge between the domains, aprerequisite in most transfer learning methodologies. These methods typicallypresuppose identical feature spaces and label spaces in both domains, known ashomogeneous transfer learning, which, however, is not always a practicalassumption. Oftentimes, the source and target domains vary in feature spaces,data distributions, and label spaces, making it challenging or costly to securesource domain data with identical feature and label spaces as the targetdomain. Arbitrary elimination of these differences is not always feasible oroptimal. Thus, heterogeneous transfer learning, acknowledging and dealing withsuch disparities, has emerged as a promising approach for a variety of tasks.Despite the existence of a survey in 2017 on this topic, the fast-pacedadvances post-2017 necessitate an updated, in-depth review. We thereforepresent a comprehensive survey of recent developments in heterogeneous transferlearning methods, offering a systematic guide for future research. Our paperreviews methodologies for diverse learning scenarios, discusses the limitationsof current studies, and covers various application contexts, including NaturalLanguage Processing, Computer Vision, Multimodality, and Biomedicine, to fostera deeper understanding and spur future research.</description><author>Runxue Bao, Yiming Sun, Yuhe Gao, Jindong Wang, Qiang Yang, Haifeng Chen, Zhi-Hong Mao, Xing Xie, Ye Ye</author><pubDate>Thu, 12 Oct 2023 17:19:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08459v1</guid></item><item><title>Metrics for popularity bias in dynamic recommender systems</title><link>http://arxiv.org/abs/2310.08455v1</link><description>Albeit the widespread application of recommender systems (RecSys) in ourdaily lives, rather limited research has been done on quantifying unfairnessand biases present in such systems. Prior work largely focuses on determiningwhether a RecSys is discriminating or not but does not compute the amount ofbias present in these systems. Biased recommendations may lead to decisionsthat can potentially have adverse effects on individuals, sensitive usergroups, and society. Hence, it is important to quantify these biases for fairand safe commercial applications of these systems. This paper focuses onquantifying popularity bias that stems directly from the output of RecSysmodels, leading to over recommendation of popular items that are likely to bemisaligned with user preferences. Four metrics to quantify popularity bias inRescSys over time in dynamic setting across different sensitive user groupshave been proposed. These metrics have been demonstrated for four collaborativefiltering based RecSys algorithms trained on two commonly used benchmarkdatasets in the literature. Results obtained show that the metrics proposedprovide a comprehensive understanding of growing disparities in treatmentbetween sensitive groups over time when used conjointly.</description><author>Valentijn Braun, Debarati Bhaumik, Diptish Dey</author><pubDate>Thu, 12 Oct 2023 17:15:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08455v1</guid></item><item><title>On the Security Vulnerabilities of Text-to-SQL Models</title><link>http://arxiv.org/abs/2211.15363v3</link><description>Although it has been demonstrated that Natural Language Processing (NLP)algorithms are vulnerable to deliberate attacks, the question of whether suchweaknesses can lead to software security threats is under-explored. To bridgethis gap, we conducted vulnerability tests on Text-to-SQL systems that arecommonly used to create natural language interfaces to databases. We showedthat the Text-to-SQL modules within six commercial applications can bemanipulated to produce malicious code, potentially leading to data breaches andDenial of Service attacks. This is the first demonstration that NLP models canbe exploited as attack vectors in the wild. In addition, experiments using fouropen-source language models verified that straightforward backdoor attacks onText-to-SQL systems achieve a 100% success rate without affecting theirperformance. The aim of this work is to draw the community's attention topotential software security issues associated with NLP algorithms and encourageexploration of methods to mitigate against them.</description><author>Xutan Peng, Yipeng Zhang, Jingfeng Yang, Mark Stevenson</author><pubDate>Thu, 12 Oct 2023 17:12:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15363v3</guid></item><item><title>Proving the Potential of Skeleton Based Action Recognition to Automate the Analysis of Manual Processes</title><link>http://arxiv.org/abs/2310.08451v1</link><description>In manufacturing sectors such as textiles and electronics, manual processesare a fundamental part of production. The analysis and monitoring of theprocesses is necessary for efficient production design. Traditional methods foranalyzing manual processes are complex, expensive, and inflexible. Compared toestablished approaches such as Methods-Time-Measurement (MTM), machine learning(ML) methods promise: Higher flexibility, self-sufficient &amp; permanent use,lower costs. In this work, based on a video stream, the current motion class ina manual assembly process is detected. With information on the current motion,Key-Performance-Indicators (KPIs) can be derived easily. A skeleton-basedaction recognition approach is taken, as this field recently shows majorsuccess in machine vision tasks. For skeleton-based action recognition inmanual assembly, no sufficient pre-work could be found. Therefore, a MLpipeline is developed, to enable extensive research on different (pre-)processing methods and neural nets. Suitable well generalizing approaches arefound, proving the potential of ML to enhance analyzation of manual processes.Models detect the current motion, performed by an operator in manual assembly,but the results can be transferred to all kinds of manual processes.</description><author>Marlin Berger, Frederik Cloppenburg, Jens Eufinger, Thomas Gries</author><pubDate>Thu, 12 Oct 2023 17:11:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08451v1</guid></item><item><title>Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery</title><link>http://arxiv.org/abs/2305.14259v3</link><description>Literature-Based Discovery (LBD) aims to discover new scientific knowledge bymining papers and generating hypotheses. Standard LBD is limited to predictingpairwise relations between discrete concepts (e.g., drug-disease links), andignores critical contexts like experimental settings (e.g., a specific patientpopulation where a drug is evaluated) and background motivations (e.g., to finddrugs without specific side effects). We address these limitations with a novelformulation of contextualized-LBD (C-LBD): generating scientific hypotheses innatural language, while grounding them in a context that controls thehypothesis search space. We present a modeling framework using retrieval of``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4tends to generate ideas with overall low technical depth and novelty, while ourinspiration prompting approaches partially mitigate this issue. Our workrepresents a first step toward building language models that generate new ideasderived from scientific literature.</description><author>Qingyun Wang, Doug Downey, Heng Ji, Tom Hope</author><pubDate>Thu, 12 Oct 2023 17:10:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14259v3</guid></item><item><title>CIDER: Context sensitive sentiment analysis for short-form text</title><link>http://arxiv.org/abs/2307.07864v2</link><description>Researchers commonly perform sentiment analysis on large collections of shorttexts like tweets, Reddit posts or newspaper headlines that are all focused ona specific topic, theme or event. Usually, general purpose sentiment analysismethods are used which perform well on average but miss the variation inmeaning that happens across different contexts, for example, the word "active"has a very different intention and valence in the phrase "active lifestyle"versus "active volcano". This work presents a new approach, CIDER (ContextInformed Dictionary and sEntiment Reasoner), which performs context sensitivesentiment analysis, where the valence of sentiment laden terms is inferred fromthe whole corpus before being used to score the individual texts. In this paperwe detail the CIDER algorithm and demonstrate that it outperformsstate-of-the-art generalist sentiment analysis on a large collection of tweetsabout the weather. We have made our implementation of CIDER available as apython package: https://pypi.org/project/ciderpolarity/.</description><author>James C. Young, Rudy Arthur, Hywel T. P. Williams</author><pubDate>Thu, 12 Oct 2023 17:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07864v2</guid></item><item><title>Towards Robust Multi-Modal Reasoning via Model Selection</title><link>http://arxiv.org/abs/2310.08446v1</link><description>The reasoning capabilities of LLM (Large Language Model) are widelyacknowledged in recent research, inspiring studies on tool learning andautonomous agents. LLM serves as the "brain" of agent, orchestrating multipletools for collaborative multi-step task solving. Unlike methods invoking toolslike calculators or weather APIs for straightforward tasks, multi-modal agentsexcel by integrating diverse AI models for complex challenges. However, currentmulti-modal agents neglect the significance of model selection: they primarilyfocus on the planning and execution phases, and will only invoke predefinedtask-specific models for each subtask, making the execution fragile. Meanwhile,other traditional model selection methods are either incompatible with orsuboptimal for the multi-modal agent scenarios, due to ignorance ofdependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges therein and propose the$\textit{M}^3$ framework as a plug-in with negligible runtime overhead attest-time. This framework improves model selection and bolsters the robustnessof multi-modal agents in multi-step reasoning. In the absence of suitablebenchmarks, we create MS-GQA, a new dataset specifically designed toinvestigate the model selection challenge in multi-modal agents. Ourexperiments reveal that our framework enables dynamic model selection,considering both user inputs and subtask dependencies, thereby robustifying theoverall reasoning process. Our code and benchmark:https://github.com/LINs-lab/M3.</description><author>Xiangyan Liu, Rongxue Li, Wei Ji, Tao Lin</author><pubDate>Thu, 12 Oct 2023 17:06:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08446v1</guid></item><item><title>Debias the Training of Diffusion Models</title><link>http://arxiv.org/abs/2310.08442v1</link><description>Diffusion models have demonstrated compelling generation quality byoptimizing the variational lower bound through a simple denoising scorematching loss. In this paper, we provide theoretical evidence that theprevailing practice of using a constant loss weight strategy in diffusionmodels leads to biased estimation during the training phase. Simply optimizingthe denoising network to predict Gaussian noise with constant weighting mayhinder precise estimations of original images. To address the issue, we proposean elegant and effective weighting strategy grounded in the theoreticallyunbiased principle. Moreover, we conduct a comprehensive and systematicexploration to dissect the inherent bias problem deriving from constantweighting loss from the perspectives of its existence, impact and reasons.These analyses are expected to advance our understanding and demystify theinner workings of diffusion models. Through empirical evaluation, wedemonstrate that our proposed debiased estimation method significantly enhancessample quality without the reliance on complex techniques, and exhibitsimproved efficiency compared to the baseline method both in training andsampling processes.</description><author>Hu Yu, Li Shen, Jie Huang, Man Zhou, Hongsheng Li, Feng Zhao</author><pubDate>Thu, 12 Oct 2023 17:04:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08442v1</guid></item><item><title>Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2308.16198v2</link><description>In modern communication systems, efficient and reliable informationdissemination is crucial for supporting critical operations across domains likedisaster response, autonomous vehicles, and sensor networks. This paperintroduces a Multi-Agent Reinforcement Learning (MARL) approach as asignificant step forward in achieving more decentralized, efficient, andcollaborative solutions. We propose a Partially Observable Stochastic Game(POSG) formulation for information dissemination empowering each agent todecide on message forwarding independently, based on their one-hopneighborhood. This constitutes a significant paradigm shift from traditionalheuristics based on Multi-Point Relay (MPR) selection. Our approach harnessesGraph Convolutional Reinforcement Learning, employing Graph Attention Networks(GAT) with dynamic attention to capture essential network features. We proposetwo approaches, L-DGN and HL-DGN, which differ in the information that isexchanged among agents. We evaluate the performance of our decentralizedapproaches, by comparing them with a widely-used MPR heuristic, and we showthat our trained policies are able to efficiently cover the network whilebypassing the MPR set selection process. Our approach is a first step towardsupporting the resilience of real-world broadcast communication infrastructuresvia learned, collaborative information dissemination.</description><author>Raffaele Galliera, Kristen Brent Venable, Matteo Bassani, Niranjan Suri</author><pubDate>Thu, 12 Oct 2023 16:57:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.16198v2</guid></item><item><title>Effective Slogan Generation with Noise Perturbation</title><link>http://arxiv.org/abs/2310.04472v2</link><description>Slogans play a crucial role in building the brand's identity of the firm. Aslogan is expected to reflect firm's vision and brand's value propositions inmemorable and likeable ways. Automating the generation of slogans with suchcharacteristics is challenging. Previous studies developted and tested slogangeneration with syntactic control and summarization models which are notcapable of generating distinctive slogans. We introduce a a novel apporach thatleverages pre-trained transformer T5 model with noise perturbation on newlyproposed 1:N matching pair dataset. This approach serves as a contributingfator in generting distinctive and coherent slogans. Turthermore, the proposedapproach incorporates descriptions about the firm and brand into the generationof slogans. We evaluate generated slogans based on ROUGE1, ROUGEL and CosineSimilarity metrics and also assess them with human subjects in terms ofslogan's distinctiveness, coherence, and fluency. The results demonstrate thatour approach yields better performance than baseline models and othertransformer-based models.</description><author>Jongeun Kim, MinChung Kim, Taehwan Kim</author><pubDate>Thu, 12 Oct 2023 16:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04472v2</guid></item><item><title>A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing</title><link>http://arxiv.org/abs/2310.08433v1</link><description>We evaluate a range of recent LLMs on English creative writing, a challengingand complex task that requires imagination, coherence, and style. We use adifficult, open-ended scenario chosen to avoid training data reuse: an epicnarration of a single combat between Ignatius J. Reilly, the protagonist of thePulitzer Prize-winning novel A Confederacy of Dunces (1980), and a pterodactyl,a prehistoric flying reptile. We ask several LLMs and humans to write such astory and conduct a human evalution involving various criteria such as fluency,coherence, originality, humor, and style. Our results show that somestate-of-the-art commercial LLMs match or slightly outperform our writers inmost dimensions; whereas open-source LLMs lag behind. Humans retain an edge increativity, while humor shows a binary divide between LLMs that can handle itcomparably to humans and those that fail at it. We discuss the implications andlimitations of our study and suggest directions for future research.</description><author>Carlos Gómez-Rodríguez, Paul Williams</author><pubDate>Thu, 12 Oct 2023 16:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08433v1</guid></item><item><title>Neural Sampling in Hierarchical Exponential-family Energy-based Models</title><link>http://arxiv.org/abs/2310.08431v1</link><description>Bayesian brain theory suggests that the brain employs generative models tounderstand the external world. The sampling-based perspective posits that thebrain infers the posterior distribution through samples of stochastic neuronalresponses. Additionally, the brain continually updates its generative model toapproach the true distribution of the external world. In this study, weintroduce the Hierarchical Exponential-family Energy-based (HEE) model, whichcaptures the dynamics of inference and learning. In the HEE model, we decomposethe partition function into individual layers and leverage a group of neuronswith shorter time constants to sample the gradient of the decomposednormalization term. This allows our model to estimate the partition functionand perform inference simultaneously, circumventing the negative phaseencountered in conventional energy-based models (EBMs). As a result, thelearning process is localized both in time and space, and the model is easy toconverge. To match the brain's rapid computation, we demonstrate that neuraladaptation can serve as a momentum term, significantly accelerating theinference process. On natural image datasets, our model exhibitsrepresentations akin to those observed in the biological visual system.Furthermore, for the machine learning community, our model can generateobservations through joint or marginal generation. We show that marginalgeneration outperforms joint generation and achieves performance on par withother EBMs.</description><author>Xingsi Dong, Si Wu</author><pubDate>Thu, 12 Oct 2023 16:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08431v1</guid></item><item><title>QKSAN: A Quantum Kernel Self-Attention Network</title><link>http://arxiv.org/abs/2308.13422v2</link><description>Self-Attention Mechanism (SAM) excels at distilling important informationfrom the interior of data to improve the computational efficiency of models.Nevertheless, many Quantum Machine Learning (QML) models lack the ability todistinguish the intrinsic connections of information like SAM, which limitstheir effectiveness on massive high-dimensional quantum data. To tackle theabove issue, a Quantum Kernel Self-Attention Mechanism (QKSAM) is introduced tocombine the data representation merit of Quantum Kernel Methods (QKM) with theefficient information extraction capability of SAM. Further, a Quantum KernelSelf-Attention Network (QKSAN) framework is proposed based on QKSAM, whichingeniously incorporates the Deferred Measurement Principle (DMP) andconditional measurement techniques to release half of quantum resources bymid-circuit measurement, thereby bolstering both feasibility and adaptability.Simultaneously, the Quantum Kernel Self-Attention Score (QKSAS) with anexponentially large characterization space is spawned to accommodate moreinformation and determine the measurement conditions. Eventually, four QKSANsub-models are deployed on PennyLane and IBM Qiskit platforms to perform binaryclassification on MNIST and Fashion MNIST, where the QKSAS tests andcorrelation assessments between noise immunity and learning ability areexecuted on the best-performing sub-model. The paramount experimental findingis that a potential learning advantage is revealed in partial QKSAN subclassesthat acquire an impressive more than 98.05% high accuracy with very fewparameters that are much less in aggregate than classical machine learningmodels. Predictably, QKSAN lays the foundation for future quantum computers toperform machine learning on massive amounts of data while driving advances inareas such as quantum computer vision.</description><author>Ren-Xin Zhao, Jinjing Shi, Xuelong Li</author><pubDate>Thu, 12 Oct 2023 16:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13422v2</guid></item><item><title>Assessing of Soil Erosion Risk Through Geoinformation Sciences and Remote Sensing -- A Review</title><link>http://arxiv.org/abs/2310.08430v1</link><description>During past decades a marked manifestation of widespread erosion phenomenawas studied worldwide. Global conservation community has launched campaigns atlocal, regional and continental level in developing countries for preservationof soil resources in order not only to stop or mitigate human impact on naturebut also to improve life in rural areas introducing new approaches for soilcultivation. After the adoption of Sustainable Development Goals of UNs andlaunching several world initiatives such as the Land Degradation Neutrality(LDN) the world came to realize the very importance of the soil resources onwhich the biosphere relies for its existence. The main goal of the chapter isto review different types and structures erosion models as well as theirapplications. Several methods using spatial analysis capabilities of geographicinformation systems (GIS) are in operation for soil erosion risk assessment,such as Universal Soil Loss Equation (USLE), Revised Universal Soil LossEquation (RUSLE) in operation worldwide and in the USA and MESALES model. Theseand more models are being discussed in the present work alongside moreexperimental models and methods for assessing soil erosion risk such asArtificial Intelligence (AI), Machine and Deep Learning, etc. At the end ofthis work, a prospectus for the future development of soil erosion riskassessment is drawn.</description><author>Lachezar Filchev, Vasil Kolev</author><pubDate>Thu, 12 Oct 2023 16:53:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08430v1</guid></item><item><title>Revisiting Data Augmentation for Rotational Invariance in Convolutional Neural Networks</title><link>http://arxiv.org/abs/2310.08429v1</link><description>Convolutional Neural Networks (CNN) offer state of the art performance invarious computer vision tasks. Many of those tasks require different subtypesof affine invariances (scale, rotational, translational) to imagetransformations. Convolutional layers are translation equivariant by design,but in their basic form lack invariances. In this work we investigate how bestto include rotational invariance in a CNN for image classification. Ourexperiments show that networks trained with data augmentation alone canclassify rotated images nearly as well as in the normal unrotated case; thisincrease in representational power comes only at the cost of training time. Wealso compare data augmentation versus two modified CNN models for achievingrotational invariance or equivariance, Spatial Transformer Networks and GroupEquivariant CNNs, finding no significant accuracy increase with thesespecialized methods. In the case of data augmented networks, we also analyzewhich layers help the network to encode the rotational invariance, which isimportant for understanding its limitations and how to best retrain a networkwith data augmentation to achieve invariance to rotation.</description><author>Facundo Manuel Quiroga, Franco Ronchetti, Laura Lanzarini, Aurelio Fernandez-Bariviera</author><pubDate>Thu, 12 Oct 2023 16:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08429v1</guid></item><item><title>Generative modeling of time-dependent densities via optimal transport and projection pursuit</title><link>http://arxiv.org/abs/2304.09663v2</link><description>Motivated by the computational difficulties incurred by popular deep learningalgorithms for the generative modeling of temporal densities, we propose acheap alternative which requires minimal hyperparameter tuning and scalesfavorably to high dimensional problems. In particular, we use aprojection-based optimal transport solver [Meng et al., 2019] to joinsuccessive samples and subsequently use transport splines [Chewi et al., 2020]to interpolate the evolving density. When the sampling frequency issufficiently high, the optimal maps are close to the identity and are thuscomputationally efficient to compute. Moreover, the training process is highlyparallelizable as all optimal maps are independent and can thus be learnedsimultaneously. Finally, the approach is based solely on numerical linearalgebra rather than minimizing a nonconvex objective function, allowing us toeasily analyze and control the algorithm. We present several numericalexperiments on both synthetic and real-world datasets to demonstrate theefficiency of our method. In particular, these experiments show that theproposed approach is highly competitive compared with state-of-the-artnormalizing flows conditioned on time across a wide range of dimensionalities.</description><author>Jonah Botvinick-Greenhouse, Yunan Yang, Romit Maulik</author><pubDate>Thu, 12 Oct 2023 16:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09663v2</guid></item><item><title>Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application</title><link>http://arxiv.org/abs/2310.08426v1</link><description>Multiple data views measured on the same set of participants is becoming morecommon and has the potential to deepen our understanding of many complexdiseases by analyzing these different views simultaneously. Equally important,many of these complex diseases show evidence of subgroup heterogeneity (e.g.,by sex or race). HIP (Heterogeneity in Integration and Prediction) is among thefirst methods proposed to integrate multiple data views while also accountingfor subgroup heterogeneity to identify common and subgroup-specific markers ofa particular disease. However, HIP is applicable to continuous outcomes andrequires programming expertise by the user. Here we propose extensions to HIPthat accommodate multi-class, Poisson, and Zero-Inflated Poisson outcomes whileretaining the benefits of HIP. Additionally, we introduce an R Shinyapplication, accessible on shinyapps.io athttps://multi-viewlearn.shinyapps.io/HIP_ShinyApp/, that provides an interfacewith the Python implementation of HIP to allow more researchers to use themethod anywhere and on any device. We applied HIP to identify genes andproteins common and specific to males and females that are associated withexacerbation frequency. Although some of the identified genes and proteins showevidence of a relationship with chronic obstructive pulmonary disease (COPD) inexisting literature, others may be candidates for future research investigatingtheir relationship with COPD. We demonstrate the use of the Shiny applicationwith a publicly available data. An R-package for HIP would be made available athttps://github.com/lasandrall/HIP.</description><author>J. Butts, C. Wendt, R. Bowler, C. P. Hersh, Q. Long, L. Eberly, S. E. Safo</author><pubDate>Thu, 12 Oct 2023 16:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08426v1</guid></item><item><title>Differentially Private Non-convex Learning for Multi-layer Neural Networks</title><link>http://arxiv.org/abs/2310.08425v1</link><description>This paper focuses on the problem of Differentially Private StochasticOptimization for (multi-layer) fully connected neural networks with a singleoutput node. In the first part, we examine cases with no hidden nodes,specifically focusing on Generalized Linear Models (GLMs). We investigate thewell-specific model where the random noise possesses a zero mean, and the linkfunction is both bounded and Lipschitz continuous. We propose severalalgorithms and our analysis demonstrates the feasibility of achieving an excesspopulation risk that remains invariant to the data dimension. We also delveinto the scenario involving the ReLU link function, and our findings mirrorthose of the bounded link function. We conclude this section by contrastingwell-specified and misspecified models, using ReLU regression as arepresentative example. In the second part of the paper, we extend our ideas to two-layer neuralnetworks with sigmoid or ReLU activation functions in the well-specified model.In the third part, we study the theoretical guarantees of DP-SGD in Abadi etal. (2016) for fully connected multi-layer neural networks. By utilizing recentadvances in Neural Tangent Kernel theory, we provide the first excesspopulation risk when both the sample size and the width of the network aresufficiently large. Additionally, we discuss the role of some parameters inDP-SGD regarding their utility, both theoretically and empirically.</description><author>Hanpu Shen, Cheng-Long Wang, Zihang Xiang, Yiming Ying, Di Wang</author><pubDate>Thu, 12 Oct 2023 16:48:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08425v1</guid></item><item><title>Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation</title><link>http://arxiv.org/abs/2211.12345v4</link><description>Larger and deeper networks generalise well despite their increased capacityto overfit. Understanding why this happens is theoretically and practicallyimportant. One recent approach looks at the infinitely wide limits of suchnetworks and their corresponding kernels. However, these theoretical toolscannot fully explain finite networks as the empirical kernel changessignificantly during gradient-descent-based training in contrast to infinitenetworks. In this work, we derive an iterative linearised training method as anovel empirical tool to further investigate this distinction, allowing us tocontrol for sparse (i.e. infrequent) feature updates and quantify the frequencyof feature learning needed to achieve comparable performance. We justifyiterative linearisation as an interpolation between a finite analog of theinfinite width regime, which does not learn features, and standard gradientdescent training, which does. Informally, we also show that it is analogous toa damped version of the Gauss-Newton algorithm -- a second-order method. Weshow that in a variety of cases, iterative linearised training surprisinglyperforms on par with standard training, noting in particular how much lessfrequent feature learning is required to achieve comparable performance. Wealso show that feature learning is essential for good performance. Since suchfeature learning inevitably causes changes in the NTK kernel, we provide directnegative evidence for the NTK theory, which states the NTK kernel remainsconstant during training.</description><author>Adrian Goldwaser, Hong Ge</author><pubDate>Thu, 12 Oct 2023 16:44:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.12345v4</guid></item><item><title>On Scale Space Radon Transform, Properties and Application in CT Image Reconstruction</title><link>http://arxiv.org/abs/2205.05188v3</link><description>Since the Radon transform (RT) consists in a line integral function, somemodeling assumptions are made on Computed Tomography (CT) system, making imagereconstruction analytical methods, such as Filtered Backprojection (FBP),sensitive to artifacts and noise. In the other hand, recently, a new integraltransform, called Scale Space Radon Transform (SSRT), is introduced where, RTis a particular case. Thanks to its interesting properties, such as good scalespace behavior, the SSRT has known number of new applications. In this paper,with the aim to improve the reconstructed image quality for these methods, wepropose to model the X-ray beam with the Scale Space Radon Transform (SSRT)where, the assumptions done on the physical dimensions of the CT systemelements reflect better the reality. After depicting the basic properties andthe inversion of SSRT, the FBP algorithm is used to reconstruct the image fromthe SSRT sinogram where the RT spectrum used in FBP is replaced by SSRT and theGaussian kernel, expressed in their frequency domain. PSNR and SSIM, as qualitymeasures, are used to compare RT and SSRT-based image reconstruction onShepp-Logan head and anthropomorphic abdominal phantoms. The first findingsshow that the SSRT-based method outperforms the methods based on RT,especially, when the number of projections is reduced, making it moreappropriate for applications requiring low-dose radiation, such as medicalX-ray CT. While SSRT-FBP and RT-FBP have utmost the same runtime, theexperiments show that SSRT-FBP is more robust to Poisson-Gaussian noisecorrupting CT data.</description><author>Nafaa Nacereddine, Djemel Ziou, Aicha Baya Goumeidane</author><pubDate>Thu, 12 Oct 2023 16:43:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.05188v3</guid></item><item><title>"SegLoc": Study on Novel Visual Self-supervised Learning Scheme (Segment Localization) Tailored for Dense Prediction Tasks of Security Inspection X-ray Images</title><link>http://arxiv.org/abs/2310.08421v1</link><description>Lately, remarkable advancements of artificial intelligence have beenattributed to the integration of self-supervised learning scheme. Despiteimpressive achievements within NLP, yet SSL in computer vision has not beenable to stay on track comparatively. Recently, integration of contrastivelearning on top of existing SSL models has established considerable progress incomputer vision through which visual SSL models have outperformed theirsupervised counterparts. Nevertheless, most of these improvements were limitedto classification tasks, and also, few works have been dedicated to evaluationof SSL models in real-world scenarios of computer vision, while the majority ofworks are centered around datasets containing class-wise portrait images, mostnotably, ImageNet. Consequently, in this work, we have considered denseprediction task of semantic segmentation in security inspection x-ray images toevaluate our proposed model Segmentation Localization. Based upon the modelInstance Localization, our model SegLoc has managed to address one of the mostchallenging downsides of contrastive learning, i.e., false negative pairs ofquery embeddings. In order to do so, in contrast to baseline model InsLoc, ourpretraining dataset is synthesized by cropping, transforming, then pastingalready labeled segments from an available labeled dataset, foregrounds, ontoinstances of an unlabeled dataset, backgrounds. In our case, PIDray and SIXraydatasets are considered as labeled and unlabeled datasets, respectively.Moreover, we fully harness labels by avoiding false negative pairs throughimplementing the idea, one queue per class, in MoCo-v2 whereby negative pairscorresponding to each query are extracted from its corresponding queue withinthe memory bank. Our approach has outperformed random initialization by 3% to6%, while having underperformed supervised initialization.</description><author>Shervin Halat, Mohammad Rahmati, Ehsan Nazerfard</author><pubDate>Thu, 12 Oct 2023 16:42:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08421v1</guid></item><item><title>Visual Attention-Prompted Prediction and Learning</title><link>http://arxiv.org/abs/2310.08420v1</link><description>Explanation(attention)-guided learning is a method that enhances a model'spredictive power by incorporating human understanding during the trainingphase. While attention-guided learning has shown promising results, it ofteninvolves time-consuming and computationally expensive model retraining. Toaddress this issue, we introduce the attention-prompted prediction technique,which enables direct prediction guided by the attention prompt without the needfor model retraining. However, this approach presents several challenges,including: 1) How to incorporate the visual attention prompt into the model'sdecision-making process and leverage it for future predictions even in theabsence of a prompt? and 2) How to handle the incomplete information from thevisual attention prompt? To tackle these challenges, we propose a novelframework called Visual Attention-Prompted Prediction and Learning, whichseamlessly integrates visual attention prompts into the model's decision-makingprocess and adapts to images both with and without attention prompts forprediction. To address the incomplete information of the visual attentionprompt, we introduce a perturbation-based attention map modification method.Additionally, we propose an optimization-based mask aggregation method with anew weight learning function for adaptive perturbed annotation aggregation inthe attention map modification process. Our overall framework is designed tolearn in an attention-prompt guided multi-task manner to enhance futurepredictions even for samples without attention prompts and trained in analternating manner for better convergence. Extensive experiments conducted ontwo datasets demonstrate the effectiveness of our proposed framework inenhancing predictions for samples, both with and without provided prompts.</description><author>Yifei Zhang, Siyi Gu, Bo Pan, Guangji Bai, Xiaofeng Yang, Liang Zhao</author><pubDate>Thu, 12 Oct 2023 16:39:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08420v1</guid></item><item><title>Jailbreaking Black Box Large Language Models in Twenty Queries</title><link>http://arxiv.org/abs/2310.08419v1</link><description>There is growing interest in ensuring that large language models (LLMs) alignwith human values. However, the alignment of such models is vulnerable toadversarial jailbreaks, which coax LLMs into overriding their safetyguardrails. The identification of these vulnerabilities is thereforeinstrumental in understanding inherent weaknesses and preventing future misuse.To this end, we propose Prompt Automatic Iterative Refinement (PAIR), analgorithm that generates semantic jailbreaks with only black-box access to anLLM. PAIR -- which is inspired by social engineering attacks -- uses anattacker LLM to automatically generate jailbreaks for a separate targeted LLMwithout human intervention. In this way, the attacker LLM iteratively queriesthe target LLM to update and refine a candidate jailbreak. Empirically, PAIRoften requires fewer than twenty queries to produce a jailbreak, which isorders of magnitude more efficient than existing algorithms. PAIR also achievescompetitive jailbreaking success rates and transferability on open andclosed-source LLMs, including GPT-3.5/4, Vicuna, and PaLM-2.</description><author>Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, Eric Wong</author><pubDate>Thu, 12 Oct 2023 16:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08419v1</guid></item><item><title>Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?</title><link>http://arxiv.org/abs/2302.11713v4</link><description>Pre-trained vision and language models have demonstrated state-of-the-artcapabilities over existing tasks involving images and texts, including visualquestion answering. However, it remains unclear whether these models possessthe capability to answer questions that are not only querying visual contentbut knowledge-intensive and information-seeking. In this study, we introduceInfoSeek, a visual question answering dataset tailored for information-seekingquestions that cannot be answered with only common sense knowledge. UsingInfoSeek, we analyze various pre-trained visual question answering models andgain insights into their characteristics. Our findings reveal thatstate-of-the-art pre-trained multi-modal models (e.g., PaLI-X, BLIP2, etc.)face challenges in answering visual information-seeking questions, butfine-tuning on the InfoSeek dataset elicits models to use fine-grainedknowledge that was learned during their pre-training. Furthermore, we show thataccurate visual entity recognition can be used to improve performance onInfoSeek by retrieving relevant documents, showing a significant space forimprovement.</description><author>Yang Chen, Hexiang Hu, Yi Luan, Haitian Sun, Soravit Changpinyo, Alan Ritter, Ming-Wei Chang</author><pubDate>Thu, 12 Oct 2023 16:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11713v4</guid></item><item><title>Evaluation of ChatGPT-Generated Medical Responses: A Systematic Review and Meta-Analysis</title><link>http://arxiv.org/abs/2310.08410v1</link><description>Large language models such as ChatGPT are increasingly explored in medicaldomains. However, the absence of standard guidelines for performance evaluationhas led to methodological inconsistencies. This study aims to summarize theavailable evidence on evaluating ChatGPT's performance in medicine and providedirection for future research. We searched ten medical literature databases onJune 15, 2023, using the keyword "ChatGPT". A total of 3520 articles wereidentified, of which 60 were reviewed and summarized in this paper and 17 wereincluded in the meta-analysis. The analysis showed that ChatGPT displayed anoverall integrated accuracy of 56% (95% CI: 51%-60%, I2 = 87%) in addressingmedical queries. However, the studies varied in question resource,question-asking process, and evaluation metrics. Moreover, many studies failedto report methodological details, including the version of ChatGPT and whethereach question was used independently or repeatedly. Our findings revealed thatalthough ChatGPT demonstrated considerable potential for application inhealthcare, the heterogeneity of the studies and insufficient reporting mayaffect the reliability of these results. Further well-designed studies withcomprehensive and transparent reporting are needed to evaluate ChatGPT'sperformance in medicine.</description><author>Qiuhong Wei, Zhengxiong Yao, Ying Cui, Bo Wei, Zhezhen Jin, Ximing Xu</author><pubDate>Thu, 12 Oct 2023 16:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08410v1</guid></item><item><title>Data-Centric Learning from Unlabeled Graphs with Diffusion Model</title><link>http://arxiv.org/abs/2303.10108v2</link><description>Graph property prediction tasks are important and numerous. While each taskoffers a small size of labeled examples, unlabeled graphs have been collectedfrom various sources and at a large scale. A conventional approach is traininga model with the unlabeled graphs on self-supervised tasks and then fine-tuningthe model on the prediction tasks. However, the self-supervised task knowledgecould not be aligned or sometimes conflicted with what the predictions needed.In this paper, we propose to extract the knowledge underlying the large set ofunlabeled graphs as a specific set of useful data points to augment eachproperty prediction model. We use a diffusion model to fully utilize theunlabeled graphs and design two new objectives to guide the model's denoisingprocess with each task's labeled data to generate task-specific graph examplesand their labels. Experiments demonstrate that our data-centric approachperforms significantly better than fifteen existing various methods on fifteentasks. The performance improvement brought by unlabeled data is visible as thegenerated labeled examples unlike the self-supervised learning.</description><author>Gang Liu, Eric Inae, Tong Zhao, Jiaxin Xu, Tengfei Luo, Meng Jiang</author><pubDate>Thu, 12 Oct 2023 16:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10108v2</guid></item><item><title>Tightening Bounds on Probabilities of Causation By Merging Datasets</title><link>http://arxiv.org/abs/2310.08406v1</link><description>Probabilities of Causation (PoC) play a fundamental role in decision-makingin law, health care and public policy. Nevertheless, their point identificationis challenging, requiring strong assumptions, in the absence of which onlybounds can be derived. Existing work to further tighten these bounds byleveraging extra information either provides numerical bounds, symbolic boundsfor fixed dimensionality, or requires access to multiple datasets that containthe same treatment and outcome variables. However, in many clinical,epidemiological and public policy applications, there exist external datasetsthat examine the effect of different treatments on the same outcome variable,or study the association between covariates and the outcome variable. Theseexternal datasets cannot be used in conjunction with the aforementioned bounds,since the former may entail different treatment assignment mechanisms, or evenobey different causal structures. Here, we provide symbolic bounds on the PoCfor this challenging scenario. We focus on combining either two randomizedexperiments studying different treatments, or a randomized experiment and anobservational study, assuming causal sufficiency. Our symbolic bounds work forarbitrary dimensionality of covariates and treatment, and we discuss theconditions under which these bounds are tighter than existing bounds inliterature. Finally, our bounds parameterize the difference in treatmentassignment mechanism across datasets, allowing the mechanisms to vary acrossdatasets while still allowing causal information to be transferred from theexternal dataset to the target dataset.</description><author>Numair Sani, Atalanti A. Mastakouri</author><pubDate>Thu, 12 Oct 2023 16:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08406v1</guid></item><item><title>Performance/power assessment of CNN packages on embedded automotive platforms</title><link>http://arxiv.org/abs/2310.08401v1</link><description>The rise of power-efficient embedded computers based on highly-parallelaccelerators opens a number of opportunities and challenges for researchers andengineers, and paved the way to the era of edge computing. At the same time,advances in embedded AI for object detection and categorization such as YOLO,GoogleNet and AlexNet reached an unprecedented level of accuracy (mean-AveragePrecision - mAP) and performance (Frames-Per-Second - FPS). Today, edgecomputers based on heterogeneous many-core systems are a predominant choice todeploy such systems in industry 4.0, wearable devices, and - our focus -autonomous driving systems. In these latter systems, engineers struggle to makereduced automotive power and size budgets co-exist with the accuracy andperformance targets requested by autonomous driving. We aim at validating theeffectiveness and efficiency of most recent networks on state-of-the-artplatforms with embedded commercial-off-the-shelf System-on-Chips, such asXavier AGX, Tegra X2 and Nano for NVIDIA and XCZU9EG and XCZU3EG of the ZynqUltraScale+ family, for the Xilinx counterpart. Our work aims at supportingengineers in choosing the most appropriate CNN package and computing system fortheir designs, and deriving guidelines for adequately sizing their systems.</description><author>Paolo Burgio, Gianluca Brilli</author><pubDate>Thu, 12 Oct 2023 16:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08401v1</guid></item><item><title>Towards Design and Development of an ArUco Markers-Based Quantitative Surface Tactile Sensor</title><link>http://arxiv.org/abs/2310.08398v1</link><description>In this paper, with the goal of quantifying the qualitative image outputs ofa Vision-based Tactile Sensor (VTS), we present the design, fabrication, andcharacterization of a novel Quantitative Surface Tactile Sensor (called QS-TS).QS-TS directly estimates the sensor's gel layer deformation in real-timeenabling safe and autonomous tactile manipulation and servoing of delicateobjects using robotic manipulators. The core of the proposed sensor is theutilization of miniature 1.5 mm x 1.5 mm synthetic square markers with innerbinary patterns and a broad black border, called ArUco Markers. Each ArUcomarker can provide real-time camera pose estimation that, in our design, isused as a quantitative measure for obtaining deformation of the QS-TS gellayer. Moreover, thanks to the use of ArUco markers, we propose a uniquefabrication procedure that mitigates various challenges associated with thefabrication of the existing marker-based VTSs and offers an intuitive andless-arduous method for the construction of the VTS. Remarkably, the proposedfabrication facilitates the integration and adherence of markers with the gellayer to robustly and reliably obtain a quantitative measure of deformation inreal-time regardless of the orientation of ArUco Markers. The performance andefficacy of the proposed QS-TS in estimating the deformation of the sensor'sgel layer were experimentally evaluated and verified. Results demonstrate thephenomenal performance of the QS-TS in estimating the deformation of the gellayer with a relative error of &lt;5%.</description><author>Ozdemir Can Kara, Charles Everson, Farshid Alambeigi</author><pubDate>Thu, 12 Oct 2023 16:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08398v1</guid></item><item><title>Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation</title><link>http://arxiv.org/abs/2310.08395v1</link><description>The task of Question Generation over Knowledge Bases (KBQG) aims to convert alogical form into a natural language question. For the sake of expensive costof large-scale question annotation, the methods of KBQG under low-resourcescenarios urgently need to be developed. However, current methods heavily relyon annotated data for fine-tuning, which is not well-suited for few-shotquestion generation. The emergence of Large Language Models (LLMs) has showntheir impressive generalization ability in few-shot tasks. Inspired byChain-of-Thought (CoT) prompting, which is an in-context learning strategy forreasoning, we formulate KBQG task as a reasoning problem, where the generationof a complete question is splitted into a series of sub-question generation.Our proposed prompting method KQG-CoT first retrieves supportive logical formsfrom the unlabeled data pool taking account of the characteristics of thelogical form. Then, we write a prompt to explicit the reasoning chain ofgenerating complicated questions based on the selected demonstrations. Tofurther ensure prompt quality, we extend KQG-CoT into KQG-CoT+ via sorting thelogical forms by their complexity. We conduct extensive experiments over threepublic KBQG datasets. The results demonstrate that our prompting methodconsistently outperforms other prompting baselines on the evaluated datasets.Remarkably, our KQG-CoT+ method could surpass existing few-shot SoTA results ofthe PathQuestions dataset by 18.25, 10.72, and 10.18 absolute points on BLEU-4,METEOR, and ROUGE-L, respectively.</description><author>Yuanyuan Liang, Jianing Wang, Hanlun Zhu, Lei Wang, Weining Qian, Yunshi Lan</author><pubDate>Thu, 12 Oct 2023 16:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08395v1</guid></item><item><title>Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization</title><link>http://arxiv.org/abs/2310.08394v1</link><description>Despite recent advances, evaluating how well large language models (LLMs)follow user instructions remains an open problem. While evaluation methods oflanguage models have seen a rise in prompt-based approaches, limited work onthe correctness of these methods has been conducted. In this work, we perform ameta-evaluation of a variety of metrics to quantify how accurately they measurethe instruction-following abilities of LLMs. Our investigation is performed ongrounded query-based summarization by collecting a new short-form, real-worlddataset riSum, containing $300$ document-instruction pairs with $3$ answerseach. All $900$ answers are rated by $3$ human annotators. Using riSum, weanalyze agreement between evaluation methods and human judgment. Finally, wepropose new LLM-based reference-free evaluation methods that improve uponestablished baselines and perform on-par with costly reference-based metricswhich require high-quality summaries.</description><author>Ondrej Skopek, Rahul Aralikatte, Sian Gooding, Victor Carbune</author><pubDate>Thu, 12 Oct 2023 16:07:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08394v1</guid></item><item><title>Multi-Objective Optimization for Sparse Deep Neural Network Training</title><link>http://arxiv.org/abs/2308.12243v2</link><description>Different conflicting optimization criteria arise naturally in various DeepLearning scenarios. These can address different main tasks (i.e., in thesetting of Multi-Task Learning), but also main and secondary tasks such as lossminimization versus sparsity. The usual approach is a simple weighting of thecriteria, which formally only works in the convex setting. In this paper, wepresent a Multi-Objective Optimization algorithm using a modified WeightedChebyshev scalarization for training Deep Neural Networks (DNNs) with respectto several tasks. By employing this scalarization technique, the algorithm canidentify all optimal solutions of the original problem while reducing itscomplexity to a sequence of single-objective problems. The simplified problemsare then solved using an Augmented Lagrangian method, enabling the use ofpopular optimization techniques such as Adam and Stochastic Gradient Descent,while efficaciously handling constraints. Our work aims to address the(economical and also ecological) sustainability issue of DNN models, with aparticular focus on Deep Multi-Task models, which are typically designed with avery large number of weights to perform equally well on multiple tasks. Throughexperiments conducted on two Machine Learning datasets, we demonstrate thepossibility of adaptively sparsifying the model during training withoutsignificantly impacting its performance, if we are willing to applytask-specific adaptations to the network weights. Code is available athttps://github.com/salomonhotegni/MDMTN.</description><author>S. S. Hotegni, S. Peitz, M. Berkemeier</author><pubDate>Thu, 12 Oct 2023 16:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12243v2</guid></item><item><title>High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation</title><link>http://arxiv.org/abs/2304.02621v2</link><description>Image-level weakly-supervised semantic segmentation (WSSS) reduces theusually vast data annotation cost by surrogate segmentation masks duringtraining. The typical approach involves training an image classificationnetwork using global average pooling (GAP) on convolutional feature maps. Thisenables the estimation of object locations based on class activation maps(CAMs), which identify the importance of image regions. The CAMs are then usedto generate pseudo-labels, in the form of segmentation masks, to supervise asegmentation model in the absence of pixel-level ground truth. Our work isbased on two techniques for improving CAMs; importance sampling, which is asubstitute for GAP, and the feature similarity loss, which utilizes a heuristicthat object contours almost always align with color edges in images. However,both are based on the multinomial posterior with softmax, and implicitly assumethat classes are mutually exclusive, which turns out suboptimal in ourexperiments. Thus, we reformulate both techniques based on binomial posteriorsof multiple independent binary problems. This has two benefits; theirperformance is improved and they become more general, resulting in an add-onmethod that can boost virtually any WSSS method. This is demonstrated on a widevariety of baselines on the PASCAL VOC dataset, improving the region similarityand contour quality of all implemented state-of-the-art methods. Experiments onthe MS COCO dataset show that our proposed add-on is well-suited forlarge-scale settings. Our code is available at https://github.com/arvijj/hfpl.</description><author>Arvi Jonnarth, Yushan Zhang, Michael Felsberg</author><pubDate>Thu, 12 Oct 2023 16:05:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02621v2</guid></item><item><title>Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation</title><link>http://arxiv.org/abs/2309.04946v2</link><description>Audio-driven talking-head synthesis is a popular research topic for virtualhuman-related applications. However, the inflexibility and inefficiency ofexisting methods, which necessitate expensive end-to-end training to transferemotions from guidance videos to talking-head predictions, are significantlimitations. In this work, we propose the Emotional Adaptation for Audio-drivenTalking-head (EAT) method, which transforms emotion-agnostic talking-headmodels into emotion-controllable ones in a cost-effective and efficient mannerthrough parameter-efficient adaptations. Our approach utilizes a pretrainedemotion-agnostic talking-head transformer and introduces three lightweightadaptations (the Deep Emotional Prompts, Emotional Deformation Network, andEmotional Adaptation Module) from different perspectives to enable precise andrealistic emotion controls. Our experiments demonstrate that our approachachieves state-of-the-art performance on widely-used benchmarks, including LRWand MEAD. Additionally, our parameter-efficient adaptations exhibit remarkablegeneralization ability, even in scenarios where emotional training videos arescarce or nonexistent. Project website: https://yuangan.github.io/eat/</description><author>Yuan Gan, Zongxin Yang, Xihang Yue, Lingyun Sun, Yi Yang</author><pubDate>Thu, 12 Oct 2023 16:04:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04946v2</guid></item><item><title>Introducing a Deep Neural Network-based Model Predictive Control Framework for Rapid Controller Implementation</title><link>http://arxiv.org/abs/2310.08392v1</link><description>Model Predictive Control (MPC) provides an optimal control solution based ona cost function while allowing for the implementation of process constraints.As a model-based optimal control technique, the performance of MPC stronglydepends on the model used where a trade-off between model computation time andprediction performance exists. One solution is the integration of MPC with amachine learning (ML) based process model which are quick to evaluate online.This work presents the experimental implementation of a deep neural network(DNN) based nonlinear MPC for Homogeneous Charge Compression Ignition (HCCI)combustion control. The DNN model consists of a Long Short-Term Memory (LSTM)network surrounded by fully connected layers which was trained usingexperimental engine data and showed acceptable prediction performance withunder 5% error for all outputs. Using this model, the MPC is designed to trackthe Indicated Mean Effective Pressure (IMEP) and combustion phasingtrajectories, while minimizing several parameters. Using the acados softwarepackage to enable the real-time implementation of the MPC on an ARM Cortex A72,the optimization calculations are completed within 1.4 ms. The external A72processor is integrated with the prototyping engine controller using a UDPconnection allowing for rapid experimental deployment of the NMPC. The IMEPtrajectory following of the developed controller was excellent, with aroot-mean-square error of 0.133 bar, in addition to observing processconstraints.</description><author>David C. Gordon, Alexander Winkler, Julian Bedei, Patrick Schaber, Jakob Andert, Charles R. Koch</author><pubDate>Thu, 12 Oct 2023 16:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08392v1</guid></item><item><title>How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?</title><link>http://arxiv.org/abs/2310.08391v1</link><description>Transformers pretrained on diverse tasks exhibit remarkable in-contextlearning (ICL) capabilities, enabling them to solve unseen tasks solely basedon input contexts without adjusting model parameters. In this paper, we studyICL in one of its simplest setups: pretraining a linearly parameterizedsingle-layer linear attention model for linear regression with a Gaussianprior. We establish a statistical task complexity bound for the attention modelpretraining, showing that effective pretraining only requires a small number ofindependent tasks. Furthermore, we prove that the pretrained model closelymatches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, byachieving nearly Bayes optimal risk on unseen tasks under a fixed contextlength. These theoretical findings complement prior experimental research andshed light on the statistical foundations of ICL.</description><author>Jingfeng Wu, Difan Zou, Zixiang Chen, Vladimir Braverman, Quanquan Gu, Peter L. Bartlett</author><pubDate>Thu, 12 Oct 2023 16:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08391v1</guid></item></channel></rss>