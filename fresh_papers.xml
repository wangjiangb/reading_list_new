<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 18 Aug 2025 19:15:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Thyme: Think Beyond Images</title><link>http://arxiv.org/abs/2508.11630v1</link><description>Following OpenAI's introduction of the ``thinking with images'' concept,recent efforts have explored stimulating the use of visual information in thereasoning process to enhance model performance in perception and reasoningtasks. However, to the best of our knowledge, no open-source work currentlyoffers a feature set as rich as proprietary models (O3), which can performdiverse image manipulations and simultaneously enhance logical reasoningcapabilities through code. In this paper, we make a preliminary attempt in thisdirection by introducing Thyme (Think Beyond Images), a novel paradigm forenabling MLLMs to transcend existing ``think with images'' approaches byautonomously generating and executing diverse image processing andcomputational operations via executable code. This approach not onlyfacilitates a rich, on-the-fly set of image manipulations (e.g., cropping,rotation, contrast enhancement) but also allows for mathematical computations,all while maintaining high autonomy in deciding when and how to apply theseoperations. We activate this capability through a two-stage training strategy:an initial SFT on a curated dataset of 500K samples to teach code generation,followed by a RL phase to refine decision-making. For the RL stage, we manuallycollect and design high-resolution question-answer pairs to increase thelearning difficulty, and we propose GRPO-ATS (Group Relative PolicyOptimization with Adaptive Temperature Sampling), an algorithm that appliesdistinct temperatures to text and code generation to balance reasoningexploration with code execution precision. We conduct extensive experimentalanalysis and ablation studies. Comprehensive evaluations on nearly 20benchmarks show that Thyme yields significant and consistent performance gains,particularly in challenging high-resolution perception and complex reasoningtasks.</description><author>Yi-Fan Zhang, Xingyu Lu, Shukang Yin, Chaoyou Fu, Wei Chen, Xiao Hu, Bin Wen, Kaiyu Jiang, Changyi Liu, Tianke Zhang, Haonan Fan, Kaibing Chen, Jiankang Chen, Haojie Ding, Kaiyu Tang, Zhang Zhang, Liang Wang, Fan Yang, Tingting Gao, Guorui Zhou</author><pubDate>Fri, 15 Aug 2025 17:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11630v1</guid></item><item><title>Diffusion Beats Autoregressive in Data-Constrained Settings</title><link>http://arxiv.org/abs/2507.15857v6</link><description>Autoregressive (AR) models have long dominated the landscape of largelanguage models, driving progress across a wide range of tasks. Recently,diffusion-based language models have emerged as a promising alternative, thoughtheir advantages over AR models remain underexplored. In this paper, wesystematically study masked diffusion models in data-constrained settings-wheretraining involves repeated passes over limited data and find that theysignificantly outperform AR models when compute is abundant but data is scarce.Diffusion models make better use of repeated data, achieving lower validationloss and superior downstream performance. We find new scaling laws fordiffusion models and derive a closed-form expression for the critical computethreshold at which diffusion begins to outperform AR. Finally, we explain whydiffusion models excel in this regime: their randomized masking objectiveimplicitly trains over a rich distribution of token orderings, acting as animplicit data augmentation that AR's fixed left-to-right factorization lacks.Our results suggest that when data, not compute, is the bottleneck, diffusionmodels offer a compelling alternative to the standard AR paradigm. Our code isavailable at: https://diffusion-scaling.github.io.</description><author>Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak</author><pubDate>Fri, 15 Aug 2025 17:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15857v6</guid></item><item><title>Is ChatGPT-5 Ready for Mammogram VQA?</title><link>http://arxiv.org/abs/2508.11628v1</link><description>Mammogram visual question answering (VQA) integrates image interpretationwith clinical reasoning and has potential to support breast cancer screening.We systematically evaluated the GPT-5 family and GPT-4o model on four publicmammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,abnormality detection, and malignancy classification tasks. GPT-5 consistentlywas the best performing model but lagged behind both human experts anddomain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scoresamong GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),calcification (63.5%), and malignancy (52.8%) classification. On InBreast, itattained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detectionand 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADSaccuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Comparedwith human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) andspecificity (52.3%). While GPT-5 exhibits promising capabilities for screeningtasks, its performance remains insufficient for high-stakes clinical imagingapplications without targeted domain adaptation and optimization. However, thetremendous improvements in performance from GPT-4o to GPT-5 show a promisingtrend in the potential for general large language models (LLMs) to assist withmammography VQA tasks.</description><author>Qiang Li, Shansong Wang, Mingzhe Hu, Mojtaba Safari, Zachary Eidex, Xiaofeng Yang</author><pubDate>Fri, 15 Aug 2025 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11628v1</guid></item><item><title>LoRAtorio: An intrinsic approach to LoRA Skill Composition</title><link>http://arxiv.org/abs/2508.11624v1</link><description>Low-Rank Adaptation (LoRA) has become a widely adopted technique intext-to-image diffusion models, enabling the personalisation of visual conceptssuch as characters, styles, and objects. However, existing approaches struggleto effectively compose multiple LoRA adapters, particularly in open-endedsettings where the number and nature of required skills are not known inadvance. In this work, we present LoRAtorio, a novel train-free framework formulti-LoRA composition that leverages intrinsic model behaviour. Our method ismotivated by two key observations: (1) LoRA adapters trained on narrow domainsproduce denoised outputs that diverge from the base model, and (2) whenoperating out-of-distribution, LoRA outputs show behaviour closer to the basemodel than when conditioned in distribution. The balance between these twoobservations allows for exceptional performance in the single LoRA scenario,which nevertheless deteriorates when multiple LoRAs are loaded. Our methodoperates in the latent space by dividing it into spatial patches and computingcosine similarity between each patch's predicted noise and that of the basemodel. These similarities are used to construct a spatially-aware weightmatrix, which guides a weighted aggregation of LoRA outputs. To address domaindrift, we further propose a modification to classifier-free guidance thatincorporates the base model's unconditional score into the composition. Weextend this formulation to a dynamic module selection setting, enablinginference-time selection of relevant LoRA adapters from a large pool. LoRAtorioachieves state-of-the-art performance, showing up to a 1.3% improvement inClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generaliseseffectively to multiple latent diffusion models.</description><author>Niki Foteinopoulou, Ignas Budvytis, Stephan Liwicki</author><pubDate>Fri, 15 Aug 2025 17:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11624v1</guid></item><item><title>Data Diversity as Implicit Regularization: How Does Diversity Shape the Weight Space of Deep Neural Networks?</title><link>http://arxiv.org/abs/2410.14602v2</link><description>Data augmentation that introduces diversity into the input data has long beenused in training deep learning models. It has demonstrated benefits inimproving robustness and generalization, practically aligning well with otherregularization strategies such as dropout and weight decay. However, theunderlying mechanism of how diverse training data contributes to modelimprovements remains unknown. In this paper, we investigate the impact of datadiversity on the weight space of deep neural networks using Random MatrixTheory. Through spectral analysis and comparing models trained with dataaugmentation, dropout, and weight decay, we reveal that increasing datadiversity alters the weight spectral distribution similarly to otherregularization techniques, while displaying a pattern more closely aligned withdropout than with weight decay. Building on these insights, we propose a metricto explain and compare the benefits of diversity introduced by traditional dataaugmentations and those achieved through synthetic data.</description><author>Yang Ba, Michelle V. Mancenido, Rong Pan</author><pubDate>Fri, 15 Aug 2025 17:36:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14602v2</guid></item><item><title>Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective</title><link>http://arxiv.org/abs/2508.11618v1</link><description>Carbon capture and storage (CCS) projects typically involve a diverse arrayof stakeholders or players from public, private, and regulatory sectors, eachwith different objectives and responsibilities. Given the complexity, scale,and long-term nature of CCS operations, determining whether individualstakeholders can independently maximize their interests or whethercollaborative coalition agreements are needed remains a central question foreffective CCS project planning and management. CCS projects are oftenimplemented in geologically connected sites, where shared geological featuressuch as pressure space and reservoir pore capacity can lead to competitivebehavior among stakeholders. Furthermore, CO2 storage sites are often locatedin geologically mature basins that previously served as sites for hydrocarbonextraction or wastewater disposal in order to leverage existinginfrastructures, which makes unilateral optimization even more complicated andunrealistic. In this work, we propose a paradigm based on Markov games to quantitativelyinvestigate how different coalition structures affect the goals ofstakeholders. We frame this multi-stakeholder multi-site problem as amulti-agent reinforcement learning problem with safety constraints. Ourapproach enables agents to learn optimal strategies while compliant with safetyregulations. We present an example where multiple operators are injecting CO2into their respective project areas in a geologically connected basin. Toaddress the high computational cost of repeated simulations of high-fidelitymodels, a previously developed surrogate model based on the Embed-to-Control(E2C) framework is employed. Our results demonstrate the effectiveness of theproposed framework in addressing optimal management of CO2 storage whenmultiple stakeholders with various objectives and goals are involved.</description><author>Jungang Chen, Seyyed A. Hosseini</author><pubDate>Fri, 15 Aug 2025 17:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11618v1</guid></item><item><title>Once Upon an AI: Six Scaffolds for Child-AI Interaction Design, Inspired by Disney</title><link>http://arxiv.org/abs/2504.08670v3</link><description>To build AI that children can intuitively understand and benefit from,designers need a design grammar that serves their developmental needs. Thispaper bridges artificial intelligence design for children - an emerging fieldstill defining its best practices - and animation, a well established fieldwith decades of experience in engaging children through accessiblestorytelling. Pairing Piagetian developmental theory with design patternextraction from 52 works of animation, the paper presents a six scaffoldframework that integrates design insights transferable to child centred AIdesign: (1) signals for visual animacy and clarity, (2) sound for musical andauditory scaffolding, (3) synchrony in audiovisual cues, (4) sidekick stylepersonas, (5) storyplay that supports symbolic play and imaginativeexploration, and (6) structure in the form of predictable narratives. Thesestrategies, long refined in animation, function as multimodal scaffolds forattention, understanding, and attunement, supporting learning and comfort. Thisstructured design grammar is transferable to AI design. By reframing cinematicstorytelling and child development theory as design logic for AI, the paperoffers heuristics for AI that aligns with the cognitive stages and emotionalneeds of young users. The work contributes to design theory by showing howsensory, affective, and narrative techniques can inform developmentally attunedAI design. Future directions include empirical testing, cultural adaptation,and participatory co design.</description><author>Nomisha Kurian</author><pubDate>Fri, 15 Aug 2025 17:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.08670v3</guid></item><item><title>Controlling Multimodal LLMs via Reward-guided Decoding</title><link>http://arxiv.org/abs/2508.11616v1</link><description>As Multimodal Large Language Models (MLLMs) gain widespread applicability, itis becoming increasingly desirable to adapt them for diverse user needs. Inthis paper, we study the adaptation of MLLMs through controlled decoding. Toachieve this, we introduce the first method for reward-guided decoding of MLLMsand demonstrate its application in improving their visual grounding. Our methodinvolves building reward models for visual grounding and using them to guidethe MLLM's decoding process. Concretely, we build two separate reward models toindependently control the degree of object precision and recall in the model'soutput. Our approach enables on-the-fly controllability of an MLLM's inferenceprocess in two ways: first, by giving control over the relative importance ofeach reward function during decoding, allowing a user to dynamically trade offobject precision for recall in image captioning tasks; second, by givingcontrol over the breadth of the search during decoding, allowing the user tocontrol the trade-off between the amount of test-time compute and the degree ofvisual grounding. We evaluate our method on standard object hallucinationbenchmarks, showing that it provides significant controllability over MLLMinference, while consistently outperforming existing hallucination mitigationmethods.</description><author>Oscar Mañas, Pierluca D'Oro, Koustuv Sinha, Adriana Romero-Soriano, Michal Drozdzal, Aishwarya Agrawal</author><pubDate>Fri, 15 Aug 2025 17:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11616v1</guid></item><item><title>Pretrained Conformers for Audio Fingerprinting and Retrieval</title><link>http://arxiv.org/abs/2508.11609v1</link><description>Conformers have shown great results in speech processing due to their abilityto capture both local and global interactions. In this work, we utilize aself-supervised contrastive learning framework to train conformer-basedencoders that are capable of generating unique embeddings for small segments ofaudio, generalizing well to previously unseen data. We achieve state-of-the-artresults for audio retrieval tasks while using only 3 seconds of audio togenerate embeddings. Our models are almost completely immune to temporalmisalignments and achieve state-of-the-art results in cases of other audiodistortions such as noise, reverb or extreme temporal stretching. Code andmodels are made publicly available and the results are easy to reproduce as wetrain and test using popular and freely available datasets of different sizes.</description><author>Kemal Altwlkany, Elmedin Selmanovic, Sead Delalic</author><pubDate>Fri, 15 Aug 2025 17:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11609v1</guid></item><item><title>Lightweight Attribute Localizing Models for Pedestrian Attribute Recognition</title><link>http://arxiv.org/abs/2306.09822v2</link><description>Pedestrian Attribute Recognition (PAR) focuses on identifying variousattributes in pedestrian images, with key applications in person retrieval,suspect re-identification, and soft biometrics. However, Deep Neural Networks(DNNs) for PAR often suffer from over-parameterization and high computationalcomplexity, making them unsuitable for resource-constrained devices.Traditional tensor-based compression methods typically factorize layers withoutadequately preserving the gradient direction during compression, leading toinefficient compression and a significant accuracy loss. In this work, wepropose a novel approach for determining the optimal ranks of low-rank layers,ensuring that the gradient direction of the compressed model closely alignswith that of the original model. This means that the compressed modeleffectively preserves the update direction of the full model, enabling moreefficient compression for PAR tasks. The proposed procedure optimizes thecompression ranks for each layer within the ALM model, followed by compressionusing CPD-EPC or truncated SVD. This results in a reduction in model complexitywhile maintaining high performance.</description><author>Ashish Jha, Dimitrii Ermilov, Konstantin Sobolev, Anh Huy Phan, Salman Ahmadi-Asl, Naveed Ahmed, Imran Junejo, Zaher AL Aghbari, Thar Baker, Ahmed Mohamed Khedr, Andrzej Cichocki</author><pubDate>Fri, 15 Aug 2025 17:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09822v2</guid></item><item><title>TinyTim: A Family of Language Models for Divergent Generation</title><link>http://arxiv.org/abs/2508.11607v1</link><description>This work introduces TinyTim, a family of large language models fine-tuned onJames Joyce's `Finnegans Wake'. Through quantitative evaluation againstbaseline models, we demonstrate that TinyTim V1 produces a statisticallydistinct generative profile characterized by high lexical diversity and lowsemantic coherence. These findings are interpreted through theories ofcreativity and complex problem-solving, arguing that such specialized modelscan function as divergent knowledge sources within more extensive creativearchitectures, powering automated discovery mechanisms in diverse settings.</description><author>Christopher J. Agostino</author><pubDate>Fri, 15 Aug 2025 17:14:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11607v1</guid></item><item><title>Dataset Creation for Visual Entailment using Generative AI</title><link>http://arxiv.org/abs/2508.11605v1</link><description>In this paper we present and validate a new synthetic dataset for trainingvisual entailment models. Existing datasets for visual entailment are small andsparse compared to datasets for textual entailment. Manually creating datasetsis labor-intensive. We base our synthetic dataset on the SNLI dataset fortextual entailment. We take the premise text from SNLI as input prompts in agenerative image model, Stable Diffusion, creating an image to replace eachtextual premise. We evaluate our dataset both intrinsically and extrinsically.For extrinsic evaluation, we evaluate the validity of the generated images byusing them as training data for a visual entailment classifier based on CLIPfeature vectors. We find that synthetic training data only leads to a slightdrop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 whentrained on real data. We also compare the quality of our generated trainingdata to original training data on another dataset: SICK-VTE. Again, there isonly a slight drop in F-score: from 0.400 to 0.384. These results indicate thatin settings with data sparsity, synthetic data can be a promising solution fortraining visual entailment models.</description><author>Rob Reijtenbach, Suzan Verberne, Gijs Wijnholds</author><pubDate>Fri, 15 Aug 2025 17:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11605v1</guid></item><item><title>CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion</title><link>http://arxiv.org/abs/2508.11603v1</link><description>Text-driven 3D editing seeks to modify 3D scenes according to textualdescriptions, and most existing approaches tackle this by adapting pre-trained2D image editors to multi-view inputs. However, without explicit control overmulti-view information exchange, they often fail to maintain cross-viewconsistency, leading to insufficient edits and blurry details. We introduceCoreEditor, a novel framework for consistent text-to-3D editing. The keyinnovation is a correspondence-constrained attention mechanism that enforcesprecise interactions between pixels expected to remain consistent throughoutthe diffusion denoising process. Beyond relying solely on geometric alignment,we further incorporate semantic similarity estimated during denoising, enablingmore reliable correspondence modeling and robust multi-view editing. Inaddition, we design a selective editing pipeline that allows users to choosepreferred results from multiple candidates, offering greater flexibility anduser control. Extensive experiments show that CoreEditor produces high-quality,3D-consistent edits with sharper details, significantly outperforming priormethods.</description><author>Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei</author><pubDate>Fri, 15 Aug 2025 17:13:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11603v1</guid></item><item><title>A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability</title><link>http://arxiv.org/abs/2502.12052v2</link><description>In NLG meta-evaluation, evaluation metrics are typically assessed based ontheir consistency with humans. However, we identify some limitations intraditional NLG meta-evaluation approaches, such as issues in handling humanratings and ambiguous selections of correlation measures, which undermine theeffectiveness of meta-evaluation. In this work, we propose a dual-perspectiveNLG meta-evaluation framework that focuses on different evaluationcapabilities, thereby providing better interpretability. In addition, weintroduce a method of automatically constructing the corresponding benchmarkswithout requiring new human annotations. Furthermore, we conduct experimentswith 16 representative LLMs as the evaluators based on our proposed framework,comprehensively analyzing their evaluation performance from differentperspectives.</description><author>Xinyu Hu, Mingqi Gao, Li Lin, Zhenghan Yu, Xiaojun Wan</author><pubDate>Fri, 15 Aug 2025 17:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12052v2</guid></item><item><title>CryptoScope: Utilizing Large Language Models for Automated Cryptographic Logic Vulnerability Detection</title><link>http://arxiv.org/abs/2508.11599v1</link><description>Cryptographic algorithms are fundamental to modern security, yet theirimplementations frequently harbor subtle logic flaws that are hard to detect.We introduce CryptoScope, a novel framework for automated cryptographicvulnerability detection powered by Large Language Models (LLMs). CryptoScopecombines Chain-of-Thought (CoT) prompting with Retrieval-Augmented Generation(RAG), guided by a curated cryptographic knowledge base containing over 12,000entries. We evaluate CryptoScope on LLM-CLVA, a benchmark of 92 cases primarilyderived from real-world CVE vulnerabilities, complemented by cryptographicchallenges from major Capture The Flag (CTF) competitions and syntheticexamples across 11 programming languages. CryptoScope consistently improvesperformance over strong LLM baselines, boosting DeepSeek-V3 by 11.62%,GPT-4o-mini by 20.28%, and GLM-4-Flash by 28.69%. Additionally, it identifies 9previously undisclosed flaws in widely used open-source cryptographic projects.</description><author>Zhihao Li, Zimo Ji, Tao Zheng, Hao Ren, Xiao Lan</author><pubDate>Fri, 15 Aug 2025 17:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11599v1</guid></item><item><title>Representing Speech Through Autoregressive Prediction of Cochlear Tokens</title><link>http://arxiv.org/abs/2508.11598v1</link><description>We introduce AuriStream, a biologically inspired model for encoding speechvia a two-stage framework inspired by the human auditory processing hierarchy.The first stage transforms raw audio into a time-frequency representation basedon the human cochlea, from which we extract discrete \textbf{cochlear tokens}.The second stage applies an autoregressive sequence model over the cochleartokens. AuriStream learns meaningful phoneme and word representations, andstate-of-the-art lexical semantics. AuriStream shows competitive performance ondiverse downstream SUPERB speech tasks. Complementing AuriStream's strongrepresentational capabilities, it generates continuations of audio which can bevisualized in a spectrogram space and decoded back into audio, providinginsights into the model's predictions. In summary, we present a two-stageframework for speech representation learning to advance the development of morehuman-like models that efficiently handle a range of speech-based tasks.</description><author>Greta Tuckute, Klemen Kotar, Evelina Fedorenko, Daniel L. K. Yamins</author><pubDate>Fri, 15 Aug 2025 17:06:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11598v1</guid></item><item><title>Nonparametric learning of stochastic differential equations from sparse and noisy data</title><link>http://arxiv.org/abs/2508.11597v1</link><description>The paper proposes a systematic framework for building data-driven stochasticdifferential equation (SDE) models from sparse, noisy observations. Unliketraditional parametric approaches, which assume a known functional form for thedrift, our goal here is to learn the entire drift function directly from datawithout strong structural assumptions, making it especially relevant inscientific disciplines where system dynamics are partially understood or highlycomplex. We cast the estimation problem as minimization of the penalizednegative log-likelihood functional over a reproducing kernel Hilbert space(RKHS). In the sparse observation regime, the presence of unobserved trajectorysegments makes the SDE likelihood intractable. To address this, we develop anExpectation-Maximization (EM) algorithm that employs a novel Sequential MonteCarlo (SMC) method to approximate the filtering distribution and generate MonteCarlo estimates of the E-step objective. The M-step then reduces to a penalizedempirical risk minimization problem in the RKHS, whose minimizer is given by afinite linear combination of kernel functions via a generalized representertheorem. To control model complexity across EM iterations, we also develop ahybrid Bayesian variant of the algorithm that uses shrinkage priors to identifysignificant coefficients in the kernel expansion. We establish importanttheoretical convergence results for both the exact and approximate EMsequences. The resulting EM-SMC-RKHS procedure enables accurate estimation ofthe drift function of stochastic dynamical systems in low-data regimes and isbroadly applicable across domains requiring continuous-time modeling underobservational constraints. We demonstrate the effectiveness of our methodthrough a series of numerical experiments.</description><author>Arnab Ganguly, Riten Mitra, Jinpu Zhou</author><pubDate>Fri, 15 Aug 2025 17:01:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11597v1</guid></item><item><title>DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring</title><link>http://arxiv.org/abs/2508.11591v1</link><description>Our study introduces a novel, low-cost, and reproducible framework forreal-time, object-level structural assessment and geolocation of roadsidevegetation and infrastructure with commonly available but underutilizeddashboard camera (dashcam) video data. We developed an end-to-end pipeline thatcombines monocular depth estimation, depth error correction, and geometrictriangulation to generate accurate spatial and structural data fromstreet-level video streams from vehicle-mounted dashcams. Depth maps were firstestimated using a state-of-the-art monocular depth model, then refined via agradient-boosted regression framework to correct underestimations, particularlyfor distant objects. The depth correction model achieved strong predictiveperformance (R2 = 0.92, MAE = 0.31 on transformed scale), significantlyreducing bias beyond 15 m. Further, object locations were estimated usingGPS-based triangulation, while object heights were calculated using pin holecamera geometry. Our method was evaluated under varying conditions of cameraplacement and vehicle speed. Low-speed vehicle with inside camera gave thehighest accuracy, with mean geolocation error of 2.83 m, and mean absoluteerror (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. Tothe best of our knowledge, it is the first framework to combine monocular depthmodeling, triangulated GPS-based geolocation, and real-time structuralassessment for urban vegetation and infrastructure using consumer-grade videodata. Our approach complements conventional RS methods, such as LiDAR and imageby offering a fast, real-time, and cost-effective solution for object-levelmonitoring of vegetation risks and infrastructure exposure, making itespecially valuable for utility companies, and urban planners aiming forscalable and frequent assessments in dynamic urban environments.</description><author>Durga Joshi, Chandi Witharana, Robert Fahey, Thomas Worthley, Zhe Zhu, Diego Cerrai</author><pubDate>Fri, 15 Aug 2025 16:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11591v1</guid></item><item><title>Convolutional Autoencoders for Data Compression and Anomaly Detection in Small Satellite Technologies</title><link>http://arxiv.org/abs/2505.00040v2</link><description>Small satellite technologies have enhanced the potential and feasibility ofgeodesic missions, through simplification of design and decreased costsallowing for more frequent launches. On-satellite data acquisition systems canbenefit from the implementation of machine learning (ML), for betterperformance and greater efficiency on tasks such as image processing or featureextraction. This work presents convolutional autoencoders for implementation onthe payload of small satellites, designed to achieve dual functionality of datacompression for more efficient off-satellite transmission, and at-sourceanomaly detection to inform satellite data-taking. This capability isdemonstrated for a use case of disaster monitoring using aerial image datasetsof the African continent, offering avenues for both novel ML-based approachesin small satellite applications along with the expansion of space technologyand artificial intelligence in Africa.</description><author>Dishanand Jayeprokash, Julia Gonski</author><pubDate>Fri, 15 Aug 2025 16:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.00040v2</guid></item><item><title>Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation</title><link>http://arxiv.org/abs/2508.11588v1</link><description>Effective and efficient agricultural manipulation and harvesting depend onaccurately understanding the current state of the grasp. The agriculturalenvironment presents unique challenges due to its complexity, clutter, andocclusion. Additionally, fruit is physically attached to the plant, requiringprecise separation during harvesting. Selecting appropriate sensors andmodeling techniques is critical for obtaining reliable feedback and correctlyidentifying grasp states. This work investigates a set of key sensors, namelyinertial measurement units (IMUs), infrared (IR) reflectance, tension, tactilesensors, and RGB cameras, integrated into a compliant gripper to classify graspstates. We evaluate the individual contribution of each sensor and compare theperformance of two widely used classification models: Random Forest and LongShort-Term Memory (LSTM) networks. Our results demonstrate that a Random Forestclassifier, trained in a controlled lab environment and tested on real cherrytomato plants, achieved 100% accuracy in identifying slip, grasp failure, andsuccessful picks, marking a substantial improvement over baseline performance.Furthermore, we identify a minimal viable sensor combination, namely IMU andtension sensors that effectively classifies grasp states. This classifierenables the planning of corrective actions based on real-time feedback, therebyenhancing the efficiency and reliability of fruit harvesting operations.</description><author>Benjamin Walt, Jordan Westphal, Girish Krishnan</author><pubDate>Fri, 15 Aug 2025 16:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11588v1</guid></item><item><title>Pr$εε$mpt: Sanitizing Sensitive Prompts for LLMs</title><link>http://arxiv.org/abs/2504.05147v2</link><description>The rise of large language models (LLMs) has introduced new privacychallenges, particularly during inference where sensitive information inprompts may be exposed to proprietary LLM APIs. In this paper, we address theproblem of formally protecting the sensitive information contained in a promptwhile maintaining response quality. To this end, first, we introduce acryptographically inspired notion of a prompt sanitizer which transforms aninput prompt to protect its sensitive tokens. Second, we proposePr$\epsilon\epsilon$mpt, a novel system that implements a prompt sanitizer.Pr$\epsilon\epsilon$mpt categorizes sensitive tokens into two types: (1) thosewhere the LLM's response depends solely on the format (such as SSNs, creditcard numbers), for which we use format-preserving encryption (FPE); and (2)those where the response depends on specific values, (such as age, salary) forwhich we apply metric differential privacy (mDP). Our evaluation demonstratesthat Pr$\epsilon\epsilon$mpt is a practical method to achieve meaningfulprivacy guarantees, while maintaining high utility compared to unsanitizedprompts, and outperforming prior methods</description><author>Amrita Roy Chowdhury, David Glukhov, Divyam Anshumaan, Prasad Chalasani, Nicolas Papernot, Somesh Jha, Mihir Bellare</author><pubDate>Fri, 15 Aug 2025 16:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.05147v2</guid></item><item><title>Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks</title><link>http://arxiv.org/abs/2508.11584v1</link><description>Deploying multiple machine learning models on resource-constrained roboticplatforms for different perception tasks often results in redundantcomputations, large memory footprints, and complex integration challenges. Inresponse, this work presents Visual Perception Engine (VPEngine), a modularframework designed to enable efficient GPU usage for visual multitasking whilemaintaining extensibility and developer accessibility. Our frameworkarchitecture leverages a shared foundation model backbone that extracts imagerepresentations, which are efficiently shared, without any unnecessary GPU-CPUmemory transfers, across multiple specialized task-specific model heads runningin parallel. This design eliminates the computational redundancy inherent infeature extraction component when deploying traditional sequential models whileenabling dynamic task prioritization based on application demands. Wedemonstrate our framework's capabilities through an example implementationusing DINOv2 as the foundation model with multiple task (depth, objectdetection and semantic segmentation) heads, achieving up to 3x speedup comparedto sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngineoffers efficient GPU utilization and maintains a constant memory footprintwhile allowing per-task inference frequencies to be adjusted dynamically duringruntime. The framework is written in Python and is open source with ROS2 C++(Humble) bindings for ease of use by the robotics community across diverserobotic platforms. Our example implementation demonstrates end-to-end real-timeperformance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimizedmodels.</description><author>Jakub Łucki, Jonathan Becktor, Georgios Georgakis, Robert Royce, Shehryar Khattak</author><pubDate>Fri, 15 Aug 2025 16:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11584v1</guid></item><item><title>Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models</title><link>http://arxiv.org/abs/2508.11582v1</link><description>Recent advancements in large language models (LLMs) have greatly improvedtheir capabilities on complex reasoning tasks through Long Chain-of-Thought(CoT). However, this approach often results in substantial redundancy,impairing computational efficiency and causing significant delays in real-timeapplications. To improve the efficiency, current methods often rely onhuman-defined difficulty priors, which do not align with the LLM's self-awareddifficulty, leading to inefficiencies. In this paper, we introduce the DynamicReasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models todynamically assess and adjust their reasoning depth in response to problemcomplexity. DR. SAF integrates three key components: Boundary Self-AwarenessAlignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.These components allow models to optimize their reasoning processes, balancingefficiency and accuracy without compromising performance. Our experimentalresults demonstrate that DR. SAF achieves a 49.27% reduction in total responsetokens with minimal loss in accuracy. The framework also delivers a 6.59x gainin token efficiency and a 5x reduction in training time, making it well-suitedto resource-limited settings. During extreme training, DR. SAF can even surpasstraditional instruction-based models in token efficiency with more than 16%accuracy improvement.</description><author>Qiguang Chen, Dengyun Peng, Jinhao Liu, HuiKang Su, Jiannan Guan, Libo Qin, Wanxiang Che</author><pubDate>Fri, 15 Aug 2025 16:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11582v1</guid></item><item><title>Causality Matters: How Temporal Information Emerges in Video Language Models</title><link>http://arxiv.org/abs/2508.11576v1</link><description>Video language models (VideoLMs) have made significant progress in multimodalunderstanding. However, temporal understanding, which involves identifyingevent order, duration, and relationships across time, still remains a corechallenge. Prior works emphasize positional encodings (PEs) as a key mechanismfor encoding temporal structure. Surprisingly, we find that removing ormodifying PEs in video inputs yields minimal degradation in the performance oftemporal understanding. In contrast, reversing the frame sequence whilepreserving the original PEs causes a substantial drop. To explain thisbehavior, we conduct substantial analysis experiments to trace how temporalinformation is integrated within the model. We uncover a causal informationpathway: temporal cues are progressively synthesized through inter-frameattention, aggregated in the final frame, and subsequently integrated into thequery tokens. This emergent mechanism shows that temporal reasoning emergesfrom inter-visual token interactions under the constraints of causal attention,which implicitly encodes temporal structure. Based on these insights, wepropose two efficiency-oriented strategies: staged cross-modal attention and atemporal exit mechanism for early token truncation. Experiments on twobenchmarks validate the effectiveness of both approaches. To the best of ourknowledge, this is the first work to systematically investigate video temporalunderstanding in VideoLMs, offering insights for future model improvement.</description><author>Yumeng Shi, Quanyu Long, Yin Wu, Wenya Wang</author><pubDate>Fri, 15 Aug 2025 16:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11576v1</guid></item><item><title>TrajSV: A Trajectory-based Model for Sports Video Representations and Applications</title><link>http://arxiv.org/abs/2508.11569v1</link><description>Sports analytics has received significant attention from both academia andindustry in recent years. Despite the growing interest and efforts in thisfield, several issues remain unresolved, including (1) data unavailability, (2)lack of an effective trajectory-based framework, and (3) requirement forsufficient supervision labels. In this paper, we present TrajSV, atrajectory-based framework that addresses various issues in existing studies.TrajSV comprises three components: data preprocessing, Clip RepresentationNetwork (CRNet), and Video Representation Network (VRNet). The datapreprocessing module extracts player and ball trajectories from sportsbroadcast videos. CRNet utilizes a trajectory-enhanced Transformer module tolearn clip representations based on these trajectories. Additionally, VRNetlearns video representations by aggregating clip representations and visualfeatures with an encoder-decoder architecture. Finally, a triple contrastiveloss is introduced to optimize both video and clip representations in anunsupervised manner. The experiments are conducted on three broadcast videodatasets to verify the effectiveness of TrajSV for three types of sports (i.e.,soccer, basketball, and volleyball) with three downstream applications (i.e.,sports video retrieval, action spotting, and video captioning). The resultsdemonstrate that TrajSV achieves state-of-the-art performance in sports videoretrieval, showcasing a nearly 70% improvement. It outperforms baselines inaction spotting, achieving state-of-the-art results in 9 out of 17 actioncategories, and demonstrates a nearly 20% improvement in video captioning.Additionally, we introduce a deployed system along with the three applicationsbased on TrajSV.</description><author>Zheng Wang, Shihao Xu, Wei Shi</author><pubDate>Fri, 15 Aug 2025 16:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11569v1</guid></item><item><title>AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment</title><link>http://arxiv.org/abs/2508.11567v1</link><description>Mental health assessment is crucial for early intervention and effectivetreatment, yet traditional clinician-based approaches are limited by theshortage of qualified professionals. Recent advances in artificial intelligencehave sparked growing interest in automated psychological assessment, yet mostexisting approaches are constrained by their reliance on static text analysis,limiting their ability to capture deeper and more informative insights thatemerge through dynamic interaction and iterative questioning. Therefore, inthis paper, we propose a multi-agent framework for mental health evaluationthat simulates clinical doctor-patient dialogues, with specialized agentsassigned to questioning, adequacy evaluation, scoring, and updating. Weintroduce an adaptive questioning mechanism in which an evaluation agentassesses the adequacy of user responses to determine the necessity ofgenerating targeted follow-up queries to address ambiguity and missinginformation. Additionally, we employ a tree-structured memory in which the rootnode encodes the user's basic information, while child nodes (e.g., topic andstatement) organize key information according to distinct symptom categoriesand interaction turns. This memory is dynamically updated throughout theinteraction to reduce redundant questioning and further enhance the informationextraction and contextual tracking capabilities. Experimental results on theDAIC-WOZ dataset illustrate the effectiveness of our proposed method, whichachieves better performance than existing approaches.</description><author>Jinpeng Hu, Ao Wang, Qianqian Xie, Hui Ma, Zhuo Li, Dan Guo</author><pubDate>Fri, 15 Aug 2025 16:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11567v1</guid></item><item><title>Emphasis Sensitivity in Speech Representations</title><link>http://arxiv.org/abs/2508.11566v1</link><description>This work investigates whether modern speech models are sensitive to prosodicemphasis - whether they encode emphasized and neutral words in systematicallydifferent ways. Prior work typically relies on isolated acoustic correlates(e.g., pitch, duration) or label prediction, both of which miss the relationalstructure of emphasis. This paper proposes a residual-based framework, definingemphasis as the difference between paired neutral and emphasized wordrepresentations. Analysis on self-supervised speech models shows that theseresiduals correlate strongly with duration changes and perform poorly at wordidentity prediction, indicating a structured, relational encoding of prosodicemphasis. In ASR fine-tuned models, residuals occupy a subspace up to 50% morecompact than in pre-trained models, further suggesting that emphasis is encodedas a consistent, low-dimensional transformation that becomes more structuredwith task-specific learning.</description><author>Shaun Cassini, Thomas Hain, Anton Ragni</author><pubDate>Fri, 15 Aug 2025 16:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11566v1</guid></item><item><title>SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling</title><link>http://arxiv.org/abs/2508.11553v1</link><description>We introduce SeamlessFlow, a server based reinforcement learning (RL)framework that addresses two core challenges in industrial scale RL: (1)decoupling RL training from the complex execution flow of agents; (2)maximizing GPU utilization with minimal idle time while preserving thestability and scalability required for large-scale deployments. First,SeamlessFlow introduces a data plane that decouples the RL trainer fromdiverse, complex agent implementations while sustaining high throughput. Acentral trajectory manager maintains complete interaction histories andsupports partial rollout, allowing rollout to pause for weight updates andresume seamlessly, keeping agents unaware of service interruptions. Second, wepropose a tag driven scheduling paradigm that abstracts hardware intocapability tagged resources, unifying colocated and disaggregatedarchitectures. Based on this, SeamlessFlow introduces a spatiotemporalmultiplexing pipeline that dynamically reassigns idle training nodes to rolloutin a train rollout separated setup, eliminating pipeline bubbles and fullyexploiting heterogeneous cluster resources. By combining these innovations,SeamlessFlow delivers both stability and high performance, making it wellsuited for multi agent, long horizon, and other complex RL tasks.</description><author>Jinghui Wang, Shaojie Wang, Yinghan Cui, Xuxing Chen, Chao Wang, Xiaojiang Zhang, Minglei Zhang, Jiarong Zhang, Wenhao Zhuang, Yuchen Cao, Wankang Bao, Haimo Li, Zheng Lin, Huiming Wang, Haoyang Huang, Zongxian Feng, Zizheng Zhan, Ken Deng, Wen Xiang, Huaixi Tang, Kun Wu, Mengtong Li, Mengfei Xie, Junyi Peng, Haotian Zhang, Bin Chen, Bing Yu</author><pubDate>Fri, 15 Aug 2025 15:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11553v1</guid></item><item><title>ADMIRE-BayesOpt: Accelerated Data MIxture RE-weighting for Language Models with Bayesian Optimization</title><link>http://arxiv.org/abs/2508.11551v1</link><description>Determining the optimal data mixture for large language model trainingremains a challenging problem with an outsized impact on performance. Inpractice, language model developers continue to rely on heuristic explorationsince no learning-based approach has emerged as a reliable solution. In thiswork, we propose to view the selection of training data mixtures as a black-boxhyperparameter optimization problem, for which Bayesian Optimization is awell-established class of appropriate algorithms. Firstly, we cast data mixturelearning as a sequential decision-making problem, in which we aim to find asuitable trade-off between the computational cost of training exploratory(proxy-) models and final mixture performance. Secondly, we systematicallyexplore the properties of transferring mixtures learned at a small scale tolarger-scale experiments, providing insights and highlighting opportunities forresearch at a modest scale. By proposing Multi-fidelity Bayesian Optimizationas a suitable method in this common scenario, we introduce a natural frameworkto balance experiment cost with model fit, avoiding the risks of overfitting tosmaller scales while minimizing the number of experiments at high cost. Wepresent results for pre-training and instruction finetuning across modelsranging from 1 million to 7 billion parameters, varying from simplearchitectures to state-of-the-art models and benchmarks spanning dozens ofdatasets. We demonstrate consistently strong results relative to a wide rangeof benchmarks, showingspeed-ups of over 500% in determining the best datamixture on our largest experiments relative to recent baselines. In addition,we broaden access to research by sharing ADMIRE IFT Runs, a dataset of 460 fulltraining &amp; evaluation runs across various model sizes worth over 13,000 GPUhours, greatly reducing the cost of conducting research in this area.</description><author>Shengzhuang Chen, Xu Ouyang, Michael Arthur Leopold Pearce, Thomas Hartvigsen, Jonathan Richard Schwarz</author><pubDate>Fri, 15 Aug 2025 15:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11551v1</guid></item><item><title>Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model</title><link>http://arxiv.org/abs/2508.11550v1</link><description>Industrial anomaly detection (AD) plays a significant role in manufacturingwhere a long-standing challenge is data scarcity. A growing body of works haveemerged to address insufficient anomaly data via anomaly generation. However,these anomaly generation methods suffer from lack of fidelity or need to betrained with extra data. To this end, we propose a training-free anomalygeneration framework dubbed AAG, which is based on Stable Diffusion (SD)'sstrong generation ability for effective anomaly image generation. Given anormal image, mask and a simple text prompt, AAG can generate realistic andnatural anomalies in the specific regions and simultaneously keep contents inother regions unchanged. In particular, we propose Cross-Attention Enhancement(CAE) to re-engineer the cross-attention mechanism within Stable Diffusionbased on the given mask. CAE increases the similarity between visual tokens inspecific regions and text embeddings, which guides these generated visualtokens in accordance with the text description. Besides, generated anomaliesneed to be more natural and plausible with object in given image. We proposeSelf-Attention Enhancement (SAE) which improves similarity between each normalvisual token and anomaly visual tokens. SAE ensures that generated anomaliesare coherent with original pattern. Extensive experiments on MVTec AD and VisAdatasets demonstrate effectiveness of AAG in anomaly generation and itsutility. Furthermore, anomaly images generated by AAG can bolster performanceof various downstream anomaly inspection tasks.</description><author>Zuo Zuo, Jiahao Dong, Yanyun Qu, Zongze Wu</author><pubDate>Fri, 15 Aug 2025 15:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11550v1</guid></item><item><title>PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments</title><link>http://arxiv.org/abs/2506.06631v2</link><description>Visual parsing of images and videos is critical for a wide range ofreal-world applications. However, progress in this field is constrained bylimitations of existing datasets: (1) insufficient annotation granularity,which impedes fine-grained scene understanding and high-level reasoning; (2)limited coverage of domains, particularly a lack of datasets tailored foreducational scenarios; and (3) lack of explicit procedural guidance, withminimal logical rules and insufficient representation of structured taskprocess. To address these gaps, we introduce PhysLab, the first video datasetthat captures students conducting complex physics experiments. The datasetincludes four representative experiments that feature diverse scientificinstruments and rich human-object interaction (HOI) patterns. PhysLab comprises620 long-form videos and provides multilevel annotations that support a varietyof vision tasks, including action recognition, object detection, HOI analysis,etc. We establish strong baselines and perform extensive evaluations tohighlight key challenges in the parsing of procedural educational videos. Weexpect PhysLab to serve as a valuable resource for advancing fine-grainedvisual parsing, facilitating intelligent classroom systems, and fosteringcloser integration between computer vision and educational technologies. Thedataset and the evaluation toolkit are publicly available athttps://github.com/ZMH-SDUST/PhysLab.</description><author>Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou</author><pubDate>Fri, 15 Aug 2025 15:41:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.06631v2</guid></item><item><title>Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs</title><link>http://arxiv.org/abs/2506.10054v2</link><description>Direct Preference Optimization (DPO) has become a cornerstone ofreinforcement learning from human feedback (RLHF) due to its simplicity andefficiency. However, existing DPO-based approaches typically treat allpreference pairs uniformly, ignoring critical variations in their inherentquality and learning utility, leading to suboptimal data utilization andperformance. To address this challenge, we propose Omni-DPO, a dual-perspectiveoptimization framework that jointly accounts for (1) the inherent quality ofeach preference pair and (2) the model's evolving performance on those pairs.By adaptively weighting samples according to both data quality and the model'slearning dynamics during training, Omni-DPO enables more effective trainingdata utilization and achieves better performance. Experimental results onvarious models and benchmarks demonstrate the superiority and generalizationcapabilities of Omni-DPO. On textual understanding tasks, Gemma-2-9b-itfinetuned with Omni-DPO beats the leading LLM, Claude 3 Opus, by a significantmargin of 6.7 points on the Arena-Hard benchmark. On mathematical reasoningtasks, Omni-DPO consistently outperforms the baseline methods across allbenchmarks, providing strong empirical evidence for the effectiveness androbustness of our approach. Code and models will be available athttps://github.com/pspdada/Omni-DPO.</description><author>Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang</author><pubDate>Fri, 15 Aug 2025 15:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.10054v2</guid></item><item><title>Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models</title><link>http://arxiv.org/abs/2508.11542v1</link><description>This paper presents a data-driven, nested Operator Inference (OpInf) approachfor learning physics-informed reduced-order models (ROMs) from snapshot data ofhigh-dimensional dynamical systems. The approach exploits the inherenthierarchy within the reduced space to iteratively construct initial guesses forthe OpInf learning problem that prioritize the interactions of the dominantmodes. The initial guess computed for any target reduced dimension correspondsto a ROM with provably smaller or equal snapshot reconstruction error than withstandard OpInf. Moreover, our nested OpInf algorithm can be warm-started frompreviously learned models, enabling versatile application scenarios involvingdynamic basis and model form updates. We demonstrate the performance of ouralgorithm on a cubic heat conduction problem, with nested OpInf achieving afour times smaller error than standard OpInf at a comparable offline time.Further, we apply nested OpInf to a large-scale, parameterized model of theGreenland ice sheet where, despite model form approximation errors, it learns aROM with, on average, 3% error and computational speed-up factor above 19,000.</description><author>Nicole Aretz, Karen Willcox</author><pubDate>Fri, 15 Aug 2025 15:38:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11542v1</guid></item><item><title>Reinforcing Video Reasoning Segmentation to Think Before It Segments</title><link>http://arxiv.org/abs/2508.11538v1</link><description>Video reasoning segmentation (VRS) endeavors to delineate referred objects invideos guided by implicit instructions that encapsulate human intent andtemporal logic. Previous approaches leverage large vision language models(LVLMs) to encode object semantics into &lt;SEG&gt; tokens for mask prediction.However, this paradigm suffers from limited interpretability during inferenceand suboptimal performance due to inadequate spatiotemporal reasoning. Drawinginspiration from seminal breakthroughs in reinforcement learning, we introduceVeason-R1, a specialized LVLM for VRS that emphasizes structured reasoning insegmentation. Veason-R1 is trained through Group Relative Policy Optimization(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, wecurate high-quality CoT training data to instill structured reasoningtrajectories, bridging video-level semantics and frame-level spatial grounding,yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPOfine-tuning encourages efficient exploration of the reasoning space byoptimizing reasoning chains. To this end, we incorporate a holistic rewardmechanism that synergistically enhances spatial alignment and temporalconsistency, bolstering keyframe localization and fine-grained grounding.Comprehensive empirical evaluations demonstrate that Veason-R1 achievesstate-of-the-art performance on multiple benchmarks, surpassing prior art bysignificant margins (e.g., +1.3 J &amp;F in ReVOS and +10.0 J &amp;F in ReasonVOS),while exhibiting robustness to hallucinations (+8.8 R). Our code and modelweights will be available at Veason-R1.</description><author>Sitong Gong, Lu Zhang, Yunzhi Zhuge, Xu Jia, Pingping Zhang, Huchuan Lu</author><pubDate>Fri, 15 Aug 2025 15:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11538v1</guid></item><item><title>Language models align with brain regions that represent concepts across modalities</title><link>http://arxiv.org/abs/2508.11536v1</link><description>Cognitive science and neuroscience have long faced the challenge ofdisentangling representations of language from representations of conceptualmeaning. As the same problem arises in today's language models (LMs), weinvestigate the relationship between LM--brain alignment and two neuralmetrics: (1) the level of brain activation during processing of sentences,targeting linguistic processing, and (2) a novel measure of meaning consistencyacross input modalities, which quantifies how consistently a brain regionresponds to the same concept across paradigms (sentence, word cloud, image)using an fMRI dataset (Pereira et al., 2018). Our experiments show that bothlanguage-only and language-vision models predict the signal better in moremeaning-consistent areas of the brain, even when these areas are not stronglysensitive to language processing, suggesting that LMs might internallyrepresent cross-modal conceptual meaning.</description><author>Maria Ryskina, Greta Tuckute, Alexander Fung, Ashley Malkin, Evelina Fedorenko</author><pubDate>Fri, 15 Aug 2025 15:32:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11536v1</guid></item><item><title>Random Walk Learning and the Pac-Man Attack</title><link>http://arxiv.org/abs/2508.05663v2</link><description>Random walk (RW)-based algorithms have long been popular in distributedsystems due to low overheads and scalability, with recent growing applicationsin decentralized learning. However, their reliance on local interactions makesthem inherently vulnerable to malicious behavior. In this work, we investigatean adversarial threat that we term the ``Pac-Man'' attack, in which a maliciousnode probabilistically terminates any RW that visits it. This stealthy behaviorgradually eliminates active RWs from the network, effectively halting thelearning process without triggering failure alarms. To counter this threat, wepropose the Average Crossing (AC) algorithm--a fully decentralized mechanismfor duplicating RWs to prevent RW extinction in the presence of Pac-Man. Ourtheoretical analysis establishes that (i) the RW population remains almostsurely bounded under AC and (ii) RW-based stochastic gradient descent remainsconvergent under AC, even in the presence of Pac-Man, with a quantifiabledeviation from the true optimum. Our extensive empirical results on bothsynthetic and real-world datasets corroborate our theoretical findings.Furthermore, they uncover a phase transition in the extinction probability as afunction of the duplication threshold. We offer theoretical insights byanalyzing a simplified variant of the AC, which sheds light on the observedphase transition.</description><author>Xingran Chen, Parimal Parag, Rohit Bhagat, Zonghong Liu, Salim El Rouayheb</author><pubDate>Fri, 15 Aug 2025 15:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.05663v2</guid></item><item><title>Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models</title><link>http://arxiv.org/abs/2508.11534v1</link><description>As large language models (LLMs) become more widely deployed, it is crucial toexamine their ethical tendencies. Building on research on fairness anddiscrimination in AI, we investigate whether LLMs exhibit speciesist bias --discrimination based on species membership -- and how they value non-humananimals. We systematically examine this issue across three paradigms: (1)SpeciesismBench, a 1,003-item benchmark assessing recognition and moralevaluation of speciesist statements; (2) established psychological measurescomparing model responses with those of human participants; (3) text-generationtasks probing elaboration on, or resistance to, speciesist rationalizations. Inour benchmark, LLMs reliably detected speciesist statements but rarelycondemned them, often treating speciesist attitudes as morally acceptable. Onpsychological measures, results were mixed: LLMs expressed slightly lowerexplicit speciesism than people, yet in direct trade-offs they more often choseto save one human over multiple animals. A tentative interpretation is thatLLMs may weight cognitive capacity rather than species per se: when capacitieswere equal, they showed no species preference, and when an animal was describedas more capable, they tended to prioritize it over a less capable human. Inopen-ended text generation tasks, LLMs frequently normalized or rationalizedharm toward farmed animals while refusing to do so for non-farmed animals.These findings suggest that while LLMs reflect a mixture of progressive andmainstream human views, they nonetheless reproduce entrenched cultural normsaround animal exploitation. We argue that expanding AI fairness and alignmentframeworks to explicitly include non-human moral patients is essential forreducing these biases and preventing the entrenchment of speciesist attitudesin AI systems and the societies they influence.</description><author>Monika Jotautaitė, Lucius Caviola, David A. Brewster, Thilo Hagendorff</author><pubDate>Fri, 15 Aug 2025 15:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11534v1</guid></item><item><title>Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs</title><link>http://arxiv.org/abs/2503.01307v2</link><description>Test-time inference has emerged as a powerful paradigm for enabling languagemodels to ``think'' longer and more carefully about complex challenges, muchlike skilled human experts. While reinforcement learning (RL) can driveself-improvement in language models on verifiable tasks, some models exhibitsubstantial gains while others quickly plateau. For instance, we find thatQwen-2.5-3B far exceeds Llama-3.2-3B under identical RL training for the gameof Countdown. This discrepancy raises a critical question: what intrinsicproperties enable effective self-improvement? We introduce a framework toinvestigate this question by analyzing four key cognitive behaviors --verification, backtracking, subgoal setting, and backward chaining -- that bothexpert human problem solvers and successful language models employ. Our studyreveals that Qwen naturally exhibits these reasoning behaviors, whereas Llamainitially lacks them. In systematic experimentation with controlled behavioraldatasets, we find that priming Llama with examples containing these reasoningbehaviors enables substantial improvements during RL, matching or exceedingQwen's performance. Importantly, the presence of reasoning behaviors, ratherthan correctness of answers, proves to be the critical factor -- models primedwith incorrect solutions containing proper reasoning patterns achievecomparable performance to those trained on correct solutions. Finally,leveraging continued pretraining with OpenWebMath data, filtered to amplifyreasoning behaviors, enables the Llama model to match Qwen's self-improvementtrajectory. Our findings establish a fundamental relationship between initialreasoning behaviors and the capacity for improvement, explaining why somelanguage models effectively utilize additional computation while othersplateau.</description><author>Kanishk Gandhi, Ayush Chakravarthy, Anikait Singh, Nathan Lile, Noah D. Goodman</author><pubDate>Fri, 15 Aug 2025 15:21:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.01307v2</guid></item><item><title>An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture</title><link>http://arxiv.org/abs/2508.11532v1</link><description>Intelligent analysis of medical imaging plays a crucial role in assistingclinical diagnosis. However, achieving efficient and high-accuracy imageclassification in resource-constrained computational environments remainschallenging. This study proposes a medical image classification method based onan improved ConvNeXt-Tiny architecture. Through structural optimization andloss function design, the proposed method enhances feature extractioncapability and classification performance while reducing computationalcomplexity. Specifically, the method introduces a dual global pooling (GlobalAverage Pooling and Global Max Pooling) feature fusion strategy into theConvNeXt-Tiny backbone to simultaneously preserve global statistical featuresand salient response information. A lightweight channel attention module,termed Squeeze-and-Excitation Vector (SEVector), is designed to improve theadaptive allocation of channel weights while minimizing parameter overhead.Additionally, a Feature Smoothing Loss is incorporated into the loss functionto enhance intra-class feature consistency and suppress intra-class variance.Under CPU-only conditions (8 threads), the method achieves a maximumclassification accuracy of 89.10% on the test set within 10 training epochs,exhibiting a stable convergence trend in loss values. Experimental resultsdemonstrate that the proposed method effectively improves medical imageclassification performance in resource-limited settings, providing a feasibleand efficient solution for the deployment and promotion of medical imaginganalysis models.</description><author>Jingsong Xia, Yue Yin, Xiuhan Li</author><pubDate>Fri, 15 Aug 2025 15:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11532v1</guid></item><item><title>Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction</title><link>http://arxiv.org/abs/2508.11531v1</link><description>Efficient trackers achieve faster runtime by reducing computationalcomplexity and model parameters. However, this efficiency often compromises theexpense of weakened feature representation capacity, thus limiting theirability to accurately capture target states using single-layer features. Toovercome this limitation, we propose Multi-State Tracker (MST), which utilizeshighly lightweight state-specific enhancement (SSE) to perform specializedenhancement on multi-state features produced by multi-state generation (MSG)and aggregates them in an interactive and adaptive manner using cross-stateinteraction (CSI). This design greatly enhances feature representation whileincurring minimal computational overhead, leading to improved trackingrobustness in complex environments. Specifically, the MSG generates multiplestate representations at multiple stages during feature extraction, while SSErefines them to highlight target-specific features. The CSI module facilitatesinformation exchange between these states and ensures the integration ofcomplementary features. Notably, the introduced SSE and CSI modules adopt ahighly lightweight hidden state adaptation-based state space duality (HSA-SSD)design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.Experimental results demonstrate that MST outperforms all previous efficienttrackers across multiple datasets, significantly improving tracking accuracyand robustness. In particular, it shows excellent runtime performance, with anAO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT onthe GOT-10K dataset. The code is available at https://github.com/wsumel/MST.</description><author>Shilei Wang, Gong Cheng, Pujian Lai, Dong Gao, Junwei Han</author><pubDate>Fri, 15 Aug 2025 15:19:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11531v1</guid></item><item><title>Incorporating Arbitrary Matrix Group Equivariance into KANs</title><link>http://arxiv.org/abs/2410.00435v4</link><description>Kolmogorov-Arnold Networks (KANs) have seen great success in scientificdomains thanks to spline activation functions, becoming an alternative toMulti-Layer Perceptrons (MLPs). However, spline functions may not respectsymmetry in tasks, which is crucial prior knowledge in machine learning. Inthis paper, we propose Equivariant Kolmogorov-Arnold Networks (EKAN), a methodfor incorporating arbitrary matrix group equivariance into KANs, aiming tobroaden their applicability to more fields. We first construct gated splinebasis functions, which form the EKAN layer together with equivariant linearweights, and then define a lift layer to align the input space of EKAN with thefeature space of the dataset, thereby building the entire EKAN architecture.Compared with baseline models, EKAN achieves higher accuracy with smallerdatasets or fewer parameters on symmetry-related tasks, such as particlescattering and the three-body problem, often reducing test MSE by severalorders of magnitude. Even in non-symbolic formula scenarios, such as top quarktagging with three jet constituents, EKAN achieves comparable results withstate-of-the-art equivariant architectures using fewer than 40% of theparameters, while KANs do not outperform MLPs as expected. Code and data areavailable at https://github.com/hulx2002/EKAN .</description><author>Lexiang Hu, Yisen Wang, Zhouchen Lin</author><pubDate>Fri, 15 Aug 2025 15:17:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00435v4</guid></item><item><title>DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning</title><link>http://arxiv.org/abs/2508.11530v1</link><description>Decentralized Federated Learning (DFL) has emerged as a robust distributedparadigm that circumvents the single-point-of-failure and communicationbottleneck risks of centralized architectures. However, a significant challengearises as existing DFL optimization strategies, primarily designed for taskssuch as computer vision, fail to address the unique topological informationinherent in the local subgraph. Notably, while Federated Graph Learning (FGL)is tailored for graph data, it is predominantly implemented in a centralizedserver-client model, failing to leverage the benefits of decentralization.Tobridge this gap, we propose DFed-SST, a decentralized federated graph learningframework with adaptive communication. The core of our method is adual-topology adaptive communication mechanism that leverages the uniquetopological features of each client's local subgraph to dynamically constructand optimize the inter-client communication topology. This allows our frameworkto guide model aggregation efficiently in the face of heterogeneity. Extensiveexperiments on eight real-world datasets consistently demonstrate thesuperiority of DFed-SST, achieving 3.26% improvement in average accuracy overbaseline methods.</description><author>Lianshuai Guo, Zhongzheng Yuan, Xunkai Li, Yinlin Zhu, Meixia Qu, Wenyu Wang</author><pubDate>Fri, 15 Aug 2025 15:15:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11530v1</guid></item><item><title>A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow</title><link>http://arxiv.org/abs/2508.11529v1</link><description>Artificial intelligence is reshaping science and industry, yet many usersstill regard its models as opaque "black boxes". Conventional explainableartificial-intelligence methods clarify individual predictions but overlook theupstream decisions and downstream quality checks that determine whetherinsights can be trusted. In this work, we present Holistic ExplainableArtificial Intelligence (HXAI), a user-centric framework that embedsexplanation into every stage of the data-analysis workflow and tailors thoseexplanations to users. HXAI unifies six components (data, analysis set-up,learning process, model output, model quality, communication channel) into asingle taxonomy and aligns each component with the needs of domain experts,data analysts and data scientists. A 112-item question bank covers these needs;our survey of contemporary tools highlights critical coverage gaps. Grounded intheories of human explanation, principles from human-computer interaction andfindings from empirical user studies, HXAI identifies the characteristics thatmake explanations clear, actionable and cognitively manageable. A comprehensivetaxonomy operationalises these insights, reducing terminological ambiguity andenabling rigorous coverage analysis of existing toolchains. We furtherdemonstrate how AI agents that embed large-language models can orchestratediverse explanation techniques, translating technical artifacts intostakeholder-specific narratives that bridge the gap between AI developers anddomain experts. Departing from traditional surveys or perspective articles,this work melds concepts from multiple disciplines, lessons from real-worldprojects and a critical synthesis of the literature to advance a novel,end-to-end viewpoint on transparency, trustworthiness and responsible AIdeployment.</description><author>George Paterakis, Andrea Castellani, George Papoutsoglou, Tobias Rodemann, Ioannis Tsamardinos</author><pubDate>Fri, 15 Aug 2025 15:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11529v1</guid></item><item><title>Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series</title><link>http://arxiv.org/abs/2508.11528v1</link><description>We propose an unsupervised anomaly detection approach based on aphysics-informed diffusion model for multivariate time series data. Over thepast years, diffusion model has demonstrated its effectiveness in forecasting,imputation, generation, and anomaly detection in the time series domain. Inthis paper, we present a new approach for learning the physics-dependenttemporal distribution of multivariate time series data using a weightedphysics-informed loss during diffusion model training. A weightedphysics-informed loss is constructed using a static weight schedule. Thisapproach enables a diffusion model to accurately approximate underlying datadistribution, which can influence the unsupervised anomaly detectionperformance. Our experiments on synthetic and real-world datasets show thatphysics-informed training improves the F1 score in anomaly detection; itgenerates better data diversity and log-likelihood. Our model outperformsbaseline approaches, additionally, it surpasses prior physics-informed work andpurely data-driven diffusion models on a synthetic dataset and one real-worlddataset while remaining competitive on others.</description><author>Juhi Soni, Markus Lange-Hegermann, Stefan Windmann</author><pubDate>Fri, 15 Aug 2025 15:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11528v1</guid></item><item><title>Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models</title><link>http://arxiv.org/abs/2508.11524v1</link><description>Addressing large-scale planning problems has become one of the centralchallenges in the planning community, deriving from the state-space explosioncaused by growing objects and actions. Recently, researchers have explored theeffectiveness of leveraging Large Language Models (LLMs) to generate helpfulactions and states to prune the search space. However, prior works have largelyoverlooked integrating LLMs with domain-specific knowledge to ensure validplans. In this paper, we propose a novel LLM-assisted planner integrated withproblem decomposition, which first decomposes large planning problems intomultiple simpler sub-tasks. Then we explore two novel paradigms to utilizeLLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, whereLLM4Inspire provides heuristic guidance according to general knowledge andLLM4Predict employs domain-specific knowledge to infer intermediate conditions.We empirically validate the effectiveness of our planner across multipledomains, demonstrating the ability of search space partition when solvinglarge-scale planning problems. The experimental results show that LLMseffectively locate feasible solutions when pruning the search space, whereinfusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holdsparticular promise compared with LLM4Inspire, which offers general knowledgewithin LLMs.</description><author>Wenkai Yu, Jianhang Tang, Yang Zhang, Shanjiang Tang, Kebing Jin, Hankz Hankui Zhuo</author><pubDate>Fri, 15 Aug 2025 15:08:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11524v1</guid></item><item><title>Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry</title><link>http://arxiv.org/abs/2508.09991v2</link><description>Automating data extraction from clinical documents offers significantpotential to improve efficiency in healthcare settings, yet deploying NaturalLanguage Processing (NLP) solutions presents practical challenges. Drawing uponour experience implementing various NLP models for information extraction andclassification tasks at the British Columbia Cancer Registry (BCCR), this papershares key lessons learned throughout the project lifecycle. We emphasize thecritical importance of defining problems based on clear business objectivesrather than solely technical accuracy, adopting an iterative approach todevelopment, and fostering deep interdisciplinary collaboration and co-designinvolving domain experts, end-users, and ML specialists from inception. Furtherinsights highlight the need for pragmatic model selection (including hybridapproaches and simpler methods where appropriate), rigorous attention to dataquality (representativeness, drift, annotation), robust error mitigationstrategies involving human-in-the-loop validation and ongoing audits, andbuilding organizational AI literacy. These practical considerations,generalizable beyond cancer registries, provide guidance for healthcareorganizations seeking to successfully implement AI/NLP solutions to enhancedata management processes and ultimately improve patient care and public healthoutcomes.</description><author>Lovedeep Gondara, Gregory Arbour, Raymond Ng, Jonathan Simkin, Shebnum Devji</author><pubDate>Fri, 15 Aug 2025 15:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.09991v2</guid></item><item><title>Finite-Width Neural Tangent Kernels from Feynman Diagrams</title><link>http://arxiv.org/abs/2508.11522v1</link><description>Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,non-linear neural networks. In the infinite-width limit, NTKs can easily becomputed for most common architectures, yielding full analytic control over thetraining dynamics. However, at infinite width, important properties of trainingsuch as NTK evolution or feature learning are absent. Nevertheless, finitewidth effects can be included by computing corrections to the Gaussianstatistics at infinite width. We introduce Feynman diagrams for computingfinite-width corrections to NTK statistics. These dramatically simplify thenecessary algebraic manipulations and enable the computation of layer-wiserecursive relations for arbitrary statistics involving preactivations, NTKs andcertain higher-derivative tensors (dNTK and ddNTK) required to predict thetraining dynamics at leading order. We demonstrate the feasibility of ourframework by extending stability results for deep networks from preactivationsto NTKs and proving the absence of finite-width corrections for scale-invariantnonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. Wevalidate our results with numerical experiments.</description><author>Max Guillen, Philipp Misof, Jan E. Gerken</author><pubDate>Fri, 15 Aug 2025 15:02:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11522v1</guid></item><item><title>A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11</title><link>http://arxiv.org/abs/2508.11517v1</link><description>Accelerated aging of transportation infrastructure in the rapidly developingYangtze River Delta region necessitates efficient concrete crack detection, ascrack deterioration critically compromises structural integrity and regionaleconomic growth. To overcome the limitations of inefficient manual inspectionand the suboptimal performance of existing deep learning models, particularlyfor small-target crack detection within complex backgrounds, this paperproposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection andsegmentation model based on the YOLOv11n architecture. The proposed modelintegrates a three-stage optimization framework: (1) Embedding dynamicKernelWarehouse convolution (KWConv) within the backbone network to enhancefeature representation through a dynamic kernel sharing mechanism; (2)Incorporating a triple attention mechanism (TA) into the feature pyramid tostrengthen channel-spatial interaction modeling; and (3) Designing an FP-IoUloss function to facilitate adaptive bounding box regression penalization.Experimental validation demonstrates that the enhanced model achievessignificant performance improvements over the baseline, attaining 91.3%precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm thesynergistic efficacy of the proposed modules. Furthermore, robustness testsindicate stable performance under conditions of data scarcity and noiseinterference. This research delivers an efficient computer vision solution forautomated infrastructure inspection, exhibiting substantial practicalengineering value.</description><author>Shaoze Huang, Qi Liu, Chao Chen, Yuhang Chen</author><pubDate>Fri, 15 Aug 2025 14:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11517v1</guid></item><item><title>Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations</title><link>http://arxiv.org/abs/2508.11515v1</link><description>The Weighted First-Order Model Counting Problem (WFOMC) asks to compute theweighted sum of models of a given first-order logic sentence over a givendomain. The boundary between fragments for which WFOMC can be computed inpolynomial time relative to the domain size lies between the two-variablefragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It isknown that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-timealgorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$,possibly extended by certain axioms such as the linear order axiom, theacyclicity axiom, and the connectedness axiom. All existing research hasconcentrated on extending the fragment with axioms on a single distinguishedrelation, leaving a gap in understanding the complexity boundary of axioms onmultiple relations. In this study, we explore the extension of the two-variablefragment by axioms on two relations, presenting both negative and positiveresults. We show that WFOMC for $\text{FO}^2$ with two linear order relationsand $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard.Conversely, we provide an algorithm in time polynomial in the domain size forWFOMC of $\text{C}^2$ with a linear order relation, its successor relation andanother successor relation.</description><author>Qipeng Kuang, Václav Kůla, Ondřej Kuželka, Yuanhong Wang, Yuyi Wang</author><pubDate>Fri, 15 Aug 2025 14:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11515v1</guid></item><item><title>DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality</title><link>http://arxiv.org/abs/2508.11514v1</link><description>The growing deployment of decision-making agents in dynamic environmentsincreases the demand for safety verification. While critical testing scenariogeneration has emerged as an appealing verification methodology, effectivelybalancing diversity and criticality remains a key challenge for existingmethods, particularly due to local optima entrapment in high-dimensionalscenario spaces. To address this limitation, we propose a dual-space guidedtesting framework that coordinates scenario parameter space and agent behaviorspace, aiming to generate testing scenarios considering diversity andcriticality. Specifically, in the scenario parameter space, a hierarchicalrepresentation framework combines dimensionality reduction andmulti-dimensional subspace evaluation to efficiently localize diverse andcritical subspaces. This guides dynamic coordination between two generationmodes: local perturbation and global exploration, optimizing critical scenarioquantity and diversity. Complementarily, in the agent behavior space,agent-environment interaction data are leveraged to quantify behavioralcriticality/diversity and adaptively support generation mode switching, forminga closed feedback loop that continuously enhances scenario characterization andexploration within the parameter space. Experiments show our framework improvescritical scenario generation by an average of 56.23\% and demonstrates greaterdiversity under novel parameter-behavior co-driven metrics when tested on fivedecision-making agents, outperforming state-of-the-art baselines.</description><author>Qitong Chu, Yufeng Yue, Danya Yao, Huaxin Pei</author><pubDate>Fri, 15 Aug 2025 14:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11514v1</guid></item><item><title>3D Whole-body Grasp Synthesis with Directional Controllability</title><link>http://arxiv.org/abs/2408.16770v2</link><description>Synthesizing 3D whole bodies that realistically grasp objects is useful foranimation, mixed reality, and robotics. This is challenging, because the handsand body need to look natural w.r.t. each other, the grasped object, as well asthe local scene (i.e., a receptacle supporting the object). Moreover, trainingdata for this task is really scarce, while capturing new data is expensive.Recent work goes beyond finite datasets via a divide-and-conquer approach; itfirst generates a "guiding" right-hand grasp, and then searches for bodies thatmatch this. However, the guiding-hand synthesis lacks controllability andreceptacle awareness, so it likely has an implausible direction (i.e., a bodycan't match this without penetrating the receptacle) and needs correctionsthrough major post-processing. Moreover, the body search needs exhaustivesampling and is expensive. These are strong limitations. We tackle these with anovel method called CWGrasp. Our key idea is that performing geometry-basedreasoning "early on," instead of "too late," provides rich "control" signalsfor inference. To this end, CWGrasp first samples a plausiblereaching-direction vector (used later for both the arm and hand) from aprobabilistic model built via ray-casting from the object and collisionchecking. Moreover, CWGrasp uniquely tackles both right and left-hand grasps.We evaluate on the GRAB and ReplicaGrasp datasets. CWGrasp outperformsbaselines, at lower runtime and budget, while all components help performance.Code and models are available at https://gpaschalidis.github.io/cwgrasp.</description><author>Georgios Paschalidis, Romana Wilschut, Dimitrije Antić, Omid Taheri, Dimitrios Tzionas</author><pubDate>Mon, 17 Feb 2025 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16770v2</guid></item><item><title>Diffusion Models without Classifier-free Guidance</title><link>http://arxiv.org/abs/2502.12154v1</link><description>This paper presents Model-guidance (MG), a novel objective for trainingdiffusion model that addresses and removes of the commonly used Classifier-freeguidance (CFG). Our innovative approach transcends the standard modeling ofsolely data distribution to incorporating the posterior probability ofconditions. The proposed technique originates from the idea of CFG and is easyyet effective, making it a plug-and-play module for existing models. Our methodsignificantly accelerates the training process, doubles the inference speed,and achieve exceptional quality that parallel and even surpass concurrentdiffusion models with CFG. Extensive experiments demonstrate the effectiveness,efficiency, scalability on different models and datasets. Finally, we establishstate-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.Our code is available at https://github.com/tzco/Diffusion-wo-CFG.</description><author>Zhicong Tang, Jianmin Bao, Dong Chen, Baining Guo</author><pubDate>Mon, 17 Feb 2025 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12154v1</guid></item><item><title>Learning Getting-Up Policies for Real-World Humanoid Robots</title><link>http://arxiv.org/abs/2502.12152v1</link><description>Automatic fall recovery is a crucial prerequisite before humanoid robots canbe reliably deployed. Hand-designing controllers for getting up is difficultbecause of the varied configurations a humanoid can end up in after a fall andthe challenging terrains humanoid robots are expected to operate on. This paperdevelops a learning framework to produce controllers that enable humanoidrobots to get up from varying configurations on varying terrains. Unlikeprevious successful applications of humanoid locomotion learning, thegetting-up task involves complex contact patterns, which necessitatesaccurately modeling the collision geometry and sparser rewards. We addressthese challenges through a two-phase approach that follows a curriculum. Thefirst stage focuses on discovering a good getting-up trajectory under minimalconstraints on smoothness or speed / torque limits. The second stage thenrefines the discovered motions into deployable (i.e. smooth and slow) motionsthat are robust to variations in initial configuration and terrains. We findthese innovations enable a real-world G1 humanoid robot to get up from two mainsituations that we considered: a) lying face up and b) lying face down, bothtested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grassand snowfield). To the best of our knowledge, this is the first successfuldemonstration of learned getting-up policies for human-sized humanoid robots inthe real world. Project page: https://humanoid-getup.github.io/</description><author>Xialin He, Runpei Dong, Zixuan Chen, Saurabh Gupta</author><pubDate>Mon, 17 Feb 2025 18:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12152v1</guid></item><item><title>VoLUT: Efficient Volumetric streaming enhanced by LUT-based super-resolution</title><link>http://arxiv.org/abs/2502.12151v1</link><description>3D volumetric video provides immersive experience and is gaining traction indigital media. Despite its rising popularity, the streaming of volumetric videocontent poses significant challenges due to the high data bandwidthrequirement. A natural approach to mitigate the bandwidth issue is to reducethe volumetric video's data rate by downsampling the content prior totransmission. The video can then be upsampled at the receiver's end using asuper-resolution (SR) algorithm to reconstruct the high-resolution details.While super-resolution techniques have been extensively explored and advancedfor 2D video content, there is limited work on SR algorithms tailored forvolumetric videos. To address this gap and the growing need for efficient volumetric videostreaming, we have developed VoLUT with a new SR algorithm specificallydesigned for volumetric content. Our algorithm uniquely harnesses the power oflookup tables (LUTs) to facilitate the efficient and accurate upscaling oflow-resolution volumetric data. The use of LUTs enables our algorithm toquickly reference precomputed high-resolution values, thereby significantlyreducing the computational complexity and time required for upscaling. Wefurther apply adaptive video bit rate algorithm (ABR) to dynamically determinethe downsampling rate according to the network condition and stream theselected video rate to the receiver. Compared to related work, VoLUT is thefirst to enable high-quality 3D SR on commodity mobile devices at line-rate.Our evaluation shows VoLUT can reduce bandwidth usage by 70% , boost QoE by36.7% for volumetric video streaming and achieve 3D SR speed-up with no quality compromise.</description><author>Chendong Wang, Anlan Zhang, Yifan Yang, Lili Qiu, Yuqing Yang, Xinyang Jiang, Feng Qian, Suman Banerjee</author><pubDate>Mon, 17 Feb 2025 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12151v1</guid></item><item><title>Idiosyncrasies in Large Language Models</title><link>http://arxiv.org/abs/2502.12150v1</link><description>In this work, we unveil and study idiosyncrasies in Large Language Models(LLMs) -- unique patterns in their outputs that can be used to distinguish themodels. To do so, we consider a simple classification task: given a particulartext output, the objective is to predict the source LLM that generates thetext. We evaluate this synthetic task across various groups of LLMs and findthat simply fine-tuning existing text embedding models on LLM-generated textsyields excellent classification accuracy. Notably, we achieve 97.1% accuracy onheld-out validation data in the five-way classification problem involvingChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation revealsthat these idiosyncrasies are rooted in word-level distributions. Thesepatterns persist even when the texts are rewritten, translated, or summarizedby an external LLM, suggesting that they are also encoded in the semanticcontent. Additionally, we leverage LLM as judges to generate detailed,open-ended descriptions of each model's idiosyncrasies. Finally, we discuss thebroader implications of our findings, particularly for training on syntheticdata and inferring model similarity. Code is available athttps://github.com/locuslab/llm-idiosyncrasies.</description><author>Mingjie Sun, Yida Yin, Zhiqiu Xu, J. Zico Kolter, Zhuang Liu</author><pubDate>Mon, 17 Feb 2025 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12150v1</guid></item><item><title>HARBOR: Exploring Persona Dynamics in Multi-Agent Competition</title><link>http://arxiv.org/abs/2502.12149v1</link><description>We investigate factors contributing to LLM agents' success in competitivemulti-agent environments, using auctions as a testbed where agents bid tomaximize profit. The agents are equipped with bidding domain knowledge,distinct personas that reflect item preferences, and a memory of auctionhistory. Our work extends the classic auction scenario by creating a realisticenvironment where multiple agents bid on houses, weighing aspects such as size,location, and budget to secure the most desirable homes at the lowest prices.Particularly, we investigate three key questions: (a) How does a personainfluence an agent's behavior in a competitive setting? (b) Can an agenteffectively profile its competitors' behavior during auctions? (c) How canpersona profiling be leveraged to create an advantage using strategies such astheory of mind? Through a series of experiments, we analyze the behaviors ofLLM agents and shed light on new findings. Our testbed, called HARBOR, offers avaluable platform for deepening our understanding of multi-agent workflows incompetitive environments.</description><author>Kenan Jiang, Li Xiong, Fei Liu</author><pubDate>Mon, 17 Feb 2025 18:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12149v1</guid></item><item><title>HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2502.12148v1</link><description>The remarkable success of the autoregressive paradigm has made significantadvancement in Multimodal Large Language Models (MLLMs), with powerful modelslike Show-o, Transfusion and Emu3 achieving notable progress in unified imageunderstanding and generation. For the first time, we uncover a commonphenomenon: the understanding capabilities of MLLMs are typically stronger thantheir generative capabilities, with a significant gap between the two. Buildingon this insight, we propose HermesFlow, a simple yet general framework designedto seamlessly bridge the gap between understanding and generation in MLLMs.Specifically, we take the homologous data as input to curate homologouspreference data of both understanding and generation. Through Pair-DPO andself-play iterative optimization, HermesFlow effectively aligns multimodalunderstanding and generation using homologous preference data. Extensiveexperiments demonstrate the significant superiority of our approach over priormethods, particularly in narrowing the gap between multimodal understanding andgeneration. These findings highlight the potential of HermesFlow as a generalalignment framework for next-generation multimodal foundation models. Code:https://github.com/Gen-Verse/HermesFlow</description><author>Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui</author><pubDate>Mon, 17 Feb 2025 18:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12148v1</guid></item><item><title>Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction</title><link>http://arxiv.org/abs/2502.12147v1</link><description>Machine learning interatomic potentials (MLIPs) have become increasinglyeffective at approximating quantum mechanical calculations at a fraction of thecomputational cost. However, lower errors on held out test sets do not alwaystranslate to improved results on downstream physical property prediction tasks.In this paper, we propose testing MLIPs on their practical ability to conserveenergy during molecular dynamic simulations. If passed, improved correlationsare found between test errors and their performance on physical propertyprediction tasks. We identify choices which may lead to models failing thistest, and use these observations to improve upon highly-expressive models. Theresulting model, eSEN, provides state-of-the-art results on a range of physicalproperty prediction tasks, including materials stability prediction, thermalconductivity prediction, and phonon calculations.</description><author>Xiang Fu, Brandon M. Wood, Luis Barroso-Luque, Daniel S. Levine, Meng Gao, Misko Dzamba, C. Lawrence Zitnick</author><pubDate>Mon, 17 Feb 2025 18:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12147v1</guid></item><item><title>Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening</title><link>http://arxiv.org/abs/2502.12146v1</link><description>We propose Diffusion-Sharpening, a fine-tuning approach that enhancesdownstream alignment by optimizing sampling trajectories. Existing RL-basedfine-tuning methods focus on single training timesteps and neglecttrajectory-level alignment, while recent sampling trajectory optimizationmethods incur significant inference NFE costs. Diffusion-Sharpening overcomesthis by using a path integral framework to select optimal trajectories duringtraining, leveraging reward feedback, and amortizing inference costs. Ourmethod demonstrates superior training efficiency with faster convergence, andbest inference efficiency without requiring additional NFEs. Extensiveexperiments show that Diffusion-Sharpening outperforms RL-based fine-tuningmethods (e.g., Diffusion-DPO) and sampling trajectory optimization methods(e.g., Inference Scaling) across diverse metrics including text alignment,compositional capabilities, and human preferences, offering a scalable andefficient solution for future diffusion model fine-tuning. Code:https://github.com/Gen-Verse/Diffusion-Sharpening</description><author>Ye Tian, Ling Yang, Xinchen Zhang, Yunhai Tong, Mengdi Wang, Bin Cui</author><pubDate>Mon, 17 Feb 2025 18:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12146v1</guid></item><item><title>Logical forms complement probability in understanding language model (and human) performance</title><link>http://arxiv.org/abs/2502.09589v2</link><description>With the increasing interest in using large language models (LLMs) forplanning in natural language, understanding their behaviors becomes animportant research question. This work conducts a systematic investigation ofLLMs' ability to perform logical reasoning in natural language. We introduce acontrolled dataset of hypothetical and disjunctive syllogisms in propositionaland modal logic and use it as the testbed for understanding LLM performance.Our results lead to novel insights in predicting LLM behaviors: in addition tothe probability of input (Gonen et al., 2023; McCoy et al., 2024), logicalforms should be considered as important factors. In addition, we showsimilarities and discrepancies between the logical reasoning performances ofhumans and LLMs by collecting and comparing behavioral data from both.</description><author>Yixuan Wang, Freda Shi</author><pubDate>Mon, 17 Feb 2025 18:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09589v2</guid></item><item><title>Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented Generation with Flexible User Control</title><link>http://arxiv.org/abs/2502.12145v1</link><description>Retrieval-Augmented Generation (RAG) has emerged as a powerful approach tomitigate large language model (LLM) hallucinations by incorporating externalknowledge retrieval. However, existing RAG frameworks often apply retrievalindiscriminately,leading to inefficiencies-over-retrieving when unnecessary orfailing to retrieve iteratively when required for complex reasoning. Recentadaptive retrieval strategies, though adaptively navigates these retrievalstrategies, predict only based on query complexity and lacks user-drivenflexibility, making them infeasible for diverse user application needs. In thispaper, we introduce a novel user-controllable RAG framework that enablesdynamic adjustment of the accuracy-cost trade-off. Our approach leverages twoclassifiers: one trained to prioritize accuracy and another to prioritizeretrieval efficiency. Via an interpretable control parameter $\alpha$, userscan seamlessly navigate between minimal-cost retrieval and high-accuracyretrieval based on their specific requirements. We empirically demonstrate thatour approach effectively balances accuracy, retrieval cost, and usercontrollability, making it a practical and adaptable solution for real-worldapplications.</description><author>Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie</author><pubDate>Mon, 17 Feb 2025 18:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12145v1</guid></item><item><title>Small Models Struggle to Learn from Strong Reasoners</title><link>http://arxiv.org/abs/2502.12143v1</link><description>Large language models (LLMs) excel in complex reasoning tasks, and distillingtheir reasoning capabilities into smaller models has shown promise. However, weuncover an interesting phenomenon, which we term the Small Model LearnabilityGap: small models ($\leq$3B parameters) do not consistently benefit from longchain-of-thought (CoT) reasoning or distillation from larger models. Instead,they perform better when fine-tuned on shorter, simpler reasoning chains thatbetter align with their intrinsic learning capacity. To address this, wepropose Mix Distillation, a simple yet effective strategy that balancesreasoning complexity by combining long and short CoT examples or reasoning fromboth larger and smaller models. Our experiments demonstrate that MixDistillation significantly improves small model reasoning performance comparedto training on either data alone. These findings highlight the limitations ofdirect strong model distillation and underscore the importance of adaptingreasoning complexity for effective reasoning capability transfer.</description><author>Yuetai Li, Xiang Yue, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Bhaskar Ramasubramanian, Radha Poovendran</author><pubDate>Mon, 17 Feb 2025 18:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12143v1</guid></item><item><title>MaLei at the PLABA Track of TREC 2024: RoBERTa for Term Replacement -- LLaMA3.1 and GPT-4o for Complete Abstract Adaptation</title><link>http://arxiv.org/abs/2411.07381v4</link><description>This report is the system description of the MaLei team (Manchester andLeiden) for the shared task Plain Language Adaptation of Biomedical Abstracts(PLABA) 2024 (we had an earlier name BeeManc following last year), affiliatedwith TREC2024 (33rd Text REtrieval Conferencehttps://ir.nist.gov/evalbase/conf/trec-2024). This report contains two sectionscorresponding to the two sub-tasks in PLABA-2024. In task one (termreplacement), we applied fine-tuned ReBERTa-Base models to identify andclassify the difficult terms, jargon, and acronyms in the biomedical abstractsand reported the F1 score (Task 1A and 1B). In task two (complete abstractadaptation), we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shotprompts to complete the abstract adaptation and reported the scores in BLEU,SARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024on Task 1A and 1B, our much smaller fine-tuned RoBERTa-Base model ranked 3rdand 2nd respectively on the two sub-tasks, and the 1st on averaged F1 scoresacross the two tasks from 9 evaluated systems. Our LLaMA-3.1-70B-instructedmodel achieved the highest Completeness score for Task 2. We share our sourcecodes, fine-tuned models, and related resources athttps://github.com/HECTA-UoM/PLABA2024</description><author>Zhidong Ling, Zihao Li, Pablo Romero, Lifeng Han, Goran Nenadic</author><pubDate>Mon, 17 Feb 2025 18:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07381v4</guid></item><item><title>FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views</title><link>http://arxiv.org/abs/2502.12138v1</link><description>We present FLARE, a feed-forward model designed to infer high-quality cameraposes and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8inputs), which is a challenging yet practical setting in real-worldapplications. Our solution features a cascaded learning paradigm with camerapose serving as the critical bridge, recognizing its essential role in mapping3D structures onto 2D image planes. Concretely, FLARE starts with camera poseestimation, whose results condition the subsequent learning of geometricstructure and appearance, optimized through the objectives of geometryreconstruction and novel-view synthesis. Utilizing large-scale public datasetsfor training, our method delivers state-of-the-art performance in the tasks ofpose estimation, geometry reconstruction, and novel view synthesis, whilemaintaining the inference efficiency (i.e., less than 0.5 seconds). The projectpage and code can be found at: https://zhanghe3z.github.io/FLARE/</description><author>Shangzhan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein</author><pubDate>Mon, 17 Feb 2025 18:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12138v1</guid></item><item><title>REVERSUM: A Multi-staged Retrieval-Augmented Generation Method to Enhance Wikipedia Tail Biographies through Personal Narratives</title><link>http://arxiv.org/abs/2502.12137v1</link><description>Wikipedia is an invaluable resource for factual information about a widerange of entities. However, the quality of articles on less-known entitiesoften lags behind that of the well-known ones. This study proposes a novelapproach to enhancing Wikipedia's B and C category biography articles byleveraging personal narratives such as autobiographies and biographies. Byutilizing a multi-staged retrieval-augmented generation technique -- REVerSum-- we aim to enrich the informational content of these lesser-known articles.Our study reveals that personal narratives can significantly improve thequality of Wikipedia articles, providing a rich source of reliable informationthat has been underutilized in previous studies. Based on crowd-basedevaluation, REVerSum generated content outperforms the best performing baselineby 17% in terms of integrability to the original Wikipedia article and 28.5\%in terms of informativeness. Code and Data are available at:https://github.com/sayantan11995/wikipedia_enrichment</description><author>Sayantan Adak, Pauras Mangesh Meher, Paramita Das, Animesh Mukherjee</author><pubDate>Mon, 17 Feb 2025 18:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12137v1</guid></item><item><title>MagicArticulate: Make Your 3D Models Articulation-Ready</title><link>http://arxiv.org/abs/2502.12135v1</link><description>With the explosive growth of 3D content creation, there is an increasingdemand for automatically converting static 3D models into articulation-readyversions that support realistic animation. Traditional approaches rely heavilyon manual annotation, which is both time-consuming and labor-intensive.Moreover, the lack of large-scale benchmarks has hindered the development oflearning-based solutions. In this work, we present MagicArticulate, aneffective framework that automatically transforms static 3D models intoarticulation-ready assets. Our key contributions are threefold. First, weintroduce Articulation-XL, a large-scale benchmark containing over 33k 3Dmodels with high-quality articulation annotations, carefully curated fromObjaverse-XL. Second, we propose a novel skeleton generation method thatformulates the task as a sequence modeling problem, leveraging anauto-regressive transformer to naturally handle varying numbers of bones orjoints within skeletons and their inherent dependencies across different 3Dmodels. Third, we predict skinning weights using a functional diffusion processthat incorporates volumetric geodesic distance priors between vertices andjoints. Extensive experiments demonstrate that MagicArticulate significantlyoutperforms existing methods across diverse object categories, achievinghigh-quality articulation that enables realistic animation. Project page:https://chaoyuesong.github.io/MagicArticulate.</description><author>Chaoyue Song, Jianfeng Zhang, Xiu Li, Fan Yang, Yiwen Chen, Zhongcong Xu, Jun Hao Liew, Xiaoyang Guo, Fayao Liu, Jiashi Feng, Guosheng Lin</author><pubDate>Mon, 17 Feb 2025 18:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12135v1</guid></item><item><title>Splitting criteria for ordinal decision trees: an experimental study</title><link>http://arxiv.org/abs/2412.13697v2</link><description>Ordinal Classification (OC) is a machine learning field that addressesclassification tasks where the labels exhibit a natural order. Unlike nominalclassification, which treats all classes as equally distinct, OC takes theordinal relationship into account, producing more accurate and relevantresults. This is particularly critical in applications where the magnitude ofclassification errors has implications. Despite this, OC problems are oftentackled using nominal methods, leading to suboptimal solutions. Althoughdecision trees are one of the most popular classification approaches, ordinaltree-based approaches have received less attention when compared to otherclassifiers. This work conducts an experimental study of tree-basedmethodologies specifically designed to capture ordinal relationships. Acomprehensive survey of ordinal splitting criteria is provided, standardisingthe notations used in the literature for clarity. Three ordinal splittingcriteria, Ordinal Gini (OGini), Weighted Information Gain (WIG), and RankingImpurity (RI), are compared to the nominal counterparts of the first two (Giniand information gain), by incorporating them into a decision tree classifier.An extensive repository considering 45 publicly available OC datasets ispresented, supporting the first experimental comparison of ordinal and nominalsplitting criteria using well-known OC evaluation metrics. Statistical analysisof the results highlights OGini as the most effective ordinal splittingcriterion to date. Source code, datasets, and results are made available to theresearch community.</description><author>Rafael Ayllón-Gavilán, Francisco José Martínez-Estudillo, David Guijo-Rubio, César Hervás-Martínez, Pedro Antonio Gutiérrez</author><pubDate>Mon, 17 Feb 2025 18:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13697v2</guid></item><item><title>SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs</title><link>http://arxiv.org/abs/2502.12134v1</link><description>Chain-of-Thought (CoT) reasoning enables Large Language Models (LLMs) tosolve complex reasoning tasks by generating intermediate reasoning steps.However, most existing approaches focus on hard token decoding, whichconstrains reasoning within the discrete vocabulary space and may not always beoptimal. While recent efforts explore continuous-space reasoning, they oftensuffer from catastrophic forgetting, limiting their applicability tostate-of-the-art LLMs that already perform well in zero-shot settings with aproper instruction. To address this challenge, we propose a novel approach forcontinuous-space reasoning that does not require modifying the underlying LLM.Specifically, we employ a lightweight assistant model to generateinstance-specific soft thought tokens speculatively as the initial chain ofthoughts, which are then mapped into the LLM's representation space via aprojection module. Experimental results on five reasoning benchmarksdemonstrate that our method enhances LLM reasoning performance throughsupervised, parameter-efficient fine-tuning.</description><author>Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao</author><pubDate>Mon, 17 Feb 2025 18:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12134v1</guid></item><item><title>OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain</title><link>http://arxiv.org/abs/2412.13018v2</link><description>As a typical and practical application of Large Language Models (LLMs),Retrieval-Augmented Generation (RAG) techniques have gained extensiveattention, particularly in vertical domains where LLMs may lack domain-specificknowledge. In this paper, we introduce an omnidirectional and automatic RAGbenchmark, OmniEval, in the financial domain. Our benchmark is characterized byits multi-dimensional evaluation framework, including (1) a matrix-based RAGscenario evaluation system that categorizes queries into five task classes and16 financial topics, leading to a structured assessment of diverse queryscenarios; (2) a multi-dimensional evaluation data generation approach, whichcombines GPT-4-based automatic generation and human annotation, achieving an87.47\% acceptance ratio in human evaluations on generated instances; (3) amulti-stage evaluation system that evaluates both retrieval and generationperformance, result in a comprehensive evaluation on the RAG pipeline; and (4)robust evaluation metrics derived from rule-based and LLM-based ones, enhancingthe reliability of assessments through manual annotations and supervisedfine-tuning of an LLM evaluator. Our experiments demonstrate thecomprehensiveness of OmniEval, which includes extensive test datasets andhighlights the performance variations of RAG systems across diverse topics andtasks, revealing significant opportunities for RAG models to improve theircapabilities in vertical domains. We open source the code of our benchmark in\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.</description><author>Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen</author><pubDate>Mon, 17 Feb 2025 18:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13018v2</guid></item><item><title>Transformer Dynamics: A neuroscientific approach to interpretability of large language models</title><link>http://arxiv.org/abs/2502.12131v1</link><description>As artificial intelligence models have exploded in scale and capability,understanding of their internal mechanisms remains a critical challenge.Inspired by the success of dynamical systems approaches in neuroscience, herewe propose a novel framework for studying computations in deep learningsystems. We focus on the residual stream (RS) in transformer models,conceptualizing it as a dynamical system evolving across layers. We find thatactivations of individual RS units exhibit strong continuity across layers,despite the RS being a non-privileged basis. Activations in the RS accelerateand grow denser over layers, while individual units trace unstable periodicorbits. In reduced-dimensional spaces, the RS follows a curved trajectory withattractor-like dynamics in the lower layers. These insights bridge dynamicalsystems theory and mechanistic interpretability, establishing a foundation fora "neuroscience of AI" that combines theoretical rigor with large-scale dataanalysis to advance our understanding of modern neural networks.</description><author>Jesseba Fernando, Grigori Guitchounts</author><pubDate>Mon, 17 Feb 2025 18:49:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12131v1</guid></item><item><title>Scaling Autonomous Agents via Automatic Reward Modeling And Planning</title><link>http://arxiv.org/abs/2502.12130v1</link><description>Large language models (LLMs) have demonstrated remarkable capabilities acrossa range of text-generation tasks. However, LLMs still struggle with problemsrequiring multi-step decision-making and environmental feedback, such as onlineshopping, scientific reasoning, and mathematical problem-solving. Unlike puretext data, collecting large-scale decision-making data is challenging.Moreover, many powerful LLMs are only accessible through APIs, which hinderstheir fine-tuning for agent tasks due to cost and complexity. To address LLMagents' limitations, we propose a framework that can automatically learn areward model from the environment without human annotations. This model can beused to evaluate the action trajectories of LLM agents and provide heuristicsfor task planning. Specifically, our approach involves employing one LLM-basedagent to navigate an environment randomly, generating diverse actiontrajectories. Subsequently, a separate LLM is leveraged to assign a task intentand synthesize a negative response alongside the correct response for eachtrajectory. These triplets (task intent, positive response, and negativeresponse) are then utilized as training data to optimize a reward model capableof scoring action trajectories. The effectiveness and generalizability of ourframework are demonstrated through evaluations conducted on different agentbenchmarks. In conclusion, our proposed framework represents a significantadvancement in enhancing LLM agents' decision-making capabilities. Byautomating the learning of reward models, we overcome the challenges of datascarcity and API limitations, potentially revolutionizing the application ofLLMs in complex and interactive environments. This research paves the way formore sophisticated AI agents capable of tackling a wide range of real-worldproblems requiring multi-step decision-making.</description><author>Zhenfang Chen, Delin Chen, Rui Sun, Wenjun Liu, Chuang Gan</author><pubDate>Mon, 17 Feb 2025 18:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12130v1</guid></item><item><title>LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities</title><link>http://arxiv.org/abs/2502.12128v1</link><description>Generative models are spearheading recent progress in deep learning, showingstrong promise for trajectory sampling in dynamical systems as well. However,while latent space modeling paradigms have transformed image and videogeneration, similar approaches are more difficult for most dynamical systems.Such systems -- from chemical molecule structures to collective human behavior-- are described by interactions of entities, making them inherently linked toconnectivity patterns and the traceability of entities over time. Our approach,LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via LinkedEntities), combines the advantages of graph neural networks, i.e., thetraceability of entities across time-steps, with the efficiency and scalabilityof recent advances in image and video generation, where pre-trained encoder anddecoder are frozen to enable generative modeling in the latent space. The coreidea of LaM-SLidE is to introduce identifier representations (IDs) to allow forretrieval of entity properties, e.g., entity coordinates, from latent systemrepresentations and thus enables traceability. Experimentally, across differentdomains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,and generalizability. (Code is available athttps://github.com/ml-jku/LaM-SLidE)</description><author>Florian Sestak, Artur Toshev, Andreas Fürst, Günter Klambauer, Andreas Mayr, Johannes Brandstetter</author><pubDate>Mon, 17 Feb 2025 18:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12128v1</guid></item><item><title>Human-LLM Coevolution: Evidence from Academic Writing</title><link>http://arxiv.org/abs/2502.09606v2</link><description>With a statistical analysis of arXiv paper abstracts, we report a marked dropin the frequency of several words previously identified as overused by ChatGPT,such as "delve", starting soon after they were pointed out in early 2024. Thefrequency of certain other words favored by ChatGPT, such as "significant", hasinstead kept increasing. These phenomena suggest that some authors of academicpapers have adapted their use of large language models (LLMs), for example, byselecting outputs or applying modifications to the LLM-generated content. Suchcoevolution and cooperation of humans and LLMs thus introduce additionalchallenges to the detection of machine-generated text in real-world scenarios.Estimating the impact of LLMs on academic writing by examining word frequencyremains feasible, and more attention should be paid to words that were alreadyfrequently employed, including those that have decreased in frequency due toLLMs' disfavor.</description><author>Mingmeng Geng, Roberto Trotta</author><pubDate>Mon, 17 Feb 2025 18:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09606v2</guid></item><item><title>The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes</title><link>http://arxiv.org/abs/2405.20582v2</link><description>Negative patient descriptions and stigmatizing language can contribute togenerating healthcare disparities in two ways: (1) read by patients, they canharm their trust and engagement with the medical center; (2) read byphysicians, they may negatively influence their perspective of a futurepatient. In psychiatry, the patient-clinician therapeutic alliance is a majordeterminant of clinical outcomes. Therefore, language usage in psychiatricclinical notes may not only create healthcare disparities, but also perpetuatethem. Recent advances in NLP systems have facilitated the efforts to detectdiscriminatory language in healthcare. However, such attempts have only focusedon the perspectives of the medical center and its physicians. Considering bothphysicians and non-physicians' point of view is a more translatable approach toidentifying potentially harmful language in clinical notes. By leveragingpre-trained and large language models (PLMs and LLMs), this work aims tocharacterize potentially harmful language usage in psychiatric notes byidentifying the sentiment expressed in sentences describing patients based onthe reader's point of view. Extracting 39 sentences from the Mount Sinai HealthSystem containing psychiatric lexicon, we fine-tuned three PLMs (RoBERTa,GatorTron, and GatorTron + Task Adaptation) and implemented zero-shot andfew-shot ICL approaches for three LLMs (GPT-3.5, Llama-3.1, and Mistral) toclassify the sentiment of the sentences according to the physician ornon-physician point of view. Results showed that GPT-3.5 aligned best tophysician point of view and Mistral aligned best to non-physician point ofview. These results underline the importance of recognizing the reader's pointof view, not only for improving the note writing process, but also for thequantification, identification, and reduction of bias in computational systemsfor downstream analyses.</description><author>Alissa A. Valentine, Lauren A. Lepow, Lili Chan, Alexander W. Charney, Isotta Landi</author><pubDate>Mon, 17 Feb 2025 18:48:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20582v2</guid></item><item><title>Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens of Class Hierarchy</title><link>http://arxiv.org/abs/2502.12125v1</link><description>We investigate the training dynamics of deep classifiers by examining howhierarchical relationships between classes evolve during training. Throughextensive experiments, we argue that the learning process in classificationproblems can be understood through the lens of label clustering. Specifically,we observe that networks tend to distinguish higher-level (hypernym) categoriesin the early stages of training, and learn more specific (hyponym) categorieslater. We introduce a novel framework to track the evolution of the featuremanifold during training, revealing how the hierarchy of class relationsemerges and refines across the network layers. Our analysis demonstrates thatthe learned representations closely align with the semantic structure of thedataset, providing a quantitative description of the clustering process.Notably, we show that in the hypernym label space, certain properties of neuralcollapse appear earlier than in the hyponym label space, helping to bridge thegap between the initial and terminal phases of learning. We believe ourfindings offer new insights into the mechanisms driving hierarchical learningin deep networks, paving the way for future advancements in understanding deeplearning dynamics.</description><author>Roman Malashin, Valeria Yachnaya, Alexander Mullin</author><pubDate>Mon, 17 Feb 2025 18:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12125v1</guid></item><item><title>RA-MTR: A Retrieval Augmented Multi-Task Reader based Approach for Inspirational Quote Extraction from Long Documents</title><link>http://arxiv.org/abs/2502.12124v1</link><description>Inspirational quotes from famous individuals are often used to conveythoughts in news articles, essays, and everyday conversations. In this paper,we propose a novel context-based quote extraction system that aims to extractthe most relevant quote from a long text. We formulate this quote extraction asan open domain question answering problem first by employing a vector-storebased retriever and then applying a multi-task reader. We curate threecontext-based quote extraction datasets and introduce a novel multi-taskframework RA-MTR that improves the state-of-the-art performance, achieving amaximum improvement of 5.08% in BoW F1-score.</description><author>Sayantan Adak, Animesh Mukherjee</author><pubDate>Mon, 17 Feb 2025 18:46:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12124v1</guid></item><item><title>On the Query Complexity of Verifier-Assisted Language Generation</title><link>http://arxiv.org/abs/2502.12123v1</link><description>Recently, a plethora of works have proposed inference-time algorithms (e.g.best-of-n), which incorporate verifiers to assist the generation process. Theirquality-efficiency trade-offs have been empirically benchmarked on a variety ofconstrained generation tasks, but the algorithmic design landscape is stilllargely poorly understood. In this paper, we develop a mathematical frameworkfor reasoning about constrained generation using a pre-trained language modelgenerator oracle and a process verifier--which can decide whether a prefix canbe extended to a string which satisfies the constraints of choice. We show thateven in very simple settings, access to a verifier can render an intractableproblem (information-theoretically or computationally) to a tractable one. Infact, we show even simple algorithms, like tokenwise rejection sampling, canenjoy significant benefits from access to a verifier. Empirically, we show thata natural modification of tokenwise rejection sampling, in which the sampler isallowed to "backtrack" (i.e., erase the final few generated tokens) has robustand substantive benefits over natural baselines (e.g. (blockwise) rejectionsampling, nucleus sampling)--both in terms of computational efficiency,accuracy and diversity.</description><author>Edoardo Botta, Yuchen Li, Aashay Mehta, Jordan T. Ash, Cyril Zhang, Andrej Risteski</author><pubDate>Mon, 17 Feb 2025 18:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12123v1</guid></item><item><title>Minimal Ranks, Maximum Confidence: Parameter-efficient Uncertainty Quantification for LoRA</title><link>http://arxiv.org/abs/2502.12122v1</link><description>Low-Rank Adaptation (LoRA) enables parameter-efficient fine-tuning of largelanguage models by decomposing weight updates into low-rank matrices,significantly reducing storage and computational overhead. While effective,standard LoRA lacks mechanisms for uncertainty quantification, leading tooverconfident and poorly calibrated models. Bayesian variants of LoRA addressthis limitation, but at the cost of a significantly increased number oftrainable parameters, partially offsetting the original efficiency gains.Additionally, these models are harder to train and may suffer from unstableconvergence. In this work, we propose a novel parameter-efficient Bayesian LoRA,demonstrating that effective uncertainty quantification can be achieved in verylow-dimensional parameter spaces. The proposed method achieves strongperformance with improved calibration and generalization while maintainingcomputational efficiency. Our empirical findings show that, with theappropriate projection of the weight space: (1) uncertainty can be effectivelymodeled in a low-dimensional space, and (2) weight covariances exhibit lowranks.</description><author>Patryk Marszałek, Klaudia Bałazy, Jacek Tabor, Tomasz Kuśmierczyk</author><pubDate>Mon, 17 Feb 2025 18:46:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12122v1</guid></item><item><title>LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws</title><link>http://arxiv.org/abs/2502.12120v1</link><description>Scaling laws guide the development of large language models (LLMs) byoffering estimates for the optimal balance of model size, tokens, and compute.More recently, loss-to-loss scaling laws that relate losses across pretrainingdatasets and downstream tasks have emerged as a powerful tool for understandingand improving LLM performance. In this work, we investigate which factors moststrongly influence loss-to-loss scaling. Our experiments reveal that thepretraining data and tokenizer determine the scaling trend. In contrast, modelsize, optimization hyperparameters, and even significant architecturaldifferences, such as between transformer-based models like Llama andstate-space models like Mamba, have limited impact. Consequently, practitionersshould carefully curate suitable pretraining datasets for optimal downstreamperformance, while architectures and other settings can be freely optimized fortraining efficiency.</description><author>Prasanna Mayilvahanan, Thaddäus Wiedemer, Sayak Mallick, Matthias Bethge, Wieland Brendel</author><pubDate>Mon, 17 Feb 2025 18:45:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12120v1</guid></item><item><title>PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection</title><link>http://arxiv.org/abs/2502.12119v1</link><description>Visual instruction tuning refines pre-trained Multimodal Large LanguageModels (MLLMs) to enhance their real-world task performance. However, the rapidexpansion of visual instruction datasets introduces significant dataredundancy, leading to excessive computational costs. Existing data selectionmethods predominantly rely on proxy models or loss-based metrics, both of whichimpose substantial computational overheads due to the necessity of modelinference and backpropagation. To address this challenge, we propose PRISM, anovel training-free approach for efficient multimodal data selection. Unlikeexisting methods, PRISM eliminates the reliance on proxy models, warm-uppretraining, and gradient-based optimization. Instead, it leverages Pearsoncorrelation analysis to quantify the intrinsic visual encoding properties ofMLLMs, computing a task-specific correlation score to identify high-valueinstances. This not only enbles data-efficient selection,but maintains theoriginal performance. Empirical evaluations across multiple MLLMs demonstratethat PRISM reduces the overall time required for visual instruction tuning anddata selection to just 30% of conventional methods, while surpassing fullyfine-tuned models across eight multimodal and three language understandingbenchmarks, achieving a 101.7% relative improvement in final performance.</description><author>Jinhe Bi, Yifan Wang, Danqi Yan, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma</author><pubDate>Mon, 17 Feb 2025 18:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12119v1</guid></item><item><title>Scaling Test-Time Compute Without Verification or RL is Suboptimal</title><link>http://arxiv.org/abs/2502.12118v1</link><description>Despite substantial advances in scaling test-time compute, an ongoing debatein the community is how it should be scaled up to enable continued andefficient improvements with scaling. There are largely two approaches: first,distilling successful search or thinking traces; and second, using verification(e.g., 0/1 outcome rewards, reward models, or verifiers) to guide reinforcementlearning (RL) and search algorithms. In this paper, we prove that finetuningLLMs with verifier-based (VB) methods based on RL or search is far superior toverifier-free (VF) approaches based on distilling or cloning search traces,given a fixed amount of compute/data budget. Further, we show that as we scaletest-time compute (measured as the output token length) and training data,suboptimality of VF methods scales poorly compared to VB when the basepre-trained LLM presents a heterogeneous distribution over correct solutiontraces (e.g., different lengths, styles, etc.) and admits a non-sharpdistribution over rewards on traces sampled from it. We formalize thiscondition using anti-concentration [Erd\H{o}s, 1945]. This implies a strongerresult that VB methods scale better asymptotically, with the performance gapbetween VB and VF methods widening as test-time budget grows. We corroborateour theory empirically on both didactic and math reasoning problems with3/8/32B-sized pre-trained LLMs, where we find verification is crucial forscaling test-time compute.</description><author>Amrith Setlur, Nived Rajaraman, Sergey Levine, Aviral Kumar</author><pubDate>Mon, 17 Feb 2025 18:43:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12118v1</guid></item><item><title>Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models</title><link>http://arxiv.org/abs/2502.09782v2</link><description>The increasing prevalence of microphones in everyday devices and the growingreliance on online services have amplified the risk of acoustic side-channelattacks (ASCAs) targeting keyboards. This study explores deep learningtechniques, specifically vision transformers (VTs) and large language models(LLMs), to enhance the effectiveness and applicability of such attacks. Wepresent substantial improvements over prior research, with the CoAtNet modelachieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvementfor keystrokes recorded via smartphone (Phone) and 5.9% for those recorded viaZoom compared to previous benchmarks. We also evaluate transformerarchitectures and language models, with the best VT model matching CoAtNet'sperformance. A key advancement is the introduction of a noise mitigation methodfor real-world scenarios. By using LLMs for contextual understanding, we detectand correct erroneous keystrokes in noisy environments, enhancing ASCAperformance. Additionally, fine-tuned lightweight language models with Low-RankAdaptation (LoRA) deliver comparable performance to heavyweight models with 67Xmore parameters. This integration of VTs and LLMs improves the practicalapplicability of ASCA mitigation, marking the first use of these technologiesto address ASCAs and error correction in real-world scenarios.</description><author>Jin Hyun Park, Seyyed Ali Ayati, Yichen Cai</author><pubDate>Mon, 17 Feb 2025 18:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09782v2</guid></item><item><title>SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?</title><link>http://arxiv.org/abs/2502.12115v1</link><description>We introduce SWE-Lancer, a benchmark of over 1,400 freelance softwareengineering tasks from Upwork, valued at \$1 million USD total in real-worldpayouts. SWE-Lancer encompasses both independent engineering tasks--rangingfrom \$50 bug fixes to \$32,000 feature implementations--and managerial tasks,where models choose between technical implementation proposals. Independenttasks are graded with end-to-end tests triple-verified by experienced softwareengineers, while managerial decisions are assessed against the choices of theoriginal hired engineering managers. We evaluate model performance and findthat frontier models are still unable to solve the majority of tasks. Tofacilitate future research, we open-source a unified Docker image and a publicevaluation split, SWE-Lancer Diamond(https://github.com/openai/SWELancer-Benchmark). By mapping model performanceto monetary value, we hope SWE-Lancer enables greater research into theeconomic impact of AI model development.</description><author>Samuel Miserendino, Michele Wang, Tejal Patwardhan, Johannes Heidecke</author><pubDate>Mon, 17 Feb 2025 18:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12115v1</guid></item><item><title>A Monocular Event-Camera Motion Capture System</title><link>http://arxiv.org/abs/2502.12113v1</link><description>Motion capture systems are a widespread tool in research to recordground-truth poses of objects. Commercial systems use reflective markersattached to the object and then triangulate pose of the object from multiplecamera views. Consequently, the object must be visible to multiple cameraswhich makes such multi-view motion capture systems unsuited for deployments innarrow, confined spaces (e.g. ballast tanks of ships). In this technical reportwe describe a monocular event-camera motion capture system which overcomes thislimitation and is ideally suited for narrow spaces. Instead of passive markersit relies on active, blinking LED markers such that each marker can be uniquelyidentified from the blinking frequency. The markers are placed at knownlocations on the tracking object. We then solve the PnP (perspective-n-points)problem to obtain the position and orientation of the object. The developedsystem has millimeter accuracy, millisecond latency and we demonstrate that itsstate estimate can be used to fly a small, agile quadrotor.</description><author>Leonard Bauersfeld, Davide Scaramuzza</author><pubDate>Mon, 17 Feb 2025 18:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12113v1</guid></item><item><title>CELL your Model: Contrastive Explanations for Large Language Models</title><link>http://arxiv.org/abs/2406.11785v3</link><description>The advent of black-box deep neural network classification models has sparkedthe need to explain their decisions. However, in the case of generative AI,such as large language models (LLMs), there is no class prediction to explain.Rather, one can ask why an LLM output a particular response to a given prompt.In this paper, we answer this question by proposing a contrastive explanationmethod requiring simply black-box/query access. Our explanations suggest thatan LLM outputs a reply to a given prompt because if the prompt was slightlymodified, the LLM would have given a different response that is either lesspreferable or contradicts the original response. The key insight is thatcontrastive explanations simply require a scoring function that has meaning tothe user and not necessarily a specific real valued quantity (viz. classlabel). To this end, we offer a novel budgeted algorithm, our main algorithmiccontribution, which intelligently creates contrasts based on such a scoringfunction while adhering to a query budget, necessary for longer contexts. Weshow the efficacy of our method on important natural language tasks such asopen-text generation and chatbot conversations.</description><author>Ronny Luss, Erik Miehling, Amit Dhurandhar</author><pubDate>Mon, 17 Feb 2025 18:37:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11785v3</guid></item><item><title>A-MEM: Agentic Memory for LLM Agents</title><link>http://arxiv.org/abs/2502.12110v1</link><description>While large language model (LLM) agents can effectively use external toolsfor complex real-world tasks, they require memory systems to leveragehistorical experiences. Current memory systems enable basic storage andretrieval but lack sophisticated memory organization, despite recent attemptsto incorporate graph databases. Moreover, these systems' fixed operations andstructures limit their adaptability across diverse tasks. To address thislimitation, this paper proposes a novel agentic memory system for LLM agentsthat can dynamically organize memories in an agentic way. Following the basicprinciples of the Zettelkasten method, we designed our memory system to createinterconnected knowledge networks through dynamic indexing and linking. When anew memory is added, we generate a comprehensive note containing multiplestructured attributes, including contextual descriptions, keywords, and tags.The system then analyzes historical memories to identify relevant connections,establishing links where meaningful similarities exist. Additionally, thisprocess enables memory evolution - as new memories are integrated, they cantrigger updates to the contextual representations and attributes of existinghistorical memories, allowing the memory network to continuously refine itsunderstanding. Our approach combines the structured organization principles ofZettelkasten with the flexibility of agent-driven decision making, allowing formore adaptive and context-aware memory management. Empirical experiments on sixfoundation models show superior improvement against existing SOTA baselines.The source code is available at https://github.com/WujiangXu/AgenticMemory.</description><author>Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang</author><pubDate>Mon, 17 Feb 2025 18:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12110v1</guid></item><item><title>Personality Structured Interview for Large Language Model Simulation in Personality Research</title><link>http://arxiv.org/abs/2502.12109v1</link><description>Although psychometrics researchers have recently explored the use of largelanguage models (LLMs) as proxies for human participants, LLMs often fail togenerate heterogeneous data with human-like diversity, which diminishes theirvalue in advancing social science research. To address these challenges, weexplored the potential of the theory-informed Personality Structured Interview(PSI) as a tool for simulating human responses in personality research. In thisapproach, the simulation is grounded in nuanced real-human interviewtranscripts that target the personality construct of interest. We have provideda growing set of 357 structured interview transcripts from a representativesample, each containing an individual's response to 32 open-ended questionscarefully designed to gather theory-based personality evidence. Additionally,grounded in psychometric research, we have summarized an evaluation frameworkto systematically validate LLM-generated psychometric data. Results from threeexperiments demonstrate that well-designed structured interviews could improvehuman-like heterogeneity in LLM-simulated personality data and predictpersonality-related behavioral outcomes (i.e., organizational citizenshipbehaviors and counterproductive work behavior). We further discuss the role oftheory-informed structured interviews in LLM-based simulation and outline ageneral framework for designing structured interviews to simulate human-likedata for psychometric research.</description><author>Pengda Wang, Huiqi Zou, Hanjie Chen, Tianjun Sun, Ziang Xiao, Frederick L. Oswald</author><pubDate>Mon, 17 Feb 2025 18:31:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12109v1</guid></item><item><title>Using the Path of Least Resistance to Explain Deep Networks</title><link>http://arxiv.org/abs/2502.12108v1</link><description>Integrated Gradients (IG), a widely used axiomatic path-based attributionmethod, assigns importance scores to input features by integrating modelgradients along a straight path from a baseline to the input. While effectivein some cases, we show that straight paths can lead to flawed attributions. Inthis paper, we identify the cause of these misattributions and propose analternative approach that treats the input space as a Riemannian manifold,computing attributions by integrating gradients along geodesics. We call thismethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, weintroduce two techniques: a k-Nearest Neighbours-based approach for smallermodels and a Stochastic Variational Inference-based method for larger ones.Additionally, we propose a new axiom, Strong Completeness, extending the axiomssatisfied by IG. We show that this property is desirable for attributionmethods and that GIG is the only method that satisfies it. Through experimentson both synthetic and real-world data, we demonstrate that GIG outperformsexisting explainability methods, including IG.</description><author>Sina Salek, Joseph Enguehard</author><pubDate>Mon, 17 Feb 2025 18:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12108v1</guid></item><item><title>Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination</title><link>http://arxiv.org/abs/2411.03823v2</link><description>The rapid progression of multimodal large language models (MLLMs) hasdemonstrated superior performance on various multimodal benchmarks. However,the issue of data contamination during training creates challenges inperformance evaluation and comparison. While numerous methods exist fordetecting models' contamination in large language models (LLMs), they are lesseffective for MLLMs due to their various modalities and multiple trainingphases. In this study, we introduce a multimodal data contamination detectionframework, MM-Detect, designed for MLLMs. Our experimental results indicatethat MM-Detect is quite effective and sensitive in identifying varying degreesof contamination, and can highlight significant performance improvements due tothe leakage of multimodal benchmark training sets. Furthermore, we explorewhether the contamination originates from the base LLMs used by MLLMs or themultimodal training phase, providing new insights into the stages at whichcontamination may be introduced.</description><author>Dingjie Song, Sicheng Lai, Shunian Chen, Lichao Sun, Benyou Wang</author><pubDate>Mon, 17 Feb 2025 18:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03823v2</guid></item><item><title>NaVILA: Legged Robot Vision-Language-Action Model for Navigation</title><link>http://arxiv.org/abs/2412.04453v2</link><description>This paper proposes to solve the problem of Vision-and-Language Navigationwith legged robots, which not only provides a flexible way for humans tocommand but also allows the robot to navigate through more challenging andcluttered scenes. However, it is non-trivial to translate human languageinstructions all the way to low-level leg joint actions. We propose NaVILA, a2-level framework that unifies a Vision-Language-Action model (VLA) withlocomotion skills. Instead of directly predicting low-level actions from VLA,NaVILA first generates mid-level actions with spatial information in the formof language, (e.g., "moving forward 75cm"), which serves as an input for avisual locomotion RL policy for execution. NaVILA substantially improvesprevious approaches on existing benchmarks. The same advantages aredemonstrated in our newly developed benchmarks with IsaacLab, featuring morerealistic scenes, low-level controls, and real-world robot experiments. We showmore results at https://navila-bot.github.io/</description><author>An-Chieh Cheng, Yandong Ji, Zhaojing Yang, Zaitian Gongye, Xueyan Zou, Jan Kautz, Erdem Bıyık, Hongxu Yin, Sifei Liu, Xiaolong Wang</author><pubDate>Mon, 17 Feb 2025 18:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04453v2</guid></item><item><title>Relational Norms for Human-AI Cooperation</title><link>http://arxiv.org/abs/2502.12102v1</link><description>How we should design and interact with social artificial intelligence dependson the socio-relational role the AI is meant to emulate or occupy. In humansociety, relationships such as teacher-student, parent-child, neighbors,siblings, or employer-employee are governed by specific norms that prescribe orproscribe cooperative functions including hierarchy, care, transaction, andmating. These norms shape our judgments of what is appropriate for eachpartner. For example, workplace norms may allow a boss to give orders to anemployee, but not vice versa, reflecting hierarchical and transactionalexpectations. As AI agents and chatbots powered by large language models areincreasingly designed to serve roles analogous to human positions - such asassistant, mental health provider, tutor, or romantic partner - it isimperative to examine whether and how human relational norms should extend tohuman-AI interactions. Our analysis explores how differences between AI systemsand humans, such as the absence of conscious experience and immunity tofatigue, may affect an AI's capacity to fulfill relationship-specific functionsand adhere to corresponding norms. This analysis, which is a collaborativeeffort by philosophers, psychologists, relationship scientists, ethicists,legal experts, and AI researchers, carries important implications for AIsystems design, user behavior, and regulation. While we accept that AI systemscan offer significant benefits such as increased availability and consistencyin certain socio-relational roles, they also risk fostering unhealthydependencies or unrealistic expectations that could spill over into human-humanrelationships. We propose that understanding and thoughtfully shaping (orimplementing) suitable human-AI relational norms will be crucial for ensuringthat human-AI interactions are ethical, trustworthy, and favorable to humanwell-being.</description><author>Brian D. Earp, Sebastian Porsdam Mann, Mateo Aboy, Edmond Awad, Monika Betzler, Marietjie Botes, Rachel Calcott, Mina Caraccio, Nick Chater, Mark Coeckelbergh, Mihaela Constantinescu, Hossein Dabbagh, Kate Devlin, Xiaojun Ding, Vilius Dranseika, Jim A. C. Everett, Ruiping Fan, Faisal Feroz, Kathryn B. Francis, Cindy Friedman, Orsolya Friedrich, Iason Gabriel, Ivar Hannikainen, Julie Hellmann, Arasj Khodadade Jahrome, Niranjan S. Janardhanan, Paul Jurcys, Andreas Kappes, Maryam Ali Khan, Gordon Kraft-Todd, Maximilian Kroner Dale, Simon M. Laham, Benjamin Lange, Muriel Leuenberger, Jonathan Lewis, Peng Liu, David M. Lyreskog, Matthijs Maas, John McMillan, Emilian Mihailov, Timo Minssen, Joshua Teperowski Monrad, Kathryn Muyskens, Simon Myers, Sven Nyholm, Alexa M. Owen, Anna Puzio, Christoph</author><pubDate>Mon, 17 Feb 2025 18:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12102v1</guid></item><item><title>Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis</title><link>http://arxiv.org/abs/2404.01438v2</link><description>This research explores the positive application of deepfake technology forupper body generation, specifically sign language for the Deaf and Hard ofHearing (DHoH) community. Given the complexity of sign language and thescarcity of experts, the generated videos are vetted by a sign language expertfor accuracy. We construct a reliable deepfake dataset, evaluating itstechnical and visual credibility using computer vision and natural languageprocessing models. The dataset, consisting of over 1200 videos featuring bothseen and unseen individuals, is also used to detect deepfake videos targetingvulnerable individuals. Expert annotations confirm that the generated videosare comparable to real sign language content. Linguistic analysis, usingtextual similarity scores and interpreter evaluations, shows that theinterpretation of generated videos is at least 90% similar to authentic signlanguage. Visual analysis demonstrates that convincingly realistic deepfakescan be produced, even for new subjects. Using a pose/style transfer model, wepay close attention to detail, ensuring hand movements are accurate and alignwith the driving video. We also apply machine learning algorithms to establisha baseline for deepfake detection on this dataset, contributing to thedetection of fraudulent sign language videos.</description><author>Shahzeb Naeem, Muhammad Riyyan Khan, Usman Tariq, Abhinav Dhall, Carlos Ivan Colon, Hasan Al-Nashash</author><pubDate>Mon, 17 Feb 2025 18:22:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01438v2</guid></item><item><title>Machine Learning for Equitable Load Shedding: Real-time Solution via Learning Binding Constraints</title><link>http://arxiv.org/abs/2407.18989v3</link><description>Timely and effective load shedding in power systems is critical formaintaining supply-demand balance and preventing cascading blackouts. Toeliminate load shedding bias against specific regions in the system,optimization-based methods are uniquely positioned to help balance betweeneconomical and equity considerations. However, the resulting optimizationproblem involves complex constraints, which can be time-consuming to solve andthus cannot meet the real-time requirements of load shedding. To tackle thischallenge, in this paper we present an efficient machine learning algorithm toenable millisecond-level computation for the optimization-based load sheddingproblem. Numerical studies on both a 3-bus toy example and a realistic RTS-GMLCsystem have demonstrated the validity and efficiency of the proposed algorithmfor delivering equitable and real-time load shedding decisions.</description><author>Yuqi Zhou, Joseph Severino, Sanjana Vijayshankar, Juliette Ugirumurera, Jibo Sanyal</author><pubDate>Mon, 17 Feb 2025 18:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18989v3</guid></item><item><title>Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications</title><link>http://arxiv.org/abs/2502.12096v1</link><description>In this paper, we introduce token communications (TokCom), a unifiedframework to leverage cross-modal context information in generative semanticcommunications (GenSC). TokCom is a new paradigm, motivated by the recentsuccess of generative foundation models and multimodal large language models(GFM/MLLMs), where the communication units are tokens, enabling efficienttransformer-based token processing at the transmitter and receiver. In thispaper, we introduce the potential opportunities and challenges of leveragingcontext in GenSC, explore how to integrate GFM/MLLMs-based token processinginto semantic communication systems to leverage cross-modal contexteffectively, present the key principles for efficient TokCom at various layersin future wireless networks. We demonstrate the corresponding TokCom benefitsin a GenSC setup for image, leveraging cross-modal context information, whichincreases the bandwidth efficiency by 70.8% with negligible loss ofsemantic/perceptual quality. Finally, the potential research directions areidentified to facilitate adoption of TokCom in future wireless networks.</description><author>Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato</author><pubDate>Mon, 17 Feb 2025 18:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12096v1</guid></item><item><title>Descriminative-Generative Custom Tokens for Vision-Language Models</title><link>http://arxiv.org/abs/2502.12095v1</link><description>This paper explores the possibility of learning custom tokens forrepresenting new concepts in Vision-Language Models (VLMs). Our aim is to learntokens that can be effective for both discriminative and generative tasks whilecomposing well with words to form new input queries. The targeted concept isspecified in terms of a small set of images and a parent concept describedusing text. We operate on CLIP text features and propose to use a combinationof a textual inversion loss and a classification loss to ensure that textfeatures of the learned token are aligned with image features of the concept inthe CLIP embedding space. We restrict the learned token to a low-dimensionalsubspace spanned by tokens for attributes that are appropriate for the givensuper-class. These modifications improve the quality of compositions of thelearned token with natural language for generating new scenes. Further, we showthat learned custom tokens can be used to form queries for text-to-imageretrieval task, and also have the important benefit that composite queries canbe visualized to ensure that the desired concept is faithfully encoded. Basedon this, we introduce the method of Generation Aided Image Retrieval, where thequery is modified at inference time to better suit the search intent. On theDeepFashion2 dataset, our method improves Mean Reciprocal Retrieval (MRR) overrelevant baselines by 7%.</description><author>Pramuditha Perera, Matthew Trager, Luca Zancato, Alessandro Achille, Stefano Soatto</author><pubDate>Mon, 17 Feb 2025 18:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12095v1</guid></item><item><title>Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)</title><link>http://arxiv.org/abs/2412.18367v5</link><description>The field of machine translation has achieved significant advancements, yetdomain-specific terminology translation, particularly in AI, remainschallenging. We introduce GIST, a large-scale multilingual AI terminologydataset containing 5K terms extracted from top AI conference papers spanning2000 to 2023. The terms are translated into Arabic, Chinese, French, Japanese,and Russian using a hybrid framework that combines LLMs for extraction withhuman expertise for translation. The dataset's quality is benchmarked againstexisting resources, demonstrating superior translation accuracy throughcrowdsourced evaluation. GIST is integrated into translation workflows usingpost-translation refinement methods that require no retraining, where LLMprompting consistently improves BLEU and COMET scores. A web demonstration onthe ACL Anthology platform highlights its practical application, showcasingimproved accessibility for non-English speakers. This work aims to addresscritical gaps in AI terminology resources and fosters global inclusivity andcollaboration in AI research.</description><author>Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona Diab</author><pubDate>Mon, 17 Feb 2025 18:13:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18367v5</guid></item><item><title>A Study on Leveraging Search and Self-Feedback for Agent Reasoning</title><link>http://arxiv.org/abs/2502.12094v1</link><description>Recent works have demonstrated that incorporating search during inference cansignificantly improve reasoning capabilities of language agents. Someapproaches may make use of the ground truth or rely on model's own generatedfeedback. The search algorithm uses this feedback to then produce values thatwill update its criterion for exploring and exploiting various reasoning paths.In this study, we investigate how search and model's self-feedback can beleveraged for reasoning tasks. First, we explore differences in ground-truthfeedback and self-feedback during search for math reasoning. Second, we observelimitations in applying search techniques to more complex tasks liketool-calling and design domain-specific approaches to address these gaps. Ourexperiments reveal challenges related to generalization when solely relying onself-feedback during search. For search to work effectively, either access tothe ground-truth is needed or feedback mechanisms need to be carefully designedfor the specific task.</description><author>Karthikeyan K, Michelle Yuan, Elman Mansimov, Katerina Margatina, Anurag Pratik, Daniele Bonadiman, Monica Sunkara, Yi Zhang, Yassine Benajiba</author><pubDate>Mon, 17 Feb 2025 18:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12094v1</guid></item><item><title>Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning</title><link>http://arxiv.org/abs/2501.03035v2</link><description>Large language models have achieved significant advancements in complexmathematical reasoning benchmarks, such as MATH. However, their substantialcomputational requirements present challenges for practical deployment. Modelquantization has emerged as an effective strategy to reduce memory usage andcomputational costs by employing lower precision and bit-width representations.In this study, we systematically evaluate the impact of quantization onmathematical reasoning tasks. Our results demonstrate that aggressivequantization methods like AWQ and GPTQ introduce up to 32.39% accuracydegradation (average 11.31%) on Llama-3 models, particularly in numericalcomputation and reasoning planning. To address this, we introduce amultidimensional evaluation framework combining qualitative capability analysisand quantitative error assessment. We further develop targeted recoverystrategies, showing that fine-tuning quantized models on only 545 task-specificexamples for 3 minutes on 4 GPUs effectively restores reasoning capabilities tonear full-precision levels. Additionally, our error assessment pipelineachieves 98.9% accuracy in diagnosing and localizing errors across 3,366failure cases, providing actionable insights for mitigatingquantization-induced degradation.</description><author>Zhen Li, Yupeng Su, Runming Yang, Congkai Xie, Zheng Wang, Zhongwei Xie, Ngai Wong, Hongxia Yang</author><pubDate>Mon, 17 Feb 2025 18:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03035v2</guid></item><item><title>CLEAR: Character Unlearning in Textual and Visual Modalities</title><link>http://arxiv.org/abs/2410.18057v3</link><description>Machine Unlearning (MU) is critical for removing private or hazardousinformation from deep learning models. While MU has advanced significantly inunimodal (text or vision) settings, multimodal unlearning (MMU) remainsunderexplored due to the lack of open benchmarks for evaluating cross-modaldata removal. To address this gap, we introduce CLEAR, the first open-sourcebenchmark designed specifically for MMU. CLEAR contains 200 fictitiousindividuals and 3,700 images linked with corresponding question-answer pairs,enabling a thorough evaluation across modalities. We conduct a comprehensiveanalysis of 11 MU methods (e.g., SCRUB, gradient ascent, DPO) across fourevaluation sets, demonstrating that jointly unlearning both modalitiesoutperforms single-modality approaches. The dataset is available athttps://huggingface.co/datasets/therem/CLEAR</description><author>Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina</author><pubDate>Mon, 17 Feb 2025 18:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18057v3</guid></item><item><title>How compositional generalization and creativity improve as diffusion models are trained</title><link>http://arxiv.org/abs/2502.12089v1</link><description>Natural data is often organized as a hierarchical composition of features.How many samples do generative models need to learn the composition rules, soas to produce a combinatorial number of novel data? What signal in the data isexploited to learn? We investigate these questions both theoretically andempirically. Theoretically, we consider diffusion models trained on simpleprobabilistic context-free grammars - tree-like graphical models used torepresent the structure of data such as language and images. We demonstratethat diffusion models learn compositional rules with the sample complexityrequired for clustering features with statistically similar context, a processsimilar to the word2vec algorithm. However, this clustering emergeshierarchically: higher-level, more abstract features associated with longercontexts require more data to be identified. This mechanism leads to a samplecomplexity that scales polynomially with the said context size. As a result,diffusion models trained on intermediate dataset size generate data coherent upto a certain scale, but that lacks global coherence. We test these predictionsin different domains, and find remarkable agreement: both generated texts andimages achieve progressively larger coherence lengths as the training time ordataset size grows. We discuss connections between the hierarchical clusteringmechanism we introduce here and the renormalization group in physics.</description><author>Alessandro Favero, Antonio Sclocchi, Francesco Cagnetta, Pascal Frossard, Matthieu Wyart</author><pubDate>Mon, 17 Feb 2025 18:06:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12089v1</guid></item></channel></rss>