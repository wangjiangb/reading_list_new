<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 30 Sep 2025 13:00:11 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>UniAPL: A Unified Adversarial Preference Learning Framework for Instruct-Following</title><link>http://arxiv.org/abs/2509.25148v1</link><description>Shaping powerful LLMs to be beneficial and safe is central to AI alignment.We argue that post-training alignment is fundamentally a unified PreferenceLearning problem, involving two modalities: demonstrated preferences (e.g.,Supervised Fine-Tuning, SFT) and comparative preferences (e.g., ReinforcementLearning, RL).The standard sequential pipeline-SFT followed by RL-is flawed dueto a critical distributional mismatch: SFT uses static expert data, but as thepolicy evolves, its generation distribution drifts, making SFT knowledgebrittle. Subsequent RL then explores without direct access to the rich,ground-truth knowledge in expert demonstrations, leading to inefficient,ungrounded updates. This separation prevents mutual regularization between datasources. To address this, we reframe alignment as a constrained optimizationproblem and propose Unified Adversarial Preference Learning (UniAPL),a novelframework that dynamically aligns the policy's distribution with the expert's.UniAPL implements a single-stage unified training objective, jointly learningfrom mixed batches of SFT and preference data. In every gradient step, denseexpert demonstrations directly ground and regularize online exploration,inherently resolving distributional mismatch and maximizing data synergy.Weevaluate UniAPL on instruction-following tasks using Qwen3-235B-Instruct-2507as the teacher. Our models match or exceed strong GRPO baselines: +5.77% onQwen3-0.6B (matching a 32B model) and +3.75% on Qwen3-4B,even outperforming theteacher. Analyses of response length and log-probability distributions confirmthat UniAPL outputs closely mimic expert demonstrations, achieving bothstronger performance and better behavioral alignment.</description><author>FaQiang Qian, WeiKun Zhang, Ziliang Wang, Kang An, Xuhui Zheng, Liangjian Wen, Mengya Gao, Yong Dai, Yichao Wu</author><pubDate>Mon, 29 Sep 2025 17:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25148v1</guid></item><item><title>Fast Feature Field ($\text{F}^3$): A Predictive Representation of Events</title><link>http://arxiv.org/abs/2509.25146v1</link><description>This paper develops a mathematical argument and algorithms for buildingrepresentations of data from event-based cameras, that we call Fast FeatureField ($\text{F}^3$). We learn this representation by predicting future eventsfrom past events and show that it preserves scene structure and motioninformation. $\text{F}^3$ exploits the sparsity of event data and is robust tonoise and variations in event rates. It can be computed efficiently using ideasfrom multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and440 Hz at VGA resolutions. $\text{F}^3$ represents events within a contiguousspatiotemporal volume as a multi-channel image, enabling a range of downstreamtasks. We obtain state-of-the-art performance on optical flow estimation,semantic segmentation, and monocular metric depth estimation, on data fromthree robotic platforms (a car, a quadruped robot and a flying platform),across different lighting conditions (daytime, nighttime), environments(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors(resolutions and event rates). Our implementations can predict these tasks at25-75 Hz at HD resolution.</description><author>Richeek Das, Kostas Daniilidis, Pratik Chaudhari</author><pubDate>Mon, 29 Sep 2025 17:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25146v1</guid></item><item><title>Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation</title><link>http://arxiv.org/abs/2509.25144v1</link><description>We present Paired by the Teacher (PbT), a two-stage teacher-student pipelinethat synthesizes accurate input-output pairs without human labels or paralleldata. In many low-resource natural language generation (NLG) scenarios,practitioners may have only raw outputs, like highlights, recaps, or questions,or only raw inputs, such as articles, dialogues, or paragraphs, but seldomboth. This mismatch forces small models to learn from very few examples or relyon costly, broad-scope synthetic examples produced by large LLMs. PbT addressesthis by asking a teacher LLM to compress each unpaired example into a conciseintermediate representation (IR), and training a student to reconstruct inputsfrom IRs. This enables outputs to be paired with student-generated inputs,yielding high-quality synthetic data. We evaluate PbT on fivebenchmarks-document summarization (XSum, CNNDM), dialogue summarization(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpairedsetting on SwitchBoard (paired with DialogSum summaries). An 8B student trainedonly on PbT data outperforms models trained on 70 B teacher-generated corporaand other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotatedpairs and closing 82% of the oracle gap at one-third the annotation cost ofdirect synthesis. Human evaluation on SwitchBoard further confirms that onlyPbT produces concise, faithful summaries aligned with the target style,highlighting its advantage of generating in-domain sources that avoid themismatch, limiting direct synthesis.</description><author>Yen-Ju Lu, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba</author><pubDate>Mon, 29 Sep 2025 17:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25144v1</guid></item><item><title>TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models</title><link>http://arxiv.org/abs/2509.25143v1</link><description>Existing medical reasoning benchmarks for vision-language models primarilyfocus on analyzing a patient's condition based on an image from a single visit.However, this setting deviates significantly from real-world clinical practice,where doctors typically refer to a patient's historical conditions to provide acomprehensive assessment by tracking their changes over time. In this paper, weintroduce TemMed-Bench, the first benchmark designed for analyzing changes inpatients' conditions between different clinical visits, which challenges largevision-language models (LVLMs) to reason over temporal medical images.TemMed-Bench consists of a test set comprising three tasks - visualquestion-answering (VQA), report generation, and image-pair selection - and asupplementary knowledge corpus of over 17,000 instances. With TemMed-Bench, weconduct an evaluation of six proprietary and six open-source LVLMs. Our resultsshow that most LVLMs lack the ability to analyze patients' condition changesover temporal medical images, and a large proportion perform only at arandom-guessing level in the closed-book setting. In contrast, GPT o3, o4-miniand Claude 3.5 Sonnet demonstrate comparatively decent performance, though theyhave yet to reach the desired level. Furthermore, we explore augmenting theinput with both retrieved visual and textual modalities in the medical domain.We also show that multi-modal retrieval augmentation yields notably higherperformance gains than no retrieval and textual retrieval alone across mostmodels on our benchmark, with the VQA task showing an average improvement of2.59%. Overall, we compose a benchmark grounded on real-world clinicalpractice, and it reveals LVLMs' limitations in temporal medical imagereasoning, as well as highlighting the use of multi-modal retrievalaugmentation as a potentially promising direction worth exploring to addressthis challenge.</description><author>Junyi Zhang, Jia-Chen Gu, Wenbo Hu, Yu Zhou, Robinson Piramuthu, Nanyun Peng</author><pubDate>Mon, 29 Sep 2025 17:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25143v1</guid></item><item><title>Visual serial processing deficits explain divergences in human and VLM reasoning</title><link>http://arxiv.org/abs/2509.25142v1</link><description>Why do Vision Language Models (VLMs), despite success on standard benchmarks,often fail to match human performance on surprisingly simple visual reasoningtasks? While the underlying computational principles are still debated, wehypothesize that a crucial factor is a deficit in visually-grounded serialprocessing. To test this hypothesis, we compared human and VLM performanceacross tasks designed to vary serial processing demands in three distinctdomains: geometric reasoning, perceptual enumeration, and mental rotation.Tasks within each domain varied serial processing load by manipulating factorssuch as geometric concept complexity, perceptual individuation load, andtransformation difficulty. Across all domains, our results revealed aconsistent pattern: decreased VLM accuracy was strongly correlated withincreased human reaction time (used as a proxy for serial processing load). Astasks require more demanding serial processing -- whether composing concepts,enumerating items, or performing mental transformations -- the VLM-humanperformance gap widens reliably. These findings support our hypothesis,indicating that limitations in serial, visually grounded reasoning represent afundamental bottleneck that distinguishes current VLMs from humans.</description><author>Nicholas Budny, Kia Ghods, Declan Campbell, Raja Marjieh, Amogh Joshi, Sreejan Kumar, Jonathan D. Cohen, Taylor W. Webb, Thomas L. Griffiths</author><pubDate>Mon, 29 Sep 2025 17:51:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25142v1</guid></item><item><title>ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory</title><link>http://arxiv.org/abs/2509.25140v1</link><description>With the growing adoption of large language model agents in persistentreal-world roles, they naturally encounter continuous streams of tasks. A keylimitation, however, is their failure to learn from the accumulated interactionhistory, forcing them to discard valuable insights and repeat past errors. Wepropose ReasoningBank, a novel memory framework that distills generalizablereasoning strategies from an agent's self-judged successful and failedexperiences. At test time, an agent retrieves relevant memories fromReasoningBank to inform its interaction and then integrates new learnings back,enabling it to become more capable over time. Building on this powerfulexperience learner, we further introduce memory-aware test-time scaling(MaTTS), which accelerates and diversifies this learning process by scaling upthe agent's interaction experience. By allocating more compute to each task,the agent generates abundant, diverse experiences that provide rich contrastivesignals for synthesizing higher-quality memory. The better memory in turnguides more effective scaling, establishing a powerful synergy between memoryand test-time scaling. Across web browsing and software engineering benchmarks,ReasoningBank consistently outperforms existing memory mechanisms that storeraw trajectories or only successful task routines, improving both effectivenessand efficiency; MaTTS further amplifies these gains. These findings establishmemory-driven experience scaling as a new scaling dimension, enabling agents toself-evolve with emergent behaviors naturally arise.</description><author>Siru Ouyang, Jun Yan, I-Hung Hsu, Yanfei Chen, Ke Jiang, Zifeng Wang, Rujun Han, Long T. Le, Samira Daruki, Xiangru Tang, Vishy Tirumalashetty, George Lee, Mahsan Rofouei, Hangfei Lin, Jiawei Han, Chen-Yu Lee, Tomas Pfister</author><pubDate>Mon, 29 Sep 2025 17:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25140v1</guid></item><item><title>Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs</title><link>http://arxiv.org/abs/2509.25139v1</link><description>Integrating large language models (LLMs) into embodied AI models is becomingincreasingly prevalent. However, existing zero-shot LLM-basedVision-and-Language Navigation (VLN) agents either encode images as textualscene descriptions, potentially oversimplifying visual details, or process rawimage inputs, which can fail to capture abstract semantics required forhigh-level reasoning. In this paper, we improve the navigation agent'scontextual understanding by incorporating textual descriptions from multipleperspectives that facilitate analogical reasoning across images. By leveragingtext-based analogical reasoning, the agent enhances its global sceneunderstanding and spatial reasoning, leading to more accurate action decisions.We evaluate our approach on the R2R dataset, where our experiments demonstratesignificant improvements in navigation performance.</description><author>Yue Zhang, Tianyi Ma, Zun Wang, Yanyuan Qiao, Parisa Kordjamshidi</author><pubDate>Mon, 29 Sep 2025 17:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25139v1</guid></item><item><title>Investigating Language and Retrieval Bias in Multilingual Previously Fact-Checked Claim Detection</title><link>http://arxiv.org/abs/2509.25138v1</link><description>Multilingual Large Language Models (LLMs) offer powerful capabilities forcross-lingual fact-checking. However, these models often exhibit language bias,performing disproportionately better on high-resource languages such as Englishthan on low-resource counterparts. We also present and inspect a novel concept- retrieval bias, when information retrieval systems tend to favor certaininformation over others, leaving the retrieval process skewed. In this paper,we study language and retrieval bias in the context of Previously Fact-CheckedClaim Detection (PFCD). We evaluate six open-source multilingual LLMs across 20languages using a fully multilingual prompting strategy, leveraging the AMC-16Kdataset. By translating task prompts into each language, we uncover disparitiesin monolingual and cross-lingual performance and identify key trends based onmodel family, size, and prompting strategy. Our findings highlight persistentbias in LLM behavior and offer recommendations for improving equity inmultilingual fact-checking. To investigate retrieval bias, we employedmultilingual embedding models and look into the frequency of retrieved claims.Our analysis reveals that certain claims are retrieved disproportionatelyacross different posts, leading to inflated retrieval performance for popularclaims while under-representing less common ones.</description><author>Ivan Vykopal, Antonia Karamolegkou, Jaroslav Kopčan, Qiwei Peng, Tomáš Javůrek, Michal Gregor, Marián Šimko</author><pubDate>Mon, 29 Sep 2025 17:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25138v1</guid></item><item><title>The Era of Real-World Human Interaction: RL from User Conversations</title><link>http://arxiv.org/abs/2509.25137v1</link><description>We posit that to achieve continual model improvement and multifacetedalignment, future models must learn from natural human interaction. Currentconversational models are aligned using pre-annotated, expert-generated humanfeedback. In this work, we introduce Reinforcement Learning from HumanInteraction (RLHI), a paradigm that learns directly from in-the-wild userconversations. We develop two complementary methods: (1) RLHI with User-GuidedRewrites, which revises unsatisfactory model outputs based on users'natural-language follow-up responses, (2) RLHI with User-Based Rewards, whichlearns via a reward model conditioned on knowledge of the user's long-terminteraction history (termed persona). Together, these methods link long-termuser personas to turn-level preferences via persona-conditioned preferenceoptimization. Trained on conversations derived from WildChat, both RLHIvariants outperform strong baselines in personalization andinstruction-following, and similar feedback enhances performance on reasoningbenchmarks. These results suggest organic human interaction offers scalable,effective supervision for personalized alignment.</description><author>Chuanyang Jin, Jing Xu, Bo Liu, Leitian Tao, Olga Golovneva, Tianmin Shu, Wenting Zhao, Xian Li, Jason Weston</author><pubDate>Mon, 29 Sep 2025 17:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25137v1</guid></item><item><title>BALF: Budgeted Activation-Aware Low-Rank Factorization for Fine-Tuning-Free Model Compression</title><link>http://arxiv.org/abs/2509.25136v1</link><description>Neural network compression techniques typically require expensive fine-tuningor search procedures, rendering them impractical on commodity hardware.Inspired by recent LLM compression research, we present a generalactivation-aware factorization framework that can be applied to a broad rangeof layers. Moreover, we introduce a scalable budgeted rank allocator thatallows flexible control over compression targets (e.g., retaining 50% ofparameters) with no overhead. Together, these components form BALF, anefficient pipeline for compressing models without fine-tuning. We demonstrateits effectiveness across multiple scales and architectures, from ResNet-20 onCIFAR-10 to ResNeXt-101 and vision transformers on ImageNet, and show that itachieves excellent results in the fine-tuning-free regime. For instance, BALFreduces FLOPs on ResNeXt-101 by 45% with only a 1-percentage-point top-1accuracy drop.</description><author>David González Martínez</author><pubDate>Mon, 29 Sep 2025 17:50:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25136v1</guid></item><item><title>Learning in an Echo Chamber: Online Learning with Replay Adversary</title><link>http://arxiv.org/abs/2509.25135v1</link><description>As machine learning systems increasingly train on self-annotated data, theyrisk reinforcing errors and becoming echo chambers of their own beliefs. Wemodel this phenomenon by introducing a learning-theoretic framework: OnlineLearning in the Replay Setting. In round $t$, the learner outputs a hypothesis$\hat{h}_t$; the adversary then reveals either the true label $f^\ast(x_t)$ ora replayed label $\hat{h}_i(x_t)$ from an earlier round $i &lt; t$. A mistake iscounted only when the true label is shown, yet classical algorithms such as theSOA or the halving algorithm are easily misled by the replayed errors. We introduce the Extended Threshold dimension, $\mathrm{ExThD}(\mathcal{H})$,and prove matching upper and lower bounds that make$\mathrm{ExThD}(\mathcal{H})$ the exact measure of learnability in this model.A closure-based learner makes at most $\mathrm{ExThD}(\mathcal{H})$ mistakesagainst any adaptive adversary, and no algorithm can perform better. Forstochastic adversaries, we prove a similar bound for every intersection-closedclass. The replay setting is provably harder than the classical mistake boundsetting: some classes have constant Littlestone dimension but arbitrarily large$\mathrm{ExThD}(\mathcal{H})$. Proper learning exhibits an even sharperseparation: a class is properly learnable under replay if and only if it is(almost) intersection-closed. Otherwise, every proper learner suffers$\Omega(T)$ errors, whereas our improper algorithm still achieves the$\mathrm{ExThD}(\mathcal{H})$ bound. These results give the first tightanalysis of learning against replay adversaries, based on new results forclosure-type algorithms.</description><author>Daniil Dmitriev, Harald Eskelund Franck, Carolin Heinzler, Amartya Sanyal</author><pubDate>Mon, 29 Sep 2025 17:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25135v1</guid></item><item><title>LayerD: Decomposing Raster Graphic Designs into Layers</title><link>http://arxiv.org/abs/2509.25134v1</link><description>Designers craft and edit graphic designs in a layer representation, butlayer-based editing becomes impossible once composited into a raster image. Inthis work, we propose LayerD, a method to decompose raster graphic designs intolayers for re-editable creative workflow. LayerD addresses the decompositiontask by iteratively extracting unoccluded foreground layers. We propose asimple yet effective refinement approach taking advantage of the assumptionthat layers often exhibit uniform appearance in graphic designs. Asdecomposition is ill-posed and the ground-truth layer structure may not bereliable, we develop a quality metric that addresses the difficulty. Inexperiments, we show that LayerD successfully achieves high-qualitydecomposition and outperforms baselines. We also demonstrate the use of LayerDwith state-of-the-art image generators and layer-based editing.</description><author>Tomoyuki Suzuki, Kang-Jun Liu, Naoto Inoue, Kota Yamaguchi</author><pubDate>Mon, 29 Sep 2025 17:50:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25134v1</guid></item><item><title>Rethinking Entropy Regularization in Large Reasoning Models</title><link>http://arxiv.org/abs/2509.25133v1</link><description>Reinforcement learning with verifiable rewards (RLVR) has shown great promisein enhancing the reasoning abilities of large reasoning models (LRMs). However,it suffers from a critical issue: entropy collapse and premature convergence.Naive entropy regularization, a common approach for encouraging exploration inthe traditional RL literature, fails to address this problem in the context ofLRM. Our analysis reveals that this failure stems from the vast action spaceand long trajectories in LRMs, which easily trigger a global entropy explosionas the model indiscriminately explores all possible actions and states. Toaddress this, we propose SIREN (SelectIve entRopy rEgularizatioN), a methodthat confines exploration to a meaningful subset of actions and states. SIRENachieves this through a two-step entropy masking mechanism, consisting of atop-p mask and a peak-entropy mask. In addition, regularization is transformedinto a self-anchored form to stabilize training. Across five mathematicalbenchmarks, SIREN attains superior average performance over previousentropy-related RLVR approaches, exemplified by a +6.6 maj@k improvement onAIME24/25 with Qwen2.5-Math-7B. Further analysis confirms that SIREN promotesgreater response diversity and maintains entropy at an appropriate level, whichhelps to preserve the validation pass@k throughout training. This effectivelymitigates the premature convergence problem common in RLVR for LRM.</description><author>Yuxian Jiang, Yafu Li, Guanxu Chen, Dongrui Liu, Yu Cheng, Jing Shao</author><pubDate>Mon, 29 Sep 2025 17:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25133v1</guid></item><item><title>MGM-Omni: Scaling Omni LLMs to Personalized Long-Horizon Speech</title><link>http://arxiv.org/abs/2509.25131v1</link><description>We present MGM-Omni, a unified Omni LLM for omni-modal understanding andexpressive, long-horizon speech generation. Unlike cascaded pipelines thatisolate speech synthesis, MGM-Omni adopts a "brain-mouth" design with adual-track, token-based architecture that cleanly decouples multimodalreasoning from real-time speech generation. This design enables efficientcross-modal interaction and low-latency, streaming speech generation. Forunderstanding, a unified training strategy coupled with a dual audio encoderdesign enables long-form audio perception across diverse acoustic conditions.For generation, a chunk-based parallel decoding scheme narrows the text speechtoken-rate gap, accelerating inference and supporting streaming zero-shot voicecloning with stable timbre over extended durations. Compared to concurrentwork, MGM-Omni achieves these capabilities with markedly data-efficienttraining. Extensive experiments demonstrate that MGM-Omni outperforms existingopen source models in preserving timbre identity across extended sequences,producing natural and context-aware speech, and achieving superior long-formaudio and omnimodal understanding. MGM-Omni establishes an efficient,end-to-end paradigm for omnimodal understanding and controllable, personalisedlong-horizon speech generation.</description><author>Chengyao Wang, Zhisheng Zhong, Bohao Peng, Senqiao Yang, Yuqi Liu, Haokun Gui, Bin Xia, Jingyao Li, Bei Yu, Jiaya Jia</author><pubDate>Mon, 29 Sep 2025 17:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25131v1</guid></item><item><title>Score Distillation of Flow Matching Models</title><link>http://arxiv.org/abs/2509.25127v1</link><description>Diffusion models achieve high-quality image generation but are limited byslow iterative sampling. Distillation methods alleviate this by enabling one-or few-step generation. Flow matching, originally introduced as a distinctframework, has since been shown to be theoretically equivalent to diffusionunder Gaussian assumptions, raising the question of whether distillationtechniques such as score distillation transfer directly. We provide a simplederivation -- based on Bayes' rule and conditional expectations -- that unifiesGaussian diffusion and flow matching without relying on ODE/SDE formulations.Building on this view, we extend Score identity Distillation (SiD) topretrained text-to-image flow-matching models, including SANA, SD3-Medium,SD3.5-Medium/Large, and FLUX.1-dev, all with DiT backbones. Experiments showthat, with only modest flow-matching- and DiT-specific adjustments, SiD worksout of the box across these models, in both data-free and data-aided settings,without requiring teacher finetuning or architectural changes. This providesthe first systematic evidence that score distillation applies broadly totext-to-image flow matching models, resolving prior concerns about stabilityand soundness and unifying acceleration techniques across diffusion- andflow-based generators. We will make the PyTorch implementation publiclyavailable.</description><author>Mingyuan Zhou, Yi Gu, Huangjie Zheng, Liangchen Song, Guande He, Yizhe Zhang, Wenze Hu, Yinfei Yang</author><pubDate>Mon, 29 Sep 2025 17:45:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25127v1</guid></item><item><title>On Spectral Learning for Odeco Tensors: Perturbation, Initialization, and Algorithms</title><link>http://arxiv.org/abs/2509.25126v1</link><description>We study spectral learning for orthogonally decomposable (odeco) tensors,emphasizing the interplay between statistical limits, optimization geometry,and initialization. Unlike matrices, recovery for odeco tensors does not hingeon eigengaps, yielding improved robustness under noise. While iterative methodssuch as tensor power iterations can be statistically efficient, initializationemerges as the main computational bottleneck. We investigate perturbationbounds, non-convex optimization analysis, and initialization strategies,clarifying when efficient algorithms attain statistical limits and whenfundamental barriers remain.</description><author>Arnab Auddy, Ming Yuan</author><pubDate>Mon, 29 Sep 2025 17:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25126v1</guid></item><item><title>From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones</title><link>http://arxiv.org/abs/2509.25123v1</link><description>Does RL teach LLMs genuinely new skills, or does it merely activate existingones? This question lies at the core of ongoing debates about the role of RL inLLM post-training. On one side, strong empirical results can be achieved withRL even without preceding supervised finetuning; on the other, critics arguethat RL contributes little beyond reweighting existing reasoning strategies.This work provides concrete evidence that LLMs can acquire genuinely new skillsduring RL by composing existing ones, mirroring one of the central mechanismsby which humans acquire new cognitive skills. To mitigate data contaminationand other confounding factors, and to allow precise control over taskcomplexity, we develop a synthetic framework for our investigation.Specifically, we define a skill as the ability to infer the output of a stringtransformation function f(x) given x. When an LLM has already learned f and gprior to RL, our experiments reveal that RL enables it to learn unseencompositions of them h(x)=g(f(x)). Further, this compositional abilitygeneralizes to more difficult problems such as compositions of &gt;2 functionsunseen during RL training. Surprisingly, our experiments show thatcompositional skill acquired on a source task transfers to a different targettask. This transfer happens even without compositional training on the target,requiring only prior knowledge of the target's atomic skills. Our qualitativeanalysis shows that RL fundamentally changes the reasoning behaviors of themodels. In contrast, next-token training with the same data yields none ofthese findings. Our systematic experiments provide fresh insights into LLMlearning, suggesting the value of first building base models with basic skills,then using RL to incentivize advanced, generalizable skills for complexproblems.</description><author>Lifan Yuan, Weize Chen, Yuchen Zhang, Ganqu Cui, Hanbin Wang, Ziming You, Ning Ding, Zhiyuan Liu, Maosong Sun, Hao Peng</author><pubDate>Mon, 29 Sep 2025 17:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25123v1</guid></item><item><title>Triangle Splatting+: Differentiable Rendering with Opaque Triangles</title><link>http://arxiv.org/abs/2509.25122v1</link><description>Reconstructing 3D scenes and synthesizing novel views has seen rapid progressin recent years. Neural Radiance Fields demonstrated that continuous volumetricradiance fields can achieve high-quality image synthesis, but their longtraining and rendering times limit practicality. 3D Gaussian Splatting (3DGS)addressed these issues by representing scenes with millions of Gaussians,enabling real-time rendering and fast optimization. However, Gaussianprimitives are not natively compatible with the mesh-based pipelines used in VRheadsets, and real-time graphics applications. Existing solutions attempt toconvert Gaussians into meshes through post-processing or two-stage pipelines,which increases complexity and degrades visual quality. In this work, weintroduce Triangle Splatting+, which directly optimizes triangles, thefundamental primitive of computer graphics, within a differentiable splattingframework. We formulate triangle parametrization to enable connectivity throughshared vertices, and we design a training strategy that enforces opaquetriangles. The final output is immediately usable in standard graphics engineswithout post-processing. Experiments on the Mip-NeRF360 and Tanks &amp; Templesdatasets show that Triangle Splatting+achieves state-of-the-art performance inmesh-based novel view synthesis. Our method surpasses prior splattingapproaches in visual fidelity while remaining efficient and fast to training.Moreover, the resulting semi-connected meshes support downstream applicationssuch as physics-based simulation or interactive walkthroughs. The project pageis https://trianglesplatting2.github.io/trianglesplatting2/.</description><author>Jan Held, Renaud Vandeghen, Sanghyun Son, Daniel Rebain, Matheus Gadelha, Yi Zhou, Ming C. Lin, Marc Van Droogenbroeck, Andrea Tagliasacchi</author><pubDate>Mon, 29 Sep 2025 17:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25122v1</guid></item><item><title>HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis</title><link>http://arxiv.org/abs/2509.25112v1</link><description>Heatwaves pose complex cascading risks across interconnected climate, social,and economic systems, but knowledge fragmentation in scientific literaturehinders comprehensive understanding of these risk pathways. We introduce HeDA(Heatwave Discovery Agent), an intelligent multi-agent system designed forautomated scientific discovery through knowledge graph construction andmulti-layer risk propagation analysis. HeDA processes over 10,247 academicpapers to construct a comprehensive knowledge graph with 23,156 nodes and89,472 relationships, employing novel multi-layer risk propagation analysis tosystematically identify overlooked risk transmission pathways. Our systemachieves 78.9% accuracy on complex question-answering tasks, outperformingstate-of-the-art baselines including GPT-4 by 13.7%. Critically, HeDAsuccessfully discovered five previously unidentified high-impact risk chains,such as the pathway where a heatwave leads to a water demand surge, resultingin industrial water restrictions and ultimately causing small businessdisruption, which were validated through historical case studies and domainexpert review. This work presents a new paradigm for AI-driven scientificdiscovery, providing actionable insights for developing more resilient climateadaptation strategies.</description><author>Yiquan Wang, Tin-Yeh Huang, Qingyun Gao, Jialin Zhang</author><pubDate>Mon, 29 Sep 2025 17:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25112v1</guid></item><item><title>The Physical Basis of Prediction: World Model Formation in Neural Organoids via an LLM-Generated Curriculum</title><link>http://arxiv.org/abs/2509.04633v2</link><description>The capacity of an embodied agent to understand, predict, and interact withits environment is fundamentally contingent on an internal world model. Thispaper introduces a novel framework for investigating the formation andadaptation of such world models within a biological substrate: human neuralorganoids. We present a curriculum of three scalable, closed-loop virtualenvironments designed to train these biological agents and probe the underlyingsynaptic mechanisms of learning, such as long-term potentiation (LTP) andlong-term depression (LTD). We detail the design of three distinct taskenvironments that demand progressively more sophisticated world models forsuccessful decision-making: (1) a conditional avoidance task for learningstatic state-action contingencies, (2) a one-dimensional predator-prey scenariofor goal-directed interaction, and (3) a replication of the classic Pong gamefor modeling dynamic, continuous-time systems. For each environment, weformalize the state and action spaces, the sensory encoding and motor decodingmechanisms, and the feedback protocols based on predictable (reward) andunpredictable (punishment) stimulation, which serve to drive model refinement.In a significant methodological advance, we propose a meta-learning approachwhere a Large Language Model automates the generative design and optimizationof experimental protocols, thereby scaling the process of environment andcurriculum design. Finally, we outline a multi-modal evaluation strategy thatmoves beyond task performance to directly measure the physical correlates ofthe learned world model by quantifying synaptic plasticity atelectrophysiological, cellular, and molecular levels. This work bridges the gapbetween model-based reinforcement learning and computational neuroscience,offering a unique platform for studying embodiment, decision-making, and thephysical basis of intelligence.</description><author>Brennen Hill</author><pubDate>Mon, 29 Sep 2025 17:40:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.04633v2</guid></item><item><title>Knowledge Extraction on Semi-Structured Content: Does It Remain Relevant for Question Answering in the Era of LLMs?</title><link>http://arxiv.org/abs/2509.25107v1</link><description>The advent of Large Language Models (LLMs) has significantly advancedweb-based Question Answering (QA) systems over semi-structured content, raisingquestions about the continued utility of knowledge extraction for questionanswering. This paper investigates the value of triple extraction in this newparadigm by extending an existing benchmark with knowledge extractionannotations and evaluating commercial and open-source LLMs of varying sizes.Our results show that web-scale knowledge extraction remains a challenging taskfor LLMs. Despite achieving high QA accuracy, LLMs can still benefit fromknowledge extraction, through augmentation with extracted triples andmulti-task learning. These findings provide insights into the evolving role ofknowledge triple extraction in web-based QA and highlight strategies formaximizing LLM effectiveness across different model sizes and resourcesettings.</description><author>Kai Sun, Yin Huang, Srishti Mehra, Mohammad Kachuee, Xilun Chen, Renjie Tao, Zhaojiang Lin, Andrea Jessee, Nirav Shah, Alex Betty, Yue Liu, Anuj Kumar, Wen-tau Yih, Xin Luna Dong</author><pubDate>Mon, 29 Sep 2025 17:39:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25107v1</guid></item><item><title>Towards Personalized Deep Research: Benchmarks and Evaluations</title><link>http://arxiv.org/abs/2509.25106v1</link><description>Deep Research Agents (DRAs) can autonomously conduct complex investigationsand generate comprehensive reports, demonstrating strong real-world potential.However, existing evaluations mostly rely on close-ended benchmarks, whileopen-ended deep research benchmarks remain scarce and typically neglectpersonalized scenarios. To bridge this gap, we introduce Personalized DeepResearch Bench, the first benchmark for evaluating personalization in DRAs. Itpairs 50 diverse research tasks across 10 domains with 25 authentic userprofiles that combine structured persona attributes with dynamic real-worldcontexts, yielding 250 realistic user-task queries. To assess systemperformance, we propose the PQR Evaluation Framework, which jointly measures(P) Personalization Alignment, (Q) Content Quality, and (R) FactualReliability. Our experiments on a range of systems highlight currentcapabilities and limitations in handling personalized deep research. This workestablishes a rigorous foundation for developing and evaluating the nextgeneration of truly personalized AI research assistants.</description><author>Yuan Liang, Jiaxian Li, Yuqing Wang, Piaohong Wang, Motong Tian, Pai Liu, Shuofei Qiao, Runnan Fang, He Zhu, Ge Zhang, Minghao Liu, Yuchen Eleanor Jiang, Ningyu Zhang, Wangchunshu Zhou</author><pubDate>Mon, 29 Sep 2025 17:39:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25106v1</guid></item><item><title>Towards generalizable deep ptychography neural networks</title><link>http://arxiv.org/abs/2509.25104v1</link><description>X-ray ptychography is a data-intensive imaging technique expected to becomeubiquitous at next-generation light sources delivering many-fold increases incoherent flux. The need for real-time feedback under accelerated acquisitionrates motivates surrogate reconstruction models like deep neural networks,which offer orders-of-magnitude speedup over conventional methods. However,existing deep learning approaches lack robustness across diverse experimentalconditions. We propose an unsupervised training workflow emphasizing probelearning by combining experimentally-measured probes with synthetic,procedurally generated objects. This probe-centric approach enables a singlephysics-informed neural network to reconstruct unseen experiments acrossmultiple beamlines; among the first demonstrations of multi-probegeneralization. We find probe learning is equally important as in-distributionlearning; models trained using this synthetic workflow achieve reconstructionfidelity comparable to those trained exclusively on experimental data, evenwhen changing the type of synthetic training object. The proposed approachenables training of experiment-steering models that provide real-time feedbackunder dynamic experimental conditions.</description><author>Albert Vong, Steven Henke, Oliver Hoidn, Hanna Ruth, Junjing Deng, Alexander Hexemer, Apurva Mehta, Arianna Gleason, Levi Hancock, Nicholas Schwarz</author><pubDate>Mon, 29 Sep 2025 17:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25104v1</guid></item><item><title>Hierarchical Task Environments as the Next Frontier for Embodied World Models in Robot Soccer</title><link>http://arxiv.org/abs/2509.04731v2</link><description>Recent advances in agent development have focused on scaling model size andraw interaction data, mirroring the successes seen in large language models.However, for complex, long-horizon multi-agent tasks such as robotic soccer,this end-to-end approach often fails due to intractable exploration spaces andsparse rewards. This position paper argues that the next frontier in developingembodied world models is not merely increasing the fidelity or size ofenvironments, but scaling their structural complexity through explicithierarchical scaffolding. We posit that an effective world model fordecision-making must model not only the world's physics but also its tasksemantics. Drawing from a systematic review of 2024 research in low-resourcemulti-agent soccer, we identify a clear trend towards integrating symbolic andhierarchical methods, such as Hierarchical Task Networks (HTNs) and BayesianStrategy Networks (BSNs), with multi-agent reinforcement learning (MARL). Thesemethods decompose complex goals into manageable subgoals, creating an intrinsiccurriculum that shapes agent learning. We propose that such structuredenvironments are essential for bridging the gap between simple, reactivebehaviors and sophisticated, strategic team play. We further extend thisprinciple, proposing that this scaffolding can be generalized to other complexdomains and dynamically generated by Large Language Models (LLMs), which act asgenerative world models of tasks. By building environments with explicit,composable task layers, we can guide agent exploration more efficiently,generate meaningful learning signals, and ultimately train more capable andgeneral-purpose agents with fewer resources than purely end-to-end approaches.</description><author>Brennen Hill</author><pubDate>Mon, 29 Sep 2025 17:38:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.04731v2</guid></item><item><title>Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations</title><link>http://arxiv.org/abs/2508.15816v2</link><description>Airborne Base Stations (ABSs) allow for flexible geographical allocation ofnetwork resources with dynamically changing load as well as rapid deployment ofalternate connectivity solutions during natural disasters. Since the radioinfrastructure is carried by unmanned aerial vehicles (UAVs) with limitedflight time, it is important to establish the best location for the ABS withoutexhaustive field trials. This paper proposes a digital twin (DT)-guidedapproach to achieve this through the following key contributions: (i)Implementation of an interactive software bridge between two open-source DTssuch that the same scene is evaluated with high fidelity across NVIDIA's Sionnaand Aerial Omniverse Digital Twin (AODT), highlighting the unique features ofeach of these platforms for this allocation problem, (ii) Design of aback-propagation-based algorithm in Sionna for rapidly converging on thephysical location of the UAVs, orientation of the antennas and transmit powerto ensure efficient coverage across the swarm of the UAVs, and (iii) numericalevaluation in AODT for large network scenarios (50 UEs, 10 ABS) that identifiesthe environmental conditions in which there is agreement or divergence ofperformance results between these twins. Finally, (iv) we propose a resiliencemechanism to provide consistent coverage to mission-critical devices anddemonstrate a use case for bi-directional flow of information between the twoDTs.</description><author>Mauro Belgiovine, Chris Dick, Kaushik Chowdhury</author><pubDate>Mon, 29 Sep 2025 17:34:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.15816v2</guid></item><item><title>ORPO-Distill: Mixed-Policy Preference Optimization for Cross-Architecture LLM Distillation</title><link>http://arxiv.org/abs/2509.25100v1</link><description>We introduce ORPO-Distill, a general-purpose method for cross-architectureLLM distillation that formulates the problem as a preference optimization task.Unlike standard CoT distillation, the approach transfers knowledge throughdiverse reasoning traces. It employs an Odds-Ratio Preference Optimizationobjective that contrasts teacher and student traces for more effectivelearning, and adopts a mixed-policy strategy for utilizing student-generatedoutputs, outperforming both off- and on-policy alternatives. Experiments onfive datasets and multiple student models show consistent improvements overconventional black-box KD baselines.</description><author>Aasheesh Singh, Vishal Vaddina, Dagnachew Birru</author><pubDate>Mon, 29 Sep 2025 17:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25100v1</guid></item><item><title>Curriculum Imitation Learning of Distributed Multi-Robot Policies</title><link>http://arxiv.org/abs/2509.25097v1</link><description>Learning control policies for multi-robot systems (MRS) remains a majorchallenge due to long-term coordination and the difficulty of obtainingrealistic training data. In this work, we address both limitations within animitation learning framework. First, we shift the typical role of CurriculumLearning in MRS, from scalability with the number of robots, to focus onimproving long-term coordination. We propose a curriculum strategy thatgradually increases the length of expert trajectories during training,stabilizing learning and enhancing the accuracy of long-term behaviors. Second,we introduce a method to approximate the egocentric perception of each robotusing only third-person global state demonstrations. Our approach transformsidealized trajectories into locally available observations by filteringneighbors, converting reference frames, and simulating onboard sensorvariability. Both contributions are integrated into a physics-informedtechnique to produce scalable, distributed policies from observations. Weconduct experiments across two tasks with varying team sizes and noise levels.Results show that our curriculum improves long-term accuracy, while ourperceptual estimation method yields policies that are robust to realisticuncertainty. Together, these strategies enable the learning of robust,distributed controllers from global demonstrations, even in the absence ofexpert actions or onboard measurements.</description><author>Jesús Roche, Eduardo Sebastián, Eduardo Montijano</author><pubDate>Mon, 29 Sep 2025 17:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25097v1</guid></item><item><title>Agribot: agriculture-specific question answer system</title><link>http://arxiv.org/abs/2509.21535v2</link><description>India is an agro-based economy and proper information about agriculturalpractices is the key to optimal agricultural growth and output. In order toanswer the queries of the farmer, we have build an agricultural chatbot basedon the dataset from Kisan Call Center. This system is robust enough to answerqueries related to weather, market rates, plant protection and governmentschemes. This system is available 24* 7, can be accessed through any electronicdevice and the information is delivered with the ease of understanding. Thesystem is based on a sentence embedding model which gives an accuracy of 56%.After eliminating synonyms and incorporating entity extraction, the accuracyjumps to 86%. With such a system, farmers can progress towards easierinformation about farming related practices and hence a better agriculturaloutput. The job of the Call Center workforce would be made easier and the hardwork of various such workers can be redirected to a better goal.</description><author>Naman Jain, Pranjali Jain, Pratik Kayal, Jayakrishna Sahit, Soham Pachpande, Jayesh Choudhari, Mayank Singh</author><pubDate>Mon, 29 Sep 2025 17:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21535v2</guid></item><item><title>Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks</title><link>http://arxiv.org/abs/2509.25095v1</link><description>The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yetmachine learning for ECG interpretation remains fragmented, often limited tonarrow tasks or datasets. Foundation models promise broader adaptability, buttheir generalization across diverse ECG tasks is not well understood. Webenchmarked eight ECG foundation models on 26 clinically relevant tasks using12 public datasets comprising 1,650 regression and classification targets.Models were evaluated under fine-tuning and frozen settings, with scalinganalyses across dataset sizes. Results show heterogeneous performance acrossdomains: in the most widely studied domain, adult ECG interpretation, threefoundation models consistently outperformed strong supervised baselines. Incontrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,dominated other categories where most foundation models failed to surpasssupervised learning. Foundation models also displayed distinct scalingbehaviors with dataset size, which are critical for small-scale clinicalapplications. Overall, while foundation models show promise for adult ECGanalysis, substantial gaps remain in cardiac structure, outcome prediction, andpatient characterization. Notably, ECG-CPC's strong performance despite beingorders of magnitude smaller and consuming minimal computational resourceshighlights untapped opportunities for advancing ECG foundation models.</description><author>M A Al-Masud, Juan Miguel Lopez Alcaraz, Nils Strodthoff</author><pubDate>Mon, 29 Sep 2025 17:29:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25095v1</guid></item><item><title>$\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization</title><link>http://arxiv.org/abs/2509.21519v2</link><description>While the phenomenon of grokking, i.e., delayed generalization, has beenstudied extensively, it remains an open problem whether there is a mathematicalframework to characterize what kind of features will emerge, how and in whichconditions it happens from training, for complex structured inputs. We proposea novel framework, named $\mathbf{Li_2}$, that captures three key stages forthe grokking behavior of 2-layer nonlinear networks: (I)\underline{\textbf{L}}azy learning, (II) \underline{\textbf{i}}ndependentfeature learning and (III) \underline{\textbf{i}}nteractive feature learning.At the lazy learning stage, top layer overfits to random hidden representationand the model appears to memorize. Thanks to lazy learning and weight decay,the \emph{backpropagated gradient} $G_F$ from the top layer now carriesinformation about the target label, with a specific structure that enables eachhidden node to learn their representation \emph{independently}. Interestingly,the independent dynamics follows exactly the \emph{gradient ascent} of anenergy function $E$, and its local maxima are precisely the emerging features.We study whether these local-optima induced features are generalizable, theirrepresentation power, and how they change on sample size, in group arithmetictasks. When hidden nodes start to interact in the later stage of learning, weprovably show how $G_F$ changes to focus on missing features that need to belearned. Our study sheds lights on roles played by key hyperparameters such asweight decay, learning rate and sample sizes in grokking, leads to provablescaling laws of memorization and generalization, and reveals the underlyingcause why recent optimizers such as Muon can be effective, from the firstprinciples of gradient dynamics. Our analysis can be extended to multi-layerarchitectures.</description><author>Yuandong Tian</author><pubDate>Mon, 29 Sep 2025 17:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.21519v2</guid></item><item><title>Unsupervised Representation Learning for 3D Mesh Parameterization with Semantic and Visibility Objectives</title><link>http://arxiv.org/abs/2509.25094v1</link><description>Recent 3D generative models produce high-quality textures for 3D meshobjects. However, they commonly rely on the heavy assumption that input 3Dmeshes are accompanied by manual mesh parameterization (UV mapping), a manualtask that requires both technical precision and artistic judgment. Industrysurveys show that this process often accounts for a significant share of assetcreation, creating a major bottleneck for 3D content creators. Moreover,existing automatic methods often ignore two perceptually important criteria:(1) semantic awareness (UV charts should align semantically similar 3D partsacross shapes) and (2) visibility awareness (cutting seams should lie inregions unlikely to be seen). To overcome these shortcomings and to automatethe mesh parameterization process, we present an unsupervised differentiableframework that augments standard geometry-preserving UV learning with semantic-and visibility-aware objectives. For semantic-awareness, our pipeline (i)segments the mesh into semantic 3D parts, (ii) applies an unsupervised learnedper-part UV-parameterization backbone, and (iii) aggregates per-part chartsinto a unified UV atlas. For visibility-awareness, we use ambient occlusion(AO) as an exposure proxy and back-propagate a soft differentiable AO-weightedseam objective to steer cutting seams toward occluded regions. By conductingqualitative and quantitative evaluations against state-of-the-art methods, weshow that the proposed method produces UV atlases that better support texturegeneration and reduce perceptible seam artifacts compared to recent baselines.Our implementation code is publicly available at:https://github.com/AHHHZ975/Semantic-Visibility-UV-Param.</description><author>AmirHossein Zamani, Bruno Roy, Arianna Rampini</author><pubDate>Mon, 29 Sep 2025 17:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25094v1</guid></item><item><title>Scaling with Collapse: Efficient and Predictable Training of LLM Families</title><link>http://arxiv.org/abs/2509.25087v1</link><description>Effective LLM training relies on *consistency*, meaning that key quantities-- such as final losses and optimal hyperparameters -- scale predictably acrossmodel sizes. Qiu et al. (2025) recently showed that this consistency extendsbeyond scalars: whole training loss curves can *collapse* onto a universaltrajectory after a simple normalization. What remains unclear is whether thisphenomenon holds for LLM families trained under *practical scaling recipes*,where width, depth, learning rate, batch size, and weight decay are scaledjointly. We show that it does: loss curves collapse across scales preciselywhen optimization hyperparameters are set optimally for the given data budget,in accordance with recent empirical scaling laws. Collapse thus emerges as asignature of compute-efficient training. We demonstrate two applications atscale: (1) deviation-from-collapse provides a sensitive, early diagnostic oftraining pathologies, and (2) the predictability of collapsed curves enablesearly stopping in large-scale hyperparameter tuning. Finally, we train acompetitive LLM family, *Celerity*, using these insights, highlighting collapseas an effective tool for developing efficient LLMs.</description><author>Shane Bergsma, Bin Claire Zhang, Nolan Dey, Shaheer Muhammad, Gurpreet Gosal, Joel Hestness</author><pubDate>Mon, 29 Sep 2025 17:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25087v1</guid></item><item><title>Towards Trustworthy Lexical Simplification: Exploring Safety and Efficiency with Small LLMs</title><link>http://arxiv.org/abs/2509.25086v1</link><description>Despite their strong performance, large language models (LLMs) facechallenges in real-world application of lexical simplification (LS),particularly in privacy-sensitive and resource-constrained environments.Moreover, since vulnerable user groups (e.g., people with disabilities) are oneof the key target groups of this technology, it is crucial to ensure the safetyand correctness of the output of LS systems. To address these issues, wepropose an efficient framework for LS systems that utilizes small LLMsdeployable in local environments. Within this framework, we explore knowledgedistillation with synthesized data and in-context learning as baselines. Ourexperiments in five languages evaluate model outputs both automatically andmanually. Our manual analysis reveals that while knowledge distillation boostsautomatic metric scores, it also introduces a safety trade-off by increasingharmful simplifications. Importantly, we find that the model's outputprobability is a useful signal for detecting harmful simplifications.Leveraging this, we propose a filtering strategy that suppresses harmfulsimplifications while largely preserving beneficial ones. This work establishesa benchmark for efficient and safe LS with small LLMs. It highlights the keytrade-offs between performance, efficiency, and safety, and demonstrates apromising approach for safe real-world deployment.</description><author>Akio Hayakawa, Stefan Bott, Horacio Saggion</author><pubDate>Mon, 29 Sep 2025 17:25:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25086v1</guid></item><item><title>Causal Attention with Lookahead Keys</title><link>http://arxiv.org/abs/2509.07301v2</link><description>In standard causal attention, each token's query, key, and value (QKV) arestatic and encode only preceding context. We introduce CAuSal aTtention withLookahead kEys (CASTLE), an attention mechanism that continually updates eachtoken's keys as the context unfolds. We term these updated keys lookahead keysbecause they belong to earlier positions yet integrate information from tokensthat appear later relative to those positions, while strictly preserving theautoregressive property. Although the mechanism appears sequential, we derive amathematical equivalence that avoids explicitly materializing lookahead keys ateach position and enables efficient parallel training. On language modelingbenchmarks, CASTLE consistently outperforms standard causal attention acrossmodel scales, reducing validation perplexity and improving performance on arange of downstream tasks.</description><author>Zhuoqing Song, Peng Sun, Huizhuo Yuan, Quanquan Gu</author><pubDate>Mon, 29 Sep 2025 17:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.07301v2</guid></item><item><title>jina-reranker-v3: Last but Not Late Interaction for Document Reranking</title><link>http://arxiv.org/abs/2509.25085v1</link><description>jina-reranker-v3 is a 0.6B parameter multilingual document reranker thatintroduces a novel last but not late interaction. Unlike late interactionmodels such as ColBERT that perform separate encoding followed by multi-vectormatching, our approach conducts causal self-attention between query anddocuments within the same context window, enabling rich cross-documentinteractions before extracting contextual embeddings from the last token ofeach document. This compact architecture achieves state-of-the-art BEIRperformance with 61.94 nDCG@10 while being ten times smaller than generativelistwise rerankers.</description><author>Feng Wang, Yuqing Li, Han Xiao</author><pubDate>Mon, 29 Sep 2025 17:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25085v1</guid></item><item><title>Scaling Generalist Data-Analytic Agents</title><link>http://arxiv.org/abs/2509.25084v1</link><description>Data-analytic agents are emerging as a key catalyst for automated scientificdiscovery and for the vision of Innovating AI. Current approaches, however,rely heavily on prompt engineering over proprietary models, while open-sourcemodels struggle to face diverse-format, large-scale data files andlong-horizon, multi-step reasoning that real-world analytics demands. Thispaper introduces DataMind, a scalable data synthesis and agent training recipedesigned to build generalist data-analytic agents. DataMind tackles three keychallenges in building open-source data-analytic agents, including insufficientdata resources, improper training strategy, and unstable code-based multi-turnrollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and arecursive easy-to-hard task composition mechanism to increase the diversity anddifficulty of synthesized queries; 2) a knowledge-augmented trajectory samplingstrategy followed by model-based and rule-based filtering; 3) a dynamicallyadjustable training objective combining both SFT and RL losses; 4) amemory-frugal and stable code-based multi-turn rollout framework. Built onDataMind, we curate DataMind-12K, a high-quality trajectory set spanningdiverse domains, task categories, and data file formats for data-analytictasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art withan average score of 71.16% on multiple data analysis benchmarks, outperformingthe strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7Balso performs best among all open-source models with a score of 68.10%. We alsoincorporate some empirical insights gained from our exploratory trials into theanalysis experiments, aiming to provide actionable insights about agentictraining for the community. We will release DataMind-12K and DataMind-7B,14Bfor the community's future research.</description><author>Shuofei Qiao, Yanqiu Zhao, Zhisong Qiu, Xiaobin Wang, Jintian Zhang, Zhao Bin, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</author><pubDate>Mon, 29 Sep 2025 17:23:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25084v1</guid></item><item><title>MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification</title><link>http://arxiv.org/abs/2509.25082v1</link><description>Adversarial purification with diffusion models has emerged as a promisingdefense strategy, but existing methods typically rely on uniform noiseinjection, which indiscriminately perturbs all frequencies, corrupting semanticstructures and undermining robustness. Our empirical study reveals thatadversarial perturbations are not uniformly distributed: they are predominantlyconcentrated in high-frequency regions, with heterogeneous magnitude intensitypatterns that vary across frequencies and attack types. Motivated by thisobservation, we introduce MANI-Pure, a magnitude-adaptive purificationframework that leverages the magnitude spectrum of inputs to guide thepurification process. Instead of injecting homogeneous noise, MANI-Pureadaptively applies heterogeneous, frequency-targeted noise, effectivelysuppressing adversarial perturbations in fragile high-frequency, low-magnitudebands while preserving semantically critical low-frequency content. Extensiveexperiments on CIFAR-10 and ImageNet-1K validate the effectiveness ofMANI-Pure. It narrows the clean accuracy gap to within 0.59 of the originalclassifier, while boosting robust accuracy by 2.15, and achieves the top-1robust accuracy on the RobustBench leaderboard, surpassing the previousstate-of-the-art method.</description><author>Xiaoyi Huang, Junwei Wu, Kejia Zhang, Carl Yang, Zhiming Luo</author><pubDate>Mon, 29 Sep 2025 17:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25082v1</guid></item><item><title>Towards a Certificate of Trust: Task-Aware OOD Detection for Scientific AI</title><link>http://arxiv.org/abs/2509.25080v1</link><description>Data-driven models are increasingly adopted in critical scientific fieldslike weather forecasting and fluid dynamics. These methods can fail onout-of-distribution (OOD) data, but detecting such failures in regression tasksis an open challenge. We propose a new OOD detection method based on estimatingjoint likelihoods using a score-based diffusion model. This approach considersnot just the input but also the regression model's prediction, providing atask-aware reliability score. Across numerous scientific datasets, includingPDE datasets, satellite imagery and brain tumor segmentation, we show that thislikelihood strongly correlates with prediction error. Our work provides afoundational step towards building a verifiable 'certificate of trust', therebyoffering a practical tool for assessing the trustworthiness of AI-basedscientific predictions. Our code is publicly available athttps://github.com/bogdanraonic3/OOD_Detection_ScientificML</description><author>Bogdan Raonić, Siddhartha Mishra, Samuel Lanthaler</author><pubDate>Mon, 29 Sep 2025 17:21:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25080v1</guid></item><item><title>UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D Generation</title><link>http://arxiv.org/abs/2509.25079v1</link><description>High-fidelity 3D asset generation is crucial for various industries. Whilerecent 3D pretrained models show strong capability in producing realisticcontent, most are built upon diffusion models and follow a two-stage pipelinethat first generates geometry and then synthesizes appearance. Such a decoupleddesign tends to produce geometry-texture misalignment and non-negligible cost.In this paper, we propose UniLat3D, a unified framework that encodes geometryand appearance in a single latent space, enabling direct single-stagegeneration. Our key contribution is a geometry-appearance Unified VAE, whichcompresses high-resolution sparse features into a compact latent representation-- UniLat. UniLat integrates structural and visual information into a denselow-resolution latent, which can be efficiently decoded into diverse 3Dformats, e.g., 3D Gaussians and meshes. Based on this unified representation,we train a single flow-matching model to map Gaussian noise directly intoUniLat, eliminating redundant stages. Trained solely on public datasets,UniLat3D produces high-quality 3D assets in seconds from a single image,achieving superior appearance fidelity and geometric quality. More demos \&amp;code are available at https://unilat3d.github.io/</description><author>Guanjun Wu, Jiemin Fang, Chen Yang, Sikuang Li, Taoran Yi, Jia Lu, Zanwei Zhou, Jiazhong Cen, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Xinggang Wang, Qi Tian</author><pubDate>Mon, 29 Sep 2025 17:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25079v1</guid></item><item><title>BRIDGE -- Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation</title><link>http://arxiv.org/abs/2509.25077v1</link><description>Monocular Depth Estimation (MDE) is a foundational task for computer vision.Traditional methods are limited by data scarcity and quality, hindering theirrobustness. To overcome this, we propose BRIDGE, an RL-optimized depth-to-image(D2I) generation framework that synthesizes over 20M realistic andgeometrically accurate RGB images, each intrinsically paired with its groundtruth depth, from diverse source depth maps. Then we train our depth estimationmodel on this dataset, employing a hybrid supervision strategy that integratesteacher pseudo-labels with ground truth depth for comprehensive and robusttraining. This innovative data generation and training paradigm enables BRIDGEto achieve breakthroughs in scale and domain diversity, consistentlyoutperforming existing state-of-the-art approaches quantitatively and incomplex scene detail capture, thereby fostering general and robust depthfeatures. Code and models are available athttps://dingning-liu.github.io/bridge.github.io/.</description><author>Dingning Liu, Haoyu Guo, Jingyi Zhou, Tong He</author><pubDate>Mon, 29 Sep 2025 17:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25077v1</guid></item><item><title>GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction</title><link>http://arxiv.org/abs/2509.25075v1</link><description>Cryo-electron microscopy (cryo-EM) has become a central tool forhigh-resolution structural biology, yet the massive scale of datasets (oftenexceeding 100k particle images) renders 3D reconstruction both computationallyexpensive and memory intensive. Traditional Fourier-space methods are efficientbut lose fidelity due to repeated transforms, while recent real-spaceapproaches based on neural radiance fields (NeRFs) improve accuracy but incurcubic memory and computation overhead. Therefore, we introduce GEM, a novelcryo-EM reconstruction framework built on 3D Gaussian Splatting (3DGS) thatoperates directly in real-space while maintaining high efficiency. Instead ofmodeling the entire density volume, GEM represents proteins with compact 3DGaussians, each parameterized by only 11 values. To further improve thetraining efficiency, we designed a novel gradient computation to 3D Gaussiansthat contribute to each voxel. This design substantially reduced both memoryfootprint and training cost. On standard cryo-EM benchmarks, GEM achieves up to48% faster training and 12% lower memory usage compared to state-of-the-artmethods, while improving local resolution by as much as 38.8%. These resultsestablish GEM as a practical and scalable paradigm for cryo-EM reconstruction,unifying speed, efficiency, and high-resolution accuracy. Our code is availableat https://github.com/UNITES-Lab/GEM.</description><author>Huaizhi Qu, Xiao Wang, Gengwei Zhang, Jie Peng, Tianlong Chen</author><pubDate>Mon, 29 Sep 2025 17:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25075v1</guid></item><item><title>An empirical study on the limitation of Transformers in program trace generation</title><link>http://arxiv.org/abs/2509.25073v1</link><description>We study Transformers on the task \emph{program trace generation} (PTG),where models produce step-by-step execution traces for synthetic programs.Unlike existing algorithmic problems, PTG externalizes reasoning through longtraces where each step is trivial. We train small Transformers with diversemodifications, including alternative position encodings, softmax replacements,hybrid model, and short convolutions. While these models achieve strongin-distribution accuracy, they exhibit systematic failures when generalizing tovarious factors (e.g., program length, trace steps), though some designssignificantly improve generalization.</description><author>Simeng Sun</author><pubDate>Mon, 29 Sep 2025 17:17:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25073v1</guid></item><item><title>Optimizing Privacy-Preserving Primitives to Support LLM-Scale Applications</title><link>http://arxiv.org/abs/2509.25072v1</link><description>Privacy-preserving technologies have introduced a paradigm shift that allowsfor realizable secure computing in real-world systems. The significant barrierto the practical adoption of these primitives is the computational andcommunication overhead that is incurred when applied at scale. In this paper,we present an overview of our efforts to bridge the gap between this overheadand practicality for privacy-preserving learning systems using multi-partycomputation (MPC), zero-knowledge proofs (ZKPs), and fully homomorphicencryption (FHE). Through meticulous hardware/software/algorithm co-design, weshow progress towards enabling LLM-scale applications in privacy-preservingsettings. We demonstrate the efficacy of our solutions in several contexts,including DNN IP ownership, ethical LLM usage enforcement, and transformerinference.</description><author>Yaman Jandali, Ruisi Zhang, Nojan Sheybani, Farinaz Koushanfar</author><pubDate>Mon, 29 Sep 2025 17:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25072v1</guid></item><item><title>Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers</title><link>http://arxiv.org/abs/2509.22445v2</link><description>The Minimum Description Length (MDL) principle offers a formal framework forapplying Occam's razor in machine learning. However, its application to neuralnetworks such as Transformers is challenging due to the lack of a principled,universal measure for model complexity. This paper introduces the theoreticalnotion of asymptotically optimal description length objectives, grounded in thetheory of Kolmogorov complexity. We establish that a minimizer of such anobjective achieves optimal compression, for any dataset, up to an additiveconstant, in the limit as model resource bounds increase. We prove thatasymptotically optimal objectives exist for Transformers, building on a newdemonstration of their computational universality. We further show that suchobjectives can be tractable and differentiable by constructing and analyzing avariational objective based on an adaptive Gaussian mixture prior. Ourempirical analysis shows that this variational objective selects for alow-complexity solution with strong generalization on an algorithmic task, butstandard optimizers fail to find such solutions from a random initialization,highlighting key optimization challenges. More broadly, by providing atheoretical framework for identifying description length objectives with strongasymptotic guarantees, we outline a potential path towards training neuralnetworks that achieve greater compression and generalization.</description><author>Peter Shaw, James Cohan, Jacob Eisenstein, Kristina Toutanova</author><pubDate>Mon, 29 Sep 2025 17:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22445v2</guid></item><item><title>Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study</title><link>http://arxiv.org/abs/2509.25063v1</link><description>Survey researchers face two key challenges: the rising costs of probabilitysamples and missing data (e.g., non-response or attrition), which can undermineinference and increase the use of convenience samples. Recent work exploresusing large language models (LLMs) to simulate respondents via persona-basedprompts, often without labeled data. We study a more practical setting wherepartial survey responses exist: we fine-tune LLMs on available data to imputeself-reported vote choice under both random and systematic nonresponse, usingthe German Longitudinal Election Study. We compare zero-shot prompting andsupervised fine-tuning against tabular classifiers (e.g., CatBoost) and testhow different convenience samples (e.g., students) used for fine-tuning affectgeneralization. Our results show that when data are missing completely at random, fine-tunedLLMs match tabular classifiers but outperform zero-shot approaches. When onlybiased convenience samples are available, fine-tuning small (3B to 8B)open-source LLMs can recover both individual-level predictions andpopulation-level distributions more accurately than zero-shot and often betterthan tabular methods. This suggests fine-tuned LLMs offer a promising strategyfor researchers working with non-probability samples or systematic missingness,and may enable new survey designs requiring only easily accessiblesubpopulations.</description><author>Tobias Holtdirk, Dennis Assenmacher, Arnim Bleier, Claudia Wagner</author><pubDate>Mon, 29 Sep 2025 17:12:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25063v1</guid></item><item><title>CharGen: Fast and Fluent Portrait Modification</title><link>http://arxiv.org/abs/2509.25058v1</link><description>Interactive editing of character images with diffusion models remainschallenging due to the inherent trade-off between fine-grained control,generation speed, and visual fidelity. We introduce CharGen, acharacter-focused editor that combines attribute-specific Concept Sliders,trained to isolate and manipulate attributes such as facial feature size,expression, and decoration with the StreamDiffusion sampling pipeline for moreinteractive performance. To counteract the loss of detail that oftenaccompanies accelerated sampling, we propose a lightweight Repair Step thatreinstates fine textures without compromising structural consistency.Throughout extensive ablation studies and in comparison to open-sourceInstructPix2Pix and closed-source Google Gemini, and a comprehensive userstudy, CharGen achieves two-to-four-fold faster edit turnaround with preciseediting control and identity-consistent results. Project page:https://chargen.jdihlmann.com/</description><author>Jan-Niklas Dihlmann, Arnela Killguss, Hendrik P. A. Lensch</author><pubDate>Mon, 29 Sep 2025 17:09:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25058v1</guid></item><item><title>Cogito, Ergo Ludo: An Agent that Learns to Play by Reasoning and Planning</title><link>http://arxiv.org/abs/2509.25052v1</link><description>The pursuit of artificial agents that can learn to master complexenvironments has led to remarkable successes, yet prevailing deep reinforcementlearning methods often rely on immense experience, encoding their knowledgeopaquely within neural network weights. We propose a different paradigm, one inwhich an agent learns to play by reasoning and planning. We introduce Cogito,ergo ludo (CEL), a novel agent architecture that leverages a Large LanguageModel (LLM) to build an explicit, language-based understanding of itsenvironment's mechanics and its own strategy. Starting from a tabula rasa statewith no prior knowledge (except action set), CEL operates on a cycle ofinteraction and reflection. After each episode, the agent analyzes its completetrajectory to perform two concurrent learning processes: Rule Induction, whereit refines its explicit model of the environment's dynamics, and Strategy andPlaybook Summarization, where it distills experiences into an actionablestrategic playbook. We evaluate CEL on diverse grid-world tasks (i.e.,Minesweeper, Frozen Lake, and Sokoban), and show that the CEL agentsuccessfully learns to master these games by autonomously discovering theirrules and developing effective policies from sparse rewards. Ablation studiesconfirm that the iterative process is critical for sustained learning. Our workdemonstrates a path toward more general and interpretable agents that not onlyact effectively but also build a transparent and improving model of their worldthrough explicit reasoning on raw experience.</description><author>Sai Wang, Yu Wu, Zhongwen Xu</author><pubDate>Mon, 29 Sep 2025 17:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25052v1</guid></item><item><title>Symmetry-Aware Bayesian Optimization via Max Kernels</title><link>http://arxiv.org/abs/2509.25051v1</link><description>Bayesian Optimization (BO) is a powerful framework for optimizing noisy,expensive-to-evaluate black-box functions. When the objective exhibitsinvariances under a group action, exploiting these symmetries can substantiallyimprove BO efficiency. While using maximum similarity across group orbits haslong been considered in other domains, the fact that the max kernel is notpositive semidefinite (PSD) has prevented its use in BO. In this work, werevisit this idea by considering a PSD projection of the max kernel. Comparedto existing invariant (and non-invariant) kernels, we show it achievessignificantly lower regret on both synthetic and real-world BO benchmarks,without increasing computational complexity.</description><author>Anthony Bardou, Antoine Gonon, Aryan Ahadinia, Patrick Thiran</author><pubDate>Mon, 29 Sep 2025 17:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25051v1</guid></item><item><title>Advantage Weighted Matching: Aligning RL with Pretraining in Diffusion Models</title><link>http://arxiv.org/abs/2509.25050v1</link><description>Reinforcement Learning (RL) has emerged as a central paradigm for advancingLarge Language Models (LLMs), where pre-training and RL post-training share thesame log-likelihood formulation. In contrast, recent RL approaches fordiffusion models, most notably Denoising Diffusion Policy Optimization (DDPO),optimize an objective different from the pretraining objectives--score/flowmatching loss. In this work, we establish a novel theoretical analysis: DDPO isan implicit form of score/flow matching with noisy targets, which increasesvariance and slows convergence. Building on this analysis, we introduce\textbf{Advantage Weighted Matching (AWM)}, a policy-gradient method fordiffusion. It uses the same score/flow-matching loss as pretraining to obtain alower-variance objective and reweights each sample by its advantage. In effect,AWM raises the influence of high-reward samples and suppresses low-reward oneswhile keeping the modeling objective identical to pretraining. This unifiespretraining and RL conceptually and practically, is consistent withpolicy-gradient theory, reduces variance, and yields faster convergence. Thissimple yet effective design yields substantial benefits: on GenEval, OCR, andPickScore benchmarks, AWM delivers up to a $24\times$ speedup over Flow-GRPO(which builds on DDPO), when applied to Stable Diffusion 3.5 Medium and FLUX,without compromising generation quality. Code is available athttps://github.com/scxue/advantage_weighted_matching.</description><author>Shuchen Xue, Chongjian Ge, Shilong Zhang, Yichen Li, Zhi-Ming Ma</author><pubDate>Mon, 29 Sep 2025 17:02:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25050v1</guid></item><item><title>Efficient Hyperparameter Tuning via Trajectory Invariance Principle</title><link>http://arxiv.org/abs/2509.25049v1</link><description>As hyperparameter tuning becomes increasingly costly at scale, efficienttuning methods are essential. Yet principles for guiding hyperparameter tuningremain limited. In this work, we seek to establish such principles byconsidering a broad range of hyperparameters, including batch size, learningrate, and weight decay. We identify a phenomenon we call trajectory invariance,where pre-training loss curves, gradient noise, and gradient norm exhibitinvariance--closely overlapping--with respect to a quantity that combineslearning rate and weight decay. This phenomenon effectively reduces theoriginal two-dimensional hyperparameter space to one dimension, yielding anefficient tuning rule: follow the salient direction revealed by trajectoryinvariance. Furthermore, we refine previous scaling laws and challenge severalexisting viewpoints. Overall, our work proposes new principles for efficienttuning and inspires future research on scaling laws.</description><author>Bingrui Li, Jiaxin Wen, Zhanpeng Zhou, Jun Zhu, Jianfei Chen</author><pubDate>Mon, 29 Sep 2025 17:01:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25049v1</guid></item><item><title>Confidence-Guided Error Correction for Disordered Speech Recognition</title><link>http://arxiv.org/abs/2509.25048v1</link><description>We investigate the use of large language models (LLMs) as post-processingmodules for automatic speech recognition (ASR), focusing on their ability toperform error correction for disordered speech. In particular, we proposeconfidence-informed prompting, where word-level uncertainty estimates areembedded directly into LLM training to improve robustness and generalizationacross speakers and datasets. This approach directs the model to uncertain ASRregions and reduces overcorrection. We fine-tune a LLaMA 3.1 model and compareour approach to both transcript-only fine-tuning and post hoc confidence-basedfiltering. Evaluations show that our method achieves a 10% relative WERreduction compared to naive LLM correction on the Speech Accessibility Projectspontaneous speech and a 47% reduction on TORGO, demonstrating theeffectiveness of confidence-aware fine-tuning for impaired speech.</description><author>Abner Hernandez, Tomás Arias Vergara, Andreas Maier, Paula Andrea Pérez-Toro</author><pubDate>Mon, 29 Sep 2025 17:00:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25048v1</guid></item><item><title>Scaling Synthetic Task Generation for Agents via Exploration</title><link>http://arxiv.org/abs/2509.25047v1</link><description>Post-Training Multimodal Large Language Models (MLLMs) to build interactiveagents holds promise across domains such as computer-use, web navigation, androbotics. A key challenge in scaling such post-training is lack of high-qualitydownstream agentic task datasets with tasks that are diverse, feasible, andverifiable. Existing approaches for task generation rely heavily on humanannotation or prompting MLLM with limited downstream environment information,which is either costly or poorly scalable as it yield tasks with limitedcoverage. To remedy this, we present AutoPlay, a scalable pipeline for taskgeneration that explicitly explores interactive environments to discoverpossible interactions and current state information to synthesizeenvironment-grounded tasks. AutoPlay operates in two stages: (i) an explorationphase, where an MLLM explorer agent systematically uncovers novel environmentstates and functionalities, and (ii) a task generation phase, where a taskgenerator leverages exploration trajectories and a set of task guidelineprompts as context to synthesize diverse, executable, and verifiable tasks. Weshow AutoPlay generates 20k tasks across 20 Android applications and 10k tasksacross 13 applications Ubuntu applications to train mobile-use and computer-useagents. AutoPlay generated tasks enable large-scale task demonstrationsynthesis without human annotation by employing an MLLM task executor andverifier. This data enables training MLLM-based UI agents that improve successrates up to $20.0\%$ on mobile-use and $10.9\%$ on computer-use scenarios. Inaddition, AutoPlay generated tasks combined with MLLM verifier-based rewardsenable scaling reinforcement learning training of UI agents, leading to anadditional $5.7\%$ gain. coverage. These results establish AutoPlay as ascalable approach for post-training capable MLLM agents reducing reliance onhuman annotation.</description><author>Ram Ramrakhya, Andrew Szot, Omar Attia, Yuhao Yang, Anh Nguyen, Bogdan Mazoure, Zhe Gan, Harsh Agrawal, Alexander Toshev</author><pubDate>Mon, 29 Sep 2025 17:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25047v1</guid></item><item><title>Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures</title><link>http://arxiv.org/abs/2509.25045v1</link><description>Despite their capabilities, Large Language Models (LLMs) remain opaque withlimited understanding of their internal representations. Currentinterpretability methods, such as direct logit attribution (DLA) and sparseautoencoders (SAEs), provide restricted insight due to limitations such as themodel's output vocabulary or unclear feature names. This work introducesHyperdimensional Probe, a novel paradigm for decoding information from the LLMvector space. It combines ideas from symbolic representations and neuralprobing to project the model's residual stream into interpretable concepts viaVector Symbolic Architectures (VSAs). This probe combines the strengths of SAEsand conventional probes while overcoming their key limitations. We validate ourdecoding paradigm with controlled input-completion tasks, probing the model'sfinal state before next-token prediction on inputs spanning syntactic patternrecognition, key-value associations, and abstract inference. We further assessit in a question-answering setting, examining the state of the model bothbefore and after text generation. Our experiments show that our probe reliablyextracts meaningful concepts across varied LLMs, embedding sizes, and inputdomains, also helping identify LLM failures. Our work advances informationdecoding in LLM vector space, enabling extracting more informative,interpretable, and structured features from neural representations.</description><author>Marco Bronzini, Carlo Nicolini, Bruno Lepri, Jacopo Staiano, Andrea Passerini</author><pubDate>Mon, 29 Sep 2025 16:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25045v1</guid></item><item><title>A Scalable Distributed Framework for Multimodal GigaVoxel Image Registration</title><link>http://arxiv.org/abs/2509.25044v1</link><description>In this work, we propose FFDP, a set of IO-aware non-GEMM fused kernelssupplemented with a distributed framework for image registration atunprecedented scales. Image registration is an inverse problem fundamental tobiomedical and life sciences, but algorithms have not scaled in tandem withimage acquisition capabilities. Our framework complements existing modelparallelism techniques proposed for large-scale transformer training byoptimizing non-GEMM bottlenecks and enabling convolution-aware tensor sharding.We demonstrate unprecedented capabilities by performing multimodal registrationof a 100 micron ex-vivo human brain MRI volume at native resolution - aninverse problem more than 570x larger than a standard clinical datum in about aminute using only 8 A6000 GPUs. FFDP accelerates existing state-of-the-artoptimization and deep learning registration pipelines by upto 6 - 7x whilereducing peak memory consumption by 20 - 59%. Comparative analysis on a 250micron dataset shows that FFDP can fit upto 64x larger problems than existingSOTA on a single GPU, and highlights both the performance and efficiency gainsof FFDP compared to SOTA image registration methods.</description><author>Rohit Jena, Vedant Zope, Pratik Chaudhari, James C. Gee</author><pubDate>Mon, 29 Sep 2025 16:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25044v1</guid></item><item><title>Large Language Models for Software Testing: A Research Roadmap</title><link>http://arxiv.org/abs/2509.25043v1</link><description>Large Language Models (LLMs) are starting to be profiled as one of the mostsignificant disruptions in the Software Testing field. Specifically, they have been successfully applied in software testing taskssuch as generating test code, or summarizing documentation. This potential has attracted hundreds of researchers, resulting in dozens ofnew contributions every month, hardening researchers to stay at the forefront of the wave. Still, to the best of our knowledge, noprior work has provided a structured vision of the progress and most relevant research trends in LLM-based testing. In this article, weaim to provide a roadmap that illustrates its current state, grouping the contributions into different categories, and also sketching themost promising and active research directions for the field. To achieve this objective, we have conducted a semi-systematic literaturereview, collecting articles and mapping them into the most prominent categories, reviewing the current and ongoing status, and analyzingthe open challenges of LLM-based software testing. Lastly, we have outlined several expected long-term impacts of LLMs over thewhole software testing field.</description><author>Cristian Augusto, Antonia Bertolino, Guglielmo De Angelis, Francesca Lonetti, Jesús Morán</author><pubDate>Mon, 29 Sep 2025 16:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25043v1</guid></item><item><title>Answer Convergence as a Signal for Early Stopping in Reasoning</title><link>http://arxiv.org/abs/2506.02536v2</link><description>Chain-of-thought (CoT) prompting enhances reasoning in large language models(LLMs) but often leads to verbose and redundant outputs, thus increasinginference cost. We hypothesize that many reasoning steps are unnecessary forproducing correct answers. To investigate this, we start with a systematicstudy to examine what is the minimum reasoning required for a model to reach astable decision. We find that on math reasoning tasks like math, modelstypically converge to their final answers after 60\% of the reasoning steps,suggesting substantial redundancy in the remaining content. Based on theseinsights, we propose three inference-time strategies to improve efficiency: (1)early stopping via answer consistency, (2) boosting the probability ofgenerating end-of-reasoning signals, and (3) a supervised method that learnswhen to stop based on internal activations. Experiments across five benchmarksand five open-weights LLMs show that our methods significantly reduce tokenusage with little or no accuracy drop. In particular, on NaturalQuestions,Answer Consistency reduces tokens by over 40\% while further improvingaccuracy. Our work underscores the importance of cost-effective reasoningmethods that operate at inference time, offering practical benefits forreal-world applications.</description><author>Xin Liu, Lu Wang</author><pubDate>Mon, 29 Sep 2025 16:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.02536v2</guid></item><item><title>Do Natural Language Descriptions of Model Activations Convey Privileged Information?</title><link>http://arxiv.org/abs/2509.13316v2</link><description>Recent interpretability methods have proposed to translate LLM internalrepresentations into natural language descriptions using a second verbalizerLLM. This is intended to illuminate how the target model represents andoperates on inputs. But do such activation verbalization approaches actuallyprovide privileged knowledge about the internal workings of the target model,or do they merely convey information about its inputs? We critically evaluatepopular verbalization methods across datasets used in prior work and find thatthey can succeed at benchmarks without any access to target model internals,suggesting that these datasets may not be ideal for evaluating verbalizationmethods. We then run controlled experiments which reveal that verbalizationsoften reflect the parametric knowledge of the verbalizer LLM which generatedthem, rather than the knowledge of the target LLM whose activations aredecoded. Taken together, our results indicate a need for targeted benchmarksand experimental controls to rigorously assess whether verbalization methodsprovide meaningful insights into the operations of LLMs.</description><author>Millicent Li, Alberto Mario Ceballos Arroyo, Giordano Rogers, Naomi Saphra, Byron C. Wallace</author><pubDate>Mon, 29 Sep 2025 16:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.13316v2</guid></item><item><title>Fast Real-Time Pipeline for Robust Arm Gesture Recognition</title><link>http://arxiv.org/abs/2509.25042v1</link><description>This paper presents a real-time pipeline for dynamic arm gesture recognitionbased on OpenPose keypoint estimation, keypoint normalization, and a recurrentneural network classifier. The 1 x 1 normalization scheme and two featurerepresentations (coordinate- and angle-based) are presented for the pipeline.In addition, an efficient method to improve robustness against camera anglevariations is also introduced by using artificially rotated training data.Experiments on a custom traffic-control gesture dataset demonstrate highaccuracy across varying viewing angles and speeds. Finally, an approach tocalculate the speed of the arm signal (if necessary) is also presented.</description><author>Milán Zsolt Bagladi, László Gulyás, Gergő Szalay</author><pubDate>Mon, 29 Sep 2025 16:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25042v1</guid></item><item><title>A multiscale analysis of mean-field transformers in the moderate interaction regime</title><link>http://arxiv.org/abs/2509.25040v1</link><description>In this paper, we study the evolution of tokens through the depth ofencoder-only transformer models at inference time by modeling them as a systemof particles interacting in a mean-field way and studying the correspondingdynamics. More specifically, we consider this problem in the moderateinteraction regime, where the number $N$ of tokens is large and the inversetemperature parameter $\beta$ of the model scales together with $N$. In thisregime, the dynamics of the system displays a multiscale behavior: a fastphase, where the token empirical measure collapses on a low-dimensional space,an intermediate phase, where the measure further collapses into clusters, and aslow one, where such clusters sequentially merge into a single one. We providea rigorous characterization of the limiting dynamics in each of these phasesand prove convergence in the above mentioned limit, exemplifying our resultswith some simulations.</description><author>Giuseppe Bruno, Federico Pasqualotto, Andrea Agazzi</author><pubDate>Mon, 29 Sep 2025 16:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25040v1</guid></item><item><title>Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory</title><link>http://arxiv.org/abs/2509.18057v3</link><description>We explore whether techniques from AI can help discover new combinatorialstructures that improve on known limits on efficient algorithms. Specifically,we use AlphaEvolve (an LLM coding agent) to study two settings: a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve arecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set onrandom 3- and 4-regular graphs. Our improved lower bounds are obtained byconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, usingAlphaEvolve. Additionally, via analytical arguments we strengthen the upperbounds to settle the computational hardness of these questions up to an errorin the third decimal place. b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain newinapproximability results, proving that it is NP-hard to approximate MAX-4-CUTand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, usingAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improvesupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the currentbest gadget-based inapproximability result of $0.9853$, but falls short ofimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadgetreduction from "standard" H{\aa}stad-style PCPs. A key technical challenge we faced: verifying a candidate constructionproduced by AlphaEvolve is costly (often requiring exponential time). In bothsettings above, our results were enabled by using AlphaEvolve itself to evolvethe verification procedure to be faster (sometimes by $10,000\times$). Weconclude with a discussion of norms by which to assess the assistance from AIin developing proofs.</description><author>Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta</author><pubDate>Mon, 29 Sep 2025 16:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.18057v3</guid></item><item><title>Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)</title><link>http://arxiv.org/abs/2505.14608v2</link><description>Despite considerable progress in the development of machine-text detectors,it has been suggested that the problem is inherently hard, and therefore, thatstakeholders should proceed under the assumption that machine-generated textcannot be reliably detected as such. We examine a recent such claim by Nicks etal. (2024) regarding the ease with which language models can be optimized todegrade the performance of machine-text detectors, including detectors notspecifically optimized against. We identify a feature space -- the stylisticfeature space -- that is robust to such optimization, and show that it may beused to reliably detect samples from language models optimized to preventdetection. Furthermore, we show that even when models are explicitly optimizedagainst stylistic detectors, detection performance remains surprisinglyunaffected. We then seek to understand if stylistic detectors are inherentlymore robust. To study this question, we explore a new paraphrasing approachthat simultaneously aims to close the gap between human writing and machinewriting in stylistic feature space while avoiding detection using traditionalfeatures. We show that when only a single sample is available for detection,this attack is universally effective across all detectors considered, includingthose that use writing style. However, as the number of samples available fordetection grows, the human and machine distributions become distinguishable.Overall, our findings underscore previous recommendations to avoid reliance onmachine-text detection.</description><author>Rafael Rivera Soto, Barry Chen, Nicholas Andrews</author><pubDate>Mon, 29 Sep 2025 16:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.14608v2</guid></item><item><title>GateMABSA: Aspect-Image Gated Fusion for Multimodal Aspect-based Sentiment Analysis</title><link>http://arxiv.org/abs/2509.25037v1</link><description>Aspect-based Sentiment Analysis (ABSA) has recently advanced into themultimodal domain, where user-generated content often combines text and images.However, existing multimodal ABSA (MABSA) models struggle to filter noisyvisual signals, and effectively align aspects with opinion-bearing contentacross modalities. To address these challenges, we propose GateMABSA, a novelgated multimodal architecture that integrates syntactic, semantic, andfusion-aware mLSTM. Specifically, GateMABSA introduces three specializedmLSTMs: Syn-mLSTM to incorporate syntactic structure, Sem-mLSTM to emphasizeaspect--semantic relevance, and Fuse-mLSTM to perform selective multimodalfusion. Extensive experiments on two benchmark Twitter datasets demonstratethat GateMABSA outperforms several baselines.</description><author>Adamu Lawan, Haruna Yunusa</author><pubDate>Mon, 29 Sep 2025 16:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25037v1</guid></item><item><title>Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct</title><link>http://arxiv.org/abs/2509.25035v1</link><description>Fast generation of language texts is the holy grail that people pursue in theAI era. In this work, we introduced Discrete Diffusion Divergence Instruct(DiDi-Instruct), a training-based method that leads to fast language generationmodels by initializing from a pre-trained (masked) discrete diffusion languagemodel (dLLM). The resulting DiDi-Instruct model outperforms the dLLMcounterparts and the GPT-2 baseline with 64x acceleration. In the theoreticalpart of the paper, we build the foundation of DiDi-Instruct in a framework ofintegral KL-divergence minimization, with practical training algorithms. Wealso introduce techniques like grouped reward normalization, intermediate-statematching, and the reward-guided ancestral sampler (RGAS) that significantlyimprove the training stability, the model coverage, and the inferenceperformances. On OpenWebText, DiDi-Instruct outperforms all acceleratedlanguage generation models as well as the GPT-2 baseline and the standarddLLMs, achieving sample perplexities ranging from 62.2 (8 NFEs) to 18.4 (128NFEs). These performance gains are accomplished with a negligible entropy lossof about 1% and 20x less additional training wall-clock time. We furthervalidate the robustness and effectiveness of DiDi-Instruct through extensiveablation studies, model scaling, and the generation of discrete proteinsequences. In conclusion, DiDi-Instruct is an efficient yet effectivedistillation method, enabling language generation in the blink of an eye. Wewill release both code and models at github.com/haoyangzheng-ai/didi-instruct.</description><author>Haoyang Zheng, Xinyang Liu, Cindy Xiangrui Kong, Nan Jiang, Zheyuan Hu, Weijian Luo, Wei Deng, Guang Lin</author><pubDate>Mon, 29 Sep 2025 16:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25035v1</guid></item><item><title>VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning</title><link>http://arxiv.org/abs/2509.25033v1</link><description>Few-shot learning (FSL) aims to recognize novel concepts from only a fewlabeled support samples. Recent studies enhance support features byincorporating additional semantic information or designing complex semanticfusion modules. However, they still suffer from hallucinating semantics thatcontradict the visual evidence due to the lack of grounding in actualinstances, resulting in noisy guidance and costly corrections. To address theseissues, we propose a novel framework, bridging Vision and Text with LLMs forFew-Shot Learning (VT-FSL), which constructs precise cross-modal promptsconditioned on Large Language Models (LLMs) and support images, seamlesslyintegrating them through a geometry-aware alignment. It mainly consists ofCross-modal Iterative Prompting (CIP) and Cross-modal Geometric Alignment(CGA). Specifically, the CIP conditions an LLM on both class names and supportimages to generate precise class descriptions iteratively in a singlestructured reasoning pass. These descriptions not only enrich the semanticunderstanding of novel classes but also enable the zero-shot synthesis ofsemantically consistent images. The descriptions and synthetic images actrespectively as complementary textual and visual prompts, providing high-levelclass semantics and low-level intra-class diversity to compensate for limitedsupport data. Furthermore, the CGA jointly aligns the fused textual, support,and synthetic visual representations by minimizing the kernelized volume of the3-dimensional parallelotope they span. It captures global and nonlinearrelationships among all representations, enabling structured and consistentmultimodal integration. The proposed VT-FSL method establishes newstate-of-the-art performance across ten diverse benchmarks, including standard,cross-domain, and fine-grained few-shot learning scenarios. Code is availableat https://github.com/peacelwh/VT-FSL.</description><author>Wenhao Li, Qiangchang Wang, Xianjing Meng, Zhibin Wu, Yilong Yin</author><pubDate>Mon, 29 Sep 2025 16:52:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25033v1</guid></item><item><title>AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation</title><link>http://arxiv.org/abs/2509.25032v1</link><description>As robots transition from controlled settings to unstructured humanenvironments, building generalist agents that can reliably follow naturallanguage instructions remains a central challenge. Progress in robust mobilemanipulation requires large-scale multimodal datasets that capture contact-richand long-horizon tasks, yet existing resources lack synchronized force-torquesensing, hierarchical annotations, and explicit failure cases. We address thisgap with the AIRoA MoMa Dataset, a large-scale real-world multimodal datasetfor mobile manipulation. It includes synchronized RGB images, joint states,six-axis wrist force-torque signals, and internal robot states, together with anovel two-layer annotation schema of sub-goals and primitive actions forhierarchical learning and error analysis. The initial dataset comprises 25,469episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and isfully standardized in the LeRobot v2.1 format. By uniquely integrating mobilemanipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMaprovides a critical benchmark for advancing the next generation ofVision-Language-Action models. The first version of our dataset is nowavailable at https://huggingface.co/datasets/airoa-org/airoa-moma .</description><author>Ryosuke Takanami, Petr Khrapchenkov, Shu Morikuni, Jumpei Arima, Yuta Takaba, Shunsuke Maeda, Takuya Okubo, Genki Sano, Satoshi Sekioka, Aoi Kadoya, Motonari Kambara, Naoya Nishiura, Haruto Suzuki, Takanori Yoshimoto, Koya Sakamoto, Shinnosuke Ono, Hu Yang, Daichi Yashima, Aoi Horo, Tomohiro Motoda, Kensuke Chiyoma, Hiroshi Ito, Koki Fukuda, Akihito Goto, Kazumi Morinaga, Yuya Ikeda, Riko Kawada, Masaki Yoshikawa, Norio Kosuge, Yuki Noguchi, Kei Ota, Tatsuya Matsushima, Yusuke Iwasawa, Yutaka Matsuo, Tetsuya Ogata</author><pubDate>Mon, 29 Sep 2025 16:51:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25032v1</guid></item><item><title>Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios</title><link>http://arxiv.org/abs/2509.25031v1</link><description>Aging infrastructure portfolios pose a critical resource allocationchallenge: deciding which structures require intervention and which can safelyremain in service. Structural assessments must balance the trade-off betweencheaper, conservative analysis methods and accurate but costly simulations thatdo not scale portfolio-wide. We propose Bayesian neural network (BNN)surrogates for rapid structural pre-assessment of worldwide common bridgetypes, such as reinforced concrete frame bridges. Trained on a large-scaledatabase of non-linear finite element analyses generated via a parametricpipeline and developed based on the Swiss Federal Railway's bridge portfolio,the models accurately and efficiently estimate high-fidelity structuralanalysis results by predicting code compliance factors with calibratedepistemic uncertainty. Our BNN surrogate enables fast, uncertainty-awaretriage: flagging likely critical structures and providing guidance whererefined analysis is pertinent. We demonstrate the framework's effectiveness ina real-world case study of a railway underpass, showing its potential tosignificantly reduce costs and emissions by avoiding unnecessary analyses andphysical interventions across entire infrastructure portfolios.</description><author>Sophia V. Kuhn, Rafael Bischof, Marius Weber, Antoine Binggeli, Michael A. Kraus, Walter Kaufmann, Fernando Pérez-Cruz</author><pubDate>Mon, 29 Sep 2025 16:51:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25031v1</guid></item><item><title>STAGE: Stable and Generalizable GRPO for Autoregressive Image Generation</title><link>http://arxiv.org/abs/2509.25027v1</link><description>Reinforcement learning has recently been explored to improve text-to-imagegeneration, yet applying existing GRPO algorithms to autoregressive (AR) imagemodels remains challenging. The instability of the training process easilydisrupts the pretrained model capability during long runs, resulting inmarginal gains, degraded image quality, and poor generalization. In this work,we revisit GRPO for AR image generation and identify two key issues:contradictory gradients from unnecessary tokens and unstable policy entropydynamics. To address these, we introduce STAGE, a stable and generalizableframework that leverages two targeted solutions: 1) Advantage/KL reweighting.Similarity-aware reweighting to alleviate conflicting updates; and 2) Entropyreward. An entropy-based reward corresponding to reference model to stabilizelearning. With the help of alleviating conflicts between tokens and an entropyreward for stabilizing training, we reduce disruption of the pretraineddistribution and mitigate reward hacking, which in turn improves generalizationand transfer better to other benchmarks. Experiments across multiple benchmarksshow that STAGE consistently improves visual quality, stability, and cross-taskgeneralization compared to baseline GRPO.</description><author>Xiaoxiao Ma, Haibo Qiu, Guohui Zhang, Zhixiong Zeng, Siqi Yang, Lin Ma, Feng Zhao</author><pubDate>Mon, 29 Sep 2025 16:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25027v1</guid></item><item><title>GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning</title><link>http://arxiv.org/abs/2509.25026v1</link><description>Recent advances in reinforcement learning (RL) have delivered strongreasoning capabilities in natural image domains, yet their potential for EarthObservation (EO) remains largely unexplored. EO tasks introduce uniquechallenges, spanning referred object detection, image or region captioning,change detection, grounding, and temporal analysis, that demand task awarereasoning. We propose a novel post training framework that incorporates taskaware rewards to enable effective adaptation of reasoning based RL models todiverse EO tasks. This training strategy enhances reasoning capabilities forremote sensing images, stabilizes optimization, and improves robustness.Extensive experiments across multiple EO benchmarks show consistent performancegains over state of the art generic and specialized vision language models.Code and models will be released publicly athttps://mustansarfiaz.github.io/GeoVLM-R1/ .</description><author>Mustansar Fiaz, Hiyam Debary, Paolo Fraccaro, Danda Paudel, Luc Van Gool, Fahad Khan, Salman Khan</author><pubDate>Mon, 29 Sep 2025 16:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25026v1</guid></item><item><title>End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost</title><link>http://arxiv.org/abs/2509.00031v2</link><description>Quantization is an effective technique to reduce the deployment cost of largelanguage models (LLMs), and post-training quantization (PTQ) has been widelystudied due to its efficiency. However, existing PTQ methods are limited bytheir inability to fine-tune model parameters and often suffer significantaccuracy loss in low-bit scenarios. Quantization-aware training (QAT) providesa more principled solution, but its reliance on backpropagation incursprohibitive memory costs, limiting its practicality for LLM deployment. Toaddress these challenges, we propose ZeroQAT, a zeroth-order optimization-basedQAT framework that supports both weight and activation quantization. ZeroQATleverages forward-only gradient estimation to eliminate backpropagation,substantially reducing computational and memory overhead while retaining thebenefits of end-to-end optimization. We further introduce a lightweight variantof ZeroQAT for quantized fine-tuning, which freezes and pre-quantizes mostparameters to further cut memory usage. Experiments show that ZeroQATconsistently outperforms representative PTQ and QAT baselines while requiringsignificantly less memory. For example, ZeroQAT enables fine-tuning of a 13Bmodel at extremely low bit-widths (e.g., 2-4 bits) on a single 8GB GPU, andeven allows fine-tuning a 6.7B model on a OnePlus 12 smartphone, demonstratingits practicality for end-to-end QAT on resource-limited edge devices.</description><author>Qitao Tan, Xiaoying Song, Jin Lu, Guoming Li, Jun Liu, Lingzi Hong, Caiwen Ding, Jundong Li, Xiaoming Zhai, Shaoyi Huang, Wei Niu, Geng Yuan</author><pubDate>Mon, 29 Sep 2025 16:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.00031v2</guid></item><item><title>MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts</title><link>http://arxiv.org/abs/2509.25020v1</link><description>The current paradigm for reasoning in large language models (LLMs) involvesmodels "thinking out loud" via a sequence of tokens, known as chain-of-thought(CoT). This approach, while effective, has several significant drawbacks.Firstly, inference requires autoregressive generation of often thousands of CoTtokens, which is slow and computationally expensive. Secondly, it constrainsreasoning to the discrete space of tokens, creating an information bottleneckacross reasoning steps. Thirdly, it fundamentally entangles reasoning withtoken generation, forcing LLMs to "think while speaking," which causespotentially short-sighted reasoning. In light of these limitations, were-imagine reasoning in LLMs and present a new paradigm: MARCOS. In ourapproach, rather than autoregressively generating tokens, we model reasoning asa hidden Markov chain of continuous, high-dimensional "thoughts". Eachreasoning step involves a transition of the internal thoughts, where explicitreasoning steps (which may consist of hundreds of tokens) serve as observablevariables, which are windows to peek into the implicit thoughts. Since thislatent process is incompatible with the standard supervised learning, wefurther propose a two-phase variational training scheme. Our experiments onthree benchmarks demonstrate that MARCOS outperforms existing continuousreasoning methods and, for the first time, achieves performance comparable totoken-based CoT, even surpassing it by 4.7% on GSM8K with up to 15.7x speedupin inference. Beyond this, MARCOS offers additional advantages, such asstep-level instead of token-level control over randomness, opening significantopportunities for reinforcement learning and reasoning in LLMs.</description><author>Jiayu Liu, Zhenya Huang, Anya Sims, Enhong Chen, Yee Whye Teh, Ning Miao</author><pubDate>Mon, 29 Sep 2025 16:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25020v1</guid></item><item><title>Uncertainty-Aware Deep Learning for Wildfire Danger Forecasting</title><link>http://arxiv.org/abs/2509.25017v1</link><description>Wildfires are among the most severe natural hazards, posing a significantthreat to both humans and natural ecosystems. The growing risk of wildfiresincreases the demand for forecasting models that are not only accurate but alsoreliable. Deep Learning (DL) has shown promise in predicting wildfire danger;however, its adoption is hindered by concerns over the reliability of itspredictions, some of which stem from the lack of uncertainty quantification. Toaddress this challenge, we present an uncertainty-aware DL framework thatjointly captures epistemic (model) and aleatoric (data) uncertainty to enhanceshort-term wildfire danger forecasting. In the next-day forecasting, ourbest-performing model improves the F1 Score by 2.3% and reduces the ExpectedCalibration Error by 2.1% compared to a deterministic baseline, enhancing bothpredictive skill and calibration. Our experiments confirm the reliability ofthe uncertainty estimates and illustrate their practical utility for decisionsupport, including the identification of uncertainty thresholds for rejectinglow-confidence predictions and the generation of well-calibrated wildfiredanger maps with accompanying uncertainty layers. Extending the forecasthorizon up to ten days, we observe that aleatoric uncertainty increases withtime, showing greater variability in environmental conditions, while epistemicuncertainty remains stable. Finally, we show that although the two uncertaintytypes may be redundant in low-uncertainty cases, they provide complementaryinsights under more challenging conditions, underscoring the value of theirjoint modeling for robust wildfire danger prediction. In summary, our approachsignificantly improves the accuracy and reliability of wildfire dangerforecasting, advancing the development of trustworthy wildfire DL systems.</description><author>Spyros Kondylatos, Gustau Camps-Valls, Ioannis Papoutsis</author><pubDate>Mon, 29 Sep 2025 16:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25017v1</guid></item><item><title>CHROMA: Consistent Harmonization of Multi-View Appearance via Bilateral Grid Prediction</title><link>http://arxiv.org/abs/2507.15748v2</link><description>Modern camera pipelines apply extensive on-device processing, such asexposure adjustment, white balance, and color correction, which, whilebeneficial individually, often introduce photometric inconsistencies acrossviews. These appearance variations violate multi-view consistency and degradenovel view synthesis. Joint optimization of scene-specific representations andper-image appearance embeddings has been proposed to address this issue, butwith increased computational complexity and slower training. In this work, wepropose a generalizable, feed-forward approach that predicts spatially adaptivebilateral grids to correct photometric variations in a multi-view consistentmanner. Our model processes hundreds of frames in a single step, enablingefficient large-scale harmonization, and seamlessly integrates into downstream3D reconstruction models, providing cross-scene generalization withoutrequiring scene-specific retraining. To overcome the lack of paired data, weemploy a hybrid self-supervised rendering loss leveraging 3D foundation models,improving generalization to real-world variations. Extensive experiments showthat our approach outperforms or matches the reconstruction quality of existingscene-specific optimization methods with appearance modeling, withoutsignificantly affecting the training time of baseline 3D models.</description><author>Jisu Shin, Richard Shaw, Seunghyun Shin, Zhensong Zhang, Hae-Gon Jeon, Eduardo Perez-Pellitero</author><pubDate>Mon, 29 Sep 2025 16:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.15748v2</guid></item><item><title>CLASP: Adaptive Spectral Clustering for Unsupervised Per-Image Segmentation</title><link>http://arxiv.org/abs/2509.25016v1</link><description>We introduce CLASP (Clustering via Adaptive Spectral Processing), alightweight framework for unsupervised image segmentation that operates withoutany labeled data or finetuning. CLASP first extracts per patch features using aself supervised ViT encoder (DINO); then, it builds an affinity matrix andapplies spectral clustering. To avoid manual tuning, we select the segmentcount automatically with a eigengap silhouette search, and we sharpen theboundaries with a fully connected DenseCRF. Despite its simplicity and trainingfree nature, CLASP attains competitive mIoU and pixel accuracy on COCO Stuffand ADE20K, matching recent unsupervised baselines. The zero training designmakes CLASP a strong, easily reproducible baseline for large unannotatedcorpora especially common in digital advertising and marketing workflows suchas brand safety screening, creative asset curation, and social media contentmoderation</description><author>Max Curie, Paulo da Costa</author><pubDate>Mon, 29 Sep 2025 16:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25016v1</guid></item><item><title>MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing</title><link>http://arxiv.org/abs/2509.22186v2</link><description>We introduce MinerU2.5, a 1.2B-parameter document parsing vision-languagemodel that achieves state-of-the-art recognition accuracy while maintainingexceptional computational efficiency. Our approach employs a coarse-to-fine,two-stage parsing strategy that decouples global layout analysis from localcontent recognition. In the first stage, the model performs efficient layoutanalysis on downsampled images to identify structural elements, circumventingthe computational overhead of processing high-resolution inputs. In the secondstage, guided by the global layout, it performs targeted content recognition onnative-resolution crops extracted from the original image, preservingfine-grained details in dense text, complex formulas, and tables. To supportthis strategy, we developed a comprehensive data engine that generates diverse,large-scale training corpora for both pretraining and fine-tuning. Ultimately,MinerU2.5 demonstrates strong document parsing ability, achievingstate-of-the-art performance on multiple benchmarks, surpassing bothgeneral-purpose and domain-specific models across various recognition tasks,while maintaining significantly lower computational overhead.</description><author>Junbo Niu, Zheng Liu, Zhuangcheng Gu, Bin Wang, Linke Ouyang, Zhiyuan Zhao, Tao Chu, Tianyao He, Fan Wu, Qintong Zhang, Zhenjiang Jin, Guang Liang, Rui Zhang, Wenzheng Zhang, Yuan Qu, Zhifei Ren, Yuefeng Sun, Yuanhong Zheng, Dongsheng Ma, Zirui Tang, Boyu Niu, Ziyang Miao, Hejun Dong, Siyi Qian, Junyuan Zhang, Jingzhou Chen, Fangdong Wang, Xiaomeng Zhao, Liqun Wei, Wei Li, Shasha Wang, Ruiliang Xu, Yuanyuan Cao, Lu Chen, Qianqian Wu, Huaiyu Gu, Lindong Lu, Keming Wang, Dechen Lin, Guanlin Shen, Xuanhe Zhou, Linfeng Zhang, Yuhang Zang, Xiaoyi Dong, Jiaqi Wang, Bo Zhang, Lei Bai, Pei Chu, Weijia Li, Jiang Wu, Lijun Wu, Zhenxiang Li, Guangyu Wang, Zhongying Tu, Chao Xu, Kai Chen, Yu Qiao, Bowen Zhou, Dahua Lin, Wentao Zhang, Conghui He</author><pubDate>Mon, 29 Sep 2025 16:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.22186v2</guid></item><item><title>Diversity-Enhanced Reasoning for Subjective Questions</title><link>http://arxiv.org/abs/2507.20187v2</link><description>Large Reasoning Models (LRMs) with long chain-of-thought capabilities,optimized via reinforcement learning with verifiable rewards (RLVR), excel atobjective reasoning tasks like mathematical problem solving and codegeneration. However, RLVR is known for degrading generation diversity, whichcauses LRMs to fall short on subjective reasoning that has multiple answersdepending on different role perspectives. While recent studies recognize theimportance of diversity-enhanced training in objective reasoning, limitedattention has been given to subjective tasks. In this paper, we find thatsubjective reasoning can be improved by introducing perspective diversity andtoken-level diversity, with the former one providing a coherent scaffoldinganchored to a real-world stakeholder group and the latter one broadening theanswer search space. We propose MultiRole-R1, a diversity-enhanced trainingframework featuring an unsupervised data construction pipeline that synthesizesreasoning chains incorporating various role perspectives. It also employsreinforcement learning via Group Relative Policy Optimization with rewardshaping, taking diversity as a reward signal in addition to verifiable reward.Training on subjective tasks solely, MultiRole-R1 increases the in-domain andout-of-domain accuracy by 14.1% and 7.64%, and even enhances the performance onadvanced math reasoning such as AIME 2024. We further show that diversity is amore consistent indicator of accuracy than reasoning length.</description><author>Yumeng Wang, Zhiyuan Fan, Jiayu Liu, Jen-tse Huang, Yi R. Fung</author><pubDate>Mon, 29 Sep 2025 16:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.20187v2</guid></item><item><title>CLPO: Curriculum Learning meets Policy Optimization for LLM Reasoning</title><link>http://arxiv.org/abs/2509.25004v1</link><description>Recently, online Reinforcement Learning with Verifiable Rewards (RLVR) hasbecome a key paradigm for enhancing the reasoning capabilities of LargeLanguage Models (LLMs). However, existing methods typically treat all trainingsamples uniformly, overlooking the vast differences in problem difficultyrelative to the model's current capabilities. This uniform training strategyleads to inefficient exploration of problems the model has already mastered,while concurrently lacking effective guidance on problems that are challengingits abilities the most, limiting both learning efficiency and upper-boundperformance. To address this, we propose CLPO (Curriculum-guided Learning forPolicy Optimization), a novel algorithm that creates a dynamic pedagogicalfeedback loop within the policy optimization process. The core of CLPOleverages the model's own rollout performance to conduct real-time difficultyassessment, thereby constructing an Online Curriculum. This curriculum thenguides an Adaptive Problem Restructuring mechanism, where the model acts as itsown teacher: it diversifies medium-difficulty problems to promotegeneralization and simplifies challenging problems to make them moreattainable. Our approach transforms the static training procedure into adynamic process that co-evolves with the model's capabilities. Experiments showthat CLPO achieves state-of-the-art performance across eight challengingmathematical and general reasoning benchmarks, with an average pass@1improvement of 6.96% over other methods, demonstrating its potential for moreefficiently training more capable reasoning models.</description><author>Shijie Zhang, Guohao Sun, Kevin Zhang, Xiang Guo, Rujun Guo</author><pubDate>Mon, 29 Sep 2025 16:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25004v1</guid></item><item><title>Score-based Membership Inference on Diffusion Models</title><link>http://arxiv.org/abs/2509.25003v1</link><description>Membership inference attacks (MIAs) against diffusion models have emerged asa pressing privacy concern, as these models may inadvertently reveal whether agiven sample was part of their training set. We present a theoretical andempirical study of score-based MIAs, focusing on the predicted noise vectorsthat diffusion models learn to approximate. We show that the expected denoiseroutput points toward a kernel-weighted local mean of nearby training samples,such that its norm encodes proximity to the training set and thereby revealsmembership. Building on this observation, we propose SimA, a single-queryattack that provides a principled, efficient alternative to existingmulti-query methods. SimA achieves consistently strong performance acrossvariants of DDPM, Latent Diffusion Model (LDM). Notably, we find that LatentDiffusion Models are surprisingly less vulnerable than pixel-space models, dueto the strong information bottleneck imposed by their latent auto-encoder. Wefurther investigate this by differing the regularization hyperparameters($\beta$ in $\beta$-VAE) in latent channel and suggest a strategy to make LDMtraining more robust to MIA. Our results solidify the theory of score-basedMIAs, while highlighting that Latent Diffusion class of methods requires betterunderstanding of inversion for VAE, and not simply inversion of the Diffusionprocess</description><author>Mingxing Rao, Bowen Qu, Daniel Moyer</author><pubDate>Mon, 29 Sep 2025 16:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25003v1</guid></item><item><title>Circuit Distillation</title><link>http://arxiv.org/abs/2509.25002v1</link><description>Model distillation typically focuses on behavioral mimicry, where a studentmodel is trained to replicate a teacher's output while treating its internalcomputations as a black box. In this work we propose an alternative approach:Distilling the underlying computational mechanisms implemented by a teachermodel. Specifically, we propose circuit distillation, which introduces anobjective to align internal representations between analogous circuitcomponents in teacher and student models. We propose a method to match``functionally correspondent'' circuit components and introduce a lossreflecting similarities between the representations that these induce. Weevaluate circuit distillation on entity tracking and theory of mind (ToM) tasksusing models from the Llama3 family. Our results demonstrate that circuitdistillation outperforms standard distillation, successfully transferringalgorithmic capabilities by adjusting only a small, targeted subset of studentmodel parameters. This work establishes the feasibility of transferringmechanisms, which may in turn allow for efficient distillation of targetedteacher capabilities via interpretable and controllable internal studentmechanisms.</description><author>Somin Wadhwa, Silvio Amir, Byron C. Wallace</author><pubDate>Mon, 29 Sep 2025 16:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25002v1</guid></item><item><title>LVT: Large-Scale Scene Reconstruction via Local View Transformers</title><link>http://arxiv.org/abs/2509.25001v1</link><description>Large transformer models are proving to be a powerful tool for 3D vision andnovel view synthesis. However, the standard Transformer's well-known quadraticcomplexity makes it difficult to scale these methods to large scenes. Toaddress this challenge, we propose the Local View Transformer (LVT), alarge-scale scene reconstruction and novel view synthesis architecture thatcircumvents the need for the quadratic attention operation. Motivated by theinsight that spatially nearby views provide more useful signal about the localscene composition than distant views, our model processes all information in alocal neighborhood around each view. To attend to tokens in nearby views, weleverage a novel positional encoding that conditions on the relative geometrictransformation between the query and nearby views. We decode the output of ourmodel into a 3D Gaussian Splat scene representation that includes both colorand opacity view-dependence. Taken together, the Local View Transformer enablesreconstruction of arbitrarily large, high-resolution scenes in a single forwardpass. See our project page for results and interactive demoshttps://toobaimt.github.io/lvt/.</description><author>Tooba Imtiaz, Lucy Chai, Kathryn Heal, Xuan Luo, Jungyeon Park, Jennifer Dy, John Flynn</author><pubDate>Mon, 29 Sep 2025 16:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.25001v1</guid></item><item><title>Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?</title><link>http://arxiv.org/abs/2505.13257v2</link><description>A prominent issue in aligning language models (LMs) to personalizedpreferences is underspecification -- the lack of information from users abouttheir preferences. A popular trend of injecting such specification is adding aprefix (e.g. prior relevant conversations) to the current user's conversationto steer preference distribution. Most methods passively model personalpreferences with prior example preferences pairs. We ask whether models benefitfrom actively inferring preference descriptions, and address this question bycreating a synthetic personalized alignment dataset based on famous people withknown public preferences. We then test how effective finetuned 1-8B size modelsare at inferring and aligning to personal preferences. Results show thathigher-quality active prefixes lead to better generalization, more contextuallyfaithful models, and less systematic biases across different protectedattributes. All our results suggest active alignment can lead to a morecontrollable and efficient path for personalized alignment.</description><author>Zilu Tang, Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya</author><pubDate>Mon, 29 Sep 2025 16:23:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.13257v2</guid></item><item><title>A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction</title><link>http://arxiv.org/abs/2507.11757v2</link><description>Accurately predicting drug-target interactions (DTIs) is pivotal foradvancing drug discovery and target validation techniques. While machinelearning approaches including those that are based on Graph Neural Networks(GNN) have achieved notable success in DTI prediction, many of them havedifficulties in effectively integrating the diverse features of drugs, targetsand their interactions. To address this limitation, we introduce a novelframework to take advantage of the power of both transductive learning andinductive learning so that features at molecular level and drug-targetinteraction network level can be exploited. Within this framework is aGNN-based model called Graph-in-Graph (GiG) that represents graphs of drug andtarget molecular structures as meta-nodes in a drug-target interaction graph,enabling a detailed exploration of their intricate relationships. To evaluatethe proposed model, we have compiled a special benchmark comprising drugSMILES, protein sequences, and their interaction data, which is interesting inits own right. Our experimental results demonstrate that the GiG modelsignificantly outperforms existing approaches across all evaluation metrics,highlighting the benefits of integrating different learning paradigms andinteraction data.</description><author>Yuehua Song, Yong Gao</author><pubDate>Mon, 29 Sep 2025 16:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.11757v2</guid></item><item><title>PanoWorld-X: Generating Explorable Panoramic Worlds via Sphere-Aware Video Diffusion</title><link>http://arxiv.org/abs/2509.24997v1</link><description>Generating a complete and explorable 360-degree visual world enables a widerange of downstream applications. While prior works have advanced the field,they remain constrained by either narrow field-of-view limitations, whichhinder the synthesis of continuous and holistic scenes, or insufficient cameracontrollability that restricts free exploration by users or autonomous agents.To address this, we propose PanoWorld-X, a novel framework for high-fidelityand controllable panoramic video generation with diverse camera trajectories.Specifically, we first construct a large-scale dataset of panoramicvideo-exploration route pairs by simulating camera trajectories in virtual 3Denvironments via Unreal Engine. As the spherical geometry of panoramic datamisaligns with the inductive priors from conventional video diffusion, we thenintroduce a Sphere-Aware Diffusion Transformer architecture that reprojectsequirectangular features onto the spherical surface to model geometricadjacency in latent space, significantly enhancing visual fidelity andspatiotemporal continuity. Extensive experiments demonstrate that ourPanoWorld-X achieves superior performance in various aspects, including motionrange, control precision, and visual quality, underscoring its potential forreal-world applications.</description><author>Yuyang Yin, HaoXiang Guo, Fangfu Liu, Mengyu Wang, Hanwen Liang, Eric Li, Yikai Wang, Xiaojie Jin, Yao Zhao, Yunchao Wei</author><pubDate>Mon, 29 Sep 2025 16:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24997v1</guid></item><item><title>Towards Better Generalization via Distributional Input Projection Network</title><link>http://arxiv.org/abs/2506.04690v2</link><description>As overparameterized models become increasingly prevalent, training lossalone offers limited insight into generalization performance. While smoothnesshas been linked to improved generalization across various settings, directlyenforcing smoothness in neural networks remains challenging. To address this,we introduce Distributional Input Projection Networks (DIPNet), a novelframework that projects inputs into learnable distributions at each layer. Thisdistributional representation induces a smoother loss landscape with respect tothe input, promoting better generalization. We provide theoretical analysisshowing that DIPNet reduces both local smoothness measures and the Lipschitzconstant of the network, contributing to improved generalization performance.Empirically, we validate DIPNet across a wide range of architectures and tasks,including Vision Transformers (ViTs), Large Language Models (LLMs), ResNet andMLPs. Our method consistently enhances test performance under standardsettings, adversarial attacks, out-of-distribution inputs, and reasoningbenchmarks. We demonstrate that the proposed input projection strategy can beseamlessly integrated into existing models, providing a general and effectiveapproach for boosting generalization performance in modern deep learning.</description><author>Yifan Hao, Yanxin Lu, Hanning Zhang, Xinwei Shen, Tong Zhang</author><pubDate>Mon, 29 Sep 2025 16:20:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.04690v2</guid></item><item><title>Embedded Deep Learning for Bio-hybrid Plant Sensors to Detect Increased Heat and Ozone Levels</title><link>http://arxiv.org/abs/2509.24992v1</link><description>We present a bio-hybrid environmental sensor system that integrates naturalplants and embedded deep learning for real-time, on-device detection oftemperature and ozone level changes. Our system, based on the low-powerPhytoNode platform, records electric differential potential signals from Hederahelix and processes them onboard using an embedded deep learning model. Wedemonstrate that our sensing device detects changes in temperature and ozonewith good sensitivity of up to 0.98. Daily and inter-plant variability, as wellas limited precision, could be mitigated by incorporating additional trainingdata, which is readily integrable in our data-driven framework. Our approachalso has potential to scale to new environmental factors and plant species. Byintegrating embedded deep learning onboard our biological sensing device, weoffer a new, low-power solution for continuous environmental monitoring andpotentially other fields of application.</description><author>Till Aust, Christoph Karl Heck, Eduard Buss, Heiko Hamann</author><pubDate>Mon, 29 Sep 2025 16:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24992v1</guid></item><item><title>Sampling Complexity of TD and PPO in RKHS</title><link>http://arxiv.org/abs/2509.24991v1</link><description>We revisit Proximal Policy Optimization (PPO) from a function-spaceperspective. Our analysis decouples policy evaluation and improvement in areproducing kernel Hilbert space (RKHS): (i) A kernelized temporal-difference(TD) critic performs efficient RKHS-gradient updates using only one-stepstate-action transition samples; (ii) a KL-regularized, natural-gradient policystep exponentiates the evaluated action-value, recovering a PPO/TRPO-styleproximal update in continuous state-action spaces. We provide non-asymptotic,instance-adaptive guarantees whose rates depend on RKHS entropy, unifyingtabular, linear, Sobolev, Gaussian, and Neural Tangent Kernel (NTK) regimes,and we derive a sampling rule for the proximal update that ensures the optimal$k^{-1/2}$ convergence rate for stochastic optimization. Empirically, thetheory-aligned schedule improves stability and sample efficiency on commoncontrol tasks (e.g., CartPole, Acrobot), while our TD-based critic attainsfavorable throughput versus a GAE baseline. Altogether, our results place PPOon a firmer theoretical footing beyond finite-dimensional assumptions andclarify when RKHS-proximal updates with kernel-TD critics yield global policyimprovement with practical efficiency.</description><author>Lu Zou, Wendi Ren, Weizhong Zhang, Liang Ding, Shuang Li</author><pubDate>Mon, 29 Sep 2025 16:19:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24991v1</guid></item><item><title>Generalized Correctness Models: Learning Calibrated and Model-Agnostic Correctness Predictors from Historical Patterns</title><link>http://arxiv.org/abs/2509.24988v1</link><description>Generating accurate and calibrated confidence estimates is critical fordeploying LLMs in high-stakes or user-facing applications, and remains an openchallenge. Prior research has often framed confidence as a problem of elicitinga model's "self-knowledge", i.e., the ability of an LLM to judge whether itsown answers are correct; this approach implicitly assumes that there is someprivileged information about the answer's correctness that is accessible to themodel itself. However, our experiments reveal that an LLM attempting to predictthe correctness of its own outputs generally performs no better than anunrelated LLM. Moreover, we hypothesize that a key factor in building a"Correctness Model" (CM) is exposure to a target model's historicalpredictions. We propose multiple methods to inject this historical correctnessinformation, creating a Generalized Correctness Model (GCM). We first show thatGCMs can be trained on the correctness data from many LLMs and learn patternsfor correctness prediction applicable across datasets and models. We then useCMs as a lens for studying the source of correctness prediction ability and itsgeneralization, systematically controlling their training data and finding thatanswer phrasing is a strong predictor for correctness. We further explorealternative methods of injecting history without training an LLM, finding thatincluding history as in-context examples can help improve correctnessprediction, and post-hoc calibration can provide complementary reductions incalibration error. We evaluate GCMs based on Qwen3-8B across 5 model familiesand the MMLU and TriviaQA datasets, as well as on a downstream selectiveprediction task, finding that reliable LLM confidence estimation is ageneralizable and model-agnostic skill learned by systematically encodingcorrectness history rather than a model-specific skill reliant onself-introspection.</description><author>Hanqi Xiao, Vaidehi Patil, Hyunji Lee, Elias Stengel-Eskin, Mohit Bansal</author><pubDate>Mon, 29 Sep 2025 16:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24988v1</guid></item><item><title>Light-SQ: Structure-aware Shape Abstraction with Superquadrics for Generated Meshes</title><link>http://arxiv.org/abs/2509.24986v1</link><description>In user-generated-content (UGC) applications, non-expert users often rely onimage-to-3D generative models to create 3D assets. In this context,primitive-based shape abstraction offers a promising solution for UGC scenariosby compressing high-resolution meshes into compact, editable representations.Towards this end, effective shape abstraction must therefore bestructure-aware, characterized by low overlap between primitives, part-awarealignment, and primitive compactness. We present Light-SQ, a novelsuperquadric-based optimization framework that explicitly emphasizesstructure-awareness from three aspects. (a) We introduce SDF carving toiteratively udpate the target signed distance field, discouraging overlapbetween primitives. (b) We propose a block-regrow-fill strategy guided bystructure-aware volumetric decomposition, enabling structural partitioning todrive primitive placement. (c) We implement adaptive residual pruning based onSDF update history to surpress over-segmentation and ensure compact results. Inaddition, Light-SQ supports multiscale fitting, enabling localized refinementto preserve fine geometric details. To evaluate our method, we introduce3DGen-Prim, a benchmark extending 3DGen-Bench with new metrics for bothreconstruction quality and primitive-level editability. Extensive experimentsdemonstrate that Light-SQ enables efficient, high-fidelity, and editable shapeabstraction with superquadrics for complex generated geometry, advancing thefeasibility of 3D UGC creation.</description><author>Yuhan Wang, Weikai Chen, Zeyu Hu, Runze Zhang, Yingda Yin, Ruoyu Wu, Keyang Luo, Shengju Qian, Yiyan Ma, Hongyi Li, Yuan Gao, Yuhuan Zhou, Hao Luo, Wan Wang, Xiaobin Shen, Zhaowei Li, Kuixin Zhu, Chuanlang Hong, Yueyue Wang, Lijie Feng, Xin Wang, Chen Change Loy</author><pubDate>Mon, 29 Sep 2025 16:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24986v1</guid></item><item><title>Streaming Sequence-to-Sequence Learning with Delayed Streams Modeling</title><link>http://arxiv.org/abs/2509.08753v2</link><description>We introduce Delayed Streams Modeling (DSM), a flexible formulation forstreaming, multimodal sequence-to-sequence learning. Sequence-to-sequencegeneration is often cast in an offline manner, where the model consumes thecomplete input sequence before generating the first output timestep.Alternatively, streaming sequence-to-sequence rely on learning a policy forchoosing when to advance on the input stream, or write to the output stream.DSM instead models already time-aligned streams with a decoder-only languagemodel. By moving the alignment to a pre-processing step,and introducingappropriate delays between streams, DSM provides streaming inference ofarbitrary output sequences, from any input combination, making it applicable tomany sequence-to-sequence problems. In particular, given text and audiostreams, automatic speech recognition (ASR) corresponds to the text streambeing delayed, while the opposite gives a text-to-speech (TTS) model. Weperform extensive experiments for these two major sequence-to-sequence tasks,showing that DSM provides state-of-the-art performance and latency whilesupporting arbitrary long sequences, being even competitive with offlinebaselines. Code, samples and demos are available athttps://github.com/kyutai-labs/delayed-streams-modeling</description><author>Neil Zeghidour, Eugene Kharitonov, Manu Orsini, Václav Volhejn, Gabriel de Marmiesse, Edouard Grave, Patrick Pérez, Laurent Mazaré, Alexandre Défossez</author><pubDate>Mon, 29 Sep 2025 16:17:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.08753v2</guid></item><item><title>LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines</title><link>http://arxiv.org/abs/2509.19580v3</link><description>Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our viewof the world. For example, Large Language Models (LLMs) based applications suchas ChatGPT have shown the capability of generating human-like conversation onextensive topics. Due to the impressive performance on a variety oflanguage-related tasks (e.g., open-domain question answering, translation, anddocument summarization), one can envision the far-reaching impacts that can bebrought by the LLMs with broader real-world applications (e.g., customerservice, education and accessibility, and scientific discovery). Inspired bytheir success, this paper will offer an overview of state-of-the-art LLMs andtheir integration into a wide range of academic disciplines, including: (1)arts, letters, and law (e.g., history, philosophy, political science, arts andarchitecture, law), (2) economics and business (e.g., finance, economics,accounting, marketing), and (3) science and engineering (e.g., mathematics,physics and mechanical engineering, chemistry and chemical engineering, lifesciences and bioengineering, earth sciences and civil engineering, computerscience and electrical engineering). Integrating humanity and technology, inthis paper, we will explore how LLMs are shaping research and practice in thesefields, while also discussing key limitations, open challenges, and futuredirections in the era of generative AI. The review of how LLMs are engagedacross disciplines-along with key observations and insights-can helpresearchers and practitioners interested in exploiting LLMs to advance theirworks in diverse real-world applications.</description><author>Yanfang Ye, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Yiyang Li, Shifu Hou, Weixiang Sun, Kaiwen Shi, Yijun Ma, Wei Song, Ahmed Abbasi, Ying Cheng, Jane Cleland-Huang, Steven Corcelli, Robert Goulding, Ming Hu, Ting Hua, John Lalor, Fang Liu, Tengfei Luo, Ed Maginn, Nuno Moniz, Jason Rohr, Brett Savoie, Daniel Slate, Tom Stapleford, Matthew Webber, Olaf Wiest, Johnny Zhang, Nitesh V. Chawla</author><pubDate>Mon, 29 Sep 2025 16:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.19580v3</guid></item><item><title>FRABench and UFEval: Unified Fine-grained Evaluation with Task and Aspect Generalization</title><link>http://arxiv.org/abs/2505.12795v4</link><description>Evaluating open-ended outputs of Multimodal Large Language Models has becomea bottleneck as model capabilities, task diversity, and modality rapidlyexpand. Existing ``MLLM-as-a-Judge'' evaluators, though promising, remainconstrained to specific tasks and aspects. In this paper, we argue that, on onehand, based on the interconnected nature of aspects, learning specific aspectscan generalize to unseen aspects; on the other hand, jointly learning to assessmultiple visual aspects and tasks may foster a synergistic effect. To this end,we propose UFEval, the first unified fine-grained evaluator with task andaspect generalization for four evaluation tasks -- Natural Language Generation,Image Understanding, Image Generation, and Interleaved Text-and-ImageGeneration. However, training such a unified evaluator is hindered by the lackof a large-scale, multi-modal, and aspect-level resource. To address this gap,we introduce FRABench, a comprehensive fine-grained evaluation dataset.Specifically, (1) We first construct a hierarchical aspect taxonomyencompassing 112 distinct aspects across the aforementioned four tasks. (2)Based on this taxonomy, we create FRABench, comprising 60.4k pairwise sampleswith 325k evaluation labels obtained from a combination of human and GPT-4oannotations. (3) Finally, leveraging FRABench, we develop UFEval, a unifiedfine-grained evaluator. Experiments show that learning on specific aspectsenables UFEval to generalize to unseen aspects, and joint learning to assessdiverse visual tasks and aspects can lead to substantial mutual benefits.</description><author>Shibo Hong, Jiahao Ying, Haiyuan Liang, Mengdi Zhang, Jun Kuang, Jiazheng Zhang, Yixin Cao</author><pubDate>Mon, 29 Sep 2025 16:11:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.12795v4</guid></item><item><title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title><link>http://arxiv.org/abs/2504.06958v4</link><description>Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description><author>Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang</author><pubDate>Mon, 29 Sep 2025 16:09:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.06958v4</guid></item><item><title>Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards</title><link>http://arxiv.org/abs/2509.24981v1</link><description>RL with Verifiable Rewards (RLVR) has emerged as a promising paradigm forimproving the reasoning abilities of large language models (LLMs). Currentmethods rely primarily on policy optimization frameworks like PPO and GRPO,which follow generalized policy iteration that alternates between evaluatingthe current policy's value and improving the policy based on evaluation. Whileeffective, they often suffer from training instability and diversity collapse,requiring complex heuristic tricks and careful tuning. We observe that standardRLVR in math reasoning can be formalized as a specialized finite-horizon MarkovDecision Process with deterministic state transitions, tree-structureddynamics, and binary terminal rewards. Though large in scale, the underlyingstructure is simpler than general-purpose control settings for which popular RLalgorithms (e.g., PPO) were developed, suggesting that several sophisticatedtechniques in existing methods may be reduced or even omitted. Based on thisinsight, we prove a surprising result: the optimal action can be recovered fromthe Q-function of a fixed uniformly random policy, thereby bypassing thegeneralized policy iteration loop and its associated heuristics. We introduceRandom Policy Valuation for Diverse Reasoning (ROVER) to translate thisprinciple into a practical and scalable algorithm for LLM math reasoning, aminimalist yet highly effective RL method that samples actions from a softmaxover these uniform-policy Q-values. ROVER preserves diversity throughouttraining, allowing sustained exploration of multiple valid pathways. Acrossmultiple base models and standard math reasoning benchmarks, ROVER demonstratessuperior performance in both \textbf{quality} (\textbf{+8.2} on pass@1,\textbf{+16.8} on pass@256) and \textbf{diversity} (\textbf{+17.6\%}), despiteits radical simplification compared to strong, complicated existing methods.</description><author>Haoran He, Yuxiao Ye, Qingpeng Cai, Chen Hu, Binxing Jiao, Daxin Jiang, Ling Pan</author><pubDate>Mon, 29 Sep 2025 16:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24981v1</guid></item><item><title>SDPose: Exploiting Diffusion Priors for Out-of-Domain and Robust Pose Estimation</title><link>http://arxiv.org/abs/2509.24980v1</link><description>Pre-trained diffusion models provide rich multi-scale latent features and areemerging as powerful vision backbones. While recent works such asMarigold~\citep{ke2024repurposing} and Lotus~\citep{he2024lotus} adaptdiffusion priors for dense prediction with strong cross-domain generalization,their potential for structured outputs (e.g., human pose estimation) remainsunderexplored. In this paper, we propose \textbf{SDPose}, a fine-tuningframework built upon Stable Diffusion to fully exploit pre-trained diffusionpriors for human pose estimation. First, rather than modifying cross-attentionmodules or introducing learnable embeddings, we directly predict keypointheatmaps in the SD U-Net's image latent space to preserve the originalgenerative priors. Second, we map these latent features into keypoint heatmapsthrough a lightweight convolutional pose head, which avoids disrupting thepre-trained backbone. Finally, to prevent overfitting and enhanceout-of-distribution robustness, we incorporate an auxiliary RGB reconstructionbranch that preserves domain-transferable generative semantics. To evaluaterobustness under domain shift, we further construct \textbf{COCO-OOD}, astyle-transferred variant of COCO with preserved annotations. With justone-fifth of the training schedule used by Sapiens on COCO, SDPose attainsparity with Sapiens-1B/2B on the COCO validation set and establishes a newstate of the art on the cross-domain benchmarks HumanArt and COCO-OOD.Furthermore, we showcase SDPose as a zero-shot pose annotator for downstreamcontrollable generation tasks, including ControlNet-based image synthesis andvideo generation, where it delivers qualitatively superior pose guidance.</description><author>Shuang Liang, Jing He, Chuanmeizhi Wang, Lejun Liao, Guo Zhang, Yingcong Chen, Yuan Yuan</author><pubDate>Mon, 29 Sep 2025 16:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24980v1</guid></item><item><title>A Survey on Stereotype Detection in Natural Language Processing</title><link>http://arxiv.org/abs/2505.17642v2</link><description>Stereotypes influence social perceptions and can escalate into discriminationand violence. While NLP research has extensively addressed gender bias and hatespeech, stereotype detection remains an emerging field with significantsocietal implications. In this work is presented a survey of existing research,analyzing definitions from psychology, sociology, and philosophy. Asemi-automatic literature review was performed by using Semantic Scholar. Weretrieved and filtered over 6,000 papers (in the year range 2000-2025),identifying key trends, methodologies, challenges and future directions. Thefindings emphasize stereotype detection as a potential early-monitoring tool toprevent bias escalation and the rise of hate speech. Conclusions highlight theneed for a broader, multilingual, and intersectional approach in NLP studies.</description><author>Alessandra Teresa Cignarella, Anastasia Giachanou, Els Lefever</author><pubDate>Mon, 29 Sep 2025 16:08:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.17642v2</guid></item><item><title>Wan-Alpha: High-Quality Text-to-Video Generation with Alpha Channel</title><link>http://arxiv.org/abs/2509.24979v1</link><description>RGBA video generation, which includes an alpha channel to representtransparency, is gaining increasing attention across a wide range ofapplications. However, existing methods often neglect visual quality, limitingtheir practical usability. In this paper, we propose \textit{Wan-Alpha}, a newframework that generates transparent videos by learning both RGB and alphachannels jointly. We design an effective variational autoencoder (VAE) thatencodes the alpha channel into the RGB latent space. Then, to support thetraining of our diffusion transformer, we construct a high-quality and diverseRGBA video dataset. Compared with state-of-the-art methods, our modeldemonstrates superior performance in visual quality, motion realism, andtransparency rendering. Notably, our model can generate a wide variety ofsemi-transparent objects, glowing effects, and fine-grained details such ashair strands. The released model is available on our website:\href{https://donghaotian123.github.io/Wan-Alpha/}{https://donghaotian123.github.io/Wan-Alpha/}.</description><author>Haotian Dong, Wenjing Wang, Chen Li, Di Lin</author><pubDate>Mon, 29 Sep 2025 16:08:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24979v1</guid></item><item><title>MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis</title><link>http://arxiv.org/abs/2506.08900v3</link><description>Artificial intelligence (AI) has become a fundamental tool for assistingclinicians in analyzing ophthalmic images, such as optical coherence tomography(OCT). However, developing AI models often requires extensive annotation, andexisting models tend to underperform on independent, unseen data. Foundationmodels (FMs), large AI models trained on vast unlabeled datasets, have shownpromise in overcoming these challenges. Nonetheless, available FMs forophthalmology lack extensive validation, especially for segmentation tasks, andfocus on a single imaging modality. In this context, we propose MIRAGE, a novelmultimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)images. Additionally, we propose a new evaluation benchmark with OCT/SLOclassification and segmentation tasks. The comparison with general andspecialized FMs and segmentation methods shows the superiority of MIRAGE inboth types of tasks, highlighting its suitability as a basis for thedevelopment of robust AI systems for retinal OCT image analysis. Both MIRAGEand the evaluation benchmark are publicly available:https://github.com/j-morano/MIRAGE.</description><author>José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie, Ursula Schmidt-Erfurth, Hrvoje Bogunović</author><pubDate>Mon, 29 Sep 2025 16:07:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.08900v3</guid></item><item><title>Agentic Exploration of Physics Models</title><link>http://arxiv.org/abs/2509.24978v1</link><description>The process of scientific discovery relies on an interplay of observations,analysis, and hypothesis generation. Machine learning is increasingly beingadopted to address individual aspects of this process. However, it remains anopen challenge to fully automate the open-ended, heuristic, iterative looprequired to discover the laws of an unknown system by exploring it throughexperiments and analysis, without tailoring the approach to the specifics of agiven task. Here, we introduce SciExplorer, an agent that leverages largelanguage model tool-use capabilities to enable free-form exploration of systemswithout any domain-specific blueprints, and apply it to the exploration ofphysical systems that are initially unknown to the agent. We test SciExploreron a broad set of models spanning mechanical dynamical systems, wave evolution,and quantum many-body physics. Despite using a minimal set of tools, primarilybased on code execution, we observe impressive performance on tasks such asrecovering equations of motion from observed dynamics and inferringHamiltonians from expectation values. The demonstrated effectiveness of thissetup opens the door towards similar scientific exploration in other domains,without the need for finetuning or task-specific instructions.</description><author>Maximilian Nägele, Florian Marquardt</author><pubDate>Mon, 29 Sep 2025 16:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24978v1</guid></item><item><title>DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern</title><link>http://arxiv.org/abs/2509.24975v1</link><description>Software development relies heavily on extensive unit testing, which makesthe efficiency of automated Unit Test Generation (UTG) particularly important.However, most existing LLMs generate test cases one token at a time in eachforward pass, which leads to inefficient UTG. Recently, diffusion LLMs (dLLMs)have emerged, offering promising parallel generation capabilities and showingstrong potential for efficient UTG. Despite this advantage, their applicationto UTG is still constrained by a clear trade-off between efficiency and testquality, since increasing the number of tokens generated in each step oftencauses a sharp decline in the quality of test cases. To overcome thislimitation, we present DiffTester, an acceleration framework specificallytailored for dLLMs in UTG. The key idea of DiffTester is that unit teststargeting the same focal method often share repetitive structural patterns. Bydynamically identifying these common patterns through abstract syntax treeanalysis during generation, DiffTester adaptively increases the number oftokens produced at each step without compromising the quality of the output. Toenable comprehensive evaluation, we extend the original TestEval benchmark,which was limited to Python, by introducing additional programming languagesincluding Java and C++. Extensive experiments on three benchmarks with tworepresentative models show that DiffTester delivers significant accelerationwhile preserving test coverage. Moreover, DiffTester generalizes well acrossdifferent dLLMs and programming languages, providing a practical and scalablesolution for efficient UTG in software development. Code and data are publiclyavailable at https://github.com/wellbeingyang/DLM4UTG-open .</description><author>Lekang Yang, Yuetong Liu, Yitong Zhang, Jia Li</author><pubDate>Mon, 29 Sep 2025 16:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24975v1</guid></item><item><title>Signal in the Noise: Polysemantic Interference Transfers and Predicts Cross-Model Influence</title><link>http://arxiv.org/abs/2505.11611v2</link><description>Polysemanticity is pervasive in language models and remains a major challengefor interpretation and model behavioral control. Leveraging sparse autoencoders(SAEs), we map the polysemantic topology of two small models (Pythia-70M andGPT-2-Small) to identify SAE feature pairs that are semantically unrelated yetexhibit interference within models. We intervene at four loci (prompt, token,feature, neuron) and measure induced shifts in the next-token predictiondistribution, uncovering polysemantic structures that expose a systematicvulnerability in these models. Critically, interventions distilled fromcounterintuitive interference patterns shared by two small models transferreliably to larger instruction-tuned models (Llama-3.1-8B/70B-Instruct andGemma-2-9B-Instruct), yielding predictable behavioral shifts without access tomodel internals. These findings challenge the view that polysemanticity ispurely stochastic, demonstrating instead that interference structuresgeneralize across scale and family. Such generalization suggests a convergent,higher-order organization of internal representations, which is only weaklyaligned with intuition and structured by latent regularities, offering newpossibilities for both black-box control and theoretical insight into human andartificial cognition.</description><author>Bofan Gong, Shiyang Lai, James Evans, Dawn Song</author><pubDate>Mon, 29 Sep 2025 16:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.11611v2</guid></item><item><title>Double Descent as a Lens for Sample Efficiency in Autoregressive vs. Discrete Diffusion Models</title><link>http://arxiv.org/abs/2509.24974v1</link><description>Data scarcity drives the need for more sample-efficient large languagemodels. In this work, we use the double descent phenomenon to holisticallycompare the sample efficiency of discrete diffusion and autoregressive models.We show that discrete diffusion models require larger capacity and moretraining epochs to escape their underparameterized regime and reach theinterpolation threshold. In the strongly overparameterized regime, both modelsexhibit similar behavior, with neither exhibiting a pronounced second descentin test loss across a large range of model sizes. Overall, our results indicatethat autoregressive models are more sample-efficient on small-scale datasets,while discrete diffusion models only become competitive when given sufficientcapacity and compute.</description><author>Ahmad Fraij, Sam Dauncey</author><pubDate>Mon, 29 Sep 2025 16:03:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.24974v1</guid></item></channel></rss>