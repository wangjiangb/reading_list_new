<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 09 Oct 2025 13:00:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Temporal Prompting Matters: Rethinking Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2510.07319v1</link><description>Referring Video Object Segmentation (RVOS) aims to segment the objectreferred to by the query sentence in the video. Most existing methods requireend-to-end training with dense mask annotations, which could becomputation-consuming and less scalable. In this work, we rethink the RVOSproblem and aim to investigate the key to this task. Based on existingfoundation segmentation models, we decompose the RVOS task into referring,video, and segmentation factors, and propose a Temporal Prompt Generation andSelection (Tenet) framework to address the referring and video factors whileleaving the segmentation problem to foundation models. To efficiently adaptimage-based foundation segmentation models to referring video objectsegmentation, we leverage off-the-shelf object detectors and trackers toproduce temporal prompts associated with the referring sentence. Whilehigh-quality temporal prompts could be produced, they can not be easilyidentified from confidence scores. To tackle this issue, we propose PromptPreference Learning to evaluate the quality of the produced temporal prompts.By taking such prompts to instruct image-based foundation segmentation models,we would be able to produce high-quality masks for the referred object,enabling efficient model adaptation to referring video object segmentation.Experiments on RVOS benchmarks demonstrate the effectiveness of the Tenetframework.</description><author>Ci-Siang Lin, Min-Hung Chen, I-Jieh Liu, Chien-Yi Wang, Sifei Liu, Yu-Chiang Frank Wang</author><pubDate>Wed, 08 Oct 2025 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07319v1</guid></item><item><title>Artificial Hippocampus Networks for Efficient Long-Context Modeling</title><link>http://arxiv.org/abs/2510.07318v1</link><description>Long-sequence modeling faces a fundamental trade-off between the efficiencyof compressive fixed-size memory in RNN-like models and the fidelity oflossless growing memory in attention-based Transformers. Inspired by theMulti-Store Model in cognitive science, we introduce a memory framework ofartificial neural networks. Our method maintains a sliding window of theTransformer's KV cache as lossless short-term memory, while a learnable moduletermed Artificial Hippocampus Network (AHN) recurrently compressesout-of-window information into a fixed-size compact long-term memory. Tovalidate this framework, we instantiate AHNs using modern RNN-likearchitectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensiveexperiments on long-context benchmarks LV-Eval and InfiniteBench demonstratethat AHN-augmented models consistently outperform sliding window baselines andachieve performance comparable or even superior to full-attention models, whilesubstantially reducing computational and memory requirements. For instance,augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5%and memory cache by 74.0%, while improving its average score on LV-Eval (128ksequence length) from 4.41 to 5.88. Code is available at:https://github.com/ByteDance-Seed/AHN.</description><author>Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei</author><pubDate>Wed, 08 Oct 2025 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07318v1</guid></item><item><title>Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms</title><link>http://arxiv.org/abs/2510.07317v1</link><description>Quantum-enhanced Computer Vision (QeCV) is a new research field at theintersection of computer vision, optimisation theory, machine learning andquantum computing. It has high potential to transform how visual signals areprocessed and interpreted with the help of quantum computing that leveragesquantum-mechanical effects in computations inaccessible to classical (i.e.non-quantum) computers. In scenarios where existing non-quantum methods cannotfind a solution in a reasonable time or compute only approximate solutions,quantum computers can provide, among others, advantages in terms of better timescalability for multiple problem classes. Parametrised quantum circuits canalso become, in the long term, a considerable alternative to classical neuralnetworks in computer vision. However, specialised and fundamentally newalgorithms must be developed to enable compatibility with quantum hardware andunveil the potential of quantum computational paradigms in computer vision.This survey contributes to the existing literature on QeCV with a holisticreview of this research field. It is designed as a quantum computing referencefor the computer vision community, targeting computer vision students,scientists and readers with related backgrounds who want to familiarisethemselves with QeCV. We provide a comprehensive introduction to QeCV, itsspecifics, and methodologies for formulations compatible with quantum hardwareand QeCV methods, leveraging two main quantum computational paradigms, i.e.gate-based quantum computing and quantum annealing. We elaborate on theoperational principles of quantum computers and the available tools to access,program and simulate them in the context of QeCV. Finally, we review existingquantum computing tools and learning materials and discuss aspects related topublishing and reviewing QeCV papers, open challenges and potential socialimplications.</description><author>Natacha Kuete Meli, Shuteng Wang, Marcel Seelbach Benkner, Michele Sasdelli, Tat-Jun Chin, Tolga Birdal, Michael Moeller, Vladislav Golyanik</author><pubDate>Wed, 08 Oct 2025 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07317v1</guid></item><item><title>NdLinear: Preserving Multi-Dimensional Structure for Parameter-Efficient Neural Networks</title><link>http://arxiv.org/abs/2503.17353v3</link><description>In deep learning, processing multidimensional inputs (e.g., images, medicalscans, and time series) is an important task that often requires flattening theinputs. We introduce $\mathit{NdLinear}$, a drop-in replacement for linearlayers that operates directly on tensors, requiring no flattening. By applyingtransformations separately along each dimension, NdLinear preserves native datastructure while achieving dramatic parameter reductions, often by orders ofmagnitude, with minimal memory overhead. We prove NdLinear maintainsexpressivity through structured Tucker decomposition while preservingVC-dimension scaling. Extensive experiments demonstrate NdLinear's capacity toachieve significant parameter reductions with substantial wall-clock efficiencygains and minimal memory overhead. For instance, our $\mathit{NdLinear-LoRA}$matches or exceeds standard LoRA on language reasoning tasks using up to$9\times$ fewer parameters. Experiments across CNNs, RNNs, Transformers, andMLPs on vision, language, time-series, and tabular tasks consistentlydemonstrate NdLinear's efficiency gains. While excelling at axis-separabletasks, NdLinear has limitations with entangled spatial interactions. Byprocessing data in its original N-dimensional form, NdLinear provides atheoretically grounded, practical component for building more efficient neuralarchitectures.</description><author>Alex Reneau, Jerry Yao-Chieh Hu, Zhongfang Zhuang, Ting-Chun Liu, Xiang He, Judah Goldfeder, Nadav Timor, Allen G Roush, Ravid Shwartz-Ziv</author><pubDate>Wed, 08 Oct 2025 17:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.17353v3</guid></item><item><title>Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers</title><link>http://arxiv.org/abs/2510.07316v1</link><description>This paper presents Pixel-Perfect Depth, a monocular depth estimation modelbased on pixel-space diffusion generation that produces high-quality,flying-pixel-free point clouds from estimated depth maps. Current generativedepth estimation models fine-tune Stable Diffusion and achieve impressiveperformance. However, they require a VAE to compress depth maps into latentspace, which inevitably introduces \textit{flying pixels} at edges and details.Our model addresses this challenge by directly performing diffusion generationin the pixel space, avoiding VAE-induced artifacts. To overcome the highcomplexity associated with pixel-space generation, we introduce two noveldesigns: 1) Semantics-Prompted Diffusion Transformers (SP-DiT), whichincorporate semantic representations from vision foundation models into DiT toprompt the diffusion process, thereby preserving global semantic consistencywhile enhancing fine-grained visual details; and 2) Cascade DiT Design thatprogressively increases the number of tokens to further enhance efficiency andaccuracy. Our model achieves the best performance among all publishedgenerative models across five benchmarks, and significantly outperforms allother models in edge-aware point cloud evaluation.</description><author>Gangwei Xu, Haotong Lin, Hongcheng Luo, Xianqi Wang, Jingfeng Yao, Lianghui Zhu, Yuechuan Pu, Cheng Chi, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Sida Peng, Xin Yang</author><pubDate>Wed, 08 Oct 2025 17:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07316v1</guid></item><item><title>Vibe Checker: Aligning Code Evaluation with Human Preference</title><link>http://arxiv.org/abs/2510.07315v1</link><description>Large Language Models (LLMs) have catalyzed vibe coding, where users leverageLLMs to generate and iteratively refine code through natural languageinteractions until it passes their vibe check. Vibe check is tied to real-worldhuman preference and goes beyond functionality: the solution should feel right,read cleanly, preserve intent, and remain correct. However, current codeevaluation remains anchored to pass@k and captures only functional correctness,overlooking the non-functional instructions that users routinely apply. In thispaper, we hypothesize that instruction following is the missing pieceunderlying vibe check that represents human preference in coding besidesfunctional correctness. To quantify models' code instruction followingcapabilities with measurable signals, we present VeriCode, a taxonomy of 30verifiable code instructions together with corresponding deterministicverifiers. We use the taxonomy to augment established evaluation suites,resulting in Vibe Checker, a testbed to assess both code instruction followingand functional correctness. Upon evaluating 31 leading LLMs, we show that eventhe strongest models struggle to comply with multiple instructions and exhibitclear functional regression. Most importantly, a composite score of functionalcorrectness and instruction following correlates the best with humanpreference, with the latter emerging as the primary differentiator onreal-world programming tasks. Our work identifies core factors of the vibecheck, providing a concrete path for benchmarking and developing models thatbetter align with user preferences in coding.</description><author>Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun</author><pubDate>Wed, 08 Oct 2025 17:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07315v1</guid></item><item><title>GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations</title><link>http://arxiv.org/abs/2510.07314v1</link><description>Nuclear fusion plays a pivotal role in the quest for reliable and sustainableenergy production. A major roadblock to viable fusion power is understandingplasma turbulence, which significantly impairs plasma confinement, and is vitalfor next-generation reactor design. Plasma turbulence is governed by thenonlinear gyrokinetic equation, which evolves a 5D distribution function overtime. Due to its high computational cost, reduced-order models are oftenemployed in practice to approximate turbulent transport of energy. However,they omit nonlinear effects unique to the full 5D dynamics. To tackle this, weintroduce GyroSwin, the first scalable 5D neural surrogate that can model 5Dnonlinear gyrokinetic simulations, thereby capturing the physical phenomenaneglected by reduced models, while providing accurate estimates of turbulentheat transport.GyroSwin (i) extends hierarchical Vision Transformers to 5D,(ii) introduces cross-attention and integration modules for latent3D$\leftrightarrow$5D interactions between electrostatic potential fields andthe distribution function, and (iii) performs channelwise mode separationinspired by nonlinear physics. We demonstrate that GyroSwin outperforms widelyused reduced numerics on heat flux prediction, captures the turbulent energycascade, and reduces the cost of fully resolved nonlinear gyrokinetics by threeorders of magnitude while remaining physically verifiable. GyroSwin showspromising scaling laws, tested up to one billion parameters, paving the way forscalable neural surrogates for gyrokinetic simulations of plasma turbulence.</description><author>Fabian Paischer, Gianluca Galletti, William Hornsby, Paul Setinek, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, Johannes Brandstetter</author><pubDate>Wed, 08 Oct 2025 17:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07314v1</guid></item><item><title>WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation</title><link>http://arxiv.org/abs/2510.07313v1</link><description>Wrist-view observations are crucial for VLA models as they capturefine-grained hand-object interactions that directly enhance manipulationperformance. Yet large-scale datasets rarely include such recordings, resultingin a substantial gap between abundant anchor views and scarce wrist views.Existing world models cannot bridge this gap, as they require a wrist-viewfirst frame and thus fail to generate wrist-view videos from anchor viewsalone. Amid this gap, recent visual geometry models such as VGGT emerge withgeometric and cross-view priors that make it possible to address extremeviewpoint shifts. Inspired by these insights, we propose WristWorld, the first4D world model that generates wrist-view videos solely from anchor views.WristWorld operates in two stages: (i) Reconstruction, which extends VGGT andincorporates our Spatial Projection Consistency (SPC) Loss to estimategeometrically consistent wrist-view poses and 4D point clouds; (ii) Generation,which employs our video generation model to synthesize temporally coherentwrist-view videos from the reconstructed perspective. Experiments on Droid,Calvin, and Franka Panda demonstrate state-of-the-art video generation withsuperior spatial consistency, while also improving VLA performance, raising theaverage task completion length on Calvin by 3.81% and closing 42.4% of theanchor-wrist view gap.</description><author>Zezhong Qian, Xiaowei Chi, Yuming Li, Shizun Wang, Zhiyuan Qin, Xiaozhu Ju, Sirui Han, Shanghang Zhang</author><pubDate>Wed, 08 Oct 2025 17:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07313v1</guid></item><item><title>h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement Learning</title><link>http://arxiv.org/abs/2510.07312v1</link><description>Large language models excel at short-horizon reasoning tasks, but performancedrops as reasoning horizon lengths increase. Existing approaches to combat thisrely on inference-time scaffolding or costly step-level supervision, neither ofwhich scales easily. In this work, we introduce a scalable method to bootstraplong-horizon reasoning capabilities using only existing, abundant short-horizondata. Our approach synthetically composes simple problems into complex,multi-step dependency chains of arbitrary length. We train models on this datausing outcome-only rewards under a curriculum that automatically increases incomplexity, allowing RL training to be scaled much further without saturating.Empirically, our method generalizes remarkably well: curriculum training oncomposed 6th-grade level math problems (GSM8K) boosts accuracy on longer,competition-level benchmarks (GSM-Symbolic, MATH-500, AIME) by up to 2.06x.Importantly, our long-horizon improvements are significantly higher thanbaselines even at high pass@k, showing that models can learn new reasoningpaths under RL. Theoretically, we show that curriculum RL with outcome rewardsachieves an exponential improvement in sample complexity over full-horizontraining, providing training signal comparable to dense supervision. h1therefore introduces an efficient path towards scaling RL for long-horizonproblems using only existing data.</description><author>Sumeet Ramesh Motwani, Alesia Ivanova, Ziyang Cai, Philip Torr, Riashat Islam, Shital Shah, Christian Schroeder de Witt, Charles London</author><pubDate>Wed, 08 Oct 2025 17:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07312v1</guid></item><item><title>DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning</title><link>http://arxiv.org/abs/2508.12726v3</link><description>Large language models (LLMs) have achieved remarkable success in many naturallanguage tasks but still struggle with complex, multi-step reasoning,particularly across diverse disciplines. Existing reasoning datasets often lackdisciplinary breadth, reasoning depth, and diversity, and lack guidingprinciples for question synthesis. We propose DESIGNER: a DESIGN-logic-guidEdReasoning data synthesis pipeline that leverages naturally available, extensiveraw documents (e.g., book corpus and web corpus) to generate multidisciplinarychallenging questions. We introduce the concept of "design logic" and instructLLMs to mimic human educators' question-creation process, enabling automatedsynthesis of large-scale, high-difficulty questions. We use LLMs toreverse-engineer and abstract over 120,000 design logics from existingquestions across various disciplines. By matching these design logics withsource documents, we are able to create reasoning questions that far surpassthe difficulty and diversity of existing datasets. Using this pipeline, wesynthesized two large-scale reasoning datasets that span 75 disciplines:DLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66million questions from the web corpus). Data analysis indicates that thequestions synthesized by our method exhibit greater difficulty and diversitycompared to those in the baseline datasets. We validate our synthesized datathrough supervised fine-tuning (SFT) on the Qwen3 and Llama3 model families.Our data substantially enhances their multidisciplinary reasoning capabilities,outperforming existing datasets. Notably, after SFT on our datasets, the baseversions of these models even surpass their official instruction-tunedcounterparts.</description><author>Weize Liu, Yongchi Zhao, Yijia Luo, Mingyu Xu, Jiaheng Liu, Yanan Li, Xiguo Hu, Zhiqi Bai, Yuchi Xu, Wenbo Su, Bo Zheng</author><pubDate>Wed, 08 Oct 2025 17:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.12726v3</guid></item><item><title>MATRIX: Mask Track Alignment for Interaction-aware Video Generation</title><link>http://arxiv.org/abs/2510.07310v1</link><description>Video DiTs have advanced video generation, yet they still struggle to modelmulti-instance or subject-object interactions. This raises a key question: Howdo these models internally represent interactions? To answer this, we curateMATRIX-11K, a video dataset with interaction-aware captions and multi-instancemask tracks. Using this dataset, we conduct a systematic analysis thatformalizes two perspectives of video DiTs: semantic grounding, viavideo-to-text attention, which evaluates whether noun and verb tokens captureinstances and their relations; and semantic propagation, via video-to-videoattention, which assesses whether instance bindings persist across frames. Wefind both effects concentrate in a small subset of interaction-dominant layers.Motivated by this, we introduce MATRIX, a simple and effective regularizationthat aligns attention in specific layers of video DiTs with multi-instance masktracks from the MATRIX-11K dataset, enhancing both grounding and propagation.We further propose InterGenEval, an evaluation protocol for interaction-awarevideo generation. In experiments, MATRIX improves both interaction fidelity andsemantic alignment while reducing drift and hallucination. Extensive ablationsvalidate our design choices. Codes and weights will be released.</description><author>Siyoon Jin, Seongchan Kim, Dahyun Chung, Jaeho Lee, Hyunwook Choi, Jisu Nam, Jiyoung Kim, Seungryong Kim</author><pubDate>Wed, 08 Oct 2025 17:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07310v1</guid></item><item><title>Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain</title><link>http://arxiv.org/abs/2510.07309v1</link><description>In the business domain, where data-driven decision making is crucial,text-to-SQL is fundamental for easy natural language access to structured data.While recent LLMs have achieved strong performance in code generation, existingtext-to-SQL benchmarks remain focused on factual retrieval of past records. Weintroduce CORGI, a new benchmark specifically designed for real-world businesscontexts. CORGI is composed of synthetic databases inspired by enterprises suchas Doordash, Airbnb, and Lululemon. It provides questions across fourincreasingly complex categories of business queries: descriptive, explanatory,predictive, and recommendational. This challenge calls for causal reasoning,temporal forecasting, and strategic recommendation, reflecting multi-level andmulti-step agentic intelligence. We find that LLM performance drops onhigh-level questions, struggling to make accurate predictions and offeractionable plans. Based on execution success rate, the CORGI benchmark is about21\% more difficult than the BIRD benchmark. This highlights the gap betweenpopular LLMs and the need for real-world business intelligence. We release apublic dataset and evaluation framework, and a website for public submissions.</description><author>Yue Li, Ran Tao, Derek Hommel, Yusuf Denizay DÃ¶nder, Sungyong Chang, David Mimno, Unso Eun Seo Jo</author><pubDate>Wed, 08 Oct 2025 17:57:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07309v1</guid></item><item><title>MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline</title><link>http://arxiv.org/abs/2510.07307v1</link><description>While Language Models (LMs) have made significant progress in automatingmachine learning engineering (MLE), the acquisition of high-quality MLEtraining data is significantly constrained. Current MLE benchmarks suffer fromlow scalability and limited applicability because they rely on static, manuallycurated tasks, demanding extensive time and manual effort to produce. Weintroduce MLE-Smith, a fully automated multi-agent pipeline, to transform rawdatasets into competition-style MLE challenges through an efficientgenerate-verify-execute paradigm for scaling MLE tasks with verifiable quality,real-world usability, and rich diversity. The proposed multi-agent pipeline inMLE-Smith drives structured task design and standardized refactoring, coupledwith a hybrid verification mechanism that enforces strict structural rules andhigh-level semantic soundness. It further validates empirical solvability andreal-world fidelity through interactive execution. We apply MLE-Smith to 224 ofreal-world datasets and generate 606 tasks spanning multiple categories,objectives, and modalities, demonstrating that MLE-Smith can work effectivelyacross a wide range of real-world datasets. Evaluation on the generated tasksshows that the performance of eight mainstream and cutting-edge LLMs onMLE-Smith tasks is strongly correlated with their performance on carefullyhuman-designed tasks, highlighting the effectiveness of the MLE-Smith toscaling up MLE tasks, while maintaining task quality.</description><author>Rushi Qiang, Yuchen Zhuang, Anikait Singh, Percy Liang, Chao Zhang, Sherry Yang, Bo Dai</author><pubDate>Wed, 08 Oct 2025 17:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07307v1</guid></item><item><title>Cocoon: A System Architecture for Differentially Private Training with Correlated Noises</title><link>http://arxiv.org/abs/2510.07304v1</link><description>Machine learning (ML) models memorize and leak training data, causing seriousprivacy issues to data owners. Training algorithms with differential privacy(DP), such as DP-SGD, have been gaining attention as a solution. However,DP-SGD adds a noise at each training iteration, which degrades the accuracy ofthe trained model. To improve accuracy, a new family of approaches addscarefully designed correlated noises, so that noises cancel out each otheracross iterations. We performed an extensive characterization study of thesenew mechanisms, for the first time to the best of our knowledge, and show theyincur non-negligible overheads when the model is large or uses large embeddingtables. Motivated by the analysis, we propose Cocoon, a hardware-softwareco-designed framework for efficient training with correlated noises. Cocoonaccelerates models with embedding tables through pre-computing and storingcorrelated noises in a coalesced format (Cocoon-Emb), and supports large modelsthrough a custom near-memory processing device (Cocoon-NMP). On a real systemwith an FPGA-based NMP device prototype, Cocoon improves the performance by2.33-10.82x(Cocoon-Emb) and 1.55-3.06x (Cocoon-NMP).</description><author>Donghwan Kim, Xin Gu, Jinho Baek, Timothy Lo, Younghoon Min, Kwangsik Shin, Jongryool Kim, Jongse Park, Kiwan Maeng</author><pubDate>Wed, 08 Oct 2025 17:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07304v1</guid></item><item><title>SpecGuard: Spectral Projection-based Advanced Invisible Watermarking</title><link>http://arxiv.org/abs/2510.07302v1</link><description>Watermarking embeds imperceptible patterns into images for authenticityverification. However, existing methods often lack robustness against varioustransformations primarily including distortions, image regeneration, andadversarial perturbation, creating real-world challenges. In this work, weintroduce SpecGuard, a novel watermarking approach for robust and invisibleimage watermarking. Unlike prior approaches, we embed the message inside hiddenconvolution layers by converting from the spatial domain to the frequencydomain using spectral projection of a higher frequency band that is decomposedby wavelet projection. Spectral projection employs Fast Fourier Transformapproximation to transform spatial data into the frequency domain efficiently.In the encoding phase, a strength factor enhances resilience against diverseattacks, including adversarial, geometric, and regeneration-based distortions,ensuring the preservation of copyrighted information. Meanwhile, the decoderleverages Parseval's theorem to effectively learn and extract the watermarkpattern, enabling accurate retrieval under challenging transformations. Weevaluate the proposed SpecGuard based on the embedded watermark's invisibility,capacity, and robustness. Comprehensive experiments demonstrate the proposedSpecGuard outperforms the state-of-the-art models. To ensure reproducibility,the full code is released on\href{https://github.com/inzamamulDU/SpecGuard_ICCV_2025}{\textcolor{blue}{\textbf{GitHub}}}.</description><author>Inzamamul Alam, Md Tanvir Islam, Khan Muhammad, Simon S. Woo</author><pubDate>Wed, 08 Oct 2025 17:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07302v1</guid></item><item><title>Valid Inference with Imperfect Synthetic Data</title><link>http://arxiv.org/abs/2508.06635v2</link><description>Predictions and generations from large language models are increasingly beingexplored as an aid in limited data regimes, such as in computational socialscience and human subjects research. While prior technical work has mainlyexplored the potential to use model-predicted labels for unlabeled data in aprincipled manner, there is increasing interest in using large language modelsto generate entirely new synthetic samples (e.g., synthetic simulations), suchas in responses to surveys. However, it remains unclear by what meanspractitioners can combine such data with real data and yet producestatistically valid conclusions upon them. In this paper, we introduce a newestimator based on generalized method of moments, providing ahyperparameter-free solution with strong theoretical guarantees to address thischallenge. Intriguingly, we find that interactions between the moment residualsof synthetic data and those of real data (i.e., when they are predictive ofeach other) can greatly improve estimates of the target parameter. We validatethe finite-sample performance of our estimator across different tasks incomputational social science applications, demonstrating large empirical gains.</description><author>Yewon Byun, Shantanu Gupta, Zachary C. Lipton, Rachel Leah Childers, Bryan Wilder</author><pubDate>Wed, 08 Oct 2025 17:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.06635v2</guid></item><item><title>Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning</title><link>http://arxiv.org/abs/2510.07300v1</link><description>Large Reasoning Models (LRMs) have achieved remarkable performance on complexreasoning tasks by adopting the "think-then-answer" paradigm, which enhancesboth accuracy and interpretability. However, current LRMs exhibit two criticallimitations when processing non-English languages: (1) They often struggle tomaintain input-output language consistency; (2) They generally perform poorlywith wrong reasoning paths and lower answer accuracy compared to English. Theselimitations significantly degrade the user experience for non-English speakersand hinder the global deployment of LRMs. To address these limitations, wepropose M-Thinker, which is trained by the GRPO algorithm that involves aLanguage Consistency (LC) reward and a novel Cross-lingual Thinking Alignment(CTA) reward. Specifically, the LC reward defines a strict constraint on thelanguage consistency between the input, thought, and answer. Besides, the CTAreward compares the model's non-English reasoning paths with its Englishreasoning path to transfer its own reasoning capability from English tonon-English languages. Through an iterative RL procedure, our M-Thinker-1.5B/7Bmodels not only achieve nearly 100% language consistency and superiorperformance on two multilingual benchmarks (MMATH and PolyMath), but alsoexhibit excellent generalization on out-of-domain languages.</description><author>Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Kaiyu Huang, Yufeng Chen, Jinan Xu, Jie Zhou</author><pubDate>Wed, 08 Oct 2025 17:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07300v1</guid></item><item><title>LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models</title><link>http://arxiv.org/abs/2501.05468v2</link><description>Systematic literature reviews and meta-analyses are essential forsynthesizing research insights, but they remain time-intensive andlabor-intensive due to the iterative processes of screening, evaluation, anddata extraction. This paper introduces and evaluates LatteReview, aPython-based framework that leverages large language models (LLMs) andmulti-agent systems to automate key elements of the systematic review process.Designed to streamline workflows while maintaining rigor, LatteReview utilizesmodular agents for tasks such as title and abstract screening, relevancescoring, and structured data extraction. These agents operate withinorchestrated workflows, supporting sequential and parallel review rounds,dynamic decision-making, and iterative refinement based on user feedback.LatteReview's architecture integrates LLM providers, enabling compatibilitywith both cloud-based and locally hosted models. The framework supportsfeatures such as Retrieval-Augmented Generation (RAG) for incorporatingexternal context, multimodal reviews, Pydantic-based validation for structuredinputs and outputs, and asynchronous programming for handling large-scaledatasets. The framework is available on the GitHub repository, with detaileddocumentation and an installable package.</description><author>Pouria Rouzrokh, Bardia Khosravi, Parsa Rouzrokh, Moein Shariatnia</author><pubDate>Wed, 08 Oct 2025 17:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05468v2</guid></item><item><title>Agentic generative AI for media content discovery at the national football league</title><link>http://arxiv.org/abs/2510.07297v1</link><description>Generative AI has unlocked new possibilities in content discovery andmanagement. Through collaboration with the National Football League (NFL), wedemonstrate how a generative-AI based workflow enables media researchers andanalysts to query relevant historical plays using natural language rather thantraditional filter-and-click interfaces. The agentic workflow takes a userquery as input, breaks it into elements, and translates them into theunderlying database query language. Accuracy and latency are further improvedthrough carefully designed semantic caching. The solution achieves over 95percent accuracy and reduces the average time to find relevant videos from 10minutes to 30 seconds, significantly increasing the NFL's operationalefficiency and allowing users to focus on producing creative content andengaging storylines.</description><author>Henry Wang, Sirajus Salekin, Jake Lee, Ross Claytor, Shinan Zhang, Michael Chi</author><pubDate>Wed, 08 Oct 2025 17:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07297v1</guid></item><item><title>AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs</title><link>http://arxiv.org/abs/2510.07293v1</link><description>Processing long-form audio is a major challenge for Large Audio Languagemodels (LALMs). These models struggle with the quadratic cost of attention($O(N^2)$) and with modeling long-range temporal dependencies. Existing audiobenchmarks are built mostly from short clips and do not evaluate models inrealistic long context settings. To address this gap, we introduceAudioMarathon, a benchmark designed to evaluate both understanding andinference efficiency on long-form audio. AudioMarathon provides a diverse setof tasks built upon three pillars: long-context audio inputs with durationsranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of2,250 to 7,500 audio tokens, respectively, full domain coverage across speech,sound, and music, and complex reasoning that requires multi-hop inference. Weevaluate state-of-the-art LALMs and observe clear performance drops as audiolength grows. We also study acceleration techniques and analyze the trade-offsof token pruning and KV cache eviction. The results show large gaps acrosscurrent LALMs and highlight the need for better temporal reasoning andmemory-efficient architectures. We believe AudioMarathon will drive the audioand multimodal research community to develop more advanced audio understandingmodels capable of solving complex audio tasks.</description><author>Peize He, Zichen Wen, Yubo Wang, Yuxuan Wang, Xiaoqian Liu, Jiajie Huang, Zehui Lei, Zhuangcheng Gu, Xiangqi Jin, Jiabing Yang, Kai Li, Zhifei Liu, Weijia Li, Cunxiang Wang, Conghui He, Linfeng Zhang</author><pubDate>Wed, 08 Oct 2025 17:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07293v1</guid></item><item><title>Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents</title><link>http://arxiv.org/abs/2506.00320v2</link><description>Recent progress in reasoning with large language models (LLMs), such asDeepSeek-R1, demonstrates impressive capabilities in domains like mathematicsand coding, by exhibiting complex cognitive behaviors such as verification,goal decomposition, and self-reflection. However, it is unclear what behavioris effective and what behavior is missing for long-horizon AI agents tasks. Inthis work, we propose Dyna-Think, a thinking framework that integrates planningwith an internal world model with reasoning and acting to enhance AI agentperformance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy withDyna-Think, DIT reconstructs the thinking process of R1 to focus on performingworld model simulation relevant to the proposed (and planned) action, andtrains the policy using this reconstructed data. To enhance Dyna-Think, DDTuses a two-stage training process to first improve the agent's world modelingability via objectives such as state prediction or critique generation, andthen improve the agent's action via policy training. We evaluate our methods onOSWorld and WindowsAgentArena, and demonstrate that Dyna-Think improves theagent's in-domain and out-of-domain performance, achieving similar best-of-nperformance compared to R1 while generating 2x less tokens on average. Ourextensive empirical studies reveal that 1) using critique generation for worldmodel training is effective to improve policy performance; and 2) AI agentswith better performance correlate with better world modeling abilities. Webelieve our results suggest a promising research direction to integrate worldmodel simulation into AI agents to enhance their reasoning, planning, andacting capabilities.</description><author>Xiao Yu, Baolin Peng, Ruize Xu, Michel Galley, Hao Cheng, Suman Nath, Jianfeng Gao, Zhou Yu</author><pubDate>Wed, 08 Oct 2025 17:49:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.00320v2</guid></item><item><title>BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection in Language Model Pretraining</title><link>http://arxiv.org/abs/2510.06048v2</link><description>Effective data selection is essential for pretraining large language models(LLMs), enhancing efficiency and improving generalization to downstream tasks.However, existing approaches often require leveraging external pretrainedmodels, making it difficult to disentangle the effects of data selection fromthose of the external pretrained models. In addition, they often overlook thelong-term impact of selected data if the model is trained to convergence,primarily due to the prohibitive cost of full-scale LLM pretraining. In thispaper, we introduce BLISS (\textbf{B}ileve\textbf{L} \textbf{I}nfluence\textbf{S}coring method for data \textbf{S}election): a lightweight dataselection method that operates entirely \emph{from scratch}, without relying onany external pretrained oracle models, while explicitly accounting for thelong-term impact of selected data. BLISS leverages a small proxy model as asurrogate for the LLM and employs a score model to estimate the long-terminfluence of training samples if the proxy model is trained to convergence. Weformulate data selection as a bilevel optimization problem, where theupper-level objective optimizes the score model to assign importance weights totraining samples, ensuring that minimizing the lower-level objective (i.e.,training the proxy model over the weighted training loss until convergence)leads to best validation performance. Once optimized, the trained score modelpredicts influence scores for the dataset, enabling efficient selection ofhigh-quality samples for LLM pretraining. We validate BLISS by pretraining410M/1B/2.8B Pythia and LLaMA-0.5B models on selected subsets of the C4dataset. Notably, under the 1B model setting, BLISS achieves $1.7\times$speedup in reaching the same performance as the state-of-the-art method,demonstrating superior performance across multiple downstream tasks.</description><author>Jie Hao, Rui Yu, Wei Zhang, Huixia Wang, Jie Xu, Mingrui Liu</author><pubDate>Wed, 08 Oct 2025 17:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.06048v2</guid></item><item><title>SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models</title><link>http://arxiv.org/abs/2509.03487v2</link><description>Proteins play crucial roles in almost all biological processes. Theadvancement of deep learning has greatly accelerated the development of proteinfoundation models, leading to significant successes in protein understandingand design. However, the lack of systematic red-teaming for these models hasraised serious concerns about their potential misuse, such as generatingproteins with biological safety risks. This paper introduces SafeProtein, thefirst red-teaming framework designed for protein foundation models to the bestof our knowledge. SafeProtein combines multimodal prompt engineering andheuristic beam search to systematically design red-teaming methods and conducttests on protein foundation models. We also curated SafeProtein-Bench, whichincludes a manually constructed red-teaming benchmark dataset and acomprehensive evaluation protocol. SafeProtein achieved continuous jailbreakson state-of-the-art protein foundation models (up to 70% attack success ratefor ESM3), revealing potential biological safety risks in current proteinfoundation models and providing insights for the development of robust securityprotection technologies for frontier models. The codes will be made publiclyavailable at https://github.com/jigang-fan/SafeProtein.</description><author>Jigang Fan, Zhenghong Zhou, Ruofan Jin, Le Cong, Mengdi Wang, Zaixi Zhang</author><pubDate>Wed, 08 Oct 2025 17:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.03487v2</guid></item><item><title>On the Convergence of Moral Self-Correction in Large Language Models</title><link>http://arxiv.org/abs/2510.07290v1</link><description>Large Language Models (LLMs) are able to improve their responses wheninstructed to do so, a capability known as self-correction. When instructionsprovide only a general and abstract goal without specific details aboutpotential issues in the response, LLMs must rely on their internal knowledge toimprove response quality, a process referred to as intrinsic self-correction.The empirical success of intrinsic self-correction is evident in variousapplications, but how and why it is effective remains unknown. Focusing onmoral self-correction in LLMs, we reveal a key characteristic of intrinsicself-correction: performance convergence through multi-round interactions; andprovide a mechanistic analysis of this convergence behavior. Based on ourexperimental results and analysis, we uncover the underlying mechanism ofconvergence: consistently injected self-correction instructions activate moralconcepts that reduce model uncertainty, leading to converged performance as theactivated moral concepts stabilize over successive rounds. This paperdemonstrates the strong potential of moral self-correction by showing that itexhibits a desirable property of converged performance.</description><author>Guangliang Liu, Haitao Mao, Bochuan Cao, Zhiyu Xue, Xitong Zhang, Rongrong Wang, Kristen Marie Johnson</author><pubDate>Wed, 08 Oct 2025 17:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07290v1</guid></item><item><title>MolGA: Molecular Graph Adaptation with Pre-trained 2D Graph Encoder</title><link>http://arxiv.org/abs/2510.07289v1</link><description>Molecular graph representation learning is widely used in chemical andbiomedical research. While pre-trained 2D graph encoders have demonstratedstrong performance, they overlook the rich molecular domain knowledgeassociated with submolecular instances (atoms and bonds). While molecularpre-training approaches incorporate such knowledge into their pre-trainingobjectives, they typically employ designs tailored to a specific type ofknowledge, lacking the flexibility to integrate diverse knowledge present inmolecules. Hence, reusing widely available and well-validated pre-trained 2Dencoders, while incorporating molecular domain knowledge during downstreamadaptation, offers a more practical alternative. In this work, we proposeMolGA, which adapts pre-trained 2D graph encoders to downstream molecularapplications by flexibly incorporating diverse molecular domain knowledge.First, we propose a molecular alignment strategy that bridge the gap betweenpre-trained topological representations with domain-knowledge representations.Second, we introduce a conditional adaptation mechanism that generatesinstance-specific tokens to enable fine-grained integration of molecular domainknowledge for downstream tasks. Finally, we conduct extensive experiments oneleven public datasets, demonstrating the effectiveness of MolGA.</description><author>Xingtong Yu, Chang Zhou, Xinming Zhang, Yuan Fang</author><pubDate>Wed, 08 Oct 2025 17:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07289v1</guid></item><item><title>Evolutionary Profiles for Protein Fitness Prediction</title><link>http://arxiv.org/abs/2510.07286v1</link><description>Predicting the fitness impact of mutations is central to protein engineeringbut constrained by limited assays relative to the size of sequence space.Protein language models (pLMs) trained with masked language modeling (MLM)exhibit strong zero-shot fitness prediction; we provide a unifying view byinterpreting natural evolution as implicit reward maximization and MLM asinverse reinforcement learning (IRL), in which extant sequences act as expertdemonstrations and pLM log-odds serve as fitness estimates. Building on thisperspective, we introduce EvoIF, a lightweight model that integrates twocomplementary sources of evolutionary signal: (i) within-family profiles fromretrieved homologs and (ii) cross-family structural-evolutionary constraintsdistilled from inverse folding logits. EvoIF fuses sequence-structurerepresentations with these profiles via a compact transition block, yieldingcalibrated probabilities for log-odds scoring. On ProteinGym (217 mutationalassays; &gt;2.5M mutants), EvoIF and its MSA-enabled variant achievestate-of-the-art or competitive performance while using only 0.15% of thetraining data and fewer parameters than recent large models. Ablations confirmthat within-family and cross-family profiles are complementary, improvingrobustness across function types, MSA depths, taxa, and mutation depths. Thecodes will be made publicly available at https://github.com/aim-uofa/EvoIF.</description><author>Jigang Fan, Xiaoran Jiao, Shengdong Lin, Zhanming Liang, Weian Mao, Chenchen Jing, Hao Chen, Chunhua Shen</author><pubDate>Wed, 08 Oct 2025 17:46:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07286v1</guid></item><item><title>GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)</title><link>http://arxiv.org/abs/2510.07285v1</link><description>The escalating complexity of network threats and the inherent class imbalancein traffic data present formidable challenges for modern Intrusion DetectionSystems (IDS). While Graph Neural Networks (GNNs) excel in modeling topologicalstructures and Temporal Convolutional Networks (TCNs) are proficient incapturing time-series dependencies, a framework that synergistically integratesboth while explicitly addressing data imbalance remains an open challenge. Thispaper introduces a novel deep learning framework, named Gated TemporalConvolutional Network and Graph (GTCN-G), engineered to overcome theselimitations. Our model uniquely fuses a Gated TCN (G-TCN) for extractinghierarchical temporal features from network flows with a Graph ConvolutionalNetwork (GCN) designed to learn from the underlying graph structure. The coreinnovation lies in the integration of a residual learning mechanism,implemented via a Graph Attention Network (GAT). This mechanism preservesoriginal feature information through residual connections, which is criticalfor mitigating the class imbalance problem and enhancing detection sensitivityfor rare malicious activities (minority classes). We conducted extensiveexperiments on two public benchmark datasets, UNSW-NB15 and ToN-IoT, tovalidate our approach. The empirical results demonstrate that the proposedGTCN-G model achieves state-of-the-art performance, significantly outperformingexisting baseline models in both binary and multi-class classification tasks.</description><author>Tianxiang Xu, Zhichao Wen, Xinyu Zhao, Qi Hu, Yan Li, Chang Liu</author><pubDate>Wed, 08 Oct 2025 17:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07285v1</guid></item><item><title>Online Rubrics Elicitation from Pairwise Comparisons</title><link>http://arxiv.org/abs/2510.07284v1</link><description>Rubrics provide a flexible way to train LLMs on open-ended long-form answerswhere verifiable rewards are not applicable and human preferences providecoarse signals. Prior work shows that reinforcement learning with rubric-basedrewards leads to consistent gains in LLM post-training. Most existingapproaches rely on rubrics that remain static over the course of training. Suchstatic rubrics, however, are vulnerable to reward-hacking type behaviors andfail to capture emergent desiderata that arise during training. We introduceOnline Rubrics Elicitation (OnlineRubrics), a method that dynamically curatesevaluation criteria in an online manner through pairwise comparisons ofresponses from current and reference policies. This online process enablescontinuous identification and mitigation of errors as training proceeds.Empirically, this approach yields consistent improvements of up to 8% overtraining exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard aswell as the validation sets of expert questions and rubrics. We qualitativelyanalyze the elicited criteria and identify prominent themes such astransparency, practicality, organization, and reasoning.</description><author>MohammadHossein Rezaei, Robert Vacareanu, Zihao Wang, Clinton Wang, Yunzhong He, Afra Feyza AkyÃ¼rek</author><pubDate>Wed, 08 Oct 2025 17:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07284v1</guid></item><item><title>Speculative Decoding and Beyond: An In-Depth Survey of Techniques</title><link>http://arxiv.org/abs/2502.19732v4</link><description>Sequential dependencies present a fundamental bottleneck in deployinglarge-scale autoregressive models, particularly for real-time applications.While traditional optimization approaches like pruning and quantization oftencompromise model quality, recent advances in generation-refinement frameworksdemonstrate that this trade-off can be significantly mitigated. This survey presents a comprehensive taxonomy of generation-refinementframeworks, analyzing methods across autoregressive sequence tasks. Wecategorize methods based on their generation strategies (from simple n-gramprediction to sophisticated draft models) and refinement mechanisms (includingsingle-pass verification and iterative approaches). Through systematic analysisof both algorithmic innovations and system-level implementations, we examinedeployment strategies across computing environments and explore applicationsspanning text, images, and speech generation. This systematic examination ofboth theoretical frameworks and practical implementations provides a foundationfor future research in efficient autoregressive decoding.</description><author>Yunhai Hu, Zining Liu, Zhenyuan Dong, Tianfan Peng, Bradley McDanel, Sai Qian Zhang</author><pubDate>Wed, 08 Oct 2025 17:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.19732v4</guid></item><item><title>Empirical Comparison of Membership Inference Attacks in Deep Transfer Learning</title><link>http://arxiv.org/abs/2510.05753v2</link><description>With the emergence of powerful large-scale foundation models, the trainingparadigm is increasingly shifting from from-scratch training to transferlearning. This enables high utility training with small, domain-specificdatasets typical in sensitive applications. Membership inference attacks (MIAs)provide an empirical estimate of the privacy leakage by machine learningmodels. Yet, prior assessments of MIAs against models fine-tuned with transferlearning rely on a small subset of possible attacks. We address this bycomparing performance of diverse MIAs in transfer learning settings to helppractitioners identify the most efficient attacks for privacy risk evaluation.We find that attack efficacy decreases with the increase in training data forscore-based MIAs. We find that there is no one MIA which captures all privacyrisks in models trained with transfer learning. While the Likelihood RatioAttack (LiRA) demonstrates superior performance across most experimentalscenarios, the Inverse Hessian Attack (IHA) proves to be more effective againstmodels fine-tuned on PatchCamelyon dataset in high data regime.</description><author>Yuxuan Bai, Gauri Pradhan, Marlon Tobaben, Antti Honkela</author><pubDate>Wed, 08 Oct 2025 17:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.05753v2</guid></item><item><title>Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection</title><link>http://arxiv.org/abs/2510.07277v1</link><description>Diabetic Macular Edema (DME) is a leading cause of vision loss among patientswith Diabetic Retinopathy (DR). While deep learning has shown promising resultsfor automatically detecting this condition from fundus images, its applicationremains challenging due the limited availability of annotated data. FoundationModels (FM) have emerged as an alternative solution. However, it is unclear ifthey can cope with DME detection in particular. In this paper, wesystematically compare different FM and standard transfer learning approachesfor this task. Specifically, we compare the two most popular FM for retinalimages--RETFound and FLAIR--and an EfficientNet-B0 backbone, across differenttraining regimes and evaluation settings in IDRiD, MESSIDOR-2 andOCT-and-Eye-Fundus-Images (OEFI). Results show that despite their scale, FM donot consistently outperform fine-tuned CNNs in this task. In particular, anEfficientNet-B0 ranked first or second in terms of area under the ROC andprecision/recall curves in most evaluation settings, with RETFound only showingpromising results in OEFI. FLAIR, on the other hand, demonstrated competitivezero-shot performance, achieving notable AUC-PR scores when promptedappropriately. These findings reveal that FM might not be a good tool forfine-grained ophthalmic tasks such as DME detection even after fine-tuning,suggesting that lightweight CNNs remain strong baselines in data-scarceenvironments.</description><author>Franco Javier Arellano, JosÃ© Ignacio Orlando</author><pubDate>Wed, 08 Oct 2025 17:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07277v1</guid></item><item><title>Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences</title><link>http://arxiv.org/abs/2510.07276v1</link><description>Many real-world scenarios require multiple agents to coordinate in sharedenvironments, while balancing trade-offs between multiple, potentiallycompeting objectives. Current multi-objective multi-agent path finding(MO-MAPF) algorithms typically produce conflict-free plans by computing Paretofrontiers. They do not explicitly optimize for user-defined preferences, evenwhen the preferences are available, and scale poorly with the number ofobjectives. We propose a lexicographic framework for modeling MO-MAPF, alongwith an algorithm \textit{Lexicographic Conflict-Based Search} (LCBS) thatdirectly computes a single solution aligned with a lexicographic preferenceover objectives. LCBS integrates a priority-aware low-level $A^*$ search withconflict-based search, avoiding Pareto frontier construction and enablingefficient planning guided by preference over objectives. We provide insightsinto optimality and scalability, and empirically demonstrate that LCBS computesoptimal solutions while scaling to instances with up to ten objectives -- farbeyond the limits of existing MO-MAPF methods. Evaluations on standard andrandomized MAPF benchmarks show consistently higher success rates againststate-of-the-art baselines, especially with increasing number of objectives.</description><author>Pulkit Rustagi, Kyle Hollins Wray, Sandhya Saisubramanian</author><pubDate>Wed, 08 Oct 2025 17:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07276v1</guid></item><item><title>Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2505.21404v2</link><description>Natural-gradient methods markedly accelerate the training of Physics-InformedNeural Networks (PINNs), yet their Gauss--Newton update must be solved in theparameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ isthe number of network trainable weights. We show that exactly the same step caninstead be formulated in a generally smaller residual space of size $m =\sum_{\gamma} N_{\gamma} d_{\gamma}$, where each residual class $\gamma$ (e.g.PDE interior, boundary, initial data) contributes $N_{\gamma}$ collocationpoints of output dimension $d_{\gamma}$. Building on this insight, we introduce \textit{Dual Natural Gradient Descent}(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments itwith a geodesic-acceleration correction at negligible extra cost, and providesboth a dense direct solver for modest $m$ and a Nystrom-preconditionedconjugate-gradient solver for larger $m$. Experimentally, D-NGD scales second-order PINN optimization to networks withup to 12.8 million parameters, delivers one- to three-order-of-magnitude lowerfinal error $L^2$ than first-order methods (Adam, SGD) and quasi-Newtonmethods, and -- crucially -- enables natural-gradient training of PINNs at thisscale on a single GPU.</description><author>Anas Jnini, Flavio Vella</author><pubDate>Wed, 08 Oct 2025 17:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.21404v2</guid></item><item><title>MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search</title><link>http://arxiv.org/abs/2503.20757v2</link><description>We introduce MCTS-RAG, a novel approach that enhances the reasoningcapabilities of small language models on knowledge-intensive tasks byleveraging retrieval-augmented generation (RAG) to provide relevant context andMonte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamicallyintegrates retrieval and reasoning through an iterative decision-makingprocess. Unlike standard RAG methods, which typically retrieve informationindependently from reasoning and thus integrate knowledge suboptimally, orconventional MCTS reasoning, which depends solely on internal model knowledgewithout external facts, MCTS-RAG combines structured reasoning with adaptiveretrieval. This integrated approach enhances decision-making, reduceshallucinations, and ensures improved factual accuracy and response consistency.The experimental results on multiple reasoning and knowledge-intensive datasetsdatasets (i.e., ComplexWebQA, GPQA, and FoolMeTwice) show that our methodenables small-scale LMs to achieve performance comparable to frontier LLMs likeGPT-4o by effectively scaling inference-time compute, setting a new standardfor reasoning in small-scale models.</description><author>Yunhai Hu, Yilun Zhao, Chen Zhao, Arman Cohan</author><pubDate>Wed, 08 Oct 2025 17:36:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.20757v2</guid></item><item><title>On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]</title><link>http://arxiv.org/abs/2510.07268v1</link><description>This short essay is a reworking of the answers offered by the author at theDebate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized byMarta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater(OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC),Eulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025.Albert Sabater posed three questions: (1) How can regulatory frameworkspriori-tise the protection of fundamental rights (privacy, non-discrimination,autonomy, etc.) in the development of AI, without falling into the falsedichotomy between regulation and innova-tion? (2) Given the risks of AI (bias,mass surveillance, manipulation), what examples of regu-lations or policieshave demonstrated that it is possible to foster responsible innovation, puttingthe public interest before profitability, without giving in to competitivepressure from actors such as China or the US? (3) In a scenario where the USprioritizes flexibility, what mecha-nisms could ensure that internationalcooperation in AI does not become a race to the bottom in rights, but rather aglobal standard of accountability? The article attempts to answer these threequestions and concludes with some reflections on the relevance of the answersfor education and research.</description><author>Pompeu Casanovas</author><pubDate>Wed, 08 Oct 2025 17:33:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07268v1</guid></item><item><title>ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects</title><link>http://arxiv.org/abs/2508.16185v2</link><description>Large language models have been widely evaluated on tasks such ascomprehension, summarization, code generation, etc. However, their performanceon graduate-level, culturally grounded questions in the Indian context remainslargely unexplored. Existing Indian benchmarks emphasise basic fact-orientatedqueries that offer limited assessment of a deeper disciplinary understandingtailored to the Indian setting. In this paper, we present ParamBench,consisting of more than 17K questions in the Hindi language, comprisingquestionnaires from 21 diverse subjects. These questions are primarily derivedfrom a nationwide graduate-level entrance examination covering topics such ashistory, music, instruments, yoga, literature, philosophy, law, etc.~specifically for the Indian context. Additionally, we assess the ability ofLLMs to handle diverse question formats - such as list-based matching,assertion-reason pairs, and sequence ordering - alongside conventionalmultiple-choice questions. We evaluated the performance of more than 16 opensource LLMs on this benchmark, observing that Gemma3-27B attains the highestoverall accuracy of 56.4\%. Furthermore, subject-wise analysis indicates thateven for the best-performing LLMs, performance remains weak on topics such asmusic, classical instruments, and law, underscoring persistent challenges inculturally grounded reasoning. The dataset and source code is present athttps://github.com/ayushbits/ParamBench.</description><author>Ayush Maheshwari, Kaushal Sharma, Vivek Patel, Aditya Maheshwari</author><pubDate>Wed, 08 Oct 2025 17:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.16185v2</guid></item><item><title>Dynamic Regret Bounds for Online Omniprediction with Long Term Constraints</title><link>http://arxiv.org/abs/2510.07266v1</link><description>We present an algorithm guaranteeing dynamic regret bounds for onlineomniprediction with long term constraints. The goal in this recently introducedproblem is for a learner to generate a sequence of predictions which arebroadcast to a collection of downstream decision makers. Each decision makerhas their own utility function, as well as a vector of constraint functions,each mapping their actions and an adversarially selected state to reward orconstraint violation terms. The downstream decision makers select actions "asif" the state predictions are correct, and the goal of the learner is toproduce predictions such that all downstream decision makers choose actionsthat give them worst-case utility guarantees while minimizing worst-caseconstraint violation. Within this framework, we give the first algorithm thatobtains simultaneous \emph{dynamic regret} guarantees for all of the agents --where regret for each agent is measured against a potentially changing sequenceof actions across rounds of interaction, while also ensuring vanishingconstraint violation for each agent. Our results do not require the agentsthemselves to maintain any state -- they only solve one-round constrainedoptimization problems defined by the prediction made at that round.</description><author>Yahav Bechavod, Jiuyao Lu, Aaron Roth</author><pubDate>Wed, 08 Oct 2025 17:28:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07266v1</guid></item><item><title>LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning</title><link>http://arxiv.org/abs/2306.10354v2</link><description>Our winning entry for the CVPR 2023 Generic Event Boundary Captioning (GEBC)competition is detailed in this paper. Unlike conventional video captioningtasks, GEBC demands that the captioning model possess an understanding ofimmediate changes in status around the designated video boundary, making it adifficult task. This paper proposes an effective model LLMVA-GEBC (LargeLanguage Model with Video Adapter for Generic Event Boundary Captioning): (1)We utilize a pretrained LLM for generating human-like captions with highquality. (2) To adapt the model to the GEBC task, we take the video Q-former asan adapter and train it with the frozen visual feature extractors and LLM. Ourproposed method achieved a 76.14 score on the test set and won the first placein the challenge. Our code is available athttps://github.com/zjr2000/LLMVA-GEBC .</description><author>Yolo Yunlong Tang, Jinrui Zhang, Xiangchen Wang, Teng Wang, Feng Zheng</author><pubDate>Wed, 08 Oct 2025 17:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10354v2</guid></item><item><title>LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad</title><link>http://arxiv.org/abs/2307.04827v3</link><description>Launchpad is a musical instrument that allows users to create and performmusic by pressing illuminated buttons. To assist and inspire the design of theLaunchpad light effect, and provide a more accessible approach for beginners tocreate music visualization with this instrument, we proposed the LaunchpadGPTmodel to generate music visualization designs on Launchpad automatically. Basedon the language model with excellent generation ability, our proposedLaunchpadGPT takes an audio piece of music as input and outputs the lightingeffects of Launchpad-playing in the form of a video (Launchpad-playing video).We collect Launchpad-playing videos and process them to obtain music andcorresponding video frame of Launchpad-playing as prompt-completion pairs, totrain the language model. The experiment result shows the proposed method cancreate better music visualization than random generation methods and hold thepotential for a broader range of music visualization applications. Our code isavailable at https://github.com/yunlong10/LaunchpadGPT/.</description><author>Siting Xu, Yolo Yunlong Tang, Feng Zheng</author><pubDate>Wed, 08 Oct 2025 17:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04827v3</guid></item><item><title>V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning</title><link>http://arxiv.org/abs/2404.12353v3</link><description>Video summarization aims to create short, accurate, and cohesive summaries oflonger videos. Despite the existence of various video summarization datasets, anotable limitation is their limited amount of source videos, which hampers theeffective training of advanced large vision-language models (VLMs).Additionally, most existing datasets are created for video-to-videosummarization, overlooking the contemporary need for multimodal video contentsummarization. Recent efforts have been made to expand from unimodal tomultimodal video summarization, categorizing the task into three sub-tasksbased on the summary's modality: video-to-video (V2V), video-to-text (V2T), anda combination of video and text summarization (V2VT). However, the textualsummaries in previous multimodal datasets are inadequate. To address theseissues, we introduce Instruct-V2Xum, a cross-modal video summarization datasetfeaturing 30,000 diverse videos sourced from YouTube, with lengths ranging from40 to 940 seconds and an average summarization ratio of 16.39%. Each videosummary in Instruct-V2Xum is paired with a textual summary that referencesspecific frame indexes, facilitating the generation of aligned video andtextual summaries. In addition, we propose a new video summarization frameworknamed V2Xum-LLM. V2Xum-LLM, specifically V2Xum-LLaMA in this study, is thefirst framework that unifies different video summarization tasks into one largelanguage model's (LLM) text decoder and achieves task-controllable videosummarization with temporal prompts and task instructions. Experiments showthat V2Xum-LLaMA outperforms strong baseline models on multiple videosummarization tasks. Furthermore, we propose an enhanced evaluation metric forV2V and V2VT summarization tasks.</description><author>Hang Hua, Yolo Yunlong Tang, Chenliang Xu, Jiebo Luo</author><pubDate>Wed, 08 Oct 2025 17:22:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12353v3</guid></item><item><title>Test-Time Graph Search for Goal-Conditioned Reinforcement Learning</title><link>http://arxiv.org/abs/2510.07257v1</link><description>Offline goal-conditioned reinforcement learning (GCRL) trains policies thatreach user-specified goals at test time, providing a simple, unsupervised,domain-agnostic way to extract diverse behaviors from unlabeled, reward-freedatasets. Nonetheless, long-horizon decision making remains difficult for GCRLagents due to temporal credit assignment and error accumulation, and theoffline setting amplifies these effects. To alleviate this issue, we introduceTest-Time Graph Search (TTGS), a lightweight planning approach to solve theGCRL task. TTGS accepts any state-space distance or cost signal, builds aweighted graph over dataset states, and performs fast search to assemble asequence of subgoals that a frozen policy executes. When the base learner isvalue-based, the distance is derived directly from the learned goal-conditionedvalue function, so no handcrafted metric is needed. TTGS requires no changes totraining, no additional supervision, no online interaction, and no privilegedinformation, and it runs entirely at inference. On the OGBench benchmark, TTGSimproves success rates of multiple base learners on challenging locomotiontasks, demonstrating the benefit of simple metric-guided test-time planning foroffline GCRL.</description><author>Evgenii Opryshko, Junwei Quan, Claas Voelcker, Yilun Du, Igor Gilitschenski</author><pubDate>Wed, 08 Oct 2025 17:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07257v1</guid></item><item><title>Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding</title><link>http://arxiv.org/abs/2403.16276v3</link><description>Large language models (LLMs) have demonstrated remarkable capabilities innatural language and multimodal domains. By fine-tuning multimodal LLMs withtemporal annotations from well-annotated datasets, e.g., dense video captioningdatasets, their temporal understanding capacity in video-language tasks can beobtained. However, there is a notable lack of untrimmed audio-visual videodatasets with precise temporal annotations for events. This deficiency hindersLLMs from learning the alignment between time, audio-visual events, and texttokens, thus impairing their ability to temporally localize audio-visual eventsin videos. To address this gap, we introduce PU-VALOR, a comprehensiveaudio-visual dataset comprising over 114,000 pseudo-untrimmed videos withdetailed temporal annotations. PU-VALOR is derived from the large-scale butcoarse-annotated audio-visual dataset VALOR, through a subtle method involvingevent-based video clustering, random temporal scaling, and permutation. Byfine-tuning a multimodal LLM on PU-VALOR, we developed AVicuna, a model capableof aligning audio-visual events with temporal intervals and corresponding texttokens. AVicuna excels in temporal localization and time-aware dialoguecapabilities. Our experiments demonstrate that AVicuna effectively handlestemporal understanding in audio-visual videos and achieves state-of-the-artperformance on open-ended video QA, audio-visual QA, and audio-visual eventdense localization tasks.</description><author>Yolo Yunlong Tang, Daiki Shimada, Jing Bi, Mingqian Feng, Hang Hua, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 17:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16276v3</guid></item><item><title>Efficient reductions from a Gaussian source with applications to statistical-computational tradeoffs</title><link>http://arxiv.org/abs/2510.07250v1</link><description>Given a single observation from a Gaussian distribution with unknown mean$\theta$, we design computationally efficient procedures that can approximatelygenerate an observation from a different target distribution $Q_{\theta}$uniformly for all $\theta$ in a parameter set. We leverage our technique toestablish reduction-based computational lower bounds for several canonicalhigh-dimensional statistical models under widely-believed conjectures inaverage-case complexity. In particular, we cover cases in which: 1. $Q_{\theta}$ is a general location model with non-Gaussian distribution,including both light-tailed examples (e.g., generalized normal distributions)and heavy-tailed ones (e.g., Student's $t$-distributions). As a consequence, weshow that computational lower bounds proved for spiked tensor PCA with Gaussiannoise are universal, in that they extend to other non-Gaussian noisedistributions within our class. 2. $Q_{\theta}$ is a normal distribution with mean $f(\theta)$ for a general,smooth, and nonlinear link function $f:\mathbb{R} \rightarrow \mathbb{R}$.Using this reduction, we construct a reduction from symmetric mixtures oflinear regressions to generalized linear models with link function $f$, andestablish computational lower bounds for solving the $k$-sparse generalizedlinear model when $f$ is an even function. This result constitutes the firstreduction-based confirmation of a $k$-to-$k^2$ statistical-to-computational gapin $k$-sparse phase retrieval, resolving a conjecture posed by Cai et al.(2016). As a second application, we construct a reduction from the sparserank-1 submatrix model to the planted submatrix model, establishing a pointwisecorrespondence between the phase diagrams of the two models that faithfullypreserves regions of computational hardness and tractability.</description><author>Mengqi Lou, Guy Bresler, Ashwin Pananjady</author><pubDate>Wed, 08 Oct 2025 17:16:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07250v1</guid></item><item><title>TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation</title><link>http://arxiv.org/abs/2510.07249v1</link><description>In this work, we present TalkCuts, a large-scale dataset designed tofacilitate the study of multi-shot human speech video generation. Unlikeexisting datasets that focus on single-shot, static viewpoints, TalkCuts offers164k clips totaling over 500 hours of high-quality human speech videos withdiverse camera shots, including close-up, half-body, and full-body views. Thedataset includes detailed textual descriptions, 2D keypoints and 3D SMPL-Xmotion annotations, covering over 10k identities, enabling multimodal learningand evaluation. As a first attempt to showcase the value of the dataset, wepresent Orator, an LLM-guided multi-modal generation framework as a simplebaseline, where the language model functions as a multi-faceted director,orchestrating detailed specifications for camera transitions, speakergesticulations, and vocal modulation. This architecture enables the synthesisof coherent long-form videos through our integrated multi-modal videogeneration module. Extensive experiments in both pose-guided and audio-drivensettings show that training on TalkCuts significantly enhances thecinematographic coherence and visual appeal of generated multi-shot speechvideos. We believe TalkCuts provides a strong foundation for future work incontrollable, multi-shot speech video generation and broader multimodallearning.</description><author>Jiaben Chen, Zixin Wang, Ailing Zeng, Yang Fu, Xueyang Yu, Siyuan Cen, Julian Tanke, Yihang Chen, Koichi Saito, Yuki Mitsufuji, Chuang Gan</author><pubDate>Wed, 08 Oct 2025 17:16:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07249v1</guid></item><item><title>Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the Models</title><link>http://arxiv.org/abs/2510.07248v1</link><description>Small language models (SLMs) offer significant computational advantages fortool-augmented AI systems, yet they struggle with tool-use tasks, particularlyin selecting appropriate tools and identifying correct parameters. A commonfailure mode is schema misalignment: models hallucinate plausible butnon-existent tool names that reflect naming conventions internalized duringpretraining but absent from the provided tool schema. Rather than forcingmodels to adapt to arbitrary schemas, we propose adapting schemas to align withmodels' pretrained knowledge. We introduce PA-Tool (Pretraining-Aligned ToolSchema Generation), a training-free method that leverages peakedness-a signalfrom contamination detection indicating pretraining familiarity-toautomatically rename tool components. By generating multiple candidates andselecting those with highest output concentration across samples, PA-Toolidentifies pretrain-aligned naming patterns. Experiments on MetaTool andRoTBench show improvements of up to 17% points, with schema misalignment errorsreduced by 80%. PA-Tool enables small models to approach state-of-the-artperformance while maintaining computational efficiency for adaptation to newtools without retraining. Our work demonstrates that schema-level interventionscan unlock the tool-use potential of resource-efficient models by adaptingschemas to models rather than models to schemas.</description><author>Jonggeun Lee, Woojung Song, Jongwook Han, Haesung Pyun, Yohan Jo</author><pubDate>Wed, 08 Oct 2025 17:16:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07248v1</guid></item><item><title>CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for Saliency Prediction with Diffusion</title><link>http://arxiv.org/abs/2408.12009v2</link><description>Video saliency prediction aims to identify the regions in a video thatattract human attention and gaze, driven by bottom-up features from the videoand top-down processes like memory and cognition. Among these top-downinfluences, language plays a crucial role in guiding attention by shaping howvisual information is interpreted. Existing methods primarily focus on modelingperceptual information while neglecting the reasoning process facilitated bylanguage, where ranking cues are crucial outcomes of this process and practicalguidance for saliency prediction. In this paper, we propose CaRDiff (Caption,Rank, and generate with Diffusion), a framework that imitates the process byintegrating a multimodal large language model (MLLM), a grounding module, and adiffusion model, to enhance video saliency prediction. Specifically, weintroduce a novel prompting method VSOR-CoT (Video Salient Object Ranking Chainof Thought), which utilizes an MLLM with a grounding module to caption videocontent and infer salient objects along with their rankings and positions. Thisprocess derives ranking maps that can be sufficiently leveraged by thediffusion model to decode the saliency maps for the given video accurately.Extensive experiments show the effectiveness of VSOR-CoT in improving theperformance of video saliency prediction. The proposed CaRDiff performs betterthan state-of-the-art models on the MVS dataset and demonstrates cross-datasetcapabilities on the DHF1k dataset through zero-shot evaluation.</description><author>Yolo Yunlong Tang, Gen Zhan, Li Yang, Yiting Liao, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 17:14:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12009v2</guid></item><item><title>Discriminative Feature Feedback with General Teacher Classes</title><link>http://arxiv.org/abs/2510.07245v1</link><description>We study the theoretical properties of the interactive learning protocolDiscriminative Feature Feedback (DFF) (Dasgupta et al., 2018). The DFF learningprotocol uses feedback in the form of discriminative feature explanations. Weprovide the first systematic study of DFF in a general framework that iscomparable to that of classical protocols such as supervised learning andonline learning. We study the optimal mistake bound of DFF in the realizableand the non-realizable settings, and obtain novel structural results, as wellas insights into the differences between Online Learning and settings withricher feedback such as DFF. We characterize the mistake bound in therealizable setting using a new notion of dimension. In the non-realizablesetting, we provide a mistake upper bound and show that it cannot be improvedin general. Our results show that unlike Online Learning, in DFF the realizabledimension is insufficient to characterize the optimal non-realizable mistakebound or the existence of no-regret algorithms.</description><author>Omri Bar Oz, Tosca Lechner, Sivan Sabato</author><pubDate>Wed, 08 Oct 2025 17:14:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07245v1</guid></item><item><title>Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics</title><link>http://arxiv.org/abs/2402.09225v4</link><description>This article introduces the Membership Inference Test (MINT), a novelapproach that aims to empirically assess if given data was used during thetraining of AI/ML models. Specifically, we propose two MINT architecturesdesigned to learn the distinct activation patterns that emerge when an AuditedModel is exposed to data used during its training process. These architecturesare based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks(CNNs). The experimental framework focuses on the challenging task of FaceRecognition, considering three state-of-the-art Face Recognition systems.Experiments are carried out using six publicly available databases, comprisingover 22 million face images in total. Different experimental scenarios areconsidered depending on the context of the AI model to test. Our proposed MINTapproach achieves promising results, with up to 90\% accuracy, indicating thepotential to recognize if an AI model has been trained with specific data. Theproposed MINT approach can serve to enforce privacy and fairness in several AIapplications, e.g., revealing if sensitive or private data was used fortraining or tuning Large Language Models (LLMs).</description><author>Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Javier Ortega-Garcia</author><pubDate>Wed, 08 Oct 2025 17:12:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09225v4</guid></item><item><title>VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?</title><link>http://arxiv.org/abs/2411.10979v4</link><description>The advancement of Multimodal Large Language Models (MLLMs) has enabledsignificant progress in multimodal understanding, expanding their capacity toanalyze video content. However, existing evaluation benchmarks for MLLMsprimarily focus on abstract video comprehension, lacking a detailed assessmentof their ability to understand video compositions, the nuanced interpretationof how visual elements combine and interact within highly compiled videocontexts. We introduce VidComposition, a new benchmark specifically designed toevaluate the video composition understanding capabilities of MLLMs usingcarefully curated compiled videos and cinematic-level annotations.VidComposition includes 982 videos with 1706 multiple-choice questions,covering various compositional aspects such as camera movement, angle, shotsize, narrative structure, character actions and emotions, etc. Ourcomprehensive evaluation of 33 open-source and proprietary MLLMs reveals asignificant performance gap between human and model capabilities. Thishighlights the limitations of current MLLMs in understanding complex, compiledvideo compositions and offers insights into areas for further improvement. Theleaderboard and evaluation code are available athttps://yunlong10.github.io/VidComposition/.</description><author>Yolo Yunlong Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang, Jing Bi, Zeliang Zhang, Pooyan Fazli, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 17:12:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10979v4</guid></item><item><title>LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation</title><link>http://arxiv.org/abs/2510.07243v1</link><description>Evaluating large language model (LLM) outputs in the legal domain presentsunique challenges due to the complex and nuanced nature of legal analysis.Current evaluation approaches either depend on reference data, which is costlyto produce, or use standardized assessment methods, both of which havesignificant limitations for legal applications. Although LLM-as-a-Judge has emerged as a promising evaluation technique, itsreliability and effectiveness in legal contexts depend heavily on evaluationprocesses unique to the legal industry and how trustworthy the evaluationappears to the human legal expert. This is where existing evaluation methodscurrently fail and exhibit considerable variability. This paper aims to close the gap: a) we break down lengthy responses into'Legal Data Points' (LDPs), self-contained units of information, and introducea novel, reference-free evaluation methodology that reflects how lawyersevaluate legal answers; b) we demonstrate that our method outperforms a varietyof baselines on both our proprietary dataset and an open-source dataset(LegalBench); c) we show how our method correlates more closely with humanexpert evaluations and helps improve inter-annotator agreement; and finally d)we open source our Legal Data Points for a subset of LegalBench used in ourexperiments, allowing the research community to replicate our results andadvance research in this vital area of LLM evaluation on legalquestion-answering.</description><author>Joseph Enguehard, Morgane Van Ermengem, Kate Atkinson, Sujeong Cha, Arijit Ghosh Chowdhury, Prashanth Kallur Ramaswamy, Jeremy Roghair, Hannah R Marlowe, Carina Suzana Negreanu, Kitty Boxall, Diana Mincu</author><pubDate>Wed, 08 Oct 2025 17:10:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07243v1</guid></item><item><title>Lossy Neural Compression for Geospatial Analytics: A Review</title><link>http://arxiv.org/abs/2503.01505v2</link><description>Over the past decades, there has been an explosion in the amount of availableEarth Observation (EO) data. The unprecedented coverage of the Earth's surfaceand atmosphere by satellite imagery has resulted in large volumes of data thatmust be transmitted to ground stations, stored in data centers, and distributedto end users. Modern Earth System Models (ESMs) face similar challenges,operating at high spatial and temporal resolutions, producing petabytes of dataper simulated day. Data compression has gained relevance over the past decade,with neural compression (NC) emerging from deep learning and informationtheory, making EO data and ESM outputs ideal candidates due to their abundanceof unlabeled data. In this review, we outline recent developments in NC appliedto geospatial data. We introduce the fundamental concepts of NC includingseminal works in its traditional applications to image and video compressiondomains with focus on lossy compression. We discuss the unique characteristicsof EO and ESM data, contrasting them with "natural images", and explain theadditional challenges and opportunities they present. Moreover, we reviewcurrent applications of NC across various EO modalities and explore the limitedefforts in ESM compression to date. The advent of self-supervised learning(SSL) and foundation models (FM) has advanced methods to efficiently distillrepresentations from vast unlabeled data. We connect these developments to NCfor EO, highlighting the similarities between the two fields and elaborate onthe potential of transferring compressed feature representations formachine--to--machine communication. Based on insights drawn from this review,we devise future directions relevant to applications in EO and ESM.</description><author>Carlos Gomes, Isabelle Wittmann, Damien Robert, Johannes Jakubik, Tim Reichelt, Michele Martone, Stefano Maurogiovanni, Rikard Vinge, Jonas Hurst, Erik Scheurer, Rocco Sedona, Thomas Brunschwiler, Stefan Kesselheim, Matej Batic, Philip Stier, Jan Dirk Wegner, Gabriele Cavallaro, Edzer Pebesma, Michael Marszalek, Miguel A Belenguer-Plomer, Kennedy Adriko, Paolo Fraccaro, Romeo Kienzler, Rania Briq, Sabrina Benassou, Michele Lazzarini, Conrad M Albrecht</author><pubDate>Wed, 08 Oct 2025 17:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2503.01505v2</guid></item><item><title>Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense</title><link>http://arxiv.org/abs/2510.07242v1</link><description>Post-training for reasoning of large language models (LLMs) increasinglyrelies on verifiable rewards: deterministic checkers that provide 0-1correctness signals. While reliable, such binary feedback is brittle--manytasks admit partially correct or alternative answers that verifiersunder-credit, and the resulting all-or-nothing supervision limits learning.Reward models offer richer, continuous feedback, which can serve as acomplementary supervisory signal to verifiers. We introduce HERO (HybridEnsemble Reward Optimization), a reinforcement learning framework thatintegrates verifier signals with reward-model scores in a structured way. HEROemploys stratified normalization to bound reward-model scores withinverifier-defined groups, preserving correctness while refining qualitydistinctions, and variance-aware weighting to emphasize challenging promptswhere dense signals matter most. Across diverse mathematical reasoningbenchmarks, HERO consistently outperforms RM-only and verifier-only baselines,with strong gains on both verifiable and hard-to-verify tasks. Our results showthat hybrid reward design retains the stability of verifiers while leveragingthe nuance of reward models to advance reasoning.</description><author>Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu</author><pubDate>Wed, 08 Oct 2025 17:09:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07242v1</guid></item><item><title>AutoMind: Adaptive Knowledgeable Agent for Automated Data Science</title><link>http://arxiv.org/abs/2506.10974v3</link><description>Large Language Model (LLM) agents have shown great potential in addressingreal-world data science problems. LLM-driven data science agents promise toautomate the entire machine learning pipeline, yet their real-worldeffectiveness remains limited. Existing frameworks depend on rigid, pre-definedworkflows and inflexible coding strategies; consequently, they excel only onrelatively simple, classical problems and fail to capture the empiricalexpertise that human practitioners bring to complex, innovative tasks. In thiswork, we introduce AutoMind, an adaptive, knowledgeable LLM-agent frameworkthat overcomes these deficiencies through three key advances: (1) a curatedexpert knowledge base that grounds the agent in domain expert knowledge, (2) anagentic knowledgeable tree search algorithm that strategically explorespossible solutions, and (3) a self-adaptive coding strategy that dynamicallytailors code generation to task complexity. Evaluations on two automated datascience benchmarks demonstrate that AutoMind delivers superior performanceversus state-of-the-art baselines. Additional analyses confirm favorableeffectiveness, efficiency, and qualitative solution quality, highlightingAutoMind as an efficient and robust step toward fully automated data science.Code is at https://github.com/innovatingAI/AutoMind.</description><author>Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Zhuoyun Yu, Shuofei Qiao, Jintian Zhang, Da Zheng, Yuren Mao, Yunjun Gao, Huajun Chen, Ningyu Zhang</author><pubDate>Wed, 08 Oct 2025 17:06:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.10974v3</guid></item><item><title>Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts</title><link>http://arxiv.org/abs/2510.07239v1</link><description>Automated red-teaming has emerged as a scalable approach for auditing LargeLanguage Models (LLMs) prior to deployment, yet existing approaches lackmechanisms to efficiently adapt to model-specific vulnerabilities at inference.We introduce Red-Bandit, a red-teaming framework that adapts online to identifyand exploit model failure modes under distinct attack styles (e.g.,manipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRAexperts, each specialized for a particular attack style, using reinforcementlearning that rewards the generation of unsafe prompts via a rule-based safetymodel. At inference, a multi-armed bandit policy dynamically selects amongthese attack-style experts based on the target model's response safety,balancing exploration and exploitation. Red-Bandit achieves state-of-the-artresults on AdvBench under sufficient exploration (ASR@10), while producing morehuman-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policyserves as a diagnostic tool for uncovering model-specific vulnerabilities byindicating which attack styles most effectively elicit unsafe behaviors.</description><author>Christos Ziakas, Nicholas Loo, Nishita Jain, Alessandra Russo</author><pubDate>Wed, 08 Oct 2025 17:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07239v1</guid></item><item><title>When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation</title><link>http://arxiv.org/abs/2510.07238v1</link><description>The rapid evolution of large language models (LLMs) and the real world hasoutpaced the static nature of widely used evaluation benchmarks, raisingconcerns about their reliability for evaluating LLM factuality. Whilesubstantial works continue to rely on the popular but old benchmarks, theirtemporal misalignment with real-world facts and modern LLMs, and their effectson LLM factuality evaluation remain underexplored. Therefore, in this work, wepresent a systematic investigation of this issue by examining five popularfactuality benchmarks and eight LLMs released across different years. Anup-to-date fact retrieval pipeline and three metrics are tailored to quantifybenchmark aging and its impact on LLM factuality evaluation. Experimentalresults and analysis illustrate that a considerable portion of samples in thewidely used factuality benchmarks are outdated, leading to unreliableassessments of LLM factuality. We hope our work can provide a testbed to assessthe reliability of a benchmark for LLM factuality evaluation and inspire moreresearch on the benchmark aging issue. Codes are available inhttps://github.com/JiangXunyi/BenchAge.</description><author>Xunyi Jiang, Dingyi Chang, Julian McAuley, Xin Xu</author><pubDate>Wed, 08 Oct 2025 17:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07238v1</guid></item><item><title>LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document Understanding</title><link>http://arxiv.org/abs/2510.07233v1</link><description>Question answering over visually rich documents (VRDs) requires reasoning notonly over isolated content but also over documents' structural organization andcross-page dependencies. However, conventional retrieval-augmented generation(RAG) methods encode content in isolated chunks during ingestion, losingstructural and cross-page dependencies, and retrieve a fixed number of pages atinference, regardless of the specific demands of the question or context. Thisoften results in incomplete evidence retrieval and degraded answer quality formulti-page reasoning tasks. To address these limitations, we propose LAD-RAG, anovel Layout-Aware Dynamic RAG framework. During ingestion, LAD-RAG constructsa symbolic document graph that captures layout structure and cross-pagedependencies, adding it alongside standard neural embeddings to yield a moreholistic representation of the document. During inference, an LLM agentdynamically interacts with the neural and symbolic indices to adaptivelyretrieve the necessary evidence based on the query. Experiments onMMLongBench-Doc, LongDocURL, DUDE, and MP-DocVQA demonstrate that LAD-RAGimproves retrieval, achieving over 90% perfect recall on average without anytop-k tuning, and outperforming baseline retrievers by up to 20% in recall atcomparable noise levels, yielding higher QA accuracy with minimal latency.</description><author>Zhivar Sourati, Zheng Wang, Marianne Menglin Liu, Yazhe Hu, Mengqing Guo, Sujeeth Bharadwaj, Kyu Han, Tao Sheng, Sujith Ravi, Morteza Dehghani, Dan Roth</author><pubDate>Wed, 08 Oct 2025 17:02:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07233v1</guid></item><item><title>Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships</title><link>http://arxiv.org/abs/2510.07231v1</link><description>Causal reasoning is fundamental for Large Language Models (LLMs) tounderstand genuine cause-and-effect relationships beyond pattern matching.Existing benchmarks suffer from critical limitations such as reliance onsynthetic data and narrow domain coverage. We introduce a novel benchmarkconstructed from casually identified relationships extracted from top-tiereconomics and finance journals, drawing on rigorous methodologies includinginstrumental variables, difference-in-differences, and regression discontinuitydesigns. Our benchmark comprises 40,379 evaluation items covering five tasktypes across domains such as health, environment, technology, law, and culture.Experimental results on eight state-of-the-art LLMs reveal substantiallimitations, with the best model achieving only 57.6\% accuracy. Moreover,model scale does not consistently translate to superior performance, and evenadvanced reasoning models struggle with fundamental causal relationshipidentification. These findings underscore a critical gap between current LLMcapabilities and demands of reliable causal reasoning in high-stakesapplications.</description><author>Donggyu Lee, Sungwon Park, Yerin Hwang, Hyunwoo Oh, Hyoshin Kim, Jungwon Kim, Meeyoung Cha, Sangyoon Park, Jihee Kim</author><pubDate>Wed, 08 Oct 2025 17:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07231v1</guid></item><item><title>Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM Agent in Online Shopping</title><link>http://arxiv.org/abs/2510.07230v1</link><description>Simulating step-wise human behavior with Large Language Models (LLMs) hasbecome an emerging research direction, enabling applications in variouspractical domains. While prior methods, including prompting, supervisedfine-tuning (SFT), and reinforcement learning (RL), have shown promise inmodeling step-wise behavior, they primarily learn a population-level policywithout conditioning on a user's persona, yielding generic rather thanpersonalized simulations. In this work, we pose a critical question: how canLLM agents better simulate personalized user behavior? We introduceCustomer-R1, an RL-based method for personalized, step-wise user behaviorsimulation in online shopping environments. Our policy is conditioned on anexplicit persona, and we optimize next-step rationale and action generation viaaction correctness reward signals. Experiments on the OPeRA dataset emonstratethat Customer-R1 not only significantly outperforms prompting and SFT-basedbaselines in next-action prediction tasks, but also better matches users'action distribution, indicating higher fidelity in personalized behaviorsimulation.</description><author>Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Dakuo Wang</author><pubDate>Wed, 08 Oct 2025 17:00:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07230v1</guid></item><item><title>Prefilled responses enhance zero-shot detection of AI-generated images</title><link>http://arxiv.org/abs/2506.11031v3</link><description>As AI models generate increasingly realistic images, growing concerns overpotential misuse underscore the need for reliable detection. Traditionalsupervised detection methods depend on large, curated datasets for training andoften fail to generalize to novel, out-of-domain image generators. As analternative, we explore pre-trained Vision-Language Models (VLMs) for zero-shotdetection of AI-generated images. We evaluate VLM performance on three diversebenchmarks encompassing synthetic images of human faces, objects, and animalsproduced by 16 different state-of-the-art image generators. While off-the-shelfVLMs perform poorly on these datasets, we find that their reasoning can beguided effectively through simple response prefilling -- a method we callPrefill-Guided Thinking (PGT). In particular, prefilling a VLM response withthe task-aligned phrase "Let's examine the style and the synthesis artifacts"improves the Macro F1 scores of three widely used open-source VLMs by up to24%.</description><author>Zoher Kachwala, Danishjeet Singh, Danielle Yang, Filippo Menczer</author><pubDate>Wed, 08 Oct 2025 16:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.11031v3</guid></item><item><title>MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness</title><link>http://arxiv.org/abs/2505.20426v2</link><description>Understanding perspective is fundamental to human visual perception, yet theextent to which multimodal large language models (MLLMs) internalizeperspective geometry remains unclear. We introduce MMPerspective, the firstbenchmark specifically designed to systematically evaluate MLLMs' understandingof perspective through 10 carefully crafted tasks across three complementarydimensions: Perspective Perception, Reasoning, and Robustness. Our benchmarkcomprises 2,711 real-world and synthetic image instances with 5,083question-answer pairs that probe key capabilities, such as vanishing pointperception and counting, perspective type reasoning, line relationshipunderstanding in 3D space, invariance to perspective-preservingtransformations, etc. Through a comprehensive evaluation of 43 state-of-the-artMLLMs, we uncover significant limitations: while models demonstrate competenceon surface-level perceptual tasks, they struggle with compositional reasoningand maintaining spatial consistency under perturbations. Our analysis furtherreveals intriguing patterns between model architecture, scale, and perspectivecapabilities, highlighting both robustness bottlenecks and the benefits ofchain-of-thought prompting. MMPerspective establishes a valuable testbed fordiagnosing and advancing spatial understanding in vision-language systems.Resources available at: https://yunlong10.github.io/MMPerspective/</description><author>Yolo Yunlong Tang, Pinxin Liu, Mingqian Feng, Zhangyun Tan, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao, Susan Liang, Hang Hua, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 16:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.20426v2</guid></item><item><title>Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation</title><link>http://arxiv.org/abs/2510.07227v1</link><description>Small Language models (SLMs) offer an efficient and accessible alternative toLarge Language Models (LLMs), delivering strong performance while using farfewer resources. We introduce a simple and effective framework for pretrainingSLMs that brings together three complementary ideas. First, we identifystructurally sparse sub-network initializations that consistently outperformrandomly initialized models of similar size under the same compute budget.Second, we use evolutionary search to automatically discover high-qualitysub-network initializations, providing better starting points for pretraining.Third, we apply knowledge distillation from larger teacher models to speed uptraining and improve generalization. Together, these components make SLMpretraining substantially more efficient: our best model, discovered usingevolutionary search and initialized with LLM weights, matches the validationperplexity of a comparable Pythia SLM while requiring 9.2x fewer pretrainingtokens. We release all code and models athttps://github.com/whittle-org/whittle/, offering a practical and reproduciblepath toward cost-efficient small language model development at scale.</description><author>Arjun Krishnakumar, Rhea Sanjay Sukthanker, Hannan Javed Mahadik, Gabriela KadlecovÃ¡, Vladyslav Moroshan, Timur Carstensen, Frank Hutter, Aaron Klein</author><pubDate>Wed, 08 Oct 2025 16:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07227v1</guid></item><item><title>Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit</title><link>http://arxiv.org/abs/2510.07226v1</link><description>Generative Artificial Intelligence is reshaping online communication byenabling large-scale production of Machine-Generated Text (MGT) at low cost.While its presence is rapidly growing across the Web, little is known about howMGT integrates into social media environments. In this paper, we present thefirst large-scale characterization of MGT on Reddit. Using a state-of-the-artstatistical method for detection of MGT, we analyze over two years of activity(2022-2024) across 51 subreddits representative of Reddit's main communitytypes such as information seeking, social support, and discussion. We study theconcentration of MGT across communities and over time, and compared MGT tohuman-authored text in terms of social signals it expresses and engagement itreceives. Our very conservative estimate of MGT prevalence indicates thatsynthetic text is marginally present on Reddit, but it can reach peaks of up to9% in some communities in some months. MGT is unevenly distributed acrosscommunities, more prevalent in subreddits focused on technical knowledge andsocial support, and often concentrated in the activity of a small fraction ofusers. MGT also conveys distinct social signals of warmth and status givingtypical of language of AI assistants. Despite these stylistic differences, MGTachieves engagement levels comparable than human-authored content and in a fewcases even higher, suggesting that AI-generated text is becoming an organiccomponent of online social discourse. This work offers the first perspective onthe MGT footprint on Reddit, paving the way for new investigations involvingplatform governance, detection strategies, and community dynamics.</description><author>Lucio La Cava, Luca Maria Aiello, Andrea Tagarelli</author><pubDate>Wed, 08 Oct 2025 16:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07226v1</guid></item><item><title>KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality</title><link>http://arxiv.org/abs/2506.19807v3</link><description>Large Language Models (LLMs), particularly slow-thinking models, oftenexhibit severe hallucination, outputting incorrect content due to an inabilityto accurately recognize knowledge boundaries during reasoning. WhileReinforcement Learning (RL) can enhance complex reasoning abilities, itsoutcome-oriented reward mechanism often lacks factual supervision over thethinking process, further exacerbating the hallucination problem. To addressthe high hallucination in slow-thinking models, we propose Knowledge-enhancedRL, KnowRL. KnowRL guides models to perform fact-based slow thinking byintegrating a factuality reward, based on knowledge verification, into the RLtraining process, helping them recognize their knowledge boundaries. KnowRLguides models to perform fact-based slow thinking by integrating a factualityreward, based on knowledge verification, into the RL training process, helpingthem recognize their knowledge boundaries. This targeted factual input duringRL training enables the model to learn and internalize fact-based reasoningstrategies. By directly rewarding adherence to facts within the reasoningsteps, KnowRL fosters a more reliable thinking process. Experimental results onthree hallucination evaluation datasets and two reasoning evaluation datasetsdemonstrate that KnowRL effectively mitigates hallucinations in slow-thinkingmodels while maintaining their original strong reasoning capabilities. Our codeis available at https://github.com/zjunlp/KnowRL.</description><author>Baochang Ren, Shuofei Qiao, Da Zheng, Huajun Chen, Ningyu Zhang</author><pubDate>Wed, 08 Oct 2025 16:56:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.19807v3</guid></item><item><title>Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics and Generalization</title><link>http://arxiv.org/abs/2502.16600v5</link><description>Ensuring that Large Language Models (LLMs) return just responses which adhereto societal values is crucial for their broader application. Prior research hasshown that LLMs often fail to perform satisfactorily on tasks requiring moralcognizance, such as ethics-based judgments. While current approaches havefocused on fine-tuning LLMs with curated datasets to improve their capabilitieson such tasks, choosing the optimal learning paradigm to enhance the ethicalresponses of LLMs remains an open research debate. In this work, we aim toaddress this fundamental question: can current learning paradigms enable LLMsto acquire sufficient moral reasoning capabilities? Drawing from distributionalsemantics theory and the pragmatic nature of moral discourse, our analysisindicates that performance improvements follow a mechanism similar to that ofsemantic-level tasks, and therefore remain affected by the pragmatic nature ofmorals latent in discourse, a phenomenon we name the pragmatic dilemma. Weconclude that this pragmatic dilemma imposes significant limitations on thegeneralization ability of current learning paradigms, making it the primarybottleneck for moral reasoning acquisition in LLMs.</description><author>Guangliang Liu, Zimo Qi, Xitong Zhang, Lei Jiang, Kristen Marie Johnson</author><pubDate>Wed, 08 Oct 2025 16:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.16600v5</guid></item><item><title>How much speech data is necessary for ASR in African languages? An evaluation of data scaling in Kinyarwanda and Kikuyu</title><link>http://arxiv.org/abs/2510.07221v1</link><description>The development of Automatic Speech Recognition (ASR) systems forlow-resource African languages remains challenging due to limited transcribedspeech data. While recent advances in large multilingual models like OpenAI'sWhisper offer promising pathways for low-resource ASR development, criticalquestions persist regarding practical deployment requirements. This paperaddresses two fundamental concerns for practitioners: determining the minimumdata volumes needed for viable performance and characterizing the primaryfailure modes that emerge in production systems. We evaluate Whisper'sperformance through comprehensive experiments on two Bantu languages:systematic data scaling analysis on Kinyarwanda using training sets from 1 to1,400 hours, and detailed error characterization on Kikuyu using 270 hours oftraining data. Our scaling experiments demonstrate that practical ASRperformance (WER &lt; 13\%) becomes achievable with as little as 50 hours oftraining data, with substantial improvements continuing through 200 hours (WER&lt; 10\%). Complementing these volume-focused findings, our error analysisreveals that data quality issues, particularly noisy ground truthtranscriptions, account for 38.6\% of high-error cases, indicating that carefuldata curation is as critical as data volume for robust system performance.These results provide actionable benchmarks and deployment guidance for teamsdeveloping ASR systems across similar low-resource language contexts. Werelease accompanying and models seehttps://github.com/SunbirdAI/kinyarwanda-whisper-eval</description><author>Benjamin Akera, Evelyn Nafula, Patrick Walukagga, Gilbert Yiga, John Quinn, Ernest Mwebaze</author><pubDate>Wed, 08 Oct 2025 16:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07221v1</guid></item><item><title>Bit-Level Discrete Diffusion with Markov Probabilistic Models: An Improved Framework with Sharp Convergence Bounds under Minimal Assumptions</title><link>http://arxiv.org/abs/2502.07939v2</link><description>This paper introduces Discrete Markov Probabilistic Models (DMPMs), a noveldiscrete diffusion algorithm for discrete data generation. The algorithmoperates in discrete bit space, where the noising process is a continuous-timeMarkov chain that flips labels uniformly at random. The time-reversal process,like the forward noise process, is a jump process with its intensity governedby a discrete analogue of the classical score function. Crucially, thisintensity is proven to be the conditional expectation of a function of theforward process, underlining theoretical alignment with score-based generativemodels. We establish convergence bounds for the algorithm under minimalassumptions, ensuring robustness and efficiency, which we demonstrate throughexperiments on low-dimensional Bernoulli-distributed datasets andhigh-dimensional binary MNIST data. The results highlight competitiveperformance in generating discrete structures compared to the state-of-the-art.This work bridges theoretical foundations and practical applications, advancingthe development of effective and theoretically grounded discrete generativemodeling.</description><author>Le-Tuyet-Nhi Pham, Dario Shariatian, Antonio Ocello, Giovanni Conforti, Alain Durmus</author><pubDate>Wed, 08 Oct 2025 16:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07939v2</guid></item><item><title>RGS-DR: Deferred Reflections and Residual Shading in 2D Gaussian Splatting</title><link>http://arxiv.org/abs/2504.18468v5</link><description>In this work, we address specular appearance in inverse rendering using 2DGaussian splatting with deferred shading and argue for a refinement stage toimprove specular detail, thereby bridging the gap with reconstruction-onlymethods. Our pipeline estimates editable material properties and environmentillumination while employing a directional residual pass that captures leftoverview-dependent effects for further refining novel view synthesis. In contrastto per-Gaussian shading with shortest-axis normals and normal residuals, whichtends to result in more noisy geometry and specular appearance, apixel-deferred surfel formulation with specular residuals yields sharperhighlights, cleaner materials, and improved editability. We evaluate ourapproach on rendering and reconstruction quality on three popular datasetsfeaturing glossy objects, and also demonstrate high-quality relighting andmaterial editing.</description><author>Georgios Kouros, Minye Wu, Tinne Tuytelaars</author><pubDate>Wed, 08 Oct 2025 16:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.18468v5</guid></item><item><title>Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning</title><link>http://arxiv.org/abs/2508.19828v4</link><description>Large Language Models (LLMs) have demonstrated impressive capabilities acrossa wide range of NLP tasks, but they remain fundamentally stateless, constrainedby limited context windows that hinder long-horizon reasoning. Recent effortsto address this limitation often augment LLMs with an external memory bank, yetmost existing pipelines are static and heuristic-driven, lacking a learnedmechanism for deciding what to store, update, or retrieve. We presentMemory-R1, a reinforcement learning (RL) framework that equips LLMs with theability to actively manage and utilize external memory through two specializedagents: a Memory Manager that learns structured operations, including ADD,UPDATE, DELETE, and NOOP; and an Answer Agent that pre-selects and reasons overrelevant entries. Both agents are fine-tuned with outcome-driven RL (PPO andGRPO), enabling adaptive memory management with minimal supervision. With only152 training QA pairs, Memory-R1 outperforms strong baselines and generalizesacross diverse question types, three benchmarks (LoCoMo, MSC, LongMemEval), andmultiple model scales (3B-14B).</description><author>Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Kristian Kersting, Jeff Z. Pan, Hinrich SchÃ¼tze, Volker Tresp, Yunpu Ma</author><pubDate>Wed, 08 Oct 2025 16:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.19828v4</guid></item><item><title>Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation</title><link>http://arxiv.org/abs/2308.00856v2</link><description>Federated Learning (FL) is a distributed machine learning approach thatsafeguards privacy by creating an impartial global model while respecting theprivacy of individual client data. However, the conventional FL method canintroduce security risks when dealing with diverse client data, potentiallycompromising privacy and data integrity. To address these challenges, wepresent a differential privacy (DP) federated deep learning framework inmedical image segmentation. In this paper, we extend our similarity weightaggregation (SimAgg) method to DP-SimAgg algorithm, a differentially privatesimilarity-weighted aggregation algorithm for brain tumor segmentation inmulti-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not onlyenhances model segmentation capabilities but also provides an additional layerof privacy preservation. Extensive benchmarking and evaluation of ourframework, with computational performance as a key consideration, demonstratethat DP-SimAgg enables accurate and robust brain tumor segmentation whileminimizing communication costs during model training. This advancement iscrucial for preserving the privacy of medical image data and safeguardingsensitive information. In conclusion, adding a differential privacy layer inthe global weight aggregation phase of the federated brain tumor segmentationprovides a promising solution to privacy concerns without compromisingsegmentation model efficacy. By leveraging DP, we ensure the protection ofclient data against adversarial attacks and malicious participants.</description><author>Muhammad Irfan Khan, Esa Alhoniemi, Elina Kontio, Suleiman A. Khan, Mojtaba Jafaritadi</author><pubDate>Wed, 08 Oct 2025 16:53:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00856v2</guid></item><item><title>GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation</title><link>http://arxiv.org/abs/2510.07217v1</link><description>Text-to-image synthesis has made remarkable progress, yet accuratelyinterpreting complex and lengthy prompts remains challenging, often resultingin semantic inconsistencies and missing details. Existing solutions, such asfine-tuning, are model-specific and require training, while prior automaticprompt optimization (APO) approaches typically lack systematic error analysisand refinement strategies, resulting in limited reliability and effectiveness.Meanwhile, test-time scaling methods operate on fixed prompts and on noise orsample numbers, limiting their interpretability and adaptability. To solvethese, we introduce a flexible and efficient test-time prompt optimizationstrategy that operates directly on the input text. We propose a plug-and-playmulti-agent system called GenPilot, integrating error analysis,clustering-based adaptive exploration, fine-grained verification, and a memorymodule for iterative optimization. Our approach is model-agnostic,interpretable, and well-suited for handling long and complex prompts.Simultaneously, we summarize the common patterns of errors and the refinementstrategy, offering more experience and encouraging further exploration.Experiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7%demonstrate the strong capability of our methods in enhancing the text andimage consistency and structural coherence of generated images, revealing theeffectiveness of our test-time prompt optimization strategy. The code isavailable at https://github.com/27yw/GenPilot.</description><author>Wen Ye, Zhaocheng Liu, Yuwei Gui, Tingyu Yuan, Yunyue Su, Bowen Fang, Chaoyang Zhao, Qiang Liu, Liang Wang</author><pubDate>Wed, 08 Oct 2025 16:51:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07217v1</guid></item><item><title>AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction</title><link>http://arxiv.org/abs/2505.23663v2</link><description>The cost and accuracy of simulating complex physical systems using the FiniteElement Method (FEM) scales with the resolution of the underlying mesh.Adaptive meshes improve computational efficiency by refining resolution incritical regions, but typically require task-specific heuristics or cumbersomemanual design by a human expert. We propose Adaptive Meshing By ExpertReconstruction (AMBER), a supervised learning approach to mesh adaptation.Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,a function mapping from the geometry to the local element size of the targetmesh, and uses this prediction to produce a new intermediate mesh using anout-of-the-box mesh generator. This process is enabled through a hierarchicalgraph neural network, and relies on data augmentation by automaticallyprojecting expert labels onto AMBER-generated data during training. We evaluateAMBER on 2D and 3D datasets, including classical physics problems, mechanicalcomponents, and real-world industrial designs with human expert meshes. AMBERgeneralizes to unseen geometries and consistently outperforms multiple recentbaselines, including ones using Graph and Convolutional Neural Networks, andReinforcement Learning-based approaches.</description><author>Niklas Freymuth, Tobias WÃ¼rth, Nicolas Schreiber, Balazs Gyenes, Andreas Boltres, Johannes Mitsch, Aleksandar Taranovic, Tai Hoang, Philipp Dahlinger, Philipp Becker, Luise KÃ¤rger, Gerhard Neumann</author><pubDate>Wed, 08 Oct 2025 16:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.23663v2</guid></item><item><title>Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models</title><link>http://arxiv.org/abs/2510.07213v1</link><description>Large language models exhibit strong multilingual capabilities despitelimited exposure to non-English data. Prior studies show that English-centriclarge language models map multilingual content into English-alignedrepresentations at intermediate layers and then project them back intotarget-language token spaces in the final layer. From this observation, wehypothesize that this cross-lingual transition is governed by a small andsparse set of dimensions, which occur at consistent indices across theintermediate to final layers. Building on this insight, we introduce a simple,training-free method to identify and manipulate these dimensions, requiringonly as few as 50 sentences of either parallel or monolingual data. Experimentson a multilingual generation control task reveal the interpretability of thesedimensions, demonstrating that the interventions in these dimensions can switchthe output language while preserving semantic content, and that it surpassesthe performance of prior neuron-based approaches at a substantially lower cost.</description><author>Chengzhi Zhong, Fei Cheng, Qianying Liu, Yugo Murawaki, Chenhui Chu, Sadao Kurohashi</author><pubDate>Wed, 08 Oct 2025 16:46:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07213v1</guid></item><item><title>Generative AI for Cel-Animation: A Survey</title><link>http://arxiv.org/abs/2501.06250v4</link><description>Traditional Celluloid (Cel) Animation production pipeline encompassesmultiple essential steps, including storyboarding, layout design, keyframeanimation, inbetweening, and colorization, which demand substantial manualeffort, technical expertise, and significant time investment. These challengeshave historically impeded the efficiency and scalability of Cel-Animationproduction. The rise of generative artificial intelligence (GenAI),encompassing large language models, multimodal models, and diffusion models,offers innovative solutions by automating tasks such as inbetween framegeneration, colorization, and storyboard creation. This survey explores howGenAI integration is revolutionizing traditional animation workflows bylowering technical barriers, broadening accessibility for a wider range ofcreators through tools like AniDoc, ToonCrafter, and AniSora, and enablingartists to focus more on creative expression and artistic innovation. Despiteits potential, challenges like visual consistency, stylistic coherence, andethical considerations persist. Additionally, this paper explores futuredirections and advancements in AI-assisted animation. For further explorationand resources, please visit our GitHub repository:https://github.com/yunlong10/Awesome-AI4Animation</description><author>Yolo Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 16:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.06250v4</guid></item><item><title>HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving</title><link>http://arxiv.org/abs/2510.07210v1</link><description>We present a novel hybrid learning-assisted planning method, named HyPlan,for solving the collision-free navigation problem for self-driving cars inpartially observable traffic environments. HyPlan combines methods formulti-agent behavior prediction, deep reinforcement learning with proximalpolicy optimization and approximated online POMDP planning with heuristicconfidence-based vertical pruning to reduce its execution time withoutcompromising safety of driving. Our experimental performance analysis on theCARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealedthat HyPlan may navigate safer than selected relevant baselines and performsignificantly faster than considered alternative online POMDP planners.</description><author>Donald Pfaffmann, Matthias Klusch, Marcel Steinmetz</author><pubDate>Wed, 08 Oct 2025 16:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07210v1</guid></item><item><title>A Broader View of Thompson Sampling</title><link>http://arxiv.org/abs/2510.07208v1</link><description>Thompson Sampling is one of the most widely used and studied banditalgorithms, known for its simple structure, low regret performance, and solidtheoretical guarantees. Yet, in stark contrast to most other families of banditalgorithms, the exact mechanism through which posterior sampling (as introducedby Thompson) is able to "properly" balance exploration and exploitation,remains a mystery. In this paper we show that the core insight to address thisquestion stems from recasting Thompson Sampling as an online optimizationalgorithm. To distill this, a key conceptual tool is introduced, which we referto as "faithful" stationarization of the regret formulation. Essentially, thefinite horizon dynamic optimization problem is converted into a stationarycounterpart which "closely resembles" the original objective (in contrast, theclassical infinite horizon discounted formulation, that leads to the Gittinsindex, alters the problem and objective in too significant a manner). The newlycrafted time invariant objective can be studied using Bellman's principle whichleads to a time invariant optimal policy. When viewed through this lens,Thompson Sampling admits a simple online optimization form that mimics thestructure of the Bellman-optimal policy, and where greediness is regularized bya measure of residual uncertainty based on point-biserial correlation. Thisanswers the question of how Thompson Sampling balancesexploration-exploitation, and moreover, provides a principled framework tostudy and further improve Thompson's original idea.</description><author>Yanlin Qu, Hongseok Namkoong, Assaf Zeevi</author><pubDate>Wed, 08 Oct 2025 16:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07208v1</guid></item><item><title>EigenScore: OOD Detection using Covariance in Diffusion Models</title><link>http://arxiv.org/abs/2510.07206v1</link><description>Out-of-distribution (OOD) detection is critical for the safe deployment ofmachine learning systems in safety-sensitive domains. Diffusion models haverecently emerged as powerful generative models, capable of capturing complexdata distributions through iterative denoising. Building on this progress,recent work has explored their potential for OOD detection. We proposeEigenScore, a new OOD detection method that leverages the eigenvalue spectrumof the posterior covariance induced by a diffusion model. We argue thatposterior covariance provides a consistent signal of distribution shift,leading to larger trace and leading eigenvalues on OOD inputs, yielding a clearspectral signature. We further provide analysis explicitly linking posteriorcovariance to distribution mismatch, establishing it as a reliable signal forOOD detection. To ensure tractability, we adopt a Jacobian-free subspaceiteration method to estimate the leading eigenvalues using only forwardevaluations of the denoiser. Empirically, EigenScore achieves SOTA performance,with up to 5% AUROC improvement over the best baseline. Notably, it remainsrobust in near-OOD settings such as CIFAR-10 vs CIFAR-100, where existingdiffusion-based methods often fail.</description><author>Shirin Shoushtari, Yi Wang, Xiao Shi, M. Salman Asif, Ulugbek S. Kamilov</author><pubDate>Wed, 08 Oct 2025 16:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07206v1</guid></item><item><title>SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis</title><link>http://arxiv.org/abs/2505.16834v3</link><description>Retrieval-augmented generation (RAG) systems have advanced large languagemodels (LLMs) in complex deep search scenarios requiring multi-step reasoningand iterative information retrieval. However, existing approaches face criticallimitations that lack high-quality training trajectories or suffer from thedistributional mismatches in simulated environments and prohibitivecomputational costs for real-world deployment. This paper introducesSimpleDeepSearcher, a lightweight yet effective framework that bridges this gapthrough strategic data engineering rather than complex training paradigms. Ourapproach synthesizes high-quality training data by simulating realistic userinteractions in live web search environments, coupled with a multi-criteriacuration strategy that optimizes the diversity and quality of input and outputside. Experiments on five benchmarks across diverse domains demonstrate thatSFT on only 871 curated samples yields significant improvements over RL-basedbaselines. Our work establishes SFT as a viable pathway by systematicallyaddressing the data-scarce bottleneck, offering practical insights forefficient deep search systems. Our code is available athttps://github.com/RUCAIBox/SimpleDeepSearcher.</description><author>Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen</author><pubDate>Wed, 08 Oct 2025 16:40:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.16834v3</guid></item><item><title>Guided by the Experts: Provable Feature Learning Dynamic of Soft-Routed Mixture-of-Experts</title><link>http://arxiv.org/abs/2510.07205v1</link><description>Mixture-of-Experts (MoE) architectures have emerged as a cornerstone ofmodern AI systems. In particular, MoEs route inputs dynamically to specializedexperts whose outputs are aggregated through weighted summation. Despite theirwidespread application, theoretical understanding of MoE training dynamicsremains limited to either separate expert-router optimization or only top-1routing scenarios with carefully constructed datasets. This paper advances MoEtheory by providing convergence guarantees for joint training of soft-routedMoE models with non-linear routers and experts in a student-teacher framework.We prove that, with moderate over-parameterization, the student networkundergoes a feature learning phase, where the router's learning process is``guided'' by the experts, that recovers the teacher's parameters. Moreover, weshow that a post-training pruning can effectively eliminate redundant neurons,followed by a provably convergent fine-tuning process that reaches globaloptimality. To our knowledge, our analysis is the first to bring novel insightsin understanding the optimization landscape of the MoE architecture.</description><author>Fangshuo Liao, Anastasios Kyrillidis</author><pubDate>Wed, 08 Oct 2025 16:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07205v1</guid></item><item><title>Sunflower: A New Approach To Expanding Coverage of African Languages in Large Language Models</title><link>http://arxiv.org/abs/2510.07203v1</link><description>There are more than 2000 living languages in Africa, most of which have beenbypassed by advances in language technology. Current leading LLMs exhibitstrong performance on a number of the most common languages (e.g. Swahili orYoruba), but prioritise support for the languages with the most speakers first,resulting in piecemeal ability across disparate languages. We contend that aregionally focussed approach is more efficient, and present a case study forUganda, a country with high linguistic diversity. We describe the developmentof Sunflower 14B and 32B, a pair of models based on Qwen 3 with state of theart comprehension in the majority of all Ugandan languages. These models areopen source and can be used to reduce language barriers in a number ofimportant practical applications.</description><author>Benjamin Akera, Evelyn Nafula Ouma, Gilbert Yiga, Patrick Walukagga, Phionah Natukunda, Trevor Saaka, Solomon Nsumba, Lilian Teddy Nabukeera, Joel Muhanguzi, Imran Sekalala, Nimpamya Janat Namara, Engineer Bainomugisha, Ernest Mwebaze, John Quinn</author><pubDate>Wed, 08 Oct 2025 16:35:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07203v1</guid></item><item><title>An in-depth look at approximation via deep and narrow neural networks</title><link>http://arxiv.org/abs/2510.07202v1</link><description>In 2017, Hanin and Sellke showed that the class of arbitrarily deep,real-valued, feed-forward and ReLU-activated networks of width w forms a densesubset of the space of continuous functions on R^n, with respect to thetopology of uniform convergence on compact sets, if and only if w&gt;n holds. Toshow the necessity, a concrete counterexample function f:R^n-&gt;R was used. Inthis note we actually approximate this very f by neural networks in the twocases w=n and w=n+1 around the aforementioned threshold. We study how theapproximation quality behaves if we vary the depth and what effect (spoileralert: dying neurons) cause that behavior.</description><author>Joris Dommel, Sven A. Wegner</author><pubDate>Wed, 08 Oct 2025 16:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07202v1</guid></item><item><title>Last-iterate Convergence for Symmetric, General-sum, $2 \times 2$ Games Under The Exponential Weights Dynamic</title><link>http://arxiv.org/abs/2502.08063v2</link><description>We conduct a comprehensive analysis of the discrete-time exponential-weightsdynamic with a constant step size on all \emph{general-sum and symmetric} $2\times 2$ normal-form games, i.e. games with $2$ pure strategies per player,and where the ensuing payoff tuple is of the form $(A,A^\top)$ (where $A$ isthe $2 \times 2$ payoff matrix corresponding to the first player). Suchsymmetric games commonly arise in real-world interactions between "symmetric"agents who have identically defined utility functions -- such as Bertrandcompetition, multi-agent performative prediction, and certain congestion games-- and display a rich multiplicity of equilibria despite the seemingly simplesetting. Somewhat surprisingly, we show through a first-principles analysisthat the exponential weights dynamic, which is popular in online learning,converges in the last iterate for such games regardless of initialization withan appropriately chosen step size. For certain games and/or initializations, wefurther show that the convergence rate is in fact exponential and holds for anystep size. We illustrate our theory with extensive simulations and applications to theaforementioned game-theoretic interactions. In the case of multi-agentperformative prediction, we formulate a new "mortgage competition" game betweenlenders (i.e. banks) who interact with a population of customers, and show thatit fits into our framework.</description><author>Guanghui Wang, Krishna Acharya, Lokranjan Lakshmikanthan, Juba Ziani, Vidya Muthukumar</author><pubDate>Wed, 08 Oct 2025 16:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08063v2</guid></item><item><title>AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations</title><link>http://arxiv.org/abs/2504.07836v4</link><description>Visual grounding (VG) aims to localize target objects in an image based onnatural language descriptions. In this paper, we propose AerialVG, a new taskfocusing on visual grounding from aerial views. Compared to traditional VG,AerialVG poses new challenges, \emph{e.g.}, appearance-based grounding isinsufficient to distinguish among multiple visually similar objects, andpositional relations should be emphasized. Besides, existing VG models strugglewhen applied to aerial imagery, where high-resolution images cause significantdifficulties. To address these challenges, we introduce the first AerialVGdataset, consisting of 5K real-world aerial images, 50K manually annotateddescriptions, and 103K objects. Particularly, each annotation in AerialVGdataset contains multiple target objects annotated with relative spatialrelations, requiring models to perform comprehensive spatial reasoning.Furthermore, we propose an innovative model especially for the AerialVG task,where a Hierarchical Cross-Attention is devised to focus on target regions, anda Relation-Aware Grounding module is designed to infer positional relations.Experimental results validate the effectiveness of our dataset and method,highlighting the importance of spatial reasoning in aerial visual grounding.The code and dataset will be released.</description><author>Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Xuelong Li, Bin Zhao</author><pubDate>Wed, 08 Oct 2025 16:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.07836v4</guid></item><item><title>Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward</title><link>http://arxiv.org/abs/2209.12164v2</link><description>Advertisement video editing aims to automatically edit advertising videosinto shorter videos while retaining coherent content and crucial informationconveyed by advertisers. It mainly contains two stages: video segmentation andsegment assemblage. The existing method performs well at video segmentationstages but suffers from the problems of dependencies on extra cumbersome modelsand poor performance at the segment assemblage stage. To address theseproblems, we propose M-SAN (Multi-modal Segment Assemblage Network) which canperform efficient and coherent segment assemblage task end-to-end. It utilizesmulti-modal representation extracted from the segments and follows theEncoder-Decoder Ptr-Net framework with the Attention mechanism.Importance-coherence reward is designed for training M-SAN. We experiment onthe Ads-1k dataset with 1000+ videos under rich ad scenarios collected fromadvertisers. To evaluate the methods, we propose a unified metric,Imp-Coh@Time, which comprehensively assesses the importance, coherence, andduration of the outputs at the same time. Experimental results show that ourmethod achieves better performance than random selection and the previousmethod on the metric. Ablation experiments further verify that multi-modalrepresentation and importance-coherence reward significantly improve theperformance. Ads-1k dataset is available at:https://github.com/yunlong10/Ads-1k</description><author>Yolo Yunlong Tang, Siting Xu, Teng Wang, Qin Lin, Qinglin Lu, Feng Zheng</author><pubDate>Wed, 08 Oct 2025 16:27:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12164v2</guid></item><item><title>Accelerating Inference for Multilayer Neural Networks with Quantum Computers</title><link>http://arxiv.org/abs/2510.07195v1</link><description>Fault-tolerant Quantum Processing Units (QPUs) promise to deliver exponentialspeed-ups in select computational tasks, yet their integration into modern deeplearning pipelines remains unclear. In this work, we take a step towardsbridging this gap by presenting the first fully-coherent quantum implementationof a multilayer neural network with non-linear activation functions. Ourconstructions mirror widely used deep learning architectures based on ResNet,and consist of residual blocks with multi-filter 2D convolutions, sigmoidactivations, skip-connections, and layer normalizations. We analyse thecomplexity of inference for networks under three quantum data access regimes.Without any assumptions, we establish a quadratic speedup over classicalmethods for shallow bilinear-style networks. With efficient quantum access tothe weights, we obtain a quartic speedup over classical methods. With efficientquantum access to both the inputs and the network weights, we prove that anetwork with an $N$-dimensional vectorized input, $k$ residual block layers,and a final residual-linear-pooling layer can be implemented with an error of$\epsilon$ with $O(\text{polylog}(N/\epsilon)^k)$ inference cost.</description><author>Arthur G. Rattew, Po-Wei Huang, Naixu Guo, LirandÃ« Pira, Patrick Rebentrost</author><pubDate>Wed, 08 Oct 2025 16:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07195v1</guid></item><item><title>Covert Quantum Learning: Privately and Verifiably Learning from Quantum Data</title><link>http://arxiv.org/abs/2510.07193v1</link><description>Quantum learning from remotely accessed quantum compute and data must addresstwo key challenges: verifying the correctness of data and ensuring the privacyof the learner's data-collection strategies and resulting conclusions. Thecovert (verifiable) learning model of Canetti and Karchmer (TCC 2021) providesa framework for endowing classical learning algorithms with such guarantees. Inthis work, we propose models of covert verifiable learning in quantum learningtheory and realize them without computational hardness assumptions for remotedata access scenarios motivated by established quantum data advantages. Weconsider two privacy notions: (i) strategy-covertness, where the eavesdropperdoes not gain information about the learner's strategy; and (ii)target-covertness, where the eavesdropper does not gain information about theunknown object being learned. We show: Strategy-covert algorithms for makingquantum statistical queries via classical shadows; Target-covert algorithms forlearning quadratic functions from public quantum examples and private quantumstatistical queries, for Pauli shadow tomography and stabilizer state learningfrom public multi-copy and private single-copy quantum measurements, and forsolving Forrelation and Simon's problem from public quantum queries and privateclassical queries, where the adversary is a unidirectional or i.i.d.ancilla-free eavesdropper. The lattermost results in particular establish thatthe exponential separation between classical and quantum queries forForrelation and Simon's problem survives under covertness constraints. Alongthe way, we design covert verifiable protocols for quantum data acquisitionfrom public quantum queries which may be of independent interest. Overall, ourmodels and corresponding algorithms demonstrate that quantum advantages areprivately and verifiably achievable even with untrusted, remote data.</description><author>Abhishek Anand, Matthias C. Caro, Ari Karchmer, Saachi Mutreja</author><pubDate>Wed, 08 Oct 2025 16:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07193v1</guid></item><item><title>Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples</title><link>http://arxiv.org/abs/2510.07192v1</link><description>Poisoning attacks can compromise the safety of large language models (LLMs)by injecting malicious documents into their training data. Existing work hasstudied pretraining poisoning assuming adversaries control a percentage of thetraining corpus. However, for large models, even small percentages translate toimpractically large amounts of data. This work demonstrates for the first timethat poisoning attacks instead require a near-constant number of documentsregardless of dataset size. We conduct the largest pretraining poisoningexperiments to date, pretraining models from 600M to 13B parameters onchinchilla-optimal datasets (6B to 260B tokens). We find that 250 poisoneddocuments similarly compromise models across all model and dataset sizes,despite the largest models training on more than 20 times more clean data. Wealso run smaller-scale experiments to ablate factors that could influenceattack success, including broader ratios of poisoned to clean data andnon-random distributions of poisoned samples. Finally, we demonstrate the samedynamics for poisoning during fine-tuning. Altogether, our results suggest thatinjecting backdoors through data poisoning may be easier for large models thanpreviously believed as the number of poisons required does not scale up withmodel size, highlighting the need for more research on defences to mitigatethis risk in future models.</description><author>Alexandra Souly, Javier Rando, Ed Chapman, Xander Davies, Burak Hasircioglu, Ezzeldin Shereen, Carlos Mougan, Vasilios Mavroudis, Erik Jones, Chris Hicks, Nicholas Carlini, Yarin Gal, Robert Kirk</author><pubDate>Wed, 08 Oct 2025 16:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07192v1</guid></item><item><title>Resolution scaling governs DINOv3 transfer performance in chest radiograph classification</title><link>http://arxiv.org/abs/2510.07191v1</link><description>Self-supervised learning (SSL) has advanced visual representation learning,but its value in chest radiography, a high-volume imaging modality withfine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSLmodels through Gram-anchored self-distillation. Whether these design choicesimprove transfer learning for chest radiography has not been systematicallytested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization acrossseven datasets (n&gt;814,000). Two representative backbones were evaluated:ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and1024x1024 pixels. We additionally assessed frozen features from a 7B model. Theprimary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2achieved comparable performance on adult datasets. Increasing resolution to512x512 yielded consistent improvements for DINOv3 over both DINOv2 andImageNet. In contrast, results in pediatric cohort showed no differences acrossinitializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Modelsusing frozen DINOv3-7B features underperformed relative to fully finetuned86-89M-parameter backbones, highlighting the importance of domain adaptation.Scaling to 1024x1024 did not further improve accuracy. Resolution-related gainswere most evident for boundary-dependent and small focal abnormalities. Inchest radiography, higher input resolution is critical for leveraging thebenefits of modern self-supervised models. 512x512 pixels represent a practicalupper limit where DINOv3-initialized ConvNeXt-B networks provide the strongestperformance, while larger inputs offer minimal return on cost. Clinically,these findings support use of finetuned, mid-sized backbones at 512x512 forchest radiograph interpretation, with the greatest gains expected in detectingsubtle or boundary-centered lesions relevant to emergency and critical caresettings.</description><author>Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn</author><pubDate>Wed, 08 Oct 2025 16:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07191v1</guid></item><item><title>Video Understanding with Large Language Models: A Survey</title><link>http://arxiv.org/abs/2312.17432v7</link><description>With the burgeoning growth of online video platforms and the escalatingvolume of video content, the demand for proficient video understanding toolshas intensified markedly. Given the remarkable capabilities of large languagemodels (LLMs) in language and multimodal tasks, this survey provides a detailedoverview of recent advancements in video understanding that harness the powerof LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisinglyadvanced, particularly their ability for open-ended multi-granularity (general,temporal, and spatiotemporal) reasoning combined with commonsense knowledge,suggesting a promising path for future video understanding. We examine theunique characteristics and capabilities of Vid-LLMs, categorizing theapproaches into three main types: Video Analyzer x LLM, Video Embedder x LLM,and (Analyzer + Embedder) x LLM. Furthermore, we identify five sub-types basedon the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM asText Decoder, LLM as Regressor, and LLM as Hidden Layer. Furthermore, thissurvey presents a comprehensive study of the tasks, datasets, benchmarks, andevaluation methodologies for Vid-LLMs. Additionally, it explores the expansiveapplications of Vid-LLMs across various domains, highlighting their remarkablescalability and versatility in real-world video understanding challenges.Finally, it summarizes the limitations of existing Vid-LLMs and outlinesdirections for future research. For more information, readers are recommendedto visit the repository athttps://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.</description><author>Yolo Yunlong Tang, Jing Bi, Siting Xu, Luchuan Song, Susan Liang, Teng Wang, Daoan Zhang, Jie An, Jingyang Lin, Rongyi Zhu, Ali Vosoughi, Chao Huang, Zeliang Zhang, Pinxin Liu, Mingqian Feng, Feng Zheng, Jianguo Zhang, Ping Luo, Jiebo Luo, Chenliang Xu</author><pubDate>Wed, 08 Oct 2025 16:24:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17432v7</guid></item><item><title>MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis</title><link>http://arxiv.org/abs/2510.07190v1</link><description>Recent breakthroughs in video generation, powered by large-scale datasets anddiffusion techniques, have shown that video diffusion models can function asimplicit 4D novel view synthesizers. Nevertheless, current methods primarilyconcentrate on redirecting camera trajectory within the front view whilestruggling to generate 360-degree viewpoint changes. In this paper, we focus onhuman-centric subdomain and present MV-Performer, an innovative framework forcreating synchronized novel view videos from monocular full-body captures. Toachieve a 360-degree synthesis, we extensively leverage the MVHumanNet datasetand incorporate an informative condition signal. Specifically, we use thecamera-dependent normal maps rendered from oriented partial point clouds, whicheffectively alleviate the ambiguity between seen and unseen observations. Tomaintain synchronization in the generated videos, we propose a multi-viewhuman-centric video diffusion model that fuses information from the referencevideo, partial rendering, and different viewpoints. Additionally, we provide arobust inference procedure for in-the-wild video cases, which greatly mitigatesthe artifacts induced by imperfect monocular depth estimation. Extensiveexperiments on three datasets demonstrate our MV-Performer's state-of-the-arteffectiveness and robustness, setting a strong model for human-centric 4D novelview synthesis.</description><author>Yihao Zhi, Chenghong Li, Hongjie Liao, Xihe Yang, Zhengwentai Sun, Jiahao Chang, Xiaodong Cun, Wensen Feng, Xiaoguang Han</author><pubDate>Wed, 08 Oct 2025 16:24:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07190v1</guid></item><item><title>From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models</title><link>http://arxiv.org/abs/2509.03122v2</link><description>Fingerprinting is critical for maintaining traceability and protecting theintellectual property (IP) of developers, as LLMs deployed in web applicationsare susceptible to unauthorized redistribution and misuse via fine-tuning orblack-box deployment. However, current backdoor-based fingerprinting methodsface a fundamental trade-off: fingerprints embedded as garbled text are easilydetected and filtered, whereas those crafted as coherent natural language areprone to being triggered unintentionally. To overcome these limitations, wepropose RFEdit, a knowledge-editing framework that embeds a rule-basedmultilingual natural language fingerprint (MNLF) by modifying a sparse subsetof model weights. This approach enables efficient and robust fingerprintinjection with minimal impact on unrelated knowledge in LLMs. Our RFEditframework is further safeguarded by Fingerprint Subspace-aware Fine-Tuning(FSFT), which mitigates fingerprint degradation during legitimate fine-tuningby restricting parameter updates to the fingerprint subspace. This approachpreserves fingerprint integrity while enhancing downstream task performance ofLLMs. These advances establish a comprehensive pipeline from fingerprintinjection to defense, achieving high detection effectiveness, robustnessagainst adversarial manipulations, harmlessness to model utility, andpersistence under fine-tuning. Extensive experiments demonstrate that RFEditmaintains robustness under quantization and pruning. Additionally, fingerprinteffectiveness is generally improved by more than 10\% when combined with FSFTfor math and alpaca downstream tasks.</description><author>Yue Li, Xin Yi, Dongsheng Shi, Yongyi Cui, Gerard de Melo, Linlin Wang</author><pubDate>Wed, 08 Oct 2025 16:23:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.03122v2</guid></item><item><title>Split Conformal Classification with Unsupervised Calibration</title><link>http://arxiv.org/abs/2510.07185v1</link><description>Methods for split conformal prediction leverage calibration samples totransform any prediction rule into a set-prediction rule that complies with atarget coverage probability. Existing methods provide remarkably strongperformance guarantees with minimal computational costs. However, they requireto use calibration samples composed by labeled examples different to those usedfor training. This requirement can be highly inconvenient, as it prevents theuse of all labeled examples for training and may require acquiring additionallabels solely for calibration. This paper presents an effective methodology forsplit conformal prediction with unsupervised calibration for classificationtasks. In the proposed approach, set-prediction rules are obtained usingunsupervised calibration samples together with supervised training samplespreviously used to learn the classification rule. Theoretical and experimentalresults show that the presented methods can achieve performance comparable tothat with supervised calibration, at the expenses of a moderate degradation inperformance guarantees and computational efficiency.</description><author>Santiago Mazuelas</author><pubDate>Wed, 08 Oct 2025 16:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07185v1</guid></item><item><title>BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring</title><link>http://arxiv.org/abs/2504.17693v2</link><description>Augmented reality (AR) applications for construction monitoring rely onreal-time environmental tracking to visualize architectural elements. However,construction sites present significant challenges for traditional trackingmethods due to featureless surfaces, dynamic changes, and drift accumulation,leading to misalignment between digital models and the physical world. Thispaper proposes a BIM-aware drift correction method to address these challenges.Instead of relying solely on SLAM-based localization, we align ``as-built"detected planes from the real-world environment with ``as-planned"architectural planes in BIM. Our method performs robust plane matching andcomputes a transformation (TF) between SLAM (S) and BIM (B) origin frames usingoptimization techniques, minimizing drift over time. By incorporating BIM asprior structural knowledge, we can achieve improved long-term localization andenhanced AR visualization accuracy in noisy construction environments. Themethod is evaluated through real-world experiments, showing significantreductions in drift-induced errors and optimized alignment consistency. Onaverage, our system achieves a reduction of 52.24% in angular deviations and areduction of 60.8% in the distance error of the matched walls compared to theinitial manual alignment by the user.</description><author>Asier Bikandi-Noya, Muhammad Shaheer, Hriday Bavle, Jayan Jevanesan, Holger Voos, Jose Luis Sanchez-Lopez</author><pubDate>Wed, 08 Oct 2025 16:20:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.17693v2</guid></item><item><title>Bridged Clustering for Representation Learning: Semi-Supervised Sparse Bridging</title><link>http://arxiv.org/abs/2510.07182v1</link><description>We introduce Bridged Clustering, a semi-supervised framework to learnpredictors from any unpaired input $X$ and output $Y$ dataset. Our method firstclusters $X$ and $Y$ independently, then learns a sparse, interpretable bridgebetween clusters using only a few paired examples. At inference, a new input$x$ is assigned to its nearest input cluster, and the centroid of the linkedoutput cluster is returned as the prediction $\hat{y}$. Unlike traditional SSL,Bridged Clustering explicitly leverages output-only data, and unlike densetransport-based methods, it maintains a sparse and interpretable alignment.Through theoretical analysis, we show that with bounded mis-clustering andmis-bridging rates, our algorithm becomes an effective and efficient predictor.Empirically, our method is competitive with SOTA methods while remainingsimple, model-agnostic, and highly label-efficient in low-supervision settings.</description><author>Patrick Peixuan Ye, Chen Shani, Ellen Vitercik</author><pubDate>Wed, 08 Oct 2025 16:20:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07182v1</guid></item><item><title>TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics</title><link>http://arxiv.org/abs/2510.07181v1</link><description>Vision-Language Models (VLMs) have shown remarkable capabilities in spatialreasoning, yet they remain fundamentally limited to qualitative precision andlack the computational precision required for real-world robotics. Currentapproaches fail to leverage metric cues from depth sensors and cameracalibration, instead reducing geometric problems to pattern recognition tasksthat cannot deliver the centimeter-level accuracy essential for roboticmanipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novelframework that transforms VLMs from perceptual estimators to geometriccomputers by enabling them to generate and execute precise geometriccomputations through external tools. Rather than attempting to internalizecomplex geometric operations within neural networks, TIGeR empowers models torecognize geometric reasoning requirements, synthesize appropriatecomputational code, and invoke specialized libraries for exact calculations. Tosupport this paradigm, we introduce TIGeR-300K, a comprehensivetool-invocation-oriented dataset covering point transformations, poseestimation, trajectory generation, and spatial compatibility verification,complete with tool invocation sequences and intermediate computations. Througha two-stage training pipeline combining supervised fine-tuning (SFT) andreinforcement fine-tuning (RFT) with our proposed hierarchical reward design,TIGeR achieves SOTA performance on geometric reasoning benchmarks whiledemonstrating centimeter-level precision in real-world robotic manipulationtasks.</description><author>Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang</author><pubDate>Wed, 08 Oct 2025 16:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07181v1</guid></item><item><title>SubGrapher: Visual Fingerprinting of Chemical Structures</title><link>http://arxiv.org/abs/2504.19695v2</link><description>Automatic extraction of chemical structures from scientific literature playsa crucial role in accelerating research across fields ranging from drugdiscovery to materials science. Patent documents, in particular, containmolecular information in visual form, which is often inaccessible throughtraditional text-based searches. In this work, we introduce SubGrapher, amethod for the visual fingerprinting of chemical structure images. Unlikeconventional Optical Chemical Structure Recognition (OCSR) models that attemptto reconstruct full molecular graphs, SubGrapher focuses on extractingmolecular fingerprints directly from chemical structure images. Usinglearning-based instance segmentation, SubGrapher identifies functional groupsand carbon backbones, constructing a substructure-based fingerprint thatenables chemical structure retrieval. Our approach is evaluated againststate-of-the-art OCSR and fingerprinting methods, demonstrating superiorretrieval performance and robustness across diverse molecular depictions. Thedataset, models, and code are publicly available.</description><author>Lucas Morin, Gerhard Ingmar Meijer, ValÃ©ry Weber, Luc Van Gool, Peter W. J. Staar</author><pubDate>Wed, 08 Oct 2025 16:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.19695v2</guid></item><item><title>Bayesian Portfolio Optimization by Predictive Synthesis</title><link>http://arxiv.org/abs/2510.07180v1</link><description>Portfolio optimization is a critical task in investment. Most existingportfolio optimization methods require information on the distribution ofreturns of the assets that make up the portfolio. However, such distributioninformation is usually unknown to investors. Various methods have been proposedto estimate distribution information, but their accuracy greatly depends on theuncertainty of the financial markets. Due to this uncertainty, a model thatcould well predict the distribution information at one point in time mayperform less accurately compared to another model at a different time. To solvethis problem, we investigate a method for portfolio optimization based onBayesian predictive synthesis (BPS), one of the Bayesian ensemble methods formeta-learning. We assume that investors have access to multiple asset returnprediction models. By using BPS with dynamic linear models to combine thesepredictions, we can obtain a Bayesian predictive posterior about the meanrewards of assets that accommodate the uncertainty of the financial markets. Inthis study, we examine how to construct mean-variance portfolios andquantile-based portfolios based on the predicted distribution information.</description><author>Masahiro Kato, Kentaro Baba, Hibiki Kaibuchi, Ryo Inokuchi</author><pubDate>Wed, 08 Oct 2025 16:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07180v1</guid></item><item><title>Biasless Language Models Learn Unnaturally: How LLMs Fail to Distinguish the Possible from the Impossible</title><link>http://arxiv.org/abs/2510.07178v1</link><description>Are large language models (LLMs) sensitive to the distinction between humanlypossible languages and humanly impossible languages? This question is taken bymany to bear on whether LLMs and humans share the same innate learning biases.Previous work has attempted to answer it in the positive by comparing LLMlearning curves on existing language datasets and on "impossible" datasetsderived from them via various perturbation functions. Using the samemethodology, we examine this claim on a wider set of languages and impossibleperturbations. We find that in most cases, GPT-2 learns each language and itsimpossible counterpart equally easily, in contrast to previous claims. We alsoapply a more lenient condition by testing whether GPT-2 provides any kind ofseparation between the whole set of natural languages and the whole set ofimpossible languages. By considering cross-linguistic variance in variousmetrics computed on the perplexity curves, we show that GPT-2 provides nosystematic separation between the possible and the impossible. Taken together,these perspectives show that LLMs do not share the human innate biases thatshape linguistic typology.</description><author>Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir</author><pubDate>Wed, 08 Oct 2025 16:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07178v1</guid></item><item><title>CARPAS: Towards Content-Aware Refinement of Provided Aspects for Summarization in Large Language Models</title><link>http://arxiv.org/abs/2510.07177v1</link><description>Aspect-based summarization has attracted significant attention for itsability to generate more fine-grained and user-aligned summaries. While mostexisting approaches assume a set of predefined aspects as input, real-worldscenarios often present challenges where these given aspects may be incomplete,irrelevant, or entirely missing from the document. Users frequently expectsystems to adaptively refine or filter the provided aspects based on the actualcontent. In this paper, we initiate this novel task setting, termedContent-Aware Refinement of Provided Aspects for Summarization (CARPAS), withthe aim of dynamically adjusting the provided aspects based on the documentcontext before summarizing. We construct three new datasets to facilitate ourpilot experiments, and by using LLMs with four representative promptingstrategies in this task, we find that LLMs tend to predict an overlycomprehensive set of aspects, which often results in excessively long andmisaligned summaries. Building on this observation, we propose a preliminarysubtask to predict the number of relevant aspects, and demonstrate that thepredicted number can serve as effective guidance for the LLMs, reducing theinference difficulty, and enabling them to focus on the most pertinent aspects.Our extensive experiments show that the proposed approach significantlyimproves performance across all datasets. Moreover, our deeper analyses uncoverLLMs' compliance when the requested number of aspects differs from their ownestimations, establishing a crucial insight for the deployment of LLMs insimilar real-world applications.</description><author>Yong-En Tian, Yu-Chien Tang, An-Zi Yen, Wen-Chih Peng</author><pubDate>Wed, 08 Oct 2025 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07177v1</guid></item><item><title>Quantifying Data Contamination in Psychometric Evaluations of LLMs</title><link>http://arxiv.org/abs/2510.07175v1</link><description>Recent studies apply psychometric questionnaires to Large Language Models(LLMs) to assess high-level psychological constructs such as values,personality, moral foundations, and dark traits. Although prior work has raisedconcerns about possible data contamination from psychometric inventories, whichmay threaten the reliability of such evaluations, there has been no systematicattempt to quantify the extent of this contamination. To address this gap, wepropose a framework to systematically measure data contamination inpsychometric evaluations of LLMs, evaluating three aspects: (1) itemmemorization, (2) evaluation memorization, and (3) target score matching.Applying this framework to 21 models from major families and four widely usedpsychometric inventories, we provide evidence that popular inventories such asthe Big Five Inventory (BFI-44) and Portrait Values Questionnaire (PVQ-40)exhibit strong contamination, where models not only memorize items but can alsoadjust their responses to achieve specific target scores.</description><author>Jongwook Han, Woojung Song, Jonggeun Lee, Yohan Jo</author><pubDate>Wed, 08 Oct 2025 16:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07175v1</guid></item><item><title>NurseLLM: The First Specialized Language Model for Nursing</title><link>http://arxiv.org/abs/2510.07173v1</link><description>Recent advancements in large language models (LLMs) have significantlytransformed medical systems. However, their potential within specializeddomains such as nursing remains largely underexplored. In this work, weintroduce NurseLLM, the first nursing-specialized LLM tailored for multiplechoice question-answering (MCQ) tasks. We develop a multi-stage data generationpipeline to build the first large scale nursing MCQ dataset to train LLMs on abroad spectrum of nursing topics. We further introduce multiple nursingbenchmarks to enable rigorous evaluation. Our extensive experiments demonstratethat NurseLLM outperforms SoTA general-purpose and medical-specialized LLMs ofcomparable size on different benchmarks, underscoring the importance of aspecialized LLM for the nursing domain. Finally, we explore the role ofreasoning and multi-agent collaboration systems in nursing, highlighting theirpromise for future research and applications.</description><author>Md Tawkat Islam Khondaker, Julia Harrington, Shady Shehata</author><pubDate>Wed, 08 Oct 2025 16:15:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.07173v1</guid></item></channel></rss>