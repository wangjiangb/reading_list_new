<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 18 Aug 2025 19:03:25 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>3D Whole-body Grasp Synthesis with Directional Controllability</title><link>http://arxiv.org/abs/2408.16770v2</link><description>Synthesizing 3D whole bodies that realistically grasp objects is useful foranimation, mixed reality, and robotics. This is challenging, because the handsand body need to look natural w.r.t. each other, the grasped object, as well asthe local scene (i.e., a receptacle supporting the object). Moreover, trainingdata for this task is really scarce, while capturing new data is expensive.Recent work goes beyond finite datasets via a divide-and-conquer approach; itfirst generates a "guiding" right-hand grasp, and then searches for bodies thatmatch this. However, the guiding-hand synthesis lacks controllability andreceptacle awareness, so it likely has an implausible direction (i.e., a bodycan't match this without penetrating the receptacle) and needs correctionsthrough major post-processing. Moreover, the body search needs exhaustivesampling and is expensive. These are strong limitations. We tackle these with anovel method called CWGrasp. Our key idea is that performing geometry-basedreasoning "early on," instead of "too late," provides rich "control" signalsfor inference. To this end, CWGrasp first samples a plausiblereaching-direction vector (used later for both the arm and hand) from aprobabilistic model built via ray-casting from the object and collisionchecking. Moreover, CWGrasp uniquely tackles both right and left-hand grasps.We evaluate on the GRAB and ReplicaGrasp datasets. CWGrasp outperformsbaselines, at lower runtime and budget, while all components help performance.Code and models are available at https://gpaschalidis.github.io/cwgrasp.</description><author>Georgios Paschalidis, Romana Wilschut, Dimitrije AntiÄ‡, Omid Taheri, Dimitrios Tzionas</author><pubDate>Mon, 17 Feb 2025 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16770v2</guid></item><item><title>Diffusion Models without Classifier-free Guidance</title><link>http://arxiv.org/abs/2502.12154v1</link><description>This paper presents Model-guidance (MG), a novel objective for trainingdiffusion model that addresses and removes of the commonly used Classifier-freeguidance (CFG). Our innovative approach transcends the standard modeling ofsolely data distribution to incorporating the posterior probability ofconditions. The proposed technique originates from the idea of CFG and is easyyet effective, making it a plug-and-play module for existing models. Our methodsignificantly accelerates the training process, doubles the inference speed,and achieve exceptional quality that parallel and even surpass concurrentdiffusion models with CFG. Extensive experiments demonstrate the effectiveness,efficiency, scalability on different models and datasets. Finally, we establishstate-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.Our code is available at https://github.com/tzco/Diffusion-wo-CFG.</description><author>Zhicong Tang, Jianmin Bao, Dong Chen, Baining Guo</author><pubDate>Mon, 17 Feb 2025 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12154v1</guid></item><item><title>Learning Getting-Up Policies for Real-World Humanoid Robots</title><link>http://arxiv.org/abs/2502.12152v1</link><description>Automatic fall recovery is a crucial prerequisite before humanoid robots canbe reliably deployed. Hand-designing controllers for getting up is difficultbecause of the varied configurations a humanoid can end up in after a fall andthe challenging terrains humanoid robots are expected to operate on. This paperdevelops a learning framework to produce controllers that enable humanoidrobots to get up from varying configurations on varying terrains. Unlikeprevious successful applications of humanoid locomotion learning, thegetting-up task involves complex contact patterns, which necessitatesaccurately modeling the collision geometry and sparser rewards. We addressthese challenges through a two-phase approach that follows a curriculum. Thefirst stage focuses on discovering a good getting-up trajectory under minimalconstraints on smoothness or speed / torque limits. The second stage thenrefines the discovered motions into deployable (i.e. smooth and slow) motionsthat are robust to variations in initial configuration and terrains. We findthese innovations enable a real-world G1 humanoid robot to get up from two mainsituations that we considered: a) lying face up and b) lying face down, bothtested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grassand snowfield). To the best of our knowledge, this is the first successfuldemonstration of learned getting-up policies for human-sized humanoid robots inthe real world. Project page: https://humanoid-getup.github.io/</description><author>Xialin He, Runpei Dong, Zixuan Chen, Saurabh Gupta</author><pubDate>Mon, 17 Feb 2025 18:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12152v1</guid></item><item><title>VoLUT: Efficient Volumetric streaming enhanced by LUT-based super-resolution</title><link>http://arxiv.org/abs/2502.12151v1</link><description>3D volumetric video provides immersive experience and is gaining traction indigital media. Despite its rising popularity, the streaming of volumetric videocontent poses significant challenges due to the high data bandwidthrequirement. A natural approach to mitigate the bandwidth issue is to reducethe volumetric video's data rate by downsampling the content prior totransmission. The video can then be upsampled at the receiver's end using asuper-resolution (SR) algorithm to reconstruct the high-resolution details.While super-resolution techniques have been extensively explored and advancedfor 2D video content, there is limited work on SR algorithms tailored forvolumetric videos. To address this gap and the growing need for efficient volumetric videostreaming, we have developed VoLUT with a new SR algorithm specificallydesigned for volumetric content. Our algorithm uniquely harnesses the power oflookup tables (LUTs) to facilitate the efficient and accurate upscaling oflow-resolution volumetric data. The use of LUTs enables our algorithm toquickly reference precomputed high-resolution values, thereby significantlyreducing the computational complexity and time required for upscaling. Wefurther apply adaptive video bit rate algorithm (ABR) to dynamically determinethe downsampling rate according to the network condition and stream theselected video rate to the receiver. Compared to related work, VoLUT is thefirst to enable high-quality 3D SR on commodity mobile devices at line-rate.Our evaluation shows VoLUT can reduce bandwidth usage by 70% , boost QoE by36.7% for volumetric video streaming and achieve 3D SR speed-up with no quality compromise.</description><author>Chendong Wang, Anlan Zhang, Yifan Yang, Lili Qiu, Yuqing Yang, Xinyang Jiang, Feng Qian, Suman Banerjee</author><pubDate>Mon, 17 Feb 2025 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12151v1</guid></item><item><title>Idiosyncrasies in Large Language Models</title><link>http://arxiv.org/abs/2502.12150v1</link><description>In this work, we unveil and study idiosyncrasies in Large Language Models(LLMs) -- unique patterns in their outputs that can be used to distinguish themodels. To do so, we consider a simple classification task: given a particulartext output, the objective is to predict the source LLM that generates thetext. We evaluate this synthetic task across various groups of LLMs and findthat simply fine-tuning existing text embedding models on LLM-generated textsyields excellent classification accuracy. Notably, we achieve 97.1% accuracy onheld-out validation data in the five-way classification problem involvingChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation revealsthat these idiosyncrasies are rooted in word-level distributions. Thesepatterns persist even when the texts are rewritten, translated, or summarizedby an external LLM, suggesting that they are also encoded in the semanticcontent. Additionally, we leverage LLM as judges to generate detailed,open-ended descriptions of each model's idiosyncrasies. Finally, we discuss thebroader implications of our findings, particularly for training on syntheticdata and inferring model similarity. Code is available athttps://github.com/locuslab/llm-idiosyncrasies.</description><author>Mingjie Sun, Yida Yin, Zhiqiu Xu, J. Zico Kolter, Zhuang Liu</author><pubDate>Mon, 17 Feb 2025 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12150v1</guid></item><item><title>HARBOR: Exploring Persona Dynamics in Multi-Agent Competition</title><link>http://arxiv.org/abs/2502.12149v1</link><description>We investigate factors contributing to LLM agents' success in competitivemulti-agent environments, using auctions as a testbed where agents bid tomaximize profit. The agents are equipped with bidding domain knowledge,distinct personas that reflect item preferences, and a memory of auctionhistory. Our work extends the classic auction scenario by creating a realisticenvironment where multiple agents bid on houses, weighing aspects such as size,location, and budget to secure the most desirable homes at the lowest prices.Particularly, we investigate three key questions: (a) How does a personainfluence an agent's behavior in a competitive setting? (b) Can an agenteffectively profile its competitors' behavior during auctions? (c) How canpersona profiling be leveraged to create an advantage using strategies such astheory of mind? Through a series of experiments, we analyze the behaviors ofLLM agents and shed light on new findings. Our testbed, called HARBOR, offers avaluable platform for deepening our understanding of multi-agent workflows incompetitive environments.</description><author>Kenan Jiang, Li Xiong, Fei Liu</author><pubDate>Mon, 17 Feb 2025 18:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12149v1</guid></item><item><title>HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2502.12148v1</link><description>The remarkable success of the autoregressive paradigm has made significantadvancement in Multimodal Large Language Models (MLLMs), with powerful modelslike Show-o, Transfusion and Emu3 achieving notable progress in unified imageunderstanding and generation. For the first time, we uncover a commonphenomenon: the understanding capabilities of MLLMs are typically stronger thantheir generative capabilities, with a significant gap between the two. Buildingon this insight, we propose HermesFlow, a simple yet general framework designedto seamlessly bridge the gap between understanding and generation in MLLMs.Specifically, we take the homologous data as input to curate homologouspreference data of both understanding and generation. Through Pair-DPO andself-play iterative optimization, HermesFlow effectively aligns multimodalunderstanding and generation using homologous preference data. Extensiveexperiments demonstrate the significant superiority of our approach over priormethods, particularly in narrowing the gap between multimodal understanding andgeneration. These findings highlight the potential of HermesFlow as a generalalignment framework for next-generation multimodal foundation models. Code:https://github.com/Gen-Verse/HermesFlow</description><author>Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui</author><pubDate>Mon, 17 Feb 2025 18:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12148v1</guid></item><item><title>Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction</title><link>http://arxiv.org/abs/2502.12147v1</link><description>Machine learning interatomic potentials (MLIPs) have become increasinglyeffective at approximating quantum mechanical calculations at a fraction of thecomputational cost. However, lower errors on held out test sets do not alwaystranslate to improved results on downstream physical property prediction tasks.In this paper, we propose testing MLIPs on their practical ability to conserveenergy during molecular dynamic simulations. If passed, improved correlationsare found between test errors and their performance on physical propertyprediction tasks. We identify choices which may lead to models failing thistest, and use these observations to improve upon highly-expressive models. Theresulting model, eSEN, provides state-of-the-art results on a range of physicalproperty prediction tasks, including materials stability prediction, thermalconductivity prediction, and phonon calculations.</description><author>Xiang Fu, Brandon M. Wood, Luis Barroso-Luque, Daniel S. Levine, Meng Gao, Misko Dzamba, C. Lawrence Zitnick</author><pubDate>Mon, 17 Feb 2025 18:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12147v1</guid></item><item><title>Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening</title><link>http://arxiv.org/abs/2502.12146v1</link><description>We propose Diffusion-Sharpening, a fine-tuning approach that enhancesdownstream alignment by optimizing sampling trajectories. Existing RL-basedfine-tuning methods focus on single training timesteps and neglecttrajectory-level alignment, while recent sampling trajectory optimizationmethods incur significant inference NFE costs. Diffusion-Sharpening overcomesthis by using a path integral framework to select optimal trajectories duringtraining, leveraging reward feedback, and amortizing inference costs. Ourmethod demonstrates superior training efficiency with faster convergence, andbest inference efficiency without requiring additional NFEs. Extensiveexperiments show that Diffusion-Sharpening outperforms RL-based fine-tuningmethods (e.g., Diffusion-DPO) and sampling trajectory optimization methods(e.g., Inference Scaling) across diverse metrics including text alignment,compositional capabilities, and human preferences, offering a scalable andefficient solution for future diffusion model fine-tuning. Code:https://github.com/Gen-Verse/Diffusion-Sharpening</description><author>Ye Tian, Ling Yang, Xinchen Zhang, Yunhai Tong, Mengdi Wang, Bin Cui</author><pubDate>Mon, 17 Feb 2025 18:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12146v1</guid></item><item><title>Logical forms complement probability in understanding language model (and human) performance</title><link>http://arxiv.org/abs/2502.09589v2</link><description>With the increasing interest in using large language models (LLMs) forplanning in natural language, understanding their behaviors becomes animportant research question. This work conducts a systematic investigation ofLLMs' ability to perform logical reasoning in natural language. We introduce acontrolled dataset of hypothetical and disjunctive syllogisms in propositionaland modal logic and use it as the testbed for understanding LLM performance.Our results lead to novel insights in predicting LLM behaviors: in addition tothe probability of input (Gonen et al., 2023; McCoy et al., 2024), logicalforms should be considered as important factors. In addition, we showsimilarities and discrepancies between the logical reasoning performances ofhumans and LLMs by collecting and comparing behavioral data from both.</description><author>Yixuan Wang, Freda Shi</author><pubDate>Mon, 17 Feb 2025 18:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09589v2</guid></item><item><title>Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented Generation with Flexible User Control</title><link>http://arxiv.org/abs/2502.12145v1</link><description>Retrieval-Augmented Generation (RAG) has emerged as a powerful approach tomitigate large language model (LLM) hallucinations by incorporating externalknowledge retrieval. However, existing RAG frameworks often apply retrievalindiscriminately,leading to inefficiencies-over-retrieving when unnecessary orfailing to retrieve iteratively when required for complex reasoning. Recentadaptive retrieval strategies, though adaptively navigates these retrievalstrategies, predict only based on query complexity and lacks user-drivenflexibility, making them infeasible for diverse user application needs. In thispaper, we introduce a novel user-controllable RAG framework that enablesdynamic adjustment of the accuracy-cost trade-off. Our approach leverages twoclassifiers: one trained to prioritize accuracy and another to prioritizeretrieval efficiency. Via an interpretable control parameter $\alpha$, userscan seamlessly navigate between minimal-cost retrieval and high-accuracyretrieval based on their specific requirements. We empirically demonstrate thatour approach effectively balances accuracy, retrieval cost, and usercontrollability, making it a practical and adaptable solution for real-worldapplications.</description><author>Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie</author><pubDate>Mon, 17 Feb 2025 18:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12145v1</guid></item><item><title>Small Models Struggle to Learn from Strong Reasoners</title><link>http://arxiv.org/abs/2502.12143v1</link><description>Large language models (LLMs) excel in complex reasoning tasks, and distillingtheir reasoning capabilities into smaller models has shown promise. However, weuncover an interesting phenomenon, which we term the Small Model LearnabilityGap: small models ($\leq$3B parameters) do not consistently benefit from longchain-of-thought (CoT) reasoning or distillation from larger models. Instead,they perform better when fine-tuned on shorter, simpler reasoning chains thatbetter align with their intrinsic learning capacity. To address this, wepropose Mix Distillation, a simple yet effective strategy that balancesreasoning complexity by combining long and short CoT examples or reasoning fromboth larger and smaller models. Our experiments demonstrate that MixDistillation significantly improves small model reasoning performance comparedto training on either data alone. These findings highlight the limitations ofdirect strong model distillation and underscore the importance of adaptingreasoning complexity for effective reasoning capability transfer.</description><author>Yuetai Li, Xiang Yue, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Bhaskar Ramasubramanian, Radha Poovendran</author><pubDate>Mon, 17 Feb 2025 18:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12143v1</guid></item><item><title>MaLei at the PLABA Track of TREC 2024: RoBERTa for Term Replacement -- LLaMA3.1 and GPT-4o for Complete Abstract Adaptation</title><link>http://arxiv.org/abs/2411.07381v4</link><description>This report is the system description of the MaLei team (Manchester andLeiden) for the shared task Plain Language Adaptation of Biomedical Abstracts(PLABA) 2024 (we had an earlier name BeeManc following last year), affiliatedwith TREC2024 (33rd Text REtrieval Conferencehttps://ir.nist.gov/evalbase/conf/trec-2024). This report contains two sectionscorresponding to the two sub-tasks in PLABA-2024. In task one (termreplacement), we applied fine-tuned ReBERTa-Base models to identify andclassify the difficult terms, jargon, and acronyms in the biomedical abstractsand reported the F1 score (Task 1A and 1B). In task two (complete abstractadaptation), we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shotprompts to complete the abstract adaptation and reported the scores in BLEU,SARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024on Task 1A and 1B, our much smaller fine-tuned RoBERTa-Base model ranked 3rdand 2nd respectively on the two sub-tasks, and the 1st on averaged F1 scoresacross the two tasks from 9 evaluated systems. Our LLaMA-3.1-70B-instructedmodel achieved the highest Completeness score for Task 2. We share our sourcecodes, fine-tuned models, and related resources athttps://github.com/HECTA-UoM/PLABA2024</description><author>Zhidong Ling, Zihao Li, Pablo Romero, Lifeng Han, Goran Nenadic</author><pubDate>Mon, 17 Feb 2025 18:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07381v4</guid></item><item><title>FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views</title><link>http://arxiv.org/abs/2502.12138v1</link><description>We present FLARE, a feed-forward model designed to infer high-quality cameraposes and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8inputs), which is a challenging yet practical setting in real-worldapplications. Our solution features a cascaded learning paradigm with camerapose serving as the critical bridge, recognizing its essential role in mapping3D structures onto 2D image planes. Concretely, FLARE starts with camera poseestimation, whose results condition the subsequent learning of geometricstructure and appearance, optimized through the objectives of geometryreconstruction and novel-view synthesis. Utilizing large-scale public datasetsfor training, our method delivers state-of-the-art performance in the tasks ofpose estimation, geometry reconstruction, and novel view synthesis, whilemaintaining the inference efficiency (i.e., less than 0.5 seconds). The projectpage and code can be found at: https://zhanghe3z.github.io/FLARE/</description><author>Shangzhan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein</author><pubDate>Mon, 17 Feb 2025 18:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12138v1</guid></item><item><title>REVERSUM: A Multi-staged Retrieval-Augmented Generation Method to Enhance Wikipedia Tail Biographies through Personal Narratives</title><link>http://arxiv.org/abs/2502.12137v1</link><description>Wikipedia is an invaluable resource for factual information about a widerange of entities. However, the quality of articles on less-known entitiesoften lags behind that of the well-known ones. This study proposes a novelapproach to enhancing Wikipedia's B and C category biography articles byleveraging personal narratives such as autobiographies and biographies. Byutilizing a multi-staged retrieval-augmented generation technique -- REVerSum-- we aim to enrich the informational content of these lesser-known articles.Our study reveals that personal narratives can significantly improve thequality of Wikipedia articles, providing a rich source of reliable informationthat has been underutilized in previous studies. Based on crowd-basedevaluation, REVerSum generated content outperforms the best performing baselineby 17% in terms of integrability to the original Wikipedia article and 28.5\%in terms of informativeness. Code and Data are available at:https://github.com/sayantan11995/wikipedia_enrichment</description><author>Sayantan Adak, Pauras Mangesh Meher, Paramita Das, Animesh Mukherjee</author><pubDate>Mon, 17 Feb 2025 18:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12137v1</guid></item><item><title>MagicArticulate: Make Your 3D Models Articulation-Ready</title><link>http://arxiv.org/abs/2502.12135v1</link><description>With the explosive growth of 3D content creation, there is an increasingdemand for automatically converting static 3D models into articulation-readyversions that support realistic animation. Traditional approaches rely heavilyon manual annotation, which is both time-consuming and labor-intensive.Moreover, the lack of large-scale benchmarks has hindered the development oflearning-based solutions. In this work, we present MagicArticulate, aneffective framework that automatically transforms static 3D models intoarticulation-ready assets. Our key contributions are threefold. First, weintroduce Articulation-XL, a large-scale benchmark containing over 33k 3Dmodels with high-quality articulation annotations, carefully curated fromObjaverse-XL. Second, we propose a novel skeleton generation method thatformulates the task as a sequence modeling problem, leveraging anauto-regressive transformer to naturally handle varying numbers of bones orjoints within skeletons and their inherent dependencies across different 3Dmodels. Third, we predict skinning weights using a functional diffusion processthat incorporates volumetric geodesic distance priors between vertices andjoints. Extensive experiments demonstrate that MagicArticulate significantlyoutperforms existing methods across diverse object categories, achievinghigh-quality articulation that enables realistic animation. Project page:https://chaoyuesong.github.io/MagicArticulate.</description><author>Chaoyue Song, Jianfeng Zhang, Xiu Li, Fan Yang, Yiwen Chen, Zhongcong Xu, Jun Hao Liew, Xiaoyang Guo, Fayao Liu, Jiashi Feng, Guosheng Lin</author><pubDate>Mon, 17 Feb 2025 18:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12135v1</guid></item><item><title>Splitting criteria for ordinal decision trees: an experimental study</title><link>http://arxiv.org/abs/2412.13697v2</link><description>Ordinal Classification (OC) is a machine learning field that addressesclassification tasks where the labels exhibit a natural order. Unlike nominalclassification, which treats all classes as equally distinct, OC takes theordinal relationship into account, producing more accurate and relevantresults. This is particularly critical in applications where the magnitude ofclassification errors has implications. Despite this, OC problems are oftentackled using nominal methods, leading to suboptimal solutions. Althoughdecision trees are one of the most popular classification approaches, ordinaltree-based approaches have received less attention when compared to otherclassifiers. This work conducts an experimental study of tree-basedmethodologies specifically designed to capture ordinal relationships. Acomprehensive survey of ordinal splitting criteria is provided, standardisingthe notations used in the literature for clarity. Three ordinal splittingcriteria, Ordinal Gini (OGini), Weighted Information Gain (WIG), and RankingImpurity (RI), are compared to the nominal counterparts of the first two (Giniand information gain), by incorporating them into a decision tree classifier.An extensive repository considering 45 publicly available OC datasets ispresented, supporting the first experimental comparison of ordinal and nominalsplitting criteria using well-known OC evaluation metrics. Statistical analysisof the results highlights OGini as the most effective ordinal splittingcriterion to date. Source code, datasets, and results are made available to theresearch community.</description><author>Rafael AyllÃ³n-GavilÃ¡n, Francisco JosÃ© MartÃ­nez-Estudillo, David Guijo-Rubio, CÃ©sar HervÃ¡s-MartÃ­nez, Pedro Antonio GutiÃ©rrez</author><pubDate>Mon, 17 Feb 2025 18:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13697v2</guid></item><item><title>SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs</title><link>http://arxiv.org/abs/2502.12134v1</link><description>Chain-of-Thought (CoT) reasoning enables Large Language Models (LLMs) tosolve complex reasoning tasks by generating intermediate reasoning steps.However, most existing approaches focus on hard token decoding, whichconstrains reasoning within the discrete vocabulary space and may not always beoptimal. While recent efforts explore continuous-space reasoning, they oftensuffer from catastrophic forgetting, limiting their applicability tostate-of-the-art LLMs that already perform well in zero-shot settings with aproper instruction. To address this challenge, we propose a novel approach forcontinuous-space reasoning that does not require modifying the underlying LLM.Specifically, we employ a lightweight assistant model to generateinstance-specific soft thought tokens speculatively as the initial chain ofthoughts, which are then mapped into the LLM's representation space via aprojection module. Experimental results on five reasoning benchmarksdemonstrate that our method enhances LLM reasoning performance throughsupervised, parameter-efficient fine-tuning.</description><author>Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao</author><pubDate>Mon, 17 Feb 2025 18:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12134v1</guid></item><item><title>OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain</title><link>http://arxiv.org/abs/2412.13018v2</link><description>As a typical and practical application of Large Language Models (LLMs),Retrieval-Augmented Generation (RAG) techniques have gained extensiveattention, particularly in vertical domains where LLMs may lack domain-specificknowledge. In this paper, we introduce an omnidirectional and automatic RAGbenchmark, OmniEval, in the financial domain. Our benchmark is characterized byits multi-dimensional evaluation framework, including (1) a matrix-based RAGscenario evaluation system that categorizes queries into five task classes and16 financial topics, leading to a structured assessment of diverse queryscenarios; (2) a multi-dimensional evaluation data generation approach, whichcombines GPT-4-based automatic generation and human annotation, achieving an87.47\% acceptance ratio in human evaluations on generated instances; (3) amulti-stage evaluation system that evaluates both retrieval and generationperformance, result in a comprehensive evaluation on the RAG pipeline; and (4)robust evaluation metrics derived from rule-based and LLM-based ones, enhancingthe reliability of assessments through manual annotations and supervisedfine-tuning of an LLM evaluator. Our experiments demonstrate thecomprehensiveness of OmniEval, which includes extensive test datasets andhighlights the performance variations of RAG systems across diverse topics andtasks, revealing significant opportunities for RAG models to improve theircapabilities in vertical domains. We open source the code of our benchmark in\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.</description><author>Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen</author><pubDate>Mon, 17 Feb 2025 18:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13018v2</guid></item><item><title>Transformer Dynamics: A neuroscientific approach to interpretability of large language models</title><link>http://arxiv.org/abs/2502.12131v1</link><description>As artificial intelligence models have exploded in scale and capability,understanding of their internal mechanisms remains a critical challenge.Inspired by the success of dynamical systems approaches in neuroscience, herewe propose a novel framework for studying computations in deep learningsystems. We focus on the residual stream (RS) in transformer models,conceptualizing it as a dynamical system evolving across layers. We find thatactivations of individual RS units exhibit strong continuity across layers,despite the RS being a non-privileged basis. Activations in the RS accelerateand grow denser over layers, while individual units trace unstable periodicorbits. In reduced-dimensional spaces, the RS follows a curved trajectory withattractor-like dynamics in the lower layers. These insights bridge dynamicalsystems theory and mechanistic interpretability, establishing a foundation fora "neuroscience of AI" that combines theoretical rigor with large-scale dataanalysis to advance our understanding of modern neural networks.</description><author>Jesseba Fernando, Grigori Guitchounts</author><pubDate>Mon, 17 Feb 2025 18:49:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12131v1</guid></item><item><title>Scaling Autonomous Agents via Automatic Reward Modeling And Planning</title><link>http://arxiv.org/abs/2502.12130v1</link><description>Large language models (LLMs) have demonstrated remarkable capabilities acrossa range of text-generation tasks. However, LLMs still struggle with problemsrequiring multi-step decision-making and environmental feedback, such as onlineshopping, scientific reasoning, and mathematical problem-solving. Unlike puretext data, collecting large-scale decision-making data is challenging.Moreover, many powerful LLMs are only accessible through APIs, which hinderstheir fine-tuning for agent tasks due to cost and complexity. To address LLMagents' limitations, we propose a framework that can automatically learn areward model from the environment without human annotations. This model can beused to evaluate the action trajectories of LLM agents and provide heuristicsfor task planning. Specifically, our approach involves employing one LLM-basedagent to navigate an environment randomly, generating diverse actiontrajectories. Subsequently, a separate LLM is leveraged to assign a task intentand synthesize a negative response alongside the correct response for eachtrajectory. These triplets (task intent, positive response, and negativeresponse) are then utilized as training data to optimize a reward model capableof scoring action trajectories. The effectiveness and generalizability of ourframework are demonstrated through evaluations conducted on different agentbenchmarks. In conclusion, our proposed framework represents a significantadvancement in enhancing LLM agents' decision-making capabilities. Byautomating the learning of reward models, we overcome the challenges of datascarcity and API limitations, potentially revolutionizing the application ofLLMs in complex and interactive environments. This research paves the way formore sophisticated AI agents capable of tackling a wide range of real-worldproblems requiring multi-step decision-making.</description><author>Zhenfang Chen, Delin Chen, Rui Sun, Wenjun Liu, Chuang Gan</author><pubDate>Mon, 17 Feb 2025 18:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12130v1</guid></item><item><title>LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities</title><link>http://arxiv.org/abs/2502.12128v1</link><description>Generative models are spearheading recent progress in deep learning, showingstrong promise for trajectory sampling in dynamical systems as well. However,while latent space modeling paradigms have transformed image and videogeneration, similar approaches are more difficult for most dynamical systems.Such systems -- from chemical molecule structures to collective human behavior-- are described by interactions of entities, making them inherently linked toconnectivity patterns and the traceability of entities over time. Our approach,LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via LinkedEntities), combines the advantages of graph neural networks, i.e., thetraceability of entities across time-steps, with the efficiency and scalabilityof recent advances in image and video generation, where pre-trained encoder anddecoder are frozen to enable generative modeling in the latent space. The coreidea of LaM-SLidE is to introduce identifier representations (IDs) to allow forretrieval of entity properties, e.g., entity coordinates, from latent systemrepresentations and thus enables traceability. Experimentally, across differentdomains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,and generalizability. (Code is available athttps://github.com/ml-jku/LaM-SLidE)</description><author>Florian Sestak, Artur Toshev, Andreas FÃ¼rst, GÃ¼nter Klambauer, Andreas Mayr, Johannes Brandstetter</author><pubDate>Mon, 17 Feb 2025 18:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12128v1</guid></item><item><title>Human-LLM Coevolution: Evidence from Academic Writing</title><link>http://arxiv.org/abs/2502.09606v2</link><description>With a statistical analysis of arXiv paper abstracts, we report a marked dropin the frequency of several words previously identified as overused by ChatGPT,such as "delve", starting soon after they were pointed out in early 2024. Thefrequency of certain other words favored by ChatGPT, such as "significant", hasinstead kept increasing. These phenomena suggest that some authors of academicpapers have adapted their use of large language models (LLMs), for example, byselecting outputs or applying modifications to the LLM-generated content. Suchcoevolution and cooperation of humans and LLMs thus introduce additionalchallenges to the detection of machine-generated text in real-world scenarios.Estimating the impact of LLMs on academic writing by examining word frequencyremains feasible, and more attention should be paid to words that were alreadyfrequently employed, including those that have decreased in frequency due toLLMs' disfavor.</description><author>Mingmeng Geng, Roberto Trotta</author><pubDate>Mon, 17 Feb 2025 18:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09606v2</guid></item><item><title>The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes</title><link>http://arxiv.org/abs/2405.20582v2</link><description>Negative patient descriptions and stigmatizing language can contribute togenerating healthcare disparities in two ways: (1) read by patients, they canharm their trust and engagement with the medical center; (2) read byphysicians, they may negatively influence their perspective of a futurepatient. In psychiatry, the patient-clinician therapeutic alliance is a majordeterminant of clinical outcomes. Therefore, language usage in psychiatricclinical notes may not only create healthcare disparities, but also perpetuatethem. Recent advances in NLP systems have facilitated the efforts to detectdiscriminatory language in healthcare. However, such attempts have only focusedon the perspectives of the medical center and its physicians. Considering bothphysicians and non-physicians' point of view is a more translatable approach toidentifying potentially harmful language in clinical notes. By leveragingpre-trained and large language models (PLMs and LLMs), this work aims tocharacterize potentially harmful language usage in psychiatric notes byidentifying the sentiment expressed in sentences describing patients based onthe reader's point of view. Extracting 39 sentences from the Mount Sinai HealthSystem containing psychiatric lexicon, we fine-tuned three PLMs (RoBERTa,GatorTron, and GatorTron + Task Adaptation) and implemented zero-shot andfew-shot ICL approaches for three LLMs (GPT-3.5, Llama-3.1, and Mistral) toclassify the sentiment of the sentences according to the physician ornon-physician point of view. Results showed that GPT-3.5 aligned best tophysician point of view and Mistral aligned best to non-physician point ofview. These results underline the importance of recognizing the reader's pointof view, not only for improving the note writing process, but also for thequantification, identification, and reduction of bias in computational systemsfor downstream analyses.</description><author>Alissa A. Valentine, Lauren A. Lepow, Lili Chan, Alexander W. Charney, Isotta Landi</author><pubDate>Mon, 17 Feb 2025 18:48:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20582v2</guid></item><item><title>Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens of Class Hierarchy</title><link>http://arxiv.org/abs/2502.12125v1</link><description>We investigate the training dynamics of deep classifiers by examining howhierarchical relationships between classes evolve during training. Throughextensive experiments, we argue that the learning process in classificationproblems can be understood through the lens of label clustering. Specifically,we observe that networks tend to distinguish higher-level (hypernym) categoriesin the early stages of training, and learn more specific (hyponym) categorieslater. We introduce a novel framework to track the evolution of the featuremanifold during training, revealing how the hierarchy of class relationsemerges and refines across the network layers. Our analysis demonstrates thatthe learned representations closely align with the semantic structure of thedataset, providing a quantitative description of the clustering process.Notably, we show that in the hypernym label space, certain properties of neuralcollapse appear earlier than in the hyponym label space, helping to bridge thegap between the initial and terminal phases of learning. We believe ourfindings offer new insights into the mechanisms driving hierarchical learningin deep networks, paving the way for future advancements in understanding deeplearning dynamics.</description><author>Roman Malashin, Valeria Yachnaya, Alexander Mullin</author><pubDate>Mon, 17 Feb 2025 18:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12125v1</guid></item><item><title>RA-MTR: A Retrieval Augmented Multi-Task Reader based Approach for Inspirational Quote Extraction from Long Documents</title><link>http://arxiv.org/abs/2502.12124v1</link><description>Inspirational quotes from famous individuals are often used to conveythoughts in news articles, essays, and everyday conversations. In this paper,we propose a novel context-based quote extraction system that aims to extractthe most relevant quote from a long text. We formulate this quote extraction asan open domain question answering problem first by employing a vector-storebased retriever and then applying a multi-task reader. We curate threecontext-based quote extraction datasets and introduce a novel multi-taskframework RA-MTR that improves the state-of-the-art performance, achieving amaximum improvement of 5.08% in BoW F1-score.</description><author>Sayantan Adak, Animesh Mukherjee</author><pubDate>Mon, 17 Feb 2025 18:46:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12124v1</guid></item><item><title>On the Query Complexity of Verifier-Assisted Language Generation</title><link>http://arxiv.org/abs/2502.12123v1</link><description>Recently, a plethora of works have proposed inference-time algorithms (e.g.best-of-n), which incorporate verifiers to assist the generation process. Theirquality-efficiency trade-offs have been empirically benchmarked on a variety ofconstrained generation tasks, but the algorithmic design landscape is stilllargely poorly understood. In this paper, we develop a mathematical frameworkfor reasoning about constrained generation using a pre-trained language modelgenerator oracle and a process verifier--which can decide whether a prefix canbe extended to a string which satisfies the constraints of choice. We show thateven in very simple settings, access to a verifier can render an intractableproblem (information-theoretically or computationally) to a tractable one. Infact, we show even simple algorithms, like tokenwise rejection sampling, canenjoy significant benefits from access to a verifier. Empirically, we show thata natural modification of tokenwise rejection sampling, in which the sampler isallowed to "backtrack" (i.e., erase the final few generated tokens) has robustand substantive benefits over natural baselines (e.g. (blockwise) rejectionsampling, nucleus sampling)--both in terms of computational efficiency,accuracy and diversity.</description><author>Edoardo Botta, Yuchen Li, Aashay Mehta, Jordan T. Ash, Cyril Zhang, Andrej Risteski</author><pubDate>Mon, 17 Feb 2025 18:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12123v1</guid></item><item><title>Minimal Ranks, Maximum Confidence: Parameter-efficient Uncertainty Quantification for LoRA</title><link>http://arxiv.org/abs/2502.12122v1</link><description>Low-Rank Adaptation (LoRA) enables parameter-efficient fine-tuning of largelanguage models by decomposing weight updates into low-rank matrices,significantly reducing storage and computational overhead. While effective,standard LoRA lacks mechanisms for uncertainty quantification, leading tooverconfident and poorly calibrated models. Bayesian variants of LoRA addressthis limitation, but at the cost of a significantly increased number oftrainable parameters, partially offsetting the original efficiency gains.Additionally, these models are harder to train and may suffer from unstableconvergence. In this work, we propose a novel parameter-efficient Bayesian LoRA,demonstrating that effective uncertainty quantification can be achieved in verylow-dimensional parameter spaces. The proposed method achieves strongperformance with improved calibration and generalization while maintainingcomputational efficiency. Our empirical findings show that, with theappropriate projection of the weight space: (1) uncertainty can be effectivelymodeled in a low-dimensional space, and (2) weight covariances exhibit lowranks.</description><author>Patryk MarszaÅ‚ek, Klaudia BaÅ‚azy, Jacek Tabor, Tomasz KuÅ›mierczyk</author><pubDate>Mon, 17 Feb 2025 18:46:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12122v1</guid></item><item><title>LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws</title><link>http://arxiv.org/abs/2502.12120v1</link><description>Scaling laws guide the development of large language models (LLMs) byoffering estimates for the optimal balance of model size, tokens, and compute.More recently, loss-to-loss scaling laws that relate losses across pretrainingdatasets and downstream tasks have emerged as a powerful tool for understandingand improving LLM performance. In this work, we investigate which factors moststrongly influence loss-to-loss scaling. Our experiments reveal that thepretraining data and tokenizer determine the scaling trend. In contrast, modelsize, optimization hyperparameters, and even significant architecturaldifferences, such as between transformer-based models like Llama andstate-space models like Mamba, have limited impact. Consequently, practitionersshould carefully curate suitable pretraining datasets for optimal downstreamperformance, while architectures and other settings can be freely optimized fortraining efficiency.</description><author>Prasanna Mayilvahanan, ThaddÃ¤us Wiedemer, Sayak Mallick, Matthias Bethge, Wieland Brendel</author><pubDate>Mon, 17 Feb 2025 18:45:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12120v1</guid></item><item><title>PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection</title><link>http://arxiv.org/abs/2502.12119v1</link><description>Visual instruction tuning refines pre-trained Multimodal Large LanguageModels (MLLMs) to enhance their real-world task performance. However, the rapidexpansion of visual instruction datasets introduces significant dataredundancy, leading to excessive computational costs. Existing data selectionmethods predominantly rely on proxy models or loss-based metrics, both of whichimpose substantial computational overheads due to the necessity of modelinference and backpropagation. To address this challenge, we propose PRISM, anovel training-free approach for efficient multimodal data selection. Unlikeexisting methods, PRISM eliminates the reliance on proxy models, warm-uppretraining, and gradient-based optimization. Instead, it leverages Pearsoncorrelation analysis to quantify the intrinsic visual encoding properties ofMLLMs, computing a task-specific correlation score to identify high-valueinstances. This not only enbles data-efficient selection,but maintains theoriginal performance. Empirical evaluations across multiple MLLMs demonstratethat PRISM reduces the overall time required for visual instruction tuning anddata selection to just 30% of conventional methods, while surpassing fullyfine-tuned models across eight multimodal and three language understandingbenchmarks, achieving a 101.7% relative improvement in final performance.</description><author>Jinhe Bi, Yifan Wang, Danqi Yan, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma</author><pubDate>Mon, 17 Feb 2025 18:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12119v1</guid></item><item><title>Scaling Test-Time Compute Without Verification or RL is Suboptimal</title><link>http://arxiv.org/abs/2502.12118v1</link><description>Despite substantial advances in scaling test-time compute, an ongoing debatein the community is how it should be scaled up to enable continued andefficient improvements with scaling. There are largely two approaches: first,distilling successful search or thinking traces; and second, using verification(e.g., 0/1 outcome rewards, reward models, or verifiers) to guide reinforcementlearning (RL) and search algorithms. In this paper, we prove that finetuningLLMs with verifier-based (VB) methods based on RL or search is far superior toverifier-free (VF) approaches based on distilling or cloning search traces,given a fixed amount of compute/data budget. Further, we show that as we scaletest-time compute (measured as the output token length) and training data,suboptimality of VF methods scales poorly compared to VB when the basepre-trained LLM presents a heterogeneous distribution over correct solutiontraces (e.g., different lengths, styles, etc.) and admits a non-sharpdistribution over rewards on traces sampled from it. We formalize thiscondition using anti-concentration [Erd\H{o}s, 1945]. This implies a strongerresult that VB methods scale better asymptotically, with the performance gapbetween VB and VF methods widening as test-time budget grows. We corroborateour theory empirically on both didactic and math reasoning problems with3/8/32B-sized pre-trained LLMs, where we find verification is crucial forscaling test-time compute.</description><author>Amrith Setlur, Nived Rajaraman, Sergey Levine, Aviral Kumar</author><pubDate>Mon, 17 Feb 2025 18:43:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12118v1</guid></item><item><title>Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models</title><link>http://arxiv.org/abs/2502.09782v2</link><description>The increasing prevalence of microphones in everyday devices and the growingreliance on online services have amplified the risk of acoustic side-channelattacks (ASCAs) targeting keyboards. This study explores deep learningtechniques, specifically vision transformers (VTs) and large language models(LLMs), to enhance the effectiveness and applicability of such attacks. Wepresent substantial improvements over prior research, with the CoAtNet modelachieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvementfor keystrokes recorded via smartphone (Phone) and 5.9% for those recorded viaZoom compared to previous benchmarks. We also evaluate transformerarchitectures and language models, with the best VT model matching CoAtNet'sperformance. A key advancement is the introduction of a noise mitigation methodfor real-world scenarios. By using LLMs for contextual understanding, we detectand correct erroneous keystrokes in noisy environments, enhancing ASCAperformance. Additionally, fine-tuned lightweight language models with Low-RankAdaptation (LoRA) deliver comparable performance to heavyweight models with 67Xmore parameters. This integration of VTs and LLMs improves the practicalapplicability of ASCA mitigation, marking the first use of these technologiesto address ASCAs and error correction in real-world scenarios.</description><author>Jin Hyun Park, Seyyed Ali Ayati, Yichen Cai</author><pubDate>Mon, 17 Feb 2025 18:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09782v2</guid></item><item><title>SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?</title><link>http://arxiv.org/abs/2502.12115v1</link><description>We introduce SWE-Lancer, a benchmark of over 1,400 freelance softwareengineering tasks from Upwork, valued at \$1 million USD total in real-worldpayouts. SWE-Lancer encompasses both independent engineering tasks--rangingfrom \$50 bug fixes to \$32,000 feature implementations--and managerial tasks,where models choose between technical implementation proposals. Independenttasks are graded with end-to-end tests triple-verified by experienced softwareengineers, while managerial decisions are assessed against the choices of theoriginal hired engineering managers. We evaluate model performance and findthat frontier models are still unable to solve the majority of tasks. Tofacilitate future research, we open-source a unified Docker image and a publicevaluation split, SWE-Lancer Diamond(https://github.com/openai/SWELancer-Benchmark). By mapping model performanceto monetary value, we hope SWE-Lancer enables greater research into theeconomic impact of AI model development.</description><author>Samuel Miserendino, Michele Wang, Tejal Patwardhan, Johannes Heidecke</author><pubDate>Mon, 17 Feb 2025 18:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12115v1</guid></item><item><title>A Monocular Event-Camera Motion Capture System</title><link>http://arxiv.org/abs/2502.12113v1</link><description>Motion capture systems are a widespread tool in research to recordground-truth poses of objects. Commercial systems use reflective markersattached to the object and then triangulate pose of the object from multiplecamera views. Consequently, the object must be visible to multiple cameraswhich makes such multi-view motion capture systems unsuited for deployments innarrow, confined spaces (e.g. ballast tanks of ships). In this technical reportwe describe a monocular event-camera motion capture system which overcomes thislimitation and is ideally suited for narrow spaces. Instead of passive markersit relies on active, blinking LED markers such that each marker can be uniquelyidentified from the blinking frequency. The markers are placed at knownlocations on the tracking object. We then solve the PnP (perspective-n-points)problem to obtain the position and orientation of the object. The developedsystem has millimeter accuracy, millisecond latency and we demonstrate that itsstate estimate can be used to fly a small, agile quadrotor.</description><author>Leonard Bauersfeld, Davide Scaramuzza</author><pubDate>Mon, 17 Feb 2025 18:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12113v1</guid></item><item><title>CELL your Model: Contrastive Explanations for Large Language Models</title><link>http://arxiv.org/abs/2406.11785v3</link><description>The advent of black-box deep neural network classification models has sparkedthe need to explain their decisions. However, in the case of generative AI,such as large language models (LLMs), there is no class prediction to explain.Rather, one can ask why an LLM output a particular response to a given prompt.In this paper, we answer this question by proposing a contrastive explanationmethod requiring simply black-box/query access. Our explanations suggest thatan LLM outputs a reply to a given prompt because if the prompt was slightlymodified, the LLM would have given a different response that is either lesspreferable or contradicts the original response. The key insight is thatcontrastive explanations simply require a scoring function that has meaning tothe user and not necessarily a specific real valued quantity (viz. classlabel). To this end, we offer a novel budgeted algorithm, our main algorithmiccontribution, which intelligently creates contrasts based on such a scoringfunction while adhering to a query budget, necessary for longer contexts. Weshow the efficacy of our method on important natural language tasks such asopen-text generation and chatbot conversations.</description><author>Ronny Luss, Erik Miehling, Amit Dhurandhar</author><pubDate>Mon, 17 Feb 2025 18:37:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11785v3</guid></item><item><title>A-MEM: Agentic Memory for LLM Agents</title><link>http://arxiv.org/abs/2502.12110v1</link><description>While large language model (LLM) agents can effectively use external toolsfor complex real-world tasks, they require memory systems to leveragehistorical experiences. Current memory systems enable basic storage andretrieval but lack sophisticated memory organization, despite recent attemptsto incorporate graph databases. Moreover, these systems' fixed operations andstructures limit their adaptability across diverse tasks. To address thislimitation, this paper proposes a novel agentic memory system for LLM agentsthat can dynamically organize memories in an agentic way. Following the basicprinciples of the Zettelkasten method, we designed our memory system to createinterconnected knowledge networks through dynamic indexing and linking. When anew memory is added, we generate a comprehensive note containing multiplestructured attributes, including contextual descriptions, keywords, and tags.The system then analyzes historical memories to identify relevant connections,establishing links where meaningful similarities exist. Additionally, thisprocess enables memory evolution - as new memories are integrated, they cantrigger updates to the contextual representations and attributes of existinghistorical memories, allowing the memory network to continuously refine itsunderstanding. Our approach combines the structured organization principles ofZettelkasten with the flexibility of agent-driven decision making, allowing formore adaptive and context-aware memory management. Empirical experiments on sixfoundation models show superior improvement against existing SOTA baselines.The source code is available at https://github.com/WujiangXu/AgenticMemory.</description><author>Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang</author><pubDate>Mon, 17 Feb 2025 18:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12110v1</guid></item><item><title>Personality Structured Interview for Large Language Model Simulation in Personality Research</title><link>http://arxiv.org/abs/2502.12109v1</link><description>Although psychometrics researchers have recently explored the use of largelanguage models (LLMs) as proxies for human participants, LLMs often fail togenerate heterogeneous data with human-like diversity, which diminishes theirvalue in advancing social science research. To address these challenges, weexplored the potential of the theory-informed Personality Structured Interview(PSI) as a tool for simulating human responses in personality research. In thisapproach, the simulation is grounded in nuanced real-human interviewtranscripts that target the personality construct of interest. We have provideda growing set of 357 structured interview transcripts from a representativesample, each containing an individual's response to 32 open-ended questionscarefully designed to gather theory-based personality evidence. Additionally,grounded in psychometric research, we have summarized an evaluation frameworkto systematically validate LLM-generated psychometric data. Results from threeexperiments demonstrate that well-designed structured interviews could improvehuman-like heterogeneity in LLM-simulated personality data and predictpersonality-related behavioral outcomes (i.e., organizational citizenshipbehaviors and counterproductive work behavior). We further discuss the role oftheory-informed structured interviews in LLM-based simulation and outline ageneral framework for designing structured interviews to simulate human-likedata for psychometric research.</description><author>Pengda Wang, Huiqi Zou, Hanjie Chen, Tianjun Sun, Ziang Xiao, Frederick L. Oswald</author><pubDate>Mon, 17 Feb 2025 18:31:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12109v1</guid></item><item><title>Using the Path of Least Resistance to Explain Deep Networks</title><link>http://arxiv.org/abs/2502.12108v1</link><description>Integrated Gradients (IG), a widely used axiomatic path-based attributionmethod, assigns importance scores to input features by integrating modelgradients along a straight path from a baseline to the input. While effectivein some cases, we show that straight paths can lead to flawed attributions. Inthis paper, we identify the cause of these misattributions and propose analternative approach that treats the input space as a Riemannian manifold,computing attributions by integrating gradients along geodesics. We call thismethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, weintroduce two techniques: a k-Nearest Neighbours-based approach for smallermodels and a Stochastic Variational Inference-based method for larger ones.Additionally, we propose a new axiom, Strong Completeness, extending the axiomssatisfied by IG. We show that this property is desirable for attributionmethods and that GIG is the only method that satisfies it. Through experimentson both synthetic and real-world data, we demonstrate that GIG outperformsexisting explainability methods, including IG.</description><author>Sina Salek, Joseph Enguehard</author><pubDate>Mon, 17 Feb 2025 18:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12108v1</guid></item><item><title>Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination</title><link>http://arxiv.org/abs/2411.03823v2</link><description>The rapid progression of multimodal large language models (MLLMs) hasdemonstrated superior performance on various multimodal benchmarks. However,the issue of data contamination during training creates challenges inperformance evaluation and comparison. While numerous methods exist fordetecting models' contamination in large language models (LLMs), they are lesseffective for MLLMs due to their various modalities and multiple trainingphases. In this study, we introduce a multimodal data contamination detectionframework, MM-Detect, designed for MLLMs. Our experimental results indicatethat MM-Detect is quite effective and sensitive in identifying varying degreesof contamination, and can highlight significant performance improvements due tothe leakage of multimodal benchmark training sets. Furthermore, we explorewhether the contamination originates from the base LLMs used by MLLMs or themultimodal training phase, providing new insights into the stages at whichcontamination may be introduced.</description><author>Dingjie Song, Sicheng Lai, Shunian Chen, Lichao Sun, Benyou Wang</author><pubDate>Mon, 17 Feb 2025 18:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03823v2</guid></item><item><title>NaVILA: Legged Robot Vision-Language-Action Model for Navigation</title><link>http://arxiv.org/abs/2412.04453v2</link><description>This paper proposes to solve the problem of Vision-and-Language Navigationwith legged robots, which not only provides a flexible way for humans tocommand but also allows the robot to navigate through more challenging andcluttered scenes. However, it is non-trivial to translate human languageinstructions all the way to low-level leg joint actions. We propose NaVILA, a2-level framework that unifies a Vision-Language-Action model (VLA) withlocomotion skills. Instead of directly predicting low-level actions from VLA,NaVILA first generates mid-level actions with spatial information in the formof language, (e.g., "moving forward 75cm"), which serves as an input for avisual locomotion RL policy for execution. NaVILA substantially improvesprevious approaches on existing benchmarks. The same advantages aredemonstrated in our newly developed benchmarks with IsaacLab, featuring morerealistic scenes, low-level controls, and real-world robot experiments. We showmore results at https://navila-bot.github.io/</description><author>An-Chieh Cheng, Yandong Ji, Zhaojing Yang, Zaitian Gongye, Xueyan Zou, Jan Kautz, Erdem BÄ±yÄ±k, Hongxu Yin, Sifei Liu, Xiaolong Wang</author><pubDate>Mon, 17 Feb 2025 18:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04453v2</guid></item><item><title>Relational Norms for Human-AI Cooperation</title><link>http://arxiv.org/abs/2502.12102v1</link><description>How we should design and interact with social artificial intelligence dependson the socio-relational role the AI is meant to emulate or occupy. In humansociety, relationships such as teacher-student, parent-child, neighbors,siblings, or employer-employee are governed by specific norms that prescribe orproscribe cooperative functions including hierarchy, care, transaction, andmating. These norms shape our judgments of what is appropriate for eachpartner. For example, workplace norms may allow a boss to give orders to anemployee, but not vice versa, reflecting hierarchical and transactionalexpectations. As AI agents and chatbots powered by large language models areincreasingly designed to serve roles analogous to human positions - such asassistant, mental health provider, tutor, or romantic partner - it isimperative to examine whether and how human relational norms should extend tohuman-AI interactions. Our analysis explores how differences between AI systemsand humans, such as the absence of conscious experience and immunity tofatigue, may affect an AI's capacity to fulfill relationship-specific functionsand adhere to corresponding norms. This analysis, which is a collaborativeeffort by philosophers, psychologists, relationship scientists, ethicists,legal experts, and AI researchers, carries important implications for AIsystems design, user behavior, and regulation. While we accept that AI systemscan offer significant benefits such as increased availability and consistencyin certain socio-relational roles, they also risk fostering unhealthydependencies or unrealistic expectations that could spill over into human-humanrelationships. We propose that understanding and thoughtfully shaping (orimplementing) suitable human-AI relational norms will be crucial for ensuringthat human-AI interactions are ethical, trustworthy, and favorable to humanwell-being.</description><author>Brian D. Earp, Sebastian Porsdam Mann, Mateo Aboy, Edmond Awad, Monika Betzler, Marietjie Botes, Rachel Calcott, Mina Caraccio, Nick Chater, Mark Coeckelbergh, Mihaela Constantinescu, Hossein Dabbagh, Kate Devlin, Xiaojun Ding, Vilius Dranseika, Jim A. C. Everett, Ruiping Fan, Faisal Feroz, Kathryn B. Francis, Cindy Friedman, Orsolya Friedrich, Iason Gabriel, Ivar Hannikainen, Julie Hellmann, Arasj Khodadade Jahrome, Niranjan S. Janardhanan, Paul Jurcys, Andreas Kappes, Maryam Ali Khan, Gordon Kraft-Todd, Maximilian Kroner Dale, Simon M. Laham, Benjamin Lange, Muriel Leuenberger, Jonathan Lewis, Peng Liu, David M. Lyreskog, Matthijs Maas, John McMillan, Emilian Mihailov, Timo Minssen, Joshua Teperowski Monrad, Kathryn Muyskens, Simon Myers, Sven Nyholm, Alexa M. Owen, Anna Puzio, Christoph</author><pubDate>Mon, 17 Feb 2025 18:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12102v1</guid></item><item><title>Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis</title><link>http://arxiv.org/abs/2404.01438v2</link><description>This research explores the positive application of deepfake technology forupper body generation, specifically sign language for the Deaf and Hard ofHearing (DHoH) community. Given the complexity of sign language and thescarcity of experts, the generated videos are vetted by a sign language expertfor accuracy. We construct a reliable deepfake dataset, evaluating itstechnical and visual credibility using computer vision and natural languageprocessing models. The dataset, consisting of over 1200 videos featuring bothseen and unseen individuals, is also used to detect deepfake videos targetingvulnerable individuals. Expert annotations confirm that the generated videosare comparable to real sign language content. Linguistic analysis, usingtextual similarity scores and interpreter evaluations, shows that theinterpretation of generated videos is at least 90% similar to authentic signlanguage. Visual analysis demonstrates that convincingly realistic deepfakescan be produced, even for new subjects. Using a pose/style transfer model, wepay close attention to detail, ensuring hand movements are accurate and alignwith the driving video. We also apply machine learning algorithms to establisha baseline for deepfake detection on this dataset, contributing to thedetection of fraudulent sign language videos.</description><author>Shahzeb Naeem, Muhammad Riyyan Khan, Usman Tariq, Abhinav Dhall, Carlos Ivan Colon, Hasan Al-Nashash</author><pubDate>Mon, 17 Feb 2025 18:22:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01438v2</guid></item><item><title>Machine Learning for Equitable Load Shedding: Real-time Solution via Learning Binding Constraints</title><link>http://arxiv.org/abs/2407.18989v3</link><description>Timely and effective load shedding in power systems is critical formaintaining supply-demand balance and preventing cascading blackouts. Toeliminate load shedding bias against specific regions in the system,optimization-based methods are uniquely positioned to help balance betweeneconomical and equity considerations. However, the resulting optimizationproblem involves complex constraints, which can be time-consuming to solve andthus cannot meet the real-time requirements of load shedding. To tackle thischallenge, in this paper we present an efficient machine learning algorithm toenable millisecond-level computation for the optimization-based load sheddingproblem. Numerical studies on both a 3-bus toy example and a realistic RTS-GMLCsystem have demonstrated the validity and efficiency of the proposed algorithmfor delivering equitable and real-time load shedding decisions.</description><author>Yuqi Zhou, Joseph Severino, Sanjana Vijayshankar, Juliette Ugirumurera, Jibo Sanyal</author><pubDate>Mon, 17 Feb 2025 18:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18989v3</guid></item><item><title>Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications</title><link>http://arxiv.org/abs/2502.12096v1</link><description>In this paper, we introduce token communications (TokCom), a unifiedframework to leverage cross-modal context information in generative semanticcommunications (GenSC). TokCom is a new paradigm, motivated by the recentsuccess of generative foundation models and multimodal large language models(GFM/MLLMs), where the communication units are tokens, enabling efficienttransformer-based token processing at the transmitter and receiver. In thispaper, we introduce the potential opportunities and challenges of leveragingcontext in GenSC, explore how to integrate GFM/MLLMs-based token processinginto semantic communication systems to leverage cross-modal contexteffectively, present the key principles for efficient TokCom at various layersin future wireless networks. We demonstrate the corresponding TokCom benefitsin a GenSC setup for image, leveraging cross-modal context information, whichincreases the bandwidth efficiency by 70.8% with negligible loss ofsemantic/perceptual quality. Finally, the potential research directions areidentified to facilitate adoption of TokCom in future wireless networks.</description><author>Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato</author><pubDate>Mon, 17 Feb 2025 18:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12096v1</guid></item><item><title>Descriminative-Generative Custom Tokens for Vision-Language Models</title><link>http://arxiv.org/abs/2502.12095v1</link><description>This paper explores the possibility of learning custom tokens forrepresenting new concepts in Vision-Language Models (VLMs). Our aim is to learntokens that can be effective for both discriminative and generative tasks whilecomposing well with words to form new input queries. The targeted concept isspecified in terms of a small set of images and a parent concept describedusing text. We operate on CLIP text features and propose to use a combinationof a textual inversion loss and a classification loss to ensure that textfeatures of the learned token are aligned with image features of the concept inthe CLIP embedding space. We restrict the learned token to a low-dimensionalsubspace spanned by tokens for attributes that are appropriate for the givensuper-class. These modifications improve the quality of compositions of thelearned token with natural language for generating new scenes. Further, we showthat learned custom tokens can be used to form queries for text-to-imageretrieval task, and also have the important benefit that composite queries canbe visualized to ensure that the desired concept is faithfully encoded. Basedon this, we introduce the method of Generation Aided Image Retrieval, where thequery is modified at inference time to better suit the search intent. On theDeepFashion2 dataset, our method improves Mean Reciprocal Retrieval (MRR) overrelevant baselines by 7%.</description><author>Pramuditha Perera, Matthew Trager, Luca Zancato, Alessandro Achille, Stefano Soatto</author><pubDate>Mon, 17 Feb 2025 18:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12095v1</guid></item><item><title>Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)</title><link>http://arxiv.org/abs/2412.18367v5</link><description>The field of machine translation has achieved significant advancements, yetdomain-specific terminology translation, particularly in AI, remainschallenging. We introduce GIST, a large-scale multilingual AI terminologydataset containing 5K terms extracted from top AI conference papers spanning2000 to 2023. The terms are translated into Arabic, Chinese, French, Japanese,and Russian using a hybrid framework that combines LLMs for extraction withhuman expertise for translation. The dataset's quality is benchmarked againstexisting resources, demonstrating superior translation accuracy throughcrowdsourced evaluation. GIST is integrated into translation workflows usingpost-translation refinement methods that require no retraining, where LLMprompting consistently improves BLEU and COMET scores. A web demonstration onthe ACL Anthology platform highlights its practical application, showcasingimproved accessibility for non-English speakers. This work aims to addresscritical gaps in AI terminology resources and fosters global inclusivity andcollaboration in AI research.</description><author>Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona Diab</author><pubDate>Mon, 17 Feb 2025 18:13:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18367v5</guid></item><item><title>A Study on Leveraging Search and Self-Feedback for Agent Reasoning</title><link>http://arxiv.org/abs/2502.12094v1</link><description>Recent works have demonstrated that incorporating search during inference cansignificantly improve reasoning capabilities of language agents. Someapproaches may make use of the ground truth or rely on model's own generatedfeedback. The search algorithm uses this feedback to then produce values thatwill update its criterion for exploring and exploiting various reasoning paths.In this study, we investigate how search and model's self-feedback can beleveraged for reasoning tasks. First, we explore differences in ground-truthfeedback and self-feedback during search for math reasoning. Second, we observelimitations in applying search techniques to more complex tasks liketool-calling and design domain-specific approaches to address these gaps. Ourexperiments reveal challenges related to generalization when solely relying onself-feedback during search. For search to work effectively, either access tothe ground-truth is needed or feedback mechanisms need to be carefully designedfor the specific task.</description><author>Karthikeyan K, Michelle Yuan, Elman Mansimov, Katerina Margatina, Anurag Pratik, Daniele Bonadiman, Monica Sunkara, Yi Zhang, Yassine Benajiba</author><pubDate>Mon, 17 Feb 2025 18:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12094v1</guid></item><item><title>Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning</title><link>http://arxiv.org/abs/2501.03035v2</link><description>Large language models have achieved significant advancements in complexmathematical reasoning benchmarks, such as MATH. However, their substantialcomputational requirements present challenges for practical deployment. Modelquantization has emerged as an effective strategy to reduce memory usage andcomputational costs by employing lower precision and bit-width representations.In this study, we systematically evaluate the impact of quantization onmathematical reasoning tasks. Our results demonstrate that aggressivequantization methods like AWQ and GPTQ introduce up to 32.39% accuracydegradation (average 11.31%) on Llama-3 models, particularly in numericalcomputation and reasoning planning. To address this, we introduce amultidimensional evaluation framework combining qualitative capability analysisand quantitative error assessment. We further develop targeted recoverystrategies, showing that fine-tuning quantized models on only 545 task-specificexamples for 3 minutes on 4 GPUs effectively restores reasoning capabilities tonear full-precision levels. Additionally, our error assessment pipelineachieves 98.9% accuracy in diagnosing and localizing errors across 3,366failure cases, providing actionable insights for mitigatingquantization-induced degradation.</description><author>Zhen Li, Yupeng Su, Runming Yang, Congkai Xie, Zheng Wang, Zhongwei Xie, Ngai Wong, Hongxia Yang</author><pubDate>Mon, 17 Feb 2025 18:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03035v2</guid></item><item><title>CLEAR: Character Unlearning in Textual and Visual Modalities</title><link>http://arxiv.org/abs/2410.18057v3</link><description>Machine Unlearning (MU) is critical for removing private or hazardousinformation from deep learning models. While MU has advanced significantly inunimodal (text or vision) settings, multimodal unlearning (MMU) remainsunderexplored due to the lack of open benchmarks for evaluating cross-modaldata removal. To address this gap, we introduce CLEAR, the first open-sourcebenchmark designed specifically for MMU. CLEAR contains 200 fictitiousindividuals and 3,700 images linked with corresponding question-answer pairs,enabling a thorough evaluation across modalities. We conduct a comprehensiveanalysis of 11 MU methods (e.g., SCRUB, gradient ascent, DPO) across fourevaluation sets, demonstrating that jointly unlearning both modalitiesoutperforms single-modality approaches. The dataset is available athttps://huggingface.co/datasets/therem/CLEAR</description><author>Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina</author><pubDate>Mon, 17 Feb 2025 18:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18057v3</guid></item><item><title>How compositional generalization and creativity improve as diffusion models are trained</title><link>http://arxiv.org/abs/2502.12089v1</link><description>Natural data is often organized as a hierarchical composition of features.How many samples do generative models need to learn the composition rules, soas to produce a combinatorial number of novel data? What signal in the data isexploited to learn? We investigate these questions both theoretically andempirically. Theoretically, we consider diffusion models trained on simpleprobabilistic context-free grammars - tree-like graphical models used torepresent the structure of data such as language and images. We demonstratethat diffusion models learn compositional rules with the sample complexityrequired for clustering features with statistically similar context, a processsimilar to the word2vec algorithm. However, this clustering emergeshierarchically: higher-level, more abstract features associated with longercontexts require more data to be identified. This mechanism leads to a samplecomplexity that scales polynomially with the said context size. As a result,diffusion models trained on intermediate dataset size generate data coherent upto a certain scale, but that lacks global coherence. We test these predictionsin different domains, and find remarkable agreement: both generated texts andimages achieve progressively larger coherence lengths as the training time ordataset size grows. We discuss connections between the hierarchical clusteringmechanism we introduce here and the renormalization group in physics.</description><author>Alessandro Favero, Antonio Sclocchi, Francesco Cagnetta, Pascal Frossard, Matthieu Wyart</author><pubDate>Mon, 17 Feb 2025 18:06:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12089v1</guid></item><item><title>BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data</title><link>http://arxiv.org/abs/2410.16491v2</link><description>In this work, we tackle the challenge of embedding realistic humanpersonality traits into LLMs. Previous approaches have primarily focused onprompt-based methods that describe the behavior associated with the desiredpersonality traits, suffering from realism and validity issues. To addressthese limitations, we introduce BIG5-CHAT, a large-scale dataset containing100,000 dialogues designed to ground models in how humans express theirpersonality in language. Leveraging this dataset, we explore SupervisedFine-Tuning and Direct Preference Optimization as training-based methods toalign LLMs more naturally with human personality patterns. Our methodsoutperform prompting on personality assessments such as BFI and IPIP-NEO, withtrait correlations more closely matching human data. Furthermore, ourexperiments reveal that models trained to exhibit higher conscientiousness,higher agreeableness, lower extraversion, and lower neuroticism display betterperformance on reasoning tasks, aligning with psychological findings on howthese traits impact human cognitive performance. To our knowledge, this work isthe first comprehensive study to demonstrate how training-based methods canshape LLM personalities through learning from real human behaviors.</description><author>Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap</author><pubDate>Mon, 17 Feb 2025 18:05:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16491v2</guid></item><item><title>Meta-Statistical Learning: Supervised Learning of Statistical Inference</title><link>http://arxiv.org/abs/2502.12088v1</link><description>This work demonstrates that the tools and principles driving the success oflarge language models (LLMs) can be repurposed to tackle distribution-leveltasks, where the goal is to predict properties of the data-generatingdistribution rather than labels for individual datapoints. These tasksencompass statistical inference problems such as parameter estimation,hypothesis testing, or mutual information estimation. Framing these taskswithin traditional machine learning pipelines is challenging, as supervision istypically tied to individual datapoint. We propose meta-statistical learning, aframework inspired by multi-instance learning that reformulates statisticalinference tasks as supervised learning problems. In this approach, entiredatasets are treated as single inputs to neural networks, which predictdistribution-level parameters. Transformer-based architectures, withoutpositional encoding, provide a natural fit due to their permutation-invarianceproperties. By training on large-scale synthetic datasets, meta-statisticalmodels can leverage the scalability and optimization infrastructure ofTransformer-based LLMs. We demonstrate the framework's versatility withapplications in hypothesis testing and mutual information estimation, showingstrong performance, particularly for small datasets where traditional neuralmethods struggle.</description><author>Maxime Peyrard, Kyunghyun Cho</author><pubDate>Mon, 17 Feb 2025 18:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12088v1</guid></item><item><title>Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems</title><link>http://arxiv.org/abs/2502.12086v1</link><description>Dynamical systems, prevalent in various scientific and engineering domains,are susceptible to anomalies that can significantly impact their performanceand reliability. This paper addresses the critical challenges of anomalydetection, root cause localization, and anomaly type classification indynamical systems governed by ordinary differential equations (ODEs). We definetwo categories of anomalies: cyber anomalies, which propagate throughinterconnected variables, and measurement anomalies, which remain localized toindividual variables. To address these challenges, we propose the InterpretableCausality Ordinary Differential Equation (ICODE) Networks, a model-intrinsicexplainable learning framework. ICODE leverages Neural ODEs for anomalydetection while employing causality inference through an explanation channel toperform root cause analysis (RCA), elucidating why specific time periods areflagged as anomalous. ICODE is designed to simultaneously perform anomalydetection, RCA, and anomaly type classification within a single, interpretableframework. Our approach is grounded in the hypothesis that anomalies alter theunderlying ODEs of the system, manifesting as changes in causal relationshipsbetween variables. We provide a theoretical analysis of how perturbations inlearned model parameters can be utilized to identify anomalies and their rootcauses in time series data. Comprehensive experimental evaluations demonstratethe efficacy of ICODE across various dynamical systems, showcasing its abilityto accurately detect anomalies, classify their types, and pinpoint theirorigins.</description><author>Yue Sun, Rick S. Blum, Parv Venkitasubramaniam</author><pubDate>Mon, 17 Feb 2025 18:01:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12086v1</guid></item><item><title>APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs</title><link>http://arxiv.org/abs/2502.12085v1</link><description>While long-context inference is crucial for advancing large language model(LLM) applications, its prefill speed remains a significant bottleneck. Currentapproaches, including sequence parallelism strategies and compute reductionthrough approximate attention mechanisms, still fall short of deliveringoptimal inference efficiency. This hinders scaling the inputs to longersequences and processing long-context queries in a timely manner. To addressthis, we introduce APB, an efficient long-context inference framework thatleverages multi-host approximate attention to enhance prefill speed by reducingcompute and enhancing parallelism simultaneously. APB introduces acommunication mechanism for essential key-value pairs within a sequenceparallelism framework, enabling a faster inference speed while maintaining taskperformance. We implement APB by incorporating a tailored FlashAttn kernelalongside optimized distribution strategies, supporting diverse models andparallelism configurations. APB achieves speedups of up to 9.2x, 4.2x, and 1.6xcompared with FlashAttn, RingAttn, and StarAttn, respectively, without anyobservable task performance degradation. We provide the implementation andexperiment code of APB in https://github.com/thunlp/APB.</description><author>Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Sun Ao, Hao Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun</author><pubDate>Mon, 17 Feb 2025 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12085v1</guid></item><item><title>VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues</title><link>http://arxiv.org/abs/2502.12084v1</link><description>Visually linking matching cues is a crucial ability in daily life, such asidentifying the same person in multiple photos based on their cues, evenwithout knowing who they are. Despite the extensive knowledge thatvision-language models (VLMs) possess, it remains largely unexplored whetherthey are capable of performing this fundamental task. To address this, weintroduce VLM$^2$-Bench, a benchmark designed to assess whether VLMs canVisually Link Matching cues, with 9 subtasks and over 3,000 test cases.Comprehensive evaluation across eight open-source VLMs and GPT-4o, along withfurther analysis of various language-side and vision-side prompting methods,leads to a total of eight key findings. We identify critical challenges inmodels' ability to link visual cues, highlighting a significant performance gapwhere even GPT-4o lags 34.80% behind humans. Based on these insights, weadvocate for (i) enhancing core visual capabilities to improve adaptability andreduce reliance on prior knowledge, (ii) establishing clearer principles forintegrating language-based reasoning in vision-centric tasks to preventunnecessary biases, and (iii) shifting vision-text training paradigms towardfostering models' ability to independently structure and infer relationshipsamong visual cues.</description><author>Jianshu Zhang, Dongyu Yao, Renjie Pi, Paul Pu Liang, Yi R., Fung</author><pubDate>Mon, 17 Feb 2025 17:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12084v1</guid></item><item><title>AdaSplash: Adaptive Sparse Flash Attention</title><link>http://arxiv.org/abs/2502.12082v1</link><description>The computational cost of softmax-based attention in transformers limitstheir applicability to long-context tasks. Adaptive sparsity, of which$\alpha$-entmax attention is an example, offers a flexible data-dependentalternative, but existing implementations are inefficient and do not leveragethe sparsity to obtain runtime and memory gains. In this work, we proposeAdaSplash, which combines the efficiency of GPU-optimized algorithms with thesparsity benefits of $\alpha$-entmax. We first introduce a hybridHalley-bisection algorithm, resulting in a 7-fold reduction in the number ofiterations needed to compute the $\alpha$-entmax transformation. Then, weimplement custom Triton kernels to efficiently handle adaptive sparsity.Experiments with RoBERTa and ModernBERT for text classification andsingle-vector retrieval, along with GPT-2 for language modeling, show that ourmethod achieves substantial improvements in runtime and memory efficiencycompared to existing $\alpha$-entmax implementations. It approaches -- and insome cases surpasses -- the efficiency of highly optimized softmaximplementations like FlashAttention-2, enabling long-context training whilemaintaining strong task performance.</description><author>Nuno GonÃ§alves, Marcos Treviso, AndrÃ© F. T. Martins</author><pubDate>Mon, 17 Feb 2025 17:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12082v1</guid></item><item><title>Unhackable Temporal Rewarding for Scalable Video MLLMs</title><link>http://arxiv.org/abs/2502.12081v1</link><description>In the pursuit of superior video-processing MLLMs, we have encountered aperplexing paradox: the "anti-scaling law", where more data and larger modelslead to worse performance. This study unmasks the culprit: "temporal hacking",a phenomenon where models shortcut by fixating on select frames, missing thefull video narrative. In this work, we systematically establish a comprehensivetheory of temporal hacking, defining it from a reinforcement learningperspective, introducing the Temporal Perplexity (TPL) score to assess thismisalignment, and proposing the Unhackable Temporal Rewarding (UTR) frameworkto mitigate the temporal hacking. Both theoretically and empirically, TPLproves to be a reliable indicator of temporal modeling quality, correlatingstrongly with frame activation patterns. Extensive experiments reveal that UTRnot only counters temporal hacking but significantly elevates videocomprehension capabilities. This work not only advances video-AI systems butalso illuminates the critical importance of aligning proxy rewards with trueobjectives in MLLM development.</description><author>En Yu, Kangheng Lin, Liang Zhao, Yana Wei, Zining Zhu, Haoran Wei, Jianjian Sun, Zheng Ge, Xiangyu Zhang, Jingyu Wang, Wenbing Tao</author><pubDate>Mon, 17 Feb 2025 17:55:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12081v1</guid></item><item><title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title><link>http://arxiv.org/abs/2501.11613v6</link><description>This study introduces Conversation Routines (CR), a structured promptengineering framework for developing task-oriented dialog systems using LargeLanguage Models (LLMs). While LLMs demonstrate remarkable natural languageunderstanding capabilities, engineering them to reliably execute complexbusiness workflows remains challenging. The proposed CR framework enables thedevelopment of Conversation Agentic Systems (CAS) through natural languagespecifications, embedding task-oriented logic within LLM prompts. This approachprovides a systematic methodology for designing and implementing complexconversational workflows while maintaining behavioral consistency. Wedemonstrate the framework's effectiveness through two proof-of-conceptimplementations: a Train Ticket Booking System and an InteractiveTroubleshooting Copilot. These case studies validate CR's capability to encodesophisticated behavioral patterns and decision logic while preserving naturalconversational flexibility. Results show that CR enables domain experts todesign conversational workflows in natural language while leveraging customfunctions (tools) developed by software engineers, creating an efficientdivision of responsibilities where developers focus on core API implementationand domain experts handle conversation design. While the framework showspromise in accessibility and adaptability, we identify key challenges includingcomputational overhead, non-deterministic behavior, and domain-specific logicoptimization. Future research directions include CR evaluation methods based onprompt engineering frameworks driven by goal-oriented grading criteria,improving scalability for complex multi-agent interactions, and enhancingsystem robustness to address the identified limitations across diverse businessapplications.</description><author>Giorgio Robino</author><pubDate>Mon, 17 Feb 2025 17:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11613v6</guid></item><item><title>HumanGif: Single-View Human Diffusion with Generative Prior</title><link>http://arxiv.org/abs/2502.12080v1</link><description>While previous single-view-based 3D human reconstruction methods madesignificant progress in novel view synthesis, it remains a challenge tosynthesize both view-consistent and pose-consistent results for animatablehuman avatars from a single image input. Motivated by the success of 2Dcharacter animation, we propose &lt;strong&gt;HumanGif&lt;/strong&gt;, a single-view humandiffusion model with generative prior. Specifically, we formulate thesingle-view-based 3D human novel view and pose synthesis as asingle-view-conditioned human diffusion process, utilizing generative priorsfrom foundational diffusion models. To ensure fine-grained and consistent novelview and pose synthesis, we introduce a Human NeRF module in HumanGif to learnspatially aligned features from the input image, implicitly capturing therelative camera and human pose transformation. Furthermore, we introduce animage-level loss during optimization to bridge the gap between latent and imagespaces in diffusion models. Extensive experiments on RenderPeople andDNA-Rendering datasets demonstrate that HumanGif achieves the best perceptualperformance, with better generalizability for novel view and pose synthesis.</description><author>Shoukang Hu, Takuya Narihira, Kazumi Fukuda, Ryosuke Sawata, Takashi Shibuya, Yuki Mitsufuji</author><pubDate>Mon, 17 Feb 2025 17:55:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12080v1</guid></item><item><title>Vision CNNs trained to estimate spatial latents learned similar ventral-stream-aligned representations</title><link>http://arxiv.org/abs/2412.09115v2</link><description>Studies of the functional role of the primate ventral visual stream havetraditionally focused on object categorization, often ignoring -- despite muchprior evidence -- its role in estimating "spatial" latents such as objectposition and pose. Most leading ventral stream models are derived by optimizingnetworks for object categorization, which seems to imply that the ventralstream is also derived under such an objective. Here, we explore an alternativehypothesis: Might the ventral stream be optimized for estimating spatiallatents? And a closely related question: How different -- if at all -- arerepresentations learned from spatial latent estimation compared tocategorization? To ask these questions, we leveraged synthetic image datasetsgenerated by a 3D graphic engine and trained convolutional neural networks(CNNs) to estimate different combinations of spatial and category latents. Wefound that models trained to estimate just a few spatial latents achieve neuralalignment scores comparable to those trained on hundreds of categories, and thespatial latent performance of models strongly correlates with their neuralalignment. Spatial latent and category-trained models have very similar -- butnot identical -- internal representations, especially in their early and middlelayers. We provide evidence that this convergence is partly driven bynon-target latent variability in the training data, which facilitates theimplicit learning of representations of those non-target latents. Takentogether, these results suggest that many training objectives, such as spatiallatents, can lead to similar models aligned neurally with the ventral stream.Thus, one should not assume that the ventral stream is optimized for objectcategorization only. As a field, we need to continue to sharpen our measures ofcomparing models to brains to better understand the functional roles of theventral stream.</description><author>Yudi Xie, Weichen Huang, Esther Alter, Jeremy Schwartz, Joshua B. Tenenbaum, James J. DiCarlo</author><pubDate>Mon, 17 Feb 2025 17:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.09115v2</guid></item><item><title>Exploring the Effect of Explanation Content and Format on User Comprehension and Trust in Healthcare</title><link>http://arxiv.org/abs/2408.17401v2</link><description>AI-driven tools for healthcare are widely acknowledged as potentiallybeneficial to health practitioners and patients, e.g. the QCancer regressiontool for cancer risk prediction. However, for these tools to be trusted, theyneed to be supplemented with explanations. We examine how explanations' contentand format affect user comprehension and trust when explaining QCancer'spredictions. Regarding content, we deploy SHAP and Occlusion-1. Regardingformat, we present SHAP explanations, conventionally, as charts (SC) andOcclusion-1 explanations as charts (OC) as well as text (OT), to which theirsimpler nature lends itself. We conduct experiments with two sets ofstakeholders: the general public (representing patients) and medical students(representing healthcare practitioners). Our experiments showed highersubjective comprehension and trust for Occlusion-1 over SHAP explanations basedon content. However, when controlling for format, only OT outperformed SC,suggesting this trend is driven by preferences for text. Other findingscorroborated that explanation format, rather than content, is often thecritical factor.</description><author>Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni</author><pubDate>Mon, 17 Feb 2025 17:49:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17401v2</guid></item><item><title>Can LLMs Simulate Social Media Engagement? A Study on Action-Guided Response Generation</title><link>http://arxiv.org/abs/2502.12073v1</link><description>Social media enables dynamic user engagement with trending topics, and recentresearch has explored the potential of large language models (LLMs) forresponse generation. While some studies investigate LLMs as agents forsimulating user behavior on social media, their focus remains on practicalviability and scalability rather than a deeper understanding of how well LLMaligns with human behavior. This paper analyzes LLMs' ability to simulatesocial media engagement through action guided response generation, where amodel first predicts a user's most likely engagement action-retweet, quote, orrewrite-towards a trending post before generating a personalized responseconditioned on the predicted action. We benchmark GPT-4o-mini, O1-mini, andDeepSeek-R1 in social media engagement simulation regarding a major societalevent discussed on X. Our findings reveal that zero-shot LLMs underperform BERTin action prediction, while few-shot prompting initially degrades theprediction accuracy of LLMs with limited examples. However, in responsegeneration, few-shot LLMs achieve stronger semantic alignment with ground truthposts.</description><author>Zhongyi Qiu, Hanjia Lyu, Wei Xiong, Jiebo Luo</author><pubDate>Mon, 17 Feb 2025 17:43:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12073v1</guid></item><item><title>TokenSkip: Controllable Chain-of-Thought Compression in LLMs</title><link>http://arxiv.org/abs/2502.12067v1</link><description>Chain-of-Thought (CoT) has been proven effective in enhancing the reasoningcapabilities of large language models (LLMs). Recent advancements, such asOpenAI's o1 and DeepSeek-R1, suggest that scaling up the length of CoTsequences during inference could further boost LLM reasoning performance.However, due to the autoregressive nature of LLM decoding, longer CoT outputslead to a linear increase in inference latency, adversely affecting userexperience, particularly when the CoT exceeds 10,000 tokens. To address thislimitation, we analyze the semantic importance of tokens within CoT outputs andreveal that their contributions to reasoning vary. Building on this insight, wepropose TokenSkip, a simple yet effective approach that enables LLMs toselectively skip less important tokens, allowing for controllable CoTcompression. Extensive experiments across various models and tasks demonstratethe effectiveness of TokenSkip in reducing CoT token usage while preservingstrong reasoning performance. Notably, when applied to Qwen2.5-14B-Instruct,TokenSkip reduces reasoning tokens by 40% (from 313 to 181) on GSM8K, with lessthan a 0.4% performance drop.</description><author>Heming Xia, Yongqi Li, Chak Tou Leong, Wenjie Wang, Wenjie Li</author><pubDate>Mon, 17 Feb 2025 17:37:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12067v1</guid></item><item><title>CONSTRUCTA: Automating Commercial Construction Schedules in Fabrication Facilities with Large Language Models</title><link>http://arxiv.org/abs/2502.12066v1</link><description>Automating planning with LLMs presents transformative opportunities fortraditional industries, yet remains underexplored. In commercial construction,the complexity of automated scheduling often requires manual intervention toensure precision. We propose CONSTRUCTA, a novel framework leveraging LLMs tooptimize construction schedules in complex projects like semiconductorfabrication. CONSTRUCTA addresses key challenges by: (1) integratingconstruction-specific knowledge through static RAG; (2) employingcontext-sampling techniques inspired by architectural expertise to providerelevant input; and (3) deploying Construction DPO to align schedules withexpert preferences using RLHF. Experiments on proprietary data demonstrateperformance improvements of +42.3% in missing value prediction, +79.1% independency analysis, and +28.9% in automated planning compared to baselinemethods, showcasing its potential to revolutionize construction workflows andinspire domain-specific LLM advancements.</description><author>Yifan Zhang, Xue Yang</author><pubDate>Mon, 17 Feb 2025 17:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12066v1</guid></item><item><title>Formalizing Complex Mathematical Statements with LLMs: A Study on Mathematical Definitions</title><link>http://arxiv.org/abs/2502.12065v1</link><description>Thanks to their linguistic capabilities, LLMs offer an opportunity to bridgethe gap between informal mathematics and formal languages throughautoformalization. However, it is still unclear how well LLMs generalize tosophisticated and naturally occurring mathematical statements. To address thisgap, we investigate the task of autoformalizing real-world mathematicaldefinitions -- a critical component of mathematical discourse. Specifically, weintroduce two novel resources for autoformalisation, collecting definitionsfrom Wikipedia (Def_Wiki) and arXiv papers (Def_ArXiv). We then systematicallyevaluate a range of LLMs, analyzing their ability to formalize definitions intoIsabelle/HOL. Furthermore, we investigate strategies to enhance LLMs'performance including refinement through external feedback from ProofAssistants, and formal definition grounding, where we guide LLMs throughrelevant contextual elements from formal mathematical libraries. Our findingsreveal that definitions present a greater challenge compared to existingbenchmarks, such as miniF2F. In particular, we found that LLMs still strugglewith self-correction, and aligning with relevant mathematical libraries. At thesame time, structured refinement methods and definition grounding strategiesyield notable improvements of up to 16% on self-correction capabilities and 43%on the reduction of undefined errors, highlighting promising directions forenhancing LLM-based autoformalization in real-world scenarios.</description><author>Lan Zhang, Marco Valentino, Andre Freitas</author><pubDate>Mon, 17 Feb 2025 17:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12065v1</guid></item><item><title>DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors</title><link>http://arxiv.org/abs/2406.11427v2</link><description>Large-scale latent diffusion models (LDMs) excel in content generation acrossvarious modalities, but their reliance on phonemes and durations intext-to-speech (TTS) limits scalability and access from other fields. Whilerecent studies show potential in removing these domain-specific factors,performance remains suboptimal. In this work, we introduce DiTTo-TTS, aDiffusion Transformer (DiT)-based TTS model, to investigate whether LDM-basedTTS can achieve state-of-the-art performance without domain-specific factors.Through rigorous analysis and empirical exploration, we find that (1) DiT withminimal modifications outperforms U-Net, (2) variable-length modeling with aspeech length predictor significantly improves results over fixed-lengthapproaches, and (3) conditions like semantic alignment in speech latentrepresentations are key to further enhancement. By scaling our training data to82K hours and the model size to 790M parameters, we achieve superior orcomparable zero-shot performance to state-of-the-art TTS models in naturalness,intelligibility, and speaker similarity, all without relying on domain-specificfactors. Speech samples are available at https://ditto-tts.github.io.</description><author>Keon Lee, Dong Won Kim, Jaehyeon Kim, Seungjun Chung, Jaewoong Cho</author><pubDate>Mon, 17 Feb 2025 17:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11427v2</guid></item><item><title>AI-generated Text Detection with a GLTR-based Approach</title><link>http://arxiv.org/abs/2502.12064v1</link><description>The rise of LLMs (Large Language Models) has contributed to the improvedperformance and development of cutting-edge NLP applications. However, thesecan also pose risks when used maliciously, such as spreading fake news, harmfulcontent, impersonating individuals, or facilitating school plagiarism, amongothers. This is because LLMs can generate high-quality texts, which arechallenging to differentiate from those written by humans. GLTR, which standsfor Giant Language Model Test Room and was developed jointly by the MIT-IBMWatson AI Lab and HarvardNLP, is a visual tool designed to help detectmachine-generated texts based on GPT-2, that highlights the words in textdepending on the probability that they were machine-generated. One limitationof GLTR is that the results it returns can sometimes be ambiguous and lead toconfusion. This study aims to explore various ways to improve GLTR'seffectiveness for detecting AI-generated texts within the context of theIberLef-AuTexTification 2023 shared task, in both English and Spanishlanguages. Experiment results show that our GLTR-based GPT-2 model overcomesthe state-of-the-art models on the English dataset with a macro F1-score of80.19%, except for the first ranking model (80.91%). However, for the Spanishdataset, we obtained a macro F1-score of 66.20%, which differs by 4.57%compared to the top-performing model.</description><author>LucÃ­a Yan Wu, Isabel Segura-Bedmar</author><pubDate>Mon, 17 Feb 2025 17:32:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12064v1</guid></item><item><title>Low-Rank Thinning</title><link>http://arxiv.org/abs/2502.12063v1</link><description>The goal in thinning is to summarize a dataset using a small set ofrepresentative points. Remarkably, sub-Gaussian thinning algorithms like KernelHalving and Compress can match the quality of uniform subsampling whilesubstantially reducing the number of summary points. However, existingguarantees cover only a restricted range of distributions and kernel-basedquality measures and suffer from pessimistic dimension dependence. To addressthese deficiencies, we introduce a new low-rank analysis of sub-Gaussianthinning that applies to any distribution and any kernel, guaranteeinghigh-quality compression whenever the kernel or data matrix is approximatelylow-rank. To demonstrate the broad applicability of the techniques, we designpractical sub-Gaussian thinning approaches that improve upon the best knownguarantees for approximating attention in transformers, accelerating stochasticgradient training through reordering, and distinguishing distributions innear-linear time.</description><author>Annabelle Michael Carrell, Albert Gong, Abhishek Shetty, Raaz Dwivedi, Lester Mackey</author><pubDate>Mon, 17 Feb 2025 17:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12063v1</guid></item><item><title>Culture is Not Trivia: Sociocultural Theory for Cultural NLP</title><link>http://arxiv.org/abs/2502.12057v1</link><description>The field of cultural NLP has recently experienced rapid growth, driven by apressing need to ensure that language technologies are effective and safeacross a pluralistic user base. This work has largely progressed without ashared conception of culture, instead choosing to rely on a wide array ofcultural proxies. However, this leads to a number of recurring limitations:coarse national boundaries fail to capture nuanced differences that lay withinthem, limited coverage restricts datasets to only a subset of usuallyhighly-represented cultures, and a lack of dynamicity results in staticcultural benchmarks that do not change as culture evolves. In this positionpaper, we argue that these methodological limitations are symptomatic of atheoretical gap. We draw on a well-developed theory of culture fromsociocultural linguistics to fill this gap by 1) demonstrating in a case studyhow it can clarify methodological constraints and affordances, 2) offeringtheoretically-motivated paths forward to achieving cultural competence, and 3)arguing that localization is a more useful framing for the goals of muchcurrent work in cultural NLP.</description><author>Naitian Zhou, David Bamman, Isaac L. Bleaman</author><pubDate>Mon, 17 Feb 2025 17:25:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12057v1</guid></item><item><title>Understanding Figurative Meaning through Explainable Visual Entailment</title><link>http://arxiv.org/abs/2405.01474v3</link><description>Large Vision-Language Models (VLMs) have demonstrated strong capabilities intasks requiring a fine-grained understanding of literal meaning in images andtext, such as visual question-answering or visual entailment. However, therehas been little exploration of the capabilities of these models when presentedwith images and captions containing figurative meaning, such as metaphors orhumor. To close this gap, we propose a new task framing the figurative meaningunderstanding problem as an explainable visual entailment task, where the modelhas to predict whether the image (premise) entails a caption (hypothesis) andjustify the predicted label with a textual explanation. The figurativephenomena can be present in the image, in the caption, or both. Using ahuman-AI collaboration approach, we build the accompanying expert-verifieddataset V-FLUTE, containing 6,027 {image, caption, label, explanation}instances spanning five diverse figurative phenomena: metaphors, similes,idioms, sarcasm, and humor. Through automatic evaluation, we find that VLMsstruggle to generalize from literal to figurative meaning, particularly when itis present in images. Further, we identify common types of errors in VLMreasoning (hallucination and incomplete or unsound reasoning) across classes ofmodels via human evaluation.</description><author>Arkadiy Saakyan, Shreyas Kulkarni, Tuhin Chakrabarty, Smaranda Muresan</author><pubDate>Mon, 17 Feb 2025 17:24:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01474v3</guid></item><item><title>Designing Role Vectors to Improve LLM Inference Behaviour</title><link>http://arxiv.org/abs/2502.12055v1</link><description>The influence of personas on Large Language Models (LLMs) has been widelystudied, yet their direct impact on performance remains uncertain. This workexplores a novel approach to guiding LLM behaviour through role vectors, analternative to persona-based prompting. We construct 29 role vectors derivedfrom model activations and evaluate their impact on benchmark performanceacross multiple domains. Our analysis investigates whether these vectors caneffectively steer models toward domain-specific expertise. We measure two keyinterventions: (i) activation addition, which reinforces role-specificdirections, and (ii) directional ablation, which removes them. Results onwell-established benchmarks indicate that role vectors do, in fact, influencemodel behaviour, improving task performance in relevant domains whilemarginally affecting unrelated tasks. This, in turn, suggests that manipulatinginternal model representations has a greater impact on outcomes thanpersona-based prompting.</description><author>Daniele PotertÃ¬, Andrea Seveso, Fabio Mercorio</author><pubDate>Mon, 17 Feb 2025 17:24:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12055v1</guid></item><item><title>PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning</title><link>http://arxiv.org/abs/2502.12054v1</link><description>Large language models demonstrate remarkable capabilities across variousdomains, especially mathematics and logic reasoning. However, currentevaluations overlook physics-based reasoning - a complex task requiring physicstheorems and constraints. We present PhysReason, a 1,200-problem benchmarkcomprising knowledge-based (25%) and reasoning-based (75%) problems, where thelatter are divided into three difficulty levels (easy, medium, hard). Notably,problems require an average of 8.1 solution steps, with hard requiring 15.6,reflecting the complexity of physics-based reasoning. We propose the PhysicsSolution Auto Scoring Framework, incorporating efficient answer-level andcomprehensive step-level evaluations. Top-performing models like Deepseek-R1,Gemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% onanswer-level evaluation, with performance dropping from knowledge questions(75.11%) to hard problems (31.95%). Through step-level evaluation, weidentified four key bottlenecks: Physics Theorem Application, Physics ProcessUnderstanding, Calculation, and Physics Condition Analysis. These findingsposition PhysReason as a novel and comprehensive benchmark for evaluatingphysics-based reasoning capabilities in large language models. Our code anddata will be published at https:/dxzxy12138.github.io/PhysReason.</description><author>Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu</author><pubDate>Mon, 17 Feb 2025 17:24:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12054v1</guid></item><item><title>A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability</title><link>http://arxiv.org/abs/2502.12052v1</link><description>In NLG meta-evaluation, evaluation metrics are typically assessed based ontheir consistency with humans. However, we identify some limitations intraditional NLG meta-evaluation approaches, such as issues in handling humanratings and ambiguous selections of correlation measures, which undermine theeffectiveness of meta-evaluation. In this work, we propose a dual-perspectiveNLG meta-evaluation framework that focuses on different evaluationcapabilities, thereby providing better interpretability. In addition, weintroduce a method of automatically constructing the corresponding benchmarkswithout requiring new human annotations. Furthermore, we conduct experimentswith 16 representative LLMs as the evaluators based on our proposed framework,comprehensively analyzing their evaluation performance from differentperspectives.</description><author>Xinyu Hu, Mingqi Gao, Li Lin, Zhenghan Yu, Xiaojun Wan</author><pubDate>Mon, 17 Feb 2025 17:22:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12052v1</guid></item><item><title>How to Upscale Neural Networks with Scaling Law? A Survey and Practical Guidelines</title><link>http://arxiv.org/abs/2502.12051v1</link><description>Neural scaling laws have revolutionized the design and optimization oflarge-scale AI models by revealing predictable relationships between modelsize, dataset volume, and computational resources. Early research establishedpower-law relationships in model performance, leading to compute-optimalscaling strategies. However, recent studies highlighted their limitationsacross architectures, modalities, and deployment contexts. Sparse models,mixture-of-experts, retrieval-augmented learning, and multimodal models oftendeviate from traditional scaling patterns. Moreover, scaling behaviors varyacross domains such as vision, reinforcement learning, and fine-tuning,underscoring the need for more nuanced approaches. In this survey, wesynthesize insights from over 50 studies, examining the theoreticalfoundations, empirical findings, and practical implications of scaling laws. Wealso explore key challenges, including data efficiency, inference scaling, andarchitecture-specific constraints, advocating for adaptive scaling strategiestailored to real-world applications. We suggest that while scaling laws providea useful guide, they do not always generalize across all architectures andtraining strategies.</description><author>Ayan Sengupta, Yash Goel, Tanmoy Chakraborty</author><pubDate>Mon, 17 Feb 2025 17:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12051v1</guid></item><item><title>SpeechT: Findings of the First Mentorship in Speech Translation</title><link>http://arxiv.org/abs/2502.12050v1</link><description>This work presents the details and findings of the first mentorship in speechtranslation (SpeechT), which took place in December 2024 and January 2025. Tofulfil the requirements of the mentorship, the participants engaged in keyactivities, including data preparation, modelling, and advanced research.</description><author>Yasmin Moslem, Juan JuliÃ¡n Cea MorÃ¡n, Mariano Gonzalez-Gomez, Muhammad Hazim Al Farouq, Farah Abdou, Satarupa Deb</author><pubDate>Mon, 17 Feb 2025 17:18:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12050v1</guid></item><item><title>HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation</title><link>http://arxiv.org/abs/2502.09838v2</link><description>We present HealthGPT, a powerful Medical Large Vision-Language Model(Med-LVLM) that integrates medical visual comprehension and generationcapabilities within a unified autoregressive paradigm. Our bootstrappingphilosophy is to progressively adapt heterogeneous comprehension and generationknowledge to pre-trained large language models (LLMs). This is achieved througha novel heterogeneous low-rank adaptation (H-LoRA) technique, which iscomplemented by a tailored hierarchical visual perception approach and athree-stage learning strategy. To effectively learn the HealthGPT, we devise acomprehensive medical domain-specific comprehension and generation datasetcalled VL-Health. Experimental results demonstrate exceptional performance andscalability of HealthGPT in medical visual unified tasks. Our project can beaccessed at https://github.com/DCDmllm/HealthGPT.</description><author>Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang, Mengze Li, Xiaohui Song, Siliang Tang, Jun Xiao, Hui Lin, Yueting Zhuang, Beng Chin Ooi</author><pubDate>Mon, 17 Feb 2025 17:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09838v2</guid></item><item><title>Classifying the Stoichiometry of Virus-like Particles with Interpretable Machine Learning</title><link>http://arxiv.org/abs/2502.12049v1</link><description>Virus-like particles (VLPs) are valuable for vaccine development due to theirimmune-triggering properties. Understanding their stoichiometry, the number ofprotein subunits to form a VLP, is critical for vaccine optimisation. However,current experimental methods to determine stoichiometry are time-consuming andrequire highly purified proteins. To efficiently classify stoichiometry classesin proteins, we curate a new dataset and propose an interpretable, data-drivenpipeline leveraging linear machine learning models. We also explore the impactof feature encoding on model performance and interpretability, as well asmethods to identify key protein sequence features influencing classification.The evaluation of our pipeline demonstrates that it can classify stoichiometrywhile revealing protein features that possibly influence VLP assembly. The dataand code used in this work are publicly available athttps://github.com/Shef-AIRE/StoicIML.</description><author>Jiayang Zhang, Xianyuan Liu, Wei Wu, Sina Tabakhi, Wenrui Fan, Shuo Zhou, Kang Lan Tee, Tuck Seng Wong, Haiping Lu</author><pubDate>Mon, 17 Feb 2025 17:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12049v1</guid></item><item><title>A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond</title><link>http://arxiv.org/abs/2502.12048v1</link><description>Integration of Brain-Computer Interfaces (BCIs) and Generative ArtificialIntelligence (GenAI) has opened new frontiers in brain signal decoding,enabling assistive communication, neural representation learning, andmultimodal integration. BCIs, particularly those leveragingElectroencephalography (EEG), provide a non-invasive means of translatingneural activity into meaningful outputs. Recent advances in deep learning,including Generative Adversarial Networks (GANs) and Transformer-based LargeLanguage Models (LLMs), have significantly improved EEG-based generation ofimages, text, and speech. This paper provides a literature review of thestate-of-the-art in EEG-based multimodal generation, focusing on (i)EEG-to-image generation through GANs, Variational Autoencoders (VAEs), andDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer basedlanguage models and contrastive learning methods. Additionally, we discuss theemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. Wehighlight key datasets, use cases, challenges, and EEG feature encoding methodsthat underpin generative approaches. By providing a structured overview ofEEG-based generative AI, this survey aims to equip researchers andpractitioners with insights to advance neural decoding, enhance assistivetechnologies, and expand the frontiers of brain-computer interaction.</description><author>Shreya Shukla, Jose Torres, Abhijit Mishra, Jacek Gwizdka, Shounak Roychowdhury</author><pubDate>Mon, 17 Feb 2025 17:16:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12048v1</guid></item><item><title>Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach</title><link>http://arxiv.org/abs/2502.05171v2</link><description>We study a novel language model architecture that is capable of scalingtest-time computation by implicitly reasoning in latent space. Our model worksby iterating a recurrent block, thereby unrolling to arbitrary depth attest-time. This stands in contrast to mainstream reasoning models that scale upcompute by producing more tokens. Unlike approaches based on chain-of-thought,our approach does not require any specialized training data, can work withsmall context windows, and can capture types of reasoning that are not easilyrepresented in words. We scale a proof-of-concept model to 3.5 billionparameters and 800 billion tokens. We show that the resulting model can improveits performance on reasoning benchmarks, sometimes dramatically, up to acomputation load equivalent to 50 billion parameters.</description><author>Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Tom Goldstein</author><pubDate>Mon, 17 Feb 2025 17:14:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05171v2</guid></item><item><title>Revisiting the Equivalence of Bayesian Neural Networks and Gaussian Processes: On the Importance of Learning Activations</title><link>http://arxiv.org/abs/2410.15777v2</link><description>Gaussian Processes (GPs) provide a convenient framework for specifyingfunction-space priors, making them a natural choice for modeling uncertainty.In contrast, Bayesian Neural Networks (BNNs) offer greater scalability andextendability but lack the advantageous properties of GPs. This motivates thedevelopment of BNNs capable of replicating GP-like behavior. However, existingsolutions are either limited to specific GP kernels or rely on heuristics. We demonstrate that trainable activations are crucial for effective mappingof GP priors to wide BNNs. Specifically, we leverage the closed-form2-Wasserstein distance for efficient gradient-based optimization ofreparameterized priors and activations. Beyond learned activations, we alsointroduce trainable periodic activations that ensure global stationarity bydesign, and functional priors conditioned on GP hyperparameters to allowefficient model selection. Empirically, our method consistently outperforms existing approaches ormatches performance of the heuristic methods, while offering strongertheoretical foundations.</description><author>Marcin Sendera, Amin Sorkhei, Tomasz KuÅ›mierczyk</author><pubDate>Mon, 17 Feb 2025 17:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15777v2</guid></item><item><title>The geometry of BERT</title><link>http://arxiv.org/abs/2502.12033v1</link><description>Transformer neural networks, particularly Bidirectional EncoderRepresentations from Transformers (BERT), have shown remarkable performanceacross various tasks such as classification, text summarization, and questionanswering. However, their internal mechanisms remain mathematically obscure,highlighting the need for greater explainability and interpretability. In thisdirection, this paper investigates the internal mechanisms of BERT proposing anovel perspective on the attention mechanism of BERT from a theoreticalperspective. The analysis encompasses both local and global network behavior.At the local level, the concept of directionality of subspace selection as wellas a comprehensive study of the patterns emerging from the self-attentionmatrix are presented. Additionally, this work explores the semantic content ofthe information stream through data distribution analysis and globalstatistical measures including the novel concept of cone index. A case study onthe classification of SARS-CoV-2 variants using RNA which resulted in a veryhigh accuracy has been selected in order to observe these concepts in anapplication. The insights gained from this analysis contribute to a deeperunderstanding of BERT's classification process, offering potential avenues forfuture architectural improvements in Transformer models and further analysis inthe training process.</description><author>Matteo Bonino, Giorgia Ghione, Giansalvo Cirrincione</author><pubDate>Mon, 17 Feb 2025 17:03:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12033v1</guid></item><item><title>Masked Latent Prediction and Classification for Self-Supervised Audio Representation Learning</title><link>http://arxiv.org/abs/2502.12031v1</link><description>Recently, self-supervised learning methods based on masked latent predictionhave proven to encode input data into powerful representations. However, duringtraining, the learned latent space can be further transformed to extracthigher-level information that could be more suited for downstreamclassification tasks. Therefore, we propose a new method: MAsked latenTPrediction And Classification (MATPAC), which is trained with two pretext taskssolved jointly. As in previous work, the first pretext task is a masked latentprediction task, ensuring a robust input representation in the latent space.The second one is unsupervised classification, which utilises the latentrepresentations of the first pretext task to match probability distributionsbetween a teacher and a student. We validate the MATPAC method by comparing itto other state-of-the-art proposals and conducting ablations studies. MATPACreaches state-of-the-art self-supervised learning results on reference audioclassification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperformscomparable supervised methods results for musical auto-tagging onMagna-tag-a-tune.</description><author>Aurian Quelennec, Pierre Chouteau, Geoffroy Peeters, Slim Essid</author><pubDate>Mon, 17 Feb 2025 17:02:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12031v1</guid></item><item><title>KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths over Knowledge Graphs</title><link>http://arxiv.org/abs/2502.12029v1</link><description>Large language models (LLMs) have demonstrated remarkable capabilities invarious complex tasks, yet they still suffer from hallucinations. Introducingexternal knowledge, such as knowledge graph, can enhance the LLMs' ability toprovide factual answers. LLMs have the ability to interactively exploreknowledge graphs. However, most approaches have been affected by insufficientinternal knowledge excavation in LLMs, limited generation of trustworthyknowledge reasoning paths, and a vague integration between internal andexternal knowledge. Therefore, we propose KnowPath, a knowledge-enhanced largemodel framework driven by the collaboration of internal and external knowledge.It relies on the internal knowledge of the LLM to guide the exploration ofinterpretable directed subgraphs in external knowledge graphs, betterintegrating the two knowledge sources for more accurate reasoning. Extensiveexperiments on multiple real-world datasets confirm the superiority ofKnowPath.</description><author>Qi Zhao, Hongyu Yang, Qi Song, Xinwei Yao, Xiangyang Li</author><pubDate>Mon, 17 Feb 2025 17:02:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12029v1</guid></item><item><title>Enhancing Transparent Object Pose Estimation: A Fusion of GDR-Net and Edge Detection</title><link>http://arxiv.org/abs/2502.12027v1</link><description>Object pose estimation of transparent objects remains a challenging task inthe field of robot vision due to the immense influence of lighting, background,and reflections. However, the edges of clear objects have the highest contrast,which leads to stable and prominent features. We propose a novel approach byincorporating edge detection in a pre-processing step for the tasks of objectdetection and object pose estimation. We conducted experiments to investigatethe effect of edge detectors on transparent objects. We examine the performanceof the state-of-the-art 6D object pose estimation pipeline GDR-Net and theobject detector YOLOX when applying different edge detectors as pre-processingsteps (i.e., Canny edge detection with and without color information, andholistically-nested edges (HED)). We evaluate the physically-based rendereddataset Trans6D-32 K of transparent objects with parameters proposed by the BOPChallenge. Our results indicate that applying edge detection as apre-processing enhances performance for certain objects.</description><author>Tessa Pulli, Peter HÃ¶nig, Stefan Thalhammer, Matthias Hirschmanner, Markus Vincze</author><pubDate>Mon, 17 Feb 2025 16:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12027v1</guid></item><item><title>SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities</title><link>http://arxiv.org/abs/2502.12025v1</link><description>Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leveragelong chain-of-thought (CoT) reasoning to generate structured intermediatesteps, enhancing their reasoning capabilities. However, long CoT does notinherently guarantee safe outputs, potentially leading to harmful consequencessuch as the introduction of security vulnerabilities in code or the spread ofmisinformation. Current research on large language model (LLM) safety usuallyfocuses on short-answer responses, overlooking the long CoT style outputs ofLRMs. To bridge this gap, we conduct a systematic study of LRM safety. First,we investigate safety evaluators calibrated against human annotations. Usingour newly developed metrics, we thoroughly assess the safety of 12state-of-the-art LRMs on StrongReject and WildJailbreak datasets. Our resultsshow that LRMs are not safe compared to their reasoning advance. Further, weperform a fine-grained analysis of the reasoning trace and final answer. Wefind that three decoding strategies-ZeroThink, LessThink, and MoreThink-canimprove model safety without additional training. However, these strategieseither use constrained reasoning traces or incur high inference costs. Tobetter strengthen LRM safety, we introduce SafeChain, the first-of-its-kindsafety training dataset in CoT style. We fine-tune two LRMs with SafeChain,showing that it not only enhances model safety but also preserves performanceacross 6 reasoning benchmarks.</description><author>Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, Radha Poovendran</author><pubDate>Mon, 17 Feb 2025 16:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12025v1</guid></item><item><title>Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving</title><link>http://arxiv.org/abs/2502.12022v1</link><description>Existing approaches to mathematical reasoning with large language models(LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-IntegratedReasoning (TIR) for precise computation. While efforts have been made tocombine these methods, they primarily rely on post-selection or predefinedstrategies, leaving an open question: whether LLMs can autonomously adapt theirreasoning strategy based on their inherent capabilities. In this work, wepropose TATA (Teaching LLMs According to Their Aptitude), an adaptive frameworkthat enables LLMs to personalize their reasoning strategy spontaneously,aligning it with their intrinsic aptitude. TATA incorporates base-LLM-awaredata selection during supervised fine-tuning (SFT) to tailor training data tothe model's unique abilities. This approach equips LLMs to autonomouslydetermine and apply the appropriate reasoning strategy at test time. Weevaluate TATA through extensive experiments on six mathematical reasoningbenchmarks, using both general-purpose and math-specialized LLMs. Empiricalresults demonstrate that TATA effectively combines the complementary strengthsof CoT and TIR, achieving superior or comparable performance with improvedinference efficiency compared to TIR alone. Further analysis underscores thecritical role of aptitude-aware data selection in enabling LLMs to makeeffective and adaptive reasoning decisions and align reasoning strategies withmodel capabilities.</description><author>Xin Xu, Yan Xu, Tianhao Chen, Yuchen Yan, Chengwu Liu, Zaoyu Chen, Yufei Wang, Yichun Yin, Yasheng Wang, Lifeng Shang, Qun Liu</author><pubDate>Mon, 17 Feb 2025 16:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12022v1</guid></item><item><title>Learning in a Multifield Coherent Ising Machine</title><link>http://arxiv.org/abs/2502.12020v1</link><description>Physical information processors can learn from examples if they are modifiedaccording to an abstract parameter update equation, termed a learning rule. Weintroduce a physical model for self-learning that encodes the learning rule inthe Hamiltonian of the system. The model consists of a network of multi-modalresonators. One of the modes is driven parametrically into a bi-stable regime,forming a coherent Ising machine (CIM) -- that provides the long-term memorythat stores learned responses (weights). The CIM is augmented with anadditional spinor field that acts as short-term (activation) memory. Wenumerically demonstrate that, in the presence of suitable nonlinearinteractions between the long-term memory Ising machine and the short-termmemory auxiliary field, the system autonomously learns from examples.</description><author>Daan de Bos, Marc Serra-Garcia</author><pubDate>Mon, 17 Feb 2025 16:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12020v1</guid></item><item><title>Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</title><link>http://arxiv.org/abs/2501.18592v3</link><description>In real-world scenarios, achieving domain adaptation and generalization posessignificant challenges, as models must adapt to or generalize across unknowntarget distributions. Extending these capabilities to unseen multimodaldistributions, i.e., multimodal domain adaptation and generalization, is evenmore challenging due to the distinct characteristics of different modalities.Significant progress has been made over the years, with applications rangingfrom action recognition to semantic segmentation. Besides, the recent advent oflarge-scale pre-trained multimodal foundation models, such as CLIP, hasinspired works leveraging these models to enhance adaptation and generalizationperformances or adapting them to downstream tasks. This survey provides thefirst comprehensive review of recent advances from traditional approaches tofoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodaltest-time adaptation; (3) Multimodal domain generalization; (4) Domainadaptation and generalization with the help of multimodal foundation models;and (5) Adaptation of multimodal foundation models. For each topic, we formallydefine the problem and thoroughly review existing methods. Additionally, weanalyze relevant datasets and applications, highlighting open challenges andpotential future research directions. We maintain an active repository thatcontains up-to-date literature athttps://github.com/donghao51/Awesome-Multimodal-Adaptation.</description><author>Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink</author><pubDate>Mon, 17 Feb 2025 16:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18592v3</guid></item><item><title>Investigating the importance of social vulnerability in opioid-related mortality across the United States</title><link>http://arxiv.org/abs/2412.15218v2</link><description>The opioid crisis remains a critical public health challenge in the UnitedStates. Despite national efforts to reduce opioid prescribing rates by nearly45\% between 2011 and 2021, opioid overdose deaths more than tripled duringthis same period. This alarming trend reflects a major shift in the crisis,with illegal opioids now driving the majority of overdose deaths instead ofprescription opioids. Although much attention has been given to supply-sidefactors fueling this transition, the underlying socioeconomic conditions thatperpetuate and exacerbate opioid misuse remain less understood. Moreover, theCOVID-19 pandemic intensified the opioid crisis through widespread socialisolation and record-high unemployment; consequently, understanding thesocioeconomic drivers of this epidemic has become even more crucial in recentyears. To address this need, our study examines the correlation betweenopioid-related mortality and thirteen components of the Social VulnerabilityIndex (SVI). Leveraging a nationwide county-level dataset spanning consecutiveyears from 2010 to 2022, this study integrates empirical insights fromexploratory data analysis with feature importance metrics derived from machinelearning models. Our findings highlight critical social factors stronglycorrelated with opioid-related mortality, emphasizing their potential roles inworsening the epidemic when their levels are high and mitigating it when theirlevels are low.</description><author>Andrew Deas, Adam Spannaus, Dakotah D. Maguire, Jodie Trafton, Anuj J. Kapadia, Vasileios Maroulas</author><pubDate>Mon, 17 Feb 2025 16:54:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15218v2</guid></item><item><title>Atom of Thoughts for Markov LLM Test-Time Scaling</title><link>http://arxiv.org/abs/2502.12018v1</link><description>Large Language Models (LLMs) achieve superior performance throughtraining-time scaling, and test-time scaling further enhances theircapabilities by conducting effective reasoning during inference. However, asthe scale of reasoning increases, existing test-time scaling methods sufferfrom accumulated historical information, which not only wastes computationalresources but also interferes with effective reasoning. To address this issue,we observe that complex reasoning progress is often achieved by solving asequence of independent subquestions, each being self-contained and verifiable.These subquestions are essentially atomic questions, relying primarily on theircurrent state rather than accumulated history, similar to the memorylesstransitions in a Markov process. Based on this observation, we propose Atom ofThoughts (AoT), where each state transition in the reasoning process consistsof decomposing the current question into a dependency-based directed acyclicgraph and contracting its subquestions, forming a new atomic question state.This iterative decomposition-contraction process continues until reachingdirectly solvable atomic questions, naturally realizing Markov transitionsbetween question states. Furthermore, these atomic questions can be seamlesslyintegrated into existing test-time scaling methods, enabling AoT to serve as aplug-in enhancement for improving reasoning capabilities. Experiments acrosssix benchmarks demonstrate the effectiveness of AoT both as a standaloneframework and a plug-in enhancement. Notably, on HotpotQA, when applied togpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% andDeepSeek-R1 by 10.6%. The code will be available athttps://github.com/qixucen/atom.</description><author>Fengwei Teng, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo</author><pubDate>Mon, 17 Feb 2025 16:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12018v1</guid></item><item><title>MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs</title><link>http://arxiv.org/abs/2502.00997v3</link><description>The recent success of specialized Large Language Models (LLMs) in domainssuch as mathematical reasoning and coding has led to growing interest inmethods for merging these expert LLMs into a unified Mixture-of-Experts (MoE)model, with the goal of enhancing performance in each domain while retainingeffectiveness on general tasks. However, the effective merging of expert modelsremains an open challenge, especially for models with highly divergent weightparameters or different architectures. State-of-the-art MoE merging methodsonly work with homogeneous model architectures and rely on simple unweightedaveraging to merge expert layers, which does not address parameter interferenceand requires extensive fine-tuning of the merged MoE to restore performance. Toaddress these limitations, this paper introduces new MoE merging techniques,including strategies to mitigate parameter interference, routing heuristics toreduce the need for MoE fine-tuning, and a novel method for merging expertswith different architectures. Extensive experiments across multiple domainsdemonstrate the effectiveness of our proposed methods, reducing fine-tuningcosts, improving performance over state-of-the-art methods, and expanding theapplicability of MoE merging.</description><author>Yuhang Zhou, Giannis Karamanolakis, Victor Soto, Anna Rumshisky, Mayank Kulkarni, Furong Huang, Wei Ai, Jianhua Lu</author><pubDate>Mon, 17 Feb 2025 16:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.00997v3</guid></item><item><title>Unsupervised Structural-Counterfactual Generation under Domain Shift</title><link>http://arxiv.org/abs/2502.12013v1</link><description>Motivated by the burgeoning interest in cross-domain learning, we present anovel generative modeling challenge: generating counterfactual samples in atarget domain based on factual observations from a source domain. Our approachoperates within an unsupervised paradigm devoid of parallel or joint datasets,relying exclusively on distinct observational samples and causal graphs foreach domain. This setting presents challenges that surpass those ofconventional counterfactual generation. Central to our methodology is thedisambiguation of exogenous causes into effect-intrinsic and domain-intrinsiccategories. This differentiation facilitates the integration of domain-specificcausal graphs into a unified joint causal graph via shared effect-intrinsicexogenous variables. We propose leveraging Neural Causal models within thisjoint framework to enable accurate counterfactual generation under standardidentifiability assumptions. Furthermore, we introduce a novel loss functionthat effectively segregates effect-intrinsic from domain-intrinsic variablesduring model training. Given a factual observation, our framework combines theposterior distribution of effect-intrinsic variables from the source domainwith the prior distribution of domain-intrinsic variables from the targetdomain to synthesize the desired counterfactuals, adhering to Pearl's causalhierarchy. Intriguingly, when domain shifts are restricted to alterations incausal mechanisms without accompanying covariate shifts, our training regimenparallels the resolution of a conditional optimal transport problem. Empiricalevaluations on a synthetic dataset show that our framework generatescounterfactuals in the target domain that very closely resemble the groundtruth.</description><author>Krishn Vishwas Kher, Lokesh Venkata Siva Maruthi Badisa, Kusampudi Venkata Datta Sri Harsha, Chitneedi Geetha Sowmya, SakethaNath Jagarlapudi</author><pubDate>Mon, 17 Feb 2025 16:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12013v1</guid></item><item><title>Reconfigurable Intelligent Surfaces-Assisted Integrated Access and Backhaul</title><link>http://arxiv.org/abs/2502.12011v1</link><description>In this paper, we study the impact of reconfigurable intelligent surfaces(RISs) on the coverage extension of integrated access and backhaul (IAB)networks. Particularly, using a finite stochastic geometry model, with randomdistributions of user equipments (UEs) in a finite region, and plannedhierachical architecture for IAB, we study the service coverage probabilitydefined as the probability of the event that the UEs' minimum rate requirementsare satisfied. We present comparisons between different cases includingIAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by networkcontrolled repeaters (NCRs). Our investigations focus on wide-area IAB assistedwith RIS through the lens of different design architectures and deployments,revealing both conflicts and synergies for minimizing the effect of treefoliage over seasonal changes. Our simulation results reveal both opportunitiesand challenges towards the implementation of RIS in IAB.</description><author>Charitha Madapatha, Behrooz Makki, Hao Guo, Tommy Svensson</author><pubDate>Mon, 17 Feb 2025 16:46:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12011v1</guid></item><item><title>Demographic Attributes Prediction from Speech Using WavLM Embeddings</title><link>http://arxiv.org/abs/2502.12007v1</link><description>This paper introduces a general classifier based on WavLM features, to inferdemographic characteristics, such as age, gender, native language, education,and country, from speech. Demographic feature prediction plays a crucial rolein applications like language learning, accessibility, and digital forensics,enabling more personalized and inclusive technologies. Leveraging pretrainedmodels for embedding extraction, the proposed framework identifies key acousticand linguistic fea-tures associated with demographic attributes, achieving aMean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracyfor gender classification across various datasets. Our system improves uponexisting models by up to relative 30% in MAE and up to relative 10% in accuracyand F1 scores across tasks, leveraging a diverse range of datasets and largepretrained models to ensure robustness and generalizability. This study offersnew insights into speaker diversity and provides a strong foundation for futureresearch in speech-based demographic profiling.</description><author>Yuchen Yang, Thomas Thebaud, Najim Dehak</author><pubDate>Mon, 17 Feb 2025 16:43:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12007v1</guid></item><item><title>Predicting Next-Day Wildfire Spread with Time Series and Attention</title><link>http://arxiv.org/abs/2502.12003v1</link><description>Recent research has demonstrated the potential of deep neural networks (DNNs)to accurately predict next-day wildfire spread, based upon the current extentof a fire and geospatial rasters of influential environmental covariates e.g.,vegetation, topography, climate, and weather. In this work, we investigate arecent transformer-based model, termed the SwinUnet, for next-day wildfireprediction. We benchmark Swin-based models against several currentstate-of-the-art models on WildfireSpreadTS (WFTS), a large public benchmarkdataset of historical wildfire events. We consider two next-day fire predictionscenarios: when the model is given input of (i) a single previous day of data,or (ii) five previous days of data. We find that, with the propermodifications, SwinUnet achieves state-of-the-art accuracy on next-dayprediction for both the single-day and multi-day scenarios. SwinUnet's successdepends heavily upon utilizing pre-trained weights from ImageNet. Consistentwith prior work, we also found that models with multi-day-input alwaysoutperformed models with single-day input.</description><author>Saad Lahrichi, Jesse Johnson, Jordan Malof</author><pubDate>Mon, 17 Feb 2025 16:41:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12003v1</guid></item><item><title>NaturalL2S: End-to-End High-quality Multispeaker Lip-to-Speech Synthesis with Differential Digital Signal Processing</title><link>http://arxiv.org/abs/2502.12002v1</link><description>Recent advancements in visual speech recognition (VSR) have promoted progressin lip-to-speech synthesis, where pre-trained VSR models enhance theintelligibility of synthesized speech by providing valuable semanticinformation. The success achieved by cascade frameworks, which combinepseudo-VSR with pseudo-text-to-speech (TTS) or implicitly utilize thetranscribed text, highlights the benefits of leveraging VSR models. However,these methods typically rely on mel-spectrograms as an intermediaterepresentation, which may introduce a key bottleneck: the domain gap betweensynthetic mel-spectrograms, generated from inherently error-prone lip-to-speechmappings, and real mel-spectrograms used to train vocoders. This mismatchinevitably degrades synthesis quality. To bridge this gap, we propose NaturalLip-to-Speech (NaturalL2S), an end-to-end framework integrating acousticinductive biases with differentiable speech generation components.Specifically, we introduce a fundamental frequency (F0) predictor to captureprosodic variations in synthesized speech. The predicted F0 then drives aDifferentiable Digital Signal Processing (DDSP) synthesizer to generate acoarse signal which serves as prior information for subsequent speechsynthesis. Additionally, instead of relying on a reference speaker embedding asan auxiliary input, our approach achieves satisfactory performance on speakersimilarity without explicitly modelling speaker characteristics. Both objectiveand subjective evaluation results demonstrate that NaturalL2S can effectivelyenhance the quality of the synthesized speech when compared to state-of-the-artmethods. Our demonstration page is accessible athttps://yifan-liang.github.io/NaturalL2S/.</description><author>Yifan Liang, Fangkun Liu, Andong Li, Xiaodong Li, Chengshi Zheng</author><pubDate>Mon, 17 Feb 2025 16:40:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12002v1</guid></item><item><title>Merging Language and Domain Specific Models: The Impact on Technical Vocabulary Acquisition</title><link>http://arxiv.org/abs/2502.12001v1</link><description>This paper investigates the integration of technical vocabulary in mergedlanguage models. We explore the knowledge transfer mechanisms involved whencombining a general-purpose language-specific model with a domain-specificmodel, focusing on the resulting model's comprehension of technical jargon. Ourexperiments analyze the impact of this merging process on the target model'sproficiency in handling specialized terminology. We present a quantitativeevaluation of the performance of the merged model, comparing it with that ofthe individual constituent models. The findings offer insights into theeffectiveness of different model merging methods for enhancing domain-specificknowledge and highlight potential challenges and future directions inleveraging these methods for cross-lingual knowledge transfer in NaturalLanguage Processing.</description><author>Thibault Rousset, Taisei Kakibuchi, Yusuke Sasaki, Yoshihide Nomura</author><pubDate>Mon, 17 Feb 2025 16:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.12001v1</guid></item><item><title>ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization</title><link>http://arxiv.org/abs/2502.09278v2</link><description>Recent advances in diffusion models have significantly improved 3Dgeneration, enabling the use of assets generated from an image for embodied AIsimulations. However, the one-to-many nature of the image-to-3D problem limitstheir use due to inconsistent content and quality across views. Previous modelsoptimize a 3D model by sampling views from a view-conditioned diffusion prior,but diffusion models cannot guarantee view consistency. Instead, we presentConsistentDreamer, where we first generate a set of fixed multi-view priorimages and sample random views between them with another diffusion modelthrough a score distillation sampling (SDS) loss. Thereby, we limit thediscrepancies between the views guided by the SDS loss and ensure a consistentrough shape. In each iteration, we also use our generated multi-view priorimages for fine-detail reconstruction. To balance between the rough shape andthe fine-detail optimizations, we introduce dynamic task-dependent weightsbased on homoscedastic uncertainty, updated automatically in each iteration.Additionally, we employ opacity, depth distortion, and normal alignment lossesto refine the surface for mesh extraction. Our method ensures better viewconsistency and visual quality compared to the state-of-the-art.</description><author>Onat Åžahin, Mohammad Altillawi, George Eskandar, Carlos Carbone, Ziyuan Liu</author><pubDate>Mon, 17 Feb 2025 16:37:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.09278v2</guid></item><item><title>On the Expressive Power of Sparse Geometric MPNNs</title><link>http://arxiv.org/abs/2407.02025v4</link><description>Motivated by applications in chemistry and other sciences, we study theexpressive power of message-passing neural networks for geometric graphs, whosenode features correspond to 3-dimensional positions. Recent work has shown thatsuch models can separate generic pairs of non-isomorphic geometric graphs,though they may fail to separate some rare and complicated instances. However,these results assume a fully connected graph, where each node possessescomplete knowledge of all other nodes. In contrast, often, in application,every node only possesses knowledge of a small number of nearest neighbors. This paper shows that generic pairs of non-isomorphic geometric graphs can beseparated by message-passing networks with rotation equivariant features aslong as the underlying graph is connected. When only invariant intermediatefeatures are allowed, generic separation is guaranteed for generically globallyrigid graphs. We introduce a simple architecture, EGENNET, which achieves ourtheoretical guarantees and compares favorably with alternative architecture onsynthetic and chemical benchmarks. Our code is available athttps://github.com/yonatansverdlov/E-GenNet.</description><author>Yonatan Sverdlov, Nadav Dym</author><pubDate>Mon, 17 Feb 2025 16:36:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02025v4</guid></item><item><title>Presumed Cultural Identity: How Names Shape LLM Responses</title><link>http://arxiv.org/abs/2502.11995v1</link><description>Names are deeply tied to human identity. They can serve as markers ofindividuality, cultural heritage, and personal history. However, using names asa core indicator of identity can lead to over-simplification of complexidentities. When interacting with LLMs, user names are an important point ofinformation for personalisation. Names can enter chatbot conversations throughdirect user input (requested by chatbots), as part of task contexts such as CVreviews, or as built-in memory features that store user information forpersonalisation. We study biases associated with names by measuring culturalpresumptions in the responses generated by LLMs when presented with commonsuggestion-seeking queries, which might involve making assumptions about theuser. Our analyses demonstrate strong assumptions about cultural identityassociated with names present in LLM generations across multiple cultures. Ourwork has implications for designing more nuanced personalisation systems thatavoid reinforcing stereotypes while maintaining meaningful customisation.</description><author>Siddhesh Pawar, Arnav Arora, Lucie-AimÃ©e Kaffee, Isabelle Augenstein</author><pubDate>Mon, 17 Feb 2025 16:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.11995v1</guid></item></channel></rss>