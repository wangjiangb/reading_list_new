<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 17 Jan 2024 06:01:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Faster ISNet for Background Bias Mitigation on Deep Neural Networks</title><link>http://arxiv.org/abs/2401.08409v1</link><description>Image background features can constitute background bias (spuriouscorrelations) and impact deep classifiers decisions, causing shortcut learning(Clever Hans effect) and reducing the generalization skill on real-world data.The concept of optimizing Layer-wise Relevance Propagation (LRP) heatmaps, toimprove classifier behavior, was recently introduced by a neural networkarchitecture named ISNet. It minimizes background relevance in LRP maps, tomitigate the influence of image background features on deep classifiersdecisions, hindering shortcut learning and improving generalization. For eachtraining image, the original ISNet produces one heatmap per possible class inthe classification task, hence, its training time scales linearly with thenumber of classes. Here, we introduce reformulated architectures that allow thetraining time to become independent from this number, rendering theoptimization process much faster. We challenged the enhanced models utilizingthe MNIST dataset with synthetic background bias, and COVID-19 detection inchest X-rays, an application that is prone to shortcut learning due tobackground bias. The trained models minimized background attention and hinderedshortcut learning, while retaining high accuracy. Considering external(out-of-distribution) test datasets, they consistently proved more accuratethan multiple state-of-the-art deep neural network architectures, including adedicated image semantic segmenter followed by a classifier. The architecturespresented here represent a potentially massive improvement in training speedover the original ISNet, thus introducing LRP optimization into a gamut ofapplications that could not be feasibly handled by the original model.</description><author>Pedro R. A. S. Bassi, Sergio Decherchi, Andrea Cavalli</author><pubDate>Tue, 16 Jan 2024 14:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08409v1</guid></item><item><title>Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining</title><link>http://arxiv.org/abs/2401.08407v1</link><description>Cross-Domain Few-Shot Segmentation (CD-FSS) poses the challenge of segmentingnovel categories from a distinct domain using only limited exemplars. In thispaper, we undertake a comprehensive study of CD-FSS and uncover two crucialinsights: (i) the necessity of a fine-tuning stage to effectively transfer thelearned meta-knowledge across domains, and (ii) the overfitting risk during thena\"ive fine-tuning due to the scarcity of novel category examples. With theseinsights, we propose a novel cross-domain fine-tuning strategy that addressesthe challenging CD-FSS tasks. We first design Bi-directional Few-shotPrediction (BFP), which establishes support-query correspondence in abi-directional manner, crafting augmented supervision to reduce the overfittingrisk. Then we further extend BFP into Iterative Few-shot Adaptor (IFA), whichis a recursive framework to capture the support-query correspondenceiteratively, targeting maximal exploitation of supervisory signals from thesparse novel category samples. Extensive empirical evaluations show that ourmethod significantly outperforms the state-of-the-arts (+7.8\%), which verifiesthat IFA tackles the cross-domain challenges and mitigates the overfittingsimultaneously. Code will be made available.</description><author>Jiahao Nie, Yun Xing, Gongjie Zhang, Pei Yan, Aoran Xiao, Yap-Peng Tan, Alex C. Kot, Shijian Lu</author><pubDate>Tue, 16 Jan 2024 14:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08407v1</guid></item><item><title>RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture</title><link>http://arxiv.org/abs/2401.08406v1</link><description>There are two common ways in which developers are incorporating proprietaryand domain-specific data when building applications of Large Language Models(LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments theprompt with the external data, while fine-Tuning incorporates the additionalknowledge into the model itself. However, the pros and cons of both approachesare not well understood. In this paper, we propose a pipeline for fine-tuningand RAG, and present the tradeoffs of both for multiple popular LLMs, includingLlama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages,including extracting information from PDFs, generating questions and answers,using them for fine-tuning, and leveraging GPT-4 for evaluating the results. Wepropose metrics to assess the performance of different stages of the RAG andfine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset.Agriculture as an industry has not seen much penetration of AI, and we study apotentially disruptive application - what if we could provide location-specificinsights to a farmer? Our results show the effectiveness of our datasetgeneration pipeline in capturing geographic-specific knowledge, and thequantitative and qualitative benefits of RAG and fine-tuning. We see anaccuracy increase of over 6 p.p. when fine-tuning the model and this iscumulative with RAG, which increases accuracy by 5 p.p. further. In oneparticular experiment, we also demonstrate that the fine-tuned model leveragesinformation from across geographies to answer specific questions, increasinganswer similarity from 47% to 72%. Overall, the results point to how systemsbuilt using LLMs can be adapted to respond and incorporate knowledge across adimension that is critical for a specific industry, paving the way for furtherapplications of LLMs in other industrial domains.</description><author>Aman Gupta, Anup Shirgaonkar, Angels de Luis Balaguer, Bruno Silva, Daniel Holstein, Dawei Li, Jennifer Marsman, Leonardo O. Nunes, Mahsa Rouzbahman, Morris Sharp, Nick Mecklenburg, Rafael Padilha, Ranveer Chandra, Renato Luiz de Freitas Cunha, Roberto de M. Estevão Filho, Ryan Tsang, Sara Malvar, Swati Sharma, Todd Hendry, Vijay Aski, Vijetha Vijayendran, Vinamra Benara</author><pubDate>Tue, 16 Jan 2024 14:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08406v1</guid></item><item><title>Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT</title><link>http://arxiv.org/abs/2401.08405v1</link><description>In an era of AI's growing capabilities and influences, recent advancementsare reshaping HCI and CSCW's view of AI as mere tools. Playful interactionswith AI systems naturally emerged as a way for users to make sense of theever-changing technology. However, these emergent and playful interactions areunderexamined. We target this gap by investigating playful interactionsexhibited by users of a recently trending powerful AI technology, ChatGPT.Through a thematic analysis of 372 user-generated posts on the ChatGPTsubreddit, we found that a substantial portion of user discourse revolvesaround playful interactions. The analysis further allowed us to construct apreliminary taxonomy to describe these interactions, categorizing them into sixtypes: reflecting, jesting, imitating, challenging, tricking, and contriving;each included sub-categories. Overall, this study contributes to the field ofHCI and CSCW by illuminating the multifaceted nature of playful interactionswith AI, underlining their significance in shaping the human-AI relationship.</description><author>Mohammad Ronagh Nikghalb, Jinghui Cheng</author><pubDate>Tue, 16 Jan 2024 14:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08405v1</guid></item><item><title>Training and Comparison of nnU-Net and DeepMedic Methods for Autosegmentation of Pediatric Brain Tumors</title><link>http://arxiv.org/abs/2401.08404v1</link><description>Brain tumors are the most common solid tumors and the leading cause ofcancer-related death among children. Tumor segmentation is essential insurgical and treatment planning, and response assessment and monitoring.However, manual segmentation is time-consuming and has high inter-operatorvariability, underscoring the need for more efficient methods. We compared twodeep learning-based 3D segmentation models, DeepMedic and nnU-Net, aftertraining with pediatric-specific multi-institutional brain tumor data usingbased on multi-parametric MRI scans.Multi-parametric preoperative MRI scans of339 pediatric patients (n=293 internal and n=46 external cohorts) with avariety of tumor subtypes, were preprocessed and manually segmented into fourtumor subregions, i.e., enhancing tumor (ET), non-enhancing tumor (NET), cysticcomponents (CC), and peritumoral edema (ED). After training, performance of thetwo models on internal and external test sets was evaluated using Dice scores,sensitivity, and Hausdorff distance with reference to ground truth manualsegmentations. Dice score for nnU-Net internal test sets was (mean +/- SD(median)) 0.9+/-0.07 (0.94) for WT, 0.77+/-0.29 for ET, 0.66+/-0.32 for NET,0.71+/-0.33 for CC, and 0.71+/-0.40 for ED, respectively. For DeepMedic theDice scores were 0.82+/-0.16 for WT, 0.66+/-0.32 for ET, 0.48+/-0.27, for NET,0.48+/-0.36 for CC, and 0.19+/-0.33 for ED, respectively. Dice scores weresignificantly higher for nnU-Net (p&lt;=0.01). External validation of the trainednnU-Net model on the multi-institutional BraTS-PEDs 2023 dataset revealed highgeneralization capability in segmentation of whole tumor and tumor core withDice scores of 0.87+/-0.13 (0.91) and 0.83+/-0.18 (0.89), respectively.Pediatric-specific data trained nnU-Net model is superior to DeepMedic forwhole tumor and subregion segmentation of pediatric brain tumors.</description><author>Arastoo Vossough, Nastaran Khalili, Ariana M. Familiar, Deep Gandhi, Karthik Viswanathan, Wenxin Tu, Debanjan Haldar, Sina Bagheri, Hannah Anderson, Shuvanjan Haldar, Phillip B. Storm, Adam Resnick, Jeffrey B. Ware, Ali Nabavizadeh, Anahita Fathi Kazerooni</author><pubDate>Tue, 16 Jan 2024 14:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08404v1</guid></item><item><title>POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation</title><link>http://arxiv.org/abs/2401.05596v2</link><description>Low-resource languages (LRLs) face challenges in supervised neural machinetranslation due to limited parallel data, prompting research into unsupervisedmethods. Unsupervised neural machine translation (UNMT) methods, includingback-translation, transfer learning, and pivot-based translation, offerpractical solutions for LRL translation, but they are hindered by issues likesynthetic data noise, language bias, and error propagation, which canpotentially be mitigated by Large Language Models (LLMs). LLMs have advancedNMT with in-context learning (ICL) and supervised fine-tuning methods, butinsufficient training data results in poor performance in LRLs. We argue thatLLMs can mitigate the linguistic noise with auxiliary languages to improvetranslations in LRLs. In this paper, we propose Probability-driven Meta-graphPrompter (POMP), a novel approach employing a dynamic, sampling-based graph ofmultiple auxiliary languages to enhance LLMs' translation capabilities forLRLs. POMP involves constructing a directed acyclic meta-graph for each sourcelanguage, from which we dynamically sample multiple paths to prompt LLMs tomitigate the linguistic noise and improve translations during training. We usethe BLEURT metric to evaluate the translations and back-propagate rewards,estimated by scores, to update the probabilities of auxiliary languages in thepaths. Our experiments show significant improvements in the translation qualityof three LRLs, demonstrating the effectiveness of our approach.</description><author>Shilong Pan, Zhiliang Tian, Liang Ding, Zhen Huang, Zhihua Wen, Dongsheng Li</author><pubDate>Tue, 16 Jan 2024 14:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05596v2</guid></item><item><title>TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object Understanding</title><link>http://arxiv.org/abs/2401.08399v1</link><description>Humans commonly work with multiple objects in daily life and can intuitivelytransfer manipulation skills to novel objects by understanding objectfunctional regularities. However, existing technical approaches for analyzingand synthesizing hand-object manipulation are mostly limited to handling asingle hand and object due to the lack of data support. To address this, weconstruct TACO, an extensive bimanual hand-object-interaction dataset spanninga large variety of tool-action-object compositions for daily human activities.TACO contains 2.5K motion sequences paired with third-person and egocentricviews, precise hand-object 3D meshes, and action labels. To rapidly expand thedata scale, we present a fully-automatic data acquisition pipeline combiningmulti-view sensing with an optical motion capture system. With the vastresearch fields provided by TACO, we benchmark three generalizablehand-object-interaction tasks: compositional action recognition, generalizablehand-object motion forecasting, and cooperative grasp synthesis. Extensiveexperiments reveal new insights, challenges, and opportunities for advancingthe studies of generalizable hand-object motion analysis and synthesis. Ourdata and code are available at https://taco2024.github.io.</description><author>Yun Liu, Haolin Yang, Xu Si, Ling Liu, Zipeng Li, Yuxiang Zhang, Yebin Liu, Li Yi</author><pubDate>Tue, 16 Jan 2024 14:41:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08399v1</guid></item><item><title>High-Quality Mesh Blendshape Generation from Face Videos via Neural Inverse Rendering</title><link>http://arxiv.org/abs/2401.08398v1</link><description>Readily editable mesh blendshapes have been widely used in animationpipelines, while recent advancements in neural geometry and appearancerepresentations have enabled high-quality inverse rendering. Building uponthese observations, we introduce a novel technique that reconstructs mesh-basedblendshape rigs from single or sparse multi-view videos, leveragingstate-of-the-art neural inverse rendering. We begin by constructing adeformation representation that parameterizes vertex displacements intodifferential coordinates with tetrahedral connections, allowing forhigh-quality vertex deformation on high-resolution meshes. By constructing aset of semantic regulations in this representation, we achieve jointoptimization of blendshapes and expression coefficients. Furthermore, to enablea user-friendly multi-view setup with unsynchronized cameras, we propose aneural regressor to model time-varying motion parameters. This approachimplicitly considers the time difference across multiple cameras, enhancing theaccuracy of motion modeling. Experiments demonstrate that, with the flexibleinput of single or sparse multi-view videos, we reconstruct personalizedhigh-fidelity blendshapes. These blendshapes are both geometrically andsemantically accurate, and they are compatible with industrial animationpipelines. Code and data will be released.</description><author>Xin Ming, Jiawei Li, Jingwang Ling, Libo Zhang, Feng Xu</author><pubDate>Tue, 16 Jan 2024 14:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08398v1</guid></item><item><title>Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine</title><link>http://arxiv.org/abs/2401.08396v1</link><description>Recent studies indicate that Generative Pre-trained Transformer 4 with Vision(GPT-4V) outperforms human physicians in medical challenge tasks. However,these evaluations primarily focused on the accuracy of multi-choice questionsalone. Our study extends the current scope by conducting a comprehensiveanalysis of GPT-4V's rationales of image comprehension, recall of medicalknowledge, and step-by-step multimodal reasoning when solving New EnglandJournal of Medicine (NEJM) Image Challenges - an imaging quiz designed to testthe knowledge and diagnostic capabilities of medical professionals. Evaluationresults confirmed that GPT-4V outperforms human physicians regardingmulti-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well incases where physicians incorrectly answer, with over 80% accuracy. However, wediscovered that GPT-4V frequently presents flawed rationales in cases where itmakes the correct final choices (27.3%), most prominent in image comprehension(21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, ourfindings emphasize the necessity for further in-depth evaluations of itsrationales before integrating such models into clinical workflows.</description><author>Qiao Jin, Fangyuan Chen, Yiliang Zhou, Ziyang Xu, Justin M. Cheung, Robert Chen, Ronald M. Summers, Justin F. Rousseau, Peiyun Ni, Marc J Landsman, Sally L. Baxter, Subhi J. Al'Aref, Yijia Li, Michael F. Chiang, Yifan Peng, Zhiyong Lu</author><pubDate>Tue, 16 Jan 2024 14:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08396v1</guid></item><item><title>A Micro Architectural Events Aware Real-Time Embedded System Fault Injector</title><link>http://arxiv.org/abs/2401.08397v1</link><description>In contemporary times, the increasing complexity of the system posessignificant challenges to the reliability, trustworthiness, and security of theSACRES. Key issues include the susceptibility to phenomena such asinstantaneous voltage spikes, electromagnetic interference, neutron strikes,and out-of-range temperatures. These factors can induce switch state changes intransistors, resulting in bit-flipping, soft errors, and transient corruptionof stored data in memory. The occurrence of soft errors, in turn, may lead tosystem faults that can propel the system into a hazardous state. Particularlyin critical sectors like automotive, avionics, or aerospace, such malfunctionscan have real-world implications, potentially causing harm to individuals. This paper introduces a novel fault injector designed to facilitate themonitoring, aggregation, and examination of micro-architectural events. This isachieved by harnessing the microprocessor's PMU and the debugging interface,specifically focusing on ensuring the repeatability of fault injections. Thefault injection methodology targets bit-flipping within the memory system,affecting CPU registers and RAM. The outcomes of these fault injections enablea thorough analysis of the impact of soft errors and establish a robustcorrelation between the identified faults and the essential timingpredictability demanded by SACRES.</description><author>Enrico Magliano, Alessio Carpegna, Alessadro Savino, Stefano Di Carlo</author><pubDate>Tue, 16 Jan 2024 14:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08397v1</guid></item><item><title>DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models</title><link>http://arxiv.org/abs/2401.08392v1</link><description>The field of AI agents is advancing at an unprecedented rate due to thecapabilities of large language models (LLMs). However, LLM-driven visual agentsmainly focus on solving tasks for the image modality, which limits theirability to understand the dynamic nature of the real world, making it still farfrom real-life applications, e.g., guiding students in laboratory experimentsand identifying their mistakes. Considering the video modality better reflectsthe ever-changing and perceptually intensive nature of real-world scenarios, wedevise DoraemonGPT, a comprehensive and conceptually elegant system driven byLLMs to handle dynamic video tasks. Given a video with a question/task,DoraemonGPT begins by converting the input video with massive content into asymbolic memory that stores \textit{task-related} attributes. This structuredrepresentation allows for spatial-temporal querying and reasoning by sub-tasktools, resulting in concise and relevant intermediate results. Recognizing thatLLMs have limited internal knowledge when it comes to specialized domains(e.g., analyzing the scientific principles underlying experiments), weincorporate plug-and-play tools to assess external knowledge and address tasksacross different domains. Moreover, we introduce a novel LLM-driven plannerbased on Monte Carlo Tree Search to efficiently explore the large planningspace for scheduling various tools. The planner iteratively finds feasiblesolutions by backpropagating the result's reward, and multiple solutions can besummarized into an improved final answer. We extensively evaluate DoraemonGPTin dynamic scenes and provide in-the-wild showcases demonstrating its abilityto handle more complex questions than previous studies.</description><author>Zongxin Yang, Guikun Chen, Xiaodi Li, Wenguan Wang, Yi Yang</author><pubDate>Tue, 16 Jan 2024 14:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08392v1</guid></item><item><title>Deep Learning-based Group Causal Inference in Multivariate Time-series</title><link>http://arxiv.org/abs/2401.08386v1</link><description>Causal inference in a nonlinear system of multivariate timeseries isinstrumental in disentangling the intricate web of relationships amongvariables, enabling us to make more accurate predictions and gain deeperinsights into real-world complex systems. Causality methods typically identifythe causal structure of a multivariate system by considering the cause-effectrelationship of each pair of variables while ignoring the collective effect ofa group of variables or interactions involving more than two-time seriesvariables. In this work, we test model invariance by group-level interventionson the trained deep networks to infer causal direction in groups of variables,such as climate and ecosystem, brain networks, etc. Extensive testing withsynthetic and real-world time series data shows a significant improvement ofour method over other applied group causality methods and provides us insightsinto real-world time series. The code for our method can be foundat:https://github.com/wasimahmadpk/gCause.</description><author>Wasim Ahmad, Maha Shadaydeh, Joachim Denzler</author><pubDate>Tue, 16 Jan 2024 14:19:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08386v1</guid></item><item><title>Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference</title><link>http://arxiv.org/abs/2401.08383v1</link><description>In large language models like the Generative Pre-trained Transformer, theMixture of Experts paradigm has emerged as a powerful technique for enhancingmodel expressiveness and accuracy. However, deploying GPT MoE models forparallel inference on distributed systems presents significant challenges,primarily due to the extensive Alltoall communication required for expertrouting and aggregation. This communication bottleneck exacerbates the alreadycomplex computational landscape, hindering the efficient utilization ofhigh-performance computing resources. In this paper, we propose a lightweightoptimization technique called ExFlow, to largely accelerate the inference ofthese MoE models. We take a new perspective on alleviating the communicationoverhead by exploiting the inter-layer expert affinity. Unlike previousmethods, our solution can be directly applied to pre-trained MoE models withoutany fine-tuning or accuracy degradation. By proposing a context-coherent expertparallelism on distributed systems, our design only uses one Alltoallcommunication to deliver the same functionality while previous methods allrequire two Alltoalls. By carefully examining the conditional probability intokens' routing across multiple layers, we proved that pre-trained GPT MoEmodels implicitly exhibit a strong inter-layer expert affinity. We then designan efficient integer programming model to capture such features and show thatby properly placing the experts on corresponding GPUs, we can reduce up to 67%cross-GPU routing latency. Our solution beats the cutting-edge MoEimplementations with experts from 8 to 64, with up to 2.2x improvement ininference throughput. We further provide a detailed study of how the modelimplicitly acquires this expert affinity at the very early training stage andhow this affinity evolves and stabilizes during training.</description><author>Jinghan Yao, Quentin Anthony, Aamir Shafi, Hari Subramoni, Dhabaleswar K., Panda</author><pubDate>Tue, 16 Jan 2024 14:16:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08383v1</guid></item><item><title>Persistent Test-time Adaptation in Episodic Testing Scenarios</title><link>http://arxiv.org/abs/2311.18193v2</link><description>Current test-time adaptation (TTA) approaches aim to adapt to environmentsthat change continuously. Yet, when the environments not only change but alsorecur in a correlated manner over time, such as in the case of day-nightsurveillance cameras, it is unclear whether the adaptability of these methodsis sustained after a long run. This study aims to examine the erroraccumulation of TTA models when they are repeatedly exposed to previous testingenvironments, proposing a novel testing setting called episodic TTA. To studythis phenomenon, we design a simulation of TTA process on a simple yetrepresentative $\epsilon$-perturbed Gaussian Mixture Model Classifier andderive the theoretical findings revealing the dataset- and algorithm-dependentfactors that contribute to the gradual degeneration of TTA methods throughtime. Our investigation has led us to propose a method, named persistent TTA(PeTTA). PeTTA senses the model divergence towards a collapsing and adjusts theadaptation strategy of TTA, striking a balance between two primary objectives:adaptation and preventing model collapse. The stability of PeTTA in the face ofepisodic TTA scenarios has been demonstrated through a set of comprehensiveexperiments on various benchmarks.</description><author>Trung-Hieu Hoang, Duc Minh Vo, Minh N. Do</author><pubDate>Tue, 16 Jan 2024 14:16:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18193v2</guid></item><item><title>Robotic Imitation of Human Actions</title><link>http://arxiv.org/abs/2401.08381v1</link><description>Imitation can allow us to quickly gain an understanding of a new task.Through a demonstration, we can gain direct knowledge about which actions needto be performed and which goals they have. In this paper, we introduce a newapproach to imitation learning that tackles the challenges of a robot imitatinga human, such as the change in perspective and body schema. Our approach canuse a single human demonstration to abstract information about the demonstratedtask, and use that information to generalise and replicate it. We facilitatethis ability by a new integration of two state-of-the-art methods: a diffusionaction segmentation model to abstract temporal information from thedemonstration and an open vocabulary object detector for spatial information.Furthermore, we refine the abstracted information and use symbolic reasoning tocreate an action plan utilising inverse kinematics, to allow the robot toimitate the demonstrated action.</description><author>Josua Spisak, Matthias Kerzel, Stefan Wermter</author><pubDate>Tue, 16 Jan 2024 14:11:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08381v1</guid></item><item><title>KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation</title><link>http://arxiv.org/abs/2401.08376v1</link><description>Commit messages are natural language descriptions of code changes, which areimportant for software evolution such as code understanding and maintenance.However, previous methods are trained on the entire dataset without consideringthe fact that a portion of commit messages adhere to good practice (i.e.,good-practice commits), while the rest do not. On the basis of our empiricalstudy, we discover that training on good-practice commits significantlycontributes to the commit message generation. Motivated by this finding, wepropose a novel knowledge-aware denoising learning method called KADEL.Considering that good-practice commits constitute only a small proportion ofthe dataset, we align the remaining training samples with these good-practicecommits. To achieve this, we propose a model that learns the commit knowledgeby training on good-practice commits. This knowledge model enablessupplementing more information for training samples that do not conform to goodpractice. However, since the supplementary information may contain noise orprediction errors, we propose a dynamic denoising training method. This methodcomposes a distribution-aware confidence function and a dynamic distributionlist, which enhances the effectiveness of the training process. Experimentalresults on the whole MCMD dataset demonstrate that our method overall achievesstate-of-the-art performance compared with previous methods. Our source codeand data are available at https://github.com/DeepSoftwareAnalytics/KADEL</description><author>Wei Tao, Yucheng Zhou, Yanlin Wang, Hongyu Zhang, Haofen Wang, Wenqiang Zhang</author><pubDate>Tue, 16 Jan 2024 14:07:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08376v1</guid></item><item><title>Sparse PCA with False Discovery Rate Controlled Variable Selection</title><link>http://arxiv.org/abs/2401.08375v1</link><description>Sparse principal component analysis (PCA) aims at mapping large dimensionaldata to a linear subspace of lower dimension. By imposing loading vectors to besparse, it performs the double duty of dimension reduction and variableselection. Sparse PCA algorithms are usually expressed as a trade-off betweenexplained variance and sparsity of the loading vectors (i.e., number ofselected variables). As a high explained variance is not necessarily synonymouswith relevant information, these methods are prone to select irrelevantvariables. To overcome this issue, we propose an alternative formulation ofsparse PCA driven by the false discovery rate (FDR). We then leverage theTerminating-Random Experiments (T-Rex) selector to automatically determine anFDR-controlled support of the loading vectors. A major advantage of theresulting T-Rex PCA is that no sparsity parameter tuning is required. Numericalexperiments and a stock market data example demonstrate a significantperformance improvement.</description><author>Jasin Machkour, Arnaud Breloy, Michael Muma, Daniel P. Palomar, Frédéric Pascal</author><pubDate>Tue, 16 Jan 2024 14:07:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08375v1</guid></item><item><title>Cross-lingual neural fuzzy matching for exploiting target-language monolingual corpora in computer-aided translation</title><link>http://arxiv.org/abs/2401.08374v1</link><description>Computer-aided translation (CAT) tools based on translation memories (MT)play a prominent role in the translation workflow of professional translators.However, the reduced availability of in-domain TMs, as compared to in-domainmonolingual corpora, limits its adoption for a number of translation tasks. Inthis paper, we introduce a novel neural approach aimed at overcoming thislimitation by exploiting not only TMs, but also in-domain target-language (TL)monolingual corpora, and still enabling a similar functionality to that offeredby conventional TM-based CAT tools. Our approach relies on cross-lingualsentence embeddings to retrieve translation proposals from TL monolingualcorpora, and on a neural model to estimate their post-editing effort. The paperpresents an automatic evaluation of these techniques on four language pairsthat shows that our approach can successfully exploit monolingual texts in aTM-based CAT environment, increasing the amount of useful translationproposals, and that our neural model for estimating the post-editing effortenables the combination of translation proposals obtained from monolingualcorpora and from TMs in the usual way. A human evaluation performed on a singlelanguage pair confirms the results of the automatic evaluation and seems toindicate that the translation proposals retrieved with our approach are moreuseful than what the automatic evaluation shows.</description><author>Miquel Esplà-Gomis, Víctor M. Sánchez-Cartagena, Juan Antonio Pérez-Ortiz, Felipe Sánchez-Martínez</author><pubDate>Tue, 16 Jan 2024 14:00:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08374v1</guid></item><item><title>Amplitude-Independent Machine Learning for PPG through Visibility Graphs and Transfer Learning</title><link>http://arxiv.org/abs/2305.14062v4</link><description>Photoplethysmography (PPG) refers to the measurement of variations in bloodvolume using light and is a feature of most wearable devices. The PPG signalsprovide insight into the body's circulatory system and can be employed toextract various bio-features, such as heart rate and vascular ageing. Althoughseveral algorithms have been proposed for this purpose, many exhibitlimitations, including heavy reliance on human calibration, high signal qualityrequirements, and a lack of generalisation. In this paper, we introduce a PPGsignal processing framework that integrates graph theory and computer visionalgorithms, to provide an analysis framework which is amplitude-independent andinvariant to affine transformations. It also requires minimal preprocessing,fuses information through RGB channels and exhibits robust generalisationacross tasks and datasets. The proposed VGTL-net achieves state-of-the-artperformance in the prediction of vascular ageing and demonstrates robustestimation of continuous blood pressure waveforms.</description><author>Yuyang Miao, Harry J. Davies, Danilo P. Mandic</author><pubDate>Tue, 16 Jan 2024 13:54:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14062v4</guid></item><item><title>Morphology and Syntax of the Tamil Language</title><link>http://arxiv.org/abs/2401.08367v1</link><description>This paper provides an overview of the morphology and syntax of the Tamillanguage, focusing on its contemporary usage. The paper also highlights thecomplexity and richness of Tamil in terms of its morphological and syntacticfeatures, which will be useful for linguists analysing the language andconducting comparative studies. In addition, the paper will be useful for thosedeveloping computational resources for the Tamil language. It is proven as arule-based morphological analyser cum generator and a computational grammar forTamil have already been developed based on this paper. To enhance accessibilityfor a broader audience, the analysis is conducted without relying on anyspecific grammatical formalism.</description><author>Kengatharaiyer Sarveswaran</author><pubDate>Tue, 16 Jan 2024 13:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08367v1</guid></item><item><title>Weighted Spectral Filters for Kernel Interpolation on Spheres: Estimates of Prediction Accuracy for Noisy Data</title><link>http://arxiv.org/abs/2401.08364v1</link><description>Spherical radial-basis-based kernel interpolation abounds in image sciencesincluding geophysical image reconstruction, climate trends description andimage rendering due to its excellent spatial localization property and perfectapproximation performance. However, in dealing with noisy data, kernelinterpolation frequently behaves not so well due to the large condition numberof the kernel matrix and instability of the interpolation process. In thispaper, we introduce a weighted spectral filter approach to reduce the conditionnumber of the kernel matrix and then stabilize kernel interpolation. The mainbuilding blocks of the proposed method are the well developed sphericalpositive quadrature rules and high-pass spectral filters. Using a recentlydeveloped integral operator approach for spherical data analysis, wetheoretically demonstrate that the proposed weighted spectral filter approachsucceeds in breaking through the bottleneck of kernel interpolation, especiallyin fitting noisy data. We provide optimal approximation rates of the new methodto show that our approach does not compromise the predicting accuracy.Furthermore, we conduct both toy simulations and two real-world dataexperiments with synthetically added noise in geophysical image reconstructionand climate image processing to verify our theoretical assertions and show thefeasibility of the weighted spectral filter approach.</description><author>Xiaotong Liu, Jinxin Wang, Di Wang, Shao-Bo Lin</author><pubDate>Tue, 16 Jan 2024 13:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08364v1</guid></item><item><title>Hallucination Detection and Hallucination Mitigation: An Investigation</title><link>http://arxiv.org/abs/2401.08358v1</link><description>Large language models (LLMs), including ChatGPT, Bard, and Llama, haveachieved remarkable successes over the last two years in a range of differentapplications. In spite of these successes, there exist concerns that limit thewide application of LLMs. A key problem is the problem of hallucination.Hallucination refers to the fact that in addition to correct responses, LLMscan also generate seemingly correct but factually incorrect responses. Thisreport aims to present a comprehensive review of the current literature on bothhallucination detection and hallucination mitigation. We hope that this reportcan serve as a good reference for both engineers and researchers who areinterested in LLMs and applying them to real world tasks.</description><author>Junliang Luo, Tianyu Li, Di Wu, Michael Jenkin, Steve Liu, Gregory Dudek</author><pubDate>Tue, 16 Jan 2024 13:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08358v1</guid></item><item><title>SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection</title><link>http://arxiv.org/abs/2401.08357v1</link><description>Existing multi-focus image fusion (MFIF) methods often fail to preserve theuncertain transition region and detect small focus areas within large defocusedregions accurately. To address this issue, this study proposes a newsmall-area-aware MFIF algorithm for enhancing object detection capability.First, we enhance the pixel attributes within the small focus and boundaryregions, which are subsequently combined with visual saliency detection toobtain the pre-fusion results used to discriminate the distribution of focusedpixels. To accurately ensure pixel focus, we consider the source image as acombination of focused, defocused, and uncertain regions and propose athree-region segmentation strategy. Finally, we design an effective pixelselection rule to generate segmentation decision maps and obtain the finalfusion results. Experiments demonstrated that the proposed method canaccurately detect small and smooth focus areas while improving object detectionperformance, outperforming existing methods in both subjective and objectiveevaluations. The source code is available at https://github.com/ixilai/SAMF.</description><author>Xilai Li, Xiaosong Li, Haishu Tan, Jinyang Li</author><pubDate>Tue, 16 Jan 2024 13:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08357v1</guid></item><item><title>Linguistic and Structural Basis of Engineering Design Knowledge</title><link>http://arxiv.org/abs/2312.06355v2</link><description>Artefact descriptions are the primary carriers of engineering designknowledge that is both an outcome and a driver of the design process. While anartefact could be described in different connotations, the design processrequires a description to embody engineering design knowledge, which isexpressed in the text through intricate placement of entities andrelationships. As large-language models learn from all kinds of text merely asa sequence of characters/tokens, these are yet to generate text that embodiesexplicit engineering design facts. Existing ontological design theories areless likely to guide the large-language models whose applications are currentlylimited to ideation and learning purposes. In this article, we explicateengineering design knowledge as knowledge graphs from a large sample of 33,881patent documents. We examine the constituents of these knowledge graphs tounderstand the linguistic and structural basis of engineering design knowledge.In terms of linguistic basis, we observe that entities and relationships couldbe generalised to 64 and 24 linguistic syntaxes. While relationships mainlycapture attributes ('of'), structure ('in', 'with'), purpose ('to', 'for'),hierarchy ('include'), exemplification ('such as'), and behaviour ('to','from'), the hierarchical relationships could specifically be identified using75 unique syntaxes. To understand the structural basis, we draw inspirationfrom various studies on biological/ecological networks and discover motifs frompatent knowledge graphs. We identify four 3-node and four 4-node patterns thatcould further be converged and simplified into sequence [-&gt;...-&gt;], aggregation[-&gt;...&lt;-], and hierarchy [&lt;-...-&gt;]. Expected to guide large-language modelbased design tools, we propose few regulatory precepts for concretisingabstract entities and relationships within subgraphs, while explicatinghierarchical structures.</description><author>L. Siddharth, Jianxi Luo</author><pubDate>Tue, 16 Jan 2024 13:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06355v2</guid></item><item><title>Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian Approach</title><link>http://arxiv.org/abs/2401.08351v1</link><description>Federated learning aims to infer a shared model from private anddecentralized data stored locally by multiple clients. Personalized federatedlearning (PFL) goes one step further by adapting the global model to eachclient, enhancing the model's fit for different clients. A significant level ofpersonalization is required for highly heterogeneous clients, but can bechallenging to achieve especially when they have small datasets. To addressthis problem, we propose a PFL algorithm named PAC-PFL for learningprobabilistic models within a PAC-Bayesian framework that utilizes differentialprivacy to handle data-dependent priors. Our algorithm collaboratively learns ashared hyper-posterior and regards each client's posterior inference as thepersonalization step. By establishing and minimizing a generalization bound onthe average true risk of clients, PAC-PFL effectively combats over-fitting.PACPFL achieves accurate and well-calibrated predictions, supported byexperiments on a dataset of photovoltaic panel power generation, FEMNISTdataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohenet al., 2017).</description><author>Mahrokh Ghoddousi Boroujeni, Andreas Krause, Giancarlo Ferrari Trecate</author><pubDate>Tue, 16 Jan 2024 13:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08351v1</guid></item><item><title>Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models</title><link>http://arxiv.org/abs/2401.08350v1</link><description>The evolution of Neural Machine Translation (NMT) has been significantlyinfluenced by six core challenges (Koehn and Knowles, 2017), which have actedas benchmarks for progress in this field. This study revisits these challenges,offering insights into their ongoing relevance in the context of advanced LargeLanguage Models (LLMs): domain mismatch, amount of parallel data, rare wordprediction, translation of long sentences, attention model as word alignment,and sub-optimal beam search. Our empirical findings indicate that LLMseffectively lessen the reliance on parallel data for major languages in thepretraining phase. Additionally, the LLM-based translation system significantlyenhances the translation of long sentences that contain approximately 80 wordsand shows the capability to translate documents of up to 512 words. However,despite these significant improvements, the challenges of domain mismatch andprediction of rare words persist. While the challenges of word alignment andbeam search, specifically associated with NMT, may not apply to LLMs, weidentify three new challenges for LLMs in translation tasks: inferenceefficiency, translation of low-resource languages in the pretraining phase, andhuman-aligned evaluation. The datasets and models are released athttps://github.com/pangjh3/LLM4MT.</description><author>Jianhui Pang, Fanghua Ye, Longyue Wang, Dian Yu, Derek F. Wong, Shuming Shi, Zhaopeng Tu</author><pubDate>Tue, 16 Jan 2024 13:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08350v1</guid></item><item><title>We don't need no labels: Estimating post-deployment model performance under covariate shift without ground truth</title><link>http://arxiv.org/abs/2401.08348v1</link><description>The performance of machine learning models often degrades after deploymentdue to data distribution shifts. In many use cases, it is impossible tocalculate the post-deployment performance because labels are unavailable orsignificantly delayed. Proxy methods for evaluating model performancestability, like drift detection techniques, do not properly quantify datadistribution shift impact. As a solution, we propose a robust and accurateperformance estimation method for evaluating ML classification models onunlabeled data that accurately quantifies the impact of covariate shift onmodel performance. We call it multi-calibrated confidence-based performanceestimation (M-CBPE). It is model and data-type agnostic and works for anyperformance metric. It does not require access to the monitored model - it usesthe model predictions and probability estimates. M-CBPE does not need userinput on the nature of the covariate shift as it fully learns from the data. Weevaluate it with over 600 dataset-model pairs from US census data and compareit with multiple benchmarks using several evaluation metrics. Results show thatM-CBPE is the best method to estimate the performance of classification modelsin any evaluation context.</description><author>Jakub Białek, Wojtek Kuberski, Nikolaos Perrakis</author><pubDate>Tue, 16 Jan 2024 13:29:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08348v1</guid></item><item><title>Multi-view Distillation based on Multi-modal Fusion for Few-shot Action Recognition(CLIP-$\mathrm{M^2}$DF)</title><link>http://arxiv.org/abs/2401.08345v1</link><description>In recent years, few-shot action recognition has attracted increasingattention. It generally adopts the paradigm of meta-learning. In this field,overcoming the overlapping distribution of classes and outliers is still achallenging problem based on limited samples. We believe the combination ofMulti-modal and Multi-view can improve this issue depending on informationcomplementarity. Therefore, we propose a method of Multi-view Distillationbased on Multi-modal Fusion. Firstly, a Probability Prompt Selector for thequery is constructed to generate probability prompt embedding based on thecomparison score between the prompt embeddings of the support and the visualembedding of the query. Secondly, we establish a Multi-view. In each view, wefuse the prompt embedding as consistent information with visual and the globalor local temporal context to overcome the overlapping distribution of classesand outliers. Thirdly, we perform the distance fusion for the Multi-view andthe mutual distillation of matching ability from one to another, enabling themodel to be more robust to the distribution bias. Our code is available at theURL: \url{https://github.com/cofly2014/MDMF}.</description><author>Fei Guo, YiKang Wang, Han Qi, WenPing Jin, Li Zhu</author><pubDate>Tue, 16 Jan 2024 13:23:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08345v1</guid></item><item><title>Investigating Collaborative Data Practices: a Case Study on Artificial Intelligence for Healthcare Research</title><link>http://arxiv.org/abs/2311.18424v2</link><description>Developing artificial intelligence (AI) tools for healthcare is acollaborative effort, bringing data scientists, clinicians, patients and otherdisciplines together. In this paper, we explore the collaborative datapractices of research consortia tasked with applying AI tools to understand andmanage multiple long-term conditions in the UK. Through an inductive thematicanalysis of 13 semi-structured interviews with participants of these consortia,we aimed to understand how collaboration happens based on the tools used,communication processes and settings, as well as the conditions and obstaclesfor collaborative work. Our findings reveal the adaptation of tools that areused for sharing knowledge and the tailoring of information based on theaudience, particularly those from a clinical or patient perspective.Limitations on the ability to do this were also found to be imposed by the useof electronic healthcare records and access to datasets. We identified meetingsas the key setting for facilitating exchanges between disciplines and allowingfor the blending and creation of knowledge. Finally, we bring to light theconditions needed to facilitate collaboration and discuss how some of thechallenges may be navigated in future work.</description><author>Rafael Henkin, Elizabeth Remfry, Duncan J. Reynolds, Megan Clinch, Michael R. Barnes</author><pubDate>Tue, 16 Jan 2024 13:12:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18424v2</guid></item><item><title>Guardians of Trust: Navigating Data Security in AIOps through Vendor Partnerships</title><link>http://arxiv.org/abs/2312.06008v2</link><description>Artificial Intelligence for IT Operations (AIOps) is a rapidly growing fieldthat applies artificial intelligence and machine learning to automate andoptimize IT operations. AIOps vendors provide services that ingest end-to-endlogs, traces, and metrics to offer a full stack observability of IT systems.However, these data sources may contain sensitive information such as internalIP addresses, hostnames, HTTP headers, SQLs, method/argument return values,URLs, personal identifiable information (PII), or confidential business data.Therefore, data security is a crucial concern when working with AIOps vendors.In this article, we will discuss the security features offered by differentvendors and how we can adopt best practices to ensure data protection andprivacy.</description><author>Subhadip Kumar</author><pubDate>Tue, 16 Jan 2024 13:09:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06008v2</guid></item><item><title>Generative Denoise Distillation: Simple Stochastic Noises Induce Efficient Knowledge Transfer for Dense Prediction</title><link>http://arxiv.org/abs/2401.08332v1</link><description>Knowledge distillation is the process of transferring knowledge from a morepowerful large model (teacher) to a simpler counterpart (student). Numerouscurrent approaches involve the student imitating the knowledge of the teacherdirectly. However, redundancy still exists in the learned representationsthrough these prevalent methods, which tend to learn each spatial location'sfeatures indiscriminately. To derive a more compact representation (conceptfeature) from the teacher, inspired by human cognition, we suggest aninnovative method, termed Generative Denoise Distillation (GDD), wherestochastic noises are added to the concept feature of the student to embed theminto the generated instance feature from a shallow network. Then, the generatedinstance feature is aligned with the knowledge of the instance from theteacher. We extensively experiment with object detection, instancesegmentation, and semantic segmentation to demonstrate the versatility andeffectiveness of our method. Notably, GDD achieves new state-of-the-artperformance in the tasks mentioned above. We have achieved substantialimprovements in semantic segmentation by enhancing PspNet and DeepLabV3, bothof which are based on ResNet-18, resulting in mIoU scores of 74.67 and 77.69,respectively, surpassing their previous scores of 69.85 and 73.20 on theCityscapes dataset of 20 categories. The source code of GDD is available athttps://github.com/ZhgLiu/GDD.</description><author>Zhaoge Liu, Xiaohao Xu, Yunkang Cao, Weiming Shen</author><pubDate>Tue, 16 Jan 2024 12:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08332v1</guid></item><item><title>Boosting Gradient Ascent for Continuous DR-submodular Maximization</title><link>http://arxiv.org/abs/2401.08330v1</link><description>Projected Gradient Ascent (PGA) is the most commonly used optimization schemein machine learning and operations research areas. Nevertheless, numerousstudies and examples have shown that the PGA methods may fail to achieve thetight approximation ratio for continuous DR-submodular maximization problems.To address this challenge, we present a boosting technique in this paper, whichcan efficiently improve the approximation guarantee of the standard PGA to\emph{optimal} with only small modifications on the objective function. Thefundamental idea of our boosting technique is to exploit non-oblivious searchto derive a novel auxiliary function $F$, whose stationary points are excellentapproximations to the global maximum of the original DR-submodular objective$f$. Specifically, when $f$ is monotone and $\gamma$-weakly DR-submodular, wepropose an auxiliary function $F$ whose stationary points can provide a better$(1-e^{-\gamma})$-approximation than the$(\gamma^2/(1+\gamma^2))$-approximation guaranteed by the stationary points of$f$ itself. Similarly, for the non-monotone case, we devise another auxiliaryfunction $F$ whose stationary points can achieve an optimal$\frac{1-\min_{\boldsymbol{x}\in\mathcal{C}}\|\boldsymbol{x}\|_{\infty}}{4}$-approximationguarantee where $\mathcal{C}$ is a convex constraint set. In contrast, thestationary points of the original non-monotone DR-submodular function can bearbitrarily bad~\citep{chen2023continuous}. Furthermore, we demonstrate thescalability of our boosting technique on four problems. In all of these fourproblems, our resulting variants of boosting PGA algorithm beat the previousstandard PGA in several aspects such as approximation ratio and efficiency.Finally, we corroborate our theoretical findings with numerical experiments,which demonstrate the effectiveness of our boosting PGA methods.</description><author>Qixin Zhang, Zongqi Wan, Zengde Deng, Zaiyi Chen, Xiaoming Sun, Jialin Zhang, Yu Yang</author><pubDate>Tue, 16 Jan 2024 12:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08330v1</guid></item><item><title>Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation</title><link>http://arxiv.org/abs/2401.08328v1</link><description>In an era where test-time adaptation methods increasingly rely on the nuancedmanipulation of batch normalization (BN) parameters, one critical assumptionoften goes overlooked: that of independently and identically distributed(i.i.d.) test batches with respect to unknown labels. This assumptionculminates in biased estimates of BN statistics and jeopardizes systemstability under non-i.i.d. conditions. This paper pioneers a departure from thei.i.d. paradigm by introducing a groundbreaking strategy termed "Un-MixingTest-Time Normalization Statistics" (UnMix-TNS). UnMix-TNS re-calibrates theinstance-wise statistics used to normalize each instance in a batch by mixingit with multiple unmixed statistics components, thus inherently simulating thei.i.d. environment. The key lies in our innovative online unmixing procedure,which persistently refines these statistics components by drawing upon theclosest instances from an incoming test batch. Remarkably generic in itsdesign, UnMix-TNS seamlessly integrates with an array of state-of-the-arttest-time adaptation methods and pre-trained architectures equipped with BNlayers. Empirical evaluations corroborate the robustness of UnMix-TNS undervaried scenarios ranging from single to continual and mixed domain shifts.UnMix-TNS stands out when handling test data streams with temporal correlation,including those with corrupted real-world non-i.i.d. streams, sustaining itsefficacy even with minimal batch sizes and individual samples. Our results seta new standard for test-time adaptation, demonstrating significant improvementsin both stability and performance across multiple benchmarks.</description><author>Devavrat Tomar, Guillaume Vray, Jean-Philippe Thiran, Behzad Bozorgtabar</author><pubDate>Tue, 16 Jan 2024 12:48:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08328v1</guid></item><item><title>Learn What You Need in Personalized Federated Learning</title><link>http://arxiv.org/abs/2401.08327v1</link><description>Personalized federated learning aims to address data heterogeneity acrosslocal clients in federated learning. However, current methods blindlyincorporate either full model parameters or predefined partial parameters inpersonalized federated learning. They fail to customize the collaborationmanner according to each local client's data characteristics, causingunpleasant aggregation results. To address this essential issue, we propose$\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federatedlearning framework, enabling each client to adaptively select which part of itslocal model parameters should participate in collaborative training. The keynovelty of the proposed $\textit{Learn2pFed}$ is to optimize each local modelparameter's degree of participant in collaboration as learnable parameters viaalgorithm unrolling methods. This approach brings two benefits: 1)mathmatically determining the participation degree of local model parameters inthe federated collaboration, and 2) obtaining more stable and improvedsolutions. Extensive experiments on various tasks, including regression,forecasting, and image classification, demonstrate that $\textit{Learn2pFed}$significantly outperforms previous personalized federated learning methods.</description><author>Kexin Lv, Rui Ye, Xiaolin Huang, Jie Yang, Siheng Chen</author><pubDate>Tue, 16 Jan 2024 12:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08327v1</guid></item><item><title>RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning</title><link>http://arxiv.org/abs/2401.08326v1</link><description>Tool learning has generated widespread interest as a vital means ofinteraction between Large Language Models (LLMs) and the physical world.Current research predominantly emphasizes LLMs' capacity to utilize tools inwell-structured environments while overlooking their stability when confrontedwith the inevitable noise of the real world. To bridge this gap, we introduceRoTBench, a multi-level benchmark for evaluating the robustness of LLMs in toollearning. Specifically, we establish five external environments, each featuringvarying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),providing an in-depth analysis of the model's resilience across three criticalphases: tool selection, parameter identification, and content filling.Experiments involving six widely-used models underscore the urgent necessityfor enhancing the robustness of LLMs in tool learning. For instance, theperformance of GPT-4 even drops significantly from 80.00 to 58.10 when there isno substantial change in manual accuracy. More surprisingly, the noisecorrection capability inherent in the GPT family paradoxically impedes itsadaptability in the face of mild noise. In light of these findings, we proposeRoTTuning, a strategy that enriches the diversity of training environments tobolster the robustness of LLMs in tool learning. The code and data areavailable at https://github.com/Junjie-Ye/RoTBench.</description><author>Junjie Ye, Yilong Wu, Songyang Gao, Sixian Li, Guanyu Li, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang</author><pubDate>Tue, 16 Jan 2024 12:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08326v1</guid></item><item><title>The Memory Perturbation Equation: Understanding Model's Sensitivity to Data</title><link>http://arxiv.org/abs/2310.19273v2</link><description>Understanding model's sensitivity to its training data is crucial but canalso be challenging and costly, especially during training. To simplify suchissues, we present the Memory-Perturbation Equation (MPE) which relates model'ssensitivity to perturbation in its training data. Derived using Bayesianprinciples, the MPE unifies existing sensitivity measures, generalizes them toa wide-variety of models and algorithms, and unravels useful propertiesregarding sensitivities. Our empirical results show that sensitivity estimatesobtained during training can be used to faithfully predict generalization onunseen test data. The proposed equation is expected to be useful for futureresearch on robust and adaptive learning.</description><author>Peter Nickl, Lu Xu, Dharmesh Tailor, Thomas Möllenhoff, Mohammad Emtiyaz Khan</author><pubDate>Tue, 16 Jan 2024 12:38:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19273v2</guid></item><item><title>OpenDPD: An Open-Source End-to-End Learning &amp; Benchmarking Framework for Wideband Power Amplifier Modeling and Digital Pre-Distortion</title><link>http://arxiv.org/abs/2401.08318v1</link><description>With the rise in communication capacity, deep neural networks (DNN) fordigital pre-distortion (DPD) to correct non-linearity in wideband poweramplifiers (PAs) have become prominent. Yet, there is a void in open-source andmeasurement-setup-independent platforms for fast DPD exploration and objectiveDPD model comparison. This paper presents an open-source framework, OpenDPD,crafted in PyTorch, with an associated dataset for PA modeling and DPDlearning. We introduce a Dense Gated Recurrent Unit (DGRU)-DPD, trained via anovel end-to-end learning architecture, outperforming previous DPD models on adigital PA DPA in the new digital transmitter (DTX) architecture withunconventional transfer characteristics compared to analog PAs. Measurementsshow our DGRU-DPD achieves an ACPR of -44.69/-44.47 dBc and an EVM of -35.22 dBfor 200 MHz OFDM signals. OpenDPD code, datasets, and documentation arepublicly available at https://github.com/lab-emi/OpenDPD.</description><author>Yizhuo Wu, Gagan Deep Singh, Mohammadreza Beikmirza, Leo de Vreede, Morteza Alavi, Chang Gao</author><pubDate>Tue, 16 Jan 2024 12:36:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08318v1</guid></item><item><title>Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening</title><link>http://arxiv.org/abs/2401.08315v1</link><description>The automation of resume screening is a crucial aspect of the recruitmentprocess in organizations. Automated resume screening systems often encompass arange of natural language processing (NLP) tasks. The advent of Large LanguageModels (LLMs) has notably enhanced the efficacy of these systems, showcasingtheir robust generalization abilities across diverse language-related tasks.Accompanying these developments are various agents based on LLMs, whichfacilitate their application in practical scenarios. This paper introduces anovel LLM-based agent framework for resume screening, aimed at enhancingefficiency and time management in recruitment processes. Our framework isdistinct in its ability to efficiently summarize and grade each resume from alarge dataset. Moreover, it utilizes LLM agents for decision-making,determining which candidates receive job offers, or which ones to bring in forinterviews. To evaluate our framework, we constructed a dataset from actualresumes and conducted simulate a resume screening process. Subsequently, theoutcomes of the simulation experiment were compared and subjected to detailedanalysis. The results demonstrate that our automated resume screening frameworkis 11 times faster than traditional manual methods. Furthermore, by fine-tuningthe LLMs, we observed a significant improvement in the F1 score, reaching87.73\%, during the resume sentence classification phase. In the resumesummarization and grading phase, our fine-tuned model surpassed the baselineperformance of the GPT-3.5 model. Analysis of the decision-making efficacy ofthe LLM agents in the final offer stage further underscores the potential ofLLM agents in transforming resume screening processes.</description><author>Chengguang Gan, Qinghao Zhang, Tatsunori Mori</author><pubDate>Tue, 16 Jan 2024 12:30:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08315v1</guid></item><item><title>GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection</title><link>http://arxiv.org/abs/2311.09620v2</link><description>Detecting out-of-distribution (OOD) examples is crucial to guarantee thereliability and safety of deep neural networks in real-world settings. In thispaper, we offer an innovative perspective on quantifying the disparitiesbetween in-distribution (ID) and OOD data -- analyzing the uncertainty thatarises when models attempt to explain their predictive decisions. Thisperspective is motivated by our observation that gradient-based attributionmethods encounter challenges in assigning feature importance to OOD data,thereby yielding divergent explanation patterns. Consequently, we investigatehow attribution gradients lead to uncertain explanation outcomes and introducetwo forms of abnormalities for OOD detection: the zero-deflation abnormalityand the channel-wise average abnormality. We then propose GAIA, a simple andeffective approach that incorporates Gradient Abnormality Inspection andAggregation. The effectiveness of GAIA is validated on both commonly utilized(CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reducesthe average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared toadvanced post-hoc methods.</description><author>Jinggang Chen, Junjie Li, Xiaoyang Qu, Jianzong Wang, Jiguang Wan, Jing Xiao</author><pubDate>Tue, 16 Jan 2024 12:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09620v2</guid></item><item><title>Anchor function: a type of benchmark functions for studying language models</title><link>http://arxiv.org/abs/2401.08309v1</link><description>Understanding transformer-based language models is becoming increasinglycrucial, particularly as they play pivotal roles in advancing towardsartificial general intelligence. However, language model research facessignificant challenges, especially for academic research groups withconstrained resources. These challenges include complex data structures,unknown target functions, high computational costs and memory requirements, anda lack of interpretability in the inference process, etc. Drawing a parallel tothe use of simple models in scientific research, we propose the concept of ananchor function. This is a type of benchmark function designed for studyinglanguage models in learning tasks that follow an "anchor-key" pattern. Byutilizing the concept of an anchor function, we can construct a series offunctions to simulate various language tasks. The anchor function plays a roleanalogous to that of mice in diabetes research, particularly suitable foracademic research. We demonstrate the utility of the anchor function with anexample, revealing two basic operations by attention structures in languagemodels: shifting tokens and broadcasting one token from one position to manypositions. These operations are also commonly observed in large languagemodels. The anchor function framework, therefore, opens up a series of valuableand accessible research questions for further exploration, especially fortheoretical study.</description><author>Zhongwang Zhang, Zhiwei Wang, Junjie Yao, Zhangchen Zhou, Xiaolong Li, Weinan E, Zhi-Qin John Xu</author><pubDate>Tue, 16 Jan 2024 12:10:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08309v1</guid></item><item><title>On Quantum Natural Policy Gradients</title><link>http://arxiv.org/abs/2401.08307v1</link><description>This research delves into the role of the quantum Fisher Information Matrix(FIM) in enhancing the performance of Parameterized Quantum Circuit (PQC)-basedreinforcement learning agents. While previous studies have highlighted theeffectiveness of PQC-based policies preconditioned with the quantum FIM incontextual bandits, its impact in broader reinforcement learning contexts, suchas Markov Decision Processes, is less clear. Through a detailed analysis ofL\"owner inequalities between quantum and classical FIMs, this study uncoversthe nuanced distinctions and implications of using each type of FIM. Ourresults indicate that a PQC-based agent using the quantum FIM withoutadditional insights typically incurs a larger approximation error and does notguarantee improved performance compared to the classical FIM. Empiricalevaluations in classic control benchmarks suggest even though quantum FIMpreconditioning outperforms standard gradient ascent, in general it is notsuperior to classical FIM preconditioning.</description><author>André Sequeira, Luis Paulo Santos, Luis Soares Barbosa</author><pubDate>Tue, 16 Jan 2024 12:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08307v1</guid></item><item><title>CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models</title><link>http://arxiv.org/abs/2312.04350v2</link><description>The ability to perform causal reasoning is widely considered a core featureof intelligence. In this work, we investigate whether large language models(LLMs) can coherently reason about causality. Much of the existing work innatural language processing (NLP) focuses on evaluating commonsense causalreasoning in LLMs, thus failing to assess whether a model can perform causalinference in accordance with a set of well-defined formal rules. To addressthis, we propose a new NLP task, causal inference in natural language, inspiredby the "causal inference engine" postulated by Judea Pearl et al. We compose alarge dataset, CLadder, with 10K samples: based on a collection of causalgraphs and queries (associational, interventional, and counterfactual), weobtain symbolic questions and ground-truth answers, through an oracle causalinference engine. These are then translated into natural language. We evaluatemultiple LLMs on our dataset, and we introduce and evaluate a bespokechain-of-thought prompting strategy, CausalCoT. We show that our task is highlychallenging for LLMs, and we conduct an in-depth analysis to gain deeperinsights into the causal reasoning abilities of LLMs. Our data is open-sourcedat https://huggingface.co/datasets/causalNLP/cladder, and our code can be foundat https://github.com/causalNLP/cladder.</description><author>Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng Lyu, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, Bernhard Schölkopf</author><pubDate>Tue, 16 Jan 2024 12:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04350v2</guid></item><item><title>FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning</title><link>http://arxiv.org/abs/2307.13716v2</link><description>Traditional federated learning uses the number of samples to calculate theweights of each client model and uses this fixed weight value to fusion theglobal model. However, in practical scenarios, each client's device and dataheterogeneity leads to differences in the quality of each client's model. Thusthe contribution to the global model is not wholly determined by the samplesize. In addition, if clients intentionally upload low-quality or maliciousmodels, using these models for aggregation will lead to a severe decrease inglobal model accuracy. Traditional federated learning algorithms do not addressthese issues. To solve this probelm, we propose FedDRL, a model fusion approachusing reinforcement learning based on a two staged approach. In the firststage, Our method could filter out malicious models and selects trusted clientmodels to participate in the model fusion. In the second stage, the FedDRLalgorithm adaptively adjusts the weights of the trusted client models andaggregates the optimal global model. We also define five model fusion scenariosand compare our method with two baseline algorithms in those scenarios. Theexperimental results show that our algorithm has higher reliability than otheralgorithms while maintaining accuracy.</description><author>Leiming Chen, Cihao Dong, Sibo Qiao, Ziling Huang, Kai Wang, Yuming Nie, Zhaoxiang Hou, Cheewei Tan</author><pubDate>Tue, 16 Jan 2024 12:03:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13716v2</guid></item><item><title>Sum Throughput Maximization in Multi-BD Symbiotic Radio NOMA Network Assisted by Active-STAR-RIS</title><link>http://arxiv.org/abs/2401.08301v1</link><description>In this paper, we employ active simultaneously transmitting and reflectingreconfigurable intelligent surface (ASRIS) to aid in establishing and enhancingcommunication within a commensal symbiotic radio (CSR) network. Unliketraditional RIS, ASRIS not only ensures coverage in an omni directional mannerbut also amplifies received signals, consequently elevating overall networkperformance. in the first phase, base station (BS) with active massive MIMOantennas, send ambient signal to SBDs. In the first phase, the BS transmitsambient signals to the symbiotic backscatter devices (SBDs), and afterharvesting the energy and modulating their information onto the signal carrier,the SBDs send Backscatter signals back to the BS. In this scheme, we employ theBackscatter Relay system to facilitate the transmission of information from theSBDs to the symbiotic User Equipments (SUEs) with the assistance of the BS. Inthe second phase, the BS transmits information signals to the SUEs aftereliminating interference using the Successive Interference Cancellation (SIC)method. ASRIS is employed to establish communication among SUEs lacking a lineof sight (LoS) and to amplify power signals for SUEs with a LoS connection tothe BS. It is worth noting that we use NOMA for multiple access in all network. The main goal of this paper is to maximize the sum throughput between allusers. To achieve this, we formulate an optimization problem with variablesincluding active beamforming coefficients at the BS and ASRIS, as well as thephase adjustments of ASRIS and scheduling parameters between the first andsecond phases. To model this optimization problem, we employ three deepreinforcement learning (DRL) methods, namely PPO, TD3, and A3C. Finally, thementioned methods are simulated and compared with each other.</description><author>Rahman Saadat Yeganeh, Mohammad Javad Omidi, Farshad Zeinali, Mohammad Robatmili, Mohammad Ghavami</author><pubDate>Tue, 16 Jan 2024 11:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08301v1</guid></item><item><title>Online Unsupervised Video Object Segmentation via Contrastive Motion Clustering</title><link>http://arxiv.org/abs/2306.12048v2</link><description>Online unsupervised video object segmentation (UVOS) uses the previous framesas its input to automatically separate the primary object(s) from a streamingvideo without using any further manual annotation. A major challenge is thatthe model has no access to the future and must rely solely on the history,i.e., the segmentation mask is predicted from the current frame as soon as itis captured. In this work, a novel contrastive motion clustering algorithm withan optical flow as its input is proposed for the online UVOS by exploiting thecommon fate principle that visual elements tend to be perceived as a group ifthey possess the same motion pattern. We build a simple and effectiveauto-encoder to iteratively summarize non-learnable prototypical bases for themotion pattern, while the bases in turn help learn the representation of theembedding network. Further, a contrastive learning strategy based on a boundaryprior is developed to improve foreground and background feature discriminationin the representation learning stage. The proposed algorithm can be optimizedon arbitrarily-scale data i.e., frame, clip, dataset) and performed in anonline fashion. Experiments on $\textit{DAVIS}_{\textit{16}}$, $\textit{FBMS}$,and $\textit{SegTrackV2}$ datasets show that the accuracy of our methodsurpasses the previous state-of-the-art (SoTA) online UVOS method by a marginof 0.8%, 2.9%, and 1.1%, respectively. Furthermore, by using an online deepsubspace clustering to tackle the motion grouping, our method is able toachieve higher accuracy at $3\times$ faster inference time compared to SoTAonline UVOS method, and making a good trade-off between effectiveness andefficiency.</description><author>Lin Xi, Weihai Chen, Xingming Wu, Zhong Liu, Zhengguo Li</author><pubDate>Tue, 16 Jan 2024 11:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12048v2</guid></item><item><title>DAPT: A Dual Attention Framework for Parameter-Efficient Continual Learning of Large Language Models</title><link>http://arxiv.org/abs/2401.08295v1</link><description>The continual learning (CL) ability is vital for deploying large languagemodels (LLMs) in the dynamic world. Based on parameter-efficient tuning (PET),existing methods devise the learning module and the selection module to handlethe challenges of catastrophic forgetting (CF) and knowledge transfer (KT) inCL. The learning module allocates separate PET blocks for each continuallyemerged task and the selection module function to choose the correct one forthe input at testing time. However, there are limitations in their deigns ofboth modules and they ignore the potential of aligning the two module toaddress CF and KT simultaneously. To this end, we propose a novel DualAttention Framework , to align the PET learning and selection via the DualAttentive Learning\&amp;Selection module. Extensive Experiments on two CLbenchmarks demonstrate the superiority of DAPT to resist CF and facilitate KTat the same time. Moreover, DAPT exhibits the superiority when we scale it todifferent model sizes (from 770M to 11B) and unseen tasks.</description><author>Weixiang Zhao, Shilong Wang, Yulin Hu, Yanyan Zhao, Bing Qin, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che</author><pubDate>Tue, 16 Jan 2024 11:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08295v1</guid></item><item><title>Inferflow: an Efficient and Highly Configurable Inference Engine for Large Language Models</title><link>http://arxiv.org/abs/2401.08294v1</link><description>We present Inferflow, an efficient and highly configurable inference enginefor large language models (LLMs). With Inferflow, users can serve most of thecommon transformer models by simply modifying some lines in correspondingconfiguration files, without writing a single line of source code. Comparedwith most existing inference engines, Inferflow has some key features. First,by implementing a modular framework of atomic build-blocks and technologies,Inferflow is compositionally generalizable to new models. Second, 3.5-bitquantization is introduced in Inferflow as a tradeoff between 3-bit and 4-bitquantization. Third, hybrid model partitioning for multi-GPU inference isintroduced in Inferflow to better balance inference speed and throughput thanthe existing partition-by-layer and partition-by-tensor strategies.</description><author>Shuming Shi, Enbo Zhao, Deng Cai, Leyang Cui, Xinting Huang, Huayang Li</author><pubDate>Tue, 16 Jan 2024 11:39:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08294v1</guid></item><item><title>Causal Machine Learning for Moderation Effects</title><link>http://arxiv.org/abs/2401.08290v1</link><description>It is valuable for any decision maker to know the impact of decisions(treatments) on average and for subgroups. The causal machine learningliterature has recently provided tools for estimating group average treatmenteffects (GATE) to understand treatment heterogeneity better. This paperaddresses the challenge of interpreting such differences in treatment effectsbetween groups while accounting for variations in other covariates. We proposea new parameter, the balanced group average treatment effect (BGATE), whichmeasures a GATE with a specific distribution of a priori-determined covariates.By taking the difference of two BGATEs, we can analyse heterogeneity moremeaningfully than by comparing two GATEs. The estimation strategy for thisparameter is based on double/debiased machine learning for discrete treatmentsin an unconfoundedness setting, and the estimator is shown to be$\sqrt{N}$-consistent and asymptotically normal under standard conditions.Adding additional identifying assumptions allows specific balanced differencesin treatment effects between groups to be interpreted causally, leading to thecausal balanced group average treatment effect. We explore the finite sampleproperties in a small-scale simulation study and demonstrate the usefulness ofthese parameters in an empirical example.</description><author>Nora Bearth, Michael Lechner</author><pubDate>Tue, 16 Jan 2024 11:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08290v1</guid></item><item><title>RLPlanner: Reinforcement Learning based Floorplanning for Chiplets with Fast Thermal Analysis</title><link>http://arxiv.org/abs/2312.16895v2</link><description>Chiplet-based systems have gained significant attention in recent years dueto their low cost and competitive performance. As the complexity andcompactness of a chiplet-based system increase, careful consideration must begiven to microbump assignments, interconnect delays, and thermal limitationsduring the floorplanning stage. This paper introduces RLPlanner, an efficientearly-stage floorplanning tool for chiplet-based systems with a novel fastthermal evaluation method. RLPlanner employs advanced reinforcement learning tojointly minimize total wirelength and temperature. To alleviate thetime-consuming thermal calculations, RLPlanner incorporates the developed fastthermal evaluation method to expedite the iterations and optimizations.Comprehensive experiments demonstrate that our proposed fast thermal evaluationmethod achieves a mean absolute error (MAE) of 0.25 K and delivers over 120xspeed-up compared to the open-source thermal solver HotSpot. When integratedwith our fast thermal evaluation method, RLPlanner achieves an averageimprovement of 20.28\% in minimizing the target objective (a combination ofwirelength and temperature), within a similar running time, compared to theclassic simulated annealing method with HotSpot.</description><author>Yuanyuan Duan, Xingchen Liu, Zhiping Yu, Hanming Wu, Leilai Shao, Xiaolei Zhu</author><pubDate>Tue, 16 Jan 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16895v2</guid></item><item><title>Deep learning based Image Compression for Microscopy Images: An Empirical Study</title><link>http://arxiv.org/abs/2311.01352v2</link><description>With the fast development of modern microscopes and bioimaging techniques, anunprecedentedly large amount of imaging data are being generated, stored,analyzed, and even shared through networks. The size of the data poses greatchallenges for current data infrastructure. One common way to reduce the datasize is by image compression. This present study analyzes classic and deeplearning based image compression methods, and their impact on deep learningbased image processing models. Deep learning based label-free prediction models(i.e., predicting fluorescent images from bright field images) are used as anexample application for comparison and analysis. Effective image compressionmethods could help reduce the data size significantly without losing necessaryinformation, and therefore reduce the burden on data management infrastructureand permit fast transmission through the network for data sharing or cloudcomputing. To compress images in such a wanted way, multiple classical lossyimage compression techniques are compared to several AI-based compressionmodels provided by and trained with the CompressAI toolbox using python. Thesedifferent compression techniques are compared in compression ratio, multipleimage similarity measures and, most importantly, the prediction accuracy fromlabel-free models on compressed images. We found that AI-based compressiontechniques largely outperform the classic ones and will minimally affect thedownstream label-free task in 2D cases. In the end, we hope the present studycould shed light on the potential of deep learning based image compression andthe impact of image compression on downstream deep learning based imageanalysis models.</description><author>Yu Zhou, Jan Sollmann, Jianxu Chen</author><pubDate>Tue, 16 Jan 2024 11:32:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01352v2</guid></item><item><title>ENN: A Neural Network with DCT Adaptive Activation Functions</title><link>http://arxiv.org/abs/2307.00673v2</link><description>The expressiveness of neural networks highly depends on the nature of theactivation function, although these are usually assumed predefined and fixedduring the training stage. Under a signal processing perspective, in this paperwe present Expressive Neural Network (ENN), a novel model in which thenon-linear activation functions are modeled using the Discrete Cosine Transform(DCT) and adapted using backpropagation during training. This parametrizationkeeps the number of trainable parameters low, is appropriate for gradient-basedschemes, and adapts to different learning tasks. This is the first non-linearmodel for activation functions that relies on a signal processing perspective,providing high flexibility and expressiveness to the network. We contributewith insights in the explainability of the network at convergence by recoveringthe concept of bump, this is, the response of each activation function in theoutput space. Finally, through exhaustive experiments we show that the modelcan adapt to classification and regression tasks. The performance of ENNoutperforms state of the art benchmarks, providing above a 40% gap in accuracyin some scenarios.</description><author>Marc Martinez-Gost, Ana Pérez-Neira, Miguel Ángel Lagunas</author><pubDate>Tue, 16 Jan 2024 11:15:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00673v2</guid></item><item><title>The Faiss library</title><link>http://arxiv.org/abs/2401.08281v1</link><description>Vector databases manage large collections of embedding vectors. As AIapplications are growing rapidly, so are the number of embeddings that need tobe stored and indexed. The Faiss library is dedicated to vector similaritysearch, a core functionality of vector databases. Faiss is a toolkit ofindexing methods and related primitives used to search, cluster, compress andtransform vectors. This paper first describes the tradeoff space of vectorsearch, then the design principles of Faiss in terms of structure, approach tooptimization and interfacing. We benchmark key features of the library anddiscuss a few selected applications to highlight its broad applicability.</description><author>Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, Hervé Jégou</author><pubDate>Tue, 16 Jan 2024 11:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08281v1</guid></item><item><title>AQuA: A Benchmarking Tool for Label Quality Assessment</title><link>http://arxiv.org/abs/2306.09467v2</link><description>Machine learning (ML) models are only as good as the data they are trainedon. But recent studies have found datasets widely used to train and evaluate MLmodels, e.g. ImageNet, to have pervasive labeling errors. Erroneous labels onthe train set hurt ML models' ability to generalize, and they impact evaluationand model selection using the test set. Consequently, learning in the presenceof labeling errors is an active area of research, yet this field lacks acomprehensive benchmark to evaluate these methods. Most of these methods areevaluated on a few computer vision datasets with significant variance in theexperimental protocols. With such a large pool of methods and inconsistentevaluation, it is also unclear how ML practitioners can choose the right modelsto assess label quality in their data. To this end, we propose a benchmarkingenvironment AQuA to rigorously evaluate methods that enable machine learning inthe presence of label noise. We also introduce a design space to delineateconcrete design choices of label error detection models. We hope that ourproposed design space and benchmark enable practitioners to choose the righttools to improve their label quality and that our benchmark enables objectiveand rigorous evaluation of machine learning tools facing mislabeled data.</description><author>Mononito Goswami, Vedant Sanil, Arjun Choudhry, Arvind Srinivasan, Chalisa Udompanyawit, Artur Dubrawski</author><pubDate>Tue, 16 Jan 2024 11:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09467v2</guid></item><item><title>Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks</title><link>http://arxiv.org/abs/2312.03365v2</link><description>Controlling energy consumption in buildings through demand response (DR) hasbecome increasingly important to reduce global carbon emissions and limitclimate change. In this paper, we specifically focus on controlling the heatingsystem of a residential building to optimize its energy consumption whilerespecting user's thermal comfort. Recent works in this area have mainlyfocused on either model-based control, e.g., model predictive control (MPC), ormodel-free reinforcement learning (RL) to implement practical DR algorithms. Aspecific RL method that recently has achieved impressive success in domainssuch as board games (go, chess) is Monte Carlo Tree Search (MCTS). Yet, forbuilding control it has remained largely unexplored. Thus, we study MCTSspecifically for building demand response. Its natural structure allows aflexible optimization that implicitly integrate exogenous constraints (asopposed, for example, to conventional RL solutions), making MCTS a promisingcandidate for DR control problems. We demonstrate how to improve MCTS controlperformance by incorporating a Physics-informed Neural Network (PiNN) model forits underlying thermal state prediction, as opposed to traditional purelydata-driven Black-Box approaches. Our MCTS implementation aligned with a PiNNmodel is able to obtain a 3% increment of the obtained reward compared to arule-based controller; leading to a 10% cost reduction and 35% reduction ontemperature difference with the desired one when applied to an artificial priceprofile. We further implemented a Deep Learning layer into the Monte Carlo TreeSearch technique using a neural network that leads the tree search through moreoptimal nodes. We then compared this addition with its Vanilla version, showingthe improvement in computational cost required.</description><author>Fabio Pavirani, Gargya Gokhale, Bert Claessens, Chris Develder</author><pubDate>Tue, 16 Jan 2024 11:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03365v2</guid></item><item><title>Intelligence of Astronomical Optical Telescope: Present Status and Future Perspectives</title><link>http://arxiv.org/abs/2306.16834v2</link><description>Artificial intelligence technology has been widely used in astronomy, and newartificial intelligence technologies and application scenarios are constantlyemerging. There have been a large number of papers reviewing the application ofartificial intelligence technology in astronomy. However, relevant articlesseldom mention telescope intelligence separately, and it is difficult tounderstand the current development status and research hotspots of telescopeintelligence from these papers. This paper combines the development history ofartificial intelligence technology and the difficulties of criticaltechnologies of telescopes, comprehensively introduces the development andresearch hotspots of telescope intelligence, then conducts statistical analysison various research directions of telescope intelligence and defines theresearch directions' merits. All kinds of research directions are evaluated,and the research trend of each telescope's intelligence is pointed out.Finally, according to the advantages of artificial intelligence technology andthe development trend of telescopes, future research hotspots of telescopeintelligence are given.</description><author>Kang Huang, Tianzhu Hu, Jingyi Cai, Xiushan Pang, Yonghui Hou, Yong Zhang, Huaiqing Wang, Xiangqun Cui</author><pubDate>Tue, 16 Jan 2024 11:02:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16834v2</guid></item><item><title>AesBench: An Expert Benchmark for Multimodal Large Language Models on Image Aesthetics Perception</title><link>http://arxiv.org/abs/2401.08276v1</link><description>With collective endeavors, multimodal large language models (MLLMs) areundergoing a flourishing development. However, their performances on imageaesthetics perception remain indeterminate, which is highly desired inreal-world applications. An obvious obstacle lies in the absence of a specificbenchmark to evaluate the effectiveness of MLLMs on aesthetic perception. Thisblind groping may impede the further development of more advanced MLLMs withaesthetic perception capacity. To address this dilemma, we propose AesBench, anexpert benchmark aiming to comprehensively evaluate the aesthetic perceptioncapacities of MLLMs through elaborate design across dual facets. (1) Weconstruct an Expert-labeled Aesthetics Perception Database (EAPD), whichfeatures diversified image contents and high-quality annotations provided byprofessional aesthetic experts. (2) We propose a set of integrative criteria tomeasure the aesthetic perception abilities of MLLMs from four perspectives,including Perception (AesP), Empathy (AesE), Assessment (AesA) andInterpretation (AesI). Extensive experimental results underscore that thecurrent MLLMs only possess rudimentary aesthetic perception ability, and thereis still a significant gap between MLLMs and humans. We hope this work caninspire the community to engage in deeper explorations on the aestheticpotentials of MLLMs. Source data will be available athttps://github.com/yipoh/AesBench.</description><author>Yipo Huang, Quan Yuan, Xiangfei Sheng, Zhichao Yang, Haoning Wu, Pengfei Chen, Yuzhe Yang, Leida Li, Weisi Lin</author><pubDate>Tue, 16 Jan 2024 10:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08276v1</guid></item><item><title>Modeling Spoof Noise by De-spoofing Diffusion and its Application in Face Anti-spoofing</title><link>http://arxiv.org/abs/2401.08275v1</link><description>Face anti-spoofing is crucial for ensuring the security and reliability offace recognition systems. Several existing face anti-spoofing methods utilizeGAN-like networks to detect presentation attacks by estimating the noisepattern of a spoof image and recovering the corresponding genuine image. ButGAN's limited face appearance space results in the denoised faces cannot coverthe full data distribution of genuine faces, thereby undermining thegeneralization performance of such methods. In this work, we present apioneering attempt to employ diffusion models to denoise a spoof image andrestore the genuine image. The difference between these two images isconsidered as the spoof noise, which can serve as a discriminative cue for faceanti-spoofing. We evaluate our proposed method on several intra-testing andinter-testing protocols, where the experimental results showcase theeffectiveness of our method in achieving competitive performance in terms ofboth accuracy and generalization.</description><author>Bin Zhang, Xiangyu Zhu, Xiaoyu Zhang, Zhen Lei</author><pubDate>Tue, 16 Jan 2024 10:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08275v1</guid></item><item><title>Large Language Models are Null-Shot Learners</title><link>http://arxiv.org/abs/2401.08273v1</link><description>This paper presents null-shot prompting. Null-shot prompting exploitshallucination in large language models (LLMs) by instructing LLMs to utilizeinformation from the "Examples" section that never exists within the providedcontext to perform a task. While reducing hallucination is crucial andnon-negligible for daily and critical uses of LLMs, we propose that in thecurrent landscape in which these LLMs still hallucinate, it is possible, infact, to exploit hallucination to increase performance in performing taskscompared to standard zero-shot prompting. Experiments with six LLMs showimprovements in performance across the majority of eight datasets, includingreading comprehension, arithmetic reasoning, and closed-book questionanswering. The observed inconsistency in increased relative performance acrossLLMs also potentially indicates a different degree of inherent hallucination ineach model. These differences show that it is possible to utilize null-shotprompting as a way to detect degrees of hallucination in LLMs using existingbenchmarking datasets. We also perform ablation studies, includingexperimenting with a modified version of null-shot prompting that incorporatesideas from zero-shot chain-of-thought prompting, which shows different trendsof results.</description><author>Pittawat Taveekitworachai, Febri Abdullah, Ruck Thawonmas</author><pubDate>Tue, 16 Jan 2024 10:53:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08273v1</guid></item><item><title>How to Turn Your Knowledge Graph Embeddings into Generative Models</title><link>http://arxiv.org/abs/2305.15944v3</link><description>Some of the most successful knowledge graph embedding (KGE) models for linkprediction -- CP, RESCAL, TuckER, ComplEx -- can be interpreted as energy-basedmodels. Under this perspective they are not amenable for exactmaximum-likelihood estimation (MLE), sampling and struggle to integrate logicalconstraints. This work re-interprets the score functions of these KGEs ascircuits -- constrained computational graphs allowing efficientmarginalisation. Then, we design two recipes to obtain efficient generativecircuit models by either restricting their activations to be non-negative orsquaring their outputs. Our interpretation comes with little or no loss ofperformance for link prediction, while the circuits framework unlocks exactlearning by MLE, efficient sampling of new triples, and guarantee that logicalconstraints are satisfied by design. Furthermore, our models scale moregracefully than the original KGEs on graphs with millions of entities.</description><author>Lorenzo Loconte, Nicola Di Mauro, Robert Peharz, Antonio Vergari</author><pubDate>Tue, 16 Jan 2024 10:53:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15944v3</guid></item><item><title>Siamese Content-based Search Engine for a More Transparent Skin and Breast Cancer Diagnosis through Histological Imaging</title><link>http://arxiv.org/abs/2401.08272v1</link><description>Computer Aid Diagnosis (CAD) has developed digital pathology with DeepLearning (DL)-based tools to assist pathologists in decision-making.Content-Based Histopathological Image Retrieval (CBHIR) is a novel tool to seekhighly correlated patches in terms of similarity in histopathological features.In this work, we proposed two CBHIR approaches on breast (Breast-twins) andskin cancer (Skin-twins) data sets for robust and accurate patch-levelretrieval, integrating a custom-built Siamese network as a feature extractor.The proposed Siamese network is able to generalize for unseen images byfocusing on the similar histopathological features of the input pairs. Theproposed CBHIR approaches are evaluated on the Breast (public) and Skin(private) data sets with top K accuracy. Finding the optimum amount of K ischallenging, but also, as much as K increases, the dissimilarity between thequery and the returned images increases which might mislead the pathologists.To the best of the author's belief, this paper is tackling this issue for thefirst time on histopathological images by evaluating the top first retrievedimages. The Breast-twins model achieves 70% of the F1score at the top first,which exceeds the other state-of-the-art methods at a higher amount of K suchas 5 and 400. Skin-twins overpasses the recently proposed Convolutional AutoEncoder (CAE) by 67%, increasing the precision. Besides, the Skin-twins modeltackles the challenges of Spitzoid Tumors of Uncertain Malignant Potential(STUMP) to assist pathologists with retrieving top K images and theircorresponding labels. So, this approach can offer a more explainable CAD toolto pathologists in terms of transparency, trustworthiness, or reliability amongother characteristics.</description><author>Zahra Tabatabaei, Adrián Colomer, JAvier Oliver Moll, Valery Naranjo</author><pubDate>Tue, 16 Jan 2024 10:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08272v1</guid></item><item><title>An Explainable Proxy Model for Multiabel Audio Segmentation</title><link>http://arxiv.org/abs/2401.08268v1</link><description>Audio signal segmentation is a key task for automatic audio indexing. Itconsists of detecting the boundaries of class-homogeneous segments in thesignal. In many applications, explainable AI is a vital process fortransparency of decision-making with machine learning. In this paper, wepropose an explainable multilabel segmentation model that solves speechactivity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD)simultaneously. This proxy uses the non-negative matrix factorization (NMF) tomap the embedding used for the segmentation to the frequency domain.Experiments conducted on two datasets show similar performances as thepre-trained black box model while showing strong explainability features.Specifically, the frequency bins used for the decision can be easily identifiedat both the segment level (local explanations) and global level (classprototypes).</description><author>Théo Mariotte, Antonio Almudévar, Marie Tahon, Alsonfo Ortega</author><pubDate>Tue, 16 Jan 2024 10:41:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08268v1</guid></item><item><title>Multi-Technique Sequential Information Consistency For Dynamic Visual Place Recognition In Changing Environments</title><link>http://arxiv.org/abs/2401.08263v1</link><description>Visual place recognition (VPR) is an essential component of robot navigationand localization systems that allows them to identify a place using only imagedata. VPR is challenging due to the significant changes in a place's appearancedriven by different daily illumination, seasonal weather variations and diverseviewpoints. Currently, no single VPR technique excels in every environmentalcondition, each exhibiting unique benefits and shortcomings, and thereforecombining multiple techniques can achieve more reliable VPR performance.Present multi-method approaches either rely on online ground-truth information,which is often not available, or on brute-force technique combination,potentially lowering performance with high variance technique sets. Addressingthese shortcomings, we propose a VPR system dubbed Multi-Sequential InformationConsistency (MuSIC) which leverages sequential information to select the mostcohesive technique on an online per-frame basis. For each technique in a set,MuSIC computes their respective sequential consistencies by analysing theframe-to-frame continuity of their top match candidates, which are thendirectly compared to select the optimal technique for the current query image.The use of sequential information to select between VPR methods results in anoverall VPR performance increase across different benchmark datasets, whileavoiding the need for extra ground-truth of the runtime environment.</description><author>Bruno Arcanjo, Bruno Ferrarini, Michael Milford, Klaus D. McDonald-Maier, Shoaib Ehsan</author><pubDate>Tue, 16 Jan 2024 10:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08263v1</guid></item><item><title>Probabilistically Robust Watermarking of Neural Networks</title><link>http://arxiv.org/abs/2401.08261v1</link><description>As deep learning (DL) models are widely and effectively used in MachineLearning as a Service (MLaaS) platforms, there is a rapidly growing interest inDL watermarking techniques that can be used to confirm the ownership of aparticular model. Unfortunately, these methods usually produce watermarkssusceptible to model stealing attacks. In our research, we introduce a noveltrigger set-based watermarking approach that demonstrates resilience againstfunctionality stealing attacks, particularly those involving extraction anddistillation. Our approach does not require additional model training and canbe applied to any model architecture. The key idea of our method is to computethe trigger set, which is transferable between the source model and the set ofproxy models with a high probability. In our experimental study, we show thatif the probability of the set being transferable is reasonably high, it can beeffectively used for ownership verification of the stolen model. We evaluateour method on multiple benchmarks and show that our approach outperformscurrent state-of-the-art watermarking techniques in all considered experimentalsetups.</description><author>Mikhail Pautov, Nikita Bogdanov, Stanislav Pyatkin, Oleg Rogov, Ivan Oseledets</author><pubDate>Tue, 16 Jan 2024 10:32:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08261v1</guid></item><item><title>Fast Kernel Summation in High Dimensions via Slicing and Fourier Transforms</title><link>http://arxiv.org/abs/2401.08260v1</link><description>Kernel-based methods are heavily used in machine learning. However, theysuffer from $O(N^2)$ complexity in the number $N$ of considered data points. Inthis paper, we propose an approximation procedure, which reduces thiscomplexity to $O(N)$. Our approach is based on two ideas. First, we prove thatany radial kernel with analytic basis function can be represented as slicedversion of some one-dimensional kernel and derive an analytic formula for theone-dimensional counterpart. It turns out that the relation between one- and$d$-dimensional kernels is given by a generalized Riemann-Liouville fractionalintegral. Hence, we can reduce the $d$-dimensional kernel summation to aone-dimensional setting. Second, for solving these one-dimensional problemsefficiently, we apply fast Fourier summations on non-equispaced data, a sortingalgorithm or a combination of both. Due to its practical importance we payspecial attention to the Gaussian kernel, where we show a dimension-independenterror bound and represent its one-dimensional counterpart via a closed-formFourier transform. We provide a run time comparison and error estimate of ourfast kernel summations.</description><author>Johannes Hertrich</author><pubDate>Tue, 16 Jan 2024 10:31:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08260v1</guid></item><item><title>Multitask Learning in Minimally Invasive Surgical Vision: A Review</title><link>http://arxiv.org/abs/2401.08256v1</link><description>Minimally invasive surgery (MIS) has revolutionized many procedures and ledto reduced recovery time and risk of patient injury. However, MIS posesadditional complexity and burden on surgical teams. Data-driven surgical visionalgorithms are thought to be key building blocks in the development of futureMIS systems with improved autonomy. Recent advancements in machine learning andcomputer vision have led to successful applications in analyzing videosobtained from MIS with the promise of alleviating challenges in MIS videos.Surgical scene and action understanding encompasses multiple related tasksthat, when solved individually, can be memory-intensive, inefficient, and failto capture task relationships. Multitask learning (MTL), a learning paradigmthat leverages information from multiple related tasks to improve performanceand aid generalization, is wellsuited for fine-grained and high-levelunderstanding of MIS data. This review provides an overview of the currentstate-of-the-art MTL systems that leverage videos obtained from MIS. Beyondlisting published approaches, we discuss the benefits and limitations of theseMTL systems. Moreover, this manuscript presents an analysis of the literaturefor various application fields of MTL in MIS, including those with largemodels, highlighting notable trends, new directions of research, anddevelopments.</description><author>Oluwatosin Alabi, Tom Vercauteren, Miaojing Shi</author><pubDate>Tue, 16 Jan 2024 10:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08256v1</guid></item><item><title>A Generative Adversarial Attack for Multilingual Text Classifiers</title><link>http://arxiv.org/abs/2401.08255v1</link><description>Current adversarial attack algorithms, where an adversary changes a text tofool a victim model, have been repeatedly shown to be effective against textclassifiers. These attacks, however, generally assume that the victim model ismonolingual and cannot be used to target multilingual victim models, asignificant limitation given the increased use of these models. For thisreason, in this work we propose an approach to fine-tune a multilingualparaphrase model with an adversarial objective so that it becomes able togenerate effective adversarial examples against multilingual classifiers. Thetraining objective incorporates a set of pre-trained models to ensure textquality and language consistency of the generated text. In addition, all themodels are suitably connected to the generator by vocabulary-mapping matrices,allowing for full end-to-end differentiability of the overall trainingpipeline. The experimental validation over two multilingual datasets and fivelanguages has shown the effectiveness of the proposed approach compared toexisting baselines, particularly in terms of query efficiency. We also providea detailed analysis of the generated attacks and discuss limitations andopportunities for future research.</description><author>Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi</author><pubDate>Tue, 16 Jan 2024 10:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08255v1</guid></item><item><title>Knowledge Graph Error Detection with Contrastive Confidence Adaption</title><link>http://arxiv.org/abs/2312.12108v2</link><description>Knowledge graphs (KGs) often contain various errors. Previous works ondetecting errors in KGs mainly rely on triplet embedding from graph structure.We conduct an empirical study and find that these works struggle todiscriminate noise from semantically-similar correct triplets. In this paper,we propose a KG error detection model CCA to integrate both textual and graphstructural information from triplet reconstruction for better distinguishingsemantics. We design interactive contrastive learning to capture thedifferences between textual and structural patterns. Furthermore, we constructrealistic datasets with semantically-similar noise and adversarial noise.Experimental results demonstrate that CCA outperforms state-of-the-artbaselines, especially in detecting semantically-similar noise and adversarialnoise.</description><author>Xiangyu Liu, Yang Liu, Wei Hu</author><pubDate>Tue, 16 Jan 2024 10:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12108v2</guid></item><item><title>Diffusion Language Models Generation Can Be Halted Early</title><link>http://arxiv.org/abs/2305.10818v2</link><description>Diffusion Language models (DLMs) are a promising avenue for text generationdue to their practical properties on tractable controllable generation. Theyalso have the advantage of not having to predict text autoregressively.However, despite these notable features, DLMs have not yet reached theperformance levels of their Autoregressive counterparts. One of the ways toreduce the performance gap between these two types of language models is tospeed up the generation of DLMs. Therefore, we propose a pioneering methodologyto address this issue in this work. It enables the execution of more generationsteps within a given time frame, potentially leading to higher-quality outputs.Specifically, our methods estimate DLMs completeness of text generation andallow adaptive halting of the generation process. We test and refine ourmethods on Plaid, SSD, and CDCD DLMs and create a cohesive perspective on theirgeneration workflows. Finally, we confirm that our methods allow halting Plaid,SSD, and CDCD models and decrease the generation time by $10$-$40$% without adrop in the quality of model samples.</description><author>Sofia Maria Lo Cicero Vaina, Nikita Balagansky, Daniil Gavrilov</author><pubDate>Tue, 16 Jan 2024 10:03:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10818v2</guid></item><item><title>Optimizing $k$ in $k$NN Graphs with Graph Learning Perspective</title><link>http://arxiv.org/abs/2401.08245v1</link><description>In this paper, we propose a method, based on graph signal processing, tooptimize the choice of $k$ in $k$-nearest neighbor graphs ($k$NNGs). $k$NN isone of the most popular approaches and is widely used in machine learning andsignal processing. The parameter $k$ represents the number of neighbors thatare connected to the target node; however, its appropriate selection is still achallenging problem. Therefore, most $k$NNGs use ad hoc selection methods for$k$. In the proposed method, we assume that a different $k$ can be chosen foreach node. We formulate a discrete optimization problem to seek the best $k$with a constraint on the sum of distances of the connected nodes. The optimal$k$ values are efficiently obtained without solving a complex optimization.Furthermore, we reveal that the proposed method is closely related to existinggraph learning methods. In experiments on real datasets, we demonstrate thatthe $k$NNGs obtained with our method are sparse and can determine anappropriate variable number of edges per node. We validate the effectiveness ofthe proposed method for point cloud denoising, comparing our denoisingperformance with achievable graph construction methods that can be scaled totypical point cloud sizes (e.g., thousands of nodes).</description><author>Asuka Tamaru, Junya Hara, Hiroshi Higashi, Yuichi Tanaka, Antonio Ortega</author><pubDate>Tue, 16 Jan 2024 09:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08245v1</guid></item><item><title>Iterative Regularization with k-support Norm: An Important Complement to Sparse Recovery</title><link>http://arxiv.org/abs/2401.05394v2</link><description>Sparse recovery is ubiquitous in machine learning and signal processing. Dueto the NP-hard nature of sparse recovery, existing methods are known to suffereither from restrictive (or even unknown) applicability conditions, or highcomputational cost. Recently, iterative regularization methods have emerged asa promising fast approach because they can achieve sparse recovery in one passthrough early stopping, rather than the tedious grid-search used in thetraditional methods. However, most of those iterative methods are based on the$\ell_1$ norm which requires restrictive applicability conditions and couldfail in many cases. Therefore, achieving sparse recovery with iterativeregularization methods under a wider range of conditions has yet to be furtherexplored. To address this issue, we propose a novel iterative regularizationalgorithm, IRKSN, based on the $k$-support norm regularizer rather than the$\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, andcompare them with traditional conditions for recovery with $\ell_1$ normregularizers. Additionally, we give an early stopping bound on the model errorof IRKSN with explicit constants, achieving the standard linear rate for sparserecovery. Finally, we illustrate the applicability of our algorithm on severalexperiments, including a support recovery experiment with a correlated designmatrix.</description><author>William de Vazelhes, Bhaskar Mukhoty, Xiao-Tong Yuan, Bin Gu</author><pubDate>Tue, 16 Jan 2024 09:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05394v2</guid></item><item><title>Interpolation of mountain weather forecasts by machine learning</title><link>http://arxiv.org/abs/2308.13983v2</link><description>Recent advances in numerical simulation methods based on physical models andtheir combination with machine learning have improved the accuracy of weatherforecasts. However, the accuracy decreases in complex terrains such asmountainous regions because these methods usually use grids of severalkilometers square and simple machine learning models. While deep learning hasalso made significant progress in recent years, its direct application isdifficult to utilize the physical knowledge used in the simulation. This paperproposes a method that uses machine learning to interpolate future weather inmountainous regions using forecast data from surrounding plains and pastobserved data to improve weather forecasts in mountainous regions. We focus onmountainous regions in Japan and predict temperature and precipitation mainlyusing LightGBM as a machine learning model. Despite the use of a small dataset,through feature engineering and model tuning, our method partially achievesimprovements in the RMSE with significantly less training time.</description><author>Kazuma Iwase, Tomoyuki Takenawa</author><pubDate>Tue, 16 Jan 2024 09:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13983v2</guid></item><item><title>Enhancing Wind Speed and Wind Power Forecasting Using Shape-Wise Feature Engineering: A Novel Approach for Improved Accuracy and Robustness</title><link>http://arxiv.org/abs/2401.08233v1</link><description>Accurate prediction of wind speed and power is vital for enhancing theefficiency of wind energy systems. Numerous solutions have been implemented todate, demonstrating their potential to improve forecasting. Among these, deeplearning is perceived as a revolutionary approach in the field. However,despite their effectiveness, the noise present in the collected data remains asignificant challenge. This noise has the potential to diminish the performanceof these algorithms, leading to inaccurate predictions. In response to this,this study explores a novel feature engineering approach. This approachinvolves altering the data input shape in both Convolutional NeuralNetwork-Long Short-Term Memory (CNN-LSTM) and Autoregressive models for variousforecasting horizons. The results reveal substantial enhancements in modelresilience against noise resulting from step increases in data. The approachcould achieve an impressive 83% accuracy in predicting unseen data up to the24th steps. Furthermore, this method consistently provides high accuracy forshort, mid, and long-term forecasts, outperforming the performance ofindividual models. These findings pave the way for further research on noisereduction strategies at different forecasting horizons through shape-wisefeature engineering.</description><author>Mulomba Mukendi Christian, Yun Seon Kim, Hyebong Choi, Jaeyoung Lee, SongHee You</author><pubDate>Tue, 16 Jan 2024 09:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08233v1</guid></item><item><title>Multi-scale 2D Temporal Map Diffusion Models for Natural Language Video Localization</title><link>http://arxiv.org/abs/2401.08232v1</link><description>Natural Language Video Localization (NLVL), grounding phrases from naturallanguage descriptions to corresponding video segments, is a complex yetcritical task in video understanding. Despite ongoing advancements, manyexisting solutions lack the capability to globally capture temporal dynamics ofthe video data. In this study, we present a novel approach to NLVL that aims toaddress this issue. Our method involves the direct generation of a global 2Dtemporal map via a conditional denoising diffusion process, based on the inputvideo and language query. The main challenges are the inherent sparsity anddiscontinuity of a 2D temporal map in devising the diffusion decoder. Toaddress these challenges, we introduce a multi-scale technique and develop aninnovative diffusion decoder. Our approach effectively encapsulates theinteraction between the query and video data across various time scales.Experiments on the Charades and DiDeMo datasets underscore the potency of ourdesign.</description><author>Chongzhi Zhang, Mingyuan Zhang, Zhiyang Teng, Jiayi Li, Xizhou Zhu, Lewei Lu, Ziwei Liu, Aixin Sun</author><pubDate>Tue, 16 Jan 2024 09:33:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08232v1</guid></item><item><title>Attention, Distillation, and Tabularization: Towards Practical Neural Network-Based Prefetching</title><link>http://arxiv.org/abs/2401.06362v2</link><description>Attention-based Neural Networks (NN) have demonstrated their effectiveness inaccurate memory access prediction, an essential step in data prefetching.However, the substantial computational overheads associated with these modelsresult in high inference latency, limiting their feasibility as practicalprefetchers. To close the gap, we propose a new approach based ontabularization that significantly reduces model complexity and inferencelatency without sacrificing prediction accuracy. Our novel tabularizationmethodology takes as input a distilled, yet highly accurate attention-basedmodel for memory access prediction and efficiently converts its expensivematrix multiplications into a hierarchy of fast table lookups. As an exemplarof the above approach, we develop DART, a prefetcher comprised of a simplehierarchy of tables. With a modest 0.09 drop in F1-score, DART reduces 99.99%of arithmetic operations from the large attention-based model and 91.83% fromthe distilled model. DART accelerates the large model inference by 170x and thedistilled model by 9.4x. DART has comparable latency and storage costs asstate-of-the-art rule-based prefetcher BO but surpasses it by 6.1% in IPCimprovement. DART outperforms state-of-the-art NN-based prefetchers TransFetchby 33.1% and Voyager by 37.2% in terms of IPC improvement, primarily due to itslow prefetching latency.</description><author>Pengmiao Zhang, Neelesh Gupta, Rajgopal Kannan, Viktor K. Prasanna</author><pubDate>Tue, 16 Jan 2024 09:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06362v2</guid></item><item><title>Efficient and Mathematically Robust Operations for Certified Neural Networks Inference</title><link>http://arxiv.org/abs/2401.08225v1</link><description>In recent years, machine learning (ML) and neural networks (NNs) have gainedwidespread use and attention across various domains, particularly intransportation for achieving autonomy, including the emergence of flying taxisfor urban air mobility (UAM). However, concerns about certification have comeup, compelling the development of standardized processes encompassing theentire ML and NN pipeline. This paper delves into the inference stage and therequisite hardware, highlighting the challenges associated with IEEE 754floating-point arithmetic and proposing alternative number representations. Byevaluating diverse summation and dot product algorithms, we aim to mitigateissues related to non-associativity. Additionally, our exploration offixed-point arithmetic reveals its advantages over floating-point methods,demonstrating significant hardware efficiencies. Employing an empiricalapproach, we ascertain the optimal bit-width necessary to attain an acceptablelevel of accuracy, considering the inherent complexity of bit-widthoptimization.</description><author>Fabien Geyer, Johannes Freitag, Tobias Schulz, Sascha Uhrig</author><pubDate>Tue, 16 Jan 2024 09:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08225v1</guid></item><item><title>Differentially Private Estimation of CATE in Adaptive Experiment</title><link>http://arxiv.org/abs/2401.08224v1</link><description>Adaptive experiment is widely adopted to estimate conditional averagetreatment effect (CATE) in clinical trials and many other scenarios. While theprimary goal in experiment is to maximize estimation accuracy, due to theimperative of social welfare, it's also crucial to provide treatment withsuperior outcomes to patients, which is measured by regret in contextual banditframework. These two objectives often lead to contrast optimal allocationmechanism. Furthermore, privacy concerns arise in clinical scenarios containingsensitive data like patients health records. Therefore, it's essential for thetreatment allocation mechanism to incorporate robust privacy protectionmeasures. In this paper, we investigate the tradeoff between loss of socialwelfare and statistical power in contextual bandit experiment. We propose amatched upper and lower bound for the multi-objective optimization problem, andthen adopt the concept of Pareto optimality to mathematically characterize theoptimality condition. Furthermore, we propose differentially private algorithmswhich still matches the lower bound, showing that privacy is "almost free".Additionally, we derive the asymptotic normality of the estimator, which isessential in statistical inference and hypothesis testing.</description><author>Jiachun Li, David Simchi-Levi, Kaining Shi</author><pubDate>Tue, 16 Jan 2024 09:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08224v1</guid></item><item><title>Towards Causal Relationship in Indefinite Data: Baseline Model and New Datasets</title><link>http://arxiv.org/abs/2401.08221v1</link><description>Integrating deep learning and causal discovery has encouraged us to spot thatlearning causal structures and representations in dialogue and video is full ofchallenges. We defined These data forms as "Indefinite Data", characterized bymulti-structure data and multi-value representations. Unlike existing adaptabledata forms, Indefinite Data still faces gaps in datasets and methods. Toaddress the dataset gap, we release two high-quality datasets - Causalogue andCausaction, containing text dialogue samples and video action samples withcausal annotations respectively. Moreover, the method gap arises from thecoexistence of multi-structure data and multi-value representations, breakingthe assumptions of all current methods and rendering them infeasible onIndefinite Data. To this end, we propose a probabilistic framework as abaseline, incorporating three designed highlights for this gap: 1) establishingCausation Condition of representations using the independence of noise termsunder non-fixed causal structures, 2) treating causal strength as a latentvariable and measuring the reconstruction loss in the correlation space, and 3)estimating the effects of latent confounders. These highpoints make theprobabilistic model capable of overcoming challenges brought by the coexistenceof multi-structure data and multi-value representations and pave the way forthe extension of latent confounders. Comprehensive experiments have evaluatedbaseline results of causal structures, causal representations, and confoundingdisentanglement.</description><author>Hang Chen, Xinyu Yang, Keqing Du</author><pubDate>Tue, 16 Jan 2024 09:15:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08221v1</guid></item><item><title>StemGen: A music generation model that listens</title><link>http://arxiv.org/abs/2312.08723v2</link><description>End-to-end generation of musical audio using deep learning techniques hasseen an explosion of activity recently. However, most models concentrate ongenerating fully mixed music in response to abstract conditioning information.In this work, we present an alternative paradigm for producing music generationmodels that can listen and respond to musical context. We describe how such amodel can be constructed using a non-autoregressive, transformer-based modelarchitecture and present a number of novel architectural and samplingimprovements. We train the described architecture on both an open-source and aproprietary dataset. We evaluate the produced models using standard qualitymetrics and a new approach based on music information retrieval descriptors.The resulting model reaches the audio quality of state-of-the-arttext-conditioned models, as well as exhibiting strong musical coherence withits context.</description><author>Julian D. Parker, Janne Spijkervet, Katerina Kosta, Furkan Yesiler, Boris Kuznetsov, Ju-Chiang Wang, Matt Avent, Jitong Chen, Duc Le</author><pubDate>Tue, 16 Jan 2024 09:15:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08723v2</guid></item><item><title>Learning a Structural Causal Model for Intuition Reasoning in Conversation</title><link>http://arxiv.org/abs/2305.17727v2</link><description>Reasoning, a crucial aspect of NLP research, has not been adequatelyaddressed by prevailing models including Large Language Model. Conversationreasoning, as a critical component of it, remains largely unexplored due to theabsence of a well-designed cognitive model. In this paper, inspired byintuition theory on conversation cognition, we develop a conversation cognitivemodel (CCM) that explains how each utterance receives and activates channels ofinformation recursively. Besides, we algebraically transformed CCM into astructural causal model (SCM) under some mild assumptions, rendering itcompatible with various causal discovery methods. We further propose aprobabilistic implementation of the SCM for utterance-level relation reasoning.By leveraging variational inference, it explores substitutes for implicitcauses, addresses the issue of their unobservability, and reconstructs thecausal representations of utterances through the evidence lower bounds.Moreover, we constructed synthetic and simulated datasets incorporatingimplicit causes and complete cause labels, alleviating the current situationwhere all available datasets are implicit-causes-agnostic. Extensiveexperiments demonstrate that our proposed method significantly outperformsexisting methods on synthetic, simulated, and real-world datasets. Finally, weanalyze the performance of CCM under latent confounders and propose theoreticalideas for addressing this currently unresolved issue.</description><author>Hang Chen, Bingyu Liao, Jing Luo, Wenjing Zhu, Xinyu Yang</author><pubDate>Tue, 16 Jan 2024 09:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17727v2</guid></item><item><title>Towards Efficient and Certified Recovery from Poisoning Attacks in Federated Learning</title><link>http://arxiv.org/abs/2401.08216v1</link><description>Federated learning (FL) is vulnerable to poisoning attacks, where maliciousclients manipulate their updates to affect the global model. Although variousmethods exist for detecting those clients in FL, identifying malicious clientsrequires sufficient model updates, and hence by the time malicious clients aredetected, FL models have been already poisoned. Thus, a method is needed torecover an accurate global model after malicious clients are identified.Current recovery methods rely on (i) all historical information fromparticipating FL clients and (ii) the initial model unaffected by the maliciousclients, leading to a high demand for storage and computational resources. Inthis paper, we show that highly effective recovery can still be achieved basedon (i) selective historical information rather than all historical informationand (ii) a historical model that has not been significantly affected bymalicious clients rather than the initial model. In this scenario, whilemaintaining comparable recovery performance, we can accelerate the recoveryspeed and decrease memory consumption. Following this concept, we introduceCrab, an efficient and certified recovery method, which relies on selectiveinformation storage and adaptive model rollback. Theoretically, we demonstratethat the difference between the global model recovered by Crab and the onerecovered by train-from-scratch can be bounded under certain assumptions. Ourempirical evaluation, conducted across three datasets over multiple machinelearning models, and a variety of untargeted and targeted poisoning attacksreveals that Crab is both accurate and efficient, and consistently outperformsprevious approaches in terms of both recovery speed and memory consumption.</description><author>Yu Jiang, Jiyuan Shen, Ziyao Liu, Chee Wei Tan, Kwok-Yan Lam</author><pubDate>Tue, 16 Jan 2024 09:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08216v1</guid></item><item><title>DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image Generation using Limited Data</title><link>http://arxiv.org/abs/2306.14153v4</link><description>Denoising diffusion probabilistic models (DDPMs) have been proven capable ofsynthesizing high-quality images with remarkable diversity when trained onlarge amounts of data. Typical diffusion models and modern large-scaleconditional generative models like text-to-image generative models arevulnerable to overfitting when fine-tuned on extremely limited data. Existingworks have explored subject-driven generation using a reference set containinga few images. However, few prior works explore DDPM-based domain-drivengeneration, which aims to learn the common features of target domains whilemaintaining diversity. This paper proposes a novel DomainStudio approach toadapt DDPMs pre-trained on large-scale source datasets to target domains usinglimited data. It is designed to keep the diversity of subjects provided bysource domains and get high-quality and diverse adapted samples in targetdomains. We propose to keep the relative distances between adapted samples toachieve considerable generation diversity. In addition, we further enhance thelearning of high-frequency details for better generation quality. Our approachis compatible with both unconditional and conditional diffusion models. Thiswork makes the first attempt to realize unconditional few-shot image generationwith diffusion models, achieving better quality and greater diversity thancurrent state-of-the-art GAN-based approaches. Moreover, this work alsosignificantly relieves overfitting for conditional generation and realizeshigh-quality domain-driven generation, further expanding the applicablescenarios of modern large-scale text-to-image models.</description><author>Jingyuan Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan</author><pubDate>Tue, 16 Jan 2024 08:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14153v4</guid></item><item><title>Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and Usage in Digital Communication</title><link>http://arxiv.org/abs/2401.08212v1</link><description>Leveraging Large Multimodal Models (LMMs) to simulate human behaviors whenprocessing multimodal information, especially in the context of social media,has garnered immense interest due to its broad potential and far-reachingimplications. Emojis, as one of the most unique aspects of digitalcommunication, are pivotal in enriching and often clarifying the emotional andtonal dimensions. Yet, there is a notable gap in understanding how theseadvanced models, such as GPT-4V, interpret and employ emojis in the nuancedcontext of online interaction. This study intends to bridge this gap byexamining the behavior of GPT-4V in replicating human-like use of emojis. Thefindings reveal a discernible discrepancy between human and GPT-4V behaviors,likely due to the subjective nature of human interpretation and the limitationsof GPT-4V's English-centric training, suggesting cultural biases and inadequaterepresentation of non-English cultures.</description><author>Hanjia Lyu, Weihong Qi, Zhongyu Wei, Jiebo Luo</author><pubDate>Tue, 16 Jan 2024 08:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08212v1</guid></item><item><title>ModelNet-O: A Large-Scale Synthetic Dataset for Occlusion-Aware Point Cloud Classification</title><link>http://arxiv.org/abs/2401.08210v1</link><description>Recently, 3D point cloud classification has made significant progress withthe help of many datasets. However, these datasets do not reflect theincomplete nature of real-world point clouds caused by occlusion, which limitsthe practical application of current methods. To bridge this gap, we proposeModelNet-O, a large-scale synthetic dataset of 123,041 samples that emulatereal-world point clouds with self-occlusion caused by scanning from monocularcameras. ModelNet-O is 10 times larger than existing datasets and offers morechallenging cases to evaluate the robustness of existing methods. Ourobservation on ModelNet-O reveals that well-designed sparse structures canpreserve structural information of point clouds under occlusion, motivating usto propose a robust point cloud processing method that leverages a criticalpoint sampling (CPS) strategy in a multi-level manner. We term our methodPointMLS. Through extensive experiments, we demonstrate that our PointMLSachieves state-of-the-art results on ModelNet-O and competitive results onregular datasets, and it is robust and effective. More experiments alsodemonstrate the robustness and effectiveness of PointMLS.</description><author>Zhongbin Fang, Xia Li, Xiangtai Li, Shen Zhao, Mengyuan Liu</author><pubDate>Tue, 16 Jan 2024 08:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08210v1</guid></item><item><title>Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary</title><link>http://arxiv.org/abs/2401.08209v1</link><description>Single Image Super-Resolution is a classic computer vision problem thatinvolves estimating high-resolution (HR) images from low-resolution (LR) ones.Although deep neural networks (DNNs), especially Transformers forsuper-resolution, have seen significant advancements in recent years,challenges still remain, particularly in limited receptive field caused bywindow-based self-attention. To address these issues, we introduce a group ofauxiliary Adapeive Token Dictionary to SR Transformer and establish an ATD-SRmethod. The introduced token dictionary could learn prior information fromtraining data and adapt the learned prior to specific testing image through anadaptive refinement step. The refinement strategy could not only provide globalinformation to all input tokens but also group image tokens into categories.Based on category partitions, we further propose a category-basedself-attention mechanism designed to leverage distant but similar tokens forenhancing input features. The experimental results show that our methodachieves the best performance on various single image super-resolutionbenchmarks.</description><author>Leheng Zhang, Yawei Li, Xingyu Zhou, Xiaorui Zhao, Shuhang Gu</author><pubDate>Tue, 16 Jan 2024 08:50:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08209v1</guid></item><item><title>FUSC: Fetal Ultrasound Semantic Clustering of Second Trimester Scans Using Deep Self-supervised Learning</title><link>http://arxiv.org/abs/2310.12600v2</link><description>Ultrasound is the primary imaging modality in clinical practice duringpregnancy. More than 140M fetuses are born yearly, resulting in numerous scans.The availability of a large volume of fetal ultrasound scans presents theopportunity to train robust machine learning models. However, the abundance ofscans also has its challenges, as manual labeling of each image is needed forsupervised methods. Labeling is typically labor-intensive and requiresexpertise to annotate the images accurately. This study presents anunsupervised approach for automatically clustering ultrasound images into alarge range of fetal views, reducing or eliminating the need for manuallabeling. Our Fetal Ultrasound Semantic Clustering (FUSC) method is developedusing a large dataset of 88,063 images and further evaluated on an additionalunseen dataset of 8,187 images achieving over 92% clustering purity. The resultof our investigation hold the potential to significantly impact the field offetal ultrasound imaging and pave the way for more advanced automated labelingsolutions. Finally, we make the code and the experimental setup publiclyavailable to help advance the field.</description><author>Hussain Alasmawi, Leanne Bricker, Mohammad Yaqub</author><pubDate>Tue, 16 Jan 2024 08:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12600v2</guid></item><item><title>Generative Multi-Modal Knowledge Retrieval with Large Language Models</title><link>http://arxiv.org/abs/2401.08206v1</link><description>Knowledge retrieval with multi-modal queries plays a crucial role insupporting knowledge-intensive multi-modal applications. However, existingmethods face challenges in terms of their effectiveness and trainingefficiency, especially when it comes to training and integrating multipleretrievers to handle multi-modal queries. In this paper, we propose aninnovative end-to-end generative framework for multi-modal knowledge retrieval.Our framework takes advantage of the fact that large language models (LLMs) caneffectively serve as virtual knowledge bases, even when trained with limiteddata. We retrieve knowledge via a two-step process: 1) generating knowledgeclues related to the queries, and 2) obtaining the relevant document bysearching databases using the knowledge clue. In particular, we first introducean object-aware prefix-tuning technique to guide multi-grained visual learning.Then, we align multi-grained visual features into the textual feature space ofthe LLM, employing the LLM to capture cross-modal interactions. Subsequently,we construct instruction data with a unified format for model training.Finally, we propose the knowledge-guided generation strategy to impose priorconstraints in the decoding steps, thereby promoting the generation ofdistinctive knowledge clues. Through experiments conducted on three benchmarks,we demonstrate significant improvements ranging from 3.0% to 14.6% across allevaluation metrics when compared to strong baselines.</description><author>Xinwei Long, Jiali Zeng, Fandong Meng, Zhiyuan Ma, Kaiyan Zhang, Bowen Zhou, Jie Zhou</author><pubDate>Tue, 16 Jan 2024 08:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08206v1</guid></item><item><title>Adaptive Confidence Multi-View Hashing for Multimedia Retrieval</title><link>http://arxiv.org/abs/2312.07327v2</link><description>The multi-view hash method converts heterogeneous data from multiple viewsinto binary hash codes, which is one of the critical technologies in multimediaretrieval. However, the current methods mainly explore the complementarityamong multiple views while lacking confidence learning and fusion. Moreover, inpractical application scenarios, the single-view data contain redundant noise.To conduct the confidence learning and eliminate unnecessary noise, we proposea novel Adaptive Confidence Multi-View Hashing (ACMVH) method. First, aconfidence network is developed to extract useful information from varioussingle-view features and remove noise information. Furthermore, an adaptiveconfidence multi-view network is employed to measure the confidence of eachview and then fuse multi-view features through a weighted summation. Lastly, adilation network is designed to further enhance the feature representation ofthe fused features. To the best of our knowledge, we pioneer the application ofconfidence learning into the field of multimedia retrieval. Extensiveexperiments on two public datasets show that the proposed ACMVH performs betterthan state-of-the-art methods (maximum increase of 3.24%). The source code isavailable at https://github.com/HackerHyper/ACMVH.</description><author>Jian Zhu, Yu Cui, Zhangmin Huang, Xingyu Li, Lei Liu, Lingfang Zeng, Li-Rong Dai</author><pubDate>Tue, 16 Jan 2024 08:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07327v2</guid></item><item><title>FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning</title><link>http://arxiv.org/abs/2312.04432v2</link><description>Federated learning (FL) is a collaborative learning paradigm allowingmultiple clients to jointly train a model without sharing their training data.However, FL is susceptible to poisoning attacks, in which the adversary injectsmanipulated model updates into the federated model aggregation process tocorrupt or destroy predictions (untargeted poisoning) or implant hiddenfunctionalities (targeted poisoning or backdoors). Existing defenses againstpoisoning attacks in FL have several limitations, such as relying on specificassumptions about attack types and strategies or data distributions or notsufficiently robust against advanced injection techniques and strategies andsimultaneously maintaining the utility of the aggregated model. To address thedeficiencies of existing defenses, we take a generic and completely differentapproach to detect poisoning (targeted and untargeted) attacks. We presentFreqFed, a novel aggregation mechanism that transforms the model updates (i.e.,weights) into the frequency domain, where we can identify the core frequencycomponents that inherit sufficient information about weights. This allows us toeffectively filter out malicious updates during local training on the clients,regardless of attack types, strategies, and clients' data distributions. Weextensively evaluate the efficiency and effectiveness of FreqFed in differentapplication domains, including image classification, word prediction, IoTintrusion detection, and speech recognition. We demonstrate that FreqFed canmitigate poisoning attacks effectively with a negligible impact on the utilityof the aggregated model.</description><author>Hossein Fereidooni, Alessandro Pegoraro, Phillip Rieger, Alexandra Dmitrienko, Ahmad-Reza Sadeghi</author><pubDate>Tue, 16 Jan 2024 08:40:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04432v2</guid></item><item><title>How do Minimum-Norm Shallow Denoisers Look in Function Space?</title><link>http://arxiv.org/abs/2311.06748v2</link><description>Neural network (NN) denoisers are an essential building block in many commontasks, ranging from image reconstruction to image generation. However, thesuccess of these models is not well understood from a theoretical perspective.In this paper, we aim to characterize the functions realized by shallow ReLU NNdenoisers -- in the common theoretical setting of interpolation (i.e., zerotraining loss) with a minimal representation cost (i.e., minimal $\ell^2$ normweights). First, for univariate data, we derive a closed form for the NNdenoiser function, find it is contractive toward the clean data points, andprove it generalizes better than the empirical MMSE estimator at a low noiselevel. Next, for multivariate data, we find the NN denoiser functions in aclosed form under various geometric assumptions on the training data: datacontained in a low-dimensional subspace, data contained in a union of one-sidedrays, or several types of simplexes. These functions decompose into a sum ofsimple rank-one piecewise linear interpolations aligned with edges and/or facesconnecting training samples. We empirically verify this alignment phenomenon onsynthetic data and real images.</description><author>Chen Zeno, Greg Ongie, Yaniv Blumenfeld, Nir Weinberger, Daniel Soudry</author><pubDate>Tue, 16 Jan 2024 08:35:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06748v2</guid></item><item><title>Tiny-VBF: Resource-Efficient Vision Transformer based Lightweight Beamformer for Ultrasound Single-Angle Plane Wave Imaging</title><link>http://arxiv.org/abs/2311.12082v2</link><description>Accelerating compute intensive non-real-time beam-forming algorithms inultrasound imaging using deep learning architectures has been gaining momentumin the recent past. Nonetheless, the complexity of the state-of-the-art deeplearning techniques poses challenges for deployment on resource-constrainededge devices. In this work, we propose a novel vision transformer based tinybeamformer (Tiny-VBF), which works on the raw radio-frequency channel dataacquired through single-angle plane wave insonification. The output of ourTiny-VBF provides fast envelope detection requiring very low frame rate, i.e.0.34 GOPs/Frame for a frame size of 368 x 128 in comparison to thestate-of-the-art deep learning models. It also exhibited an 8% increase incontrast and gains of 5% and 33% in axial and lateral resolution respectivelywhen compared to Tiny-CNN on in-vitro dataset. Additionally, our model showed a4.2% increase in contrast and gains of 4% and 20% in axial and lateralresolution respectively when compared against conventional Delay-and-Sum (DAS)beamformer. We further propose an accelerator architecture and implement ourTiny-VBF model on a Zynq UltraScale+ MPSoC ZCU104 FPGA using a hybridquantization scheme with 50% less resource consumption compared to thefloating-point implementation, while preserving the image quality.</description><author>Abdul Rahoof, Vivek Chaturvedi, Mahesh Raveendranatha Panicker, Muhammad Shafique</author><pubDate>Tue, 16 Jan 2024 08:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12082v2</guid></item><item><title>Translatotron 3: Speech to Speech Translation with Monolingual Data</title><link>http://arxiv.org/abs/2305.17547v3</link><description>This paper presents Translatotron 3, a novel approach to unsupervised directspeech-to-speech translation from monolingual speech-text datasets by combiningmasked autoencoder, unsupervised embedding mapping, and back-translation.Experimental results in speech-to-speech translation tasks between Spanish andEnglish show that Translatotron 3 outperforms a baseline cascade system,reporting $18.14$ BLEU points improvement on the synthesizedUnpaired-Conversational dataset. In contrast to supervised approaches thatnecessitate real paired data, or specialized modeling to replicatepara-/non-linguistic information such as pauses, speaking rates, and speakeridentity, Translatotron 3 showcases its capability to retain it. Audio samplescan be found at http://google-research.github.io/lingvo-lab/translatotron3</description><author>Eliya Nachmani, Alon Levkovitch, Yifan Ding, Chulayuth Asawaroengchai, Heiga Zen, Michelle Tadmor Ramanovich</author><pubDate>Tue, 16 Jan 2024 08:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17547v3</guid></item><item><title>Matrix Completion with Hypergraphs:Sharp Thresholds and Efficient Algorithms</title><link>http://arxiv.org/abs/2401.08197v1</link><description>This paper considers the problem of completing a rating matrix based onsub-sampled matrix entries as well as observed social graphs and hypergraphs.We show that there exists a \emph{sharp threshold} on the sample probabilityfor the task of exactly completing the rating matrix -- the task is achievablewhen the sample probability is above the threshold, and is impossible otherwise-- demonstrating a phase transition phenomenon. The threshold can be expressedas a function of the ``quality'' of hypergraphs, enabling us to \emph{quantify}the amount of reduction in sample probability due to the exploitation ofhypergraphs. This also highlights the usefulness of hypergraphs in the matrixcompletion problem. En route to discovering the sharp threshold, we develop acomputationally efficient matrix completion algorithm that effectively exploitsthe observed graphs and hypergraphs. Theoretical analyses show that ouralgorithm succeeds with high probability as long as the sample probabilityexceeds the aforementioned threshold, and this theoretical result is furthervalidated by synthetic experiments. Moreover, our experiments on a real socialnetwork dataset (with both graphs and hypergraphs) show that our algorithmoutperforms other state-of-the-art matrix completion algorithms.</description><author>Zhongtian Ma, Qiaosheng Zhang, Zhen Wang</author><pubDate>Tue, 16 Jan 2024 08:25:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08197v1</guid></item><item><title>ZeroShape: Regression-based Zero-shot Shape Reconstruction</title><link>http://arxiv.org/abs/2312.14198v2</link><description>We study the problem of single-image zero-shot 3D shape reconstruction.Recent works learn zero-shot shape reconstruction through generative modelingof 3D assets, but these models are computationally expensive at train andinference time. In contrast, the traditional approach to this problem isregression-based, where deterministic models are trained to directly regressthe object shape. Such regression methods possess much higher computationalefficiency than generative methods. This raises a natural question: isgenerative modeling necessary for high performance, or conversely, areregression-based approaches still competitive? To answer this, we design astrong regression-based model, called ZeroShape, based on the convergingfindings in this field and a novel insight. We also curate a large real-worldevaluation benchmark, with objects from three different real-world 3D datasets.This evaluation benchmark is more diverse and an order of magnitude larger thanwhat prior works use to quantitatively evaluate their models, aiming atreducing the evaluation variance in our field. We show that ZeroShape not onlyachieves superior performance over state-of-the-art methods, but alsodemonstrates significantly higher computational and data efficiency.</description><author>Zixuan Huang, Stefan Stojanov, Anh Thai, Varun Jampani, James M. Rehg</author><pubDate>Tue, 16 Jan 2024 08:18:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14198v2</guid></item><item><title>End-to-End Optimized Image Compression with the Frequency-Oriented Transform</title><link>http://arxiv.org/abs/2401.08194v1</link><description>Image compression constitutes a significant challenge amidst the era ofinformation explosion. Recent studies employing deep learning methods havedemonstrated the superior performance of learning-based image compressionmethods over traditional codecs. However, an inherent challenge associated withthese methods lies in their lack of interpretability. Following an analysis ofthe varying degrees of compression degradation across different frequencybands, we propose the end-to-end optimized image compression model facilitatedby the frequency-oriented transform. The proposed end-to-end image compressionmodel consists of four components: spatial sampling, frequency-orientedtransform, entropy estimation, and frequency-aware fusion. Thefrequency-oriented transform separates the original image signal into distinctfrequency bands, aligning with the human-interpretable concept. Leveraging thenon-overlapping hypothesis, the model enables scalable coding through theselective transmission of arbitrary frequency components. Extensive experimentsare conducted to demonstrate that our model outperforms all traditional codecsincluding next-generation standard H.266/VVC on MS-SSIM metric. Moreover,visual analysis tasks (i.e., object detection and semantic segmentation) areconducted to verify the proposed compression method could preserve semanticfidelity besides signal-level precision.</description><author>Yuefeng Zhang, Kai Lin</author><pubDate>Tue, 16 Jan 2024 08:16:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08194v1</guid></item><item><title>"Paraphrasing The Original Text" Makes High Accuracy Long-Context QA</title><link>http://arxiv.org/abs/2312.11193v7</link><description>Most open-source generative language models currently have a context windowof no more than 4k, limiting their ability when facing long text. Many previousefforts have tried to extend the context window of models, but their actualeffects have been found to be very limited. To address this issue, wetheoretically analyze the effectiveness of the long-context training data andfind that long-context training requires "effective" data rather than simply"long" data, which is rarely noticed in previous studies. Thus, we proposeadding "original text paraphrasing" to enhance the effectiveness of the data.The model trained on our re-fined dataset obtains excellent long-contextcapabilities and achieves state-of-the-art accuracy on multi-document retrievaland QA tasks among models of comparable scales. The model and training datahave been made available onHuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) andWiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).</description><author>Yijiong Yu</author><pubDate>Tue, 16 Jan 2024 08:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11193v7</guid></item><item><title>Learning Explicit Contact for Implicit Reconstruction of Hand-held Objects from Monocular Images</title><link>http://arxiv.org/abs/2305.20089v2</link><description>Reconstructing hand-held objects from monocular RGB images is an appealingyet challenging task. In this task, contacts between hands and objects provideimportant cues for recovering the 3D geometry of the hand-held objects. Thoughrecent works have employed implicit functions to achieve impressive progress,they ignore formulating contacts in their frameworks, which results inproducing less realistic object meshes. In this work, we explore how to modelcontacts in an explicit way to benefit the implicit reconstruction of hand-heldobjects. Our method consists of two components: explicit contact prediction andimplicit shape reconstruction. In the first part, we propose a new subtask ofdirectly estimating 3D hand-object contacts from a single image. The part-leveland vertex-level graph-based transformers are cascaded and jointly learned in acoarse-to-fine manner for more accurate contact probabilities. In the secondpart, we introduce a novel method to diffuse estimated contact states from thehand mesh surface to nearby 3D space and leverage diffused contactprobabilities to construct the implicit neural representation for themanipulated object. Benefiting from estimating the interaction patterns betweenthe hand and the object, our method can reconstruct more realistic objectmeshes, especially for object parts that are in contact with hands. Extensiveexperiments on challenging benchmarks show that the proposed method outperformsthe current state of the arts by a great margin. Our code is publicly availableat https://junxinghu.github.io/projects/hoi.html.</description><author>Junxing Hu, Hongwen Zhang, Zerui Chen, Mengcheng Li, Yunlong Wang, Yebin Liu, Zhenan Sun</author><pubDate>Tue, 16 Jan 2024 08:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20089v2</guid></item><item><title>Self-Supervised Models of Speech Infer Universal Articulatory Kinematics</title><link>http://arxiv.org/abs/2310.10788v2</link><description>Self-Supervised Learning (SSL) based models of speech have shown remarkableperformance on a range of downstream tasks. These state-of-the-art models haveremained blackboxes, but many recent studies have begun "probing" models likeHuBERT, to correlate their internal representations to different aspects ofspeech. In this paper, we show "inference of articulatory kinematics" asfundamental property of SSL models, i.e., the ability of these models totransform acoustics into the causal articulatory dynamics underlying the speechsignal. We also show that this abstraction is largely overlapping across thelanguage of the data used to train the model, with preference to the languagewith similar phonological system. Furthermore, we show that with simple affinetransformations, Acoustic-to-Articulatory inversion (AAI) is transferrableacross speakers, even across genders, languages, and dialects, showing thegeneralizability of this property. Together, these results shed new light onthe internals of SSL models that are critical to their superior performance,and open up new avenues into language-agnostic universal models for speechengineering, that are interpretable and grounded in speech science.</description><author>Cheol Jun Cho, Abdelrahman Mohamed, Alan W Black, Gopala K. Anumanchipalli</author><pubDate>Tue, 16 Jan 2024 08:09:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10788v2</guid></item><item><title>MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline</title><link>http://arxiv.org/abs/2401.08190v1</link><description>Large language models (LLMs) have seen considerable advancements in naturallanguage understanding tasks, yet there remains a gap to bridge beforeattaining true artificial general intelligence, especially concerningshortcomings in mathematical reasoning capabilities. We postulate that theinherent nature of LLM training, which focuses on predicting probabilities ofnext token, presents challenges in effectively modeling mathematical reasoningthat demands exact calculations, both from data-driven and theoreticalstandpoints. In this paper, we address this challenge by enriching the datalandscape and introducing a novel math dataset, enhanced with a capability toutilize a Python code interpreter. This dataset is derived from GSM8K and MATHand has been further refined through a combination of GPT-4 annotations, humanreview, and self-training processes, where the errors in the original GSM8Ktraining set have been fixed. Additionally, we propose a tentative, easilyreplicable protocol for the fine-tuning of math-specific LLMs, which has led toa significant improvement in the performance of a 7B-parameter LLM on the GSM8Kand MATH datasets. We are committed to advancing the field of mathematicalreasoning in LLMs and, to that end, we have made the model checkpoints and willmake the dataset publicly available. We hope this will facilitate furtherresearch and development within the community.</description><author>Minpeng Liao, Wei Luo, Chengxi Li, Jing Wu, Kai Fan</author><pubDate>Tue, 16 Jan 2024 08:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08190v1</guid></item><item><title>PRewrite: Prompt Rewriting with Reinforcement Learning</title><link>http://arxiv.org/abs/2401.08189v1</link><description>Prompt engineering is critical for the development of LLM-based applications.However, it is usually done manually in a "trial and error" fashion. Thismanual procedure can be time consuming, ineffective, and the generated promptsare, in a lot of cases, sub-optimal. Even for the prompts which seemingly workwell, there is always a lingering question: can the prompts be made better withfurther modifications? To address these questions, in this paper, we investigate prompt engineeringautomation. We consider a specific use case scenario in which developers/usershave drafted initial prompts, but lack the time/expertise to optimize them. Wepropose PRewrite, an automated tool to rewrite these drafts and to generatehighly effective new prompts. PRewrite is based on the Reinforcement Learning(RL) framework which allows for end-to-end optimization and our design allowsthe RL search to happen in a large action space. The automated tool leveragesmanually crafted prompts as starting points which makes the rewriting proceduremore guided and efficient. The generated prompts are human readable, andself-explanatory, unlike some of those in previous works. We conductedextensive experiments on diverse datasets and found that the prompts generatedwith this new method not only outperform professionally crafted prompts, butalso prompts generated with other previously proposed methods.</description><author>Weize Kong, Spurthi Amba Hombaiah, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky</author><pubDate>Tue, 16 Jan 2024 08:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08189v1</guid></item><item><title>Energy-Calibrated VAE with Test Time Free Lunch</title><link>http://arxiv.org/abs/2311.04071v3</link><description>In this paper, we propose a novel generative model that utilizes aconditional Energy-Based Model (EBM) for enhancing Variational Autoencoder(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often sufferfrom blurry generated samples due to the lack of a tailored training on thesamples generated in the generative direction. On the other hand, EBMs cangenerate high-quality samples but require expensive Markov Chain Monte Carlo(MCMC) sampling. To address these issues, we introduce a conditional EBM forcalibrating the generative direction of VAE during training, without requiringit for the generation at test time. In particular, we train EC-VAE upon boththe input data and the calibrated samples with adaptive weight to enhanceefficacy while avoiding MCMC sampling at test time. Furthermore, we extend thecalibration idea of EC-VAE to variational learning and normalizing flows, andapply EC-VAE to an additional application of zero-shot image restoration vianeural transport prior and range-null theory. We evaluate the proposed methodwith two applications, including image generation and zero-shot imagerestoration, and the experimental results show that our method achieves thestate-of-the-art performance over single-step non-adversarial generation. Ourcode is available at https://github.com/DJ-LYH/EC-VAE.</description><author>Yihong Luo, Siya Qiu, Xingjian Tao, Yujun Cai, Jing Tang</author><pubDate>Tue, 16 Jan 2024 08:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04071v3</guid></item></channel></rss>