<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivhot papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 23 Nov 2025 12:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting</title><link>http://arxiv.org/abs/2510.18874v1</link><description>Adapting language models (LMs) to new tasks via post-training carries therisk of degrading existing capabilities -- a phenomenon classically known ascatastrophic forgetting. In this paper, toward identifying guidelines formitigating this phenomenon, we systematically compare the forgetting patternsof two widely adopted post-training methods: supervised fine-tuning (SFT) andreinforcement learning (RL). Our experiments reveal a consistent trend acrossLM families (Llama, Qwen) and tasks (instruction following, general knowledge,and arithmetic reasoning): RL leads to less forgetting than SFT while achievingcomparable or higher target task performance. To investigate the cause for thisdifference, we consider a simplified setting in which the LM is modeled as amixture of two distributions, one corresponding to prior knowledge and theother to the target task. We identify that the mode-seeking nature of RL, whichstems from its use of on-policy data, enables keeping prior knowledge intactwhen learning the target task. We then verify this insight by demonstratingthat the use on-policy data underlies the robustness of RL to forgetting inpractical settings, as opposed to other algorithmic choices such as the KLregularization or advantage estimation. Lastly, as a practical implication, ourresults highlight the potential of mitigating forgetting using approximatelyon-policy data, which can be substantially more efficient to obtain than fullyon-policy data.</description><author>Howard Chen, Noam Razin, Karthik Narasimhan, Danqi Chen</author><pubDate>Tue, 21 Oct 2025 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18874v1</guid></item><item><title>DSI-Bench: A Benchmark for Dynamic Spatial Intelligence</title><link>http://arxiv.org/abs/2510.18873v1</link><description>Reasoning about dynamic spatial relationships is essential, as both observersand objects often move simultaneously. Although vision-language models (VLMs)and visual expertise models excel in 2D tasks and static scenarios, theirability to fully understand dynamic 3D scenarios remains limited. We introduceDynamic Spatial Intelligence and propose DSI-Bench, a benchmark with nearly1,000 dynamic videos and over 1,700 manually annotated questions covering ninedecoupled motion patterns of observers and objects. Spatially and temporallysymmetric designs reduce biases and enable systematic evaluation of models'reasoning about self-motion and object motion. Our evaluation of 14 VLMs andexpert models reveals key limitations: models often conflate observer andobject motion, exhibit semantic biases, and fail to accurately infer relativerelationships in dynamic scenarios. Our DSI-Bench provides valuable findingsand insights about the future development of general and expertise models withdynamic spatial intelligence.</description><author>Ziang Zhang, Zehan Wang, Guanghao Zhang, Weilong Dai, Yan Xia, Ziang Yan, Minjie Hong, Zhou Zhao</author><pubDate>Tue, 21 Oct 2025 17:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18873v1</guid></item><item><title>Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs</title><link>http://arxiv.org/abs/2510.13795v2</link><description>Fully open multimodal large language models (MLLMs) currently lag behindproprietary counterparts, primarily due to a significant gap in data qualityfor supervised fine-tuning (SFT). Existing open-source datasets are oftenplagued by widespread noise and a critical deficit in complex reasoning data,such as Chain-of-Thought (CoT), which hinders the development of advanced modelcapabilities. Addressing these challenges, our work makes three primarycontributions. First, we introduce Honey-Data-15M, a new SFT dataset comprisingapproximately 15 million QA pairs, processed through multiple cleaningtechniques and enhanced with a novel dual-level (short and long) CoT enrichmentstrategy. Second, we introduce HoneyPipe, the data curation pipeline, and itsunderlying framework DataStudio, providing the community with a transparent andadaptable methodology for data curation that moves beyond static datasetreleases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8Bmodel on Honey-Data-15M. Experiments show that Bee-8B establishes a newstate-of-the-art (SOTA) for fully open MLLMs, achieving performance that iscompetitive with, and in some cases surpasses, recent semi-open models such asInternVL3.5-8B. Our work delivers to the community a suite of foundationalresources, including: the Honey-Data-15M corpus; the full-stack suitecomprising HoneyPipe and DataStudio; training recipes; an evaluation harness;and the model weights. This effort demonstrates that a principled focus on dataquality is a key pathway to developing fully open MLLMs that are highlycompetitive with their semi-open counterparts.</description><author>Yi Zhang, Bolin Ni, Xin-Sheng Chen, Heng-Rui Zhang, Yongming Rao, Houwen Peng, Qinglin Lu, Han Hu, Meng-Hao Guo, Shi-Min Hu</author><pubDate>Tue, 21 Oct 2025 17:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.13795v2</guid></item><item><title>How Do LLMs Use Their Depth?</title><link>http://arxiv.org/abs/2510.18871v1</link><description>Growing evidence suggests that large language models do not use their depthuniformly, yet we still lack a fine-grained understanding of their layer-wiseprediction dynamics. In this paper, we trace the intermediate representationsof several open-weight models during inference and reveal a structured andnuanced use of depth. Specifically, we propose a "Guess-then-Refine" frameworkthat explains how LLMs internally structure their computations to makepredictions. We first show that the top-ranked predictions in early LLM layersare composed primarily of high-frequency tokens, which act as statisticalguesses proposed by the model early on due to the lack of appropriatecontextual information. As contextual information develops deeper into themodel, these initial guesses get refined into contextually appropriate tokens.Even high-frequency token predictions from early layers get refined &gt;70% of thetime, indicating that correct token prediction is not "one-and-done". We thengo beyond frequency-based prediction to examine the dynamic usage of layerdepth across three case studies. (i) Part-of-speech analysis shows thatfunction words are, on average, the earliest to be predicted correctly. (ii)Fact recall task analysis shows that, in a multi-token answer, the first tokenrequires more computational depth than the rest. (iii) Multiple-choice taskanalysis shows that the model identifies the format of the response within thefirst half of the layers, but finalizes its response only toward the end.Together, our results provide a detailed view of depth usage in LLMs, sheddinglight on the layer-by-layer computations that underlie successful predictionsand providing insights for future works to improve computational efficiency intransformer-based models.</description><author>Akshat Gupta, Jay Yeung, Gopala Anumanchipalli, Anna Ivanova</author><pubDate>Tue, 21 Oct 2025 17:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18871v1</guid></item><item><title>A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks</title><link>https://arxiv.org/abs/2510.19973v2</link><description>The path to higher network autonomy in 6G lies beyond the mere optimization of key performance indicators (KPIs). While KPIs have enabled automation gains under TM Forum Levels 1--3, they remain numerical abstractions that act only as proxies for the real essence of communication networks: seamless connectivity, fairness, adaptability, and resilience. True autonomy requires perceiving and reasoning over the network environment as it is. Such progress can be achieved through \emph{agentic AI}, where large language model (LLM)-powered agents perceive multimodal telemetry, reason with memory, negotiate across domains, and act via APIs to achieve multi-objective goals. However, deploying such agents introduces the challenge of cognitive biases inherited from human design, which can distort reasoning, negotiation, tool use, and actuation. Between neuroscience and AI, this paper provides a tutorial on a selection of well-known biases, including their taxonomy, definition, mathematical formulation, emergence in telecom systems and the commonly impacted agentic components. The tutorial also presents various mitigation strategies tailored to each type of bias. The article finally provides two practical use-cases, which tackle the emergence, impact and mitigation gain of some famous biases in 6G inter-slice and cross-domain management. In particular, anchor randomization, temporal decay and inflection bonus techniques are introduced to specifically address anchoring, temporal and confirmation biases. This avoids that agents stick to the initial high resource allocation proposal or decisions that are recent and/or confirming a prior hypothesis. By grounding decisions in a richer and fairer set of past experiences, the quality and bravery of the agentic agreements in the second use-case, for instance, are leading to $\times 5$ lower latency and around $40\%$ higher energy saving.</description><author>Hatim Chergui, Farhad Rezazadeh, Merouane Debbah, Christos Verikoukis</author><pubDate>Tue, 04 Nov 2025 10:36:29 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/abs/2510.19973v2</guid></item><item><title>LightMem: Lightweight and Efficient Memory-Augmented Generation</title><link>http://arxiv.org/abs/2510.18866v1</link><description>Despite their remarkable capabilities, Large Language Models (LLMs) struggleto effectively leverage historical interaction information in dynamic andcomplex environments. Memory systems enable LLMs to move beyond statelessinteractions by introducing persistent information storage, retrieval, andutilization mechanisms. However, existing memory systems often introducesubstantial time and computational overhead. To this end, we introduce a newmemory system called LightMem, which strikes a balance between the performanceand efficiency of memory systems. Inspired by the Atkinson-Shiffrin model ofhuman memory, LightMem organizes memory into three complementary stages. First,cognition-inspired sensory memory rapidly filters irrelevant informationthrough lightweight compression and groups information according to theirtopics. Next, topic-aware short-term memory consolidates these topic-basedgroups, organizing and summarizing content for more structured access. Finally,long-term memory with sleep-time update employs an offline procedure thatdecouples consolidation from online inference. Experiments on LongMemEval withGPT and Qwen backbones show that LightMem outperforms strong baselines inaccuracy (up to 10.9% gains) while reducing token usage by up to 117x, APIcalls by up to 159x, and runtime by over 12x. The code is available athttps://github.com/zjunlp/LightMem.</description><author>Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, Huajun Chen, Ningyu Zhang</author><pubDate>Tue, 21 Oct 2025 17:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18866v1</guid></item><item><title>Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration</title><link>http://arxiv.org/abs/2509.20648v2</link><description>Autonomous exploration in complex multi-agent reinforcement learning (MARL)with sparse rewards critically depends on providing agents with effectiveintrinsic motivation. While artificial curiosity offers a powerfulself-supervised signal, it often confuses environmental stochasticity withmeaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniformnovelty bias, treating all unexpected observations equally. However, peerbehavior novelty, which encode latent task dynamics, are often overlooked,resulting in suboptimal exploration in decentralized, communication-free MARLsettings. To this end, inspired by how human children adaptively calibratetheir own exploratory behaviors via observing peers, we propose a novelapproach to enhance multi-agent exploration. We introduce CERMIC, a principledframework that empowers agents to robustly filter noisy surprise signals andguide exploration by dynamically calibrating their intrinsic curiosity withinferred multi-agent context. Additionally, CERMIC generatestheoretically-grounded intrinsic rewards, encouraging agents to explore statetransitions with high information gain. We evaluate CERMIC on benchmark suitesincluding VMAS, Meltingpot, and SMACv2. Empirical results demonstrate thatexploration with CERMIC significantly outperforms SoTA algorithms insparse-reward environments.</description><author>Yiyuan Pan, Zhe Liu, Hesheng Wang</author><pubDate>Tue, 21 Oct 2025 17:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.20648v2</guid></item><item><title>Fourier Transform Multiple Instance Learning for Whole Slide Image Classification</title><link>http://arxiv.org/abs/2510.15138v2</link><description>Whole Slide Image (WSI) classification relies on Multiple Instance Learning(MIL) with spatial patch features, yet existing methods struggle to captureglobal dependencies due to the immense size of WSIs and the local nature ofpatch embeddings. This limitation hinders the modeling of coarse structuresessential for robust diagnostic prediction. We propose Fourier TransformMultiple Instance Learning (FFT-MIL), a framework that augments MIL with afrequency-domain branch to provide compact global context. Low-frequency cropsare extracted from WSIs via the Fast Fourier Transform and processed through amodular FFT-Block composed of convolutional layers and Min-Max normalization tomitigate the high variance of frequency data. The learned global frequencyfeature is fused with spatial patch features through lightweight integrationstrategies, enabling compatibility with diverse MIL architectures. FFT-MIL wasevaluated across six state-of-the-art MIL methods on three public datasets(BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1 scoresby an average of 3.51% and AUC by 1.51%, demonstrating consistent gains acrossarchitectures and datasets. These results establish frequency-domain learningas an effective and efficient mechanism for capturing global dependencies inWSI classification, complementing spatial features and advancing thescalability and accuracy of MIL-based computational pathology.</description><author>Anthony Bilic, Guangyu Sun, Ming Li, Md Sanzid Bin Hossain, Yu Tian, Wei Zhang, Laura Brattain, Dexter Hadley, Chen Chen</author><pubDate>Tue, 21 Oct 2025 17:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.15138v2</guid></item><item><title>PowerChain: A Verifiable Agentic AI System for Automating Distribution Grid Analyses</title><link>http://arxiv.org/abs/2508.17094v3</link><description>Rapid electrification and decarbonization are increasing the complexity ofdistribution grid (DG) operation and planning, necessitating advancedcomputational analyses to ensure reliability and resilience. These analysesdepend on disparate workflows comprising complex models, function calls, anddata pipelines that require substantial expert knowledge and remain difficultto automate. Workforce and budget constraints further limit utilities' abilityto apply such analyses at scale. To address this gap, we build an agenticsystem PowerChain, which is capable of autonomously performing complex gridanalyses. Existing agentic AI systems are typically developed in a bottom-upmanner with customized context for predefined analysis tasks; therefore, theydo not generalize to tasks that the agent has never seen. In comparison, togeneralize to unseen DG analysis tasks, PowerChain dynamically generatesstructured context by leveraging supervisory signals from self-contained powersystems tools (e.g., GridLAB-D) and an optimized set of expert-annotated andverified reasoning trajectories. For complex DG tasks defined in naturallanguage, empirical results on real utility data demonstrate that PowerChainachieves up to a 144/% improvement in performance over baselines.</description><author>Emmanuel O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey</author><pubDate>Tue, 21 Oct 2025 17:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.17094v3</guid></item><item><title>Correct-Detect: Balancing Performance and Ambiguity Through the Lens of Coreference Resolution in LLMs</title><link>http://arxiv.org/abs/2509.14456v2</link><description>Large Language Models (LLMs) are intended to reflect human linguisticcompetencies. But humans have access to a broad and embodied context, which iskey in detecting and resolving linguistic ambiguities, even in isolated textspans. A foundational case of semantic ambiguity is found in the task ofcoreference resolution: how is a pronoun related to an earlier person mention?This capability is implicit in nearly every downstream task, and the presenceof ambiguity at this level can alter performance significantly. We show thatLLMs can achieve good performance with minimal prompting in both coreferencedisambiguation and the detection of ambiguity in coreference, however, theycannot do both at the same time. We present the CORRECT-DETECT trade-off:though models have both capabilities and deploy them implicitly, successfulperformance balancing these two abilities remains elusive.</description><author>Amber Shore, Russell Scheinberg, Ameeta Agrawal, So Young Lee</author><pubDate>Tue, 21 Oct 2025 17:46:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.14456v2</guid></item><item><title>Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model</title><link>http://arxiv.org/abs/2510.18855v1</link><description>We present Ring-1T, the first open-source, state-of-the-art thinking modelwith a trillion-scale parameter. It features 1 trillion total parameters andactivates approximately 50 billion per token. Training such models at atrillion-parameter scale introduces unprecedented challenges, includingtrain-inference misalignment, inefficiencies in rollout processing, andbottlenecks in the RL system. To address these, we pioneer three interconnectedinnovations: (1) IcePop stabilizes RL training via token-level discrepancymasking and clipping, resolving instability from training-inference mismatches;(2) C3PO++ improves resource utilization for long rollouts under a token budgetby dynamically partitioning them, thereby obtaining high time efficiency; and(3) ASystem, a high-performance RL framework designed to overcome the systemicbottlenecks that impede trillion-parameter model training. Ring-1T deliversbreakthrough results across critical benchmarks: 93.4 on AIME-2025, 86.72 onHMMT-2025, 2088 on CodeForces, and 55.94 on ARC-AGI-v1. Notably, it attains asilver medal-level result on the IMO-2025, underscoring its exceptionalreasoning capabilities. By releasing the complete 1T parameter MoE model to thecommunity, we provide the research community with direct access to cutting-edgereasoning capabilities. This contribution marks a significant milestone indemocratizing large-scale reasoning intelligence and establishes a new baselinefor open-source model performance.</description><author>Ling Team, Anqi Shen, Baihui Li, Bin Hu, Bin Jing, Cai Chen, Chao Huang, Chao Zhang, Chaokun Yang, Cheng Lin, Chengyao Wen, Congqi Li, Deng Zhao, Dingbo Yuan, Donghai You, Fagui Mao, Fanzhuang Meng, Feng Xu, Guojie Li, Guowei Wang, Hao Dai, Haonan Zheng, Hong Liu, Jia Guo, Jiaming Liu, Jian Liu, Jianhao Fu, Jiannan Shi, Jianwen Wang, Jianxin Lai, Jin Yang, Jun Mei, Jun Zhou, Junbo Zhao, Junping Zhao, Kuan Xu, Le Su, Lei Chen, Li Tang, Liang Jiang, Liangcheng Fu, Lianhao Xu, Linfeng Shi, Lisha Liao, Longfei Zheng, Meng Li, Mingchun Chen, Qi Zuo, Qiang Cheng, Qianggang Cao, Qitao Shi, Quanrui Guo, Senlin Zhu, Shaofei Wang, Shaomian Zheng, Shuaicheng Li, Shuwei Gu, Siba Chen, Tao Wu, Tao Zhang, Tianyu Zhang, Tianyu Zhou, Tiwei Bie, Tongkai Yang, Wang Hong, Wang Ren, Weihua Chen, Wenbo Yu, Wen</author><pubDate>Tue, 21 Oct 2025 17:46:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18855v1</guid></item><item><title>Lyapunov-Aware Quantum-Inspired Reinforcement Learning for Continuous-Time Vehicle Control: A Feasibility Study</title><link>http://arxiv.org/abs/2510.18852v1</link><description>This paper presents a novel Lyapunov-Based Quantum Reinforcement Learning(LQRL) framework that integrates quantum policy optimization with Lyapunovstability analysis for continuous-time vehicle control. The proposed approachcombines the representational power of variational quantum circuits (VQCs) witha stability-aware policy gradient mechanism to ensure asymptotic convergenceand safe decision-making under dynamic environments. The vehicle longitudinalcontrol problem was formulated as a continuous-state reinforcement learningtask, where the quantum policy network generates control actions subject toLyapunov stability constraints. Simulation experiments were conducted in aclosed-loop adaptive cruise control scenario using a quantum-inspired policytrained under stability feedback. The results demonstrate that the LQRLframework successfully embeds Lyapunov stability verification into quantumpolicy learning, enabling interpretable and stability-aware controlperformance. Although transient overshoot and Lyapunov divergence were observedunder aggressive acceleration, the system maintained bounded state evolution,validating the feasibility of integrating safety guarantees within quantumreinforcement learning architectures. The proposed framework provides afoundational step toward provably safe quantum control in autonomous systemsand hybrid quantum-classical optimization domains.</description><author>Nutkritta Kraipatthanapong, Natthaphat Thathong, Pannita Suksawas, Thanunnut Klunklin, Kritin Vongthonglua, Krit Attahakul, Aueaphum Aueawatthanaphisut</author><pubDate>Tue, 21 Oct 2025 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18852v1</guid></item><item><title>DP$^2$O-SR: Direct Perceptual Preference Optimization for Real-World Image Super-Resolution</title><link>http://arxiv.org/abs/2510.18851v1</link><description>Benefiting from pre-trained text-to-image (T2I) diffusion models, real-worldimage super-resolution (Real-ISR) methods can synthesize rich and realisticdetails. However, due to the inherent stochasticity of T2I models, differentnoise inputs often lead to outputs with varying perceptual quality. Althoughthis randomness is sometimes seen as a limitation, it also introduces a widerperceptual quality range, which can be exploited to improve Real-ISRperformance. To this end, we introduce Direct Perceptual PreferenceOptimization for Real-ISR (DP$^2$O-SR), a framework that aligns generativemodels with perceptual preferences without requiring costly human annotations.We construct a hybrid reward signal by combining full-reference andno-reference image quality assessment (IQA) models trained on large-scale humanpreference datasets. This reward encourages both structural fidelity andnatural appearance. To better utilize perceptual diversity, we move beyond thestandard best-vs-worst selection and construct multiple preference pairs fromoutputs of the same model. Our analysis reveals that the optimal selectionratio depends on model capacity: smaller models benefit from broader coverage,while larger models respond better to stronger contrast in supervision.Furthermore, we propose hierarchical preference optimization, which adaptivelyweights training pairs based on intra-group reward gaps and inter-groupdiversity, enabling more efficient and stable learning. Extensive experimentsacross both diffusion- and flow-based T2I backbones demonstrate that DP$^2$O-SRsignificantly improves perceptual quality and generalizes well to real-worldbenchmarks.</description><author>Rongyuan Wu, Lingchen Sun, Zhengqiang Zhang, Shihao Wang, Tianhe Wu, Qiaosi Yi, Shuai Li, Lei Zhang</author><pubDate>Tue, 21 Oct 2025 17:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18851v1</guid></item><item><title>NEXUS: Network Exploration for eXploiting Unsafe Sequences in Multi-Turn LLM Jailbreaks</title><link>http://arxiv.org/abs/2510.03417v2</link><description>Large Language Models (LLMs) have revolutionized natural language processingbut remain vulnerable to jailbreak attacks, especially multi-turn jailbreaksthat distribute malicious intent across benign exchanges and bypass alignmentmechanisms. Existing approaches often explore the adversarial space poorly,rely on hand-crafted heuristics, or lack systematic query refinement. Wepresent NEXUS (Network Exploration for eXploiting Unsafe Sequences), a modularframework for constructing, refining, and executing optimized multi-turnattacks. NEXUS comprises: (1) ThoughtNet, which hierarchically expands aharmful intent into a structured semantic network of topics, entities, andquery chains; (2) a feedback-driven Simulator that iteratively refines andprunes these chains through attacker-victim-judge LLM collaboration usingharmfulness and semantic-similarity benchmarks; and (3) a Network Traverserthat adaptively navigates the refined query space for real-time attacks. Thispipeline uncovers stealthy, high-success adversarial paths across LLMs. Onseveral closed-source and open-source LLMs, NEXUS increases attack success rateby 2.1% to 19.4% over prior methods. Code: https://github.com/inspire-lab/NEXUS</description><author>Javad Rafiei Asl, Sidhant Narula, Mohammad Ghasemigol, Eduardo Blanco, Daniel Takabi</author><pubDate>Tue, 21 Oct 2025 17:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.03417v2</guid></item><item><title>UniVideo: Unified Understanding, Generation, and Editing for Videos</title><link>http://arxiv.org/abs/2510.08377v2</link><description>Unified multimodal models have shown promising results in multimodal contentgeneration and editing but remain largely limited to the image domain. In thiswork, we present UniVideo, a versatile framework that extends unified modelingto the video domain. UniVideo adopts a dual-stream design, combining aMultimodal Large Language Model (MLLM) for instruction understanding with aMultimodal DiT (MMDiT) for video generation. This design enables accurateinterpretation of complex multimodal instructions while preserving visualconsistency. Built on this architecture, UniVideo unifies diverse videogeneration and editing tasks under a single multimodal instruction paradigm andis jointly trained across them. Extensive experiments demonstrate that UniVideomatches or surpasses state-of-the-art task-specific baselines intext/image-to-video generation, in-context video generation and in-contextvideo editing. Notably, the unified design of UniVideo enables two forms ofgeneralization. First, UniVideo supports task composition, such as combiningediting with style transfer, by integrating multiple capabilities within asingle instruction. Second, even without explicit training on free-form videoediting, UniVideo transfers its editing capability from large-scale imageediting data to this setting, handling unseen instructions such asgreen-screening characters or changing materials within a video. Beyond thesecore capabilities, UniVideo also supports visual-prompt-based video generation,where the MLLM interprets visual prompts and guides the MMDiT during synthesis.To foster future research, we will release our model and code.</description><author>Cong Wei, Quande Liu, Zixuan Ye, Qiulin Wang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhu Chen</author><pubDate>Tue, 21 Oct 2025 17:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.08377v2</guid></item><item><title>Adaptive Sample-Level Framework Motivated by Distributionally Robust Optimization with Variance-Based Radius Assignment for Enhanced Neural Network Generalization Under Distribution Shift</title><link>https://arxiv.org/abs/2511.05568v1</link><description>Distribution shifts and minority subpopulations frequently undermine the reliability of deep neural networks trained using Empirical Risk Minimization (ERM). Distributionally Robust Optimization (DRO) addresses this by optimizing for the worst-case risk within a neighborhood of the training distribution. However, conventional methods depend on a single, global robustness budget, which can lead to overly conservative models or a misallocation of robustness. We propose a variance-driven, adaptive, sample-level DRO (Var-DRO) framework that automatically identifies high-risk training samples and assigns a personalized robustness budget to each based on its online loss variance. Our formulation employs two-sided, KL-divergence-style bounds to constrain the ratio between adversarial and empirical weights for every sample. This results in a linear inner maximization problem over a convex polytope, which admits an efficient water-filling solution. To stabilize training, we introduce a warmup phase and a linear ramp schedule for the global cap on per-sample budgets, complemented by label smoothing for numerical robustness. Evaluated on CIFAR-10-C (corruptions), our method achieves the highest overall mean accuracy compared to ERM and KL-DRO. On Waterbirds, Var-DRO improves overall performance while matching or surpassing KL-DRO. On the original CIFAR-10 dataset, Var-DRO remains competitive, exhibiting the modest trade-off anticipated when prioritizing robustness. The proposed framework is unsupervised (requiring no group labels), straightforward to implement, theoretically sound, and computationally efficient.</description><author>Aheer Sravon, Devdyuti Mazumder, Md. Ibrahim</author><pubDate>Tue, 04 Nov 2025 10:20:21 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/abs/2511.05568v1</guid></item><item><title>Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset</title><link>https://arxiv.org/abs/2510.20209v2</link><description>The development of accessible screening tools for early cancer detection in dogs represents a significant challenge in veterinary medicine. Routine laboratory data offer a promising, low-cost source for such tools, but their utility is hampered by the non-specificity of individual biomarkers and the severe class imbalance inherent in screening populations. This study assesses the feasibility of cancer risk classification using the Golden Retriever Lifetime Study (GRLS) cohort under real-world constraints, including the grouping of diverse cancer types and the inclusion of post-diagnosis samples. A comprehensive benchmark evaluation was conducted, systematically comparing 126 analytical pipelines that comprised various machine learning models, feature selection methods, and data balancing techniques. Data were partitioned at the patient level to prevent leakage. The optimal model, a Logistic Regression classifier with class weighting and recursive feature elimination, demonstrated moderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical classification performance (F1-score = 0.25, Positive Predictive Value = 0.15). While a high Negative Predictive Value (0.98) was achieved, insufficient recall (0.79) precludes its use as a reliable rule-out test. Interpretability analysis with SHapley Additive exPlanations (SHAP) revealed that predictions were driven by non-specific features like age and markers of inflammation and anemia. It is concluded that while a statistically detectable cancer signal exists in routine lab data, it is too weak and confounded for clinically reliable discrimination from normal aging or other inflammatory conditions. This work establishes a critical performance ceiling for this data modality in isolation and underscores that meaningful progress in computational veterinary oncology will require integration of multi-modal data sources.</description><author>Shumin Li</author><pubDate>Sat, 25 Oct 2025 00:55:35 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/abs/2510.20209v2</guid></item><item><title>Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning</title><link>http://arxiv.org/abs/2510.18849v1</link><description>Faithfully personalizing large language models (LLMs) to align withindividual user preferences is a critical but challenging task. Whilesupervised fine-tuning (SFT) quickly reaches a performance plateau, standardreinforcement learning from human feedback (RLHF) also struggles with thenuances of personalization. Scalar-based reward models are prone to rewardhacking which leads to verbose and superficially personalized responses. Toaddress these limitations, we propose Critique-Post-Edit, a robustreinforcement learning framework that enables more faithful and controllablepersonalization. Our framework integrates two key components: (1) aPersonalized Generative Reward Model (GRM) that provides multi-dimensionalscores and textual critiques to resist reward hacking, and (2) aCritique-Post-Edit mechanism where the policy model revises its own outputsbased on these critiques for more targeted and efficient learning. Under arigorous length-controlled evaluation, our method substantially outperformsstandard PPO on personalization benchmarks. Personalized Qwen2.5-7B achieves anaverage 11\% win-rate improvement, and personalized Qwen2.5-14B model surpassesthe performance of GPT-4.1. These results demonstrate a practical path tofaithful, efficient, and controllable personalization.</description><author>Chenghao Zhu, Meiling Tao, Tiannan Wang, Dongyi Ding, Yuchen Eleanor Jiang, Wangchunshu Zhou</author><pubDate>Tue, 21 Oct 2025 17:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18849v1</guid></item><item><title>High-Fidelity And Complex Test Data Generation For Google SQL Code Generation Services</title><link>http://arxiv.org/abs/2504.17203v3</link><description>The demand for high-fidelity test data is paramount in industrial settingswhere access to production data is largely restricted. Traditional datageneration methods often fall short, struggling with low-fidelity and theability to model complex data structures and semantic relationships that arecritical for testing complex SQL code generation services like Natural Languageto SQL (NL2SQL). In this paper, we address the critical need for generatingsyntactically correct and semantically relevant high-fidelity mock data forcomplex data structures that includes columns with nested structures that wefrequently encounter in Google workloads. We highlight the limitations ofexisting approaches used in production, particularly their inability to handlelarge and complex data structures, as well as the lack of semantically coherenttest data that lead to limited test coverage. We demonstrate that by leveragingLarge Language Models (LLMs) and incorporating strategic pre- andpost-processing steps, we can generate syntactically correct and semanticallyrelevant high-fidelity test data that adheres to complex structural constraintsand maintains semantic integrity to the SQL test targets (queries/functions).This approach supports comprehensive testing of complex SQL queries involvingjoins, aggregations, and even deeply nested subqueries, ensuring robustevaluation of SQL code generation services, like NL2SQL and SQL Code Assistant.Our results demonstrate the practical utility of an LLM (\textit{gemini}) basedtest data generation for industrial SQL code generation services wheregenerating high-fidelity test data is essential due to the frequentunavailability and inaccessibility of production datasets for testing.</description><author>Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan</author><pubDate>Tue, 21 Oct 2025 17:38:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2504.17203v3</guid></item><item><title>One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares</title><link>http://arxiv.org/abs/2207.13853v2</link><description>While large machine learning models have shown remarkable performance invarious domains, their training typically requires iterating for many passesover the training data. However, due to computational and memory constraintsand potential privacy concerns, storing and accessing all the data isimpractical in many real-world scenarios where the data arrives in a stream. Inthis paper, we investigate the problem of one-pass learning, in which a modelis trained on sequentially arriving data without retraining on previousdatapoints. Motivated by the demonstrated effectiveness of overparameterizedmodels and the phenomenon of benign overfitting, we propose OrthogonalRecursive Fitting (ORFit), an algorithm for one-pass learning which seeks toperfectly fit each new datapoint while minimally altering the predictions onprevious datapoints. ORFit updates the parameters in a direction orthogonal topast gradients, similar to orthogonal gradient descent (OGD) in continuallearning. We show that, interestingly, ORFit's update leads to an operationsimilar to the recursive least-squares (RLS) algorithm in adaptive filteringbut with significantly improved memory and computational efficiency, i.e.,linear, instead of quadratic, in the number of parameters. To further reducememory usage, we leverage the structure of the streaming data via anincremental principal component analysis (IPCA). We show that using theprincipal components is minimax optimal, i.e., it minimizes the worst-caseforgetting of previous predictions for unknown future updates. Further, weprove that, for overparameterized linear models, the parameter vector obtainedby ORFit matches what the standard multi-pass stochastic gradient descent (SGD)would converge to. Finally, we extend our results to the nonlinear setting forhighly overparameterized models, relevant for deep learning.</description><author>Youngjae Min, Namhoon Cho, Navid Azizan</author><pubDate>Tue, 21 Oct 2025 17:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.13853v2</guid></item><item><title>Inference on Local Variable Importance Measures for Heterogeneous Treatment Effects</title><link>http://arxiv.org/abs/2510.18843v1</link><description>We provide an inferential framework to assess variable importance forheterogeneous treatment effects. This assessment is especially useful inhigh-risk domains such as medicine, where decision makers hesitate to rely onblack-box treatment recommendation algorithms. The variable importance measureswe consider are local in that they may differ across individuals, while theinference is global in that it tests whether a given variable is important forany individual. Our approach builds on recent developments in semiparametrictheory for function-valued parameters, and is valid even when statisticalmachine learning algorithms are employed to quantify treatment effectheterogeneity. We demonstrate the applicability of our method to infectiousdisease prevention strategies.</description><author>Pawel Morzywolek, Peter B. Gilbert, Alex Luedtke</author><pubDate>Tue, 21 Oct 2025 17:35:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18843v1</guid></item><item><title>A Hybrid Enumeration Framework for Optimal Counterfactual Generation in Post-Acute COVID-19 Heart Failure</title><link>http://arxiv.org/abs/2510.18841v1</link><description>Counterfactual inference provides a mathematical framework for reasoningabout hypothetical outcomes under alternative interventions, bridging causalreasoning and predictive modeling. We present a counterfactual inferenceframework for individualized risk estimation and intervention analysis,illustrated through a clinical application to post-acute sequelae of COVID-19(PASC) among patients with pre-existing heart failure (HF). Using longitudinaldiagnosis, laboratory, and medication data from a large health-system cohort,we integrate regularized predictive modeling with counterfactual search toidentify actionable pathways to PASC-related HF hospital admissions. Theframework combines exact enumeration with optimization-based methods, includingthe Nearest Instance Counterfactual Explanations (NICE) and Multi-ObjectiveCounterfactuals (MOC) algorithms, to efficiently explore high-dimensionalintervention spaces. Applied to more than 2700 individuals with confirmedSARS-CoV-2 infection and prior HF, the model achieved strong discriminativeperformance (AUROC: 0.88, 95% CI: 0.84-0.91) and generated interpretable,patient-specific counterfactuals that quantify how modifying comorbiditypatterns or treatment factors could alter predicted outcomes. This workdemonstrates how counterfactual reasoning can be formalized as an optimizationproblem over predictive functions, offering a rigorous, interpretable, andcomputationally efficient approach to personalized inference in complexbiomedical systems.</description><author>Jingya Cheng, Alaleh Azhir, Jiazi Tian, Hossein Estiri</author><pubDate>Tue, 21 Oct 2025 17:35:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18841v1</guid></item><item><title>Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training</title><link>https://arxiv.org/abs/2510.27630v2</link><description>Large Language Model (LLM) agents have recently shown strong potential in domains such as automated coding, deep research, and graphical user interface manipulation. However, training them to succeed on long-horizon, domain-specialized tasks remains challenging. Current methods primarily fall into two categories. The first relies on dense human annotations through behavior cloning, which is prohibitively expensive for long-horizon tasks that can take days or months. The second depends on outcome-driven sampling, which often collapses due to the rarity of valid positive trajectories on domain-specialized tasks. We introduce Apollo, a sampling framework that integrates asynchronous human guidance with action-level data filtering. Instead of requiring annotators to shadow every step, Apollo allows them to intervene only when the agent drifts from a promising trajectory, by providing prior knowledge, strategic advice, etc. This lightweight design makes it possible to sustain interactions for over 30 hours and produces valuable trajectories at a lower cost. Apollo then applies supervision control to filter out sub-optimal actions and prevent error propagation. Together, these components enable reliable and effective data collection in long-horizon environments. To demonstrate the effectiveness of Apollo, we evaluate it using InnovatorBench. Our experiments show that when applied to train the GLM-4.5 model on InnovatorBench, Apollo achieves more than a 50% improvement over the untrained baseline and a 28% improvement over a variant trained without human interaction. These results highlight the critical role of human-in-the-loop sampling and the robustness of Apollo's design in handling long-horizon, domain-specialized tasks.</description><author>Dayuan Fu, Yunze Wu, Xiaojie Cai, Lyumanshan Ye, Shijie Xia, Zhen Huang, Weiye Si, Tianze Xu, Jie Sun, Keyu Li, Mohan Jiang, Junfei Wang, Qishuo Hua, Pengrui Lu, Yang Xiao, Pengfei Liu</author><pubDate>Mon, 03 Nov 2025 10:53:11 GMT</pubDate><guid isPermaLink="true">https://arxiv.org/abs/2510.27630v2</guid></item><item><title>See the Text: From Tokenization to Visual Reading</title><link>http://arxiv.org/abs/2510.18840v1</link><description>People see text. Humans read by recognizing words as visual objects,including their shapes, layouts, and patterns, before connecting them tomeaning, which enables us to handle typos, distorted fonts, and various scriptseffectively. Modern large language models (LLMs), however, rely on subwordtokenization, fragmenting text into pieces from a fixed vocabulary. Whileeffective for high-resource languages, this approach over-segments low-resourcelanguages, yielding long, linguistically meaningless sequences and inflatingcomputation. In this work, we challenge this entrenched paradigm and movetoward a vision-centric alternative. Our method, SeeTok, renders text as images(visual-text) and leverages pretrained multimodal LLMs to interpret them,reusing strong OCR and text-vision alignment abilities learned from large-scalemultimodal training. Across three different language tasks, SeeTok matches orsurpasses subword tokenizers while requiring 4.43 times fewer tokens andreducing FLOPs by 70.5%, with additional gains in cross-lingual generalization,robustness to typographic noise, and linguistic hierarchy. SeeTok signals ashift from symbolic tokenization to human-like visual reading, and takes a steptoward more natural and cognitively inspired language models.</description><author>Ling Xing, Alex Jinpeng Wang, Rui Yan, Hongyu Qu, Zechao Li, Jinhui Tang</author><pubDate>Tue, 21 Oct 2025 17:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18840v1</guid></item><item><title>How Transformers Learn In-Context Recall Tasks? Optimality, Training Dynamics and Generalization</title><link>http://arxiv.org/abs/2505.15009v3</link><description>We study the approximation capabilities, convergence speeds andon-convergence behaviors of transformers trained on in-context recall tasks --which requires to recognize the \emph{positional} association between a pair oftokens from in-context examples. Existing theoretical results only focus on thein-context reasoning behavior of transformers after being trained for the\emph{one} gradient descent step. It remains unclear what is the on-convergencebehavior of transformers being trained by gradient descent and how fast theconvergence rate is. In addition, the generalization of transformers inone-step in-context reasoning has not been formally investigated. This workaddresses these gaps. We first show that a class of transformers with eitherlinear, ReLU or softmax attentions, is provably Bayes-optimal for an in-contextrecall task. When being trained with gradient descent, we show via afinite-sample analysis that the expected loss converges at linear rate to theBayes risks. Moreover, we show that the trained transformers exhibitout-of-distribution (OOD) generalization, i.e., generalizing to samples outsideof the population distribution. Our theoretical findings are further supportedby extensive empirical validations, showing that \emph{without} properparameterization, models with larger expressive power surprisingly \emph{fail}to generalize OOD after being trained by gradient descent.</description><author>Quan Nguyen, Thanh Nguyen-Tang</author><pubDate>Tue, 21 Oct 2025 17:34:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15009v3</guid></item><item><title>FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning</title><link>http://arxiv.org/abs/2510.18837v1</link><description>Federated learning (FL) enables multiple clients to collaboratively trainmachine learning models without exposing local data, balancing performance andprivacy. However, domain shift and label heterogeneity across clients oftenhinder the generalization of the aggregated global model. Recently, large-scalevision-language models like CLIP have shown strong zero-shot classificationcapabilities, raising the question of how to effectively fine-tune CLIP acrossdomains in a federated setting. In this work, we propose an adaptive federatedprompt tuning framework, FedDEAP, to enhance CLIP's generalization inmulti-domain scenarios. Our method includes the following three key components:(1) To mitigate the loss of domain-specific information caused bylabel-supervised tuning, we disentangle semantic and domain-specific featuresin images by using semantic and domain transformation networks with unbiasedmappings; (2) To preserve domain-specific knowledge during global promptaggregation, we introduce a dual-prompt design with a global semantic promptand a local domain prompt to balance shared and personalized information; (3)To maximize the inclusion of semantic and domain information from images in thegenerated text features, we align textual and visual representations under thetwo learned transformations to preserve semantic and domain consistency.Theoretical analysis and extensive experiments on four datasets demonstrate theeffectiveness of our method in enhancing the generalization of CLIP forfederated image recognition across multiple domains.</description><author>Yubin Zheng, Pak-Hei Yeung, Jing Xia, Tianjie Ju, Peng Tang, Weidong Qiu, Jagath C. Rajapakse</author><pubDate>Tue, 21 Oct 2025 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18837v1</guid></item><item><title>AstroMMBench: A Benchmark for Evaluating Multimodal Large Language Models Capabilities in Astronomy</title><link>http://arxiv.org/abs/2510.00063v2</link><description>Astronomical image interpretation presents a significant challenge forapplying multimodal large language models (MLLMs) to specialized scientifictasks. Existing benchmarks focus on general multimodal capabilities but fail tocapture the complexity of astronomical data. To bridge this gap, we introduceAstroMMBench, the first comprehensive benchmark designed to evaluate MLLMs inastronomical image understanding. AstroMMBench comprises 621 multiple-choicequestions across six astrophysical subfields, curated and reviewed by 15 domainexperts for quality and relevance. We conducted an extensive evaluation of 25diverse MLLMs, including 22 open-source and 3 closed-source models, usingAstroMMBench. The results show that Ovis2-34B achieved the highest overallaccuracy (70.5%), demonstrating leading capabilities even compared to strongclosed-source models. Performance showed variations across the sixastrophysical subfields, proving particularly challenging in domains likecosmology and high-energy astrophysics, while models performed relativelybetter in others, such as instrumentation and solar astrophysics. Thesefindings underscore the vital role of domain-specific benchmarks likeAstroMMBench in critically evaluating MLLM performance and guiding theirtargeted development for scientific applications. AstroMMBench provides afoundational resource and a dynamic tool to catalyze advancements at theintersection of AI and astronomy.</description><author>Jinghang Shi, Xiaoyu Tang, Yang Huang, Yuyang Li, Xiao Kong, Yanxia Zhang, Caizhan Yue</author><pubDate>Tue, 21 Oct 2025 17:29:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.00063v2</guid></item><item><title>Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks</title><link>http://arxiv.org/abs/2510.16028v2</link><description>Neural networks increasingly run on hardware outside the user's control(cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little aboutwhat actually ran or whether returned outputs faithfully reflect the intendedinputs. Users lack recourse against service downgrades (model swaps,quantization, graph rewrites, or discrepancies like altered ad embeddings).Verifying outputs is hard because floating-point(FP) execution on heterogeneousaccelerators is inherently nondeterministic. Existing approaches are eitherimpractical for real FP neural networks or reintroduce vendor trust. We presentNAO: a Nondeterministic tolerance Aware Optimistic verification protocol thataccepts outputs within principled operator-level acceptance regions rather thanrequiring bitwise equality. NAO combines two error models: (i) soundper-operator IEEE-754 worst-case bounds and (ii) tight empirical percentileprofiles calibrated across hardware. Discrepancies trigger a Merkle-anchored,threshold-guided dispute game that recursively partitions the computation graphuntil one operator remains, where adjudication reduces to a lightweighttheoretical-bound check or a small honest-majority vote against empiricalthresholds. Unchallenged results finalize after a challenge window, withoutrequiring trusted hardware or deterministic kernels. We implement NAO as aPyTorch-compatible runtime and a contract layer currently deployed on EthereumHolesky testnet. The runtime instruments graphs, computes per-operator bounds,and runs unmodified vendor kernels in FP32 with negligible overhead (0.3% onQwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100,RTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter thantheoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAOreconciles scalability with verifiability for real-world heterogeneous MLcompute.</description><author>Jianzhu Yao, Hongxu Su, Taobo Liao, Zerui Cheng, Huan Zhang, Xuechao Wang, Pramod Viswanath</author><pubDate>Tue, 21 Oct 2025 17:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.16028v2</guid></item><item><title>MTraining: Distributed Dynamic Sparse Attention for Efficient Ultra-Long Context Training</title><link>http://arxiv.org/abs/2510.18830v1</link><description>The adoption of long context windows has become a standard feature in LargeLanguage Models (LLMs), as extended contexts significantly enhance theircapacity for complex reasoning and broaden their applicability across diversescenarios. Dynamic sparse attention is a promising approach for reducing thecomputational cost of long-context. However, efficiently training LLMs withdynamic sparse attention on ultra-long contexts-especially in distributedsettings-remains a significant challenge, due in large part to worker- andstep-level imbalance. This paper introduces MTraining, a novel distributedmethodology leveraging dynamic sparse attention to enable efficient trainingfor LLMs with ultra-long contexts. Specifically, MTraining integrates three keycomponents: a dynamic sparse training pattern, balanced sparse ring attention,and hierarchical sparse ring attention. These components are designed tosynergistically address the computational imbalance and communication overheadsinherent in dynamic sparse attention mechanisms during the training of modelswith extensive context lengths. We demonstrate the efficacy of MTraining bytraining Qwen2.5-3B, successfully expanding its context window from 32K to 512Ktokens on a cluster of 32 A100 GPUs. Our evaluations on a comprehensive suiteof downstream tasks, including RULER, PG-19, InfiniteBench, and Needle In AHaystack, reveal that MTraining achieves up to a 6x higher training throughputwhile preserving model accuracy. Our code is available athttps://github.com/microsoft/MInference/tree/main/MTraining.</description><author>Wenxuan Li, Chengruidong Zhang, Huiqiang Jiang, Yucheng Li, Yuqing Yang, Lili Qiu</author><pubDate>Tue, 21 Oct 2025 17:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18830v1</guid></item><item><title>Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods</title><link>http://arxiv.org/abs/2506.10959v2</link><description>While in-context learning (ICL) has achieved remarkable success in naturallanguage and vision domains, its theoretical understanding-particularly in thecontext of structured geometric data-remains unexplored. This paper initiates atheoretical study of ICL for regression of H\"older functions on manifolds. Weestablish a novel connection between the attention mechanism and classicalkernel methods, demonstrating that transformers effectively performkernel-based prediction at a new query through its interaction with the prompt.This connection is validated by numerical experiments, revealing that thelearned query-prompt scores for H\"older functions are highly correlated withthe Gaussian kernel. Building on this insight, we derive generalization errorbounds in terms of the prompt length and the number of training tasks. When asufficient number of training tasks are observed, transformers give rise to theminimax regression rate of H\"older functions on manifolds, which scalesexponentially with the intrinsic dimension of the manifold, rather than theambient space dimension. Our result also characterizes how the generalizationerror scales with the number of training tasks, shedding light on thecomplexity of transformers as in-context kernel algorithm learners. Ourfindings provide foundational insights into the role of geometry in ICL andnovels tools to study ICL of nonlinear models.</description><author>Zhaiming Shen, Alexander Hsu, Rongjie Lai, Wenjing Liao</author><pubDate>Tue, 21 Oct 2025 17:24:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.10959v2</guid></item><item><title>Actor-Free Continuous Control via Structurally Maximizable Q-Functions</title><link>http://arxiv.org/abs/2510.18828v1</link><description>Value-based algorithms are a cornerstone of off-policy reinforcement learningdue to their simplicity and training stability. However, their use hastraditionally been restricted to discrete action spaces, as they rely onestimating Q-values for individual state-action pairs. In continuous actionspaces, evaluating the Q-value over the entire action space becomescomputationally infeasible. To address this, actor-critic methods are typicallyemployed, where a critic is trained on off-policy data to estimate Q-values,and an actor is trained to maximize the critic's output. Despite theirpopularity, these methods often suffer from instability during training. Inthis work, we propose a purely value-based framework for continuous controlthat revisits structural maximization of Q-functions, introducing a set of keyarchitectural and algorithmic choices to enable efficient and stable learning.We evaluate the proposed actor-free Q-learning approach on a range of standardsimulation tasks, demonstrating performance and sample efficiency on par withstate-of-the-art baselines, without the cost of learning a separate actor.Particularly, in environments with constrained action spaces, where the valuefunctions are typically non-smooth, our method with structural maximizationoutperforms traditional actor-critic methods with gradient-based maximization.We have released our code at https://github.com/USC-Lira/Q3C.</description><author>Yigit Korkmaz, Urvi Bhuwania, Ayush Jain, Erdem Byk</author><pubDate>Tue, 21 Oct 2025 17:24:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18828v1</guid></item><item><title>SO(3)-invariant PCA with application to molecular data</title><link>http://arxiv.org/abs/2510.18827v1</link><description>Principal component analysis (PCA) is a fundamental technique fordimensionality reduction and denoising; however, its application tothree-dimensional data with arbitrary orientations -- common in structuralbiology -- presents significant challenges. A naive approach requiresaugmenting the dataset with many rotated copies of each sample, incurringprohibitive computational costs. In this paper, we extend PCA to 3D volumetricdatasets with unknown orientations by developing an efficient and principledframework for SO(3)-invariant PCA that implicitly accounts for all rotationswithout explicit data augmentation. By exploiting underlying algebraicstructure, we demonstrate that the computation involves only the square root ofthe total number of covariance entries, resulting in a substantial reduction incomplexity. We validate the method on real-world molecular datasets,demonstrating its effectiveness and opening up new possibilities forlarge-scale, high-dimensional reconstruction problems.</description><author>Michael Fraiman, Paulina Hoyos, Tamir Bendory, Joe Kileel, Oscar Mickelin, Nir Sharon, Amit Singer</author><pubDate>Tue, 21 Oct 2025 17:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18827v1</guid></item><item><title>Unifying and Enhancing Graph Transformers via a Hierarchical Mask Framework</title><link>http://arxiv.org/abs/2510.18825v1</link><description>Graph Transformers (GTs) have emerged as a powerful paradigm for graphrepresentation learning due to their ability to model diverse nodeinteractions. However, existing GTs often rely on intricate architecturaldesigns tailored to specific interactions, limiting their flexibility. Toaddress this, we propose a unified hierarchical mask framework that reveals anunderlying equivalence between model architecture and attention maskconstruction. This framework enables a consistent modeling paradigm bycapturing diverse interactions through carefully designed attention masks.Theoretical analysis under this framework demonstrates that the probability ofcorrect classification positively correlates with the receptive field size andlabel consistency, leading to a fundamental design principle: an effectiveattention mask should ensure both a sufficiently large receptive field and ahigh level of label consistency. While no single existing mask satisfies thisprinciple across all scenarios, our analysis reveals that hierarchical masksoffer complementary strengths, motivating their effective integration. Then, weintroduce M3Dphormer, a Mixture-of-Experts-based Graph Transformer withMulti-Level Masking and Dual Attention Computation. M3Dphormer incorporatesthree theoretically grounded hierarchical masks and employs a bi-level expertrouting mechanism to adaptively integrate multi-level interaction information.To ensure scalability, we further introduce a dual attention computation schemethat dynamically switches between dense and sparse modes based on local masksparsity. Extensive experiments across multiple benchmarks demonstrate thatM3Dphormer achieves state-of-the-art performance, validating the effectivenessof our unified framework and model design.</description><author>Yujie Xing, Xiao Wang, Bin Wu, Hai Huang, Chuan Shi</author><pubDate>Tue, 21 Oct 2025 17:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18825v1</guid></item><item><title>BO4Mob: Bayesian Optimization Benchmarks for High-Dimensional Urban Mobility Problem</title><link>http://arxiv.org/abs/2510.18824v1</link><description>We introduce \textbf{BO4Mob}, a new benchmark framework for high-dimensionalBayesian Optimization (BO), driven by the challenge of origin-destination (OD)travel demand estimation in large urban road networks. Estimating OD traveldemand from limited traffic sensor data is a difficult inverse optimizationproblem, particularly in real-world, large-scale transportation networks. Thisproblem involves optimizing over high-dimensional continuous spaces where eachobjective evaluation is computationally expensive, stochastic, andnon-differentiable. BO4Mob comprises five scenarios based on real-world SanJose, CA road networks, with input dimensions scaling up to 10,100. Thesescenarios utilize high-resolution, open-source traffic simulations thatincorporate realistic nonlinear and stochastic dynamics. We demonstrate thebenchmark's utility by evaluating five optimization methods: threestate-of-the-art BO algorithms and two non-BO baselines. This benchmark isdesigned to support both the development of scalable optimization algorithmsand their application for the design of data-driven urban mobility models,including high-resolution digital twins of metropolitan road networks. Code anddocumentation are available at https://github.com/UMN-Choi-Lab/BO4Mob.</description><author>Seunghee Ryu, Donghoon Kwon, Seongjin Choi, Aryan Deshwal, Seungmo Kang, Carolina Osorio</author><pubDate>Tue, 21 Oct 2025 17:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18824v1</guid></item><item><title>FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model</title><link>http://arxiv.org/abs/2502.01472v3</link><description>Large language models have been widely applied, but can inadvertently encodesensitive or harmful information, raising significant safety concerns. Machineunlearning has emerged to alleviate this concern; however, existingtraining-time unlearning approaches, relying on coarse-grained losscombinations, have limitations in precisely separating knowledge and balancingremoval effectiveness with model utility. In contrast, we propose Fine-grainedActivation manipuLation by Contrastive Orthogonal uNalignment (FALCON), a novelrepresentation-guided unlearning approach that leverages information-theoreticguidance for efficient parameter selection, employs contrastive mechanisms toenhance representation separation, and projects conflict gradients ontoorthogonal subspaces to resolve conflicts between forgetting and retentionobjectives. Extensive experiments demonstrate that FALCON achieves superiorunlearning effectiveness while maintaining model utility, exhibiting robustresistance against knowledge recovery attempts.</description><author>Jinwei Hu, Zhenglin Huang, Xiangyu Yin, Wenjie Ruan, Guangliang Cheng, Yi Dong, Xiaowei Huang</author><pubDate>Tue, 21 Oct 2025 17:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01472v3</guid></item><item><title>SAM 2++: Tracking Anything at Any Granularity</title><link>http://arxiv.org/abs/2510.18822v1</link><description>Video tracking aims at finding the specific target in subsequent frames givenits initial state. Due to the varying granularity of target states acrossdifferent tasks, most existing trackers are tailored to a single task andheavily rely on custom-designed modules within the individual task, whichlimits their generalization and leads to redundancy in both model design andparameters. To unify video tracking tasks, we present SAM 2++, a unified modeltowards tracking at any granularity, including masks, boxes, and points. First,to extend target granularity, we design task-specific prompts to encode varioustask inputs into general prompt embeddings, and a unified decoder to unifydiverse task results into a unified form pre-output. Next, to satisfy memorymatching, the core operation of tracking, we introduce a task-adaptive memorymechanism that unifies memory across different granularities. Finally, weintroduce a customized data engine to support tracking training at anygranularity, producing a large and diverse video tracking dataset with richannotations at three granularities, termed Tracking-Any-Granularity, whichrepresents a comprehensive resource for training and benchmarking on unifiedtracking. Comprehensive experiments on multiple benchmarks confirm that SAM 2++sets a new state of the art across diverse tracking tasks at differentgranularities, establishing a unified and robust tracking framework.</description><author>Jiaming Zhang, Cheng Liang, Yichun Yang, Chenkai Zeng, Yutao Cui, Xinwen Zhang, Xin Zhou, Kai Ma, Gangshan Wu, Limin Wang</author><pubDate>Tue, 21 Oct 2025 17:20:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18822v1</guid></item><item><title>TeLLMe v2: An Efficient End-to-End Ternary LLM Prefill and Decode Accelerator with Table-Lookup Matmul on Edge FPGAs</title><link>http://arxiv.org/abs/2510.15926v2</link><description>With the emergence of wearable devices and other embedded systems, deployinglarge language models (LLMs) on edge platforms has become an urgent need.However, this is challenging because of their high computational and memorydemands. Although recent low-bit quantization methods (e.g., BitNet, DeepSeek)compress weights to as low as 1.58~bits with minimal accuracy loss, edgedeployment is still constrained by limited on-chip resources, power budgets,and the often-neglected long latency of the prefill stage. We present\textbf{TeLLMe}, the first table-lookup-based ternary LLM accelerator forlow-power edge FPGAs that fully supports both prefill and autoregressivedecoding using 1.58-bit weights and 8-bit activations. TeLLMe incorporatesseveral novel techniques, including (1) a table-lookup-based ternary matrixmultiplication (TLMM) engine utilizing grouped activations and onlineprecomputation for low resource utilization and high throughput; (2) afine-grained analytic URAM-based weight buffer management scheme for efficientloading and compute engine access; (3) a streaming dataflow architecture thatfuses floating-point element-wise operations with linear computations to hidelatency; (4) a reversed-reordered prefill stage attention with fused attentionoperations for high memory efficiency; and (5) a resource-efficient specializeddecoding stage attention. Under a 5~W power budget, TeLLMe delivers up to25~tokens/s decoding throughput and 0.45--0.96~s time-to-first-token (TTFT) for64--128 token prompts, marking a significant energy-efficiency advancement inLLM inference on edge FPGAs.</description><author>Ye Qiao, Zhiheng Chen, Yifan Zhang, Yian Wang, Sitao Huang</author><pubDate>Tue, 21 Oct 2025 17:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.15926v2</guid></item><item><title>Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers</title><link>http://arxiv.org/abs/2510.11370v2</link><description>Reinforcement learning (RL) has emerged as a crucial approach for enhancingthe capabilities of large language models. However, in Mixture-of-Experts (MoE)models, the routing mechanism often introduces instability, even leading tocatastrophic RL training collapse. We analyze the training-inferenceconsistency of MoE models and identify a notable discrepancy in routingbehaviors between the two phases. Moreover, even under identical conditions,the routing framework can yield divergent expert selections across repeatedforward passes. To address this foundational inconsistency, we propose RolloutRouting Replay (R3), a method that records routing distributions from theinference engine and replays them during training. R3 significantly reducestraining-inference policy KL divergence and mitigates extreme discrepancieswithout compromising training speed. Extensive experiments on various settingsconfirm that R3 succeeds in stabilizing RL training, preventing collapse andoutperforming methods such as GSPO and TIS. We believe this work can offer anew solution for stabilizing RL in MoE models.</description><author>Wenhan Ma, Hailin Zhang, Liang Zhao, Yifan Song, Yudong Wang, Zhifang Sui, Fuli Luo</author><pubDate>Tue, 21 Oct 2025 17:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.11370v2</guid></item><item><title>Search Self-play: Pushing the Frontier of Agent Capability without Supervision</title><link>http://arxiv.org/abs/2510.18821v1</link><description>Reinforcement learning with verifiable rewards (RLVR) has become themainstream technique for training LLM agents. However, RLVR highly depends onwell-crafted task queries and corresponding ground-truth answers to provideaccurate rewards, which requires massive human efforts and hinders the RLscaling processes, especially under agentic scenarios. Although a few recentworks explore task synthesis methods, the difficulty of generated agentic taskscan hardly be controlled to provide effective RL training advantages. Toachieve agentic RLVR with higher scalability, we explore self-play training fordeep search agents, in which the learning LLM utilizes multi-turn search enginecalling and acts simultaneously as both a task proposer and a problem solver.The task proposer aims to generate deep search queries with well-definedground-truth answers and increasing task difficulty. The problem solver triesto handle the generated search queries and output the correct answerpredictions. To ensure that each generated search query has accurate groundtruth, we collect all the searching results from the proposer's trajectory asexternal knowledge, then conduct retrieval-augmentation generation (RAG) totest whether the proposed query can be correctly answered with all necessarysearch documents provided. In this search self-play (SSP) game, the proposerand the solver co-evolve their agent capabilities through both competition andcooperation. With substantial experimental results, we find that SSP cansignificantly improve search agents' performance uniformly on variousbenchmarks without any supervision under both from-scratch and continuous RLtraining setups. The code is at https://github.com/Alibaba-Quark/SSP.</description><author>Hongliang Lu, Yuhang Wen, Pengyu Cheng, Ruijin Ding, Haotian Xu, Jiaqi Guo, Chutian Wang, Haonan Chen, Xiaoxi Jiang, Guanjun Jiang</author><pubDate>Tue, 21 Oct 2025 17:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18821v1</guid></item><item><title>An Explainable Hybrid AI Framework for Enhanced Tuberculosis and Symptom Detection</title><link>http://arxiv.org/abs/2510.18819v1</link><description>Tuberculosis remains a critical global health issue, particularly inresource-limited and remote areas. Early detection is vital for treatment, yetthe lack of skilled radiologists underscores the need for artificialintelligence (AI)-driven screening tools. Developing reliable AI models ischallenging due to the necessity for large, high-quality datasets, which arecostly to obtain. To tackle this, we propose a teacher--student framework whichenhances both disease and symptom detection on chest X-rays by integrating twosupervised heads and a self-supervised head. Our model achieves an accuracy of98.85% for distinguishing between COVID-19, tuberculosis, and normal cases, anda macro-F1 score of 90.09% for multilabel symptom detection, significantlyoutperforming baselines. The explainability assessments also show the modelbases its predictions on relevant anatomical features, demonstrating promisefor deployment in clinical screening and triage settings.</description><author>Neel Patel, Alexander Wong, Ashkan Ebadi</author><pubDate>Tue, 21 Oct 2025 17:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18819v1</guid></item><item><title>Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring</title><link>http://arxiv.org/abs/2510.18817v1</link><description>Small Language Models (SLMs) are becoming increasingly popular in specializedfields, such as industrial applications, due to their efficiency, lowercomputational requirements, and ability to be fine-tuned for domain-specifictasks, enabling accurate and cost-effective solutions. However, performingcomplex reasoning using SLMs in specialized fields such as Industry 4.0 remainschallenging. In this paper, we propose a knowledge distillation framework forindustrial asset health, which transfers reasoning capabilities viaChain-of-Thought (CoT) distillation from Large Language Models (LLMs) tosmaller, more efficient models (SLMs). We discuss the advantages and theprocess of distilling LLMs using multi-choice question answering (MCQA) promptsto enhance reasoning and refine decision-making. We also perform in-contextlearning to verify the quality of the generated knowledge and benchmark theperformance of fine-tuned SLMs with generated knowledge against widely usedLLMs. The results show that the fine-tuned SLMs with CoT reasoning outperformthe base models by a significant margin, narrowing the gap to their LLMcounterparts. Our code is open-sourced at:https://github.com/IBM/FailureSensorIQ.</description><author>Shuxin Lin, Dhaval Patel, Christodoulos Constantinides</author><pubDate>Tue, 21 Oct 2025 17:18:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18817v1</guid></item><item><title>The Shift Towards Preprints in AI Policy Research: A Comparative Study of Preprint Trends in the U.S., Europe, and South Korea</title><link>http://arxiv.org/abs/2505.03835v2</link><description>The adoption of open science has quickly changed how artificial intelligence(AI) policy research is distributed globally. This study examines the regionaltrends in the citation of preprints, specifically focusing on the impact of twomajor disruptive events: the COVID-19 pandemic and the release of ChatGPT, onresearch dissemination patterns in the United States, Europe, and South Koreafrom 2015 to 2024. Using bibliometrics data from the Web of Science, this studytracks how global disruptive events influenced the adoption of preprints in AIpolicy research and how such shifts vary by region. By marking the timing ofthese disruptive events, the analysis reveals that while all regionsexperienced growth in preprint citations, the magnitude and trajectory ofchange varied significantly. The United States exhibited sharp, event-drivenincreases; Europe demonstrated institutional growth; and South Korea maintainedconsistent, linear growth in preprint adoption. These findings suggest thatglobal disruptions may have accelerated preprint adoption, but the extent andtrajectory are shaped by local research cultures, policy environments, andlevels of open science maturity. This paper emphasizes the need for future AIgovernance strategies to consider regional variability in researchdissemination and highlights opportunities for further longitudinal andcomparative research to deepen our understanding of open-access adoption in AIpolicy development.</description><author>Simon Suh</author><pubDate>Tue, 21 Oct 2025 17:17:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.03835v2</guid></item><item><title>Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning without Rewards</title><link>http://arxiv.org/abs/2510.18814v1</link><description>We present a simple, self-help online supervised finetuning (OSFT) paradigmfor LLM reasoning. In this paradigm, the model generates its own responses andis immediately finetuned on this self-generated data. OSFT is a highlyefficient training strategy for LLM reasoning, as it is reward-free and usesjust one rollout by default. Experiment results show that OSFT achievesdownstream performance on challenging mathematical reasoning tasks comparableto strong reinforcement learning with verifiable rewards (RLVR) methods such asGRPO. Our ablation study further demonstrates the efficiency and robustness ofOSFT. The major mechanism of OSFT lies in facilitating the model's own existingpreference (latent knowledge) learned from pretraining, which leads toreasoning ability improvement. We believe that OSFT offers an efficient andpromising alternative to more complex, reward-based training paradigms. Ourcode is available at https://github.com/ElementQi/OnlineSFT.</description><author>Mengqi Li, Lei Zhao, Anthony Man-Cho So, Ruoyu Sun, Xiao Li</author><pubDate>Tue, 21 Oct 2025 17:15:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18814v1</guid></item><item><title>Glyph: Scaling Context Windows via Visual-Text Compression</title><link>http://arxiv.org/abs/2510.17800v2</link><description>Large language models (LLMs) increasingly rely on long-context modeling fortasks such as document understanding, code analysis, and multi-step reasoning.However, scaling context windows to the million-token level brings prohibitivecomputational and memory costs, limiting the practicality of long-context LLMs.In this work, we take a different perspective-visual context scaling-to tacklethis challenge. Instead of extending token-based sequences, we propose Glyph, aframework that renders long texts into images and processes them withvision-language models (VLMs). This approach substantially compresses textualinput while preserving semantic information, and we further design anLLM-driven genetic search to identify optimal visual rendering configurationsfor balancing accuracy and compression. Through extensive experiments, wedemonstrate that our method achieves 3-4x token compression while maintainingaccuracy comparable to leading LLMs such as Qwen3-8B on various long-contextbenchmarks. This compression also leads to around 4x faster prefilling anddecoding, and approximately 2x faster SFT training. Furthermore, under extremecompression, a 128K-context VLM could scale to handle 1M-token-level texttasks. In addition, the rendered text data benefits real-world multimodaltasks, such as document understanding. Our code and model are released athttps://github.com/thu-coai/Glyph.</description><author>Jiale Cheng, Yusen Liu, Xinyu Zhang, Yulin Fei, Wenyi Hong, Ruiliang Lyu, Weihan Wang, Zhe Su, Xiaotao Gu, Xiao Liu, Yushi Bai, Jie Tang, Hongning Wang, Minlie Huang</author><pubDate>Tue, 21 Oct 2025 17:12:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.17800v2</guid></item><item><title>SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents</title><link>http://arxiv.org/abs/2510.17017v2</link><description>Large language model (LLM) based search agents iteratively generate queries,retrieve external information, and reason to answer open-domain questions.While researchers have primarily focused on improving their utility, theirsafety behaviors remain underexplored. In this paper, we first evaluate searchagents using red-teaming datasets and find that they are more likely to produceharmful outputs than base LLMs. For example, when asked "How can I tracksomeone's location without their consent?", a base model refuses, whereas asearch agent designed to retrieve and cite sources may lower its refusalthreshold, fetch documents (e.g., court cases), and, once appended, synthesizethem into an informative yet unsafe summary. We further show thatutility-oriented fine-tuning intensifies this risk, motivating joint alignmentof safety and utility. We present SafeSearch, a multi-objective reinforcementlearning approach that couples a final-output safety/utility reward with anovel query-level shaping term that penalizes unsafe queries and rewards safeones. Experiments show that SafeSearch reduces agent harmfulness by over 70%across three red-teaming datasets while producing safe, helpful responses, andmatches the QA performance of a utility-only finetuned agent; further analysesconfirm the effectiveness of the query-level reward in jointly improving safetyand utility.</description><author>Qiusi Zhan, Angeline Budiman-Chan, Abdelrahman Zayed, Xingzhi Guo, Daniel Kang, Joo-Kyung Kim</author><pubDate>Tue, 21 Oct 2025 17:12:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.17017v2</guid></item><item><title>Stochastic Path Planning in Correlated Obstacle Fields</title><link>http://arxiv.org/abs/2509.19559v2</link><description>We introduce the Stochastic Correlated Obstacle Scene (SCOS) problem, anavigation setting with spatially correlated obstacles of uncertain blockagestatus, realistically constrained sensors that provide noisy readings andcostly disambiguation. Modeling the spatial correlation with Gaussian RandomField (GRF), we develop Bayesian belief updates that refine blockageprobabilities, and use the posteriors to reduce search space for efficiency. Tofind the optimal traversal policy, we propose a novel two-stage learningframework. An offline phase learns a robust base policy via optimistic policyiteration augmented with information bonus to encourage exploration ininformative regions, followed by an online rollout policy with periodic baseupdates via a Bayesian mechanism for information adaptation. This frameworksupports both Monte Carlo point estimation and distributional reinforcementlearning (RL) to learn full cost distributions, leading to stronger uncertaintyquantification. We establish theoretical benefits of correlation-aware updatingand convergence property under posterior sampling. Comprehensive empiricalevaluations across varying obstacle densities, sensor capabilities demonstrateconsistent performance gains over baselines. This framework addressesnavigation challenges in environments with adversarial interruptions orclustered natural hazards.</description><author>Li Zhou, Elvan Ceyhan</author><pubDate>Tue, 21 Oct 2025 17:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.19559v2</guid></item><item><title>A Geometric Approach to Steerable Convolutions</title><link>http://arxiv.org/abs/2510.18813v1</link><description>In contrast to the somewhat abstract, group theoretical approach adopted bymany papers, our work provides a new and more intuitive derivation of steerableconvolutional neural networks in $d$ dimensions. This derivation is based ongeometric arguments and fundamental principles of pattern matching. We offer anintuitive explanation for the appearance of the Clebsch--Gordan decompositionand spherical harmonic basis functions. Furthermore, we suggest a novel way toconstruct steerable convolution layers using interpolation kernels that improveupon existing implementation, and offer greater robustness to noisy data.</description><author>Soumyabrata Kundu, Risi Kondor</author><pubDate>Tue, 21 Oct 2025 17:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18813v1</guid></item><item><title>H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical Imaging</title><link>http://arxiv.org/abs/2502.14221v3</link><description>3D landmark detection is a critical task in medical image analysis, andaccurately detecting anatomical landmarks is essential for subsequent medicalimaging tasks. However, mainstream deep learning methods in this field struggleto simultaneously capture fine-grained local features and model global spatialrelationships, while maintaining a balance between accuracy and computationalefficiency. Local feature extraction requires capturing fine-grained anatomicaldetails, while global modeling requires understanding the spatial relationshipswithin complex anatomical structures. The high-dimensional nature of 3D volumefurther exacerbates these challenges, as landmarks are sparsely distributed,leading to significant computational costs. Therefore, achieving efficient andprecise 3D landmark detection remains a pressing challenge in medical imageanalysis. In this work, We propose a \textbf{H}ybrid \textbf{3}D \textbf{DE}tection\textbf{Net}(H3DE-Net), a novel framework that combines CNNs for local featureextraction with a lightweight attention mechanism designed to efficientlycapture global dependencies in 3D volumetric data. This mechanism employs ahierarchical routing strategy to reduce computational cost while maintainingglobal context modeling. To our knowledge, H3DE-Net is the first 3D landmarkdetection model that integrates such a lightweight attention mechanism withCNNs. Additionally, integrating multi-scale feature fusion further enhancesdetection accuracy and robustness. Experimental results on a public CT datasetdemonstrate that H3DE-Net achieves state-of-the-art(SOTA) performance,significantly improving accuracy and robustness, particularly in scenarios withmissing landmarks or complex anatomical variations. We aready open-source ourproject, including code, data and model weights.</description><author>Zhen Huang, Tao Tang, Ronghao Xu, Yangbo Wei, Wenkai Yang, Suhua Wang, Xiaoxin Sun, Han Li, Qingsong Yao</author><pubDate>Tue, 21 Oct 2025 17:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.14221v3</guid></item><item><title>Enhancing Fractional Gradient Descent with Learned Optimizers</title><link>http://arxiv.org/abs/2510.18783v1</link><description>Fractional Gradient Descent (FGD) offers a novel and promising way toaccelerate optimization by incorporating fractional calculus into machinelearning. Although FGD has shown encouraging initial results across variousoptimization tasks, it faces significant challenges with convergence behaviorand hyperparameter selection. Moreover, the impact of its hyperparameters isnot fully understood, and scheduling them is particularly difficult innon-convex settings such as neural network training. To address these issues,we propose a novel approach called Learning to Optimize Caputo FractionalGradient Descent (L2O-CFGD), which meta-learns how to dynamically tune thehyperparameters of Caputo FGD (CFGD). Our method's meta-learned scheduleoutperforms CFGD with static hyperparameters found through an extensive searchand, in some tasks, achieves performance comparable to a fully black-boxmeta-learned optimizer. L2O-CFGD can thus serve as a powerful tool forresearchers to identify high-performing hyperparameters and gain insights onhow to leverage the history-dependence of the fractional differential inoptimization.</description><author>Jan Sobotka, Petr imnek, Pavel Kordk</author><pubDate>Tue, 21 Oct 2025 16:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18783v1</guid></item><item><title>A Unified Perspective on Optimization in Machine Learning and Neuroscience: From Gradient Descent to Neural Adaptation</title><link>http://arxiv.org/abs/2510.18812v1</link><description>Iterative optimization is central to modern artificial intelligence (AI) andprovides a crucial framework for understanding adaptive systems. This reviewprovides a unified perspective on this subject, bridging classic theory withneural network training and biological learning. Although gradient-basedmethods, powered by the efficient but biologically implausible backpropagation(BP), dominate machine learning, their computational demands can hinderscalability in high-dimensional settings. In contrast, derivative-free orzeroth-order (ZO) optimization feature computationally lighter approaches thatrely only on function evaluations and randomness. While generally less sampleefficient, recent breakthroughs demonstrate that modern ZO methods caneffectively approximate gradients and achieve performance competitive with BPin neural network models. This ZO paradigm is also particularly relevant forbiology. Its core principles of random exploration (probing) andfeedback-guided adaptation (reinforcing) parallel key mechanisms of biologicallearning, offering a mathematically principled perspective on how the brainlearns. In this review, we begin by categorizing optimization approaches basedon the order of derivative information they utilize, ranging from first-,second-, and higher-order gradient-based to ZO methods. We then explore howthese methods are adapted to the unique challenges of neural network trainingand the resulting learning dynamics. Finally, we build upon these insights toview biological learning through an optimization lens, arguing that a ZOparadigm leverages the brain's intrinsic noise as a computational resource.This framework not only illuminates our understanding of natural intelligencebut also holds vast implications for neuromorphic hardware, helping us designfast and energy-efficient AI systems that exploit intrinsic hardware noise.</description><author>Jess Garca Fernndez, Nasir Ahmad, Marcel van Gerven</author><pubDate>Tue, 21 Oct 2025 17:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18812v1</guid></item><item><title>Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization</title><link>http://arxiv.org/abs/2510.17501v2</link><description>With video exploding across social media, surveillance, and education,compressing long footage into concise yet faithful surrogates is crucial.Supervised methods learn frame/shot importance from dense labels and excelin-domain, but are costly and brittle across datasets; unsupervised methodsavoid labels but often miss high-level semantics and narrative cues. Recentzero-shot pipelines use LLMs for training-free summarization, yet remainsensitive to handcrafted prompts and dataset-specific normalization.We proposea rubric-guided, pseudo-labeled prompting framework. A small subset of humanannotations is converted into high-confidence pseudo labels and aggregated intostructured, dataset-adaptive scoring rubrics for interpretable sceneevaluation. At inference, boundary scenes (first/last) are scored from theirown descriptions, while intermediate scenes include brief summaries of adjacentsegments to assess progression and redundancy, enabling the LLM to balancelocal salience with global coherence without parameter tuning.Across threebenchmarks, our method is consistently effective. On SumMe and TVSum itachieves F1 of 57.58 and 63.05, surpassing a zero-shot baseline (56.73, 62.21)by +0.85 and +0.84 and approaching supervised performance. On the query-focusedQFVS benchmark it attains 53.79 F1, beating 53.42 by +0.37 and remaining stableacross validation videos. These results show that rubric-guided pseudolabeling, coupled with contextual prompting, stabilizes LLM-based scoring andyields a general, interpretable zero-shot paradigm for both generic andquery-focused video summarization.</description><author>Yuanli Wu, Long Zhang, Yue Du, Bin Li</author><pubDate>Tue, 21 Oct 2025 17:06:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.17501v2</guid></item><item><title>When LRP Diverges from Leave-One-Out in Transformers</title><link>http://arxiv.org/abs/2510.18810v1</link><description>Leave-One-Out (LOO) provides an intuitive measure of feature importance butis computationally prohibitive. While Layer-Wise Relevance Propagation (LRP)offers a potentially efficient alternative, its axiomatic soundness in modernTransformers remains largely under-examined. In this work, we first show thatthe bilinear propagation rules used in recent advances of AttnLRP violate theimplementation invariance axiom. We prove this analytically and confirm itempirically in linear attention layers. Second, we also revisit CP-LRP as adiagnostic baseline and find that bypassing relevance propagation through thesoftmax layer -- backpropagating relevance only through the value matrices --significantly improves alignment with LOO, particularly in middle-to-lateTransformer layers. Overall, our results suggest that (i) bilinearfactorization sensitivity and (ii) softmax propagation error potentiallyjointly undermine LRP's ability to approximate LOO in Transformers.</description><author>Weiqiu You, Siqi Zeng, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao</author><pubDate>Tue, 21 Oct 2025 17:06:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18810v1</guid></item><item><title>Improving the fact-checking performance of language models by relying on their entailment ability</title><link>http://arxiv.org/abs/2505.15050v3</link><description>Automated fact-checking has been a challenging task for the researchcommunity. Past works tried various strategies, such as end-to-end training,retrieval-augmented generation, and prompt engineering, to build robustfact-checking systems. However, their accuracy has not been very high forreal-world deployment. We, on the other hand, propose a simple yet effectivestrategy, where entailed justifications generated by LLMs are used to trainencoder-only language models (ELMs) for fact-checking. We conducted a rigorousset of experiments, comparing our approach with recent works and variousprompting and fine-tuning strategies to demonstrate the superiority of ourapproach. Additionally, we did quality analysis of model explanations, ablationstudies, and error analysis to provide a comprehensive understanding of ourapproach.</description><author>Gaurav Kumar, Debajyoti Mazumder, Ayush Garg, Jasabanta Patro</author><pubDate>Tue, 21 Oct 2025 17:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.15050v3</guid></item><item><title>On Biologically Plausible Learning in Continuous Time</title><link>http://arxiv.org/abs/2510.18808v1</link><description>Biological learning unfolds continuously in time, yet most algorithmic modelsrely on discrete updates and separate inference and learning phases. We study acontinuous-time neural model that unifies several biologically plausiblelearning algorithms and removes the need for phase separation. Rules includingstochastic gradient descent (SGD), feedback alignment (FA), direct feedbackalignment (DFA), and Kolen-Pollack (KP) emerge naturally as limiting cases ofthe dynamics. Simulations show that these continuous-time networks stably learnat biological timescales, even under temporal mismatches and integration noise.Through analysis and simulation, we show that learning depends on temporaloverlap: a synapse updates correctly only when its input and the correspondingerror signal coincide in time. When inputs are held constant, learning strengthdeclines linearly as the delay between input and error approaches the stimulusduration, explaining observed robustness and failure across network depths.Critically, robust learning requires the synaptic plasticity timescale toexceed the stimulus duration by one to two orders of magnitude. For typicalcortical stimuli (tens of milliseconds), this places the functional plasticitywindow in the few-second range, a testable prediction that identifiesseconds-scale eligibility traces as necessary for error-driven learning inbiological circuits.</description><author>Marc Gong Bacvanski, Liu Ziyin, Tomaso Poggio</author><pubDate>Tue, 21 Oct 2025 17:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18808v1</guid></item><item><title>Janus-Pro-R1: Advancing Collaborative Visual Comprehension and Generation via Reinforcement Learning</title><link>http://arxiv.org/abs/2506.01480v2</link><description>Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unifyvisual comprehension and generation. However, these two capabilities remainlargely independent, as if they are two separate functions encapsulated withinthe same model. Consequently, visual comprehension does not enhance visualgeneration, and the reasoning mechanisms of LLMs have not been fully integratedto revolutionize image generation. In this paper, we propose to enable thecollaborative co-evolution of visual comprehension and generation, advancingimage generation into an iterative introspective process. We introduce atwo-stage training approach: supervised fine-tuning teaches the MLLM with thefoundational ability to generate genuine CoT for visual generation, whilereinforcement learning activates its full potential via anexploration-exploitation trade-off. Ultimately, we unlock the Aha moment invisual generation, advancing MLLMs from text-to-image tasks to unified imagegeneration. Extensive experiments demonstrate that our model not only excels intext-to-image generation and image editing, but also functions as a superiorimage semantic evaluator with enhanced visual comprehension capabilities.Project Page: https://janus-pro-r1.github.io.</description><author>Kaihang Pan, Yang Wu, Wendong Bu, Kai Shen, Juncheng Li, Yingting Wang, Yunfei Li, Siliang Tang, Jun Xiao, Fei Wu, Hang Zhao, Yueting Zhuang</author><pubDate>Tue, 21 Oct 2025 17:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.01480v2</guid></item><item><title>Inverse Q-Learning Done Right: Offline Imitation Learning in $Q^$-Realizable MDPs</title><link>http://arxiv.org/abs/2505.19946v3</link><description>We study the problem of offline imitation learning in Markov decisionprocesses (MDPs), where the goal is to learn a well-performing policy given adataset of state-action pairs generated by an expert policy. Complementing arecent line of work on this topic that assumes the expert belongs to atractable class of known policies, we approach this problem from a new angleand leverage a different type of structural assumption about the environment.Specifically, for the class of linear $Q^\pi$-realizable MDPs, we introduce anew algorithm called saddle-point offline imitation learning (\SPOIL), which isguaranteed to match the performance of any expert up to an additive error$\varepsilon$ with access to $\mathcal{O}(\varepsilon^{-2})$ samples. Moreover,we extend this result to possibly non-linear $Q^\pi$-realizable MDPs at thecost of a worse sample complexity of order $\mathcal{O}(\varepsilon^{-4})$.Finally, our analysis suggests a new loss function for training critic networksfrom expert data in deep imitation learning. Empirical evaluations on standardbenchmarks demonstrate that the neural net implementation of \SPOIL is superiorto behavior cloning and competitive with state-of-the-art algorithms.</description><author>Antoine Moulin, Gergely Neu, Luca Viano</author><pubDate>Tue, 21 Oct 2025 16:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2505.19946v3</guid></item><item><title>Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location</title><link>http://arxiv.org/abs/2510.18803v1</link><description>Optimizing national scientific investment requires a clear understanding ofevolving research trends and the demographic and geographical forces shapingthem, particularly in light of commitments to equity, diversity, and inclusion.This study addresses this need by analyzing 18 years (2005-2022) of researchproposals funded by the Natural Sciences and Engineering Research Council ofCanada (NSERC). We conducted a comprehensive comparative evaluation of threetopic modelling approaches: Latent Dirichlet Allocation (LDA), Structural TopicModelling (STM), and BERTopic. We also introduced a novel algorithm, namedCOFFEE, designed to enable robust covariate effect estimation for BERTopic.This advancement addresses a significant gap, as BERTopic lacks a nativefunction for covariate analysis, unlike the probabilistic STM. Our findingshighlight that while all models effectively delineate core scientific domains,BERTopic outperformed by consistently identifying more granular, coherent, andemergent themes, such as the rapid expansion of artificial intelligence.Additionally, the covariate analysis, powered by COFFEE, confirmed distinctprovincial research specializations and revealed consistent gender-basedthematic patterns across various scientific disciplines. These insights offer arobust empirical foundation for funding organizations to formulate moreequitable and impactful funding strategies, thereby enhancing the effectivenessof the scientific ecosystem.</description><author>Shirin Tavakoli Kafiabad, Andrea Schiffauerova, Ashkan Ebadi</author><pubDate>Tue, 21 Oct 2025 16:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18803v1</guid></item><item><title>Computational Foundations for Strategic Coopetition: Formalizing Interdependence and Complementarity</title><link>http://arxiv.org/abs/2510.18802v1</link><description>Modern socio-technical systems are characterized by strategic coopetitionwhere actors simultaneously cooperate to create value and compete to captureit. While conceptual modeling languages like i* provide rich qualitativerepresentations of strategic dependencies, they lack mechanisms forquantitative analysis of dynamic trade-offs. Conversely, classical game theoryoffers mathematical rigor but strips away contextual richness. This technicalreport bridges this gap by developing computational foundations that formalizetwo critical dimensions of coopetition: interdependence and complementarity. Weground interdependence in i* structural dependency analysis, translatingdepender-dependee-dependum relationships into quantitative interdependencecoefficients through a structured translation framework. We formalizecomplementarity following Brandenburger and Nalebuff's Added Value concept,modeling synergistic value creation with validated parameterization. Weintegrate structural dependencies with bargaining power in value appropriationand introduce a game-theoretic formulation where Nash Equilibrium incorporatesstructural interdependence. Validation combines comprehensive experimentaltesting across power and logarithmic value function specifications,demonstrating functional form robustness, with empirical application to theSamsung-Sony S-LCD joint venture (2004-2011), where logarithmic specificationsachieve superior empirical fit (validation score 45/60) while power functionsprovide theoretical tractability. This technical report serves as thefoundational reference for a coordinated research program examining strategiccoopetition in requirements engineering and multi-agent systems, with companionwork addressing trust dynamics, team production, and reciprocity mechanisms.</description><author>Vik Pant, Eric Yu</author><pubDate>Tue, 21 Oct 2025 16:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18802v1</guid></item><item><title>WebSeer: Training Deeper Search Agents through Reinforcement Learning with Self-Reflection</title><link>http://arxiv.org/abs/2510.18798v1</link><description>Search agents have achieved significant advancements in enabling intelligentinformation retrieval and decision-making within interactive environments.Although reinforcement learning has been employed to train agentic modelscapable of more dynamic interactive retrieval, existing methods are limited byshallow tool-use depth and the accumulation of errors over multiple iterativeinteractions. In this paper, we present WebSeer, a more intelligent searchagent trained via reinforcement learning enhanced with a self-reflectionmechanism. Specifically, we construct a large dataset annotated with reflectionpatterns and design a two-stage training framework that unifies cold start andreinforcement learning within the self-reflection paradigm for real-worldweb-based environments, which enables the model to generate longer and morereflective tool-use trajectories. Our approach substantially extends tool-usechains and improves answer accuracy. Using a single 14B model, we achievestate-of-the-art results on HotpotQA and SimpleQA, with accuracies of 72.3% and90.0%, respectively, and demonstrate strong generalization toout-of-distribution datasets. The code is available athttps://github.com/99hgz/WebSeer</description><author>Guanzhong He, Zhen Yang, Jinxin Liu, Bin Xu, Lei Hou, Juanzi Li</author><pubDate>Tue, 21 Oct 2025 16:52:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18798v1</guid></item><item><title>ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder</title><link>http://arxiv.org/abs/2510.18795v1</link><description>The original CLIP text encoder is limited by a maximum input length of 77tokens, which hampers its ability to effectively process long texts and performfine-grained semantic understanding. In addition, the CLIP text encoder lackssupport for multilingual inputs. All these limitations significantly restrictits applicability across a broader range of tasks. Recent studies haveattempted to replace the CLIP text encoder with an LLM-based embedder toenhance its ability in processing long texts, multilingual understanding, andfine-grained semantic comprehension. However, because the representation spacesof LLMs and the vision-language space of CLIP are pretrained independentlywithout alignment priors, direct alignment using contrastive learning candisrupt the intrinsic vision-language alignment in the CLIP image encoder,leading to an underutilization of the knowledge acquired during pre-training.To address this challenge, we propose ProCLIP, a curriculum learning-basedprogressive vision-language alignment framework to effectively align the CLIPimage encoder with an LLM-based embedder. Specifically, ProCLIP first distillsknowledge from CLIP's text encoder into the LLM-based embedder to leverageCLIP's rich pretrained knowledge while establishing initial alignment betweenthe LLM embedder and CLIP image encoder. Subsequently, ProCLIP further alignsthe CLIP image encoder with the LLM-based embedder through image-textcontrastive tuning, employing self-distillation regularization to avoidoverfitting. To achieve a more effective alignment, instance semantic alignmentloss and embedding structure alignment loss are employed during representationinheritance and contrastive tuning. The Code is available athttps://github.com/VisionXLab/ProCLIP</description><author>Xiaoxing Hu, Kaicheng Yang, Ziyong Feng, Qi Ming, Zonghao Guo, Xiang An, Ziyong Feng, Junchi Yan, Xue Yang</author><pubDate>Tue, 21 Oct 2025 16:48:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18795v1</guid></item><item><title>Viability of perturbative expansion for quantum field theories on neurons</title><link>http://arxiv.org/abs/2508.03810v3</link><description>Neural Network (NN) architectures that break statistical independence ofparameters have been proposed as a new approach for simulating local quantumfield theories (QFTs). In the infinite neuron number limit, single-layer NNscan exactly reproduce QFT results. This paper examines the viability of thisarchitecture for perturbative calculations of local QFTs for finite neuronnumber $N$ using scalar $\phi^4$ theory in $d$ Euclidean dimensions as anexample. We find that the renormalized $O(1/N)$ corrections to two- andfour-point correlators yield perturbative series which are sensitive to theultraviolet cut-off and therefore have a weak convergence. We propose amodification to the architecture to improve this convergence and discussconstraints on the parameters of the theory and the scaling of N which allow usto extract accurate field theory results.</description><author>Srimoyee Sen, Varun Vaidya</author><pubDate>Tue, 21 Oct 2025 16:47:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.03810v3</guid></item><item><title>Protein generation with embedding learning for motif diversification</title><link>http://arxiv.org/abs/2510.18790v1</link><description>A fundamental challenge in protein design is the trade-off between generatingstructural diversity while preserving motif biological function. Currentstate-of-the-art methods, such as partial diffusion in RFdiffusion, often failto resolve this trade-off: small perturbations yield motifs nearly identical tothe native structure, whereas larger perturbations violate the geometricconstraints necessary for biological function. We introduce Protein Generationwith Embedding Learning (PGEL), a general framework that learnshigh-dimensional embeddings encoding sequence and structural features of atarget motif in the representation space of a diffusion model's frozendenoiser, and then enhances motif diversity by introducing controlledperturbations in the embedding space. PGEL is thus able to loosen geometricconstraints while satisfying typical design metrics, leading to more diverseyet viable structures. We demonstrate PGEL on three representative cases: amonomer, a protein-protein interface, and a cancer-related transcription factorcomplex. In all cases, PGEL achieves greater structural diversity, betterdesignability, and improved self-consistency, as compared to partial diffusion.Our results establish PGEL as a general strategy for embedding-driven proteingeneration allowing for systematic, viable diversification of functionalmotifs.</description><author>Kevin Michalewicz, Chen Jin, Philip Alexander Teare, Tom Diethe, Mauricio Barahona, Barbara Bravi, Asher Mullokandov</author><pubDate>Tue, 21 Oct 2025 16:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18790v1</guid></item><item><title>Stick-Breaking Embedded Topic Model with Continuous Optimal Transport for Online Analysis of Document Streams</title><link>http://arxiv.org/abs/2510.18786v1</link><description>Online topic models are unsupervised algorithms to identify latent topics indata streams that continuously evolve over time. Although these methodsnaturally align with real-world scenarios, they have received considerably lessattention from the community compared to their offline counterparts, due tospecific additional challenges. To tackle these issues, we present SB-SETM, aninnovative model extending the Embedded Topic Model (ETM) to process datastreams by merging models formed on successive partial document batches. Tothis end, SB-SETM (i) leverages a truncated stick-breaking construction for thetopic-per-document distribution, enabling the model to automatically infer fromthe data the appropriate number of active topics at each timestep; and (ii)introduces a merging strategy for topic embeddings based on a continuousformulation of optimal transport adapted to the high dimensionality of thelatent topic space. Numerical experiments show SB-SETM outperforming baselineson simulated scenarios. We extensively test it on a real-world corpus of newsarticles covering the Russian-Ukrainian war throughout 2022-2023.</description><author>Federica Granese, Serena Villata, Charles Bouveyron</author><pubDate>Tue, 21 Oct 2025 16:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18786v1</guid></item><item><title>CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training</title><link>http://arxiv.org/abs/2510.18784v1</link><description>Despite significant work on low-bit quantization-aware training (QAT), thereis still a large accuracy gap between such techniques and native training. Toaddress this, we introduce CAGE (Curvature-Aware Gradient Estimation), a newQAT method that augments the straight-through estimator (STE) gradient with acurvature-aware correction designed to counteract the loss increase induced byquantization. CAGE is derived from a multi-objective view of QAT that balancesloss minimization with adherence to quantization constraints, yielding aprincipled correction term that depends on local curvature information. On thetheoretical side, we introduce the notion of Pareto-optimal solutions forquantized optimization, and establish that CAGE yields strong convergenceguarantees in the smooth non-convex setting. In terms of implementation, ourapproach is optimizer-agnostic, but we provide a highly-efficientimplementation that leverages Adam statistics. When pre-training Llama-stylemodels of up to 800M-parameters, CAGE recovers over 10% of thequantization-induced loss increase in the W4A4 regime over outlier-mitigationmethods. These results indicate that curvature-aware gradient corrections canbridge the remaining performance gap beyond current outlier-handling methods.</description><author>Soroush Tabesh, Mher Safaryan, Dan Alistarh</author><pubDate>Tue, 21 Oct 2025 16:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18784v1</guid></item><item><title>How to Evaluate Monocular Depth Estimation?</title><link>http://arxiv.org/abs/2510.19814v1</link><description>Monocular depth estimation is an important task with rapid progress, but howto evaluate it remains an open question, as evidenced by a lack ofstandardization in existing literature and a large selection of evaluationmetrics whose trade-offs and behaviors are not well understood. This papercontributes a novel, quantitative analysis of existing metrics in terms oftheir sensitivity to various types of perturbations of ground truth,emphasizing comparison to human judgment. Our analysis reveals that existingmetrics are severely under-sensitive to curvature perturbation such as makingflat surfaces wavy. To remedy this, we introduce a new metric based on relativesurface normals, along with new depth visualization tools and a principledmethod to create composite metrics with better human alignment. Code and dataare available at: https://github.com/princeton-vl/evalmde.</description><author>Siyang Wu, Jack Nugent, Willow Yang, Jia Deng</author><pubDate>Wed, 22 Oct 2025 17:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.19814v1</guid></item><item><title>Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection</title><link>http://arxiv.org/abs/2510.18781v1</link><description>A recent class of hyperspectral anomaly detection methods that can be trainedonce on background datasets and then universally deployed -- without per-sceneretraining or parameter tuning -- has demonstrated remarkable efficiency androbustness. Building upon this paradigm, we focus on the integration ofspectral and spatial cues and introduce a novel "Rebellious Student" frameworkfor complementary feature learning. Unlike conventional teacher-studentparadigms driven by imitation, our method intentionally trains the spatialbranch to diverge from the spectral teacher, thereby learning complementaryspatial patterns that the teacher fails to capture. A two-stage learningstrategy is adopted: (1) a spectral enhancement network is first trained viareverse distillation to obtain robust background spectral representations; and(2) a spatial network -- the rebellious student -- is subsequently optimizedusing decorrelation losses that enforce feature orthogonality while maintainingreconstruction fidelity to avoid irrelevant noise. Once trained, the frameworkenhances both spectral and spatial background features, enabling parameter-freeand training-free anomaly detection when paired with conventional detectors.Extensive experiments on the HAD100 benchmark show substantial improvementsover several established baselines with minimal computational overhead,confirming the effectiveness and generality of the proposed complementarylearning paradigm. Our code is publicly available athttps://github.com/xjpp2016/FERS.</description><author>Wenping Jin, Yuyang Tang, Li Zhu, Fei Guo</author><pubDate>Tue, 21 Oct 2025 16:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18781v1</guid></item><item><title>VideoVerse: How Far is Your T2V Generator from a World Model?</title><link>http://arxiv.org/abs/2510.08398v2</link><description>The recent rapid advancement of Text-to-Video (T2V) generation technologies,which are critical to build ``world models'', makes the existing benchmarksincreasingly insufficient to evaluate state-of-the-art T2V models. First,current evaluation dimensions, such as per-frame aesthetic quality and temporalconsistency, are no longer able to differentiate state-of-the-art T2V models.Second, event-level temporal causality, which not only distinguishes video fromother modalities but also constitutes a crucial component of world models, isseverely underexplored in existing benchmarks. Third, existing benchmarks lacka systematic assessment of world knowledge, which are essential capabilitiesfor building world models. To address these issues, we introduce VideoVerse, acomprehensive benchmark that focuses on evaluating whether a T2V model couldunderstand complex temporal causality and world knowledge in the real world. Wecollect representative videos across diverse domains (e.g., natural landscapes,sports, indoor scenes, science fiction, chemical and physical experiments) andextract their event-level descriptions with inherent temporal causality, whichare then rewritten into text-to-video prompts by independent annotators. Foreach prompt, we design a suite of binary evaluation questions from theperspective of dynamic and static properties, with a total of ten carefullydefined evaluation dimensions. In total, our VideoVerse comprises 300 carefullycurated prompts, involving 815 events and 793 binary evaluation questions.Consequently, a human preference aligned QA-based evaluation pipeline isdeveloped by using modern vision-language models. Finally, we perform asystematic evaluation of state-of-the-art open-source and closed-source T2Vmodels on VideoVerse, providing in-depth analysis on how far the current T2Vgenerators are from world models.</description><author>Zeqing Wang, Xinyu Wei, Bairui Li, Zhen Guo, Jinrui Zhang, Hongyang Wei, Keze Wang, Lei Zhang</author><pubDate>Tue, 21 Oct 2025 16:28:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.08398v2</guid></item><item><title>KAT-Coder Technical Report</title><link>http://arxiv.org/abs/2510.18779v1</link><description>Recent advances in large language models (LLMs) have enabled progress inagentic coding, where models autonomously reason, plan, and act withininteractive software development workflows. However, bridging the gap betweenstatic text-based training and dynamic real-world agentic execution remains acore challenge. In this technical report, we present KAT-Coder, a large-scaleagentic code model trained through a multi-stage curriculum encompassingMid-Term Training, Supervised Fine-Tuning (SFT), Reinforcement Fine-Tuning(RFT), and Reinforcement-to-Deployment Adaptation. The Mid-Term stage enhancesreasoning, planning, and reflection capabilities through a corpus of realsoftware engineering data and synthetic agentic interactions. The SFT stageconstructs a million-sample dataset balancing twenty programming languages, tendevelopment contexts, and ten task archetypes. The RFT stage introduces a novelmulti-ground-truth reward formulation for stable and sample-efficient policyoptimization. Finally, the Reinforcement-to-Deployment phase adapts the modelto production-grade IDE environments using Error-Masked SFT and Tree-StructuredTrajectory Training. In summary, these stages enable KAT-Coder to achieverobust tool-use reliability, instruction alignment, and long-context reasoning,forming a deployable foundation for real-world intelligent coding agents. OurKAT series 32B model, KAT-Dev, has been open-sourced onhttps://huggingface.co/Kwaipilot/KAT-Dev.</description><author>Zizheng Zhan, Ken Deng, Xiaojiang Zhang, Jinghui Wang, Huaixi Tang, Zhiyi Lai, Haoyang Huang, Wen Xiang, Kun Wu, Wenhao Zhuang, Minglei Zhang, Shaojie Wang, Shangpeng Yan, Kepeng Lei, Zongxian Feng, Huiming Wang, Zheng Lin, Mengtong Li, Mengfei Xie, Yinghan Cui, Xuxing Chen, Chao Wang, Weihao Li, Wenqiang Zhu, Jiarong Zhang, Jingxuan Xu, Songwei Yu, Yifan Yao, Xinping Lei, Han Li, Junqi Xiong, Zuchen Gao, Dailin Li, Haimo Li, Jiaheng Liu, Yuqun Zhang, Junyi Peng, Haotian Zhang, Bin Chen</author><pubDate>Tue, 21 Oct 2025 16:27:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18779v1</guid></item><item><title>A Frequentist Statistical Introduction to Variational Inference, Autoencoders, and Diffusion Models</title><link>http://arxiv.org/abs/2510.18777v1</link><description>While Variational Inference (VI) is central to modern generative models likeVariational Autoencoders (VAEs) and Denoising Diffusion Models (DDMs), itspedagogical treatment is split across disciplines. In statistics, VI istypically framed as a Bayesian method for posterior approximation. In machinelearning, however, VAEs and DDMs are developed from a Frequentist viewpoint,where VI is used to approximate a maximum likelihood estimator. This creates abarrier for statisticians, as the principles behind VAEs and DDMs are hard tocontextualize without a corresponding Frequentist introduction to VI. Thispaper provides that introduction: we explain the theory for VI, VAEs, and DDMsfrom a purely Frequentist perspective, starting with the classicalExpectation-Maximization (EM) algorithm. We show how VI arises as a scalablesolution for intractable E-steps and how VAEs and DDMs are natural,deep-learning-based extensions of this framework, thereby bridging the gapbetween classical statistical inference and modern generative AI.</description><author>Yen-Chi Chen</author><pubDate>Tue, 21 Oct 2025 16:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18777v1</guid></item><item><title>UltraGen: High-Resolution Video Generation with Hierarchical Attention</title><link>http://arxiv.org/abs/2510.18775v1</link><description>Recent advances in video generation have made it possible to produce visuallycompelling videos, with wide-ranging applications in content creation,entertainment, and virtual reality. However, most existing diffusiontransformer based video generation models are limited to low-resolution outputs(&lt;=720P) due to the quadratic computational complexity of the attentionmechanism with respect to the output width and height. This computationalbottleneck makes native high-resolution video generation (1080P/2K/4K)impractical for both training and inference. To address this challenge, wepresent UltraGen, a novel video generation framework that enables i) efficientand ii) end-to-end native high-resolution video synthesis. Specifically,UltraGen features a hierarchical dual-branch attention architecture based onglobal-local attention decomposition, which decouples full attention into alocal attention branch for high-fidelity regional content and a globalattention branch for overall semantic consistency. We further propose aspatially compressed global modeling strategy to efficiently learn globaldependencies, and a hierarchical cross-window local attention mechanism toreduce computational costs while enhancing information flow across differentlocal windows. Extensive experiments demonstrate that UltraGen can effectivelyscale pre-trained low-resolution video models to 1080P and even 4K resolutionfor the first time, outperforming existing state-of-the-art methods andsuper-resolution based two-stage pipelines in both qualitative and quantitativeevaluations.</description><author>Teng Hu, Jiangning Zhang, Zihan Su, Ran Yi</author><pubDate>Tue, 21 Oct 2025 16:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18775v1</guid></item><item><title>On the hardness of RL with Lookahead</title><link>http://arxiv.org/abs/2510.19372v1</link><description>We study reinforcement learning (RL) with transition look-ahead, where theagent may observe which states would be visited upon playing any sequence of$\ell$ actions before deciding its course of action. While such predictiveinformation can drastically improve the achievable performance, we show thatusing this information optimally comes at a potentially prohibitivecomputational cost. Specifically, we prove that optimal planning with one-steplook-ahead ($\ell=1$) can be solved in polynomial time through a novel linearprogramming formulation. In contrast, for $\ell \geq 2$, the problem becomesNP-hard. Our results delineate a precise boundary between tractable andintractable cases for the problem of planning with transition look-ahead inreinforcement learning.</description><author>Corentin Pla, Hugo Richard, Marc Abeille, Nadav Merlis, Vianney Perchet</author><pubDate>Wed, 22 Oct 2025 08:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.19372v1</guid></item><item><title>AI use in American newspapers is widespread, uneven, and rarely disclosed</title><link>http://arxiv.org/abs/2510.18774v1</link><description>AI is rapidly transforming journalism, but the extent of its use in publishednewspaper articles remains unclear. We address this gap by auditing alarge-scale dataset of 186K articles from online editions of 1.5K Americannewspapers published in the summer of 2025. Using Pangram, a state-of-the-artAI detector, we discover that approximately 9% of newly-published articles areeither partially or fully AI-generated. This AI use is unevenly distributed,appearing more frequently in smaller, local outlets, in specific topics such asweather and technology, and within certain ownership groups. We also analyze45K opinion pieces from Washington Post, New York Times, and Wall StreetJournal, finding that they are 6.4 times more likely to contain AI-generatedcontent than news articles from the same publications, with many AI-flaggedop-eds authored by prominent public figures. Despite this prevalence, we findthat AI use is rarely disclosed: a manual audit of 100 AI-flagged articlesfound only five disclosures of AI use. Overall, our audit highlights theimmediate need for greater transparency and updated editorial standardsregarding the use of AI in journalism to maintain public trust.</description><author>Jenna Russell, Marzena Karpinska, Destiny Akinode, Katherine Thai, Bradley Emi, Max Spero, Mohit Iyyer</author><pubDate>Tue, 21 Oct 2025 16:22:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18774v1</guid></item><item><title>Detection and Simulation of Urban Heat Islands Using a Fine-Tuned Geospatial Foundation Model for Microclimate Impact Prediction</title><link>http://arxiv.org/abs/2510.18773v1</link><description>As urbanization and climate change progress, urban heat island effects arebecoming more frequent and severe. To formulate effective mitigation plans,cities require detailed air temperature data, yet conventional machine learningmodels with limited data often produce inaccurate predictions, particularly inunderserved areas. Geospatial foundation models trained on global unstructureddata offer a promising alternative by demonstrating strong generalization andrequiring only minimal fine-tuning. In this study, an empirical ground truth ofurban heat patterns is established by quantifying cooling effects from greenspaces and benchmarking them against model predictions to evaluate the model'saccuracy. The foundation model is subsequently fine-tuned to predict landsurface temperatures under future climate scenarios, and its practical value isdemonstrated through a simulated inpainting that highlights its role formitigation support. The results indicate that foundation models offer apowerful way for evaluating urban heat island mitigation strategies indata-scarce regions to support more climate-resilient cities.</description><author>Jannis Fleckenstein, David Kreismann, Tamara Rosemary Govindasamy, Thomas Brunschwiler, Etienne Vos, Mattia Rigotti</author><pubDate>Tue, 21 Oct 2025 16:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18773v1</guid></item><item><title>Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference</title><link>http://arxiv.org/abs/2510.18768v1</link><description>Causal inference is essential for developing and evaluating medicalinterventions, yet real-world medical datasets are often difficult to accessdue to regulatory barriers. This makes synthetic data a potentially valuableasset that enables these medical analyses, along with the development of newinference methods themselves. Generative models can produce synthetic data thatclosely approximate real data distributions, yet existing methods do notconsider the unique challenges that downstream causal inference tasks, andspecifically those focused on treatments, pose. We establish a set ofdesiderata that synthetic data containing treatments should satisfy to maximisedownstream utility: preservation of (i) the covariate distribution, (ii) thetreatment assignment mechanism, and (iii) the outcome generation mechanism.Based on these desiderata, we propose a set of evaluation metrics to assesssuch synthetic data. Finally, we present STEAM: a novel method for generatingSynthetic data for Treatment Effect Analysis in Medicine that mimics thedata-generating process of data containing treatments and optimises for ourdesiderata. We empirically demonstrate that STEAM achieves state-of-the-artperformance across our metrics as compared to existing generative models,particularly as the complexity of the true data-generating process increases.</description><author>Harry Amad, Zhaozhi Qian, Dennis Frauen, Julianna Piskorz, Stefan Feuerriegel, Mihaela van der Schaar</author><pubDate>Tue, 21 Oct 2025 16:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18768v1</guid></item><item><title>Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures</title><link>http://arxiv.org/abs/2510.10806v2</link><description>Large Language Models (LLMs) are adept at generating responses based oninformation within their context. While this ability is useful for interactingwith structured data like code files, another popular method,Retrieval-Augmented Generation (RAG), retrieves relevant documents to augmentthe model's in-context learning. However, it is not well-explored how to bestrepresent this retrieved knowledge for generating responses on structured data,particularly hierarchical structures like trees. In this work, we propose anovel bottom-up method to linearize knowledge from tree-like structures (like aGitHub repository) by generating implicit, aggregated summaries at eachhierarchical level. This approach enables the knowledge to be stored in aknowledge base and used directly with RAG. We then compare our method to usingRAG on raw, unstructured code, evaluating the accuracy and quality of thegenerated responses. Our results show that while response quality is comparableacross both methods, our approach generates over 68% fewer documents in theretriever, a significant gain in efficiency. This finding suggests thatleveraging implicit, linearized knowledge may be a highly effective andscalable strategy for handling complex, hierarchical data structures.</description><author>Mihir Gupte, Paolo Giusto, Ramesh S</author><pubDate>Tue, 21 Oct 2025 16:10:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.10806v2</guid></item><item><title>Facts are Harder Than Opinions -- A Multilingual, Comparative Analysis of LLM-Based Fact-Checking Reliability</title><link>http://arxiv.org/abs/2506.03655v2</link><description>The proliferation of misinformation necessitates scalable, automatedfact-checking solutions. Yet, current benchmarks often overlook multilingualand topical diversity. This paper introduces a novel, dynamically extensibledata set that includes 61,514 claims in multiple languages and topics,extending existing datasets up to 2024. Through a comprehensive evaluation offive prominent Large Language Models (LLMs), including GPT-4o, GPT-3.5 Turbo,LLaMA 3.1, and Mixtral 8x7B, we identify significant performance gaps betweendifferent languages and topics. While overall GPT-4o achieves the highestaccuracy, it declines to classify 43% of claims. Across all models,factual-sounding claims are misclassified more often than opinions, revealing akey vulnerability. These findings underscore the need for caution and highlightchallenges in deploying LLM-based fact-checking systems at scale.</description><author>Lorraine Saju, Arnim Bleier, Jana Lasser, Claudia Wagner</author><pubDate>Tue, 21 Oct 2025 16:09:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.03655v2</guid></item><item><title>In-Context Learning of Stochastic Differential Equations with Foundation Inference Models</title><link>http://arxiv.org/abs/2502.19049v2</link><description>Stochastic differential equations (SDEs) describe dynamical systems wheredeterministic flows, governed by a drift function, are superimposed with randomfluctuations, dictated by a diffusion function. The accurate estimation (ordiscovery) of these functions from data is a central problem in machinelearning, with wide application across the natural and social sciences. Yetcurrent solutions either rely heavily on prior knowledge of the dynamics orinvolve intricate training procedures. We introduce FIM-SDE (FoundationInference Model for SDEs), a pretrained recognition model that deliversaccurate in-context (or zero-shot) estimation of the drift and diffusionfunctions of low-dimensional SDEs, from noisy time series data, and allowsrapid finetuning to target datasets. Leveraging concepts from amortizedinference and neural operators, we (pre)train FIM-SDE in a supervised fashionto map a large set of noisy, discretely observed SDE paths onto the space ofdrift and diffusion functions. We demonstrate that FIM-SDE achieves robustin-context function estimation across a wide range of synthetic and real-worldprocesses -- from canonical SDE systems (e.g., double-well dynamics or weaklyperturbed Lorenz attractors) to stock price recordings and oil-price andwind-speed fluctuations -- while matching the performance of symbolic, Gaussianprocess and Neural SDE baselines trained on the target datasets. When finetunedto the target processes, we show that FIM-SDE consistently outperforms allthese baselines.</description><author>Patrick Seifner, Kostadin Cvejoski, David Berghaus, Cesar Ojeda, Ramses J. Sanchez</author><pubDate>Tue, 21 Oct 2025 16:08:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.19049v2</guid></item><item><title>Counterfactual reasoning: an analysis of in-context emergence</title><link>http://arxiv.org/abs/2506.05188v2</link><description>Large-scale neural language models exhibit remarkable performance inin-context learning: the ability to learn and reason about the input context onthe fly. This work studies in-context counterfactual reasoning in languagemodels, that is, the ability to predict consequences of a hypotheticalscenario. We focus on a well-defined, synthetic linear regression task thatrequires noise abduction. Accurate prediction is based on (1) inferring anunobserved latent concept and (2) copying contextual noise from factualobservations. We show that language models are capable of counterfactualreasoning. Further, we enhance existing identifiability results and reducecounterfactual reasoning for a broad class of functions to a transformation onin-context observations. In Transformers, we find that self-attention, modeldepth and pre-training data diversity drive performance. Moreover, we providemechanistic evidence that the latent concept is linearly represented in theresidual stream and we introduce designated \textit{noise abduction heads}central to performing counterfactual reasoning. Lastly, our findings extend tocounterfactual reasoning under SDE dynamics and reflect that Transformers canperform noise abduction on sequential data, providing preliminary evidence onthe potential for counterfactual story generation. Our code is available underhttps://github.com/mrtzmllr/iccr.</description><author>Moritz Miller, Bernhard Schlkopf, Siyuan Guo</author><pubDate>Tue, 21 Oct 2025 16:08:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.05188v2</guid></item><item><title>Interpretable Decision-Making for End-to-End Autonomous Driving</title><link>http://arxiv.org/abs/2508.18898v3</link><description>Trustworthy AI is mandatory for the broad deployment of autonomous vehicles.Although end-to-end approaches derive control commands directly from raw data,interpreting these decisions remains challenging, especially in complex urbanscenarios. This is mainly attributed to very deep neural networks withnon-linear decision boundaries, making it challenging to grasp the logic behindAI-driven decisions. This paper presents a method to enhance interpretabilitywhile optimizing control commands in autonomous driving. To address this, wepropose loss functions that promote the interpretability of our model bygenerating sparse and localized feature maps. The feature activations allow usto explain which image regions contribute to the predicted control command. Weconduct comprehensive ablation studies on the feature extraction step andvalidate our method on the CARLA benchmarks. We also demonstrate that ourapproach improves interpretability, which correlates with reducing infractions,yielding a safer, high-performance driving model. Notably, our monocular,non-ensemble model surpasses the top-performing approaches from the CARLALeaderboard by achieving lower infraction scores and the highest routecompletion rate, all while ensuring interpretability.</description><author>Mona Mirzaie, Bodo Rosenhahn</author><pubDate>Tue, 21 Oct 2025 16:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.18898v3</guid></item><item><title>Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation</title><link>http://arxiv.org/abs/2510.18751v1</link><description>Climate change is intensifying the occurrence of harmful algal bloom (HAB),particularly cyanobacteria, which threaten aquatic ecosystems and human healththrough oxygen depletion, toxin release, and disruption of marine biodiversity.Traditional monitoring approaches, such as manual water sampling, remainlabor-intensive and limited in spatial and temporal coverage. Recent advancesin vision-language models (VLMs) for remote sensing have shown potential forscalable AI-driven solutions, yet challenges remain in reasoning over imageryand quantifying bloom severity. In this work, we introduce ALGae Observationand Segmentation (ALGOS), a segmentation-and-reasoning system for HABmonitoring that combines remote sensing image understanding with severityestimation. Our approach integrates GeoSAM-assisted human evaluation forhigh-quality segmentation mask curation and fine-tunes vision language model onseverity prediction using the Cyanobacteria Aggregated Manual Labels (CAML)from NASA. Experiments demonstrate that ALGOS achieves robust performance onboth segmentation and severity-level estimation, paving the way towardpractical and automated cyanobacterial monitoring systems.</description><author>Patterson Hsieh, Jerry Yeh, Mao-Chi He, Wen-Han Hsieh, Elvis Hsieh</author><pubDate>Tue, 21 Oct 2025 15:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18751v1</guid></item><item><title>Symbolic Emulators for Cosmology: Accelerating Cosmological Analyses Without Sacrificing Precision</title><link>http://arxiv.org/abs/2510.18749v1</link><description>In cosmology, emulators play a crucial role by providing fast and accuratepredictions of complex physical models, enabling efficient exploration ofhigh-dimensional parameter spaces that would be computationally prohibitivewith direct numerical simulations. Symbolic emulators have emerged as promisingalternatives to numerical approaches, delivering comparable accuracy withsignificantly faster evaluation times. While previous symbolic emulators werelimited to relatively narrow prior ranges, we expand these to cover theparameter space relevant for current cosmological analyses. We introduceapproximations to hypergeometric functions used for the $\Lambda$CDM comovingdistance and linear growth factor which are accurate to better than 0.001% and0.05%, respectively, for all redshifts and for $\Omega_{\rm m} \in [0.1, 0.5]$.We show that integrating symbolic emulators into a Dark Energy Survey-like$3\times2$pt analysis produces cosmological constraints consistent with thoseobtained using standard numerical methods. Our symbolic emulators offersubstantial improvements in speed and memory usage, demonstrating theirpractical potential for scalable, likelihood-based inference.</description><author>Deaglan J. Bartlett, Shivam Pandey</author><pubDate>Tue, 21 Oct 2025 15:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18749v1</guid></item><item><title>Learning to See and Act: Task-Aware View Planning for Robotic Manipulation</title><link>http://arxiv.org/abs/2508.05186v2</link><description>Recent vision-language-action (VLA) models for multi-task roboticmanipulation commonly rely on static viewpoints and shared visual encoders,which limit 3D perception and cause task interference, hindering robustness andgeneralization. In this work, we propose Task-Aware View Planning (TAVP), aframework designed to overcome these challenges by integrating active viewplanning with task-specific representation learning. TAVP employs an efficientexploration policy, accelerated by a novel pseudo-environment, to activelyacquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)visual encoder to disentangle features across different tasks, boosting bothrepresentation fidelity and task generalization. By learning to see the worldin a task-aware way, TAVP generates more complete and discriminative visualrepresentations, demonstrating significantly enhanced action prediction acrossa wide array of manipulation challenges. Extensive experiments on RLBench tasksshow that our proposed TAVP model achieves superior performance overstate-of-the-art fixed-view approaches. Visual results and code are providedat: https://hcplab-sysu.github.io/TAVP.</description><author>Yongjie Bai, Zhouxia Wang, Yang Liu, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu, Guanbin Li, Liang Lin</author><pubDate>Tue, 21 Oct 2025 15:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.05186v2</guid></item><item><title>Topoformer: brain-like topographic organization in Transformer language models through spatial querying and reweighting</title><link>http://arxiv.org/abs/2510.18745v1</link><description>Spatial functional organization is a hallmark of biological brains: neuronsare arranged topographically according to their response properties, atmultiple scales. In contrast, representations within most machine learningmodels lack spatial biases, instead manifesting as disorganized vector spacesthat are difficult to visualize and interpret. Here, we propose a novel form ofself-attention that turns Transformers into "Topoformers" with topographicorganization. We introduce spatial querying - where keys and queries arearranged on 2D grids, and local pools of queries are associated with a givenkey - and spatial reweighting, where we convert the standard fully connectedlayer of self-attention into a locally connected layer. We first demonstratethe feasibility of our approach by training a 1-layer Topoformer on a sentimentclassification task. Training with spatial querying encourages topographicorganization in the queries and keys, and spatial reweighting separatelyencourages topographic organization in the values and self-attention outputs.We then apply the Topoformer motifs at scale, training a BERT architecture witha masked language modeling objective. We find that the topographic variantperforms on par with a non-topographic control model on NLP benchmarks, yetproduces interpretable topographic organization as evaluated via eightlinguistic test suites. Finally, analyzing an fMRI dataset of human brainresponses to a large set of naturalistic sentences, we demonstrate alignmentbetween low-dimensional topographic variability in the Topoformer model andhuman brain language network. Scaling up Topoformers further holds promise forgreater interpretability in NLP research, and for more accurate models of theorganization of linguistic information in the human brain.</description><author>Taha Binhuraib, Greta Tuckute, Nicholas Blauch</author><pubDate>Tue, 21 Oct 2025 15:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18745v1</guid></item><item><title>Who cuts emissions, who turns up the heat? causal machine learning estimates of energy efficiency interventions</title><link>http://arxiv.org/abs/2508.04478v2</link><description>Reducing domestic energy demand is central to climate mitigation and fuelpoverty strategies, yet the impact of energy efficiency interventions is highlyheterogeneous. Using a causal machine learning model trained on nationallyrepresentative data of the English housing stock, we estimate average andconditional treatment effects of wall insulation on gas consumption, focusingon distributional effects across energy burden subgroups. While interventionsreduce gas demand on average (by as much as 19 percent), low energy burdengroups achieve substantial savings, whereas those experiencing high energyburdens see little to no reduction. This pattern reflects abehaviourally-driven mechanism: households constrained by high costs-to-incomeratios (e.g. more than 0.1) reallocate savings toward improved thermal comfortrather than lowering consumption. Far from wasteful, such responses representrational adjustments in contexts of prior deprivation, with potentialco-benefits for health and well-being. These findings call for a broaderevaluation framework that accounts for both climate impacts and the equityimplications of domestic energy policy.</description><author>Bernardino D'Amico, Francesco Pomponi, Jay H. Arehart, Lina Khaddour</author><pubDate>Tue, 21 Oct 2025 15:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.04478v2</guid></item><item><title>Diffusion Buffer for Online Generative Speech Enhancement</title><link>http://arxiv.org/abs/2510.18744v1</link><description>Online Speech Enhancement was mainly reserved for predictive models. A keyadvantage of these models is that for an incoming signal frame from a stream ofdata, the model is called only once for enhancement. In contrast, generativeSpeech Enhancement models often require multiple calls, resulting in acomputational complexity that is too high for many online speech enhancementapplications. This work presents the Diffusion Buffer, a generativediffusion-based Speech Enhancement model which only requires one neural networkcall per incoming signal frame from a stream of data and performs enhancementin an online fashion on a consumer-grade GPU. The key idea of the DiffusionBuffer is to align physical time with Diffusion time-steps. The approachprogressively denoises frames through physical time, where past frames havemore noise removed. Consequently, an enhanced frame is output to the listenerwith a delay defined by the Diffusion Buffer, and the output frame has acorresponding look-ahead. In this work, we extend upon our previous work bycarefully designing a 2D convolutional UNet architecture that specificallyaligns with the Diffusion Buffer's look-ahead. We observe that the proposedUNet improves performance, particularly when the algorithmic latency is low.Moreover, we show that using a Data Prediction loss instead of Denoising ScoreMatching loss enables flexible control over the trade-off between algorithmiclatency and quality during inference. The extended Diffusion Buffer equippedwith a novel NN and loss function drastically reduces the algorithmic latencyfrom 320 - 960 ms to 32 - 176 ms with an even increased performance. While ithas been shown before that offline generative diffusion models outperformpredictive approaches in unseen noisy speech data, we confirm that the onlineDiffusion Buffer also outperforms its predictive counterpart on unseen noisyspeech data.</description><author>Bunlong Lay, Rostislav Makarov, Simon Welker, Maris Hillemann, Timo Gerkmann</author><pubDate>Tue, 21 Oct 2025 15:52:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18744v1</guid></item><item><title>Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?</title><link>http://arxiv.org/abs/2508.03963v3</link><description>Uncovering hidden symbolic laws from time series data, as an aspirationdating back to Kepler's discovery of planetary motion, remains a core challengein scientific discovery and artificial intelligence. While Large LanguageModels show promise in structured reasoning tasks, their ability to inferinterpretable, context-aligned symbolic structures from time series data isstill underexplored. To systematically evaluate this capability, we introduceSymbolBench, a comprehensive benchmark designed to assess symbolic reasoningover real-world time series across three tasks: multivariate symbolicregression, Boolean network inference, and causal discovery. Unlike priorefforts limited to simple algebraic equations, SymbolBench spans a diverse setof symbolic forms with varying complexity. We further propose a unifiedframework that integrates LLMs with genetic programming to form a closed-loopsymbolic reasoning system, where LLMs act both as predictors and evaluators.Our empirical results reveal key strengths and limitations of current models,highlighting the importance of combining domain knowledge, context alignment,and reasoning structure to improve LLMs in automated scientific discovery.</description><author>Zewen Liu, Juntong Ni, Xianfeng Tang, Max S. Y. Lau, Wenpeng Yin, Wei Jin</author><pubDate>Tue, 21 Oct 2025 15:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.03963v3</guid></item><item><title>Inductive Domain Transfer In Misspecified Simulation-Based Inference</title><link>http://arxiv.org/abs/2508.15593v3</link><description>Simulation-based inference (SBI) is a statistical inference approach forestimating latent parameters of a physical system when the likelihood isintractable but simulations are available. In practice, SBI is often hinderedby model misspecification--the mismatch between simulated and real-worldobservations caused by inherent modeling simplifications. RoPE, a recent SBIapproach, addresses this challenge through a two-stage domain transfer processthat combines semi-supervised calibration with optimal transport (OT)-baseddistribution alignment. However, RoPE operates in a fully transductive setting,requiring access to a batch of test samples at inference time, which limitsscalability and generalization. We propose here a fully inductive and amortizedSBI framework that integrates calibration and distributional alignment into asingle, end-to-end trainable model. Our method leverages mini-batch OT with aclosed-form coupling to align real and simulated observations that correspondto the same latent parameters, using both paired calibration data and unpairedsamples. A conditional normalizing flow is then trained to approximate theOT-induced posterior, enabling efficient inference without simulation access attest time. Across a range of synthetic and real-world benchmarks--includingcomplex medical biomarker estimation--our approach matches or surpasses theperformance of RoPE, as well as other standard SBI and non-SBI estimators,while offering improved scalability and applicability in challenging,misspecified environments.</description><author>Ortal Senouf, Antoine Wehenkel, Cdric Vincent-Cuaz, Emmanuel Abb, Pascal Frossard</author><pubDate>Tue, 21 Oct 2025 15:45:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.15593v3</guid></item><item><title>SEAL: Semantic-Aware Hierarchical Learning for Generalized Category Discovery</title><link>http://arxiv.org/abs/2510.18740v1</link><description>This paper investigates the problem of Generalized Category Discovery (GCD).Given a partially labelled dataset, GCD aims to categorize all unlabelledimages, regardless of whether they belong to known or unknown classes. Existingapproaches typically depend on either single-level semantics or manuallydesigned abstract hierarchies, which limit their generalizability andscalability. To address these limitations, we introduce a SEmantic-awarehierArchical Learning framework (SEAL), guided by naturally occurring andeasily accessible hierarchical structures. Within SEAL, we propose aHierarchical Semantic-Guided Soft Contrastive Learning approach that exploitshierarchical similarity to generate informative soft negatives, addressing thelimitations of conventional contrastive losses that treat all negativesequally. Furthermore, a Cross-Granularity Consistency (CGC) module is designedto align the predictions from different levels of granularity. SEALconsistently achieves state-of-the-art performance on fine-grained benchmarks,including the SSB benchmark, Oxford-Pet, and the Herbarium19 dataset, andfurther demonstrates generalization on coarse-grained datasets. Project page:https://visual-ai.github.io/seal/</description><author>Zhenqi He, Yuanpei Liu, Kai Han</author><pubDate>Tue, 21 Oct 2025 15:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18740v1</guid></item><item><title>Moving Light Adaptive Colonoscopy Reconstruction via Illumination-Attenuation-Aware 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2510.18739v1</link><description>3D Gaussian Splatting (3DGS) has emerged as a pivotal technique for real-timeview synthesis in colonoscopy, enabling critical applications such as virtualcolonoscopy and lesion tracking. However, the vanilla 3DGS assumes staticillumination and that observed appearance depends solely on viewing angle,which causes incompatibility with the photometric variations in colonoscopicscenes induced by dynamic light source/camera. This mismatch forces most 3DGSmethods to introduce structure-violating vaporous Gaussian blobs between thecamera and tissues to compensate for illumination attenuation, ultimatelydegrading the quality of 3D reconstructions. Previous works only consider theillumination attenuation caused by light distance, ignoring the physicalcharacters of light source and camera. In this paper, we propose ColIAGS, animproved 3DGS framework tailored for colonoscopy. To mimic realistic appearanceunder varying illumination, we introduce an Improved Appearance Modeling withtwo types of illumination attenuation factors, which enables Gaussians to adaptto photometric variations while preserving geometry accuracy. To ensure thegeometry approximation condition of appearance modeling, we propose an ImprovedGeometry Modeling using high-dimensional view embedding to enhance Gaussiangeometry attribute prediction. Furthermore, another cosine embedding input isleveraged to generate illumination attenuation solutions in an implicit manner.Comprehensive experimental results on standard benchmarks demonstrate that ourproposed ColIAGS achieves the dual capabilities of novel view synthesis andaccurate geometric reconstruction. It notably outperforms otherstate-of-the-art methods by achieving superior rendering fidelity whilesignificantly reducing Depth MSE. Code will be available.</description><author>Hao Wang, Ying Zhou, Haoyu Zhao, Rui Wang, Qiang Hu, Xing Zhang, Qiang Li, Zhiwei Wang</author><pubDate>Tue, 21 Oct 2025 15:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18739v1</guid></item><item><title>InternLM2.5-StepProver: Advancing Automated Theorem Proving via Critic-Guided Search</title><link>http://arxiv.org/abs/2410.15700v2</link><description>Large Language Models (LLMs) have emerged as powerful tools in mathematicaltheorem proving, particularly when utilizing formal languages such as LEAN. Aprevalent proof method involves the LLM prover iteratively constructing theproof tactic by tactic, typically following a best-first search scheme.However, this method often ignores the critical preference information insidethe existing tactic trajectories, hindering the search for deeper proofs. Wepropose an intuitive yet effective method, which utilizes a critic model tocapture the preference information and to guide the search of the prover modelat runtime. Given the prover-critic framework, a large-scale expert iterationwith more than 20,000 CPU days is then applied to further fine-tune the proverand the critic. The trained InternLM2.5-StepProver critic significantly booststhe performance of the prover model (59.4% to 65.9%). We also analyze theimpact of the critic on various aspects of the theorem proving process duringexpert iteration, providing insights into its effectiveness. We open-source ourmodels and searched proofs at https://github.com/InternLM/InternLM-Math andhttps://huggingface.co/datasets/internlm/Lean-Workbook.</description><author>Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Zheng Yuan, Wenwei Zhang, Dahua Lin, Kai Chen</author><pubDate>Tue, 21 Oct 2025 15:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15700v2</guid></item><item><title>A unified framework for establishing the universal approximation of transformer-type architectures</title><link>http://arxiv.org/abs/2506.23551v2</link><description>We investigate the universal approximation property (UAP) of transformer-typearchitectures, providing a unified theoretical framework that extends priorresults on residual networks to models incorporating attention mechanisms. Ourwork identifies token distinguishability as a fundamental requirement for UAPand introduces a general sufficient condition that applies to a broad class ofarchitectures. Leveraging an analyticity assumption on the attention layer, wecan significantly simplify the verification of this condition, providing anon-constructive approach in establishing UAP for such architectures. Wedemonstrate the applicability of our framework by proving UAP for transformerswith various attention mechanisms, including kernel-based and sparse attentionmechanisms. The corollaries of our results either generalize prior works orestablish UAP for architectures not previously covered. Furthermore, ourframework offers a principled foundation for designing novel transformerarchitectures with inherent UAP guarantees, including those with specificfunctional symmetries. We propose examples to illustrate these insights.</description><author>Jingpu Cheng, Ting Lin, Zuowei Shen, Qianxiao Li</author><pubDate>Tue, 21 Oct 2025 15:34:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.23551v2</guid></item><item><title>Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations</title><link>http://arxiv.org/abs/2510.13982v3</link><description>What if artificial agents could not just communicate, but also evolve, adapt,and reshape their worlds in ways we cannot fully predict? With llm now poweringmulti-agent systems and social simulations, we are witnessing new possibilitiesfor modeling open-ended, ever-changing environments. Yet, most currentsimulations remain constrained within static sandboxes, characterized bypredefined tasks, limited dynamics, and rigid evaluation criteria. Theselimitations prevent them from capturing the complexity of real-world societies.In this paper, we argue that static, task-specific benchmarks are fundamentallyinadequate and must be rethought. We critically review emerging architecturesthat blend llm with multi-agent dynamics, highlight key hurdles such asbalancing stability and diversity, evaluating unexpected behaviors, and scalingto greater complexity, and introduce a fresh taxonomy for this rapidly evolvingfield. Finally, we present a research roadmap centered on open-endedness,continuous co-evolution, and the development of resilient, socially aligned AIecosystems. We call on the community to move beyond static paradigms and helpshape the next generation of adaptive, socially-aware multi-agent simulations.</description><author>Jinkun Chen, Sher Badshah, Xuemin Yu, Sijia Han</author><pubDate>Tue, 21 Oct 2025 15:32:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.13982v3</guid></item><item><title>Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation</title><link>http://arxiv.org/abs/2510.18731v1</link><description>Large Language Models demonstrate strong capabilities in single-turninstruction following but suffer from Lost-in-Conversation (LiC), a degradationin performance as information is revealed progressively in multi-turn settings.Motivated by the current progress on Reinforcement Learning with VerifiableRewards (RLVR), we propose Curriculum Reinforcement Learning with VerifiableAccuracy and Abstention Rewards (RLAAR), a framework that encourages models notonly to generate correct answers, but also to judge the solvability ofquestions in the multi-turn conversation setting. Our approach employs acompetence-gated curriculum that incrementally increases dialogue difficulty(in terms of instruction shards), stabilizing training while promotingreliability. Using multi-turn, on-policy rollouts and a mixed-reward system,RLAAR teaches models to balance problem-solving with informed abstention,reducing premature answering behaviors that cause LiC. Evaluated on LiCbenchmarks, RLAAR significantly mitigates LiC performance decay (62.6% to75.1%) and improves calibrated abstention rates (33.5% to 73.4%). Together,these results provide a practical recipe for building multi-turn reliable andtrustworthy LLMs.</description><author>Ming Li</author><pubDate>Tue, 21 Oct 2025 15:32:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18731v1</guid></item><item><title>Understanding Reinforcement Learning for Model Training, and future directions with GRAPE</title><link>http://arxiv.org/abs/2509.04501v2</link><description>This paper provides a self-contained, from-scratch, exposition of keyalgorithms for instruction tuning of models: SFT, Rejection Sampling,REINFORCE, Trust Region Policy Optimization (TRPO), Proximal PolicyOptimization (PPO), Group Relative Policy Optimization (GRPO), and DirectPreference Optimization (DPO). Explanations of these algorithms often assumeprior knowledge, lack critical details, and/or are overly generalized andcomplex. Here, each method is discussed and developed step by step usingsimplified and explicit notation focused on LLMs, aiming to eliminate ambiguityand provide a clear and intuitive understanding of the concepts. By minimizingdetours into the broader RL literature and connecting concepts to LLMs, weeliminate superfluous abstractions and reduce cognitive overhead. Followingthis exposition, we provide a literature review of new techniques andapproaches beyond those detailed. Finally, new ideas for research andexploration in the form of GRAPE (Generalized Relative Advantage PolicyEvolution) are presented.</description><author>Rohit Patel</author><pubDate>Tue, 21 Oct 2025 15:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2509.04501v2</guid></item><item><title>SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction</title><link>http://arxiv.org/abs/2507.06955v2</link><description>Accurate cortical surface reconstruction from magnetic resonance imaging(MRI) data is crucial for reliable neuroanatomical analyses. Current methodshave to contend with complex cortical geometries, strict topologicalrequirements, and often produce surfaces with overlaps, self-intersections, andtopological defects. To overcome these shortcomings, we introduce SimCortex, adeep learning framework that simultaneously reconstructs all brain surfaces(left/right white-matter and pial) from T1-weighted(T1w) MRI volumes whilepreserving topological properties. Our method first segments the T1w image intoa nine-class tissue label map. From these segmentations, we generatesubject-specific, collision-free initial surface meshes. These surfaces serveas precise initializations for subsequent multiscale diffeomorphicdeformations. Employing stationary velocity fields (SVFs) integrated viascaling-and-squaring, our approach ensures smooth, topology-preservingtransformations with significantly reduced surface collisions andself-intersections. Evaluations on standard datasets demonstrate that SimCortexdramatically reduces surface overlaps and self-intersections, surpassingcurrent methods while maintaining state-of-the-art geometric accuracy.</description><author>Kaveh Moradkhani, R Jarrett Rushmore, Sylvain Bouix</author><pubDate>Tue, 21 Oct 2025 15:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2507.06955v2</guid></item><item><title>HarmNet: A Framework for Adaptive Multi-Turn Jailbreak Attacks on Large Language Models</title><link>http://arxiv.org/abs/2510.18728v1</link><description>Large Language Models (LLMs) remain vulnerable to multi-turn jailbreakattacks. We introduce HarmNet, a modular framework comprising ThoughtNet, ahierarchical semantic network; a feedback-driven Simulator for iterative queryrefinement; and a Network Traverser for real-time adaptive attack execution.HarmNet systematically explores and refines the adversarial space to uncoverstealthy, high-success attack paths. Experiments across closed-source andopen-source LLMs show that HarmNet outperforms state-of-the-art methods,achieving higher attack success rates. For example, on Mistral-7B, HarmNetachieves a 99.4% attack success rate, 13.9% higher than the best baseline.Index terms: jailbreak attacks; large language models; adversarial framework;query refinement.</description><author>Sidhant Narula, Javad Rafiei Asl, Mohammad Ghasemigol, Eduardo Blanco, Daniel Takabi</author><pubDate>Tue, 21 Oct 2025 15:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18728v1</guid></item><item><title>Dynamic object goal pushing with mobile manipulators through model-free constrained reinforcement learning</title><link>http://arxiv.org/abs/2502.01546v2</link><description>Non-prehensile pushing to move and reorient objects to a goal is a versatileloco-manipulation skill. In the real world, the object's physical propertiesand friction with the floor contain significant uncertainties, which makes thetask challenging for a mobile manipulator. In this paper, we develop alearning-based controller for a mobile manipulator to move an unknown object toa desired position and yaw orientation through a sequence of pushing actions.The proposed controller for the robotic arm and the mobile base motion istrained using a constrained Reinforcement Learning (RL) formulation. Wedemonstrate its capability in experiments with a quadrupedal robot equippedwith an arm. The learned policy achieves a success rate of 91.35% in simulationand at least 80% on hardware in challenging scenarios. Through our extensivehardware experiments, we show that the approach demonstrates high robustnessagainst unknown objects of different masses, materials, sizes, and shapes. Itreactively discovers the pushing location and direction, thus achievingcontact-rich behavior while observing only the pose of the object.Additionally, we demonstrate the adaptive behavior of the learned policytowards preventing the object from toppling.</description><author>Ioannis Dadiotis, Mayank Mittal, Nikos Tsagarakis, Marco Hutter</author><pubDate>Tue, 21 Oct 2025 15:27:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01546v2</guid></item><item><title>Brain-Like Processing Pathways Form in Models With Heterogeneous Experts</title><link>http://arxiv.org/abs/2506.02813v2</link><description>Examples of such pathways can be found in the interactions between corticaland subcortical networks during learning, or in sub-networks specializing fortask characteristics such as difficulty or modality. Despite the large rolethese pathways play in cognition, the mechanisms through which brain regionsorganize into pathways remain unclear. In this work, we use an extension of theHeterogeneous Mixture-of-Experts architecture to show that heterogeneousregions do not form processing pathways by themselves, implying that the brainlikely implements specific constraints which result in the reliable formationof pathways. We identify three biologically relevant inductive biases thatencourage pathway formation: a routing cost imposed on the use of more complexregions, a scaling factor that reduces this cost when task performance is low,and randomized expert dropout. When comparing our resulting\textit{Mixture-of-Pathways} model with the brain, we observe that theartificial pathways in our model match how the brain uses cortical andsubcortical systems to learn and solve tasks of varying difficulty. In summary,we introduce a novel framework for investigating how the brain formstask-specific pathways through inductive biases, and the effects these biaseshave on the behavior of Mixture-of-Experts models.</description><author>Jack Cook, Danyal Akarca, Rui Ponte Costa, Jascha Achterberg</author><pubDate>Tue, 21 Oct 2025 15:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2506.02813v2</guid></item><item><title>IF-VidCap: Can Video Caption Models Follow Instructions?</title><link>http://arxiv.org/abs/2510.18726v1</link><description>Although Multimodal Large Language Models (MLLMs) have demonstratedproficiency in video captioning, practical applications require captions thatfollow specific user instructions rather than generating exhaustive,unconstrained descriptions. Current benchmarks, however, primarily assessdescriptive comprehensiveness while largely overlooking instruction-followingcapabilities. To address this gap, we introduce IF-VidCap, a new benchmark forevaluating controllable video captioning, which contains 1,400 high-qualitysamples. Distinct from existing video captioning or generalinstruction-following benchmarks, IF-VidCap incorporates a systematic frameworkthat assesses captions on two dimensions: format correctness and contentcorrectness. Our comprehensive evaluation of over 20 prominent models reveals anuanced landscape: despite the continued dominance of proprietary models, theperformance gap is closing, with top-tier open-source solutions now achievingnear-parity. Furthermore, we find that models specialized for dense captioningunderperform general-purpose MLLMs on complex instructions, indicating thatfuture work should simultaneously advance both descriptive richness andinstruction-following fidelity.</description><author>Shihao Li, Yuanxing Zhang, Jiangtao Wu, Zhide Lei, Yiwen He, Runzhe Wen, Chenxi Liao, Chengkang Jiang, An Ping, Shuo Gao, Suhan Wang, Zhaozhou Bian, Zijun Zhou, Jingyi Xie, Jiayi Zhou, Jing Wang, Yifan Yao, Weihao Xie, Yingshui Tan, Yanghai Wang, Qianqian Xie, Zhaoxiang Zhang, Jiaheng Liu</author><pubDate>Tue, 21 Oct 2025 15:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18726v1</guid></item><item><title>Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs</title><link>http://arxiv.org/abs/2510.18876v1</link><description>While Multimodal Large Language Models (MLLMs) excel at holisticunderstanding, they struggle in capturing the dense world with complex scenes,requiring fine-grained analysis of intricate details and objectinter-relationships. Region-level MLLMs have been a promising step. However,previous attempts are generally optimized to understand given regions inisolation, neglecting crucial global contexts. To address this, we introduceGrasp Any Region (GAR) for comprehen- sive region-level visual understanding.Empowered by an effective RoI-aligned feature replay technique, GAR supports(1) precise perception by leveraging necessary global contexts, and (2)modeling interactions between multiple prompts. Together, it then naturallyachieves (3) advanced compositional reasoning to answer specific free-formquestions about any region, shifting the paradigm from passive description toactive dialogue. Moreover, we construct GAR-Bench, which not only provides amore accurate evaluation of single-region comprehension, but also, moreimportantly, measures interactions and complex reasoning across multipleregions. Extensive experiments have demonstrated that GAR-1B not only maintainsthe state-of-the-art captioning capabilities, e.g., outperforming DAM-3B +4.5on DLC-Bench, but also excels at modeling relationships between multipleprompts with advanced comprehension capabilities, even surpassing InternVL3-78Bon GAR-Bench-VQA. More importantly, our zero-shot GAR-8B even outperformsin-domain VideoRefer-7B on VideoRefer-BenchQ, indicating its strongcapabilities can be easily transferred to videos.</description><author>Haochen Wang, Yuhao Wang, Tao Zhang, Yikang Zhou, Yanwei Li, Jiacong Wang, Ye Tian, Jiahao Meng, Zilong Huang, Guangcan Mai, Anran Wang, Yunhai Tong, Zhuochen Wang, Xiangtai Li, Zhaoxiang Zhang</author><pubDate>Tue, 21 Oct 2025 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2510.18876v1</guid></item></channel></rss>