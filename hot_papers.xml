<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivhot papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 13 Dec 2024 13:00:35 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models</title><link>http://arxiv.org/abs/2407.07895v1</link><description>Visual instruction tuning has made considerable strides in enhancing thecapabilities of Large Multimodal Models (LMMs). However, existing open LMMslargely focus on single-image tasks, their applications to multi-imagescenarios remains less explored. Additionally, prior LMM research separatelytackles different scenarios, leaving it impossible to generalize crossscenarios with new emerging capabilities. To this end, we introduceLLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. Toenable these capabilities, we regard the interleaved data format as a generaltemplate and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4primary domains with 14 tasks and 41 datasets. We also curate theLLaVA-Interleave Bench to comprehensively evaluate the multi-image performanceof LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leadingresults in multi-image, video, and 3D benchmarks, while maintaining theperformance of single-image tasks. Besides, our model also exhibits severalemerging capabilities, e.g., transferring tasks across different settings andmodalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT</description><author>Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, Chunyuan Li</author><pubDate>Wed, 10 Jul 2024 17:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07895v1</guid></item><item><title>Mitigating Bias in Dataset Distillation</title><link>http://arxiv.org/abs/2406.06609v2</link><description>Dataset Distillation has emerged as a technique for compressing largedatasets into smaller synthetic counterparts, facilitating downstream trainingtasks. In this paper, we study the impact of bias inside the original dataseton the performance of dataset distillation. With a comprehensive empiricalevaluation on canonical datasets with color, corruption and background biases,we found that color and background biases in the original dataset will beamplified through the distillation process, resulting in a notable decline inthe performance of models trained on the distilled dataset, while corruptionbias is suppressed through the distillation process. To reduce biasamplification in dataset distillation, we introduce a simple yet highlyeffective approach based on a sample reweighting scheme utilizing kerneldensity estimation. Empirical results on multiple real-world and syntheticdatasets demonstrate the effectiveness of the proposed method. Notably, onCMNIST with 5% bias-conflict ratio and IPC 50, our method achieves 91.5% testaccuracy compared to 23.8% from vanilla DM, boosting the performance by 67.7%,whereas applying state-of-the-art debiasing method on the same dataset onlyachieves 53.7% accuracy. Our findings highlight the importance of addressingbiases in dataset distillation and provide a promising avenue to address biasamplification in the process.</description><author>Justin Cui, Ruochen Wang, Yuanhao Xiong, Cho-Jui Hsieh</author><pubDate>Wed, 10 Jul 2024 17:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06609v2</guid></item><item><title>Training on the Test Task Confounds Evaluation and Emergence</title><link>http://arxiv.org/abs/2407.07890v1</link><description>We study a fundamental problem in the evaluation of large language modelsthat we call training on the test task. Unlike wrongful practices like trainingon the test data, leakage, or data contamination, training on the test task isnot a malpractice. Rather, the term describes a growing set of techniques toinclude task-relevant data in the pretraining stage of a language model. Wedemonstrate that training on the test task confounds both relative modelevaluations and claims about emergent capabilities. We argue that the seemingsuperiority of one model family over another may be explained by a differentdegree of training on the test task. To this end, we propose an effectivemethod to adjust for training on the test task by fine-tuning each model undercomparison on the same task-relevant data before evaluation. We then show thatinstances of emergent behavior largely vanish once we adjust for training onthe test task. This also applies to reported instances of emergent behaviorthat cannot be explained by the choice of evaluation metric. Our work promotesa new perspective on the evaluation of large language models with broadimplications for benchmarking and the study of emergent capabilities.</description><author>Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt</author><pubDate>Wed, 10 Jul 2024 17:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07890v1</guid></item><item><title>AdaptiGraph: Material-Adaptive Graph-Based Neural Dynamics for Robotic Manipulation</title><link>http://arxiv.org/abs/2407.07889v1</link><description>Predictive models are a crucial component of many robotic systems. Yet,constructing accurate predictive models for a variety of deformable objects,especially those with unknown physical properties, remains a significantchallenge. This paper introduces AdaptiGraph, a learning-based dynamicsmodeling approach that enables robots to predict, adapt to, and control a widearray of challenging deformable materials with unknown physical properties.AdaptiGraph leverages the highly flexible graph-based neural dynamics (GBND)framework, which represents material bits as particles and employs a graphneural network (GNN) to predict particle motion. Its key innovation is aunified physical property-conditioned GBND model capable of predicting themotions of diverse materials with varying physical properties withoutretraining. Upon encountering new materials during online deployment,AdaptiGraph utilizes a physical property optimization process for a few-shotadaptation of the model, enhancing its fit to the observed interaction data.The adapted models can precisely simulate the dynamics and predict the motionof various deformable materials, such as ropes, granular media, rigid boxes,and cloth, while adapting to different physical properties, includingstiffness, granular size, and center of pressure. On prediction andmanipulation tasks involving a diverse set of real-world deformable objects,our method exhibits superior prediction accuracy and task proficiency overnon-material-conditioned and non-adaptive models. The project page is availableat https://robopil.github.io/adaptigraph/ .</description><author>Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li</author><pubDate>Wed, 10 Jul 2024 17:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07889v1</guid></item><item><title>Rethinking Fair Graph Neural Networks from Re-balancing</title><link>http://arxiv.org/abs/2407.11624v1</link><description>Driven by the powerful representation ability of Graph Neural Networks(GNNs), plentiful GNN models have been widely deployed in many real-worldapplications. Nevertheless, due to distribution disparities between differentdemographic groups, fairness in high-stake decision-making systems is receivingincreasing attention. Although lots of recent works devoted to improving thefairness of GNNs and achieved considerable success, they all requiresignificant architectural changes or additional loss functions requiring morehyper-parameter tuning. Surprisingly, we find that simple re-balancing methodscan easily match or surpass existing fair GNN methods. We claim that theimbalance across different demographic groups is a significant source ofunfairness, resulting in imbalanced contributions from each group to theparameters updating. However, these simple re-balancing methods have their ownshortcomings during training. In this paper, we propose FairGB, Fair GraphNeural Network via re-Balancing, which mitigates the unfairness of GNNs bygroup balancing. Technically, FairGB consists of two modules: counterfactualnode mixup and contribution alignment loss. Firstly, we select counterfactualpairs across inter-domain and inter-class, and interpolate the ego-networks togenerate new samples. Guided by analysis, we can reveal the debiasing mechanismof our model by the causal view and prove that our strategy can make sensitiveattributes statistically independent from target labels. Secondly, we reweighthe contribution of each group according to gradients. By combining these twomodules, they can mutually promote each other. Experimental results onbenchmark datasets show that our method can achieve state-of-the-art resultsconcerning both utility and fairness metrics. Code is available athttps://github.com/ZhixunLEE/FairGB.</description><author>Zhixun Li, Yushun Dong, Qiang Liu, Jeffrey Xu Yu</author><pubDate>Tue, 16 Jul 2024 11:39:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11624v1</guid></item><item><title>Is Your LLM Outdated? Evaluating LLMs at Temporal Generalization</title><link>http://arxiv.org/abs/2405.08460v2</link><description>The rapid advancement of Large Language Models (LLMs) highlights the urgentneed for evolving evaluation methodologies that keep pace with improvements inlanguage comprehension and information processing. However, traditionalbenchmarks, which are often static, fail to capture the continually changinginformation landscape, leading to a disparity between the perceived and actualeffectiveness of LLMs in ever-changing real-world scenarios. Our study examinestemporal generalization, which includes the ability to understand, predict, andgenerate text relevant to past, present, and future contexts, revealingsignificant temporal biases in LLMs. We propose an evaluation framework, fordynamically generating benchmarks from recent real-world predictions.Experiments demonstrate that LLMs struggle with temporal generalization,showing performance decline over time. These findings highlight the necessityfor improved training and updating processes to enhance adaptability and reducebiases. Our code, dataset and benchmark are available athttps://github.com/FreedomIntelligence/FreshBench.</description><author>Chenghao Zhu, Nuo Chen, Yufei Gao, Yunyi Zhang, Prayag Tiwari, Benyou Wang</author><pubDate>Wed, 10 Jul 2024 17:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08460v2</guid></item><item><title>Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing</title><link>http://arxiv.org/abs/2407.07885v1</link><description>Recent progress in reinforcement learning (RL) and tactile sensing hassignificantly advanced dexterous manipulation. However, these methods oftenutilize simplified tactile signals due to the gap between tactile simulationand the real world. We introduce a sensor model for tactile skin that enableszero-shot sim-to-real transfer of ternary shear and binary normal forces. Usingthis model, we develop an RL policy that leverages sliding contact fordexterous in-hand translation. We conduct extensive real-world experiments toassess how tactile sensing facilitates policy adaptation to various unseenobject properties and robot hand orientations. We demonstrate that our 3-axistactile policies consistently outperform baselines that use only shear forces,only normal forces, or only proprioception. Website:https://jessicayin.github.io/tactile-skin-rl/</description><author>Jessica Yin, Haozhi Qi, Jitendra Malik, James Pikul, Mark Yim, Tess Hellebrekers</author><pubDate>Wed, 10 Jul 2024 17:52:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07885v1</guid></item><item><title>Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation</title><link>http://arxiv.org/abs/2407.07884v1</link><description>Recent studies have made significant progress in addressing dexterousmanipulation problems, particularly in in-hand object reorientation. However,there are few existing works that explore the potential utilization ofdeveloped dexterous manipulation controllers for downstream tasks. In thisstudy, we focus on constrained dexterous manipulation for food peeling. Foodpeeling presents various constraints on the reorientation controller, such asthe requirement for the hand to securely hold the object after reorientationfor peeling. We propose a simple system for learning a reorientation controllerthat facilitates the subsequent peeling task. Videos are available at:https://taochenshh.github.io/projects/veg-peeling.</description><author>Tao Chen, Eric Cousineau, Naveen Kuppuswamy, Pulkit Agrawal</author><pubDate>Wed, 10 Jul 2024 17:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07884v1</guid></item><item><title>Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization</title><link>http://arxiv.org/abs/2407.07880v1</link><description>This study addresses the challenge of noise in training datasets for DirectPreference Optimization (DPO), a method for aligning Large Language Models(LLMs) with human preferences. We categorize noise into pointwise noise, whichincludes low-quality data points, and pairwise noise, which encompasseserroneous data pair associations that affect preference rankings. UtilizingDistributionally Robust Optimization (DRO), we enhance DPO's resilience tothese types of noise. Our theoretical insights reveal that DPO inherentlyembeds DRO principles, conferring robustness to pointwise noise, with theregularization coefficient $\beta$ playing a critical role in its noiseresistance. Extending this framework, we introduce DistributionallyRobustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizingagainst worst-case pairwise scenarios. The novel hyperparameter $\beta'$ in Dr.DPO allows for fine-tuned control over data pair reliability, providing astrategic balance between exploration and exploitation in noisy trainingenvironments. Empirical evaluations demonstrate that Dr. DPO substantiallyimproves the quality of generated text and response accuracy in preferencedatasets, showcasing enhanced performance in both noisy and noise-freesettings. The code is available at https://github.com/junkangwu/Dr_DPO.</description><author>Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He</author><pubDate>Wed, 10 Jul 2024 17:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07880v1</guid></item><item><title>Generative Image as Action Models</title><link>http://arxiv.org/abs/2407.07875v1</link><description>Image-generation diffusion models have been fine-tuned to unlock newcapabilities such as image-editing and novel view synthesis. Can we similarlyunlock image-generation models for visuomotor control? We present GENIMA, abehavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'as targets on RGB images. These images are fed into a controller that maps thevisual targets into a sequence of joint-positions. We study GENIMA on 25RLBench and 9 real-world manipulation tasks. We find that, by lifting actionsinto image-space, internet pre-trained diffusion models can generate policiesthat outperform state-of-the-art visuomotor approaches, especially inrobustness to scene perturbations and generalizing to novel objects. Our methodis also competitive with 3D agents, despite lacking priors such as depth,keypoints, or motion-planners.</description><author>Mohit Shridhar, Yat Long Lo, Stephen James</author><pubDate>Wed, 10 Jul 2024 17:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07875v1</guid></item><item><title>Toto: Time Series Optimized Transformer for Observability</title><link>http://arxiv.org/abs/2407.07874v1</link><description>This technical report describes the Time Series Optimized Transformer forObservability (Toto), a new state of the art foundation model for time seriesforecasting developed by Datadog. In addition to advancing the state of the arton generalized time series benchmarks in domains such as electricity andweather, this model is the first general-purpose time series forecastingfoundation model to be specifically tuned for observability metrics. Toto wastrained on a dataset of one trillion time series data points, the largest amongall currently published time series foundation models. Alongside publiclyavailable time series datasets, 75% of the data used to train Toto consists offully anonymous numerical metric data points from the Datadog platform. In ourexperiments, Toto outperforms existing time series foundation models onobservability data. It does this while also excelling at general-purposeforecasting tasks, achieving state-of-the-art zero-shot performance on multipleopen benchmark datasets.</description><author>Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal</author><pubDate>Wed, 10 Jul 2024 17:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07874v1</guid></item><item><title>LAB-Bench: Measuring Capabilities of Language Models for Biology Research</title><link>http://arxiv.org/abs/2407.10362v2</link><description>There is widespread optimism that frontier Large Language Models (LLMs) andLLM-augmented systems have the potential to rapidly accelerate scientificdiscovery across disciplines. Today, many benchmarks exist to measure LLMknowledge and reasoning on textbook-style science questions, but few if anybenchmarks are designed to evaluate language model performance on practicaltasks required for scientific research, such as literature search, protocolplanning, and data analysis. As a step toward building such benchmarks, weintroduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset ofover 2,400 multiple choice questions for evaluating AI systems on a range ofpractical biology research capabilities, including recall and reasoning overliterature, interpretation of figures, access and navigation of databases, andcomprehension and manipulation of DNA and protein sequences. Importantly, incontrast to previous scientific benchmarks, we expect that an AI system thatcan achieve consistently high scores on the more difficult LAB-Bench taskswould serve as a useful assistant for researchers in areas such as literaturesearch and molecular cloning. As an initial assessment of the emergentscientific task capabilities of frontier language models, we measureperformance of several against our benchmark and report results compared tohuman expert biology researchers. We will continue to update and expandLAB-Bench over time, and expect it to serve as a useful tool in the developmentof automated research systems going forward. A public subset of LAB-Bench isavailable for use at the following URL:https://huggingface.co/datasets/futurehouse/lab-bench</description><author>Jon M. Laurent, Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, Samuel G. Rodriques</author><pubDate>Tue, 16 Jul 2024 15:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10362v2</guid></item><item><title>Dynamical Measure Transport and Neural PDE Solvers for Sampling</title><link>http://arxiv.org/abs/2407.07873v1</link><description>The task of sampling from a probability density can be approached astransporting a tractable density function to the target, known as dynamicalmeasure transport. In this work, we tackle it through a principled unifiedframework using deterministic or stochastic evolutions described by partialdifferential equations (PDEs). This framework incorporates priortrajectory-based sampling methods, such as diffusion models or Schr\"odingerbridges, without relying on the concept of time-reversals. Moreover, it allowsus to propose novel numerical methods for solving the transport task and thussampling from complicated targets without the need for the normalizationconstant or data samples. We employ physics-informed neural networks (PINNs) toapproximate the respective PDE solutions, implying both conceptional andcomputational advantages. In particular, PINNs allow for simulation- anddiscretization-free optimization and can be trained very efficiently, leadingto significantly better mode coverage in the sampling task compared toalternative methods. Moreover, they can readily be fine-tuned with Gauss-Newtonmethods to achieve high accuracy in sampling.</description><author>Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes Müller, Kamyar Azizzadenesheli, Anima Anandkumar</author><pubDate>Wed, 10 Jul 2024 17:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07873v1</guid></item><item><title>A Clinical Benchmark of Public Self-Supervised Pathology Foundation Models</title><link>http://arxiv.org/abs/2407.06508v2</link><description>The use of self-supervised learning (SSL) to train pathology foundationmodels has increased substantially in the past few years. Notably, severalmodels trained on large quantities of clinical data have been made publiclyavailable in recent months. This will significantly enhance scientific researchin computational pathology and help bridge the gap between research andclinical deployment. With the increase in availability of public foundationmodels of different sizes, trained using different algorithms on differentdatasets, it becomes important to establish a benchmark to compare theperformance of such models on a variety of clinically relevant tasks spanningmultiple organs and diseases. In this work, we present a collection ofpathology datasets comprising clinical slides associated with clinicallyrelevant endpoints including cancer diagnoses and a variety of biomarkersgenerated during standard hospital operation from two medical centers. Weleverage these datasets to systematically assess the performance of publicpathology foundation models and provide insights into best practices fortraining new foundation models and selecting appropriate pretrained models.</description><author>Gabriele Campanella, Shengjia Chen, Ruchika Verma, Jennifer Zeng, Aryeh Stock, Matt Croken, Brandon Veremis, Abdulkadir Elmas, Kuan-lin Huang, Ricky Kwan, Jane Houldsworth, Adam J. Schoenfeld, Chad Vanderbilt</author><pubDate>Wed, 10 Jul 2024 17:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06508v2</guid></item><item><title>Adaptive Multi-head Contrastive Learning</title><link>http://arxiv.org/abs/2310.05615v2</link><description>In contrastive learning, two views of an original image, generated bydifferent augmentations, are considered a positive pair, and their similarityis required to be high. Similarly, two views of distinct images form a negativepair, with encouraged low similarity. Typically, a single similarity measure,provided by a lone projection head, evaluates positive and negative samplepairs. However, due to diverse augmentation strategies and varying intra-samplesimilarity, views from the same image may not always be similar. Additionally,owing to inter-sample similarity, views from different images may be more akinthan those from the same image. Consequently, enforcing high similarity forpositive pairs and low similarity for negative pairs may be unattainable, andin some cases, such enforcement could detrimentally impact performance. Toaddress this challenge, we propose using multiple projection heads, eachproducing a distinct set of features. Our pre-training loss function emergesfrom a solution to the maximum likelihood estimation over head-wise posteriordistributions of positive samples given observations. This loss incorporatesthe similarity measure over positive and negative pairs, each re-weighted by anindividual adaptive temperature, regulated to prevent ill solutions. Ourapproach, Adaptive Multi-Head Contrastive Learning (AMCL), can be applied toand experimentally enhances several popular contrastive learning methods suchas SimCLR, MoCo, and Barlow Twins. The improvement remains consistent acrossvarious backbones and linear probing epochs, and becomes more significant whenemploying multiple augmentation methods.</description><author>Lei Wang, Piotr Koniusz, Tom Gedeon, Liang Zheng</author><pubDate>Wed, 10 Jul 2024 17:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05615v2</guid></item><item><title>Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents</title><link>http://arxiv.org/abs/2403.02502v2</link><description>Large Language Models (LLMs) have become integral components in variousautonomous agent systems. In this study, we present an exploration-basedtrajectory optimization approach, referred to as ETO. This learning method isdesigned to enhance the performance of open LLM agents. Contrary to previousstudies that exclusively train on successful expert trajectories, our methodallows agents to learn from their exploration failures. This leads to improvedperformance through an iterative optimization framework. During the explorationphase, the agent interacts with the environment while completing given tasks,gathering failure trajectories to create contrastive trajectory pairs. In thesubsequent training phase, the agent utilizes these trajectory preference pairsto update its policy using contrastive learning methods like DPO. Thisiterative cycle of exploration and training fosters continued improvement inthe agents. Our experiments on three complex tasks demonstrate that ETOconsistently surpasses baseline performance by a large margin. Furthermore, anexamination of task-solving efficiency and potential in scenarios lackingexpert trajectory underscores the effectiveness of our approach.</description><author>Yifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian Li, Bill Yuchen Lin</author><pubDate>Wed, 10 Jul 2024 17:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02502v2</guid></item><item><title>Agent Lumos: Unified and Modular Training for Open-Source Language Agents</title><link>http://arxiv.org/abs/2311.05657v3</link><description>Closed-source agents suffer from several issues such as a lack ofaffordability, transparency, and reproducibility, particularly on complexinteractive tasks. This motivates the development of open-source alternatives.We introduce LUMOS, one of the first frameworks for training open-sourceLLM-based agents. LUMOS features a learnable, unified, and modular architecturewith a planning module that learns high-level subgoal generation, and agrounding module trained to translate these into actions using various tools inthe execution module. The design allows for modular upgrades and widerapplicability to diverse interactive tasks. To foster generalizable agentlearning, we collect large-scale, unified, and high-quality trainingannotations derived from diverse ground-truth reasoning rationales acrossvarious complex interactive tasks. On 9 datasets, LUMOS exhibits several keyadvantages: (1) LUMOS excels multiple larger open-source agents on the held-outdatasets (unused for training) for each task type. LUMOS even surpasses GPTagents on QA and web tasks; (2) LUMOS outperforms open-source agents producedby chain-of-thoughts and unmodularized integrated training; and (3) LUMOSeffectively generalizes to unseen tasks, outperforming 33B-scale agents anddomain-specific agents.</description><author>Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin</author><pubDate>Wed, 10 Jul 2024 17:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05657v3</guid></item><item><title>CDFL: Efficient Federated Human Activity Recognition using Contrastive Learning and Deep Clustering</title><link>http://arxiv.org/abs/2407.12287v1</link><description>In the realm of ubiquitous computing, Human Activity Recognition (HAR) isvital for the automation and intelligent identification of human actionsthrough data from diverse sensors. However, traditional machine learningapproaches by aggregating data on a central server and centralized processingare memory-intensive and raise privacy concerns. Federated Learning (FL) hasemerged as a solution by training a global model collaboratively acrossmultiple devices by exchanging their local model parameters instead of localdata. However, in realistic settings, sensor data on devices isnon-independently and identically distributed (Non-IID). This means that dataactivity recorded by most devices is sparse, and sensor data distribution foreach client may be inconsistent. As a result, typical FL frameworks inheterogeneous environments suffer from slow convergence and poor performancedue to deviation of the global model's objective from the global objective.Most FL methods applied to HAR are either designed for overly ideal scenarioswithout considering the Non-IID problem or present privacy and scalabilityconcerns. This work addresses these challenges, proposing CDFL, an efficientfederated learning framework for image-based HAR. CDFL efficiently selects arepresentative set of privacy-preserved images using contrastive learning anddeep clustering, reduces communication overhead by selecting effective clientsfor global model updates, and improves global model quality by training onprivacy-preserved data. Our comprehensive experiments carried out on threepublic datasets, namely Stanford40, PPMI, and VOC2012, demonstrate thesuperiority of CDFL in terms of performance, convergence rate, and bandwidthusage compared to state-of-the-art approaches.</description><author>Ensieh Khazaei, Alireza Esmaeilzehi, Bilal Taha, Dimitrios Hatzinakos</author><pubDate>Wed, 17 Jul 2024 03:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12287v1</guid></item><item><title>Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies</title><link>http://arxiv.org/abs/2404.09349v2</link><description>This paper revisits the simple, long-studied, yet still unsolved problem ofmaking image classifiers robust to imperceptible perturbations. Taking CIFAR10as an example, SOTA clean accuracy is about $100$%, but SOTA robustness to$\ell_{\infty}$-norm bounded perturbations barely exceeds $70$%. To understandthis gap, we analyze how model size, dataset size, and synthetic data qualityaffect robustness by developing the first scaling laws for adversarialtraining. Our scaling laws reveal inefficiencies in prior art and provideactionable feedback to advance the field. For instance, we discovered that SOTAmethods diverge notably from compute-optimal setups, using excess compute fortheir level of robustness. Leveraging a compute-efficient setup, we surpass theprior SOTA with $20$% ($70$%) fewer training (inference) FLOPs. We trainedvarious compute-efficient models, with our best achieving $74$% AutoAttackaccuracy ($+3$% gain). However, our scaling laws also predict robustness slowlygrows then plateaus at $90$%: dwarfing our new SOTA by scaling is impractical,and perfect robustness is impossible. To better understand this predictedlimit, we carry out a small-scale human evaluation on the AutoAttack data thatfools our top-performing model. Concerningly, we estimate that humanperformance also plateaus near $90$%, which we show to be attributable to$\ell_{\infty}$-constrained attacks' generation of invalid images notconsistent with their original labels. Having characterized limitingroadblocks, we outline promising paths for future research.</description><author>Brian R. Bartoldson, James Diffenderfer, Konstantinos Parasyris, Bhavya Kailkhura</author><pubDate>Wed, 10 Jul 2024 17:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09349v2</guid></item><item><title>Green Screen Augmentation Enables Scene Generalisation in Robotic Manipulation</title><link>http://arxiv.org/abs/2407.07868v1</link><description>Generalising vision-based manipulation policies to novel environments remainsa challenging area with limited exploration. Current practices involvecollecting data in one location, training imitation learning or reinforcementlearning policies with this data, and deploying the policy in the samelocation. However, this approach lacks scalability as it necessitates datacollection in multiple locations for each task. This paper proposes a novelapproach where data is collected in a location predominantly featuring greenscreens. We introduce Green-screen Augmentation (GreenAug), employing a chromakey algorithm to overlay background textures onto a green screen. Throughextensive real-world empirical studies with over 850 training demonstrationsand 8.2k evaluation episodes, we demonstrate that GreenAug surpasses noaugmentation, standard computer vision augmentation, and prior generativeaugmentation methods in performance. While no algorithmic novelties areclaimed, our paper advocates for a fundamental shift in data collectionpractices. We propose that real-world demonstrations in future research shouldutilise green screens, followed by the application of GreenAug. We believeGreenAug unlocks policy generalisation to visually distinct novel locations,addressing the current scene generalisation limitations in robot learning.</description><author>Eugene Teoh, Sumit Patidar, Xiao Ma, Stephen James</author><pubDate>Wed, 10 Jul 2024 17:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07868v1</guid></item><item><title>Recursive Visual Programming</title><link>http://arxiv.org/abs/2312.02249v2</link><description>Visual Programming (VP) has emerged as a powerful framework for VisualQuestion Answering (VQA). By generating and executing bespoke code for eachquestion, these methods demonstrate impressive compositional and reasoningcapabilities, especially in few-shot and zero-shot scenarios. However, existingVP methods generate all code in a single function, resulting in code that issuboptimal in terms of both accuracy and interpretability. Inspired by humancoding practices, we propose Recursive Visual Programming (RVP), whichsimplifies generated routines, provides more efficient problem solving, and canmanage more complex data structures. RVP is inspired by human coding practicesand approaches VQA tasks with an iterative recursive code generation approach,allowing decomposition of complicated problems into smaller parts. Notably, RVPis capable of dynamic type assignment, i.e., as the system recursivelygenerates a new piece of code, it autonomously determines the appropriatereturn type and crafts the requisite code to generate that output. We showRVP's efficacy through extensive experiments on benchmarks including VSR, COVR,GQA, and NextQA, underscoring the value of adopting human-like recursive andmodular programming techniques for solving VQA tasks through coding.</description><author>Jiaxin Ge, Sanjay Subramanian, Baifeng Shi, Roei Herzig, Trevor Darrell</author><pubDate>Wed, 10 Jul 2024 17:26:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02249v2</guid></item><item><title>Controlling Space and Time with Diffusion Models</title><link>http://arxiv.org/abs/2407.07860v1</link><description>We present 4DiM, a cascaded diffusion model for 4D novel view synthesis(NVS), conditioned on one or more images of a general scene, and a set ofcamera poses and timestamps. To overcome challenges due to limited availabilityof 4D training data, we advocate joint training on 3D (with camera pose), 4D(pose+time) and video (time but no pose) data and propose a new architecturethat enables the same. We further advocate the calibration of SfM posed datausing monocular metric depth estimators for metric scale camera control. Formodel evaluation, we introduce new metrics to enrich and overcome shortcomingsof current evaluation schemes, demonstrating state-of-the-art results in bothfidelity and pose control compared to existing diffusion models for 3D NVS,while at the same time adding the ability to handle temporal dynamics. 4DiM isalso used for improved panorama stitching, pose-conditioned video to videotranslation, and several other tasks. For an overview seehttps://4d-diffusion.github.io</description><author>Daniel Watson, Saurabh Saxena, Lala Li, Andrea Tagliasacchi, David J. Fleet</author><pubDate>Wed, 10 Jul 2024 17:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07860v1</guid></item><item><title>FACTS About Building Retrieval Augmented Generation-based Chatbots</title><link>http://arxiv.org/abs/2407.07858v1</link><description>Enterprise chatbots, powered by generative AI, are emerging as keyapplications to enhance employee productivity. Retrieval Augmented Generation(RAG), Large Language Models (LLMs), and orchestration frameworks likeLangchain and Llamaindex are crucial for building these chatbots. However,creating effective enterprise chatbots is challenging and requires meticulousRAG pipeline engineering. This includes fine-tuning embeddings and LLMs,extracting documents from vector databases, rephrasing queries, rerankingresults, designing prompts, honoring document access controls, providingconcise responses, including references, safeguarding personal information, andbuilding orchestration agents. We present a framework for building RAG-basedchatbots based on our experience with three NVIDIA chatbots: for IT/HRbenefits, financial earnings, and general content. Our contributions arethree-fold: introducing the FACTS framework (Freshness, Architectures, Cost,Testing, Security), presenting fifteen RAG pipeline control points, andproviding empirical results on accuracy-latency tradeoffs between large andsmall LLMs. To the best of our knowledge, this is the first paper of its kindthat provides a holistic view of the factors as well as solutions for buildingsecure enterprise-grade chatbots."</description><author>Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano</author><pubDate>Wed, 10 Jul 2024 17:20:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07858v1</guid></item><item><title>Raising the Ceiling: Conflict-Free Local Feature Matching with Dynamic View Switching</title><link>http://arxiv.org/abs/2407.07789v1</link><description>Current feature matching methods prioritize improving modeling capabilitiesto better align outputs with ground-truth matches, which are the theoreticalupper bound on matching results, metaphorically depicted as the "ceiling".However, these enhancements fail to address the underlying issues that directlyhinder ground-truth matches, including the scarcity of matchable points insmall scale images, matching conflicts in dense methods, and thekeypoint-repeatability reliance in sparse methods. We propose a novel featurematching method named RCM, which Raises the Ceiling of Matching from threeaspects. 1) RCM introduces a dynamic view switching mechanism to address thescarcity of matchable points in source images by strategically switching imagepairs. 2) RCM proposes a conflict-free coarse matching module, addressingmatching conflicts in the target image through a many-to-one matching strategy.3) By integrating the semi-sparse paradigm and the coarse-to-fine architecture,RCM preserves the benefits of both high efficiency and global search,mitigating the reliance on keypoint repeatability. As a result, RCM enablesmore matchable points in the source image to be matched in an exhaustive andconflict-free manner in the target image, leading to a substantial 260%increase in ground-truth matches. Comprehensive experiments show that RCMexhibits remarkable performance and efficiency in comparison tostate-of-the-art methods.</description><author>Xiaoyong Lu, Songlin Du</author><pubDate>Wed, 10 Jul 2024 16:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07789v1</guid></item><item><title>Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</title><link>http://arxiv.org/abs/2407.07053v2</link><description>Although most current large multimodal models (LMMs) can already understandphotos of natural scenes and portraits, their understanding of abstract images,e.g., charts, maps, or layouts, and visual reasoning capabilities remains quiterudimentary. They often struggle with simple daily tasks, such as reading timefrom a clock, understanding a flowchart, or planning a route using a road map.In light of this, we design a multi-modal self-instruct, utilizing largelanguage models and their code capabilities to synthesize massive abstractimages and visual reasoning instructions across daily scenarios. Our strategyeffortlessly creates a multimodal benchmark with 11,193 instructions for eightvisual scenarios: charts, tables, simulated maps, dashboards, flowcharts,relation graphs, floor plans, and visual puzzles. \textbf{This benchmark,constructed with simple lines and geometric elements, exposes the shortcomingsof most advanced LMMs} like Claude-3.5-Sonnet and GPT-4o in abstract imageunderstanding, spatial relations reasoning, and visual element induction.Besides, to verify the quality of our synthetic data, we fine-tune an LMM using62,476 synthetic chart, table and road map instructions. The resultsdemonstrate improved chart understanding and map navigation performance, andalso demonstrate potential benefits for other visual reasoning tasks. Our codeis available at: \url{https://github.com/zwq2018/Multi-modal-Self-instruct}.</description><author>Wenqi Zhang, Zhenglin Cheng, Yuanyu He, Mengna Wang, Yongliang Shen, Zeqi Tan, Guiyang Hou, Mingqian He, Yanna Ma, Weiming Lu, Yueting Zhuang</author><pubDate>Wed, 10 Jul 2024 17:17:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07053v2</guid></item><item><title>Progressive Growing of Patch Size: Resource-Efficient Curriculum Learning for Dense Prediction Tasks</title><link>http://arxiv.org/abs/2407.07853v1</link><description>In this work, we introduce Progressive Growing of Patch Size, aresource-efficient implicit curriculum learning approach for dense predictiontasks. Our curriculum approach is defined by growing the patch size duringmodel training, which gradually increases the task's difficulty. We integratedour curriculum into the nnU-Net framework and evaluated the methodology on all10 tasks of the Medical Segmentation Decathlon. With our approach, we are ableto substantially reduce runtime, computational costs, and CO$_{2}$ emissions ofnetwork training compared to classical constant patch size training. In ourexperiments, the curriculum approach resulted in improved convergence. We areable to outperform standard nnU-Net training, which is trained with constantpatch size, in terms of Dice Score on 7 out of 10 MSD tasks while only spendingroughly 50\% of the original training runtime. To the best of our knowledge,our Progressive Growing of Patch Size is the first successful employment of asample-length curriculum in the form of patch size in the field of computervision. Our code is publicly available at \url{https://github.com}.</description><author>Stefan M. Fischer, Lina Felsner, Richard Osuala, Johannes Kiechle, Daniel M. Lang, Jan C. Peeken, Julia A. Schnabel</author><pubDate>Wed, 10 Jul 2024 17:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07853v1</guid></item><item><title>OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training</title><link>http://arxiv.org/abs/2407.07852v1</link><description>OpenDiLoCo is an open-source implementation and replication of theDistributed Low-Communication (DiLoCo) training method for large languagemodels. We provide a reproducible implementation of the DiLoCo experiments,offering it within a scalable, decentralized training framework using theHivemind library. We demonstrate its effectiveness by training a model acrosstwo continents and three countries, while maintaining 90-95% computeutilization. Additionally, we conduct ablations studies focusing on thealgorithm's compute efficiency, scalability in the number of workers and showthat its gradients can be all-reduced using FP16 without any performancedegradation. Furthermore, we scale OpenDiLoCo to 3x the size of the originalwork, demonstrating its effectiveness for billion parameter models.</description><author>Sami Jaghouar, Jack Min Ong, Johannes Hagemann</author><pubDate>Wed, 10 Jul 2024 17:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07852v1</guid></item><item><title>Lie Group Decompositions for Equivariant Neural Networks</title><link>http://arxiv.org/abs/2310.11366v2</link><description>Invariance and equivariance to geometrical transformations have proven to bevery useful inductive biases when training (convolutional) neural networkmodels, especially in the low-data regime. Much work has focused on the casewhere the symmetry group employed is compact or abelian, or both. Recent workhas explored enlarging the class of transformations used to the case of Liegroups, principally through the use of their Lie algebra, as well as the groupexponential and logarithm maps. The applicability of such methods is limited bythe fact that depending on the group of interest $G$, the exponential map maynot be surjective. Further limitations are encountered when $G$ is neithercompact nor abelian. Using the structure and geometry of Lie groups and theirhomogeneous spaces, we present a framework by which it is possible to work withsuch groups primarily focusing on the groups $G = \text{GL}^{+}(n, \mathbb{R})$and $G = \text{SL}(n, \mathbb{R})$, as well as their representation as affinetransformations $\mathbb{R}^{n} \rtimes G$. Invariant integration as well as aglobal parametrization is realized by a decomposition into subgroups andsubmanifolds which can be handled individually. Under this framework, we showhow convolution kernels can be parametrized to build models equivariant withrespect to affine transformations. We evaluate the robustness andout-of-distribution generalisation capability of our model on the benchmarkaffine-invariant classification task, outperforming previous proposals.</description><author>Mircea Mironenco, Patrick Forré</author><pubDate>Wed, 10 Jul 2024 17:12:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11366v2</guid></item><item><title>Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers</title><link>http://arxiv.org/abs/2407.07848v1</link><description>Previous work has demonstrated that MLPs within ReLU Transformers exhibithigh levels of sparsity, with many of their activations equal to zero for anygiven token. We build on that work to more deeply explore how token-levelsparsity evolves over the course of training, and how it connects to broadersparsity patterns over the course of a sequence or batch, demonstrating thatthe different layers within small transformers exhibit distinctlylayer-specific patterns on both of these fronts. In particular, we demonstratethat the first and last layer of the network have distinctive and in many waysinverted relationships to sparsity, and explore implications for the structureof feature representations being learned at different depths of the model. Weadditionally explore the phenomenon of ReLU dimensions "turning off", and showevidence suggesting that "neuron death" is being primarily driven by thedynamics of training, rather than simply occurring randomly or accidentally asa result of outliers.</description><author>Cody Wild, Jesper Anderson</author><pubDate>Wed, 10 Jul 2024 17:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07848v1</guid></item><item><title>Enhancing Medication Recommendation with LLM Text Representation</title><link>http://arxiv.org/abs/2407.10453v1</link><description>Most of the existing medication recommendation models are predicted with onlystructured data such as medical codes, with the remaining other large amount ofunstructured or semi-structured data underutilization. To increase theutilization effectively, we proposed a method of enhancing medicationrecommendation with Large Language Model (LLM) text representation. LLMharnesses powerful language understanding and generation capabilities, enablingthe extraction of information from complex and lengthy unstructured data suchas clinical notes which contain complex terminology. This method can be appliedto several existing base models we selected and improve medicationrecommendation performance with the combination representation of text andmedical codes experiments on two different datasets. LLM text representationalone can even demonstrate a comparable ability to the medical coderepresentation alone. Overall, this is a general method that can be applied toother models for improved recommendations.</description><author>Yu-Tzu Lee</author><pubDate>Mon, 15 Jul 2024 05:51:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10453v1</guid></item><item><title>SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation</title><link>http://arxiv.org/abs/2310.00796v3</link><description>Strong inductive biases enable learning from little data and helpgeneralization outside of the training distribution. Popular neuralarchitectures such as Transformers lack strong structural inductive biases forseq2seq NLP tasks on their own. Consequently, they struggle with systematicgeneralization beyond the training distribution, e.g. with extrapolating tolonger inputs, even when pre-trained on large amounts of text. We show how astructural inductive bias can be efficiently injected into a seq2seq model bypre-training it to simulate structural transformations on synthetic data.Specifically, we inject an inductive bias towards Finite State Transducers(FSTs) into a Transformer by pre-training it to simulate FSTs given theirdescriptions. Our experiments show that our method imparts the desiredinductive bias, resulting in improved systematic generalization and betterfew-shot learning for FST-like tasks. Our analysis shows that fine-tuned modelsaccurately capture the state dynamics of the unseen underlying FSTs, suggestingthat the simulation process is internalized by the fine-tuned model.</description><author>Matthias Lindemann, Alexander Koller, Ivan Titov</author><pubDate>Wed, 10 Jul 2024 17:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00796v3</guid></item><item><title>OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion</title><link>http://arxiv.org/abs/2407.07844v1</link><description>Open-vocabulary detection is a challenging task due to the requirement ofdetecting objects based on class names, including those not encountered duringtraining. Existing methods have shown strong zero-shot detection capabilitiesthrough pre-training on diverse large-scale datasets. However, these approachesstill face two primary challenges: (i) how to universally integrate diversedata sources for end-to-end training, and (ii) how to effectively leverage thelanguage-aware capability for region-level cross-modality understanding. Toaddress these challenges, we propose a novel unified open-vocabulary detectionmethod called OV-DINO, which pre-trains on diverse large-scale datasets withlanguage-aware selective fusion in a unified framework. Specifically, weintroduce a Unified Data Integration (UniDI) pipeline to enable end-to-endtraining and eliminate noise from pseudo-label generation by unifying differentdata sources into detection-centric data. In addition, we propose aLanguage-Aware Selective Fusion (LASF) module to enable the language-awareability of the model through a language-aware query selection and fusionprocess. We evaluate the performance of the proposed OV-DINO on popularopen-vocabulary detection benchmark datasets, achieving state-of-the-artresults with an AP of 50.6\% on the COCO dataset and 40.0\% on the LVIS datasetin a zero-shot manner, demonstrating its strong generalization ability.Furthermore, the fine-tuned OV-DINO on COCO achieves 58.4\% AP, outperformingmany existing methods with the same backbone. The code for OV-DINO will beavailable at\href{https://github.com/wanghao9610/OV-DINO}{https://github.com/wanghao9610/OV-DINO}.</description><author>Hao Wang, Pengzhen Ren, Zequn Jie, Xiao Dong, Chengjian Feng, Yinlong Qian, Lin Ma, Dongmei Jiang, Yaowei Wang, Xiangyuan Lan, Xiaodan Liang</author><pubDate>Wed, 10 Jul 2024 17:05:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07844v1</guid></item><item><title>Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search</title><link>http://arxiv.org/abs/2402.11354v2</link><description>Approximate nearest neighbor search (ANNS) in high-dimensional spaces is apivotal challenge in the field of machine learning. In recent years,graph-based methods have emerged as the superior approach to ANNS, establishinga new state of the art. Although various optimizations for graph-based ANNShave been introduced, they predominantly rely on heuristic methods that lackformal theoretical backing. This paper aims to enhance routing withingraph-based ANNS by introducing a method that offers a probabilistic guaranteewhen exploring a node's neighbors in the graph. We formulate the problem asprobabilistic routing and develop two baseline strategies by incorporatinglocality-sensitive techniques. Subsequently, we introduce PEOs, a novelapproach that efficiently identifies which neighbors in the graph should beconsidered for exact distance calculation, thus significantly improvingefficiency in practice. Our experiments demonstrate that equipping PEOs canincrease throughput on commonly utilized graph indexes (HNSW and NSSG) by afactor of 1.6 to 2.5, and its efficiency consistently outperforms theleading-edge routing technique by 1.1 to 1.4 times.</description><author>Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa</author><pubDate>Wed, 10 Jul 2024 17:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11354v2</guid></item><item><title>Study on Aspect Ratio Variability toward Robustness of Vision Transformer-based Vehicle Re-identification</title><link>http://arxiv.org/abs/2407.07842v1</link><description>Vision Transformers (ViTs) have excelled in vehicle re-identification (ReID)tasks. However, non-square aspect ratios of image or video input mightsignificantly affect the re-identification performance. To address this issue,we propose a novel ViT-based ReID framework in this paper, which fuses modelstrained on a variety of aspect ratios. Our main contributions are threefold:(i) We analyze aspect ratio performance on VeRi-776 and VehicleID datasets,guiding input settings based on aspect ratios of original images. (ii) Weintroduce patch-wise mixup intra-image during ViT patchification (guided byspatial attention scores) and implement uneven stride for better object aspectratio matching. (iii) We propose a dynamic feature fusing ReID network,enhancing model robustness. Our ReID method achieves a significantly improvedmean Average Precision (mAP) of 91.0\% compared to the the closeststate-of-the-art (CAL) result of 80.9\% on VehicleID dataset.</description><author>Mei Qiu, Lauren Christopher, Lingxi Li</author><pubDate>Wed, 10 Jul 2024 17:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07842v1</guid></item><item><title>Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models</title><link>http://arxiv.org/abs/2402.14848v2</link><description>This paper explores the impact of extending input lengths on the capabilitiesof Large Language Models (LLMs). Despite LLMs advancements in recent times,their performance consistency across different input lengths is not wellunderstood. We investigate this aspect by introducing a novel QA reasoningframework, specifically designed to assess the impact of input length. Weisolate the effect of input length using multiple versions of the same sample,each being extended with padding of different lengths, types and locations. Ourfindings show a notable degradation in LLMs' reasoning performance at muchshorter input lengths than their technical maximum. We show that thedegradation trend appears in every version of our dataset, although atdifferent intensities. Additionally, our study reveals that the traditionalmetric of next word prediction correlates negatively with performance of LLMs'on our reasoning dataset. We analyse our results and identify failure modesthat can serve as useful guides for future research, potentially informingstrategies to address the limitations observed in LLMs.</description><author>Mosh Levy, Alon Jacoby, Yoav Goldberg</author><pubDate>Wed, 10 Jul 2024 17:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14848v2</guid></item><item><title>A New Approach Towards Autoformalization</title><link>http://arxiv.org/abs/2310.07957v3</link><description>Verifying mathematical proofs is difficult, but can be automated with theassistance of a computer. Autoformalization is the task of automaticallytranslating natural language mathematics into a formal language that can beverified by a program. This is a challenging task, and especially forhigher-level mathematics found in research papers. Research paper mathematicsrequires large amounts of background and context. In this paper, we propose anavenue towards tackling autoformalization for research-level mathematics, bybreaking the task into easier and more approachable subtasks: unlinkedformalization (formalization with unlinked definitions and theorems), entitylinking (linking to the proper theorems and definitions), and finally adjustingtypes so it passes the type checker. In addition, we present arXiv2Formal, abenchmark dataset for unlinked formalization consisting of 50 theoremsformalized for the Lean theorem prover sampled from papers on arXiv.org. Wewelcome any contributions from the community to future versions of thisdataset.</description><author>Nilay Patel, Rahul Saha, Jeffrey Flanigan</author><pubDate>Tue, 09 Jul 2024 19:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07957v3</guid></item><item><title>Benchmarking Embedding Aggregation Methods in Computational Pathology: A Clinical Data Perspective</title><link>http://arxiv.org/abs/2407.07841v1</link><description>Recent advances in artificial intelligence (AI), in particularself-supervised learning of foundation models (FMs), are revolutionizingmedical imaging and computational pathology (CPath). A constant challenge inthe analysis of digital Whole Slide Images (WSIs) is the problem of aggregatingtens of thousands of tile-level image embeddings to a slide-levelrepresentation. Due to the prevalent use of datasets created for genomicresearch, such as TCGA, for method development, the performance of thesetechniques on diagnostic slides from clinical practice has been inadequatelyexplored. This study conducts a thorough benchmarking analysis of tenslide-level aggregation techniques across nine clinically relevant tasks,including diagnostic assessment, biomarker classification, and outcomeprediction. The results yield following key insights: (1) Embeddings derivedfrom domain-specific (histological images) FMs outperform those from genericImageNet-based models across aggregation methods. (2) Spatial-aware aggregatorsenhance the performance significantly when using ImageNet pre-trained modelsbut not when using FMs. (3) No single model excels in all tasks andspatially-aware models do not show general superiority as it would be expected.These findings underscore the need for more adaptable and universallyapplicable aggregation techniques, guiding future research towards tools thatbetter meet the evolving needs of clinical-AI in pathology. The code used inthis work is available at\url{https://github.com/fuchs-lab-public/CPath_SABenchmark}.</description><author>Shengjia Chen, Gabriele Campanella, Abdulkadir Elmas, Aryeh Stock, Jennifer Zeng, Alexandros D. Polydorides, Adam J. Schoenfeld, Kuan-lin Huang, Jane Houldsworth, Chad Vanderbilt, Thomas J. Fuchs</author><pubDate>Wed, 10 Jul 2024 17:00:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07841v1</guid></item><item><title>Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison</title><link>http://arxiv.org/abs/2407.07840v1</link><description>Despite tremendous advancements, current state-of-the-art Vision-LanguageModels (VLMs) are still far from perfect. They tend to hallucinate and maygenerate biased responses. In such circumstances, having a way to assess thereliability of a given response generated by a VLM is quite useful. Existingmethods, such as estimating uncertainty using answer likelihoods orprompt-based confidence generation, often suffer from overconfidence. Othermethods use self-consistency comparison but are affected by confirmationbiases. To alleviate these, we propose \textbf{De}compose and \textbf{C}ompare\textbf{C}onsistency (\texttt{DeCC}) for reliability measurement. By comparingthe consistency between the direct answer generated using the VLM's internalreasoning process, and the indirect answers obtained by decomposing thequestion into sub-questions and reasoning over the sub-answers produced by theVLM, \texttt{DeCC} measures the reliability of VLM's direct answer. Experimentsacross six vision-language tasks with three VLMs show \texttt{DeCC}'sreliability estimation achieves better correlation with task accuracy comparedto the existing methods.</description><author>Qian Yang, Weixiang Yan, Aishwarya Agrawal</author><pubDate>Wed, 10 Jul 2024 17:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07840v1</guid></item><item><title>MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series</title><link>http://arxiv.org/abs/2405.19327v4</link><description>Large Language Models (LLMs) have made great strides in recent years toachieve unprecedented performance across different tasks. However, due tocommercial interest, the most competitive models like GPT, Gemini, and Claudehave been gated behind proprietary interfaces without disclosing the trainingdetails. Recently, many institutions have open-sourced several strong LLMs likeLLaMA-3, comparable to existing closed-source LLMs. However, only the model'sweights are provided with most details (e.g., intermediate checkpoints,pre-training corpus, and training code, etc.) being undisclosed. To improve thetransparency of LLMs, the research community has formed to open-source trulyopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-trainingcorpus and training code) are being provided. These models have greatlyadvanced the scientific study of these large models including their strengths,weaknesses, biases and risks. However, we observe that the existing truly openLLMs on reasoning, knowledge, and coding tasks are still inferior to existingstate-of-the-art LLMs with similar model sizes. To this end, we open-sourceMAP-Neo, a highly capable and transparent bilingual language model with 7Bparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is thefirst fully open-sourced bilingual LLM with comparable performance compared toexisting state-of-the-art LLMs. Moreover, we open-source all details toreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaningpipeline, checkpoints, and well-optimized training/evaluation framework areprovided. Finally, we hope our MAP-Neo will enhance and strengthen the openresearch community and inspire more innovations and creativities to facilitatethe further improvements of LLMs.</description><author>Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen</author><pubDate>Wed, 10 Jul 2024 16:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19327v4</guid></item><item><title>RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation</title><link>http://arxiv.org/abs/2407.07835v1</link><description>Automated 3D city generation, focusing on road networks and building layouts,is in high demand for applications in urban design, multimedia games andautonomous driving simulations. The surge of generative AI facilitatesdesigning city layouts based on deep learning models. However, the lack ofhigh-quality datasets and benchmarks hinders the progress of these data-drivenmethods in generating road networks and building layouts. Furthermore, fewstudies consider urban characteristics, which generally take graphics asanalysis objects and are crucial for practical applications, to control thegenerative process. To alleviate these problems, we introduce a multimodaldataset with accompanying evaluation metrics for controllable generation ofRoad networks and Building layouts (RoBus), which is the first and largestopen-source dataset in city generation so far. RoBus dataset is formatted asimages, graphics and texts, with $72,400$ paired samples that cover around$80,000km^2$ globally. We analyze the RoBus dataset statistically and validatethe effectiveness against existing road networks and building layoutsgeneration methods. Additionally, we design new baselines that incorporateurban characteristics, such as road orientation and building density, in theprocess of generating road networks and building layouts using the RoBusdataset, enhancing the practicality of automated urban design. The RoBusdataset and related codes are published athttps://github.com/tourlics/RoBus_Dataset.</description><author>Tao Li, Ruihang Li, Huangnan Zheng, Shanding Ye, Shijian Li, Zhijie Pan</author><pubDate>Wed, 10 Jul 2024 16:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07835v1</guid></item><item><title>TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification</title><link>http://arxiv.org/abs/2407.06658v2</link><description>Geomagnetic storms, caused by solar wind energy transfer to Earth's magneticfield, can disrupt critical infrastructure like GPS, satellite communications,and power grids. The disturbance storm-time (Dst) index measures stormintensity. Despite advancements in empirical, physics-based, andmachine-learning models using real-time solar wind data, accurately forecastingextreme geomagnetic events remains challenging due to noise and sensorfailures. This research introduces TriQXNet, a novel hybrid classical-quantumneural network for Dst forecasting. Our model integrates classical and quantumcomputing, conformal prediction, and explainable AI (XAI) within a hybridarchitecture. To ensure high-quality input data, we developed a comprehensivepreprocessing pipeline that included feature selection, normalization,aggregation, and imputation. TriQXNet processes preprocessed solar wind datafrom NASA's ACE and NOAA's DSCOVR satellites, predicting the Dst index for thecurrent hour and the next, providing vital advance notice to mitigategeomagnetic storm impacts. TriQXNet outperforms 13 state-of-the-art hybriddeep-learning models, achieving a root mean squared error of 9.27 nanoteslas(nT). Rigorous evaluation through 10-fold cross-validated paired t-testsconfirmed its superior performance with 95% confidence. Conformal predictiontechniques provide quantifiable uncertainty, which is essential for operationaldecisions, while XAI methods like ShapTime enhance interpretability.Comparative analysis shows TriQXNet's superior forecasting accuracy, setting anew level of expectations for geomagnetic storm prediction and highlighting thepotential of classical-quantum hybrid models in space weather forecasting.</description><author>Md Abrar Jahin, M. F. Mridha, Zeyar Aung, Nilanjan Dey, R. Simon Sherratt</author><pubDate>Wed, 10 Jul 2024 16:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06658v2</guid></item><item><title>Disentangled Representation Learning through Geometry Preservation with the Gromov-Monge Gap</title><link>http://arxiv.org/abs/2407.07829v1</link><description>Learning disentangled representations in an unsupervised manner is afundamental challenge in machine learning. Solving it may unlock otherproblems, such as generalization, interpretability, or fairness. Whileremarkably difficult to solve in general, recent works have shown thatdisentanglement is provably achievable under additional assumptions that canleverage geometrical constraints, such as local isometry. To use theseinsights, we propose a novel perspective on disentangled representationlearning built on quadratic optimal transport. Specifically, we formulate theproblem in the Gromov-Monge setting, which seeks isometric mappings betweendistributions supported on different spaces. We propose the Gromov-Monge-Gap(GMG), a regularizer that quantifies the geometry-preservation of an arbitrarypush-forward map between two distributions supported on different spaces. Wedemonstrate the effectiveness of GMG regularization for disentanglement on fourstandard benchmarks. Moreover, we show that geometry preservation can evenencourage unsupervised disentanglement without the standard reconstructionobjective - making the underlying model decoder-free, and promising a morepractically viable and scalable perspective on unsupervised disentanglement.</description><author>Théo Uscidda, Luca Eyring, Karsten Roth, Fabian Theis, Zeynep Akata, Marco Cuturi</author><pubDate>Wed, 10 Jul 2024 16:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07829v1</guid></item><item><title>Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG</title><link>http://arxiv.org/abs/2407.11481v1</link><description>In the context of cardiovascular diseases (CVD) that exhibit an elevatedprevalence and mortality, the electrocardiogram (ECG) is a popular and standarddiagnostic tool for doctors, commonly utilizing a 12-lead configuration inclinical practice. However, the 10 electrodes placed on the surface would causea lot of inconvenience and discomfort, while the rapidly advancing wearabledevices adopt the reduced-lead or single-lead ECG to reduce discomfort as asolution in long-term monitoring. Since the single-lead ECG is a subset of12-lead ECG, it provides insufficient cardiac health information and plays asubstandard role in real-world healthcare applications. Hence, it is necessaryto utilize signal generation technologies to reduce their clinical importancegap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,this study proposes a multi-channel masked autoencoder (MCMA) for this goal. Inthe experimental results, the visualized results between the generated and realsignals can demonstrate the effectiveness of the proposed framework. At thesame time, this study introduces a comprehensive evaluation benchmark namedECGGenEval, encompassing the signal-level, feature-level, and diagnostic-levelevaluations, providing a holistic assessment of 12-lead ECG signals andgenerative model. Further, the quantitative experimental results are asfollows, the mean square errors of 0.0178 and 0.0658, correlation coefficientsof 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score withtwo generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-levelevaluation, achieving the state-of-the-art performance. The open-source code ispublicly available at \url{https://github.com/CHENJIAR3/MCMA}.</description><author>Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong</author><pubDate>Tue, 16 Jul 2024 08:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11481v1</guid></item><item><title>Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model</title><link>http://arxiv.org/abs/2404.04167v4</link><description>In this study, we introduce CT-LLM, a 2B large language model (LLM) thatillustrates a pivotal shift towards prioritizing the Chinese language indeveloping LLMs. Uniquely initiated from scratch, CT-LLM diverges from theconventional methodology by primarily incorporating Chinese textual data,utilizing an extensive corpus of 1,200 billion tokens, including 800 billionChinese tokens, 300 billion English tokens, and 100 billion code tokens. Thisstrategic composition facilitates the model's exceptional proficiency inunderstanding and processing Chinese, a capability further enhanced throughalignment techniques. Demonstrating remarkable performance on the CHC-Bench,CT-LLM excels in Chinese language tasks, and showcases its adeptness in Englishthrough SFT. This research challenges the prevailing paradigm of training LLMspredominantly on English corpora and then adapting them to other languages,broadening the horizons for LLM training methodologies. By open-sourcing thefull process of training a Chinese LLM, including a detailed data processingprocedure with the obtained Massive Appropriate Pretraining Chinese Corpus(MAP-CC), a well-chosen multidisciplinary Chinese Hard Case Benchmark(CHC-Bench), and the 2B-size Chinese Tiny LLM (CT-LLM), we aim to fosterfurther exploration and innovation in both academia and industry, paving theway for more inclusive and versatile language models.</description><author>Xinrun Du, Zhouliang Yu, Songyang Gao, Ding Pan, Yuyang Cheng, Ziyang Ma, Ruibin Yuan, Xingwei Qu, Jiaheng Liu, Tianyu Zheng, Xinchen Luo, Guorui Zhou, Wenhu Chen, Ge Zhang</author><pubDate>Wed, 10 Jul 2024 16:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04167v4</guid></item><item><title>Estimating the stability number of a random graph using convolutional neural networks</title><link>http://arxiv.org/abs/2407.07827v1</link><description>Graph combinatorial optimization problems are widely applicable andnotoriously difficult to compute; for example, consider the traveling salesmanor facility location problems. In this paper, we explore the feasibility ofusing convolutional neural networks (CNNs) on graph images to predict thecardinality of combinatorial properties of random graphs and networks.Specifically, we use image representations of modified adjacency matrices ofrandom graphs as training samples for a CNN model to predict the stabilitynumber of random graphs; where the stability number is the cardinality of amaximum set of vertices containing no pairwise adjacency. Our approachdemonstrates the potential for applying deep learning in combinatorialoptimization problems.</description><author>Randy Davila</author><pubDate>Wed, 10 Jul 2024 16:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07827v1</guid></item><item><title>RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement</title><link>http://arxiv.org/abs/2407.07825v1</link><description>In this paper, we aim to generate clean speech frame by frame from a livevideo stream and a noisy audio stream without relying on future inputs. To thisend, we propose RT-LA-VocE, which completely re-designs every component ofLA-VocE, a state-of-the-art non-causal audio-visual speech enhancement model,to perform causal real-time inference with a 40ms input frame. We do so bydevising new visual and audio encoders that rely solely on past frames,replacing the Transformer encoder with the Emformer, and designing a new causalneural vocoder C-HiFi-GAN. On the popular AVSpeech dataset, we show that ouralgorithm achieves state-of-the-art results in all real-time scenarios. Moreimportantly, each component is carefully tuned to minimize the algorithmlatency to the theoretical minimum (40ms) while maintaining a low end-to-endprocessing latency of 28.15ms per frame, enabling real-time frame-by-frameenhancement with minimal delay.</description><author>Honglie Chen, Rodrigo Mira, Stavros Petridis, Maja Pantic</author><pubDate>Wed, 10 Jul 2024 16:49:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07825v1</guid></item><item><title>When to Accept Automated Predictions and When to Defer to Human Judgment?</title><link>http://arxiv.org/abs/2407.07821v1</link><description>Ensuring the reliability and safety of automated decision-making is crucial.It is well-known that data distribution shifts in machine learning can produceunreliable outcomes. This paper proposes a new approach for measuring thereliability of predictions under distribution shifts. We analyze how theoutputs of a trained neural network change using clustering to measuredistances between outputs and class centroids. We propose this distance as ametric to evaluate the confidence of predictions under distribution shifts. Weassign each prediction to a cluster with centroid representing the mean softmaxoutput for all correct predictions of a given class. We then define a safetythreshold for a class as the smallest distance from an incorrect prediction tothe given class centroid. We evaluate the approach on the MNIST and CIFAR-10datasets using a Convolutional Neural Network and a Vision Transformer,respectively. The results show that our approach is consistent across thesedata sets and network models, and indicate that the proposed metric can offeran efficient way of determining when automated predictions are acceptable andwhen they should be deferred to human operators given a distribution shift.</description><author>Daniel Sikar, Artur Garcez, Tillman Weyde, Robin Bloomfield, Kaleem Peeroo</author><pubDate>Wed, 10 Jul 2024 16:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07821v1</guid></item><item><title>Analysis of Langevin Monte Carlo from Poincaré to Log-Sobolev</title><link>http://arxiv.org/abs/2112.12662v2</link><description>Classically, the continuous-time Langevin diffusion converges exponentiallyfast to its stationary distribution $\pi$ under the sole assumption that $\pi$satisfies a Poincar\'e inequality. Using this fact to provide guarantees forthe discrete-time Langevin Monte Carlo (LMC) algorithm, however, isconsiderably more challenging due to the need for working with chi-squared orR\'enyi divergences, and prior works have largely focused on stronglylog-concave targets. In this work, we provide the first convergence guaranteesfor LMC assuming that $\pi$ satisfies either a Lata\l{}a--Oleszkiewicz ormodified log-Sobolev inequality, which interpolates between the Poincar\'e andlog-Sobolev settings. Unlike prior works, our results allow for weak smoothnessand do not require convexity or dissipativity conditions.</description><author>Sinho Chewi, Murat A. Erdogdu, Mufan Bill Li, Ruoqi Shen, Matthew Zhang</author><pubDate>Wed, 10 Jul 2024 16:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.12662v2</guid></item><item><title>AXIAL: Attention-based eXplainability for Interpretable Alzheimer's Localized Diagnosis using 2D CNNs on 3D MRI brain scans</title><link>http://arxiv.org/abs/2407.02418v2</link><description>This study presents an innovative method for Alzheimer's disease diagnosisusing 3D MRI designed to enhance the explainability of model decisions. Ourapproach adopts a soft attention mechanism, enabling 2D CNNs to extractvolumetric representations. At the same time, the importance of each slice indecision-making is learned, allowing the generation of a voxel-level attentionmap to produce an explainable MRI. To test our method and ensure thereproducibility of our results, we chose a standardized collection of MRI datafrom the Alzheimer's Disease Neuroimaging Initiative (ADNI). On this dataset,our method significantly outperforms state-of-the-art methods in (i)distinguishing AD from cognitive normal (CN) with an accuracy of 0.856 andMatthew's correlation coefficient (MCC) of 0.712, representing improvements of2.4% and 5.3% respectively over the second-best, and (ii) in the prognostictask of discerning stable from progressive mild cognitive impairment (MCI) withan accuracy of 0.725 and MCC of 0.443, showing improvements of 10.2% and 20.5%respectively over the second-best. We achieved this prognostic result byadopting a double transfer learning strategy, which enhanced sensitivity tomorphological changes and facilitated early-stage AD detection. Withvoxel-level precision, our method identified which specific areas are beingpaid attention to, identifying these predominant brain regions: thehippocampus, the amygdala, the parahippocampal, and the inferior lateralventricles. All these areas are clinically associated with AD development.Furthermore, our approach consistently found the same AD-related areas acrossdifferent cross-validation folds, proving its robustness and precision inhighlighting areas that align closely with known pathological markers of thedisease.</description><author>Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano</author><pubDate>Tue, 01 Oct 2024 17:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02418v2</guid></item><item><title>The Misclassification Likelihood Matrix: Some Classes Are More Likely To Be Misclassified Than Others</title><link>http://arxiv.org/abs/2407.07818v1</link><description>This study introduces the Misclassification Likelihood Matrix (MLM) as anovel tool for quantifying the reliability of neural network predictions underdistribution shifts. The MLM is obtained by leveraging softmax outputs andclustering techniques to measure the distances between the predictions of atrained neural network and class centroids. By analyzing these distances, theMLM provides a comprehensive view of the model's misclassification tendencies,enabling decision-makers to identify the most common and critical sources oferrors. The MLM allows for the prioritization of model improvements and theestablishment of decision thresholds based on acceptable risk levels. Theapproach is evaluated on the MNIST dataset using a Convolutional Neural Network(CNN) and a perturbed version of the dataset to simulate distribution shifts.The results demonstrate the effectiveness of the MLM in assessing thereliability of predictions and highlight its potential in enhancing theinterpretability and risk mitigation capabilities of neural networks. Theimplications of this work extend beyond image classification, with ongoingapplications in autonomous systems, such as self-driving cars, to improve thesafety and reliability of decision-making in complex, real-world environments.</description><author>Daniel Sikar, Artur Garcez, Robin Bloomfield, Tillman Weyde, Kaleem Peeroo, Naman Singh, Maeve Hutchinson, Mirela Reljan-Delaney</author><pubDate>Wed, 10 Jul 2024 16:43:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07818v1</guid></item><item><title>A Survey on Deep Stereo Matching in the Twenties</title><link>http://arxiv.org/abs/2407.07816v1</link><description>Stereo matching is close to hitting a half-century of history, yet witnesseda rapid evolution in the last decade thanks to deep learning. While previoussurveys in the late 2010s covered the first stage of this revolution, the lastfive years of research brought further ground-breaking advancements to thefield. This paper aims to fill this gap in a two-fold manner: first, we offeran in-depth examination of the latest developments in deep stereo matching,focusing on the pioneering architectural designs and groundbreaking paradigmsthat have redefined the field in the 2020s; second, we present a thoroughanalysis of the critical challenges that have emerged alongside these advances,providing a comprehensive taxonomy of these issues and exploring thestate-of-the-art techniques proposed to address them. By reviewing both thearchitectural innovations and the key challenges, we offer a holistic view ofdeep stereo matching and highlight the specific areas that require furtherinvestigation. To accompany this survey, we maintain a regularly updatedproject page that catalogs papers on deep stereo matching in ourAwesome-Deep-Stereo-Matching(https://github.com/fabiotosi92/Awesome-Deep-Stereo-Matching) repository.</description><author>Fabio Tosi, Luca Bartolomei, Matteo Poggi</author><pubDate>Wed, 10 Jul 2024 16:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07816v1</guid></item><item><title>3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes</title><link>http://arxiv.org/abs/2407.07090v2</link><description>Particle-based representations of radiance fields such as 3D GaussianSplatting have found great success for reconstructing and re-rendering ofcomplex scenes. Most existing methods render particles via rasterization,projecting them to screen space tiles for processing in a sorted order. Thiswork instead considers ray tracing the particles, building a bounding volumehierarchy and casting a ray for each pixel using high-performance GPU raytracing hardware. To efficiently handle large numbers of semi-transparentparticles, we describe a specialized rendering algorithm which encapsulatesparticles with bounding meshes to leverage fast ray-triangle intersections, andshades batches of intersections in depth-order. The benefits of ray tracing arewell-known in computer graphics: processing incoherent rays for secondarylighting effects such as shadows and reflections, rendering fromhighly-distorted cameras common in robotics, stochastically sampling rays, andmore. With our renderer, this flexibility comes at little cost compared torasterization. Experiments demonstrate the speed and accuracy of our approach,as well as several applications in computer graphics and vision. We furtherpropose related improvements to the basic Gaussian representation, including asimple use of generalized kernel functions which significantly reduces particlehit counts.</description><author>Nicolas Moenne-Loccoz, Ashkan Mirzaei, Or Perel, Riccardo de Lutio, Janick Martinez Esturo, Gavriel State, Sanja Fidler, Nicholas Sharp, Zan Gojcic</author><pubDate>Wed, 10 Jul 2024 16:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07090v2</guid></item><item><title>Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise</title><link>http://arxiv.org/abs/2305.13498v3</link><description>This article aims to investigate the impact of noise on parameter fitting foran Ornstein-Uhlenbeck process, focusing on the effects of multiplicative andthermal noise on the accuracy of signal separation. To address these issues, wepropose algorithms and methods that can effectively distinguish between thermaland multiplicative noise and improve the precision of parameter estimation foroptimal data analysis. Specifically, we explore the impact of bothmultiplicative and thermal noise on the obfuscation of the actual signal andpropose methods to resolve them. First, we present an algorithm that caneffectively separate thermal noise with comparable performance to HamiltonMonte Carlo (HMC) but with significantly improved speed. We then analyzemultiplicative noise and demonstrate that HMC is insufficient for isolatingthermal and multiplicative noise. However, we show that, with additionalknowledge of the ratio between thermal and multiplicative noise, we canaccurately distinguish between the two types of noise when provided with asufficiently large sampling rate or an amplitude of multiplicative noisesmaller than thermal noise. Thus, we demonstrate the mechanism underlying anotherwise counterintuitive phenomenon: when multiplicative noise dominates thenoise spectrum, one can successfully estimate the parameters for such systemsafter adding additional white noise to shift the noise balance.</description><author>Simon Carter, Lilianne Mujica-Parodi, Helmut H. Strey</author><pubDate>Wed, 10 Jul 2024 16:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13498v3</guid></item><item><title>Transformer Alignment in Large Language Models</title><link>http://arxiv.org/abs/2407.07810v1</link><description>Large Language Models (LLMs) have made significant strides in naturallanguage processing, and a precise understanding of the internal mechanismsdriving their success is essential. We regard LLMs as transforming embeddingsvia a discrete, coupled, nonlinear, dynamical system in high dimensions. Thisperspective motivates tracing the trajectories of individual tokens as theypass through transformer blocks, and linearizing the system along thesetrajectories through their Jacobian matrices. In our analysis of 38 openlyavailable LLMs, we uncover the alignment of top left and right singular vectorsof Residual Jacobians, as well as the emergence of linearity and layer-wiseexponential growth. Notably, we discover that increased alignment$\textit{positively correlates}$ with model performance. Metrics evaluatedpost-training show significant improvement in comparison to measurements madewith randomly initialized weights, highlighting the significant effects oftraining in transformers. These findings reveal a remarkable level ofregularity that has previously been overlooked, reinforcing the dynamicalinterpretation and paving the way for deeper understanding and optimization ofLLM architectures.</description><author>Murdock Aubry, Haoming Meng, Anton Sugolov, Vardan Papyan</author><pubDate>Wed, 10 Jul 2024 16:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07810v1</guid></item><item><title>SUMix: Mixup with Semantic and Uncertain Information</title><link>http://arxiv.org/abs/2407.07805v1</link><description>Mixup data augmentation approaches have been applied for various tasks ofdeep learning to improve the generalization ability of deep neural networks.Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch inone image with patches from another to generate the mixed image. Similarly, thecorresponding labels are linearly combined by a fixed ratio $\lambda$ by l. Theobjects in two images may be overlapped during the mixing process, so somesemantic information is corrupted in the mixed samples. In this case, the mixedimage does not match the mixed label information. Besides, such a label maymislead the deep learning model training, which results in poor performance. Tosolve this problem, we proposed a novel approach named SUMix to learn themixing ratio as well as the uncertainty for the mixed samples during thetraining process. First, we design a learnable similarity function to computean accurate mix ratio. Second, an approach is investigated as a regularizedterm to model the uncertainty of the mixed samples. We conduct experiments onfive image benchmarks, and extensive experimental results imply that our methodis capable of improving the performance of classifiers with differentcutting-based mixup approaches. The source code is available athttps://github.com/JinXins/SUMix.</description><author>Huafeng Qin, Xin Jin, Hongyu Zhu, Hongchao Liao, Mounîm A. El-Yacoubi, Xinbo Gao</author><pubDate>Wed, 10 Jul 2024 16:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07805v1</guid></item><item><title>ROSA: Random Subspace Adaptation for Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2407.07802v1</link><description>Model training requires significantly more memory, compared with inference.Parameter efficient fine-tuning (PEFT) methods provide a means of adaptinglarge models to downstream tasks using less memory. However, existing methodssuch as adapters, prompt tuning or low-rank adaptation (LoRA) either introducelatency overhead at inference time or achieve subpar downstream performancecompared with full fine-tuning. In this work we propose Random SubspaceAdaptation (ROSA), a method that outperforms previous PEFT methods by asignificant margin, while maintaining a zero latency overhead during inferencetime. In contrast to previous methods, ROSA is able to adapt subspaces ofarbitrarily large dimension, better approximating full-finetuning. Wedemonstrate both theoretically and experimentally that this makes ROSA strictlymore expressive than LoRA, without consuming additional memory during runtime.As PEFT methods are especially useful in the natural language processingdomain, where models operate on scales that make full fine-tuning veryexpensive, we evaluate ROSA in two common NLP scenarios: natural languagegeneration (NLG) and natural language understanding (NLU) with GPT-2 andRoBERTa, respectively. We show that on almost every GLUE task ROSA outperformsLoRA by a significant margin, while also outperforming LoRA on NLG tasks. Ourcode is available at https://github.com/rosa-paper/rosa</description><author>Marawan Gamal Abdel Hameed, Aristides Milios, Siva Reddy, Guillaume Rabusseau</author><pubDate>Wed, 10 Jul 2024 16:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07802v1</guid></item><item><title>AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning</title><link>http://arxiv.org/abs/2407.07801v1</link><description>In recent years, advancements in representation learning and language modelshave propelled Automated Captioning (AC) to new heights, enabling thegeneration of human-level descriptions. Leveraging these advancements, wepropose \textbf{AVCap}, an \textbf{A}udio-\textbf{V}isual \textbf{Cap}tioningframework, a simple yet powerful baseline approach applicable to audio-visualcaptioning. AVCap utilizes audio-visual features as text tokens, which has manyadvantages not only in performance but also in the extensibility andscalability of the model. AVCap is designed around three pivotal dimensions:the exploration of optimal audio-visual encoder architectures, the adaptationof pre-trained models according to the characteristics of generated text, andthe investigation into the efficacy of modality fusion in captioning. Ourmethod outperforms existing audio-visual captioning methods across all metricsand the code is available on https://github.com/JongSuk1/AVCap</description><author>Jongsuk Kim, Jiwon Shin, Junmo Kim</author><pubDate>Wed, 10 Jul 2024 16:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07801v1</guid></item><item><title>Lightning Fast Video Anomaly Detection via Adversarial Knowledge Distillation</title><link>http://arxiv.org/abs/2211.15597v2</link><description>We propose a very fast frame-level model for anomaly detection in video,which learns to detect anomalies by distilling knowledge from multiple highlyaccurate object-level teacher models. To improve the fidelity of our student,we distill the low-resolution anomaly maps of the teachers by jointly applyingstandard and adversarial distillation, introducing an adversarial discriminatorfor each teacher to distinguish between target and generated anomaly maps. Weconduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),showing that our method is over 7 times faster than the fastest competingmethod, and between 28 and 62 times faster than object-centric models, whileobtaining comparable results to recent methods. Our evaluation also indicatesthat our model achieves the best trade-off between speed and accuracy, due toits previously unheard-of speed of 1480 FPS. In addition, we carry out acomprehensive ablation study to justify our architectural design choices. Ourcode is freely available at: https://github.com/ristea/fast-aed.</description><author>Florinel-Alin Croitoru, Nicolae-Catalin Ristea, Dana Dascalescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Mubarak Shah</author><pubDate>Wed, 10 Jul 2024 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15597v2</guid></item><item><title>Attribute or Abstain: Large Language Models as Long Document Assistants</title><link>http://arxiv.org/abs/2407.07799v1</link><description>LLMs can help humans working with long documents, but are known tohallucinate. Attribution can increase trust in LLM responses: The LLM providesevidence that supports its response, which enhances verifiability. Existingapproaches to attribution have only been evaluated in RAG settings, where theinitial retrieval confounds LLM performance. This is crucially different fromthe long document setting, where retrieval is not needed, but could help. Thus,a long document specific evaluation of attribution is missing. To fill thisgap, we present LAB, a benchmark of 6 diverse long document tasks withattribution, and experiment with different approaches to attribution on 4 LLMsof different sizes, both prompted and fine-tuned. We find that citation, i.e.response generation and evidence extraction in one step, mostly performs best.We investigate whether the ``Lost in the Middle'' phenomenon exists forattribution, but do not find this. We also find that evidence quality canpredict response quality on datasets with simple responses, but not so forcomplex responses, as models struggle with providing evidence for complexclaims. We release code and data for further investigation.</description><author>Jan Buchmann, Xiao Liu, Iryna Gurevych</author><pubDate>Wed, 10 Jul 2024 16:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07799v1</guid></item><item><title>GraphPrint: Extracting Features from 3D Protein Structure for Drug Target Affinity Prediction</title><link>http://arxiv.org/abs/2407.10452v1</link><description>Accurate drug target affinity prediction can improve drug candidateselection, accelerate the drug discovery process, and reduce drug productioncosts. Previous work focused on traditional fingerprints or used featuresextracted based on the amino acid sequence in the protein, ignoring its 3Dstructure which affects its binding affinity. In this work, we proposeGraphPrint: a framework for incorporating 3D protein structure features fordrug target affinity prediction. We generate graph representations for protein3D structures using amino acid residue location coordinates and combine themwith drug graph representation and traditional features to jointly learn drugtarget affinity. Our model achieves a mean square error of 0.1378 and aconcordance index of 0.8929 on the KIBA dataset and improves over usingtraditional protein features alone. Our ablation study shows that the 3Dprotein structure-based features provide information complementary totraditional features.</description><author>Amritpal Singh</author><pubDate>Mon, 15 Jul 2024 05:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10452v1</guid></item><item><title>Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard</title><link>http://arxiv.org/abs/2407.07796v1</link><description>We introduce a novel and extensible benchmark for large language models(LLMs) through grid-based games such as Tic-Tac-Toe, Connect-Four, and Gomoku.The open-source game simulation code, available on GitHub, allows LLMs tocompete and generates detailed data files in JSON, CSV, TXT, and PNG formatsfor leaderboard rankings and further analysis. We present the results of gamesamong leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet byAnthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo andGPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions ofresults from other LLMs. In total, we simulated 2,310 matches (5 sessions foreach pair among 7 LLMs and a random player) across three types of games, usingthree distinct prompt types: list, illustration, and image. The resultsrevealed significant variations in LLM performance across different games andprompt types, with analysis covering win and disqualification rates, missedopportunity analysis, and invalid move analysis. The details of the leaderboardand result matrix data are available as open-access data on GitHub. This studyenhances our understanding of LLMs' capabilities in playing games they were notspecifically trained for, helping to assess their rule comprehension andstrategic thinking. On the path to Artificial General Intelligence (AGI), thisstudy lays the groundwork for future exploration into their utility in complexdecision-making scenarios, illuminating their strategic thinking abilities andoffering directions for further inquiry into the limits of LLMs withingame-based frameworks.</description><author>Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper</author><pubDate>Wed, 10 Jul 2024 16:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07796v1</guid></item><item><title>End-to-end data-driven weather forecasting</title><link>http://arxiv.org/abs/2404.00411v2</link><description>Weather forecasting is critical for a range of human activities includingtransportation, agriculture, industry, as well as the safety of the generalpublic. Machine learning models have the potential to transform the complexweather prediction pipeline, but current approaches still rely on numericalweather prediction (NWP) systems, limiting forecast speed and accuracy. Here wedemonstrate that a machine learning model can replace the entire operationalNWP pipeline. Aardvark Weather, an end-to-end data-driven weather predictionsystem, ingests raw observations and outputs global gridded forecasts and localstation forecasts. Further, it can be optimised end-to-end to maximiseperformance over quantities of interest. Global forecasts outperform anoperational NWP baseline for multiple variables and lead times. Local stationforecasts are skillful up to ten days lead time and achieve comparable andoften lower errors than a post-processed global NWP baseline and astate-of-the-art end-to-end forecasting system with input from humanforecasters. These forecasts are produced with a remarkably simple neuralprocess model using just 8\% of the input data and three orders of magnitudeless compute than existing NWP and hybrid AI-NWP methods. We anticipate thatAardvark Weather will be the starting point for a new generation of end-to-endmachine learning models for medium-range forecasting that will reducecomputational costs by orders of magnitude and enable the rapid and cheapcreation of bespoke models for users in a variety of fields, including for thedeveloping world where state-of-the-art local models are not currentlyavailable.</description><author>Anna Vaughan, Stratis Markou, Will Tebbutt, James Requeima, Wessel P. Bruinsma, Tom R. Andersson, Michael Herzog, Nicholas D. Lane, Matthew Chantry, J. Scott Hosking, Richard E. Turner</author><pubDate>Wed, 10 Jul 2024 16:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00411v2</guid></item><item><title>Reinforcement Learning of Adaptive Acquisition Policies for Inverse Problems</title><link>http://arxiv.org/abs/2407.07794v1</link><description>A promising way to mitigate the expensive process of obtaining ahigh-dimensional signal is to acquire a limited number of low-dimensionalmeasurements and solve an under-determined inverse problem by utilizing thestructural prior about the signal. In this paper, we focus on adaptiveacquisition schemes to save further the number of measurements. To this end, wepropose a reinforcement learning-based approach that sequentially collectsmeasurements to better recover the underlying signal by acquiring fewermeasurements. Our approach applies to general inverse problems with continuousaction spaces and jointly learns the recovery algorithm. Using insightsobtained from theoretical analysis, we also provide a probabilistic design forour methods using variational formulation. We evaluate our approach on multipledatasets and with two measurement spaces (Gaussian, Radon). Our results confirmthe benefits of adaptive strategies in low-acquisition horizon settings.</description><author>Gianluigi Silvestri, Fabio Valerio Massoli, Tribhuvanesh Orekondy, Afshin Abdi, Arash Behboodi</author><pubDate>Wed, 10 Jul 2024 16:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07794v1</guid></item><item><title>Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities</title><link>http://arxiv.org/abs/2407.07791v1</link><description>The rapid adoption of large language models (LLMs) in multi-agent systems hashighlighted their impressive capabilities in various applications, such ascollaborative problem-solving and autonomous negotiation. However, the securityimplications of these LLM-based multi-agent systems have not been thoroughlyinvestigated, particularly concerning the spread of manipulated knowledge. Inthis paper, we investigate this critical issue by constructing a detailedthreat model and a comprehensive simulation environment that mirrors real-worldmulti-agent deployments in a trusted platform. Subsequently, we propose a noveltwo-stage attack method involving Persuasiveness Injection and ManipulatedKnowledge Injection to systematically explore the potential for manipulatedknowledge (i.e., counterfactual and toxic knowledge) spread without explicitprompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling worldknowledge, which can be exploited by attackers to unconsciously spreadfabricated information. Through extensive experiments, we demonstrate that ourattack method can successfully induce LLM-based agents to spread bothcounterfactual and toxic knowledge without degrading their foundationalcapabilities during agent communication. Furthermore, we show that thesemanipulations can persist through popular retrieval-augmented generationframeworks, where several benign agents store and retrieve manipulated chathistories for future interactions. This persistence indicates that even afterthe interaction has ended, the benign agents may continue to be influenced bymanipulated knowledge. Our findings reveal significant security risks inLLM-based multi-agent systems, emphasizing the imperative need for robustdefenses against manipulated knowledge spread, such as introducing ``guardian''agents and advanced fact-checking tools.</description><author>Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu</author><pubDate>Wed, 10 Jul 2024 16:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07791v1</guid></item><item><title>Manipulating Feature Visualizations with Gradient Slingshots</title><link>http://arxiv.org/abs/2401.06122v2</link><description>Deep Neural Networks (DNNs) are capable of learning complex and versatilerepresentations, however, the semantic nature of the learned concepts remainsunknown. A common method used to explain the concepts learned by DNNs isFeature Visualization (FV), which generates a synthetic input signal thatmaximally activates a particular neuron in the network. In this paper, weinvestigate the vulnerability of this approach to adversarial modelmanipulations and introduce a novel method for manipulating FV withoutsignificantly impacting the model's decision-making process. The keydistinction of our proposed approach is that it does not alter the modelarchitecture. We evaluate the effectiveness of our method on several neuralnetwork models and demonstrate its capabilities to hide the functionality ofarbitrarily chosen neurons by masking the original explanations of neurons withchosen target explanations during model auditing.</description><author>Dilyara Bareeva, Marina M. -C. Höhne, Alexander Warnecke, Lukas Pirch, Klaus-Robert Müller, Konrad Rieck, Kirill Bykov</author><pubDate>Wed, 10 Jul 2024 16:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06122v2</guid></item><item><title>BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark</title><link>http://arxiv.org/abs/2407.07788v1</link><description>We introduce BiGym, a new benchmark and learning environment for mobilebi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks setin home environments, ranging from simple target reaching to complex kitchencleaning. To capture the real-world performance accurately, we providehuman-collected demonstrations for each task, reflecting the diverse modalitiesfound in real-world robot trajectories. BiGym supports a variety ofobservations, including proprioceptive data and visual inputs such as RGB, anddepth from 3 camera views. To validate the usability of BiGym, we thoroughlybenchmark the state-of-the-art imitation learning algorithms and demo-drivenreinforcement learning algorithms within the environment and discuss the futureopportunities.</description><author>Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo Seo, Stephen James</author><pubDate>Wed, 10 Jul 2024 16:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07788v1</guid></item><item><title>Continuous Control with Coarse-to-fine Reinforcement Learning</title><link>http://arxiv.org/abs/2407.07787v1</link><description>Despite recent advances in improving the sample-efficiency of reinforcementlearning (RL) algorithms, designing an RL algorithm that can be practicallydeployed in real-world environments remains a challenge. In this paper, wepresent Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RLagents to zoom-into a continuous action space in a coarse-to-fine manner,enabling the use of stable, sample-efficient value-based RL algorithms forfine-grained continuous control tasks. Our key idea is to train agents thatoutput actions by iterating the procedure of (i) discretizing the continuousaction space into multiple intervals and (ii) selecting the interval with thehighest Q-value to further discretize at the next level. We then introduce aconcrete, value-based algorithm within the CRL framework called Coarse-to-fineQ-Network (CQN). Our experiments demonstrate that CQN significantly outperformsRL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulationtasks with a modest number of environment interactions and expertdemonstrations. We also show that CQN robustly learns to solve real-worldmanipulation tasks within a few minutes of online training.</description><author>Younggyo Seo, Jafar Uruç, Stephen James</author><pubDate>Wed, 10 Jul 2024 16:04:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07787v1</guid></item><item><title>PhenDiff: Revealing Subtle Phenotypes with Diffusion Models in Real Images</title><link>http://arxiv.org/abs/2312.08290v2</link><description>For the past few years, deep generative models have increasingly been used inbiological research for a variety of tasks. Recently, they have proven to bevaluable for uncovering subtle cell phenotypic differences that are notdirectly discernible to the human eye. However, current methods employed toachieve this goal mainly rely on Generative Adversarial Networks (GANs). Whileeffective, GANs encompass issues such as training instability and modecollapse, and they do not accurately map images back to the model's latentspace, which is necessary to synthesize, manipulate, and thus interpret outputsbased on real images. In this work, we introduce PhenDiff: a multi-classconditional method leveraging Diffusion Models (DMs) designed to identifyshifts in cellular phenotypes by translating a real image from one condition toanother. We qualitatively and quantitatively validate this method on caseswhere the phenotypic changes are visible or invisible, such as in lowconcentrations of drug treatments. Overall, PhenDiff represents a valuable toolfor identifying cellular variations in real microscopy images. We anticipatethat it could facilitate the understanding of diseases and advance drugdiscovery through the identification of novel biomarkers.</description><author>Anis Bourou, Thomas Boyer, Kévin Daupin, Véronique Dubreuil, Aurélie De Thonel, Valérie Mezger, Auguste Genovesio</author><pubDate>Wed, 10 Jul 2024 16:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08290v2</guid></item><item><title>The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing</title><link>http://arxiv.org/abs/2407.07786v1</link><description>Rapid progress in general-purpose AI has sparked significant interest in "redteaming," a practice of adversarial testing originating in military andcybersecurity applications. AI red teaming raises many questions about thehuman factor, such as how red teamers are selected, biases and blindspots inhow tests are conducted, and harmful content's psychological effects on redteamers. A growing body of HCI and CSCW literature examines relatedpractices-including data labeling, content moderation, and algorithmicauditing. However, few, if any, have investigated red teaming itself. Thisworkshop seeks to consider the conceptual and empirical challenges associatedwith this practice, often rendered opaque by non-disclosure agreements. Futurestudies may explore topics ranging from fairness to mental health and otherareas of potential harm. We aim to facilitate a community of researchers andpractitioners who can begin to meet these challenges with creativity,innovation, and thoughtful reflection.</description><author>Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray</author><pubDate>Wed, 10 Jul 2024 16:02:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07786v1</guid></item><item><title>Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</title><link>http://arxiv.org/abs/2407.07061v2</link><description>The rapid advancement of large language models (LLMs) has paved the way forthe development of highly capable autonomous agents. However, existingmulti-agent frameworks often struggle with integrating diverse capablethird-party agents due to reliance on agents defined within their ownecosystems. They also face challenges in simulating distributed environments,as most frameworks are limited to single-device setups. Furthermore, theseframeworks often rely on hard-coded communication pipelines, limiting theiradaptability to dynamic task requirements. Inspired by the concept of theInternet, we propose the Internet of Agents (IoA), a novel framework thataddresses these limitations by providing a flexible and scalable platform forLLM-based multi-agent collaboration. IoA introduces an agent integrationprotocol, an instant-messaging-like architecture design, and dynamic mechanismsfor agent teaming and conversation flow control. Through extensive experimentson general assistant tasks, embodied AI tasks, and retrieval-augmentedgeneration benchmarks, we demonstrate that IoA consistently outperformsstate-of-the-art baselines, showcasing its ability to facilitate effectivecollaboration among heterogeneous agents. IoA represents a step towards linkingdiverse agents in an Internet-like environment, where agents can seamlesslycollaborate to achieve greater intelligence and capabilities. Our codebase hasbeen released at \url{https://github.com/OpenBMB/IoA}.</description><author>Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun</author><pubDate>Wed, 10 Jul 2024 15:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07061v2</guid></item><item><title>Sequential Kalman Monte Carlo for gradient-free inference in Bayesian inverse problems</title><link>http://arxiv.org/abs/2407.07781v1</link><description>Ensemble Kalman Inversion (EKI) has been proposed as an efficient method forsolving inverse problems with expensive forward models. However, the method isbased on the assumption that we proceed through a sequence of Gaussian measuresin moving from the prior to the posterior, and that the forward model islinear. In this work, we introduce Sequential Kalman Monte Carlo (SKMC)samplers, where we exploit EKI and Flow Annealed Kalman Inversion (FAKI) withina Sequential Monte Carlo (SMC) sampling scheme to perform efficientgradient-free inference in Bayesian inverse problems. FAKI employs normalizingflows (NF) to relax the Gaussian ansatz of the target measures in EKI. NFs areable to learn invertible maps between a Gaussian latent space and the originaldata space, allowing us to perform EKI updates in the Gaussianized NF latentspace. However, FAKI alone is not able to correct for the model linearityassumptions in EKI. Errors in the particle distribution as we move through thesequence of target measures can therefore compound to give incorrect posteriormoment estimates. In this work we consider the use of EKI and FAKI toinitialize the particle distribution for each target in an adaptive SMCannealing scheme, before performing t-preconditioned Crank-Nicolson (tpCN)updates to distribute particles according to the target. We demonstrate theperformance of these SKMC samplers on three challenging numerical benchmarks,showing significant improvements in the rate of convergence compared tostandard SMC with importance weighted resampling at each temperature level.Code implementing the SKMC samplers is available athttps://github.com/RichardGrumitt/KalmanMC.</description><author>Richard D. P. Grumitt, Minas Karamanis, Uroš Seljak</author><pubDate>Wed, 10 Jul 2024 15:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07781v1</guid></item><item><title>Cross Domain Object Detection via Multi-Granularity Confidence Alignment based Mean Teacher</title><link>http://arxiv.org/abs/2407.07780v1</link><description>Cross domain object detection learns an object detector for an unlabeledtarget domain by transferring knowledge from an annotated source domain.Promising results have been achieved via Mean Teacher, however, pseudo labelingwhich is the bottleneck of mutual learning remains to be further explored. Inthis study, we find that confidence misalignment of the predictions, includingcategory-level overconfidence, instance-level task confidence inconsistency,and image-level confidence misfocusing, leading to the injection of noisypseudo label in the training process, will bring suboptimal performance on thetarget domain. To tackle this issue, we present a novel general frameworktermed Multi-Granularity Confidence Alignment Mean Teacher (MGCAMT) for crossdomain object detection, which alleviates confidence misalignment acrosscategory-, instance-, and image-levels simultaneously to obtain high qualitypseudo supervision for better teacher-student learning. Specifically, to alignconfidence with accuracy at category level, we propose ClassificationConfidence Alignment (CCA) to model category uncertainty based on EvidentialDeep Learning (EDL) and filter out the category incorrect labels via anuncertainty-aware selection strategy. Furthermore, to mitigate theinstance-level misalignment between classification and localization, we designTask Confidence Alignment (TCA) to enhance the interaction between the two taskbranches and allow each classification feature to adaptively locate the optimalfeature for the regression. Finally, we develop imagery Focusing ConfidenceAlignment (FCA) adopting another way of pseudo label learning, i.e., we use theoriginal outputs from the Mean Teacher network for supervised learning withoutlabel assignment to concentrate on holistic information in the target image.These three procedures benefit from each other from a cooperative learningperspective.</description><author>Jiangming Chen, Li Liu, Wanxia Deng, Zhen Liu, Yu Liu, Yingmei Wei, Yongxiang Liu</author><pubDate>Wed, 10 Jul 2024 15:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07780v1</guid></item><item><title>Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent</title><link>http://arxiv.org/abs/2402.09844v3</link><description>The search for a general model that can operate seamlessly across multipledomains remains a key goal in machine learning research. The prevailingmethodology in Reinforcement Learning (RL) typically limits models to a singletask within a unimodal framework, a limitation that contrasts with the broadervision of a versatile, multi-domain model. In this paper, we present Jack ofAll Trades (JAT), a transformer-based model with a unique design optimized forhandling sequential decision-making tasks and multi-modal data types. The JATmodel demonstrates its robust capabilities and versatility by achieving strongperformance on very different RL benchmarks, along with promising results onComputer Vision (CV) and Natural Language Processing (NLP) tasks, all using asingle set of weights. The JAT model marks a significant step towards moregeneral, cross-domain AI model design, and notably, it is the first model ofits kind to be fully open-sourced at https://huggingface.co/jat-project/jat,including a pioneering general-purpose dataset.</description><author>Quentin Gallouédec, Edward Beeching, Clément Romac, Emmanuel Dellandréa</author><pubDate>Wed, 10 Jul 2024 15:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09844v3</guid></item><item><title>Prompting Language-Informed Distribution for Compositional Zero-Shot Learning</title><link>http://arxiv.org/abs/2305.14428v3</link><description>Compositional zero-shot learning (CZSL) task aims to recognize unseencompositional visual concepts, e.g., sliced tomatoes, where the model islearned only from the seen compositions, e.g., sliced potatoes and redtomatoes. Thanks to the prompt tuning on large pre-trained visual languagemodels such as CLIP, recent literature shows impressively better CZSLperformance than traditional vision-based methods. However, the key aspectsthat impact the generalization to unseen compositions, including the diversityand informativeness of class context, and the entanglement between visualprimitives, i.e., state and object, are not properly addressed in existingCLIP-based CZSL literature. In this paper, we propose a model by prompting thelanguage-informed distribution, aka., PLID, for the CZSL task. Specifically,the PLID leverages pre-trained large language models (LLM) to (i) formulate thelanguage-informed class distributions which are diverse and informative, and(ii) enhance the compositionality of the class embedding. Moreover, avisual-language primitive decomposition (VLPD) module is proposed todynamically fuse the classification decisions from the compositional and theprimitive space. Orthogonal to the existing literature of soft, hard, ordistributional prompts, our method advocates prompting the LLM-supported classdistributions, leading to a better zero-shot generalization. Experimentalresults on MIT-States, UT-Zappos, and C-GQA datasets show the superiorperformance of the PLID to the prior arts. Our code and models are released:https://github.com/Cogito2012/PLID.</description><author>Wentao Bao, Lichang Chen, Heng Huang, Yu Kong</author><pubDate>Wed, 10 Jul 2024 15:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14428v3</guid></item><item><title>Vanilla Feedforward Neural Networks as a Discretization of Dynamical Systems</title><link>http://arxiv.org/abs/2209.10909v2</link><description>Deep learning has made significant applications in the field of data scienceand natural science. Some studies have linked deep neural networks to dynamicsystems, but the network structure is restricted to the residual network. It isknown that residual networks can be regarded as a numerical discretization ofdynamic systems. In this paper, we back to the classical network structure andprove that the vanilla feedforward networks could also be a numericaldiscretization of dynamic systems, where the width of the network is equal tothe dimension of the input and output. Our proof is based on the properties ofthe leaky-ReLU function and the numerical technique of splitting method tosolve differential equations. Our results could provide a new perspective forunderstanding the approximation properties of feedforward neural networks.</description><author>Yifei Duan, Li'ang Li, Guanghua Ji, Yongqiang Cai</author><pubDate>Wed, 10 Jul 2024 15:53:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10909v2</guid></item><item><title>NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time-Series Pretraining</title><link>http://arxiv.org/abs/2310.07402v3</link><description>Recent research on time-series self-supervised models shows great promise inlearning semantic representations. However, it has been limited to small-scaledatasets, e.g., thousands of temporal sequences. In this work, we make keytechnical contributions that are tailored to the numerical properties oftime-series data and allow the model to scale to large datasets, e.g., millionsof temporal sequences. We adopt the Transformer architecture by firstpartitioning the input into non-overlapping windows. Each window is thencharacterized by its normalized shape and two scalar values denoting the meanand standard deviation within each window. To embed scalar values that maypossess arbitrary numerical amplitudes in a high-dimensional space, we proposea numerically multi-scaled embedding module enumerating all possible numericalscales for the scalars. The model undergoes pretraining with a simplecontrastive objective on a large-scale dataset over a million sequencescollected by merging existing public data. We study its transfer performance ona number of univariate and multivariate classification tasks, few shotlearning, unsupervised clustering and anomaly detection benchmarks. Our methodexhibits remarkable improvement against previous pretraining approaches andestablishes the new state of the art, even compared with domain-specificnon-learning-based methods. Code is available at:\url{https://github.com/chenguolin/NuTime}.</description><author>Chenguo Lin, Xumeng Wen, Wei Cao, Congrui Huang, Jiang Bian, Stephen Lin, Zhirong Wu</author><pubDate>Wed, 10 Jul 2024 15:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07402v3</guid></item><item><title>WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment</title><link>http://arxiv.org/abs/2407.07778v1</link><description>AI systems make decisions in physical environments through primitive actionsor affordances that are accessed via API calls. While deploying AI agents inthe real world involves numerous high-level actions, existing embodiedsimulators offer a limited set of domain-salient APIs. This naturally brings upthe questions: how many primitive actions (APIs) are needed for a versatileembodied agent, and what should they look like? We explore this via a thoughtexperiment: assuming that wikiHow tutorials cover a wide variety ofhuman-written tasks, what is the space of APIs needed to cover theseinstructions? We propose a framework to iteratively induce new APIs bygrounding wikiHow instruction to situated agent policies. Inspired by recentsuccesses in large language models (LLMs) for embodied planning, we propose afew-shot prompting to steer GPT-4 to generate Pythonic programs as agentpolicies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; andthen 2) fabricate new API calls when necessary. The focus of this thoughtexperiment is on defining these APIs rather than their executability. We applythe proposed pipeline on instructions from wikiHow tutorials. On a smallfraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessaryfor capturing the rich variety of tasks in the physical world. A detailedautomatic and human analysis of the induction output reveals that the proposedpipeline enables effective reuse and creation of APIs. Moreover, a manualreview revealed that existing simulators support only a small subset of theinduced APIs (9 of the top 50 frequent APIs), motivating the development ofaction-rich embodied environments.</description><author>Jiefu Ou, Arda Uzunoglu, Benjamin Van Durme, Daniel Khashabi</author><pubDate>Wed, 10 Jul 2024 15:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07778v1</guid></item><item><title>Bridging Synthetic and Real Worlds for Pre-training Scene Text Detectors</title><link>http://arxiv.org/abs/2312.05286v3</link><description>Existing scene text detection methods typically rely on extensive real datafor training. Due to the lack of annotated real images, recent works haveattempted to exploit large-scale labeled synthetic data (LSD) for pre-trainingtext detectors. However, a synth-to-real domain gap emerges, further limitingthe performance of text detectors. Differently, in this work, we proposeFreeReal, a real-domain-aligned pre-training paradigm that enables thecomplementary strengths of both LSD and unlabeled real data (URD).Specifically, to bridge real and synthetic worlds for pre-training, aglyph-based mixing mechanism (GlyphMix) is tailored for text images.GlyphMixdelineates the character structures of synthetic images and embeds them asgraffiti-like units onto real images. Without introducing real domain drift,GlyphMix freely yields real-world images with annotations derived fromsynthetic labels. Furthermore, when given free fine-grained synthetic labels,GlyphMix can effectively bridge the linguistic domain gap stemming fromEnglish-dominated LSD to URD in various languages. Without bells and whistles,FreeReal achieves average gains of 1.97%, 3.90%, 3.85%, and 4.56% in improvingthe performance of FCENet, PSENet, PANet, and DBNet methods, respectively,consistently outperforming previous pre-training methods by a substantialmargin across four public datasets. Code is available athttps://github.com/SJTU-DeepVisionLab/FreeReal.</description><author>Tongkun Guan, Wei Shen, Xue Yang, Xuehui Wang, Xiaokang Yang</author><pubDate>Wed, 10 Jul 2024 15:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05286v3</guid></item><item><title>Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs</title><link>http://arxiv.org/abs/2407.07775v1</link><description>An elusive goal in navigation research is to build an intelligent agent thatcan understand multimodal instructions including natural language and image,and perform useful navigation. To achieve this, we study a widely usefulcategory of navigation tasks we call Multimodal Instruction Navigation withdemonstration Tours (MINT), in which the environment prior is provided througha previously recorded demonstration video. Recent advances in Vision LanguageModels (VLMs) have shown a promising path in achieving this goal as itdemonstrates capabilities in perceiving and reasoning about multimodal inputs.However, VLMs are typically trained to predict textual output and it is an openresearch question about how to best utilize them in navigation. To solve MINT,we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigationpolicy that combines the environment understanding and common sense reasoningpower of long-context VLMs and a robust low-level navigation policy based ontopological graphs. The high-level policy consists of a long-context VLM thattakes the demonstration tour video and the multimodal user instruction as inputto find the goal frame in the tour video. Next, a low-level policy uses thegoal frame and an offline constructed topological graph to generate robotactions at every timestep. We evaluated Mobility VLA in a 836m^2 real worldenvironment and show that Mobility VLA has a high end-to-end success rates onpreviously unsolved multimodal instructions such as "Where should I returnthis?" while holding a plastic bin.</description><author>Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan</author><pubDate>Wed, 10 Jul 2024 15:49:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07775v1</guid></item><item><title>Exploring Description-Augmented Dataless Intent Classification</title><link>http://arxiv.org/abs/2407.17862v1</link><description>In this work, we introduce several schemes to leverage description-augmentedembedding similarity for dataless intent classification using currentstate-of-the-art (SOTA) text embedding models. We report results of our methodson four commonly used intent classification datasets and compare againstprevious works of a similar nature. Our work shows promising results fordataless classification scaling to a large number of unseen intents. We showcompetitive results and significant improvements (+6.12\% Avg.) over strongzero-shot baselines, all without training on labelled or task-specific data.Furthermore, we provide qualitative error analysis of the shortfalls of thismethodology to help guide future research in this area.</description><author>Ruoyu Hu, Foaad Khosmood, Abbas Edalat</author><pubDate>Thu, 25 Jul 2024 08:31:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17862v1</guid></item><item><title>Multi-task Prompt Words Learning for Social Media Content Generation</title><link>http://arxiv.org/abs/2407.07771v1</link><description>The rapid development of the Internet has profoundly changed human life.Humans are increasingly expressing themselves and interacting with others onsocial media platforms. However, although artificial intelligence technologyhas been widely used in many aspects of life, its application in social mediacontent creation is still blank. To solve this problem, we propose a new promptword generation framework based on multi-modal information fusion, whichcombines multiple tasks including topic classification, sentiment analysis,scene recognition and keyword extraction to generate more comprehensive promptwords. Subsequently, we use a template containing a set of prompt words toguide ChatGPT to generate high-quality tweets. Furthermore, in the absence ofeffective and objective evaluation criteria in the field of content generation,we use the ChatGPT tool to evaluate the results generated by the algorithm,making large-scale evaluation of content generation algorithms possible.Evaluation results on extensive content generation demonstrate that our cueword generation framework generates higher quality content compared to manualmethods and other cueing techniques, while topic classification, sentimentanalysis, and scene recognition significantly enhance content clarity and itsconsistency with the image.</description><author>Haochen Xue, Chong Zhang, Chengzhi Liu, Fangyu Wu, Xiaobo Jin</author><pubDate>Wed, 10 Jul 2024 15:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07771v1</guid></item><item><title>Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem</title><link>http://arxiv.org/abs/2407.07765v1</link><description>This work continues to investigate the link between differentially private(DP) and online learning. Alon, Livni, Malliaris, and Moran (2019) showed thatfor binary concept classes, DP learnability of a given class implies that ithas a finite Littlestone dimension (equivalently, that it is online learnable).Their proof relies on a model-theoretic result by Hodges (1997), whichdemonstrates that any binary concept class with a large Littlestone dimensioncontains a large subclass of thresholds. In a follow-up work, Jung, Kim, andTewari (2020) extended this proof to multiclass PAC learning with a boundednumber of labels. Unfortunately, Hodges's result does not apply in othernatural settings such as multiclass PAC learning with an unbounded label space,and PAC learning of partial concept classes. This naturally raises the question of whether DP learnability continues toimply online learnability in more general scenarios: indeed, Alon, Hanneke,Holzman, and Moran (2021) explicitly leave it as an open question in thecontext of partial concept classes, and the same question is open in thegeneral multiclass setting. In this work, we give a positive answer to thesequestions showing that for general classification tasks, DP learnabilityimplies online learnability. Our proof reasons directly about Littlestonetrees, without relying on thresholds. We achieve this by establishing severalRamsey-type theorems for trees, which might be of independent interest.</description><author>Simone Fioravanti, Steve Hanneke, Shay Moran, Hilla Schefler, Iska Tsubari</author><pubDate>Wed, 10 Jul 2024 15:43:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07765v1</guid></item><item><title>PosFormer: Recognizing Complex Handwritten Mathematical Expression with Position Forest Transformer</title><link>http://arxiv.org/abs/2407.07764v1</link><description>Handwritten Mathematical Expression Recognition (HMER) has wide applicationsin human-machine interaction scenarios, such as digitized education andautomated offices. Recently, sequence-based models with encoder-decoderarchitectures have been commonly adopted to address this task by directlypredicting LaTeX sequences of expression images. However, these methods onlyimplicitly learn the syntax rules provided by LaTeX, which may fail to describethe position and hierarchical relationship between symbols due to complexstructural relations and diverse handwriting styles. To overcome thischallenge, we propose a position forest transformer (PosFormer) for HMER, whichjointly optimizes two tasks: expression recognition and position recognition,to explicitly enable position-aware symbol feature representation learning.Specifically, we first design a position forest that models the mathematicalexpression as a forest structure and parses the relative position relationshipsbetween symbols. Without requiring extra annotations, each symbol is assigned aposition identifier in the forest to denote its relative spatial position.Second, we propose an implicit attention correction module to accuratelycapture attention for HMER in the sequence-based decoder architecture.Extensive experiments validate the superiority of PosFormer, which consistentlyoutperforms the state-of-the-art methods 2.03%/1.22%/2.00%, 1.83%, and 4.62%gains on the single-line CROHME 2014/2016/2019, multi-line M2E, and complex MNEdatasets, respectively, with no additional latency or computational cost. Codeis available at https://github.com/SJTU-DeepVisionLab/PosFormer.</description><author>Tongkun Guan, Chengyu Lin, Wei Shen, Xiaokang Yang</author><pubDate>Wed, 10 Jul 2024 15:42:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07764v1</guid></item><item><title>S&amp;D Messenger: Exchanging Semantic and Domain Knowledge for Generic Semi-Supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2407.07763v1</link><description>Semi-supervised medical image segmentation (SSMIS) has emerged as a promisingsolution to tackle the challenges of time-consuming manual labeling in themedical field. However, in practical scenarios, there are often domainvariations within the datasets, leading to derivative scenarios likesemi-supervised medical domain generalization (Semi-MDG) and unsupervisedmedical domain adaptation (UMDA). In this paper, we aim to develop a genericframework that masters all three tasks. We notice a critical shared challengeacross three scenarios: the explicit semantic knowledge for segmentationperformance and rich domain knowledge for generalizability exclusively exist inthe labeled set and unlabeled set respectively. Such discrepancy hindersexisting methods from effectively comprehending both types of knowledge undersemi-supervised settings. To tackle this challenge, we develop a Semantic &amp;Domain Knowledge Messenger (S&amp;D Messenger) which facilitates direct knowledgedelivery between the labeled and unlabeled set, and thus allowing the model tocomprehend both of them in each individual learning flow. Equipped with our S&amp;DMessenger, a naive pseudo-labeling method can achieve huge improvement on sixbenchmark datasets for SSMIS (+7.5%), UMDA (+5.6%), and Semi-MDG tasks(+1.14%), compared with state-of-the-art methods designed for specific tasks.</description><author>Qixiang Zhang, Haonan Wang, Xiaomeng Li</author><pubDate>Wed, 10 Jul 2024 15:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07763v1</guid></item><item><title>Learning Spatial-Semantic Features for Robust Video Object Segmentation</title><link>http://arxiv.org/abs/2407.07760v1</link><description>Tracking and segmenting multiple similar objects with complex or separateparts in long-term videos is inherently challenging due to the ambiguity oftarget parts and identity confusion caused by occlusion, background clutter,and long-term variations. In this paper, we propose a robust video objectsegmentation framework equipped with spatial-semantic features anddiscriminative object queries to address the above issues. Specifically, weconstruct a spatial-semantic network comprising a semantic embedding block andspatial dependencies modeling block to associate the pretrained ViT featureswith global semantic features and local spatial features, providing acomprehensive target representation. In addition, we develop a maskedcross-attention module to generate object queries that focus on the mostdiscriminative parts of target objects during query propagation, alleviatingnoise accumulation and ensuring effective long-term query propagation. Theexperimental results show that the proposed method set a new state-of-the-artperformance on multiple datasets, including the DAVIS2017 test (89.1%),YoutubeVOS 2019 (88.5%), MOSE (75.1%), LVOS test (73.0%), and LVOS val (75.1%),which demonstrate the effectiveness and generalization capacity of the proposedmethod. We will make all source code and trained models publicly available.</description><author>Xin Li, Deshui Miao, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang</author><pubDate>Wed, 10 Jul 2024 15:36:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07760v1</guid></item><item><title>MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations</title><link>http://arxiv.org/abs/2407.01523v2</link><description>Understanding documents with rich layouts and multi-modal components is along-standing and practical task. Recent Large Vision-Language Models (LVLMs)have made remarkable strides in various tasks, particularly in single-pagedocument understanding (DU). However, their abilities on long-context DU remainan open problem. This work presents MMLongBench-Doc, a long-context,multi-modal benchmark comprising 1,062 expert-annotated questions. Distinctfrom previous datasets, it is constructed upon 130 lengthy PDF-formatteddocuments with an average of 49.4 pages and 20,971 textual tokens. Towardscomprehensive evaluation, answers to these questions rely on pieces of evidencefrom (1) different sources (text, image, chart, table, and layout structure)and (2) various locations (i.e. page number). Moreover, 33.2% of the questionsare cross-page questions requiring evidence across multiple pages. 22.8% of thequestions are designed to be unanswerable for detecting potentialhallucinations. Experiments on 14 LVLMs demonstrate that long-context DUgreatly challenges current models. Notably, the best-performing model, GPT-4o,achieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worseperformance than their LLM counterparts which are fed with lossy-parsed OCRdocuments. These results validate the necessity of future research toward morecapable long-context LVLMs. Project Page:https://mayubo2333.github.io/MMLongBench-Doc</description><author>Yubo Ma, Yuhang Zang, Liangyu Chen, Meiqi Chen, Yizhu Jiao, Xinze Li, Xinyuan Lu, Ziyu Liu, Yan Ma, Xiaoyi Dong, Pan Zhang, Liangming Pan, Yu-Gang Jiang, Jiaqi Wang, Yixin Cao, Aixin Sun</author><pubDate>Wed, 10 Jul 2024 15:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01523v2</guid></item><item><title>Neural Geometry Processing via Spherical Neural Surfaces</title><link>http://arxiv.org/abs/2407.07755v1</link><description>Neural surfaces (e.g., neural map encoding, deep implicits and neuralradiance fields) have recently gained popularity because of their genericstructure (e.g., multi-layer perceptron) and easy integration with modernlearning-based setups. Traditionally, we have a rich toolbox of geometryprocessing algorithms designed for polygonal meshes to analyze and operate onsurface geometry. However, neural representations are typically discretized andconverted into a mesh, before applying any geometry processing algorithm. Thisis unsatisfactory and, as we demonstrate, unnecessary. In this work, we proposea spherical neural surface representation (a spherical parametrization) forgenus-0 surfaces and demonstrate how to compute core geometric operatorsdirectly on this representation. Namely, we show how to construct the normalsand the first and second fundamental forms of the surface, and how to computethe surface gradient, surface divergence and Laplace Beltrami operator onscalar/vector fields defined on the surface. These operators, in turn, enableus to create geometry processing tools that act directly on the neuralrepresentations without any unnecessary meshing. We demonstrate illustrativeapplications in (neural) spectral analysis, heat flow and mean curvature flow,and our method shows robustness to isometric shape variations. We both proposetheoretical formulations and validate their numerical estimates. Bysystematically linking neural surface representations with classical geometryprocessing algorithms, we believe this work can become a key ingredient inenabling neural geometry processing.</description><author>Romy Williamson, Niloy J. Mitra</author><pubDate>Wed, 10 Jul 2024 15:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07755v1</guid></item><item><title>Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems</title><link>http://arxiv.org/abs/2404.01616v3</link><description>Large language models (LLMs) are trained on text-only data that go far beyondthe languages with paired speech and text data. At the same time, Dual Encoder(DE) based retrieval systems project queries and documents into the sameembedding space and have demonstrated their success in retrieval and bi-textmining. To match speech and text in many languages, we propose using LLMs toinitialize multi-modal DE retrieval systems. Unlike traditional methods, oursystem doesn't require speech data during LLM pre-training and can exploitLLM's multilingual text understanding capabilities to match speech and text inlanguages unseen during retrieval training. Our multi-modal LLM-based retrievalsystem is capable of matching speech and text in 102 languages despite onlytraining on 21 languages. Our system outperforms previous systems trainedexplicitly on all 102 languages. We achieve a 10% absolute improvement inRecall@1 averaged across these languages. Additionally, our model demonstratescross-lingual speech and text matching, which is further enhanced by readilyavailable machine translation data.</description><author>Frank Palma Gomez, Ramon Sanabria, Yun-hsuan Sung, Daniel Cer, Siddharth Dalmia, Gustavo Hernandez Abrego</author><pubDate>Wed, 10 Jul 2024 15:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01616v3</guid></item><item><title>Learning local equivariant representations for quantum operators</title><link>http://arxiv.org/abs/2407.06053v2</link><description>Predicting quantum operator matrices such as Hamiltonian, overlap, anddensity matrices in the density functional theory (DFT) framework is crucialfor understanding material properties. Current methods often focus onindividual operators and struggle with efficiency and scalability for largesystems. Here we introduce a novel deep learning model, SLEM (strictlylocalized equivariant message-passing) for predicting multiple quantumoperators, that achieves state-of-the-art accuracy while dramatically improvingcomputational efficiency. SLEM's key innovation is its strict locality-baseddesign, constructing local, equivariant representations for quantum tensorswhile preserving physical symmetries. This enables complex many-body dependencewithout expanding the effective receptive field, leading to superior dataefficiency and transferability. Using an innovative SO(2) convolutiontechnique, SLEM reduces the computational complexity of high-order tensorproducts and is therefore capable of handling systems requiring the $f$ and $g$orbitals in their basis sets. We demonstrate SLEM's capabilities across diverse2D and 3D materials, achieving high accuracy even with limited training data.SLEM's design facilitates efficient parallelization, potentially extending DFTsimulations to systems with device-level sizes, opening new possibilities forlarge-scale quantum simulations and high-throughput materials discovery.</description><author>Zhanghao Zhouyin, Zixi Gan, Shishir Kumar Pandey, Linfeng Zhang, Qiangqiang Gu</author><pubDate>Wed, 10 Jul 2024 15:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06053v2</guid></item><item><title>Phy-Diff: Physics-guided Hourglass Diffusion Model for Diffusion MRI Synthesis</title><link>http://arxiv.org/abs/2406.03002v2</link><description>Diffusion MRI (dMRI) is an important neuroimaging technique with highacquisition costs. Deep learning approaches have been used to enhance dMRI andpredict diffusion biomarkers through undersampled dMRI. To generate morecomprehensive raw dMRI, generative adversarial network based methods areproposed to include b-values and b-vectors as conditions, but they are limitedby unstable training and less desirable diversity. The emerging diffusion model(DM) promises to improve generative performance. However, it remainschallenging to include essential information in conditioning DM for morerelevant generation, i.e., the physical principles of dMRI and white mattertract structures. In this study, we propose a physics-guided diffusion model togenerate high-quality dMRI. Our model introduces the physical principles ofdMRI in the noise evolution in the diffusion process and introduce aquery-based conditional mapping within the difussion model. In addition, toenhance the anatomical fine detials of the generation, we introduce the XTRACTatlas as prior of white matter tracts by adopting an adapter technique. Ourexperiment results show that our method outperforms other state-of-the-artmethods and has the potential to advance dMRI enhancement.</description><author>Juanhua Zhang, Ruodan Yan, Alessandro Perelli, Xi Chen, Chao Li</author><pubDate>Wed, 10 Jul 2024 15:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03002v2</guid></item><item><title>An Improved Traditional Chinese Evaluation Suite for Foundation Model</title><link>http://arxiv.org/abs/2403.01858v2</link><description>We present TMMLU+, a new benchmark designed for Traditional Chinese languageunderstanding. TMMLU+ is a multi-choice question-answering dataset with 66subjects from elementary to professional level. It is six times larger andboasts a more balanced subject distribution than its predecessor, TaiwanMassive Multitask Language Understanding (TMMLU). We also benchmarkclosed-source models and 26 open-weight Chinese large language models (LLMs) ofparameters ranging from 1.8B to 72B on the proposed TMMLU+. Our findings revealthat (1.) Traditional Chinese models still trail behind their SimplifiedChinese counterparts, highlighting a need for more focused advancements in LLMscatering to Traditional Chinese. (2.) Current LLMs still fall short of humanperformance in average scores, indicating a potential need for future researchto delve deeper into social science and humanities subjects. (3.) Among all thetokenization compression metrics examined, we identify that only the fertilityscore uniquely demonstrates strong correlations with our benchmark results. Weforesee that TMMLU+ will pinpoint areas for future model improvement, therebynarrowing the gap between machine and human linguistic capabilities andsupporting researchers in developing Traditional Chinese LLMs. Our dataset,along with the benchmark source code, is accessible athuggingface.co/datasets/ikala/tmmluplus.</description><author>Zhi-Rui Tam, Ya-Ting Pai, Yen-Wei Lee, Jun-Da Chen, Wei-Min Chu, Sega Cheng, Hong-Han Shuai</author><pubDate>Wed, 10 Jul 2024 15:11:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01858v2</guid></item><item><title>LSM: A Comprehensive Metric for Assessing the Safety of Lane Detection Systems in Autonomous Driving</title><link>http://arxiv.org/abs/2407.07740v1</link><description>Comprehensive perception of the vehicle's environment and correctinterpretation of the environment are crucial for the safe operation ofautonomous vehicles. The perception of surrounding objects is the maincomponent for further tasks such as trajectory planning. However, safetrajectory planning requires not only object detection, but also the detectionof drivable areas and lane corridors. While first approaches consider anadvanced safety evaluation of object detection, the evaluation of lanedetection still lacks sufficient safety metrics. Similar to the safety metricsfor object detection, additional factors such as the semantics of the scenewith road type and road width, the detection range as well as the potentialcauses of missing detections, incorporated by vehicle speed, should beconsidered for the evaluation of lane detection. Therefore, we propose the LaneSafety Metric (LSM), which takes these factors into account and allows toevaluate the safety of lane detection systems by determining an easilyinterpretable safety score. We evaluate our offline safety metric on variousvirtual scenarios using different lane detection approaches and compare it withstate-of-the-art performance metrics.</description><author>Jörg Gamerdinger, Sven Teufel, Stephan Amann, Georg Volk, Oliver Bringmann</author><pubDate>Wed, 10 Jul 2024 15:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07740v1</guid></item><item><title>FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation</title><link>http://arxiv.org/abs/2305.05506v3</link><description>We propose FedGT, a novel framework for identifying malicious clients infederated learning with secure aggregation. Inspired by group testing, theframework leverages overlapping groups of clients to identify the presence ofmalicious clients in the groups via a decoding operation. The clientsidentified as malicious are then removed from the model training, which isperformed over the remaining clients. By choosing the size, number, and overlapbetween groups, FedGT strikes a balance between privacy and security.Specifically, the server learns the aggregated model of the clients in eachgroup - vanilla federated learning and secure aggregation correspond to theextreme cases of FedGT with group size equal to one and the total number ofclients, respectively. The effectiveness of FedGT is demonstrated throughextensive experiments on the MNIST, CIFAR-10, and ISIC2019 datasets in across-silo setting under different data-poisoning attacks. These experimentsshowcase FedGT's ability to identify malicious clients, resulting in high modelutility. We further show that FedGT significantly outperforms the privaterobust aggregation approach based on the geometric median recently proposed byPillutla et al. in multiple settings.</description><author>Marvin Xhemrishi, Johan Östman, Antonia Wachter-Zeh, Alexandre Graell i Amat</author><pubDate>Wed, 10 Jul 2024 15:10:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05506v3</guid></item><item><title>Fine-Tuning Large Language Models with User-Level Differential Privacy</title><link>http://arxiv.org/abs/2407.07737v1</link><description>We investigate practical and scalable algorithms for training large languagemodels (LLMs) with user-level differential privacy (DP) in order to provablysafeguard all the examples contributed by each user. We study two variants ofDP-SGD with: (1) example-level sampling (ELS) and per-example gradientclipping, and (2) user-level sampling (ULS) and per-user gradient clipping. Wederive a novel user-level DP accountant that allows us to compute provablytight privacy guarantees for ELS. Using this, we show that while ELS canoutperform ULS in specific settings, ULS generally yields better results wheneach user has a diverse collection of examples. We validate our findingsthrough experiments in synthetic mean estimation and LLM fine-tuning tasksunder fixed compute budgets. We find that ULS is significantly better insettings where either (1) strong privacy guarantees are required, or (2) thecompute budget is large. Notably, our focus on LLM-compatible trainingalgorithms allows us to scale to models with hundreds of millions of parametersand datasets with hundreds of thousands of users.</description><author>Zachary Charles, Arun Ganesh, Ryan McKenna, H. Brendan McMahan, Nicole Mitchell, Krishna Pillutla, Keith Rush</author><pubDate>Wed, 10 Jul 2024 15:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07737v1</guid></item><item><title>Protecting NeRFs' Copyright via Plug-And-Play Watermarking Base Model</title><link>http://arxiv.org/abs/2407.07735v1</link><description>Neural Radiance Fields (NeRFs) have become a key method for 3D scenerepresentation. With the rising prominence and influence of NeRF, safeguardingits intellectual property has become increasingly important. In this paper, wepropose \textbf{NeRFProtector}, which adopts a plug-and-play strategy toprotect NeRF's copyright during its creation. NeRFProtector utilizes apre-trained watermarking base model, enabling NeRF creators to embed binarymessages directly while creating their NeRF. Our plug-and-play property ensuresNeRF creators can flexibly choose NeRF variants without excessivemodifications. Leveraging our newly designed progressive distillation, wedemonstrate performance on par with several leading-edge neural renderingmethods. Our project is available at:\url{https://qsong2001.github.io/NeRFProtector}.</description><author>Qi Song, Ziyuan Luo, Ka Chun Cheung, Simon See, Renjie Wan</author><pubDate>Wed, 10 Jul 2024 15:06:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07735v1</guid></item><item><title>Digital twin with automatic disturbance detection for real-time optimization of a semi-autogenous grinding (SAG) mill</title><link>http://arxiv.org/abs/2407.06216v2</link><description>This work describes the development and validation of a digital twin for asemi-autogenous grinding (SAG) mill controlled by an expert system. The digitaltwin consists of three modules emulating a closed-loop system: fuzzy logic forthe expert control, a state-space model for regulatory control, and a recurrentneural network for the SAG mill process. The model was trained with 68 hours ofdata and validated with 8 hours of test data. It predicts the mill's behaviorwithin a 2.5-minute horizon with a 30-second sampling time. The disturbancedetection evaluates the need for retraining, and the digital twin shows promisefor supervising the SAG mill with the expert control system. Future work willfocus on integrating this digital twin into real-time optimization strategieswith industrial validation.</description><author>Paulina Quintanilla, Francisco Fernández, Cristobal Mancilla, Matías Rojas, Mauricio Estrada, Daniel Navia</author><pubDate>Wed, 10 Jul 2024 15:06:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06216v2</guid></item><item><title>Boosting Transferability in Vision-Language Attacks via Diversification along the Intersection Region of Adversarial Trajectory</title><link>http://arxiv.org/abs/2403.12445v2</link><description>Vision-language pre-training (VLP) models exhibit remarkable capabilities incomprehending both images and text, yet they remain susceptible to multimodaladversarial examples (AEs).Strengthening attacks and uncoveringvulnerabilities, especially common issues in VLP models (e.g., hightransferable AEs), can advance reliable and practical VLP models. A recent work(i.e., Set-level guidance attack) indicates that augmenting image-text pairs toincrease AE diversity along the optimization path enhances the transferabilityof adversarial examples significantly. However, this approach predominantlyemphasizes diversity around the online adversarial examples (i.e., AEs in theoptimization period), leading to the risk of overfitting the victim model andaffecting the transferability.In this study, we posit that the diversity ofadversarial examples towards the clean input and online AEs are both pivotalfor enhancing transferability across VLP models. Consequently, we propose usingdiversification along the intersection region of adversarial trajectory toexpand the diversity of AEs.To fully leverage the interaction betweenmodalities, we introduce text-guided adversarial example selection duringoptimization. Furthermore, to further mitigate the potential overfitting, wedirect the adversarial text deviating from the last intersection region alongthe optimization path, rather than adversarial images as in existingmethods.Extensive experiments affirm the effectiveness of our method inimproving transferability across various VLP models and downstreamvision-and-language tasks.</description><author>Sensen Gao, Xiaojun Jia, Xuhong Ren, Ivor Tsang, Qing Guo</author><pubDate>Wed, 10 Jul 2024 15:04:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12445v2</guid></item><item><title>Using Natural Language Explanations to Rescale Human Judgments</title><link>http://arxiv.org/abs/2305.14770v3</link><description>The rise of large language models (LLMs) has brought a critical need forhigh-quality human-labeled data, particularly for processes like human feedbackand evaluation. A common practice is to label data via consensus annotationover human judgments. However, annotators' judgments for subjective tasks candiffer in many ways: they may reflect different qualitative judgments about anexample, and they may be mapped to a labeling scheme in different ways. We showthat these nuances can be captured by natural language explanations, andpropose a method to rescale ordinal annotations and explanations using LLMs.Specifically, we feed annotators' Likert ratings and corresponding explanationsinto an LLM and prompt it to produce a numeric score anchored in a scoringrubric. These scores should reflect the annotators' underlying assessments ofthe example. The rubric can be designed or modified after annotation, andinclude distinctions that may not have been known when the original errortaxonomy was devised. We explore our technique in the context of rating systemoutputs for a document-grounded question answering task, where LLMs achievenear-human performance. Our method rescales the raw judgments without impactingagreement and brings the scores closer to human judgments grounded in the samescoring rubric.</description><author>Manya Wadhwa, Jifan Chen, Junyi Jessy Li, Greg Durrett</author><pubDate>Wed, 10 Jul 2024 15:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14770v3</guid></item><item><title>SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis</title><link>http://arxiv.org/abs/2407.07728v1</link><description>Singing voice conversion (SVC) aims to convert a singer's voice in a givenmusic piece to another singer while keeping the original content. We propose anend-to-end feature disentanglement-based model, which we named SaMoye, toenable zero-shot many-to-many singing voice conversion. SaMoye disentangles thefeatures of the singing voice into content features, timbre features, and pitchfeatures respectively. The content features are enhanced using a GPT-basedmodel to perform cross-prediction with the phoneme of the lyrics. SaMoye cangenerate the music with converted voice by replacing the timbre features withthe target singer. We also establish an unparalleled large-scale dataset toguarantee zero-shot performance. The dataset consists of 1500k pure singingvocal clips containing at least 10,000 singers.</description><author>Zihao Wang, Le Ma, Yan Liu, Kejun Zhang</author><pubDate>Wed, 10 Jul 2024 15:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07728v1</guid></item><item><title>Pentagonal Photonic Crystal Mirrors: Scalable Lightsails with Enhanced Acceleration via Neural Topology Optimization</title><link>http://arxiv.org/abs/2407.07896v1</link><description>The Starshot Breakthrough Initiative aims to send one-gram microchip probesto Alpha Centauri within 20 years, using gram-scale lightsails propelled bylaser-based radiation pressure, reaching velocities nearing a fifth of lightspeed. This mission requires lightsail materials that challenge thefundamentals of nanotechnology, requiring innovations in optics, materialscience and structural engineering. Unlike the microchip payload, which must beminimized in every dimension, such lightsails need meter-scale dimensions withnanoscale thickness and billions of nanoscale holes to enhance reflectivity andreduce mass. Our study employs neural topology optimization, revealing a novelpentagonal lattice-based photonic crystal (PhC) reflector. The optimizeddesigns shorten acceleration times, therefore lowering launch costssignificantly. Crucially, these designs also enable lightsail materialfabrication with orders-of-magnitude reduction in costs. We have fabricated a60 x 60 mm$^2$, 200nm thick, single-layer reflector perforated with over abillion nanoscale features; the highest aspect-ratio nanophotonic element todate. We achieve this with nearly 9,000 times cost reduction per m$^2$.Starshot lightsails will have several stringent requirements but willultimately be driven by costs to build at scale. Here we highlight challengesand possible solutions in developing lightsail materials - showcasing thepotential of scaling nanophotonics for cost-effective next-generation spaceexploration.</description><author>L. Norder, S. Yin, M. J. de Jong, F. Stallone, H. Aydogmus, P. M. Sberna, M. A. Bessa, R. A. Norte</author><pubDate>Wed, 10 Jul 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07896v1</guid></item></channel></rss>