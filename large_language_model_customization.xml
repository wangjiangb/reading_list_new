<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 24 Aug 2025 17:36:27 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Reference Points in LLM Sentiment Analysis: The Role of Structured Context</title><link>http://arxiv.org/abs/2508.11454v1</link><description>Large language models (LLMs) are now widely used across many fields,including marketing research. Sentiment analysis, in particular, helps firmsunderstand consumer preferences. While most NLP studies classify sentiment fromreview text alone, marketing theories, such as prospect theory andexpectation--disconfirmation theory, point out that customer evaluations areshaped not only by the actual experience but also by additional referencepoints. This study therefore investigates how the content and format of suchsupplementary information affect sentiment analysis using LLMs. We comparenatural language (NL) and JSON-formatted prompts using a lightweight 3Bparameter model suitable for practical marketing applications. Experiments ontwo Yelp categories (Restaurant and Nightlife) show that the JSON prompt withadditional information outperforms all baselines without fine-tuning: Macro-F1rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making itdeployable in resource-constrained edge devices. Furthermore, a follow-upanalysis confirms that performance gains stem from genuine contextual reasoningrather than label proxying. This work demonstrates that structured promptingcan enable smaller models to achieve competitive performance, offering apractical alternative to large-scale model deployment.</description><author>Junichiro Niimi</author><pubDate>Fri, 15 Aug 2025 13:04:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2508.11454v1</guid></item><item><title>Personalized LLM for Generating Customized Responses to the Same Query from Different Users</title><link>http://arxiv.org/abs/2412.11736v2</link><description>Existing work on large language model (LLM) personalization assigneddifferent responding roles to LLMs, but overlooked the diversity of queriers.In this work, we propose a new form of querier-aware LLM personalization,generating different responses even for the same query from different queriers.We design a dual-tower model architecture with a cross-querier general encoderand a querier-specific encoder. We further apply contrastive learning withmulti-view augmentation, pulling close the dialogue representations of the samequerier, while pulling apart those of different queriers. To mitigate theimpact of query diversity on querier-contrastive learning, we cluster thedialogues based on query similarity and restrict the scope of contrastivelearning within each cluster. To address the lack of datasets designed forquerier-aware personalization, we also build a multi-querier dataset fromEnglish and Chinese scripts, as well as WeChat records, called MQDialog,containing 173 queriers and 12 responders. Extensive evaluations demonstratethat our design significantly improves the quality of personalized responsegeneration, achieving relative improvement of 8.4% to 48.7% in ROUGE-L scoresand winning rates ranging from 54% to 82% compared with various baselinemethods.</description><author>Hang Zeng, Chaoyue Niu, Fan Wu, Chengfei Lv, Guihai Chen</author><pubDate>Fri, 15 Aug 2025 08:12:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.11736v2</guid></item></channel></rss>