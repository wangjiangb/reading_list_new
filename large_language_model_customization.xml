<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 20 Nov 2024 01:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v3</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 10 Jul 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v3</guid></item><item><title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title><link>http://arxiv.org/abs/2407.07487v1</link><description>Product review generation is an important task in recommender systems, whichcould provide explanation and persuasiveness for the recommendation. Recently,Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modelingand generating ability, which could be applied in review generation. However,directly applying the LLMs for generating reviews might be troubled by the``polite'' phenomenon of the LLMs and could not generate personalized reviews(e.g., negative reviews). In this paper, we propose Review-LLM that customizesLLMs for personalized review generation. Firstly, we construct the prompt inputby aggregating user historical behaviors, which include corresponding itemtitles and reviews. This enables the LLMs to capture user interest features andreview writing style. Secondly, we incorporate ratings as indicators ofsatisfaction into the prompt, which could further improve the model'sunderstanding of user preferences and the sentiment tendency control ofgenerated reviews. Finally, we feed the prompt text into LLMs, and useSupervised Fine-Tuning (SFT) to make the model generate personalized reviewsfor the given user and target item. Experimental results on the real-worlddataset show that our fine-tuned model could achieve better review generationperformance than existing close-source LLMs.</description><author>Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang</author><pubDate>Wed, 10 Jul 2024 09:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07487v1</guid></item><item><title>PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games</title><link>http://arxiv.org/abs/2404.19721v3</link><description>This research introduces Procedural Artificial Narrative using Generative AI(PANGeA), a structured approach for leveraging large language models (LLMs),guided by a game designer's high-level criteria, to generate narrative contentfor turn-based role-playing video games (RPGs). Distinct from priorapplications of LLMs used for video game design, PANGeA innovates by not onlygenerating game level data (which includes, but is not limited to, setting, keyitems, and non-playable characters (NPCs)), but by also fostering dynamic,free-form interactions between the player and the environment that align withthe procedural game narrative. The NPCs generated by PANGeA arepersonality-biased and express traits from the Big 5 Personality Model in theirgenerated responses. PANGeA addresses challenges behind ingesting free-formtext input, which can prompt LLM responses beyond the scope of the gamenarrative. A novel validation system that uses the LLM's intelligence evaluatestext input and aligns generated responses with the unfolding narrative. Makingthese interactions possible, PANGeA is supported by a server that hosts acustom memory system that supplies context for augmenting generated responsesthus aligning them with the procedural narrative. For its broad application,the server has a REST interface enabling any game engine to integrate directlywith PANGeA, as well as an LLM interface adaptable with local or private LLMs.PANGeA's ability to foster dynamic narrative generation by aligning responseswith the procedural narrative is demonstrated through an empirical study andablation test of two versions of a demo game. These are, a custom,browser-based GPT and a Unity demo. As the results show, PANGeA holds potentialto assist game designers in using LLMs to generate narrative-consistent contenteven when provided varied and unpredictable, free-form text input.</description><author>Steph Buongiorno, Lawrence Jake Klinkert, Tanishq Chawla, Zixin Zhuang, Corey Clark</author><pubDate>Tue, 09 Jul 2024 23:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19721v3</guid></item><item><title>FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding</title><link>http://arxiv.org/abs/2407.05183v2</link><description>Flowcharts are graphical tools for representing complex concepts in concisevisual representations. This paper introduces the FlowLearn dataset, a resourcetailored to enhance the understanding of flowcharts. FlowLearn contains complexscientific flowcharts and simulated flowcharts. The scientific subset contains3,858 flowcharts sourced from scientific literature and the simulated subsetcontains 10,000 flowcharts created using a customizable script. The dataset isenriched with annotations for visual components, OCR, Mermaid coderepresentation, and VQA question-answer pairs. Despite the proven capabilitiesof Large Vision-Language Models (LVLMs) in various visual understanding tasks,their effectiveness in decoding flowcharts - a crucial element of scientificcommunication - has yet to be thoroughly investigated. The FlowLearn test setis crafted to assess the performance of LVLMs in flowchart comprehension. Ourstudy thoroughly evaluates state-of-the-art LVLMs, identifying existinglimitations and establishing a foundation for future enhancements in thisrelatively underexplored domain. For instance, in tasks involving simulatedflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the numberof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.Notably, no single model excels in all tasks within the FlowLearn framework,highlighting significant opportunities for further development.</description><author>Huitong Pan, Qi Zhang, Cornelia Caragea, Eduard Dragut, Longin Jan Latecki</author><pubDate>Tue, 09 Jul 2024 21:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05183v2</guid></item><item><title>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</title><link>http://arxiv.org/abs/2407.09467v1</link><description>In the diverse world of AI-driven storytelling, there is a unique opportunityto engage young audiences with customized, and personalized narratives. Thispaper introduces FairyLandAI an innovative Large Language Model (LLM) developedthrough OpenAI's API, specifically crafted to create personalized fairytalesfor children. The distinctive feature of FairyLandAI is its dual capability: itnot only generates stories that are engaging, age-appropriate, and reflectiveof various traditions but also autonomously produces imaginative promptssuitable for advanced image generation tools like GenAI and Dalle-3, therebyenriching the storytelling experience. FairyLandAI is expertly tailored toresonate with the imaginative worlds of children, providing narratives that areboth educational and entertaining and in alignment with the moral valuesinherent in different ages. Its unique strength lies in customizing stories tomatch individual children's preferences and cultural backgrounds, heralding anew era in personalized storytelling. Further, its integration with imagegeneration technology offers a comprehensive narrative experience thatstimulates both verbal and visual creativity. Empirical evaluations ofFairyLandAI demonstrate its effectiveness in crafting captivating stories forchildren, which not only entertain but also embody the values and teachings ofdiverse traditions. This model serves as an invaluable tool for parents andeducators, supporting them in imparting meaningful moral lessons throughengaging narratives. FairyLandAI represents a pioneering step in using LLMs,particularly through OpenAI's API, for educational and cultural enrichment,making complex moral narratives accessible and enjoyable for young, imaginativeminds.</description><author>Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos</author><pubDate>Fri, 12 Jul 2024 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09467v1</guid></item><item><title>Inference Optimization of Foundation Models on AI Accelerators</title><link>http://arxiv.org/abs/2407.09111v1</link><description>Powerful foundation models, including large language models (LLMs), withTransformer architectures have ushered in a new era of Generative AI acrossvarious industries. Industry and research community have witnessed a largenumber of new applications, based on those foundation models. Such applicationsinclude question and answer, customer services, image and video generation, andcode completions, among others. However, as the number of model parametersreaches to hundreds of billions, their deployment incurs prohibitive inferencecosts and high latency in real-world scenarios. As a result, the demand forcost-effective and fast inference using AI accelerators is ever more higher. Tothis end, our tutorial offers a comprehensive discussion on complementaryinference optimization techniques using AI accelerators. Beginning with anoverview of basic Transformer architectures and deep learning systemframeworks, we deep dive into system optimization techniques for fast andmemory-efficient attention computations and discuss how they can be implementedefficiently on AI accelerators. Next, we describe architectural elements thatare key for fast transformer inference. Finally, we examine various modelcompression and fast decoding strategies in the same context.</description><author>Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis</author><pubDate>Fri, 12 Jul 2024 09:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09111v1</guid></item><item><title>Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors</title><link>http://arxiv.org/abs/2407.09136v1</link><description>Large language models (LLMs) present an opportunity to scale high-qualitypersonalized education to all. A promising approach towards this means is tobuild dialog tutoring models that scaffold students' problem-solving. However,even though existing LLMs perform well in solving reasoning questions, theystruggle to precisely detect student's errors and tailor their feedback tothese errors. Inspired by real-world teaching practice where teachers identifystudent errors and customize their response based on them, we focus onverifying student solutions and show how grounding to such verificationimproves the overall quality of tutor response generation. We collect a datasetof 1K stepwise math reasoning chains with the first error step annotated byteachers. We show empirically that finding the mistake in a student solution ischallenging for current models. We propose and evaluate several verifiers fordetecting these errors. Using both automatic and human evaluation we show thatthe student solution verifiers steer the generation model towards highlytargeted responses to student errors which are more often correct with lesshallucinations compared to existing baselines.</description><author>Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan</author><pubDate>Fri, 12 Jul 2024 10:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09136v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v6</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adjusting the large modelsover the various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task or domain while minimizing the number of additional parametersintroduced or computational resources required. This approach is particularlyimportant when dealing with large-scale language models with high parametercounts, as fine-tuning these models from scratch can be computationallyexpensive and resource-intensive, posing considerable challenges in thesupporting system platform design. In this survey, we present comprehensivestudies of various PEFT algorithms, examining their performance andcomputational overhead. Moreover, we provide an overview of applicationsdeveloped using different PEFT algorithms and discuss common techniquesemployed to mitigate computation costs for PEFT. In addition to providing anextensive survey from an algorithmic standpoint, we also examine variousreal-world system designs to investigate the implementation costs associatedwith different PEFT approaches. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed ......</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Fri, 12 Jul 2024 09:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v6</guid></item><item><title>Evaluating Nuanced Bias in Large Language Model Free Response Answers</title><link>http://arxiv.org/abs/2407.08842v1</link><description>Pre-trained large language models (LLMs) can now be easily adapted forspecific business purposes using custom prompts or fine tuning. Thesecustomizations are often iteratively re-engineered to improve some aspect ofperformance, but after each change businesses want to ensure that there hasbeen no negative impact on the system's behavior around such critical issues asbias. Prior methods of benchmarking bias use techniques such as word maskingand multiple choice questions to assess bias at scale, but these do not captureall of the nuanced types of bias that can occur in free response answers, thetypes of answers typically generated by LLM systems. In this paper, we identifyseveral kinds of nuanced bias in free text that cannot be similarly identifiedby multiple choice tests. We describe these as: confidence bias, implied bias,inclusion bias and erasure bias. We present a semi-automated pipeline fordetecting these types of bias by first eliminating answers that can beautomatically classified as unbiased and then co-evaluating name reversed pairsusing crowd workers. We believe that the nuanced classifications our methodgenerates can be used to give better feedback to LLMs, especially as LLMreasoning capabilities become more advanced.</description><author>Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Moumita Sinha</author><pubDate>Thu, 11 Jul 2024 19:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08842v1</guid></item><item><title>UrbanWorld: An Urban World Model for 3D City Generation</title><link>http://arxiv.org/abs/2407.11965v1</link><description>Cities, as the most fundamental environment of human life, encompass diversephysical elements such as buildings, roads and vegetation with complexinterconnection. Crafting realistic, interactive 3D urban environments plays acrucial role in constructing AI agents capable of perceiving, decision-making,and acting like humans in real-world environments. However, creatinghigh-fidelity 3D urban environments usually entails extensive manual labor fromdesigners, involving intricate detailing and accurate representation of complexurban features. Therefore, how to accomplish this in an automatical way remainsa longstanding challenge. Toward this problem, we propose UrbanWorld, the firstgenerative urban world model that can automatically create a customized,realistic and interactive 3D urban world with flexible control conditions.UrbanWorld incorporates four key stages in the automatical crafting pipeline:3D layout generation from openly accessible OSM data, urban scene planning anddesigning with a powerful urban multimodal large language model (Urban MLLM),controllable urban asset rendering with advanced 3D diffusion techniques, andfinally the MLLM-assisted scene refinement. The crafted high-fidelity 3D urbanenvironments enable realistic feedback and interactions for general AI andmachine perceptual systems in simulations. We are working on contributingUrbanWorld as an open-source and versatile platform for evaluating andimproving AI abilities in perception, decision-making, and interaction inrealistic urban environments.</description><author>Yu Shang, Jiansheng Chen, Hangyu Fan, Jingtao Ding, Jie Feng, Yong Li</author><pubDate>Tue, 16 Jul 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11965v1</guid></item><item><title>How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models</title><link>http://arxiv.org/abs/2407.11549v1</link><description>Psychological evidence reveals the influence of personality traits ondecision-making. For instance, agreeableness is generally associated withpositive outcomes in negotiations, whereas neuroticism is often linked to lessfavorable outcomes. This paper introduces a simulation framework centered onLarge Language Model (LLM) agents endowed with synthesized personality traits.The agents negotiate within bargaining domains and possess customizablepersonalities and objectives. The experimental results show that the behavioraltendencies of LLM-based simulations could reproduce behavioral patternsobserved in human negotiations. The contribution is twofold. First, we proposea simulation methodology that investigates the alignment between the linguisticand economic capabilities of LLM agents. Secondly, we offer empirical insightsinto the strategic impact of Big-Five personality traits on the outcomes ofbilateral negotiations. We also provide a case study based on synthesizedbargaining dialogues to reveal intriguing behaviors, including deceitful andcompromising behaviors.</description><author>Yin Jou Huang, Rafik Hadfi</author><pubDate>Tue, 16 Jul 2024 09:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11549v1</guid></item><item><title>Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation</title><link>http://arxiv.org/abs/2407.11503v1</link><description>Existing few-shot segmentation (FSS) methods mainly focus on prototypefeature generation and the query-support matching mechanism. As a crucialprompt for generating prototype features, the pair of image-mask types in thesupport set has become the default setting. However, various types such asimage, text, box, and mask all can provide valuable information regarding theobjects in context, class, localization, and shape appearance. Existing workfocuses on specific combinations of guidance, leading FSS into differentresearch branches. Rethinking guidance types in FSS is expected to explore theefficient joint representation of the coupling between the support set andquery set, giving rise to research trends in the weakly or strongly annotatedguidance to meet the customized requirements of practical users. In this work,we provide the generalized FSS with seven guidance paradigms and develop auniversal vision-language framework (UniFSS) to integrate prompts from text,mask, box, and image. Leveraging the advantages of large-scale pre-trainingvision-language models in textual and visual embeddings, UniFSS proposeshigh-level spatial correction and embedding interactive units to overcome thesemantic ambiguity drawbacks typically encountered by pure visual matchingmethods when facing intra-class appearance diversities. Extensive experimentsshow that UniFSS significantly outperforms the state-of-the-art methods.Notably, the weakly annotated class-aware box paradigm even surpasses thefinely annotated mask paradigm.</description><author>Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu</author><pubDate>Tue, 16 Jul 2024 08:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11503v1</guid></item><item><title>Pretraining Data and Tokenizer for Indic LLM</title><link>http://arxiv.org/abs/2407.12481v1</link><description>We present a novel approach to data preparation for developing multilingualIndic large language model. Our meticulous data acquisition spans open-sourceand proprietary sources, including Common Crawl, Indic books, news articles,and Wikipedia, ensuring a diverse and rich linguistic representation. For eachIndic language, we design a custom preprocessing pipeline to effectivelyeliminate redundant and low-quality text content. Additionally, we performdeduplication on Common Crawl data to address the redundancy present in 70% ofthe crawled web pages. This study focuses on developing high-quality data,optimizing tokenization for our multilingual dataset for Indic large languagemodels with 3B and 7B parameters, engineered for superior performance in Indiclanguages. We introduce a novel multilingual tokenizer training strategy,demonstrating our custom-trained Indic tokenizer outperforms thestate-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-wordratio for Indic languages.</description><author>Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar</author><pubDate>Wed, 17 Jul 2024 11:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12481v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v4</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 17 Jul 2024 07:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v4</guid></item><item><title>Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond</title><link>http://arxiv.org/abs/2407.11100v2</link><description>Large Language Models (LLMs) are increasingly integrated into diverseindustries, posing substantial security risks due to unauthorized replicationand misuse. To mitigate these concerns, robust identification mechanisms arewidely acknowledged as an effective strategy. Identification systems for LLMsnow rely heavily on watermarking technology to manage and protect intellectualproperty and ensure data security. However, previous studies have primarilyconcentrated on the basic principles of algorithms and lacked a comprehensiveanalysis of watermarking theory and practice from the perspective ofintelligent identification. To bridge this gap, firstly, we explore how arobust identity recognition system can be effectively implemented and managedwithin LLMs by various participants using watermarking technology. Secondly, wepropose a mathematical framework based on mutual information theory, whichsystematizes the identification process to achieve more precise and customizedwatermarking. Additionally, we present a comprehensive evaluation ofperformance metrics for LLM watermarking, reflecting participant preferencesand advancing discussions on its identification applications. Lastly, weoutline the existing challenges in current watermarking technologies andtheoretical frameworks, and provide directional guidance to address thesechallenges. Our systematic classification and detailed exposition aim toenhance the comparison and evaluation of various methods, fostering furtherresearch and development toward a transparent, secure, and equitable LLMecosystem.</description><author>Xuhong Wang, Haoyu Jiang, Yi Yu, Jingru Yu, Yilun Lin, Ping Yi, Yingchun Wang, Qiao Yu, Li Li, Fei-Yue Wang</author><pubDate>Wed, 17 Jul 2024 03:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11100v2</guid></item><item><title>On Pre-training of Multimodal Language Models Customized for Chart Understanding</title><link>http://arxiv.org/abs/2407.14506v1</link><description>Recent studies customizing Multimodal Large Language Models (MLLMs) fordomain-specific tasks have yielded promising results, especially in the fieldof scientific chart comprehension. These studies generally utilize visualinstruction tuning with specialized datasets to enhance question and answer(QA) accuracy within the chart domain. However, they often neglect thefundamental discrepancy between natural image-caption pre-training data anddigital chart image-QA data, particularly in the models' capacity to extractunderlying numeric values from charts. This paper tackles this oversight byexploring the training processes necessary to improve MLLMs' comprehension ofcharts. We present three key findings: (1) Incorporating raw data values inalignment pre-training markedly improves comprehension of chart data. (2)Replacing images with their textual representation randomly during end-to-endfine-tuning transfer the language reasoning capability to chart interpretationskills. (3) Requiring the model to first extract the underlying chart data andthen answer the question in the fine-tuning can further improve the accuracy.Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chartcomprehension. CHOPINLLM effectively interprets various types of charts,including unannotated ones, while maintaining robust reasoning abilities.Furthermore, we establish a new benchmark to evaluate MLLMs' understanding ofdifferent chart types across various comprehension levels. Experimental resultsshow that CHOPINLLM exhibits strong performance in understanding both annotatedand unannotated charts across a wide range of types.</description><author>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal</author><pubDate>Fri, 19 Jul 2024 17:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14506v1</guid></item><item><title>The Art of Refusal: A Survey of Abstention in Large Language Models</title><link>http://arxiv.org/abs/2407.18418v1</link><description>Abstention, the refusal of large language models (LLMs) to provide an answer,is increasingly recognized for its potential to mitigate hallucinations andenhance safety in building LLM systems. In this survey, we introduce aframework to examine abstention behavior from three perspectives: the query,the model, and human values. We review the literature on abstention methods(categorized based on the development stages of LLMs), benchmarks, andevaluation metrics, and discuss the merits and limitations of prior work. Wefurther identify and motivate areas for future research, such as encouragingthe study of abstention as a meta-capability across tasks and customizingabstention abilities based on context. In doing so, we aim to broaden the scopeand impact of abstention methodologies in AI systems.</description><author>Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang</author><pubDate>Thu, 25 Jul 2024 22:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18418v1</guid></item><item><title>RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent</title><link>http://arxiv.org/abs/2407.16667v1</link><description>Recently, advanced Large Language Models (LLMs) such as GPT-4 have beenintegrated into many real-world applications like Code Copilot. Theseapplications have significantly expanded the attack surface of LLMs, exposingthem to a variety of threats. Among them, jailbreak attacks that induce toxicresponses through jailbreak prompts have raised critical safety concerns. Toidentify these threats, a growing number of red teaming approaches simulatepotential adversarial scenarios by crafting jailbreak prompts to test thetarget LLM. However, existing red teaming methods do not consider the uniquevulnerabilities of LLM in different scenarios, making it difficult to adjustthe jailbreak prompts to find context-specific vulnerabilities. Meanwhile,these methods are limited to refining jailbreak templates using a few mutationoperations, lacking the automation and scalability to adapt to differentscenarios. To enable context-aware and efficient red teaming, we abstract andmodel existing attacks into a coherent concept called "jailbreak strategy" andpropose a multi-agent LLM system named RedAgent that leverages these strategiesto generate context-aware jailbreak prompts. By self-reflecting on contextualfeedback in an additional memory buffer, RedAgent continuously learns how toleverage these strategies to achieve effective jailbreaks in specific contexts.Extensive experiments demonstrate that our system can jailbreak most black-boxLLMs in just five queries, improving the efficiency of existing red teamingmethods by two times. Additionally, RedAgent can jailbreak customized LLMapplications more efficiently. By generating context-aware jailbreak promptstowards applications on GPTs, we discover 60 severe vulnerabilities of thesereal-world applications with only two queries per vulnerability. We havereported all found issues and communicated with OpenAI and Meta for bug fixes.</description><author>Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren</author><pubDate>Tue, 23 Jul 2024 17:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16667v1</guid></item><item><title>ITINERA: Integrating Spatial Optimization with Large Language Models for Open-domain Urban Itinerary Planning</title><link>http://arxiv.org/abs/2402.07204v3</link><description>Citywalk, a recently popular form of urban travel, requires genuinepersonalization and understanding of fine-grained requests compared totraditional itinerary planning. In this paper, we introduce the novel task ofOpen-domain Urban Itinerary Planning (OUIP), which generates personalized urbanitineraries from user requests in natural language. We then present ITINERA, anOUIP system that integrates spatial optimization with large language models toprovide customized urban itineraries based on user needs. This involvesdecomposing user requests, selecting candidate points of interest (POIs),ordering the POIs based on cluster-aware spatial optimization, and generatingthe itinerary. Experiments on real-world datasets and the performance of thedeployed system demonstrate our system's capacity to deliver personalized andspatially coherent itineraries compared to current solutions.</description><author>Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma</author><pubDate>Tue, 23 Jul 2024 11:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07204v3</guid></item><item><title>LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation</title><link>http://arxiv.org/abs/2407.12126v2</link><description>Machine translation is indispensable in healthcare for enabling the globaldissemination of medical knowledge across languages. However, complex medicalterminology poses unique challenges to achieving adequate translation qualityand accuracy. This study introduces a novel "LLMs-in-the-loop" approach todevelop supervised neural machine translation models optimized specifically formedical texts. While large language models (LLMs) have demonstrated powerfulcapabilities, this research shows that small, specialized models trained onhigh-quality in-domain (mostly synthetic) data can outperform even vastlylarger LLMs. Custom parallel corpora in six languages were compiled from scientificarticles, synthetically generated clinical documents, and medical texts. OurLLMs-in-the-loop methodology employs synthetic data generation, rigorousevaluation, and agent orchestration to enhance performance. We developed smallmedical translation models using the MarianMT base model. We introduce a newmedical translation test dataset to standardize evaluation in this domain.Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, ourMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo. Results demonstrate that our LLMs-in-the-loop approach, combined withfine-tuning high-quality, domain-specific data, enables specialized models tooutperform general-purpose and some larger systems. This research, part of abroader series on expert small models, paves the way for futurehealthcare-related AI developments, including deidentification and bio-medicalentity extraction models. Our study underscores the potential of tailoredneural translation models and the LLMs-in-the-loop methodology to advance thefield through improved data generation, evaluation, agent, and modelingtechniques.</description><author>Bunyamin Keles, Murat Gunay, Serdar I. Caglar</author><pubDate>Fri, 26 Jul 2024 12:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12126v2</guid></item><item><title>Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</title><link>http://arxiv.org/abs/2402.05140v3</link><description>Large Language Models (LLMs) have demonstrated remarkable proficiency inunderstanding and generating natural language. However, their capabilities wanein highly specialized domains underrepresented in the pretraining corpus, suchas physical and biomedical sciences. This work explores how to repurposegeneral LLMs into effective task solvers for specialized domains. We introducea novel, model-agnostic framework for learning custom input tags, which areparameterized as continuous vectors appended to the LLM's embedding layer, tocondition the LLM. We design two types of input tags: domain tags are used todelimit specialized representations (e.g., chemical formulas) and providedomain-relevant context; function tags are used to represent specific functions(e.g., predicting molecular properties) and compress function-solvinginstructions. We develop a three-stage protocol to learn these tags usingauxiliary data and domain knowledge. By explicitly disentangling task domainsfrom task functions, our method enables zero-shot generalization to unseenproblems through diverse combinations of the input tags. It also boosts LLM'sperformance in various specialized domains, such as predicting protein orchemical properties and modeling drug-target interactions, outperforming expertmodels tailored to these tasks.</description><author>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi</author><pubDate>Fri, 26 Jul 2024 01:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05140v3</guid></item><item><title>AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes</title><link>http://arxiv.org/abs/2312.06644v3</link><description>Inspired by cognitive theories, we introduce AnyHome, a framework thattranslates any text into well-structured and textured indoor scenes at ahouse-scale. By prompting Large Language Models (LLMs) with designed templates,our approach converts provided textual narratives into amodal structuredrepresentations. These representations guarantee consistent and realisticspatial layouts by directing the synthesis of a geometry mesh within definedconstraints. A Score Distillation Sampling process is then employed to refinethe geometry, followed by an egocentric inpainting process that adds lifeliketextures to it. AnyHome stands out with its editability, customizability,diversity, and realism. The structured representations for scenes allow forextensive editing at varying levels of granularity. Capable of interpretingtexts ranging from simple labels to detailed narratives, AnyHome generatesdetailed geometries and textures that outperform existing methods in bothquantitative and qualitative measures.</description><author>Rao Fu, Zehao Wen, Zichen Liu, Srinath Sridhar</author><pubDate>Mon, 29 Jul 2024 00:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06644v3</guid></item><item><title>SOWA: Adapting Hierarchical Frozen Window Self-Attention to Visual-Language Models for Better Anomaly Detection</title><link>http://arxiv.org/abs/2407.03634v2</link><description>Visual anomaly detection is critical in industrial manufacturing, buttraditional methods often rely on extensive normal datasets and custom models,limiting scalability. Recent advancements in large-scale visual-language modelshave significantly improved zero/few-shot anomaly detection. However, theseapproaches may not fully utilize hierarchical features, potentially missingnuanced details. We introduce a window self-attention mechanism based on theCLIP model, combined with learnable prompts to process multi-level featureswithin a Soldier-Offier Window self-Attention (SOWA) framework. Our method hasbeen tested on five benchmark datasets, demonstrating superior performance byleading in 18 out of 20 metrics compared to existing state-of-the-arttechniques.</description><author>Zongxiang Hu, Zhaosheng Zhang</author><pubDate>Tue, 30 Jul 2024 11:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03634v2</guid></item><item><title>Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming</title><link>http://arxiv.org/abs/2407.20712v1</link><description>End-user development allows everyday users to tailor service robots orapplications to their needs. One user-friendly approach is natural languageprogramming. However, it encounters challenges such as an expansive userexpression space and limited support for debugging and editing, which restrictits application in end-user programming. The emergence of large language models(LLMs) offers promising avenues for the translation and interpretation betweenhuman language instructions and the code executed by robots, but theirapplication in end-user programming systems requires further study. Weintroduce Cocobo, a natural language programming system with interactivediagrams powered by LLMs. Cocobo employs LLMs to understand users' authoringintentions, generate and explain robot programs, and facilitate the conversionbetween executable code and flowchart representations. Our user study showsthat Cocobo has a low learning curve, enabling even users with zero codingexperience to customize robot programs successfully.</description><author>Yate Ge, Yi Dai, Run Shan, Kechun Li, Yuanda Hu, Xiaohua Sun</author><pubDate>Tue, 30 Jul 2024 10:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20712v1</guid></item><item><title>Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language</title><link>http://arxiv.org/abs/2407.20513v1</link><description>This paper presents a conversational pipeline for crafting domain knowledgefor complex neuro-symbolic models through natural language prompts. Itleverages large language models to generate declarative programs in theDomiKnowS framework. The programs in this framework express concepts and theirrelationships as a graph in addition to logical constraints between them. Thegraph, later, can be connected to trainable neural models according to thosespecifications. Our proposed pipeline utilizes techniques like dynamicin-context demonstration retrieval, model refinement based on feedback from asymbolic parser, visualization, and user interaction to generate the tasks'structure and formal knowledge representation. This approach empowers domainexperts, even those not well-versed in ML/AI, to formally declare theirknowledge to be incorporated in customized neural models in the DomiKnowSframework.</description><author>Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi</author><pubDate>Tue, 30 Jul 2024 03:10:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20513v1</guid></item><item><title>CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment</title><link>http://arxiv.org/abs/2407.21553v1</link><description>This paper presents the Customer Experience (CX) Simulator, a novel frameworkdesigned to assess the effects of untested web-marketing campaigns through userbehavior simulations. The proposed framework leverages large language models(LLMs) to represent various events in a user's behavioral history, such asviewing an item, applying a coupon, or purchasing an item, as semanticembedding vectors. We train a model to predict transitions between events fromtheir LLM embeddings, which can even generalize to unseen events by learningfrom diverse training data. In web-marketing applications, we leverage thistransition prediction model to simulate how users might react differently whennew campaigns or products are presented to them. This allows us to eliminatethe need for costly online testing and enhance the marketers' abilities toreveal insights. Our numerical evaluation and user study, utilizing BigQueryPublic Datasets from the Google Merchandise Store, demonstrate theeffectiveness of our framework.</description><author>Akira Kasuga, Ryo Yonetani</author><pubDate>Wed, 31 Jul 2024 12:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21553v1</guid></item><item><title>Building AI Agents for Autonomous Clouds: Challenges and Design Principles</title><link>http://arxiv.org/abs/2407.12165v2</link><description>The rapid growth in the use of Large Language Models (LLMs) and AI Agents aspart of software development and deployment is revolutionizing the informationtechnology landscape. While code generation receives significant attention, ahigher-impact application lies in using AI agents for operational resilience ofcloud services, which currently require significant human effort and domainknowledge. There is a growing interest in AI for IT Operations (AIOps) whichaims to automate complex operational tasks, like fault localization and rootcause analysis, thereby reducing human intervention and customer impact.However, achieving the vision of autonomous and self-healing clouds throughAIOps is hampered by the lack of standardized frameworks for building,evaluating, and improving AIOps agents. This vision paper lays the groundworkfor such a framework by first framing the requirements and then discussingdesign decisions that satisfy them. We also propose AIOpsLab, a prototypeimplementation leveraging agent-cloud-interface that orchestrates anapplication, injects real-time faults using chaos engineering, and interfaceswith an agent to localize and resolve the faults. We report promising resultsand lay the groundwork to build a modular and robust framework for building,evaluating, and improving agents for autonomous clouds.</description><author>Manish Shetty, Yinfang Chen, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Xuchao Zhang, Jonathan Mace, Dax Vandevoorde, Pedro Las-Casas, Shachee Mishra Gupta, Suman Nath, Chetan Bansal, Saravan Rajmohan</author><pubDate>Wed, 31 Jul 2024 06:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12165v2</guid></item><item><title>On Pre-training of Multimodal Language Models Customized for Chart Understanding</title><link>http://arxiv.org/abs/2407.14506v2</link><description>Recent studies customizing Multimodal Large Language Models (MLLMs) fordomain-specific tasks have yielded promising results, especially in the fieldof scientific chart comprehension. These studies generally utilize visualinstruction tuning with specialized datasets to enhance question and answer(QA) accuracy within the chart domain. However, they often neglect thefundamental discrepancy between natural image-caption pre-training data anddigital chart image-QA data, particularly in the models' capacity to extractunderlying numeric values from charts. This paper tackles this oversight byexploring the training processes necessary to improve MLLMs' comprehension ofcharts. We present three key findings: (1) Incorporating raw data values inalignment pre-training markedly improves comprehension of chart data. (2)Replacing images with their textual representation randomly during end-to-endfine-tuning transfer the language reasoning capability to chart interpretationskills. (3) Requiring the model to first extract the underlying chart data andthen answer the question in the fine-tuning can further improve the accuracy.Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chartcomprehension. CHOPINLLM effectively interprets various types of charts,including unannotated ones, while maintaining robust reasoning abilities.Furthermore, we establish a new benchmark to evaluate MLLMs' understanding ofdifferent chart types across various comprehension levels. Experimental resultsshow that CHOPINLLM exhibits strong performance in understanding both annotatedand unannotated charts across a wide range of types.</description><author>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal</author><pubDate>Wed, 31 Jul 2024 21:01:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14506v2</guid></item><item><title>DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency</title><link>http://arxiv.org/abs/2408.00741v1</link><description>The rapid evolution and widespread adoption of generative large languagemodels (LLMs) have made them a pivotal workload in various applications. Today,LLM inference clusters receive a large number of queries with strict ServiceLevel Objectives (SLOs). To achieve the desired performance, these modelsexecute on power-hungry GPUs causing the inference clusters to consume largeamount of energy and, consequently, result in excessive carbon emissions.Fortunately, we find that there is a great opportunity to exploit theheterogeneity in inference compute properties and fluctuations in inferenceworkloads, to significantly improve energy-efficiency. However, such a diverseand dynamic environment creates a large search-space where different systemconfigurations (e.g., number of instances, model parallelism, and GPUfrequency) translate into different energy-performance trade-offs. To addressthese challenges, we propose DynamoLLM, the first energy-management frameworkfor LLM inference environments. DynamoLLM automatically and dynamicallyreconfigures the inference cluster to optimize for energy and cost of LLMserving under the service's performance SLOs. We show that at a service-level,DynamoLLM conserves 53% energy and 38% operational carbon emissions, andreduces 61% cost to the customer, while meeting the latency SLOs.</description><author>Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse</author><pubDate>Thu, 01 Aug 2024 17:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00741v1</guid></item><item><title>AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models</title><link>http://arxiv.org/abs/2408.00665v1</link><description>Automated Machine Learning (AutoML) offers a promising approach to streamlinethe training of machine learning models. However, existing AutoML frameworksare often limited to unimodal scenarios and require extensive manualconfiguration. Recent advancements in Large Language Models (LLMs) haveshowcased their exceptional abilities in reasoning, interaction, and codegeneration, presenting an opportunity to develop a more automated anduser-friendly framework. To this end, we introduce AutoM3L, an innovativeAutomated Multimodal Machine Learning framework that leverages LLMs ascontrollers to automatically construct multimodal training pipelines. AutoM3Lcomprehends data modalities and selects appropriate models based on userrequirements, providing automation and interactivity. By eliminating the needfor manual feature engineering and hyperparameter optimization, our frameworksimplifies user engagement and enables customization through directives,addressing the limitations of previous rule-based AutoML approaches. Weevaluate the performance of AutoM3L on six diverse multimodal datasets spanningclassification, regression, and retrieval tasks, as well as a comprehensive setof unimodal datasets. The results demonstrate that AutoM3L achieves competitiveor superior performance compared to traditional rule-based AutoML methods.Furthermore, a user study highlights the user-friendliness and usability of ourframework, compared to the rule-based AutoML methods.</description><author>Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen</author><pubDate>Thu, 01 Aug 2024 16:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00665v1</guid></item><item><title>Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services</title><link>http://arxiv.org/abs/2407.00110v2</link><description>The widespread adoption of large language models (LLMs) has created apressing need for an efficient, secure and private serving infrastructure,which allows researchers to run open source or custom fine-tuned LLMs andensures users that their data remains private and is not stored without theirconsent. While high-performance computing (HPC) systems equipped withstate-of-the-art GPUs are well-suited for training LLMs, their batch schedulingparadigm is not designed to support real-time serving of AI applications. Cloudsystems, on the other hand, are well suited for web services but commonly lackaccess to the computational power of HPC clusters, especially expensive andscarce high-end GPUs, which are required for optimal inference speed. Wepropose an architecture with an implementation consisting of a web service thatruns on a cloud VM with secure access to a scalable backend running a multitudeof LLM models on HPC systems. By offering a web service using our HPCinfrastructure to host LLMs, we leverage the trusted environment of localuniversities and research centers to offer a private and secure alternative tocommercial LLM services. Our solution natively integrates with the HPC batchscheduler Slurm, enabling seamless deployment on HPC clusters, and is able torun side by side with regular Slurm workloads, while utilizing gaps in theschedule created by Slurm. In order to ensure the security of the HPC system,we use the SSH ForceCommand directive to construct a robust circuit breaker,which prevents successful attacks on the web-facing server from affecting thecluster. We have successfully deployed our system as a production service, andmade the source code available at \url{https://github.com/gwdg/chat-ai}</description><author>Ali Doosthosseini, Jonathan Decker, Hendrik Nolte, Julian M. Kunkel</author><pubDate>Fri, 02 Aug 2024 15:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00110v2</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v3</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Fri, 02 Aug 2024 03:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v3</guid></item><item><title>Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models</title><link>http://arxiv.org/abs/2408.02416v1</link><description>The drastic increase of large language models' (LLMs) parameters has led to anew research direction of fine-tuning-free downstream customization by prompts,i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)play an important role in many businesses, there has emerged growing concernsabout the prompt leakage, which undermines the intellectual properties of theseservices and causes downstream attacks. In this paper, we analyze theunderlying mechanism of prompt leakage, which we refer to as promptmemorization, and develop corresponding defending strategies. By exploring thescaling laws in prompt extraction, we analyze key attributes that influenceprompt extraction, including model sizes, prompt lengths, as well as the typesof prompts. Then we propose two hypotheses that explain how LLMs expose theirprompts. The first is attributed to the perplexity, i.e. the familiarity ofLLMs to texts, whereas the second is based on the straightforward tokentranslation path in attention matrices. To defend against such threats, weinvestigate whether alignments can undermine the extraction of prompts. We findthat current LLMs, even those with safety alignments like GPT-4, are highlyvulnerable to prompt extraction attacks, even under the most straightforwarduser attacks. Therefore, we put forward several defense strategies with theinspiration of our findings, which achieve 83.8\% and 71.0\% drop in the promptextraction rate for Llama2-7B and GPT-3.5, respectively. Source code isavaliable at \url{https://github.com/liangzid/PromptExtractionEval}.</description><author>Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li</author><pubDate>Mon, 05 Aug 2024 12:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02416v1</guid></item><item><title>Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding</title><link>http://arxiv.org/abs/2408.02361v1</link><description>State-of-the-art task-oriented dialogue systems typically rely ontask-specific ontologies for fulfilling user queries. The majority oftask-oriented dialogue data, such as customer service recordings, comes withoutontology and annotation. Such ontologies are normally built manually, limitingthe application of specialised systems. Dialogue ontology construction is anapproach for automating that process and typically consists of two steps: termextraction and relation extraction. In this work, we focus on relationextraction in a transfer learning set-up. To improve the generalisation, wepropose an extension to the decoding mechanism of large language models. Weadapt Chain-of-Thought (CoT) decoding, recently developed for reasoningproblems, to generative relation extraction. Here, we generate multiplebranches in the decoding space and select the relations based on a confidencethreshold. By constraining the decoding to ontology terms and relations, we aimto decrease the risk of hallucination. We conduct extensive experimentation ontwo widely used datasets and find improvements in performance on targetontology for source fine-tuned and one-shot prompted large language models.</description><author>Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Gašić</author><pubDate>Mon, 05 Aug 2024 10:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02361v1</guid></item><item><title>ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems</title><link>http://arxiv.org/abs/2408.02248v1</link><description>Recently, there has been increasing interest in using Large Language Models(LLMs) to construct complex multi-agent systems to perform tasks such ascompiling literature reviews, drafting consumer reports, and planningvacations. Many tools and libraries exist for helping create such systems,however none support recursive multi-agent systems -- where the modelsthemselves flexibly decide when to delegate tasks and how to organize theirdelegation structure. In this work, we introduce ReDel: a toolkit for recursivemulti-agent systems that supports custom tool-use, delegation schemes,event-based logging, and interactive replay in an easy-to-use web interface. Weshow that, using ReDel, we are able to achieve significant performance gains onagentic benchmarks and easily identify potential areas of improvements throughthe visualization and debugging tools. Our code, documentation, and PyPIpackage are open-source and free to use under the MIT license.</description><author>Andrew Zhu, Liam Dugan, Chris Callison-Burch</author><pubDate>Mon, 05 Aug 2024 05:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02248v1</guid></item><item><title>Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)</title><link>http://arxiv.org/abs/2408.02201v1</link><description>The use of large language models (LLMs) is expanding rapidly, and open-sourceversions are becoming available, offering users safer and more adaptableoptions. These models enable users to protect data privacy by eliminating theneed to provide data to third parties and can be customized for specific tasks.In this study, we compare the performance of various language models on theSustainable Development Goal (SDG) mapping task, using the output of GPT-4o asthe baseline. The selected open-source models for comparison include Mixtral,LLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a morespecialized version of GPT-4o, was included to extend the comparison. Given themulti-label nature of the SDG mapping task, we employed metrics such as F1score, precision, and recall with micro-averaging to evaluate different aspectsof the models' performance. These metrics are derived from the confusion matrixto ensure a comprehensive evaluation. We provide a clear observation andanalysis of each model's performance by plotting curves based on F1 score,precision, and recall at different thresholds. According to the results of thisexperiment, LLaMA 2 and Gemma still have significant room for improvement. Theother four models do not exhibit particularly large differences in performance.The outputs from all seven models are available on Zenodo:https://doi.org/10.5281/zenodo.12789375.</description><author>Hui Yin, Amir Aryani, Nakul Nambiar</author><pubDate>Mon, 05 Aug 2024 03:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02201v1</guid></item><item><title>LLaSA: Large Language and E-Commerce Shopping Assistant</title><link>http://arxiv.org/abs/2408.02006v1</link><description>The e-commerce platform has evolved rapidly due to its widespread popularityand convenience. Developing an e-commerce shopping assistant for customers iscrucial to aiding them in quickly finding desired products and recommendingprecisely what they need. However, most previous shopping assistants face twomain problems: (1) task-specificity, which necessitates the development ofdifferent models for various tasks, thereby increasing development costs andlimiting effectiveness; and (2) poor generalization, where the trained modelperforms inadequately on up-to-date products. To resolve these issues, weemploy Large Language Models (LLMs) to construct an omnipotent assistant,leveraging their adeptness at handling multiple tasks and their superiorgeneralization capability. Nonetheless, LLMs lack inherent knowledge ofe-commerce concepts. To address this, we create an instruction datasetcomprising 65,000 samples and diverse tasks, termed as EshopInstruct. Throughinstruction tuning on our dataset, the assistant, named LLaSA, demonstrates thepotential to function as an omnipotent assistant. Additionally, we proposevarious inference optimization strategies to enhance performance with limitedinference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,LLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57tasks and approximately 20,000 questions, and we secured top-5 rankings in eachtrack, especially in track4, where we achieved the best performance resultamong all student teams. Our extensive practices fully demonstrate that LLMspossess the great potential to be competent e-commerce shopping assistants.</description><author>Shuo Zhang, Boci Peng, Xinping Zhao, Boren Hu, Yun Zhu, Yanjia Zeng, Xuming Hu</author><pubDate>Sun, 04 Aug 2024 12:10:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02006v1</guid></item><item><title>VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model</title><link>http://arxiv.org/abs/2406.01059v2</link><description>In this paper, we focus on resolving the problem of image outpainting, whichaims to extrapolate the surrounding parts given the center contents of animage. Although recent works have achieved promising performance, the lack ofversatility and customization hinders their practical applications in broaderscenarios. Therefore, this work presents a novel image outpainting frameworkthat is capable of customizing the results according to the requirement ofusers. First of all, we take advantage of a Multimodal Large Language Model(MLLM) that automatically extracts and organizes the corresponding textualdescriptions of the masked and unmasked part of a given image. Accordingly, theobtained text prompts are introduced to endow our model with the capacity tocustomize the outpainting results. In addition, a special Cross-Attentionmodule, namely Center-Total-Surrounding (CTS), is elaborately designed toenhance further the the interaction between specific space regions of the imageand corresponding parts of the text prompts. Note that unlike most existingmethods, our approach is very resource-efficient since it is just slightlyfine-tuned on the off-the-shelf stable diffusion (SD) model rather than beingtrained from scratch. Finally, the experimental results on three commonly useddatasets, i.e. Scenery, Building, and WikiArt, demonstrate our modelsignificantly surpasses the SoTA methods. Moreover, versatile outpaintingresults are listed to show its customized ability.</description><author>Jinze Yang, Haoran Wang, Zining Zhu, Chenglong Liu, Meng Wymond Wu, Zeke Xie, Zhong Ji, Jungong Han, Mingming Sun</author><pubDate>Sat, 03 Aug 2024 08:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01059v2</guid></item><item><title>Analysis of Argument Structure Constructions in a Deep Recurrent Language Model</title><link>http://arxiv.org/abs/2408.03062v1</link><description>Understanding how language and linguistic constructions are processed in thebrain is a fundamental question in cognitive computational neuroscience. Inthis study, we explore the representation and processing of Argument StructureConstructions (ASCs) in a recurrent neural language model. We trained a LongShort-Term Memory (LSTM) network on a custom-made dataset consisting of 2000sentences, generated using GPT-4, representing four distinct ASCs: transitive,ditransitive, caused-motion, and resultative constructions. We analyzed the internal activations of the LSTM model's hidden layers usingMultidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding(t-SNE) to visualize the sentence representations. The GeneralizedDiscrimination Value (GDV) was calculated to quantify the degree of clusteringwithin these representations. Our results show that sentence representationsform distinct clusters corresponding to the four ASCs across all hidden layers,with the most pronounced clustering observed in the last hidden layer beforethe output layer. This indicates that even a relatively simple,brain-constrained recurrent neural network can effectively differentiatebetween various construction types. These findings are consistent with previous studies demonstrating theemergence of word class and syntax rule representations in recurrent languagemodels trained on next word prediction tasks. In future work, we aim tovalidate these results using larger language models and compare them withneuroimaging data obtained during continuous speech perception. This studyhighlights the potential of recurrent neural language models to mirrorlinguistic processing in the human brain, providing valuable insights into thecomputational and neural mechanisms underlying language understanding.</description><author>Pegah Ramezani, Achim Schilling, Patrick Krauss</author><pubDate>Tue, 06 Aug 2024 09:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03062v1</guid></item><item><title>OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents</title><link>http://arxiv.org/abs/2408.03047v1</link><description>Multimodal conversational agents are highly desirable because they offernatural and human-like interaction. However, there is a lack of comprehensiveend-to-end solutions to support collaborative development and benchmarking.While proprietary systems like GPT-4o and Gemini demonstrating impressiveintegration of audio, video, and text with response times of 200-250ms,challenges remain in balancing latency, accuracy, cost, and data privacy. Tobetter understand and quantify these issues, we developed OpenOmni, anopen-source, end-to-end pipeline benchmarking tool that integrates advancedtechnologies such as Speech-to-Text, Emotion Detection, Retrieval AugmentedGeneration, Large Language Models, along with the ability to integratecustomized models. OpenOmni supports local and cloud deployment, ensuring dataprivacy and supporting latency and accuracy benchmarking. This flexibleframework allows researchers to customize the pipeline, focusing on realbottlenecks and facilitating rapid proof-of-concept development. OpenOmni cansignificantly enhance applications like indoor assistance for visually impairedindividuals, advancing human-computer interaction. Our demonstration video isavailable https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available viahttps://openomni.ai4wa.com, code is available viahttps://github.com/AI4WA/OpenOmniFramework.</description><author>Qiang Sun, Yuanyi Luo, Sirui Li, Wenxiao Zhang, Wei Liu</author><pubDate>Tue, 06 Aug 2024 09:02:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03047v1</guid></item><item><title>WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models</title><link>http://arxiv.org/abs/2408.03837v1</link><description>WalledEval is a comprehensive AI safety testing toolkit designed to evaluatelarge language models (LLMs). It accommodates a diverse range of models,including both open-weight and API-based ones, and features over 35 safetybenchmarks covering areas such as multilingual safety, exaggerated safety, andprompt injections. The framework supports both LLM and judge benchmarking, andincorporates custom mutators to test safety against various text-stylemutations such as future tense and paraphrasing. Additionally, WalledEvalintroduces WalledGuard, a new, small and performant content moderation tool,and SGXSTest, a benchmark for assessing exaggerated safety in culturalcontexts. We make WalledEval publicly available athttps://github.com/walledai/walledevalA.</description><author>Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria</author><pubDate>Wed, 07 Aug 2024 15:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03837v1</guid></item><item><title>Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.03533v1</link><description>We primarily focus on the field of large language models (LLMs) forrecommendation, which has been actively explored recently and poses asignificant challenge in effectively enhancing recommender systems with logicalreasoning abilities and open-world knowledge. Current mainstream efforts mainlycenter around injecting personalized information from recommendation modelsinto LLMs by customizing input templates or aligning representations betweensemantic and recommendation spaces at the prediction layer. However, they facethree significant limitations: (1) LoRA is mostly used as a core component inexisting works, but personalization is not well established in LoRA parametersas the LoRA matrix shared by every user may not cater to different users'characteristics, leading to suboptimal performance. (2) Although lifelongpersonalized behavior sequences are ideal for personalization, their use raiseseffectiveness and efficiency issues since LLMs require escalating training andinference time to extend text lengths. (3) Existing approaches aren't scalablefor large datasets due to training efficiency constraints. Thus, LLMs only seea small fraction of the datasets (e.g., less than 10%) instead of the wholedatasets, limiting their exposure to the full training space. To address theseproblems, we propose RecLoRA. This model incorporates a Personalized LoRAmodule that maintains independent LoRAs for different users and a Long-ShortModality Retriever that retrieves different history lengths for differentmodalities, significantly improving performance while adding minimal time cost.Furthermore, we design a Few2Many Learning Strategy, using a conventionalrecommendation model as a lens to magnify small training spaces to full spaces.Extensive experiments on public datasets demonstrate the efficacy of ourRecLoRA compared to existing baseline models.</description><author>Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang</author><pubDate>Wed, 07 Aug 2024 04:20:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03533v1</guid></item><item><title>RULER: What's the Real Context Size of Your Long-Context Language Models?</title><link>http://arxiv.org/abs/2404.06654v3</link><description>The needle-in-a-haystack (NIAH) test, which examines the ability to retrievea piece of information (the "needle") from long distractor texts (the"haystack"), has been widely adopted to evaluate long-context language models(LMs). However, this simple retrieval-based test is indicative of only asuperficial form of long-context understanding. To provide a more comprehensiveevaluation of long-context LMs, we create a new synthetic benchmark RULER withflexible configurations for customized sequence length and task complexity.RULER expands upon the vanilla NIAH test to encompass variations with diversetypes and quantities of needles. Moreover, RULER introduces new task categoriesmulti-hop tracing and aggregation to test behaviors beyond searching fromcontext. We evaluate 17 long-context LMs with 13 representative tasks in RULER.Despite achieving nearly perfect accuracy in the vanilla NIAH test, almost allmodels exhibit large performance drops as the context length increases. Whilethese models all claim context sizes of 32K tokens or greater, only half ofthem can maintain satisfactory performance at the length of 32K. Our analysisof Yi-34B, which supports context length of 200K, reveals large room forimprovement as we increase input length and task complexity. We open sourceRULER to spur comprehensive evaluation of long-context LMs.</description><author>Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, Boris Ginsburg</author><pubDate>Tue, 06 Aug 2024 21:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06654v3</guid></item><item><title>Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization</title><link>http://arxiv.org/abs/2408.04112v1</link><description>Large language models (LLMs) can help writers build story worlds bygenerating world elements, such as factions, characters, and locations.However, making sense of many generated elements can be overwhelming. Moreover,if the user wants to precisely control aspects of generated elements that aredifficult to specify verbally, prompting alone may be insufficient. Weintroduce Patchview, a customizable LLM-powered system that visually aidsworldbuilding by allowing users to interact with story concepts and elementsthrough the physical metaphor of magnets and dust. Elements in Patchview arevisually dragged closer to concepts with high relevance, facilitatingsensemaking. The user can also steer the generation with verbally elusiveconcepts by indicating the desired position of the element between concepts.When the user disagrees with the LLM's visualization and generation, they cancorrect those by repositioning the element. These corrections can be used toalign the LLM's future behaviors to the user's perception. With a user study,we show that Patchview supports the sensemaking of world elements and steeringof element generation, facilitating exploration during the worldbuildingprocess. Patchview provides insights on how customizable visual representationcan help sensemake, steer, and align generative AI model behaviors with theuser's intentions.</description><author>John Joon Young Chung, Max Kreminski</author><pubDate>Wed, 07 Aug 2024 22:27:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04112v1</guid></item><item><title>WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models</title><link>http://arxiv.org/abs/2408.03837v2</link><description>WalledEval is a comprehensive AI safety testing toolkit designed to evaluatelarge language models (LLMs). It accommodates a diverse range of models,including both open-weight and API-based ones, and features over 35 safetybenchmarks covering areas such as multilingual safety, exaggerated safety, andprompt injections. The framework supports both LLM and judge benchmarking, andincorporates custom mutators to test safety against various text-stylemutations such as future tense and paraphrasing. Additionally, WalledEvalintroduces WalledGuard, a new, small and performant content moderation tool,and SGXSTest, a benchmark for assessing exaggerated safety in culturalcontexts. We make WalledEval publicly available athttps://github.com/walledai/walledeval</description><author>Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria</author><pubDate>Thu, 08 Aug 2024 18:05:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03837v2</guid></item><item><title>TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning</title><link>http://arxiv.org/abs/2408.05200v1</link><description>Language model continual learning (CL) has recently garnered significantinterest due to its potential to adapt large language models (LLMs) to dynamicreal-world environments without re-training. A key challenge in this field iscatastrophic forgetting, where models lose previously acquired knowledge whenlearning new tasks. Existing methods commonly employ multipleparameter-efficient fine-tuning (PEFT) blocks to acquire task-specificknowledge for each task, but these approaches lack efficiency and overlook thepotential for knowledge transfer through task interaction. In this paper, wepresent a novel CL framework for language models called Task Skill Localizationand Consolidation (TaSL), which enhances knowledge transfer without relying onmemory replay. TaSL first divides the model into `skill units' based onparameter dependencies, enabling more granular control. It then employs a novelgroup-wise skill localization technique to identify the importance distributionof skill units for a new task. By comparing this importance distribution withthose from previous tasks, we implement a fine-grained skill consolidationstrategy that retains task-specific knowledge, thereby preventing forgetting,and updates task-shared knowledge, which facilitates bi-directional knowledgetransfer. As a result, TaSL achieves a superior balance between retainingprevious knowledge and excelling in new tasks. TaSL also shows stronggeneralizability, suitable for general models and customizable for PEFT methodslike LoRA. Additionally, it demonstrates notable extensibility, allowingintegration with memory replay to further enhance performance. Extensiveexperiments on two CL benchmarks, with varying model sizes (from 220M to 7B),demonstrate the effectiveness of TaSL and its variants across differentsettings.</description><author>Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu</author><pubDate>Fri, 09 Aug 2024 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05200v1</guid></item><item><title>Shifting the Lens: Detecting Malicious npm Packages using Large Language Models</title><link>http://arxiv.org/abs/2403.12196v2</link><description>Existing malicious code detection techniques can aid the manual reviewprocess by predicting which packages are likely to be malicious. However, thesetechniques often suffer from high misclassification rates. Therefore, maliciouscode detection techniques could be enhanced by adopting advanced, moreautomated approaches to achieve high accuracy and a low misclassification rate.The goal of this study is to assist security analysts in detecting maliciouspackages through the empirical study of using Large Language Models (LLMs) todetect malicious code in the npm ecosystem. We present SecurityAI, a maliciouscode review workflow to detect malicious code using ChatGPT. We leverage abenchmark dataset of 5,115 npm packages, of which 2,180 packages have maliciouscode. We conducted a baseline comparison of GPT-3 and GPT- 4 models with thestate-of-the-art CodeQL static analysis tool, using 39 custom CodeQL rulesdeveloped in prior research to detect malicious Javascript code. We compare theeffectiveness of static analysis as a pre-screener with SecurityAI workflow,measuring the number of files that need to be analyzed and the associatedcosts. Additionally, we performed a qualitative study to understand the typesof malicious packages detected or missed by our workflow. Our baselinecomparison demonstrates a 16% and 9% improvement over static analysis inprecision and F1 scores, respectively. We attained precision and F1 scores of91% and 94% for GPT-3, and 99% &amp; 97% for GPT-4, respectively, with GPT-3offering a cost-effective balance. Pre-screening files with a static analyzerreduces the number of files requiring LLM analysis by 77.9% and decreases costsby 60.9% for GPT-3 and 76.1% for GPT-4. Our qualitative analysis identifieddata theft, hidden backdoors, and suspicious domain connection categories asthe top detected malicious packages.</description><author>Nusrat Zahan, Philipp Burckhardt, Mikola Lysenko, Feross Aboukhadijeh, Laurie Williams</author><pubDate>Fri, 09 Aug 2024 16:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12196v2</guid></item><item><title>It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization</title><link>http://arxiv.org/abs/2407.00487v2</link><description>In this paper, we introduce a novel approach for large language model mergingvia black-box multi-objective optimization algorithms. The goal of modelmerging is to combine multiple models, each excelling in different tasks, intoa single model that outperforms any of the individual source models. However,model merging faces two significant challenges: First, existing methods relyheavily on human intuition and customized strategies to tackle multiple tasks.Second, it's difficult to search for the great model merging configuration inlimited evaluations. To address these challenges, we propose a multi-objectiveoptimization based model merging method named MM-MO. The proposed method canautomatically search merging configurations for multiple tasks withmulti-objective optimization algorithms. Moreover, to obtain high-quality modelmerging configurations within a limited number of evaluation iterations, wehave made several improvements to multi-objective Bayesian optimizationspecifically for model merging scenarios. First, we introduced a weak-to-strongmethod to improve the acquisition strategy. Second, we employed Fisherinformation to select configurations, further increasing the chances ofdiscovering superior model merging configurations. Third, we designed asparsity metric as an additional optimization objective to enhance the model'sgeneralization performance across different tasks. We conducted comprehensiveexperiments with other mainstream model merging methods, demonstrating that ourmethod consistently outperforms them. Moreover, performance improvements areobserved even on the tasks not explicitly targeted as optimization objectives,indicating that our method enhances the overall potential of the model. ...</description><author>Bingdong Li, Zixiang Di, Yanting Yang, Hong Qian, Peng Yang, Hao Hao, Ke Tang, Aimin Zhou</author><pubDate>Mon, 12 Aug 2024 14:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00487v2</guid></item><item><title>ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers</title><link>http://arxiv.org/abs/2408.06040v1</link><description>In the rapidly evolving fields of natural language processing and computervision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yetchallenging task. The quest for models that can seamlessly integrate andinterpret multimodal data is more pressing than ever. Imagine a system that canunderstand language with the depth and nuance of human cognition, whilesimultaneously interpreting the rich visual context of the world around it. We present ARPA, an architecture that fuses the unparalleled contextualunderstanding of large language models with the advanced feature extractioncapabilities of transformers, which then pass through a custom Graph NeuralNetwork (GNN) layer to learn intricate relationships and subtle nuances withinthe data. This innovative architecture not only sets a new benchmark in visualword disambiguation but also introduces a versatile framework poised totransform how linguistic and visual data interact by harnessing the synergisticstrengths of its components, ensuring robust performance even in the mostcomplex disambiguation scenarios. Through a series of experiments andcomparative analysis, we reveal the substantial advantages of our model,underscoring its potential to redefine standards in the field. Beyond itsarchitectural prowess, our architecture excels through experimentalenrichments, including sophisticated data augmentation and multi-modal trainingtechniques. ARPA's introduction marks a significant milestone in visual worddisambiguation, offering a compelling solution that bridges the gap betweenlinguistic and visual modalities. We invite researchers and practitioners toexplore the capabilities of our model, envisioning a future where such hybridmodels drive unprecedented advancements in artificial intelligence.</description><author>Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou</author><pubDate>Mon, 12 Aug 2024 10:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06040v1</guid></item><item><title>Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models</title><link>http://arxiv.org/abs/2408.05933v1</link><description>With the growing demand for offline PDF chatbots in automotive industrialproduction environments, optimizing the deployment of large language models(LLMs) in local, low-performance settings has become increasingly important.This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniquesfor processing complex automotive industry documents using locally deployedOllama models. Based on the Langchain framework, we propose a multi-dimensionaloptimization approach for Ollama's local RAG implementation. Our methodaddresses key challenges in automotive document processing, includingmulti-column layouts and technical specifications. We introduce improvements inPDF processing, retrieval mechanisms, and context compression, tailored to theunique characteristics of automotive industry documents. Additionally, wedesign custom classes supporting embedding pipelines and an agent supportingself-RAG based on LangGraph best practices. To evaluate our approach, weconstructed a proprietary dataset comprising typical automotive industrydocuments, including technical reports and corporate regulations. We comparedour optimized RAG model and self-RAG agent against a naive RAG baseline acrossthree datasets: our automotive industry dataset, QReCC, and CoQA. Resultsdemonstrate significant improvements in context precision, context recall,answer relevancy, and faithfulness, with particularly notable performance onthe automotive industry dataset. Our optimization scheme provides an effectivesolution for deploying local RAG systems in the automotive sector, addressingthe specific needs of PDF chatbots in industrial production environments. Thisresearch has important implications for advancing information processing andintelligent production in the automotive industry.</description><author>Fei Liu, Zejun Kang, Xing Han</author><pubDate>Mon, 12 Aug 2024 06:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05933v1</guid></item><item><title>A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning</title><link>http://arxiv.org/abs/2408.05911v1</link><description>With the rapid development of large language models in recent years, therehas been an increasing demand for domain-specific Agents that can cater to theunique needs of enterprises and organizations. Unlike general models, whichstrive for broad coverage, these specialized Agents rely on focused datasetstailored to their intended applications. This research proposes a pipeline thatleverages the power of LLMs and the Retrieval-Augmented Generation relatedframework to construct high-quality instruction datasets for fine-tuning onspecific domains using custom document collections. By ingestingdomain-specific documents, the pipeline generates relevant and contextuallyappropriate instructions, thus effectively creating a comprehensive dataset forfine-tuning LLMs on the target domain. This approach overcomes the limitationsof traditional dataset creation methods, which often rely on manual curation orweb-scraping techniques that may introduce noise and irrelevant data. Notably,our pipeline offers a dynamic solution that can quickly adapt to updates ormodifications in the domain-specific document collection, eliminating the needfor complete retraining. Additionally, it addresses the challenge of datascarcity by enabling the generation of instruction datasets from a limited setof initial documents, rendering it suitable for unpopular or specializeddomains where comprehensive datasets are scarce. As a case study, we apply thisapproach to the domain of psychiatry, a field requiring specialized knowledgeand sensitive handling of patient information. The resulting fine-tuned LLMdemonstrates showcases the viability of the proposed approach and underscoresits potential for widespread adoption across various industries and domainswhere tailored, accurate, and contextually relevant language models areindispensable.</description><author>Chih-Wei Song, Yu-Kai Lee, Yin-Te Tsai</author><pubDate>Mon, 12 Aug 2024 03:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05911v1</guid></item><item><title>Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.03533v2</link><description>We primarily focus on the field of large language models (LLMs) forrecommendation, which has been actively explored recently and poses asignificant challenge in effectively enhancing recommender systems with logicalreasoning abilities and open-world knowledge. Current mainstream efforts mainlycenter around injecting personalized information from recommendation modelsinto LLMs by customizing input templates or aligning representations betweensemantic and recommendation spaces at the prediction layer. However, they facethree significant limitations: (1) LoRA is mostly used as a core component inexisting works, but personalization is not well established in LoRA parametersas the LoRA matrix shared by every user may not cater to different users'characteristics, leading to suboptimal performance. (2) Although lifelongpersonalized behavior sequences are ideal for personalization, their use raiseseffectiveness and efficiency issues since LLMs require escalating training andinference time to extend text lengths. (3) Existing approaches aren't scalablefor large datasets due to training efficiency constraints. Thus, LLMs only seea small fraction of the datasets (e.g., less than 10%) instead of the wholedatasets, limiting their exposure to the full training space. To address theseproblems, we propose RecLoRA. This model incorporates a Personalized LoRAmodule that maintains independent LoRAs for different users and a Long-ShortModality Retriever that retrieves different history lengths for differentmodalities, significantly improving performance while adding minimal time cost.Furthermore, we design a Few2Many Learning Strategy, using a conventionalrecommendation model as a lens to magnify small training spaces to full spaces.Extensive experiments on public datasets demonstrate the efficacy of ourRecLoRA compared to existing baseline models.</description><author>Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang</author><pubDate>Sun, 11 Aug 2024 09:08:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03533v2</guid></item><item><title>SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</title><link>http://arxiv.org/abs/2408.05517v1</link><description>Recent development in Large Language Models (LLMs) and Multi-modal LargeLanguage Models (MLLMs) have leverage Attention-based Transformer architecturesand achieved superior performance and generalization capabilities. They havesince covered extensive areas of traditional learning tasks. For instance,text-based tasks such as text-classification and sequence-labeling, as well asmulti-modal tasks like Visual Question Answering (VQA) and Optical CharacterRecognition (OCR), which were previously addressed using different models, cannow be tackled based on one foundation model. Consequently, the training andlightweight fine-tuning of LLMs and MLLMs, especially those based onTransformer architecture, has become particularly important. In recognition ofthese overwhelming needs, we develop SWIFT, a customizable one-stopinfrastructure for large models. With support of over $300+$ LLMs and $50+$MLLMs, SWIFT stands as the open-source framework that provide the \textit{mostcomprehensive support} for fine-tuning large models. In particular, it is thefirst training framework that provides systematic support for MLLMs. Inaddition to the core functionalities of fine-tuning, SWIFT also integratespost-training processes such as inference, evaluation, and model quantization,to facilitate fast adoptions of large models in various application scenarios.With a systematic integration of various training techniques, SWIFT offershelpful utilities such as benchmark comparisons among different trainingtechniques for large models. For fine-tuning models specialized in agentframework, we show that notable improvements on the ToolBench leader-board canbe achieved by training with customized dataset on SWIFT, with an increase of5.2\%-21.8\% in the Act.EM metric over various baseline models, a reduction inhallucination by 1.6\%-14.1\%, and an average performance improvement of8\%-17\%.</description><author>Yuze Zhao, Jintao Huang, Jinghan Hu, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</author><pubDate>Sat, 10 Aug 2024 11:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05517v1</guid></item><item><title>SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</title><link>http://arxiv.org/abs/2408.05517v2</link><description>Recent development in Large Language Models (LLMs) and Multi-modal LargeLanguage Models (MLLMs) have leverage Attention-based Transformer architecturesand achieved superior performance and generalization capabilities. They havesince covered extensive areas of traditional learning tasks. For instance,text-based tasks such as text-classification and sequence-labeling, as well asmulti-modal tasks like Visual Question Answering (VQA) and Optical CharacterRecognition (OCR), which were previously addressed using different models, cannow be tackled based on one foundation model. Consequently, the training andlightweight fine-tuning of LLMs and MLLMs, especially those based onTransformer architecture, has become particularly important. In recognition ofthese overwhelming needs, we develop SWIFT, a customizable one-stopinfrastructure for large models. With support of over $300+$ LLMs and $50+$MLLMs, SWIFT stands as the open-source framework that provide the \textit{mostcomprehensive support} for fine-tuning large models. In particular, it is thefirst training framework that provides systematic support for MLLMs. Inaddition to the core functionalities of fine-tuning, SWIFT also integratespost-training processes such as inference, evaluation, and model quantization,to facilitate fast adoptions of large models in various application scenarios.With a systematic integration of various training techniques, SWIFT offershelpful utilities such as benchmark comparisons among different trainingtechniques for large models. For fine-tuning models specialized in agentframework, we show that notable improvements on the ToolBench leader-board canbe achieved by training with customized dataset on SWIFT, with an increase of5.2%-21.8% in the Act.EM metric over various baseline models, a reduction inhallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.</description><author>Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</author><pubDate>Tue, 13 Aug 2024 09:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05517v2</guid></item><item><title>Efficient Search for Customized Activation Functions with Gradient Descent</title><link>http://arxiv.org/abs/2408.06820v1</link><description>Different activation functions work best for different deep learning models.To exploit this, we leverage recent advancements in gradient-based searchtechniques for neural architectures to efficiently identify high-performingactivation functions for a given application. We propose a fine-grained searchcell that combines basic mathematical operations to model activation functions,allowing for the exploration of novel activations. Our approach enables theidentification of specialized activations, leading to improved performance inevery model we tried, from image classification to language models. Moreover,the identified activations exhibit strong transferability to larger models ofthe same type, as well as new datasets. Importantly, our automated process forcreating customized activation functions is orders of magnitude more efficientthan previous approaches. It can easily be applied on top of arbitrary deeplearning pipelines and thus offers a promising practical avenue for enhancingdeep learning architectures.</description><author>Lukas Strack, Mahmoud Safari, Frank Hutter</author><pubDate>Tue, 13 Aug 2024 11:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06820v1</guid></item><item><title>Seeing and Understanding: Bridging Vision with Chemical Knowledge Via ChemVLM</title><link>http://arxiv.org/abs/2408.07246v1</link><description>In this technical report, we propose ChemVLM, the first open-sourcemultimodal large language model dedicated to the fields of chemistry, designedto address the incompatibility between chemical image understanding and textanalysis. Built upon the VIT-MLP-LLM architecture, we leverage ChemLLM-20B asthe foundational large model, endowing our model with robust capabilities inunderstanding and utilizing chemical text knowledge. Additionally, we employInternVIT-6B as a powerful image encoder. We have curated high-quality datafrom the chemical domain, including molecules, reaction formulas, and chemistryexamination data, and compiled these into a bilingual multimodalquestion-answering dataset. We test the performance of our model on multipleopen-source benchmarks and three custom evaluation sets. Experimental resultsdemonstrate that our model achieves excellent performance, securingstate-of-the-art results in five out of six involved tasks. Our model can befound at https://huggingface.co/AI4Chem/ChemVLM-26B.</description><author>Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Weiyun Wang, Zhe Chen, Wenhai Wang, Wei Li, Shufei Zhang, Mao Su, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou</author><pubDate>Wed, 14 Aug 2024 01:16:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07246v1</guid></item><item><title>Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach</title><link>http://arxiv.org/abs/2408.07238v1</link><description>Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superiorperformance in complex human-like interactions. But they are costly, or toolarge for edge devices such as smartphones and harder to self-host, leading tosecurity and privacy concerns. This paper introduces a novel interpretableknowledge distillation approach to enhance the performance of smaller, moreeconomical LLMs that firms can self-host. We study this problem in the contextof building a customer service agent aimed at achieving high customersatisfaction through goal-oriented dialogues. Unlike traditional knowledgedistillation, where the "student" model learns directly from the "teacher"model's responses via fine-tuning, our interpretable "strategy" teachingapproach involves the teacher providing strategies to improve the student'sperformance in various scenarios. This method alternates between a "scenariogeneration" step and a "strategies for improvement" step, creating a customizedlibrary of scenarios and optimized strategies for automated prompting. Themethod requires only black-box access to both student and teacher models; henceit can be used without manipulating model parameters. In our customer serviceapplication, the method improves performance, and the learned strategies aretransferable to other LLMs and scenarios beyond the training set. The method'sinterpretabilty helps safeguard against potential harms through human audit.</description><author>Tong Wang, K. Sudhir, Dat Hong</author><pubDate>Tue, 13 Aug 2024 23:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07238v1</guid></item><item><title>EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics</title><link>http://arxiv.org/abs/2408.08782v1</link><description>Designing emotionally intelligent conversational systems to provide comfortand advice to people experiencing distress is a compelling area of research.Previous efforts have focused on developing modular dialogue systems that treatsocio-emotional strategy prediction as an auxiliary task and generatestrategy-conditioned responses with customized decoders. Recently, withadvancements in large language models (LLMs), end-to-end dialogue agentswithout explicit socio-emotional strategy prediction steps have becomeprevalent. However, despite their excellence in language generation, recentstudies show that LLMs' inherent preference bias towards certainsocio-emotional strategies hinders the delivery of high-quality emotionalsupport. To address this challenge, we propose decoupling strategy predictionfrom language generation, and introduce a novel dialogue strategy predictor,EmoDynamiX, which models the discourse dynamics between user emotions andsystem strategies using a heterogeneous graph. Additionally, we make use of theEmotion Recognition in Conversations (ERC) task and design a flexiblemixed-emotion module to capture fine-grained emotional states of the user.Experimental results on two ESC datasets show EmoDynamiX outperforms previousstate-of-the-art methods with a significant margin.</description><author>Chenwei Wan, Matthieu Labeau, Chloé Clavel</author><pubDate>Fri, 16 Aug 2024 14:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08782v1</guid></item><item><title>Crafting Customisable Characters with LLMs: Introducing SimsChat, a Persona-Driven Role-Playing Agent Framework</title><link>http://arxiv.org/abs/2406.17962v3</link><description>Large Language Models (LLMs) demonstrate a remarkable ability to comprehendhuman instructions and generate high-quality text. This capability allows LLMsto function as agents that can emulate human beings at a more sophisticatedlevel, beyond the mere replication of basic human behaviours. However, there isa lack of exploring into leveraging LLMs to craft characters from diverseaspects. In this work, we introduce the Customisable Conversation AgentFramework, which leverages LLMs to simulate real-world characters that can befreely customised according to various user preferences. This adaptableframework is beneficial for the design of customisable characters androle-playing agents aligned with human preferences. We propose the SimsConvdataset, which encompasses 68 different customised characters, 1,360 multi-turnrole-playing dialogues, and a total of 13,971 interaction dialogues. Thecharacters are created from several real-world elements, such as career,aspiration, trait, and skill. Building upon these foundations, we presentSimsChat, a freely customisable role-playing agent. It incorporates diversereal-world scenes and topic-specific character interaction dialogues, therebysimulating characters' life experiences in various scenarios and topic-specificinteractions with specific emotions. Experimental results indicate that ourproposed framework achieves desirable performance and provides a valuableguideline for the construction of more accurate human simulacra in the future.Our data and code are publicly available athttps://github.com/Bernard-Yang/SimsChat.</description><author>Bohao Yang, Dong Liu, Chen Tang, Chenghao Xiao, Kun Zhao, Chao Li, Lin Yuan, Guang Yang, Lanxiao Huang, Chenghua Lin</author><pubDate>Fri, 16 Aug 2024 08:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17962v3</guid></item><item><title>Plan with Code: Comparing approaches for robust NL to DSL generation</title><link>http://arxiv.org/abs/2408.08335v1</link><description>Planning in code is considered a more reliable approach for manyorchestration tasks. This is because code is more tractable than stepsgenerated via Natural Language and make it easy to support more complexsequences by abstracting deterministic logic into functions. It also allowsspotting issues with incorrect function names with the help of parsing checksthat can be run on code. Progress in Code Generation methodologies, however,remains limited to general-purpose languages like C, C++, and Python. LLMscontinue to face challenges with custom function names in Domain SpecificLanguages or DSLs, leading to higher hallucination rates and syntax errors.This is more common for custom function names, that are typically part of theplan. Moreover, keeping LLMs up-to-date with newer function names is an issue.This poses a challenge for scenarios like task planning over a large number ofAPIs, since the plan is represented as a DSL having custom API names. In thispaper, we focus on workflow automation in RPA (Robotic Process Automation)domain as a special case of task planning. We present optimizations for usingRetrieval Augmented Generation (or RAG) with LLMs for DSL generation along withan ablation study comparing these strategies with a fine-tuned model. Ourresults showed that the fine-tuned model scored the best on code similaritymetric. However, with our optimizations, RAG approach is able to match thequality for in-domain API names in the test set. Additionally, it offerssignificant advantage for out-of-domain or unseen API names, outperformingFine-Tuned model on similarity metric by 7 pts.</description><author>Nastaran Bassamzadeh, Chhaya Methani</author><pubDate>Thu, 15 Aug 2024 04:29:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08335v1</guid></item><item><title>Customizing Language Models with Instance-wise LoRA for Sequential Recommendation</title><link>http://arxiv.org/abs/2408.10159v1</link><description>Sequential recommendation systems predict a user's next item of interest byanalyzing past interactions, aligning recommendations with individualpreferences. Leveraging the strengths of Large Language Models (LLMs) inknowledge comprehension and reasoning, recent approaches have applied LLMs tosequential recommendation through language generation paradigms. These methodsconvert user behavior sequences into prompts for LLM fine-tuning, utilizingLow-Rank Adaptation (LoRA) modules to refine recommendations. However, theuniform application of LoRA across diverse user behaviors sometimes fails tocapture individual variability, leading to suboptimal performance and negativetransfer between disparate sequences. To address these challenges, we proposeInstance-wise LoRA (iLoRA), integrating LoRA with the Mixture of Experts (MoE)framework. iLoRA creates a diverse array of experts, each capturing specificaspects of user preferences, and introduces a sequence representation guidedgate function. This gate function processes historical interaction sequences togenerate enriched representations, guiding the gating network to outputcustomized expert participation weights. This tailored approach mitigatesnegative transfer and dynamically adjusts to diverse behavior patterns.Extensive experiments on three benchmark datasets demonstrate the effectivenessof iLoRA, highlighting its superior performance compared to existing methods incapturing user-specific preferences and improving recommendation accuracy.</description><author>Xiaoyu Kong, Jiancan Wu, An Zhang, Leheng Sheng, Hui Lin, Xiang Wang, Xiangnan He</author><pubDate>Mon, 19 Aug 2024 17:09:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10159v1</guid></item><item><title>Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research</title><link>http://arxiv.org/abs/2408.11043v1</link><description>Qualitative data collection and analysis approaches, such as those employinginterviews and focus groups, provide rich insights into customer attitudes,sentiment, and behavior. However, manually analyzing qualitative data requiresextensive time and effort to identify relevant topics and thematic insights.This study proposes a novel approach to address this challenge by leveragingRetrieval Augmented Generation (RAG) based Large Language Models (LLMs) foranalyzing interview transcripts. The novelty of this work lies in strategizingthe research inquiry as one that is augmented by an LLM that serves as a noviceresearch assistant. This research explores the mental model of LLMs to serve asnovice qualitative research assistants for researchers in the talent managementspace. A RAG-based LLM approach is extended to enable topic modeling ofsemi-structured interview data, showcasing the versatility of these modelsbeyond their traditional use in information retrieval and search. Our findingsdemonstrate that the LLM-augmented RAG approach can successfully extract topicsof interest, with significant coverage compared to manually generated topicsfrom the same dataset. This establishes the viability of employing LLMs asnovice qualitative research assistants. Additionally, the study recommends thatresearchers leveraging such models lean heavily on quality criteria used intraditional qualitative research to ensure rigor and trustworthiness of theirapproach. Finally, the paper presents key recommendations for industrypractitioners seeking to reconcile the use of LLMs with established qualitativeresearch paradigms, providing a roadmap for the effective integration of thesepowerful, albeit novice, AI tools in the analysis of qualitative datasetswithin talent</description><author>Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Anshul Mittal, Rutu Mulkar</author><pubDate>Tue, 20 Aug 2024 17:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11043v1</guid></item><item><title>Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks</title><link>http://arxiv.org/abs/2310.10830v2</link><description>It is commonly perceived that fake news and real news exhibit distinctwriting styles, such as the use of sensationalist versus objective language.However, we emphasize that style-related features can also be exploited forstyle-based attacks. Notably, the advent of powerful Large Language Models(LLMs) has empowered malicious actors to mimic the style of trustworthy newssources, doing so swiftly, cost-effectively, and at scale. Our analysis revealsthat LLM-camouflaged fake news content significantly undermines theeffectiveness of state-of-the-art text-based detectors (up to 38% decrease inF1 Score), implying a severe vulnerability to stylistic variations. To addressthis, we introduce SheepDog, a style-robust fake news detector that prioritizescontent over style in determining news veracity. SheepDog achieves thisresilience through (1) LLM-empowered news reframings that inject stylediversity into the training process by customizing articles to match differentstyles; (2) a style-agnostic training scheme that ensures consistent veracitypredictions across style-diverse reframings; and (3) content-focused veracityattributions that distill content-centric guidelines from LLMs for debunkingfake news, offering supplementary cues and potential intepretability thatassist veracity prediction. Extensive experiments on three real-worldbenchmarks demonstrate SheepDog's style robustness and adaptability to variousbackbones.</description><author>Jiaying Wu, Jiafeng Guo, Bryan Hooi</author><pubDate>Tue, 20 Aug 2024 17:28:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10830v2</guid></item><item><title>SysBench: Can Large Language Models Follow System Messages?</title><link>http://arxiv.org/abs/2408.10943v1</link><description>Large Language Models (LLMs) have become instrumental across variousapplications, with the customization of these models to specific scenariosbecoming increasingly critical. System message, a fundamental component ofLLMs, is consist of carefully crafted instructions that guide the behavior ofmodel to meet intended goals. Despite the recognized potential of systemmessages to optimize AI-driven solutions, there is a notable absence of acomprehensive benchmark for evaluating how well different LLMs follow thesesystem messages. To fill this gap, we introduce SysBench, a benchmark thatsystematically analyzes system message following ability in terms of threechallenging aspects: constraint complexity, instruction misalignment andmulti-turn stability. In order to enable effective evaluation, SysBenchconstructs multi-turn user conversations covering various interactionrelationships, based on six common types of constraints from system messages inreal-world scenarios. Our dataset contains 500 system messages from variousdomains, each paired with 5 turns of user conversations, which have beenmanually formulated and checked to guarantee high quality. SysBench providesextensive evaluation across various LLMs, measuring their ability to followspecified constraints given in system messages. The results highlight both thestrengths and weaknesses of existing models, offering key insights anddirections for future research. The open source library SysBench is availableat https://github.com/PKU-Baichuan-MLSystemLab/SysBench.</description><author>Yanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui</author><pubDate>Tue, 20 Aug 2024 15:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10943v1</guid></item><item><title>MEGen: Generative Backdoor in Large Language Models via Model Editing</title><link>http://arxiv.org/abs/2408.10722v1</link><description>Large language models (LLMs) have demonstrated remarkable capabilities. Theirpowerful generative abilities enable flexible responses based on variousqueries or instructions. Emerging as widely adopted generalists for diversetasks, LLMs are still vulnerable to backdoors. This paper proposes anediting-based generative backdoor, named MEGen, aiming to create a customizedbackdoor for NLP tasks with the least side effects. In our approach, we firstleverage a language model to insert a trigger selected on fixed metrics intothe input, then design a pipeline of model editing to directly embed a backdoorinto an LLM. By adjusting a small set of local parameters with a mini-batch ofsamples, MEGen significantly enhances time efficiency and achieves highrobustness. Experimental results indicate that our backdoor attack strategyachieves a high attack success rate on poison data while maintaining themodel's performance on clean data. Notably, the backdoored model, whentriggered, can freely output pre-set dangerous information while successfullycompleting downstream tasks. This suggests that future LLM applications couldbe guided to deliver certain dangerous information, thus altering the LLM'sgenerative style. We believe this approach provides insights for future LLMapplications and the execution of backdoor attacks on conversational AIsystems.</description><author>Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao</author><pubDate>Tue, 20 Aug 2024 10:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10722v1</guid></item><item><title>Image Score: Learning and Evaluating Human Preferences for Mercari Search</title><link>http://arxiv.org/abs/2408.11349v1</link><description>Mercari is the largest C2C e-commerce marketplace in Japan, having more than20 million active monthly users. Search being the fundamental way to discoverdesired items, we have always had a substantial amount of data with implicitfeedback. Although we actively take advantage of that to provide the bestservice for our users, the correlation of implicit feedback for such tasks asimage quality assessment is not trivial. Many traditional lines of research inMachine Learning (ML) are similarly motivated by the insatiable appetite ofDeep Learning (DL) models for well-labelled training data. Weak supervision isabout leveraging higher-level and/or noisier supervision over unlabeled data.Large Language Models (LLMs) are being actively studied and used for datalabelling tasks. We present how we leverage a Chain-of-Thought (CoT) to enableLLM to produce image aesthetics labels that correlate well with human behaviorin e-commerce settings. Leveraging LLMs is more cost-effective compared toexplicit human judgment, while significantly improving the explainability ofdeep image quality evaluation which is highly important for customer journeyoptimization at Mercari. We propose a cost-efficient LLM-driven approach forassessing and predicting image quality in e-commerce settings, which is veryconvenient for proof-of-concept testing. We show that our LLM-produced labelscorrelate with user behavior on Mercari. Finally, we show our results from anonline experimentation, where we achieved a significant growth in sales on theweb platform.</description><author>Chingis Oinar, Miao Cao, Shanshan Fu</author><pubDate>Wed, 21 Aug 2024 05:30:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11349v1</guid></item><item><title>Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement</title><link>http://arxiv.org/abs/2402.11060v2</link><description>The increasing demand for personalized interactions with large languagemodels (LLMs) calls for methodologies capable of accurately and efficientlyidentifying user opinions and preferences. Retrieval augmentation emerges as aneffective strategy, as it can accommodate a vast number of users without thecosts from fine-tuning. Existing research, however, has largely focused onenhancing the retrieval stage and devoted limited exploration toward optimizingthe representation of the database, a crucial aspect for tasks such aspersonalization. In this work, we examine the problem from a novel angle,focusing on how data can be better represented for more data-efficientretrieval in the context of LLM customization. To tackle this challenge, weintroduce Persona-DB, a simple yet effective framework consisting of ahierarchical construction process to improve generalization across taskcontexts and collaborative refinement to effectively bridge knowledge gapsamong users. In the evaluation of response prediction, Persona-DB demonstratessuperior context efficiency in maintaining accuracy with a significantlyreduced retrieval size, a critical advantage in scenarios with extensivehistories or limited context windows. Our experiments also indicate a markedimprovement of over 10% under cold-start scenarios, when users have extremelysparse data. Furthermore, our analysis reveals the increasing importance ofcollaborative knowledge as the retrieval capacity expands.</description><author>Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi R. Fung, Hou Pong Chan, Kevin Small, ChengXiang Zhai, Heng Ji</author><pubDate>Wed, 21 Aug 2024 00:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11060v2</guid></item><item><title>RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering</title><link>http://arxiv.org/abs/2408.12369v1</link><description>With advancements in Large Language Models (LLMs), a major use case that hasemerged is querying databases in plain English, translating user questions intoexecutable database queries, which has improved significantly. However,real-world datasets often feature a vast array of attributes and complexvalues, complicating the LLMs task of accurately identifying relevant columnsor values from natural language queries. Traditional methods cannot fully relaythe datasets size and complexity to the LLM. To address these challenges, wepropose a novel framework that leverages Full-Text Search (FTS) on the inputtable. This approach not only enables precise detection of specific values andcolumns but also narrows the search space for language models, therebyenhancing query accuracy. Additionally, it supports a custom auto-completefeature that suggests queries based on the data in the table. This integrationsignificantly refines the interaction between the user and complex datasets,offering a sophisticated solution to the limitations faced by current tablequerying capabilities. This work is accompanied by an application for both Macand Windows platforms, which readers can try out themselves on their own data.</description><author>Pratyush Kumar, Kuber Vijaykumar Bellad, Bharat Vadlamudi, Aman Chadha</author><pubDate>Thu, 22 Aug 2024 13:13:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12369v1</guid></item><item><title>Search-Adaptor: Embedding Customization for Information Retrieval</title><link>http://arxiv.org/abs/2310.08750v3</link><description>Embeddings extracted by pre-trained Large Language Models (LLMs) havesignificant potential to improve information retrieval and search. Beyond thezero-shot setup in which they are being conventionally used, being able to takeadvantage of the information from the relevant query-corpus paired data canfurther boost the LLM capabilities. In this paper, we propose a novel method,Search-Adaptor, for customizing LLMs for information retrieval in an efficientand robust way. Search-Adaptor modifies the embeddings generated by pre-trainedLLMs, and can be integrated with any LLM, including those only available viaprediction APIs. On multiple English, multilingual, and multimodal retrievaldatasets, we show consistent and significant performance benefits forSearch-Adaptor -- e.g., more than 5% improvements for Google Embedding APIs innDCG@10 averaged over 14 BEIR datasets.</description><author>Jinsung Yoon, Sercan O Arik, Yanfei Chen, Tomas Pfister</author><pubDate>Fri, 23 Aug 2024 17:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08750v3</guid></item><item><title>Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption</title><link>http://arxiv.org/abs/2408.13248v1</link><description>Semiconductor imaging and analysis are critical yet understudied in deeplearning, limiting our ability for precise control and optimization insemiconductor manufacturing. We introduce a small-scale multimodal frameworkfor analyzing semiconductor electron microscopy images (MAEMI) throughvision-language instruction tuning. We generate a customizedinstruction-following dataset using large multimodal models on microscopicimage analysis. We perform knowledge transfer from larger to smaller modelsthrough knowledge distillation, resulting in improved accuracy of smallermodels on visual question answering (VQA) tasks. This approach eliminates theneed for expensive, human expert-annotated datasets for microscopic imageanalysis tasks. Enterprises can further finetune MAEMI on their intellectualdata, enhancing privacy and performance on low-cost consumer hardware. Ourexperiments show that MAEMI outperforms traditional methods, adapts to datadistribution shifts, and supports high-throughput screening.</description><author>Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Fri, 23 Aug 2024 17:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13248v1</guid></item><item><title>RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering</title><link>http://arxiv.org/abs/2408.12369v2</link><description>With advancements in Large Language Models (LLMs), a major use case that hasemerged is querying databases in plain English, translating user questions intoexecutable database queries, which has improved significantly. However,real-world datasets often feature a vast array of attributes and complexvalues, complicating the LLMs task of accurately identifying relevant columnsor values from natural language queries. Traditional methods cannot fully relaythe datasets size and complexity to the LLM. To address these challenges, wepropose a novel framework that leverages Full-Text Search (FTS) on the inputtable. This approach not only enables precise detection of specific values andcolumns but also narrows the search space for language models, therebyenhancing query accuracy. Additionally, it supports a custom auto-completefeature that suggests queries based on the data in the table. This integrationsignificantly refines the interaction between the user and complex datasets,offering a sophisticated solution to the limitations faced by current tablequerying capabilities. This work is accompanied by an application for both Macand Windows platforms, which readers can try out themselves on their own data.</description><author>Pratyush Kumar, Kuber Vijaykumar Bellad, Bharat Vadlamudi, Aman Chadha</author><pubDate>Fri, 23 Aug 2024 08:11:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12369v2</guid></item><item><title>Tuning Language Models by Proxy</title><link>http://arxiv.org/abs/2401.08565v4</link><description>Despite the general capabilities of large pretrained language models, theyconsistently benefit from further adaptation to better achieve desiredbehaviors. However, tuning these models has become increasinglyresource-intensive, or impossible when model weights are private. We introduceproxy-tuning, a lightweight decoding-time algorithm that operates on top ofblack-box LMs to achieve the same end as direct tuning, but by accessing onlyits predictions over the output vocabulary, not its parameters. Our methodtunes a smaller LM, then applies the difference between the predictions of thesmall tuned and untuned LMs to shift the original predictions of the largeruntuned model in the direction of tuning, while retaining the benefits oflarger-scale pretraining. In experiments, when we apply proxy-tuning toLlama2-70B using proxies of only 7B size, we can close 88% of the gap betweenLlama2-70B and its truly-tuned chat version, when evaluated across knowledge,reasoning, and safety benchmarks. We then demonstrate the generality ofproxy-tuning by applying it to domain adaptation on code, and task-specificfinetuning on question-answering and math problems. Finally, we show how toproxy-tune a truly black-box LM, GPT-3.5, for temporal adaptation, increasingits knowledge about recent events. Our work demonstrates the promise of usingsmall tuned LMs to efficiently customize large, potentially proprietary LMsthrough decoding-time guidance.</description><author>Alisa Liu, Xiaochuang Han, Yizhong Wang, Yulia Tsvetkov, Yejin Choi, Noah A. Smith</author><pubDate>Fri, 23 Aug 2024 05:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08565v4</guid></item><item><title>AppAgent v2: Advanced Agent for Flexible Mobile Interactions</title><link>http://arxiv.org/abs/2408.11824v2</link><description>With the advancement of Multimodal Large Language Models (MLLM), LLM-drivenvisual agents are increasingly impacting software interfaces, particularlythose with graphical user interfaces. This work introduces a novel LLM-basedmultimodal agent framework for mobile devices. This framework, capable ofnavigating mobile devices, emulates human-like interactions. Our agentconstructs a flexible action space that enhances adaptability across variousapplications including parser, text and vision descriptions. The agent operatesthrough two main phases: exploration and deployment. During the explorationphase, functionalities of user interface elements are documented either throughagent-driven or manual explorations into a customized structured knowledgebase. In the deployment phase, RAG technology enables efficient retrieval andupdate from this knowledge base, thereby empowering the agent to perform taskseffectively and accurately. This includes performing complex, multi-stepoperations across various applications, thereby demonstrating the framework'sadaptability and precision in handling customized task workflows. Ourexperimental results across various benchmarks demonstrate the framework'ssuperior performance, confirming its effectiveness in real-world scenarios. Ourcode will be open source soon.</description><author>Yanda Li, Chi Zhang, Wanqi Yang, Bin Fu, Pei Cheng, Xin Chen, Ling Chen, Yunchao Wei</author><pubDate>Fri, 23 Aug 2024 04:13:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11824v2</guid></item><item><title>UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models</title><link>http://arxiv.org/abs/2406.18966v3</link><description>Large Language Models (LLMs) such as GPT-4 and Llama3 have significantlyimpacted various fields by enabling high-quality synthetic data generation andreducing dependence on expensive human-generated datasets. Despite this,challenges remain in the areas of generalization, controllability, diversity,and truthfulness within the existing generative frameworks. To address thesechallenges, this paper presents UniGen, a comprehensive LLM-powered frameworkdesigned to produce diverse, accurate, and highly controllable datasets. UniGenis adaptable, supporting all types of text datasets and enhancing thegenerative process through innovative mechanisms. To augment data diversity,UniGen incorporates an attribute-guided generation module and a group checkingfeature. For accuracy, it employs a code-based mathematical assessment forlabel verification alongside a retrieval-augmented generation technique forfactual validation. The framework also allows for user-specified constraints,enabling customization of the data generation process to suit particularrequirements. Extensive experiments demonstrate the superior quality of datagenerated by UniGen, and each module within UniGen plays a critical role inthis enhancement. Additionally, UniGen is applied in two practical scenarios:benchmarking LLMs and data augmentation. The results indicate that UniGeneffectively supports dynamic and evolving benchmarking, and that dataaugmentation improves LLM capabilities in various domains, includingagent-oriented abilities and reasoning skills.</description><author>Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun</author><pubDate>Fri, 23 Aug 2024 00:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18966v3</guid></item><item><title>Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning</title><link>http://arxiv.org/abs/2408.14387v1</link><description>Spatio-temporal forecasting plays a crucial role in various sectors such astransportation systems, logistics, and supply chain management. However,existing methods are limited by their ability to handle large, complexdatasets. To overcome this limitation, we introduce a hybrid approach thatcombines the strengths of open-source large and small-scale language models(LLMs and LMs) with traditional forecasting methods. We augment traditionalmethods with dynamic prompting and a grouped-query, multi-head attentionmechanism to more effectively capture both intra-series and inter-seriesdependencies in evolving nonlinear time series data. In addition, we facilitateon-premises customization by fine-tuning smaller open-source LMs for timeseries trend analysis utilizing descriptions generated by open-source large LMson consumer-grade hardware using Low-Rank Adaptation with Activation MemoryReduction (LoRA-AMR) technique to reduce computational overhead and activationstorage memory demands while preserving inference latency. We combine languagemodel processing for time series trend analysis with traditional time seriesrepresentation learning method for cross-modal integration, achieving robustand accurate forecasts. The framework effectiveness is demonstrated throughextensive experiments on various real-world datasets, outperforming existingmethods by significant margins in terms of forecast accuracy.</description><author>Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Mon, 26 Aug 2024 16:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14387v1</guid></item><item><title>LLM-3D Print: Large Language Models To Monitor and Control 3D Printing</title><link>http://arxiv.org/abs/2408.14307v1</link><description>Industry 4.0 has revolutionized manufacturing by driving digitalization andshifting the paradigm toward additive manufacturing (AM). Fused DepositionModeling (FDM), a key AM technology, enables the creation of highly customized,cost-effective products with minimal material waste through layer-by-layerextrusion, posing a significant challenge to traditional subtractive methods.However, the susceptibility of material extrusion techniques to errors oftenrequires expert intervention to detect and mitigate defects that can severelycompromise product quality. While automated error detection and machinelearning models exist, their generalizability across diverse 3D printer setups,firmware, and sensors is limited, and deep learning methods require extensivelabeled datasets, hindering scalability and adaptability. To address thesechallenges, we present a process monitoring and control framework thatleverages pre-trained Large Language Models (LLMs) alongside 3D printers todetect and address printing defects. The LLM evaluates print quality byanalyzing images captured after each layer or print segment, identifyingfailure modes and querying the printer for relevant parameters. It thengenerates and executes a corrective action plan. We validated the effectivenessof the proposed framework in identifying defects by comparing it against acontrol group of engineers with diverse AM expertise. Our evaluationdemonstrated that LLM-based agents not only accurately identify common 3Dprinting errors, such as inconsistent extrusion, stringing, warping, and layeradhesion, but also effectively determine the parameters causing these failuresand autonomously correct them without any need for human intervention.</description><author>Yayati Jadhav, Peter Pak, Amir Barati Farimani</author><pubDate>Mon, 26 Aug 2024 14:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14307v1</guid></item><item><title>Advancing Enterprise Spatio-Temporal Forecasting Applications: Data Mining Meets Instruction Tuning of Language Models For Multi-modal Time Series Analysis in Low-Resource Settings</title><link>http://arxiv.org/abs/2408.13622v1</link><description>Spatio-temporal forecasting is crucial in transportation, logistics, andsupply chain management. However, current methods struggle with large, complexdatasets. We propose a dynamic, multi-modal approach that integrates thestrengths of traditional forecasting methods and instruction tuning of smalllanguage models for time series trend analysis. This approach utilizes amixture of experts (MoE) architecture with parameter-efficient fine-tuning(PEFT) methods, tailored for consumer hardware to scale up AI solutions in lowresource settings while balancing performance and latency tradeoffs.Additionally, our approach leverages related past experiences for similar inputtime series to efficiently handle both intra-series and inter-seriesdependencies of non-stationary data with a time-then-space modeling approach,using grouped-query attention, while mitigating the limitations of traditionalforecasting techniques in handling distributional shifts. Our approach modelspredictive uncertainty to improve decision-making. Our framework enableson-premises customization with reduced computational and memory demands, whilemaintaining inference speed and data privacy/security. Extensive experiments onvarious real-world datasets demonstrate that our framework provides robust andaccurate forecasts, significantly outperforming existing methods.</description><author>Sagar Srinivas Sakhinana, Geethan Sannidhi, Chidaksh Ravuru, Venkataramana Runkana</author><pubDate>Sat, 24 Aug 2024 16:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13622v1</guid></item><item><title>MergeRepair: An Exploratory Study on Merging Task-Specific Adapters in Code LLMs for Automated Program Repair</title><link>http://arxiv.org/abs/2408.09568v2</link><description>[Context] Large Language Models (LLMs) have shown good performance in severalsoftware development-related tasks such as program repair, documentation, coderefactoring, debugging, and testing. Adapters are specialized, small modulesdesigned for parameter efficient fine-tuning of LLMs for specific tasks,domains, or applications without requiring extensive retraining of the entiremodel. These adapters offer a more efficient way to customize LLMs forparticular needs, leveraging the pre-existing capabilities of the large model.Merging LLMs and adapters has shown promising results for various naturallanguage domains and tasks, enabling the use of the learned models and adapterswithout additional training for a new task. [Objective] This research proposescontinual merging and empirically studies the capabilities of merged adaptersin Code LLMs, specially for the Automated Program Repair (APR) task. The goalis to gain insights into whether and how merging task-specific adapters canaffect the performance of APR. [Method] In our framework, MergeRepair, we planto merge multiple task-specific adapters using three different merging methodsand evaluate the performance of the merged adapter for the APR task.Particularly, we will employ two main merging scenarios for all threetechniques, (i) merging using equal-weight averaging applied on parameters ofdifferent adapters, where all adapters are of equal importance; and (ii) ourproposed approach, continual merging, in which we sequentially merge thetask-specific adapters and the order and weight of merged adapters matter. Byexploratory study of merging techniques, we will investigate the improvementand generalizability of merged adapters for APR. Through continual merging, wewill explore the capability of merged adapters and the effect of task order, asit occurs in real-world software projects.</description><author>Meghdad Dehghan, Jie JW Wu, Fatemeh H. Fard, Ali Ouni</author><pubDate>Mon, 26 Aug 2024 19:27:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09568v2</guid></item><item><title>Flextron: Many-in-One Flexible Large Language Model</title><link>http://arxiv.org/abs/2406.10260v2</link><description>Training modern LLMs is extremely resource intensive, and customizing themfor various deployment scenarios characterized by limited compute and memoryresources through repeated training is impractical. In this paper, we introduceFlextron, a network architecture and post-training model optimization frameworksupporting flexible model deployment. The Flextron architecture utilizes anested elastic structure to rapidly adapt to specific user-defined latency andaccuracy targets during inference with no additional fine-tuning required. Itis also input-adaptive, and can automatically route tokens through itssub-networks for improved performance and efficiency. We present asample-efficient training method and associated routing algorithms forsystematically transforming an existing trained LLM into a Flextron model. Weevaluate Flextron on the GPT-3 and LLama-2 family of LLMs, and demonstratesuperior performance over multiple end-to-end trained variants and otherstate-of-the-art elastic networks, all with a single pretraining run thatconsumes a mere 7.63% tokens compared to original pretraining.</description><author>Ruisi Cai, Saurav Muralidharan, Greg Heinrich, Hongxu Yin, Zhangyang Wang, Jan Kautz, Pavlo Molchanov</author><pubDate>Wed, 28 Aug 2024 17:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10260v2</guid></item><item><title>Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection</title><link>http://arxiv.org/abs/2408.15866v1</link><description>The current technology landscape lacks a foundational AI model for solvingprocess engineering calculations. In this work, we introduce a novel autonomousagent framework leveraging Retrieval-Augmented Instruction-Tuning (RAIT) toenhance open, customizable small code language models (SLMs) for thesecalculations. By combining instruction tuned code SLMs with Retrieval-AugmentedCode Generation (RACG) using external tools, the agent generates, debugs, andoptimizes code from natural language specifications. Our approach addresses thelimitations of the current lack of a foundational AI model for specializedprocess engineering tasks and offers benefits of explainability, knowledgeediting, and cost-effectiveness. Additionally, we curate custom datasets ofchemical and process engineering problems and solutions to overcome datascarcity. Experimental results show that our framework matches the performanceof large-scale proprietary models on benchmark datasets, proving itseffectiveness and usability.</description><author>Sagar Srinivas Sakhinana, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Wed, 28 Aug 2024 15:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15866v1</guid></item><item><title>An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders</title><link>http://arxiv.org/abs/2408.16032v1</link><description>Recent advancements in large language models (LLMs) have enabledunderstanding webpage contexts, product details, and human instructions.Utilizing LLMs as the foundational architecture for either reward models orpolicies in reinforcement learning has gained popularity -- a notableachievement is the success of InstructGPT. RL algorithms have been instrumentalin maximizing long-term customer satisfaction and avoiding short-term, myopicgoals in industrial recommender systems, which often rely on deep learningmodels to predict immediate clicks or purchases. In this project, several RL methods are implemented and evaluated using theWebShop benchmark environment, data, simulator, and pre-trained modelcheckpoints. The goal is to train an RL agent to maximize the purchase rewardgiven a detailed human instruction describing a desired product. The RL agentsare developed by fine-tuning a pre-trained BERT model with various objectives,learning from preferences without a reward model, and employing contemporarytraining techniques such as Proximal Policy Optimization (PPO) as used inInstructGPT, and Direct Preference Optimization (DPO). This report alsoevaluates the RL agents trained using generative trajectories. Evaluations wereconducted using Thompson sampling in the WebShop simulator environment. The simulated online experiments demonstrate that agents trained on generatedtrajectories exhibited comparable task performance to those trained using humantrajectories. This has demonstrated an example of an extremely low-costdata-efficient way of training reinforcement learning agents. Also, withlimited training time (&lt;2hours), without utilizing any images, a DPO agentachieved a 19% success rate after approximately 3000 steps or 30 minutes oftraining on T4 GPUs, compared to a PPO agent, which reached a 15% success rate.</description><author>Shuang Feng, Grace Feng</author><pubDate>Wed, 28 Aug 2024 10:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16032v1</guid></item><item><title>Look, Compare, Decide: Alleviating Hallucination in Large Vision-Language Models via Multi-View Multi-Path Reasoning</title><link>http://arxiv.org/abs/2408.17150v1</link><description>Recently, Large Vision-Language Models (LVLMs) have demonstrated impressivecapabilities in multi-modal context comprehension. However, they still sufferfrom hallucination problems referring to generating inconsistent outputs withthe image content. To mitigate hallucinations, previous studies mainly focus onretraining LVLMs with custom datasets. Although effective, they inherently comewith additional computational costs. In this paper, we propose a training-freeframework, \textbf{MVP}, that aims to reduce hallucinations by making the mostof the innate capabilities of the LVLMs via \textbf{M}ulti-\textbf{V}iewMulti-\textbf{P}ath Reasoning. Specifically, we first devise a multi-viewinformation-seeking strategy to thoroughly perceive the comprehensiveinformation in the image, which enriches the general global informationcaptured by the original vision encoder in LVLMs. Furthermore, during theanswer decoding, we observe that the occurrence of hallucinations has a strongcorrelation with the certainty of the answer tokens. Thus, we proposemulti-path reasoning for each information view to quantify and aggregate thecertainty scores for each potential answer among multiple decoding paths andfinally decide the output answer. By fully grasping the information in theimage and carefully considering the certainty of the potential answers whendecoding, our MVP can effectively reduce hallucinations in LVLMs.The extensiveexperiments verify that our proposed MVP significantly mitigates thehallucination problem across four well-known LVLMs. The source code isavailable at: \url{https://github.com/GasolSun36/MVP}.</description><author>Xiaoye Qu, Jiashuo Sun, Wei Wei, Yu Cheng</author><pubDate>Fri, 30 Aug 2024 09:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17150v1</guid></item><item><title>Manipulating Large Language Models to Increase Product Visibility</title><link>http://arxiv.org/abs/2404.07981v2</link><description>Large language models (LLMs) are increasingly being integrated into searchengines to provide natural language responses tailored to user queries.Customers and end-users are also becoming more dependent on these models forquick and easy purchase decisions. In this work, we investigate whetherrecommendations from LLMs can be manipulated to enhance a product's visibility.We demonstrate that adding a strategic text sequence (STS) -- a carefullycrafted message -- to a product's information page can significantly increaseits likelihood of being listed as the LLM's top recommendation. To understandthe impact of STS, we use a catalog of fictitious coffee machines and analyzeits effect on two target products: one that seldom appears in the LLM'srecommendations and another that usually ranks second. We observe that thestrategic text sequence significantly enhances the visibility of both productsby increasing their chances of appearing as the top recommendation. Thisability to manipulate LLM-generated search responses provides vendors with aconsiderable competitive advantage and has the potential to disrupt fair marketcompetition. Just as search engine optimization (SEO) revolutionized howwebpages are customized to rank higher in search engine results, influencingLLM recommendations could profoundly impact content optimization for AI-drivensearch services. Code for our experiments is available athttps://github.com/aounon/llm-rank-optimizer.</description><author>Aounon Kumar, Himabindu Lakkaraju</author><pubDate>Mon, 02 Sep 2024 21:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07981v2</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v4</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Mon, 02 Sep 2024 20:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v4</guid></item><item><title>ERATTA: Extreme RAG for Table To Answers with Large Language Models</title><link>http://arxiv.org/abs/2405.03963v3</link><description>Large language models (LLMs) with retrieval augmented-generation (RAG) havebeen the optimal choice for scalable generative AI solutions in the recentpast. Although RAG implemented with AI agents (agentic-RAG) has been recentlypopularized, its suffers from unstable cost and unreliable performances forEnterprise-level data-practices. Most existing use-cases that incorporate RAGwith LLMs have been either generic or extremely domain specific, therebyquestioning the scalability and generalizability of RAG-LLM approaches. In thiswork, we propose a unique LLM-based system where multiple LLMs can be invokedto enable data authentication, user-query routing, data-retrieval and customprompting for question-answering capabilities from Enterprise-data tables. Thesource tables here are highly fluctuating and large in size and the proposedframework enables structured responses in under 10 seconds per query.Additionally, we propose a five metric scoring module that detects and reportshallucinations in the LLM responses. Our proposed system and scoring metricsachieve &gt;90% confidence scores across hundreds of user queries in thesustainability, financial health and social media domains. Extensions to theproposed extreme RAG architectures can enable heterogeneous source queryingusing LLMs.</description><author>Sohini Roychowdhury, Marko Krema, Anvar Mahammad, Brian Moore, Arijit Mukherjee, Punit Prakashchandra</author><pubDate>Mon, 02 Sep 2024 06:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03963v3</guid></item><item><title>An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models</title><link>http://arxiv.org/abs/2403.06764v3</link><description>In this study, we identify the inefficient attention phenomena in LargeVision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5,QwenVL-Chat and Video-LLaVA. We find out that the attention computation overvisual tokens is of extreme inefficiency in the deep layers of popular LVLMs,suggesting a need for a sparser approach compared to textual data handling. Tothis end, we introduce FastV, a versatile plug-and-play method designed tooptimize computational efficiency by learning adaptive attention patterns inearly layers and pruning visual tokens in subsequent ones. Our evaluationsdemonstrate FastV's ability to dramatically reduce computational costs (e.g., a45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in awide range of image and video understanding tasks. The computational efficiencyand performance trade-off of FastV are highly customizable andpareto-efficient. It can compress the FLOPs of a 13B-parameter model to achievea lower budget than that of a 7B-parameter model, while still maintainingsuperior performance. We believe FastV has practical values for deployment ofLVLMs in edge devices and commercial models. Code is released athttps://github.com/pkunlp-icler/FastV.</description><author>Liang Chen, Haozhe Zhao, Tianyu Liu, Shuai Bai, Junyang Lin, Chang Zhou, Baobao Chang</author><pubDate>Mon, 02 Sep 2024 05:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06764v3</guid></item><item><title>A Versatile Graph Learning Approach through LLM-based Agent</title><link>http://arxiv.org/abs/2309.04565v2</link><description>Designing versatile graph learning approaches is important, considering thediverse graphs and tasks existing in real-world applications. Existing methodshave attempted to achieve this target through automated machine learningtechniques, pre-training and fine-tuning strategies, and large language models.However, these methods are not versatile enough for graph learning, as theywork on either limited types of graphs or a single task. In this paper, wepropose to explore versatile graph learning approaches with LLM-based agents,and the key insight is customizing the graph learning procedures for diversegraphs and tasks. To achieve this, we develop several LLM-based agents,equipped with diverse profiles, tools, functions and human experience. Theycollaborate to configure each procedure with task and data-specific settingsstep by step towards versatile solutions, and the proposed method is dubbedGL-Agent. By evaluating on diverse tasks and graphs, the correct results of theagent and its comparable performance showcase the versatility of the proposedmethod, especially in complex scenarios.The low resource cost and the potentialto use open-source LLMs highlight the efficiency of GL-Agent.</description><author>Lanning Wei, Huan Zhao, Xiaohan Zheng, Zhiqiang He, Quanming Yao</author><pubDate>Sun, 01 Sep 2024 13:12:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04565v2</guid></item><item><title>Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL</title><link>http://arxiv.org/abs/2409.02711v1</link><description>The developments in the field of generative AI has brought a lot ofopportunities for companies, for instance to improve efficiency in customerservice and automating tasks. PostNL, the biggest parcel and E-commercecorporation of the Netherlands wants to use generative AI to enhance thecommunication around track and trace of parcels. During the internship aMinimal Viable Product (MVP) is created to showcase the value of usinggenerative AI technologies, to enhance parcel tracking, analyzing the parcel'sjourney and being able to communicate about it in an easy to understand manner.The primary goal was to develop an in-house LLM-based system, reducingdependency on external platforms and establishing the feasibility of adedicated generative AI team within the company. This multi-agent LLM basedsystem aimed to construct parcel journey stories and identify logisticaldisruptions with heightened efficiency and accuracy. The research involveddeploying a sophisticated AI-driven communication system, employingRetrieval-Augmented Generation (RAG) for enhanced response precision, andoptimizing large language models (LLMs) tailored to domain specific tasks. The MVP successfully implemented a multi-agent open-source LLM system, calledSuperTracy. SuperTracy is capable of autonomously managing a broad spectrum ofuser inquiries and improving internal knowledge handling. Results andevaluation demonstrated technological innovation and feasibility, notably incommunication about the track and trace of a parcel, which exceeded initialexpectations. These advancements highlight the potential of AI-driven solutionsin logistics, suggesting many opportunities for further refinement and broaderimplementation within PostNL operational framework.</description><author>Mohammad Reshadati</author><pubDate>Wed, 04 Sep 2024 13:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02711v1</guid></item><item><title>Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning</title><link>http://arxiv.org/abs/2409.02428v1</link><description>Leveraging large language models (LLMs) for designing reward functionsdemonstrates significant potential. However, achieving effective design andimprovement of reward functions in reinforcement learning (RL) tasks withcomplex custom environments and multiple requirements presents considerablechallenges. In this paper, we enable LLMs to be effective white-box searchers,highlighting their advanced semantic understanding capabilities. Specifically,we generate reward components for each explicit user requirement and employ thereward critic to identify the correct code form. Then, LLMs assign weights tothe reward components to balance their values and iteratively search andoptimize these weights based on the context provided by the training loganalyzer, while adaptively determining the search step size. We applied theframework to an underwater information collection RL task without direct humanfeedback or reward examples (zero-shot). The reward critic successfully correctthe reward code with only one feedback for each requirement, effectivelypreventing irreparable errors that can occur when reward function feedback isprovided in aggregate. The effective initialization of weights enables theacquisition of different reward functions within the Pareto solution setwithout weight search. Even in the case where a weight is 100 times off, fewerthan four iterations are needed to obtain solutions that meet userrequirements. The framework also works well with most prompts utilizing GPT-3.5Turbo, since it does not require advanced numerical understanding orcalculation.</description><author>Guanwen Xie, Jingzehua Xu, Yiyuan Yang, Shuai Zhang</author><pubDate>Wed, 04 Sep 2024 04:15:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02428v1</guid></item><item><title>How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review</title><link>http://arxiv.org/abs/2409.02375v1</link><description>The recent advances in large language models (LLMs) have significantlyexpanded their applications across various fields such as language generation,summarization, and complex question answering. However, their application toprivacy compliance and technical privacy reviews remains under-explored,raising critical concerns about their ability to adhere to global privacystandards and protect sensitive user data. This paper seeks to address this gapby providing a comprehensive case study evaluating LLMs' performance inprivacy-related tasks such as privacy information extraction (PIE), legal andregulatory key point detection (KPD), and question answering (QA) with respectto privacy policies and data protection regulations. We introduce a PrivacyTechnical Review (PTR) framework, highlighting its role in mitigating privacyrisks during the software development life-cycle. Through an empiricalassessment, we investigate the capacity of several prominent LLMs, includingBERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checksand technical privacy reviews. Our experiments benchmark the models acrossmultiple dimensions, focusing on their precision, recall, and F1-scores inextracting privacy-sensitive information and detecting key regulatorycompliance points. While LLMs show promise in automating privacy reviews andidentifying regulatory discrepancies, significant gaps persist in their abilityto fully comply with evolving legal standards. We provide actionablerecommendations for enhancing LLMs' capabilities in privacy compliance,emphasizing the need for robust model improvements and better integration withlegal and regulatory requirements. This study underscores the growingimportance of developing privacy-aware LLMs that can both support businesses incompliance efforts and safeguard user privacy rights.</description><author>Xichou Zhu, Yang Liu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma, Tao Hu, Bolong Yang, Manman Wang, Zongxing Xie, Peng Liu, Dan Cai, Junhui Wang</author><pubDate>Wed, 04 Sep 2024 01:51:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02375v1</guid></item><item><title>RAG based Question-Answering for Contextual Response Prediction System</title><link>http://arxiv.org/abs/2409.03708v1</link><description>Large Language Models (LLMs) have shown versatility in various NaturalLanguage Processing (NLP) tasks, including their potential as effectivequestion-answering systems. However, to provide precise and relevantinformation in response to specific customer queries in industry settings, LLMsrequire access to a comprehensive knowledge base to avoid hallucinations.Retrieval Augmented Generation (RAG) emerges as a promising technique toaddress this challenge. Yet, developing an accurate question-answeringframework for real-world applications using RAG entails several challenges: 1)data availability issues, 2) evaluating the quality of generated content, and3) the costly nature of human evaluation. In this paper, we introduce anend-to-end framework that employs LLMs with RAG capabilities for industry usecases. Given a customer query, the proposed system retrieves relevant knowledgedocuments and leverages them, along with previous chat history, to generateresponse suggestions for customer service agents in the contact centers of amajor retail company. Through comprehensive automated and human evaluations, weshow that this solution outperforms the current BERT-based algorithms inaccuracy and relevance. Our findings suggest that RAG-based LLMs can be anexcellent support to human customer service representatives by lightening theirworkload.</description><author>Sriram Veturi, Saurabh Vaichal, Nafis Irtiza Tripto, Reshma Lal Jagadheesh, Nian Yan</author><pubDate>Thu, 05 Sep 2024 17:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03708v1</guid></item><item><title>RAG based Question-Answering for Contextual Response Prediction System</title><link>http://arxiv.org/abs/2409.03708v2</link><description>Large Language Models (LLMs) have shown versatility in various NaturalLanguage Processing (NLP) tasks, including their potential as effectivequestion-answering systems. However, to provide precise and relevantinformation in response to specific customer queries in industry settings, LLMsrequire access to a comprehensive knowledge base to avoid hallucinations.Retrieval Augmented Generation (RAG) emerges as a promising technique toaddress this challenge. Yet, developing an accurate question-answeringframework for real-world applications using RAG entails several challenges: 1)data availability issues, 2) evaluating the quality of generated content, and3) the costly nature of human evaluation. In this paper, we introduce anend-to-end framework that employs LLMs with RAG capabilities for industry usecases. Given a customer query, the proposed system retrieves relevant knowledgedocuments and leverages them, along with previous chat history, to generateresponse suggestions for customer service agents in the contact centers of amajor retail company. Through comprehensive automated and human evaluations, weshow that this solution outperforms the current BERT-based algorithms inaccuracy and relevance. Our findings suggest that RAG-based LLMs can be anexcellent support to human customer service representatives by lightening theirworkload.</description><author>Sriram Veturi, Saurabh Vaichal, Reshma Lal Jagadheesh, Nafis Irtiza Tripto, Nian Yan</author><pubDate>Fri, 06 Sep 2024 14:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03708v2</guid></item><item><title>Prompt2Fashion: An automatically generated fashion dataset</title><link>http://arxiv.org/abs/2409.06442v1</link><description>Despite the rapid evolution and increasing efficacy of language and visiongenerative models, there remains a lack of comprehensive datasets that bridgethe gap between personalized fashion needs and AI-driven design, limiting thepotential for truly inclusive and customized fashion solutions. In this work,we leverage generative models to automatically construct a fashion imagedataset tailored to various occasions, styles, and body types as instructed byusers. We use different Large Language Models (LLMs) and prompting strategiesto offer personalized outfits of high aesthetic quality, detail, and relevanceto both expert and non-expert users' requirements, as demonstrated byqualitative analysis. Up until now the evaluation of the generated outfits hasbeen conducted by non-expert human subjects. Despite the provided fine-grainedinsights on the quality and relevance of generation, we extend the discussionon the importance of expert knowledge for the evaluation of artisticAI-generated datasets such as this one. Our dataset is publicly available onGitHub at https://github.com/georgiarg/Prompt2Fashion.</description><author>Georgia Argyro, Angeliki Dimitriou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou</author><pubDate>Tue, 10 Sep 2024 11:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06442v1</guid></item><item><title>Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization</title><link>http://arxiv.org/abs/2409.06433v1</link><description>The increasing amount of published scholarly articles, exceeding 2.5 millionyearly, raises the challenge for researchers in following scientific progress.Integrating the contributions from scholarly articles into a novel type ofcognitive knowledge graph (CKG) will be a crucial element for accessing andorganizing scholarly knowledge, surpassing the insights provided by titles andabstracts. This research focuses on effectively conveying structured scholarlyknowledge by utilizing large language models (LLMs) to categorize scholarlyarticles and describe their contributions in a structured and comparablemanner. While previous studies explored language models within specificresearch domains, the extensive domain-independent knowledge captured by LLMsoffers a substantial opportunity for generating structured contributiondescriptions as CKGs. Additionally, LLMs offer customizable pathways throughprompt engineering or fine-tuning, thus facilitating to leveraging of smallerLLMs known for their efficiency, cost-effectiveness, and environmentalconsiderations. Our methodology involves harnessing LLM knowledge, andcomplementing it with domain expert-verified scholarly data sourced from a CKG.This strategic fusion significantly enhances LLM performance, especially intasks like scholarly article categorization and predicate recommendation. Ourmethod involves fine-tuning LLMs with CKG knowledge and additionally injectingknowledge from a CKG with a novel prompting technique significantly increasingthe accuracy of scholarly knowledge extraction. We integrated our approach inthe Open Research Knowledge Graph (ORKG), thus enabling precise access toorganized scholarly knowledge, crucially benefiting domain-independentscholarly knowledge exchange and dissemination among policymakers, industrialpractitioners, and the general public.</description><author>Gollam Rabby, Sören Auer, Jennifer D'Souza, Allard Oelen</author><pubDate>Tue, 10 Sep 2024 11:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06433v1</guid></item><item><title>DocGenome: An Open Large-scale Scientific Document Benchmark for Training and Testing Multi-modal Large Language Models</title><link>http://arxiv.org/abs/2406.11633v2</link><description>Scientific documents record research findings and valuable human knowledge,comprising a vast corpus of high-quality data. Leveraging multi-modality dataextracted from these documents and assessing large models' abilities to handlescientific document-oriented tasks is therefore meaningful. Despite promisingadvancements, large models still perform poorly on multi-page scientificdocument extraction and understanding tasks, and their capacity to processwithin-document data formats such as charts and equations remainsunder-explored. To address these issues, we present DocGenome, a structureddocument benchmark constructed by annotating 500K scientific documents from 153disciplines in the arXiv open-access community, using our custom auto-labelingpipeline. DocGenome features four key characteristics: 1) Completeness: It isthe first dataset to structure data from all modalities including 13 layoutattributes along with their LaTeX source codes. 2) Logicality: It provides 6logical relationships between different entities within each scientificdocument. 3) Diversity: It covers various document-oriented tasks, includingdocument classification, visual grounding, document layout detection, documenttransformation, open-ended single-page QA and multi-page QA. 4) Correctness: Itundergoes rigorous quality control checks conducted by a specialized team. Weconduct extensive experiments to demonstrate the advantages of DocGenome andobjectively evaluate the performance of large models on our benchmark.</description><author>Renqiu Xia, Song Mao, Xiangchao Yan, Hongbin Zhou, Bo Zhang, Haoyang Peng, Jiahao Pi, Daocheng Fu, Wenjie Wu, Hancheng Ye, Shiyang Feng, Bin Wang, Chao Xu, Conghui He, Pinlong Cai, Min Dou, Botian Shi, Sheng Zhou, Yongwei Wang, Bin Wang, Junchi Yan, Fei Wu, Yu Qiao</author><pubDate>Wed, 11 Sep 2024 11:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11633v2</guid></item><item><title>Market Reaction to News Flows in Supply Chain Networks</title><link>http://arxiv.org/abs/2409.06255v1</link><description>This study examines whether positive news about firms increases their stockprices and, moreover, whether it increases stock prices of the firms' suppliersand customers, using a large sample of publicly listed firms across the worldand another of Japanese listed firms. The level of positiveness of each newsarticle is determined by FinBERT, a natural language processing modelfine-tuned specifically for financial information. Supply chains of firmsacross the world are identified mostly by financial statements, while those ofJapanese firms are taken from large-scale firm-level surveys. We find thatpositive news increases the change rate of stock prices of firms mentioned inthe news before its disclosure, most likely because of diffusion of informationthrough informal channels. Positive news also raises stock prices of the firms'suppliers and customers before its disclosure, confirming propagation of marketvalues through supply chains. In addition, we generally find a larger post-newseffect on stock prices of the mentioned firms and their suppliers and customersthan the pre-news effect. The positive difference between the post- andpre-news effects can be considered as the net effect of the disclosure ofpositive news, controlling for informal information diffusion. However, thepost-news effect on suppliers and customers in Japan is smaller than thepre-news effect, a result opposite to those from firms across the world. Thisnotable result is possibly because supply chain links of Japanese firms arestronger than global supply chains while such knowledge is restricted toselected investors.</description><author>Hiroyasu Inoue, Yasuyuki Todo</author><pubDate>Tue, 10 Sep 2024 06:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06255v1</guid></item><item><title>Revisiting Prompt Pretraining of Vision-Language Models</title><link>http://arxiv.org/abs/2409.06166v1</link><description>Prompt learning is an effective method to customize Vision-Language Models(VLMs) for various downstream tasks, involving tuning very few parameters ofinput prompt tokens. Recently, prompt pretraining in large-scale dataset (e.g.,ImageNet-21K) has played a crucial role in prompt learning for universal visualdiscrimination. However, we revisit and observe that the limited learnableprompts could face underfitting risks given the extensive images during promptpretraining, simultaneously leading to poor generalization. To address theabove issues, in this paper, we propose a general framework termed RevisitingPrompt Pretraining (RPP), which targets at improving the fitting andgeneralization ability from two aspects: prompt structure and promptsupervision. For prompt structure, we break the restriction in common practicewhere query, key, and value vectors are derived from the shared learnableprompt token. Instead, we introduce unshared individual query, key, and valuelearnable prompts, thereby enhancing the model's fitting capacity throughincreased parameter diversity. For prompt supervision, we additionally utilizesoft labels derived from zero-shot probability predictions provided by apretrained Contrastive Language Image Pretraining (CLIP) teacher model. Thesesoft labels yield more nuanced and general insights into the inter-classrelationships, thereby endowing the pretraining process with bettergeneralization ability. RPP produces a more resilient prompt initialization,enhancing its robust transferability across diverse visual recognition tasks.Experiments across various benchmarks consistently confirm the state-of-the-art(SOTA) performance of our pretrained prompts. Codes and models will be madeavailable soon.</description><author>Zhenyuan Chen, Lingfeng Yang, Shuo Chen, Zhaowei Chen, Jiajun Liang, Xiang Li</author><pubDate>Tue, 10 Sep 2024 02:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06166v1</guid></item><item><title>TravelAgent: An AI Assistant for Personalized Travel Planning</title><link>http://arxiv.org/abs/2409.08069v1</link><description>As global tourism expands and artificial intelligence technology advances,intelligent travel planning services have emerged as a significant researchfocus. Within dynamic real-world travel scenarios with multi-dimensionalconstraints, services that support users in automatically creating practicaland customized travel itineraries must address three key objectives:Rationality, Comprehensiveness, and Personalization. However, existing systemswith rule-based combinations or LLM-based planning methods struggle to fullysatisfy these criteria. To overcome the challenges, we introduce TravelAgent, atravel planning system powered by large language models (LLMs) designed toprovide reasonable, comprehensive, and personalized travel itineraries groundedin dynamic scenarios. TravelAgent comprises four modules: Tool-usage,Recommendation, Planning, and Memory Module. We evaluate TravelAgent'sperformance with human and simulated users, demonstrating its overalleffectiveness in three criteria and confirming the accuracy of personalizedrecommendations.</description><author>Aili Chen, Xuyang Ge, Ziquan Fu, Yanghua Xiao, Jiangjie Chen</author><pubDate>Thu, 12 Sep 2024 14:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08069v1</guid></item><item><title>Prompt2Fashion: An automatically generated fashion dataset</title><link>http://arxiv.org/abs/2409.06442v2</link><description>Despite the rapid evolution and increasing efficacy of language and visiongenerative models, there remains a lack of comprehensive datasets that bridgethe gap between personalized fashion needs and AI-driven design, limiting thepotential for truly inclusive and customized fashion solutions. In this work,we leverage generative models to automatically construct a fashion imagedataset tailored to various occasions, styles, and body types as instructed byusers. We use different Large Language Models (LLMs) and prompting strategiesto offer personalized outfits of high aesthetic quality, detail, and relevanceto both expert and non-expert users' requirements, as demonstrated byqualitative analysis. Up until now the evaluation of the generated outfits hasbeen conducted by non-expert human subjects. Despite the provided fine-grainedinsights on the quality and relevance of generation, we extend the discussionon the importance of expert knowledge for the evaluation of artisticAI-generated datasets such as this one. Our dataset is publicly available onGitHub at https://github.com/georgiarg/Prompt2Fashion.</description><author>Georgia Argyrou, Angeliki Dimitriou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou</author><pubDate>Thu, 12 Sep 2024 18:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06442v2</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v7</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adjusting the large modelsover the various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large model to adapt it to a specifictask or domain while minimizing the number of additional parameters introducedor computational resources required. This approach is particularly importantwhen dealing with large-scale language models with high parameter counts, asfine-tuning these models from scratch can be computationally expensive andresource-intensive, posing considerable challenges in the supporting systemplatform design. In this survey, we present comprehensive studies of variousPEFT algorithms, examining their performance and computational overhead.Moreover, we provide an overview of applications developed using different PEFTalgorithms and discuss common techniques employed to mitigate computation costsfor PEFT. In addition to providing an extensive survey from an algorithmicstandpoint, we also examine various real-world system designs to investigatethe implementation costs associated with different PEFT approaches. This surveyserves as a valuable resource for researchers aiming to understand both thePEFT algorithm and its system implementation, offering detailed ......</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Mon, 16 Sep 2024 02:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v7</guid></item></channel></rss>